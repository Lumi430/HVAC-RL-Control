Using TensorFlow backend.
[2019-04-06 14:50:13,194] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part4_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part4-Light-Pit-Train-Repeat-v1', eval_act_func='part4_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=20000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=5e-06, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2000000, metric_func='part4_v1', model_dir='None', model_param=[64, 2], model_type='nn', num_threads=16, output='./Part4-Light-Pit-Train-Repeat-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part4_heuri_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=0.5, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=10, test_env=['Part4-Light-Pit-Test-Repeat-v1', 'Part4-Light-Pit-Test-Repeat-v2'], test_mode='Multiple', train_act_func='part4_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=10.0, weight_initer='glorot_uniform', window_len=7)
[2019-04-06 14:50:13,194] A3C_AGENT_MAIN INFO:Start compiling...
2019-04-06 14:50:13.232112: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-04-06 14:50:30,042] A3C_AGENT_MAIN INFO:Start the learning...
[2019-04-06 14:50:30,042] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part4-Light-Pit-Train-Repeat-v1', 'Part4-Light-Pit-Test-Repeat-v1', 'Part4-Light-Pit-Test-Repeat-v2'] ...
[2019-04-06 14:50:30,065] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation worker starts!
[2019-04-06 14:50:30,090] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation worker starts!
[2019-04-06 14:50:30,114] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation worker starts!
[2019-04-06 14:50:30,114] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:30,115] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-04-06 14:50:30,188] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:30,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run1
[2019-04-06 14:50:31,116] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:31,117] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-04-06 14:50:31,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:31,198] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run1
[2019-04-06 14:50:32,118] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:32,119] A3C_AGENT_WORKER-Thread-4 INFO:Local worker starts!
[2019-04-06 14:50:32,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:32,202] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run1
[2019-04-06 14:50:33,120] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:33,121] A3C_AGENT_WORKER-Thread-5 INFO:Local worker starts!
[2019-04-06 14:50:33,204] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:33,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run1
[2019-04-06 14:50:34,122] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:34,123] A3C_AGENT_WORKER-Thread-6 INFO:Local worker starts!
[2019-04-06 14:50:34,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:34,210] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run1
[2019-04-06 14:50:34,382] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 14:50:34,382] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 14:50:34,382] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:34,383] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 14:50:34,383] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 14:50:34,383] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:34,383] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:34,387] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run1
[2019-04-06 14:50:34,400] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run1
[2019-04-06 14:50:34,411] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run1
[2019-04-06 14:50:35,124] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:35,125] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-04-06 14:50:35,259] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:35,260] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run1
[2019-04-06 14:50:36,126] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:36,127] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-04-06 14:50:36,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:36,267] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run1
[2019-04-06 14:50:37,128] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:37,129] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-04-06 14:50:37,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:37,251] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run1
[2019-04-06 14:50:38,130] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:38,131] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-04-06 14:50:38,275] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:38,276] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run1
[2019-04-06 14:50:39,132] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:39,132] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-04-06 14:50:39,204] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:39,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run1
[2019-04-06 14:50:40,133] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:40,134] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-04-06 14:50:40,276] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:40,278] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run1
[2019-04-06 14:50:41,135] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:41,136] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-04-06 14:50:41,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:41,259] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run1
[2019-04-06 14:50:42,137] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:42,138] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-04-06 14:50:42,306] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:42,307] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run1
[2019-04-06 14:50:43,138] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:43,139] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-04-06 14:50:43,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:43,263] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run1
[2019-04-06 14:50:44,140] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:44,141] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-04-06 14:50:44,347] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:44,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run1
[2019-04-06 14:50:45,142] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:45,142] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-04-06 14:50:45,227] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:45,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run1
[2019-04-06 14:52:11,715] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-04-06 14:52:11,715] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-4.15, 67.0, 81.0, 350.0, 22.0, 22.77234023368661, -0.2668080640105639, 1.0, 1.0, 0.0]
[2019-04-06 14:52:11,716] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 14:52:11,717] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [0.14278014 0.13184196 0.16075471 0.15800232 0.10200421 0.16412123
 0.1404955 ], sampled 0.18120520316180122
[2019-04-06 14:52:23,170] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2609.8897 65857561.5273 185.7608
[2019-04-06 14:52:31,528] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2555.2807 75935450.4022 97.1244
[2019-04-06 14:52:40,286] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2574.3178 78575186.9976 60.5587
[2019-04-06 14:52:41,308] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2555.280654058195, 75935450.4022067, 97.12436210953749, 2609.8896569013696, 65857561.52730158, 185.76080234512293, 2574.317801588395, 78575186.99763963, 60.558714036228864]
[2019-04-06 14:52:45,999] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.1368068  0.13093247 0.15649572 0.18235609 0.08876064 0.13733666
 0.16731161], sum to 1.0000
[2019-04-06 14:52:46,000] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7494
[2019-04-06 14:52:46,190] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.3, 86.0, 91.5, 0.0, 20.0, 22.245153861785, -0.3304642298165394, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [21.0], 
sim time this is 46800.0000, 
sim time next is 48600.0000, 
raw observation next is [8.0, 86.0, 87.0, 0.0, 21.0, 22.04656750333527, -0.3666769150870694, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.6842105263157896, 0.86, 0.29, 0.0, 0.25, 0.3372139586112726, 0.3777743616376435, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.21958952], dtype=float32), -1.2130668]. 
=============================================
[2019-04-06 14:53:07,015] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.13159929 0.10981744 0.1250766  0.24045865 0.09192546 0.10059848
 0.20052403], sum to 1.0000
[2019-04-06 14:53:07,015] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3978
[2019-04-06 14:53:08,109] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 25.5, 24.18460986641162, 0.1041045959153221, 1.0, 1.0, 186335.32286778395], 
current ob forecast is [], 
actual action is [25.5], 
sim time this is 234000.0000, 
sim time next is 235800.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 25.5, 25.2060918395346, 0.2120308172618641, 1.0, 1.0, 67250.91368776232], 
processed observation next is [1.0, 0.7391304347826086, 0.368421052631579, 0.65, 0.0, 0.0, 0.625, 0.60050765329455, 0.570676939087288, 1.0, 1.0, 0.32024244613220154], 
reward next is 0.7512, 
noisyNet noise sample is [array([0.43353996], dtype=float32), 0.04449538]. 
=============================================
[2019-04-06 14:53:43,708] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.12743388 0.12664111 0.1361964  0.16626565 0.0927352  0.17875883
 0.17196888], sum to 1.0000
[2019-04-06 14:53:43,709] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0194
[2019-04-06 14:53:44,146] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.6, 85.0, 0.0, 0.0, 19.0, 20.39990521492348, -0.7985348414459373, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [19.0], 
sim time this is 536400.0000, 
sim time next is 538200.0000, 
raw observation next is [1.35, 86.5, 0.0, 0.0, 19.0, 20.13507387442252, -0.8495182330911001, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.5000000000000001, 0.865, 0.0, 0.0, 0.08333333333333333, 0.17792282286854336, 0.21682725563629998, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.53276557], dtype=float32), -0.9391931]. 
=============================================
[2019-04-06 14:54:13,638] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.14282922 0.11355499 0.13868816 0.19364855 0.09825858 0.12841277
 0.18460773], sum to 1.0000
[2019-04-06 14:54:13,638] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5488
[2019-04-06 14:54:14,345] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-3.9, 84.0, 0.0, 0.0, 21.5, 22.67301076498239, -0.4273742317739446, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [21.5], 
sim time this is 840600.0000, 
sim time next is 842400.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 21.5, 22.06382863404725, -0.493463786205433, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3545706371191136, 0.82, 0.0, 0.0, 0.2916666666666667, 0.3386523861706043, 0.33551207126485566, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7350369], dtype=float32), 0.75339824]. 
=============================================
[2019-04-06 14:54:16,155] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.142901   0.11955445 0.16845167 0.19571264 0.09432198 0.1355429
 0.1435154 ], sum to 1.0000
[2019-04-06 14:54:16,156] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4662
[2019-04-06 14:54:16,269] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-7.0, 69.0, 0.0, 0.0, 20.0, 19.0606641933366, -1.006101897701947, 0.0, 1.0, 151115.42508698205], 
current ob forecast is [], 
actual action is [20.0], 
sim time this is 801000.0000, 
sim time next is 802800.0000, 
raw observation next is [-6.7, 67.0, 0.0, 0.0, 20.0, 19.7013465296949, -0.9675163557317704, 0.0, 1.0, 15232.957674008394], 
processed observation next is [1.0, 0.30434782608695654, 0.2770083102493075, 0.67, 0.0, 0.0, 0.16666666666666666, 0.14177887747457488, 0.17749454808940987, 0.0, 1.0, 0.07253789368575425], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9469226], dtype=float32), 0.81979775]. 
=============================================
[2019-04-06 14:54:17,692] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7378: loss 38.6289
[2019-04-06 14:54:17,953] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7378: learning rate 0.0000
[2019-04-06 14:54:18,319] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7412: loss 26.6333
[2019-04-06 14:54:18,319] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7412: learning rate 0.0000
[2019-04-06 14:54:22,543] A3C_AGENT_WORKER-Thread-5 INFO:Local step 500, global step 7712: loss 43.5269
[2019-04-06 14:54:22,544] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 500, global step 7712: learning rate 0.0000
[2019-04-06 14:54:23,066] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7745: loss 35.9025
[2019-04-06 14:54:23,067] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7745: learning rate 0.0000
[2019-04-06 14:54:24,317] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7843: loss 10.7340
[2019-04-06 14:54:24,317] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7843: learning rate 0.0000
[2019-04-06 14:54:24,574] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.11936602 0.09929159 0.21777914 0.19460133 0.0995032  0.11789984
 0.15155883], sum to 1.0000
[2019-04-06 14:54:24,574] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3964
[2019-04-06 14:54:25,093] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.8, 79.0, 0.0, 0.0, 21.0, 21.61840962769372, -0.5124120160203682, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [20.5], 
sim time this is 860400.0000, 
sim time next is 862200.0000, 
raw observation next is [-2.55, 79.5, 0.0, 0.0, 20.5, 21.50057390278405, -0.5531858451725138, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.3919667590027701, 0.795, 0.0, 0.0, 0.20833333333333334, 0.29171449189867094, 0.31560471827582876, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.352976], dtype=float32), -0.36639354]. 
=============================================
[2019-04-06 14:54:25,324] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7909: loss 35.8576
[2019-04-06 14:54:25,369] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7911: learning rate 0.0000
[2019-04-06 14:54:25,816] A3C_AGENT_WORKER-Thread-6 INFO:Local step 500, global step 7958: loss 39.4045
[2019-04-06 14:54:25,816] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 500, global step 7958: learning rate 0.0000
[2019-04-06 14:54:26,807] A3C_AGENT_WORKER-Thread-4 INFO:Local step 500, global step 8061: loss 36.9012
[2019-04-06 14:54:26,809] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 500, global step 8061: learning rate 0.0000
[2019-04-06 14:54:26,978] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 8077: loss 8.8545
[2019-04-06 14:54:27,043] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 8077: learning rate 0.0000
[2019-04-06 14:54:27,581] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8134: loss 40.9921
[2019-04-06 14:54:27,581] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8134: learning rate 0.0000
[2019-04-06 14:54:27,821] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 8164: loss 43.2166
[2019-04-06 14:54:27,822] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 8164: learning rate 0.0000
[2019-04-06 14:54:28,015] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 8187: loss 40.3895
[2019-04-06 14:54:28,016] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 8187: learning rate 0.0000
[2019-04-06 14:54:29,160] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8297: loss 40.4235
[2019-04-06 14:54:29,161] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8297: learning rate 0.0000
[2019-04-06 14:54:31,570] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8543: loss 39.9188
[2019-04-06 14:54:31,571] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8543: learning rate 0.0000
[2019-04-06 14:54:31,886] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 8579: loss 41.6370
[2019-04-06 14:54:31,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 8579: learning rate 0.0000
[2019-04-06 14:54:32,667] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8664: loss 35.2151
[2019-04-06 14:54:32,668] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8664: learning rate 0.0000
[2019-04-06 14:54:43,344] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.14019288 0.13167505 0.12339616 0.24326669 0.14208615 0.09553903
 0.12384401], sum to 1.0000
[2019-04-06 14:54:43,366] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4002
[2019-04-06 14:54:43,449] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [17.7, 67.0, 0.0, 0.0, 21.5, 24.52017517259159, 0.3276633638783334, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [21.5], 
sim time this is 1198800.0000, 
sim time next is 1200600.0000, 
raw observation next is [17.15, 71.0, 0.0, 0.0, 21.5, 24.45712091368829, 0.3215000842470804, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.9376731301939059, 0.71, 0.0, 0.0, 0.2916666666666667, 0.5380934094740241, 0.6071666947490267, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0187438], dtype=float32), -0.64151555]. 
=============================================
[2019-04-06 14:54:48,234] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.13026935 0.13636595 0.11292758 0.24822749 0.13181745 0.11417069
 0.12622151], sum to 1.0000
[2019-04-06 14:54:48,234] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3556
[2019-04-06 14:54:48,253] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.11553318 0.13874184 0.1313306  0.22509287 0.09939613 0.11601048
 0.17389491], sum to 1.0000
[2019-04-06 14:54:48,253] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4216
[2019-04-06 14:54:48,496] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [13.8, 100.0, 35.0, 0.0, 22.0, 24.5101222998843, 0.3812408388515709, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [22.0], 
sim time this is 1267200.0000, 
sim time next is 1269000.0000, 
raw observation next is [13.0, 100.0, 19.0, 0.0, 22.0, 24.44673967882342, 0.3643469767850158, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.8227146814404434, 1.0, 0.06333333333333334, 0.0, 0.3333333333333333, 0.5372283065686183, 0.6214489922616719, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9344347], dtype=float32), 1.3069844]. 
=============================================
[2019-04-06 14:54:48,569] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.7, 67.0, 0.0, 0.0, 24.5, 24.74134188065197, 0.3938392880428712, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1195200.0000, 
sim time next is 1197000.0000, 
raw observation next is [17.7, 67.0, 0.0, 0.0, 24.0, 24.73193052533989, 0.3868301238480749, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.9529085872576178, 0.67, 0.0, 0.0, 0.5, 0.5609942104449909, 0.628943374616025, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3792145], dtype=float32), 1.3170526]. 
=============================================
[2019-04-06 14:54:48,575] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[1.3751206]
 [1.3898015]
 [1.399697 ]
 [1.3802524]
 [1.4833398]], R is [[2.37000513]
 [3.34630513]
 [4.31284237]
 [5.26971388]
 [6.2170167 ]].
[2019-04-06 14:54:48,604] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[1.0356411]
 [1.0665989]
 [1.044159 ]
 [1.0384284]
 [1.0055853]], R is [[2.00480938]
 [2.98476124]
 [3.95491362]
 [4.91536427]
 [5.86621046]].
[2019-04-06 14:54:50,532] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.11757515 0.14346348 0.12592681 0.22472438 0.08364039 0.11537442
 0.18929534], sum to 1.0000
[2019-04-06 14:54:50,532] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3054
[2019-04-06 14:54:50,606] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [5.8, 98.0, 0.0, 0.0, 24.0, 24.99255676555888, 0.4512378577493247, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [23.5], 
sim time this is 1283400.0000, 
sim time next is 1285200.0000, 
raw observation next is [5.5, 100.0, 0.0, 0.0, 23.5, 24.83550797449449, 0.4109683124877538, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.6149584487534627, 1.0, 0.0, 0.0, 0.4583333333333333, 0.5696256645412076, 0.636989437495918, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.49161807], dtype=float32), 0.05771804]. 
=============================================
[2019-04-06 14:55:13,362] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.11177748 0.14672889 0.11903234 0.27487954 0.0786323  0.08929171
 0.17965774], sum to 1.0000
[2019-04-06 14:55:13,362] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3393
[2019-04-06 14:55:13,497] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [8.55, 70.0, 0.0, 0.0, 26.0, 25.08596893419471, 0.3687389182991246, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.5], 
sim time this is 1625400.0000, 
sim time next is 1627200.0000, 
raw observation next is [7.7, 74.0, 0.0, 0.0, 25.5, 24.85893630408061, 0.3351811883746154, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.6759002770083103, 0.74, 0.0, 0.0, 0.625, 0.571578025340051, 0.6117270627915384, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.486331], dtype=float32), -1.3455535]. 
=============================================
[2019-04-06 14:55:13,517] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15097: loss 36.0509
[2019-04-06 14:55:13,518] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15097: learning rate 0.0000
[2019-04-06 14:55:17,376] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1000, global step 15501: loss 32.3244
[2019-04-06 14:55:17,376] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 1000, global step 15501: learning rate 0.0000
[2019-04-06 14:55:19,120] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1000, global step 15686: loss 33.1676
[2019-04-06 14:55:19,120] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 1000, global step 15686: learning rate 0.0000
[2019-04-06 14:55:19,807] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15764: loss 34.7273
[2019-04-06 14:55:19,808] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15764: learning rate 0.0000
[2019-04-06 14:55:19,992] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15787: loss 42.0653
[2019-04-06 14:55:19,992] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15787: learning rate 0.0000
[2019-04-06 14:55:21,895] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15990: loss 37.8203
[2019-04-06 14:55:21,896] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15990: learning rate 0.0000
[2019-04-06 14:55:22,000] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16000: loss 41.9832
[2019-04-06 14:55:22,009] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16000: learning rate 0.0000
[2019-04-06 14:55:23,614] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16124: loss 25.4527
[2019-04-06 14:55:23,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16124: learning rate 0.0000
[2019-04-06 14:55:23,677] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1000, global step 16130: loss 39.3298
[2019-04-06 14:55:23,678] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 1000, global step 16130: learning rate 0.0000
[2019-04-06 14:55:25,944] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16282: loss 36.4564
[2019-04-06 14:55:25,944] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16282: learning rate 0.0000
[2019-04-06 14:55:25,970] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16286: loss 35.9462
[2019-04-06 14:55:25,970] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16286: learning rate 0.0000
[2019-04-06 14:55:26,086] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16296: loss 26.1557
[2019-04-06 14:55:26,092] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 16296: learning rate 0.0000
[2019-04-06 14:55:26,474] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16326: loss 29.2062
[2019-04-06 14:55:26,474] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16326: learning rate 0.0000
[2019-04-06 14:55:27,956] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16441: loss 43.6211
[2019-04-06 14:55:27,973] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16441: learning rate 0.0000
[2019-04-06 14:55:30,161] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16559: loss 29.9037
[2019-04-06 14:55:30,161] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16559: learning rate 0.0000
[2019-04-06 14:55:32,156] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16696: loss 26.1880
[2019-04-06 14:55:32,156] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16696: learning rate 0.0000
[2019-04-06 14:56:16,325] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-06 14:56:16,328] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 14:56:16,328] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:56:16,330] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run2
[2019-04-06 14:56:16,401] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 14:56:16,402] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:56:16,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run2
[2019-04-06 14:56:16,501] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 14:56:16,501] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:56:16,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run2
[2019-04-06 14:57:53,506] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2630.0485 67582203.4459 216.4524
[2019-04-06 14:58:08,447] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2591.2213 74581560.1244 70.8311
[2019-04-06 14:58:10,065] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2555.3338 77388758.4471 -9.9683
[2019-04-06 14:58:11,087] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 20000, evaluation results [20000.0, 2591.2213158026225, 74581560.12439406, 70.8311366904159, 2630.048477978537, 67582203.44594409, 216.45238599427216, 2555.3338053715397, 77388758.44705524, -9.968265513574835]
[2019-04-06 14:58:23,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.12429284 0.15783323 0.09789219 0.3051541  0.05948967 0.11649163
 0.13884635], sum to 1.0000
[2019-04-06 14:58:23,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9588
[2019-04-06 14:58:24,745] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [-1.2, 54.0, 0.0, 0.0, 23.5, 22.36633304836148, -0.2343001264192195, 1.0, 1.0, 196449.43328280034], 
current ob forecast is [], 
actual action is [25.5], 
sim time this is 2314800.0000, 
sim time next is 2316600.0000, 
raw observation next is [-1.45, 55.0, 0.0, 0.0, 25.5, 23.32731239416371, -0.002692671096083348, 0.0, 1.0, 200255.56520067295], 
processed observation next is [1.0, 0.8260869565217391, 0.422437673130194, 0.55, 0.0, 0.0, 0.625, 0.4439426995136424, 0.49910244296797224, 0.0, 1.0, 0.953597929527014], 
reward next is 0.1178, 
noisyNet noise sample is [array([0.5139191], dtype=float32), -1.3651842]. 
=============================================
[2019-04-06 14:58:41,529] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 22446: loss 39.6191
[2019-04-06 14:58:41,529] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 22446: learning rate 0.0000
[2019-04-06 14:58:42,689] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.12093508 0.14602478 0.12109499 0.24583252 0.09172765 0.15131673
 0.12306831], sum to 1.0000
[2019-04-06 14:58:42,690] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1735
[2019-04-06 14:58:42,707] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-1.45, 50.5, 245.0, 147.0, 20.0, 21.79112515560638, -0.5668935654312428, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [19.0], 
sim time this is 2637000.0000, 
sim time next is 2638800.0000, 
raw observation next is [-0.6, 47.0, 204.5, 179.0, 19.0, 21.75334825498723, -0.5681866486076319, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.44598337950138506, 0.47, 0.6816666666666666, 0.19779005524861878, 0.08333333333333333, 0.31277902124893586, 0.3106044504641227, 1.0, 1.0, 0.0], 
reward next is 0.3181, 
noisyNet noise sample is [array([0.6602779], dtype=float32), -0.7014489]. 
=============================================
[2019-04-06 14:58:46,339] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 22927: loss 45.6086
[2019-04-06 14:58:46,339] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 22927: learning rate 0.0000
[2019-04-06 14:58:51,215] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23408: loss 37.0440
[2019-04-06 14:58:51,215] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23408: learning rate 0.0000
[2019-04-06 14:58:52,460] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23539: loss 35.4121
[2019-04-06 14:58:52,461] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23539: learning rate 0.0000
[2019-04-06 14:58:52,908] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1500, global step 23583: loss 37.7340
[2019-04-06 14:58:52,909] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 1500, global step 23583: learning rate 0.0000
[2019-04-06 14:58:53,336] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1500, global step 23617: loss 37.7429
[2019-04-06 14:58:53,336] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 1500, global step 23617: learning rate 0.0000
[2019-04-06 14:58:57,561] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23954: loss 39.7686
[2019-04-06 14:58:57,582] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23955: learning rate 0.0000
[2019-04-06 14:58:58,888] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 24045: loss 39.1565
[2019-04-06 14:58:58,889] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 24045: learning rate 0.0000
[2019-04-06 14:58:59,654] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24111: loss 38.5049
[2019-04-06 14:58:59,661] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24111: learning rate 0.0000
[2019-04-06 14:59:00,496] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24182: loss 36.1309
[2019-04-06 14:59:00,498] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24182: learning rate 0.0000
[2019-04-06 14:59:01,031] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24228: loss 42.8540
[2019-04-06 14:59:01,033] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24228: learning rate 0.0000
[2019-04-06 14:59:01,548] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 24276: loss 35.7908
[2019-04-06 14:59:01,549] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 24276: learning rate 0.0000
[2019-04-06 14:59:02,638] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 24388: loss 40.0099
[2019-04-06 14:59:02,638] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 24388: learning rate 0.0000
[2019-04-06 14:59:03,695] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24487: loss 33.4142
[2019-04-06 14:59:03,695] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24487: learning rate 0.0000
[2019-04-06 14:59:06,192] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1500, global step 24716: loss 32.6656
[2019-04-06 14:59:06,192] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 1500, global step 24716: learning rate 0.0000
[2019-04-06 14:59:06,641] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 24748: loss 28.7460
[2019-04-06 14:59:06,641] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 24748: learning rate 0.0000
[2019-04-06 14:59:19,849] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.11643066 0.15326858 0.14735213 0.20877135 0.08081803 0.14951944
 0.14383975], sum to 1.0000
[2019-04-06 14:59:19,850] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8413
[2019-04-06 14:59:19,877] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 62.5, 110.0, 800.0, 21.0, 22.36834235897983, -0.2144847805294456, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [22.0], 
sim time this is 2986200.0000, 
sim time next is 2988000.0000, 
raw observation next is [-2.0, 60.0, 105.5, 775.5, 22.0, 22.31965687482025, -0.2245703866079975, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.40720221606648205, 0.6, 0.3516666666666667, 0.8569060773480663, 0.3333333333333333, 0.35997140623502083, 0.42514320446400083, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.85482377], dtype=float32), -0.3760143]. 
=============================================
[2019-04-06 14:59:19,915] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[2.7695138]
 [2.6757145]
 [2.7342486]
 [2.680662 ]
 [2.776426 ]], R is [[3.72546005]
 [4.68820572]
 [5.64132357]
 [6.58491039]
 [7.51906157]].
[2019-04-06 14:59:22,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.11207899 0.16861998 0.12414107 0.26633054 0.06047952 0.10180847
 0.16654143], sum to 1.0000
[2019-04-06 14:59:22,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0462
[2019-04-06 14:59:22,708] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.10396676 0.17224793 0.18597111 0.17181763 0.08578864 0.10668565
 0.17352222], sum to 1.0000
[2019-04-06 14:59:22,709] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7756
[2019-04-06 14:59:23,094] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 85.0, 0.0, 0.0, 19.0, 19.30654912472479, -0.905344363918943, 0.0, 1.0, 6226.803890076847], 
current ob forecast is [], 
actual action is [19.0], 
sim time this is 2926800.0000, 
sim time next is 2928600.0000, 
raw observation next is [-1.0, 81.5, 0.0, 0.0, 19.0, 19.10708147493592, -0.9445138094342772, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.815, 0.0, 0.0, 0.08333333333333333, 0.0922567895779934, 0.1851620635219076, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.04793127], dtype=float32), -0.44555086]. 
=============================================
[2019-04-06 14:59:23,253] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 55.0, 69.5, 570.5, 22.5, 21.72182204100104, -0.4124283282991899, 0.0, 1.0, 12464.073853152244], 
current ob forecast is [], 
actual action is [23.5], 
sim time this is 2995200.0000, 
sim time next is 2997000.0000, 
raw observation next is [-1.0, 55.0, 56.0, 474.0, 23.5, 22.03361660620326, -0.2453460031021698, 0.0, 1.0, 199075.16348030302], 
processed observation next is [0.0, 0.6956521739130435, 0.4349030470914128, 0.55, 0.18666666666666668, 0.523756906077348, 0.4583333333333333, 0.33613471718360505, 0.4182179989659434, 0.0, 1.0, 0.9479769689538239], 
reward next is 0.4092, 
noisyNet noise sample is [array([0.99195325], dtype=float32), 1.2767578]. 
=============================================
[2019-04-06 14:59:23,274] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[2.902692 ]
 [2.802545 ]
 [2.6369414]
 [2.5197866]
 [2.4387002]], R is [[3.17156625]
 [4.13985062]
 [5.09845209]
 [6.04746771]
 [6.98699331]].
[2019-04-06 14:59:56,596] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.10704498 0.12308592 0.1260006  0.3258377  0.06673802 0.13338105
 0.11791178], sum to 1.0000
[2019-04-06 14:59:56,596] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2999
[2019-04-06 14:59:57,125] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-10.0, 76.0, 0.0, 0.0, 25.0, 21.43157733110661, -0.5233413032532914, 0.0, 1.0, 47732.3477429703], 
current ob forecast is [], 
actual action is [24.5], 
sim time this is 3301200.0000, 
sim time next is 3303000.0000, 
raw observation next is [-10.5, 76.0, 0.0, 0.0, 24.5, 21.40943281492836, -0.5402729742898024, 0.0, 1.0, 47216.33377893808], 
processed observation next is [1.0, 0.21739130434782608, 0.17174515235457063, 0.76, 0.0, 0.0, 0.5416666666666666, 0.28411940124402985, 0.3199090085700659, 0.0, 1.0, 0.22483968466160992], 
reward next is 0.9894, 
noisyNet noise sample is [array([-0.31413403], dtype=float32), -0.49531144]. 
=============================================
[2019-04-06 14:59:57,312] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[4.432589 ]
 [4.3362894]
 [4.321286 ]
 [4.3557253]
 [4.150367 ]], R is [[5.41543818]
 [6.27684402]
 [7.12695456]
 [7.8223362 ]
 [8.57799149]].
[2019-04-06 14:59:58,743] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.12806058 0.18566611 0.1422672  0.1918478  0.05831869 0.16970187
 0.12413768], sum to 1.0000
[2019-04-06 14:59:58,743] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7687
[2019-04-06 14:59:58,813] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 54.0, 116.0, 805.5, 21.5, 22.27467058174258, -0.2869074300578297, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [22.5], 
sim time this is 3330000.0000, 
sim time next is 3331800.0000, 
raw observation next is [-4.5, 52.0, 114.0, 800.0, 22.5, 22.27212438148024, -0.2947216576597802, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3379501385041552, 0.52, 0.38, 0.8839779005524862, 0.375, 0.35601036512335327, 0.4017594474467399, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9687729], dtype=float32), 0.063295126]. 
=============================================
[2019-04-06 15:00:02,858] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 30234: loss 42.8648
[2019-04-06 15:00:02,859] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 30234: learning rate 0.0000
[2019-04-06 15:00:12,601] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31324: loss 37.3143
[2019-04-06 15:00:12,602] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31324: learning rate 0.0000
[2019-04-06 15:00:13,823] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31465: loss 35.1527
[2019-04-06 15:00:13,824] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31465: learning rate 0.0000
[2019-04-06 15:00:14,507] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2000, global step 31556: loss 37.8143
[2019-04-06 15:00:14,527] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 2000, global step 31556: learning rate 0.0000
[2019-04-06 15:00:17,794] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31967: loss 40.3494
[2019-04-06 15:00:17,795] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31967: learning rate 0.0000
[2019-04-06 15:00:17,880] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2000, global step 31975: loss 38.8675
[2019-04-06 15:00:17,890] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 2000, global step 31975: learning rate 0.0000
[2019-04-06 15:00:18,118] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31999: loss 40.0638
[2019-04-06 15:00:18,128] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31999: learning rate 0.0000
[2019-04-06 15:00:18,276] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32021: loss 37.9582
[2019-04-06 15:00:18,277] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32021: learning rate 0.0000
[2019-04-06 15:00:19,521] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32159: loss 33.9867
[2019-04-06 15:00:19,521] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32159: learning rate 0.0000
[2019-04-06 15:00:20,765] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32297: loss 30.6130
[2019-04-06 15:00:20,765] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 32297: learning rate 0.0000
[2019-04-06 15:00:20,991] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32316: loss 29.1918
[2019-04-06 15:00:20,991] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32316: learning rate 0.0000
[2019-04-06 15:00:21,169] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0998798  0.14503743 0.12900789 0.23786607 0.08563519 0.16188705
 0.14068653], sum to 1.0000
[2019-04-06 15:00:21,170] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2386
[2019-04-06 15:00:21,301] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2000, global step 32362: loss 42.7398
[2019-04-06 15:00:21,302] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 2000, global step 32362: learning rate 0.0000
[2019-04-06 15:00:21,468] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [0.0, 41.0, 63.0, 515.0, 24.5, 25.72495549998283, 0.4608373248003452, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [23.5], 
sim time this is 3601800.0000, 
sim time next is 3603600.0000, 
raw observation next is [0.0, 39.0, 38.5, 328.5, 23.5, 25.55863052464217, 0.4040950237826288, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.46260387811634357, 0.39, 0.12833333333333333, 0.3629834254143646, 0.4583333333333333, 0.6298858770535141, 0.6346983412608763, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.58064616], dtype=float32), 2.0687184]. 
=============================================
[2019-04-06 15:00:23,288] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32611: loss 38.4774
[2019-04-06 15:00:23,303] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 32613: learning rate 0.0000
[2019-04-06 15:00:23,817] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32696: loss 36.8471
[2019-04-06 15:00:23,819] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32696: learning rate 0.0000
[2019-04-06 15:00:24,422] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32776: loss 41.8387
[2019-04-06 15:00:24,423] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 32776: learning rate 0.0000
[2019-04-06 15:00:28,823] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 33272: loss 37.0566
[2019-04-06 15:00:28,823] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 33272: learning rate 0.0000
[2019-04-06 15:00:32,377] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.09112947 0.19345933 0.13872324 0.23997916 0.06252526 0.13914622
 0.13503735], sum to 1.0000
[2019-04-06 15:00:32,413] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7399
[2019-04-06 15:00:32,589] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 45.0, 116.5, 822.5, 23.5, 23.31696569212793, -0.07856393178718664, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.5], 
sim time this is 3672000.0000, 
sim time next is 3673800.0000, 
raw observation next is [4.5, 43.5, 117.0, 829.0, 24.5, 23.46225371613085, 0.01017331183006487, 0.0, 1.0, 69902.89778062764], 
processed observation next is [0.0, 0.5217391304347826, 0.5872576177285319, 0.435, 0.39, 0.9160220994475138, 0.5416666666666666, 0.4551878096775708, 0.503391103943355, 0.0, 1.0, 0.3328709418125126], 
reward next is 0.8814, 
noisyNet noise sample is [array([0.5059789], dtype=float32), 1.59795]. 
=============================================
[2019-04-06 15:00:38,653] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.11568013 0.22686456 0.10123967 0.29745457 0.03082092 0.09944923
 0.12849095], sum to 1.0000
[2019-04-06 15:00:38,653] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0573
[2019-04-06 15:00:39,076] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 55.5, 0.0, 0.0, 21.0, 22.02261874946666, -0.3160166608225554, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [19.0], 
sim time this is 3875400.0000, 
sim time next is 3877200.0000, 
raw observation next is [-1.0, 60.0, 0.0, 0.0, 19.0, 21.75442716613633, -0.3689013005566308, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.6, 0.0, 0.0, 0.08333333333333333, 0.31286893051136094, 0.37703289981445637, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6515063], dtype=float32), -1.1312584]. 
=============================================
[2019-04-06 15:00:47,353] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.10000336 0.14769077 0.12012137 0.22713652 0.07515591 0.19443075
 0.13546132], sum to 1.0000
[2019-04-06 15:00:47,354] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6209
[2019-04-06 15:00:47,971] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 54.0, 0.0, 0.0, 19.0, 23.10269141708899, -0.1248917665156046, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [19.5], 
sim time this is 4165200.0000, 
sim time next is 4167000.0000, 
raw observation next is [-4.0, 52.0, 0.0, 0.0, 19.5, 22.75947506517376, -0.1964697566342758, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.3518005540166205, 0.52, 0.0, 0.0, 0.125, 0.3966229220978133, 0.4345100811219081, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6405764], dtype=float32), 0.4991535]. 
=============================================
[2019-04-06 15:00:48,158] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[4.5675163]
 [4.7151065]
 [4.804302 ]
 [4.855081 ]
 [4.8889546]], R is [[5.4013958 ]
 [6.34738207]
 [7.28390837]
 [8.21106911]
 [9.1289587 ]].
[2019-04-06 15:00:58,326] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.10779794 0.14377792 0.13532406 0.26927453 0.07976303 0.13406272
 0.12999973], sum to 1.0000
[2019-04-06 15:00:58,326] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0881
[2019-04-06 15:00:58,446] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 50.0, 0.0, 0.0, 21.0, 19.53809801318253, -0.8870079244022221, 0.0, 1.0, 196217.9094192961], 
current ob forecast is [], 
actual action is [19.0], 
sim time this is 4168800.0000, 
sim time next is 4170600.0000, 
raw observation next is [-4.5, 49.5, 0.0, 0.0, 19.0, 19.65216207558761, -0.8838384051799649, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.3379501385041552, 0.495, 0.0, 0.0, 0.08333333333333333, 0.13768017296563428, 0.20538719827334503, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.323767], dtype=float32), -0.67540085]. 
=============================================
[2019-04-06 15:01:06,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.08003255 0.17880028 0.09093557 0.40959907 0.04595896 0.11128248
 0.08339106], sum to 1.0000
[2019-04-06 15:01:06,727] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5169
[2019-04-06 15:01:06,747] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [3.0, 30.0, 116.0, 830.0, 25.5, 25.90020389052979, 0.5150180679511318, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.5], 
sim time this is 4109400.0000, 
sim time next is 4111200.0000, 
raw observation next is [3.0, 31.0, 111.0, 812.0, 25.5, 26.33249991136988, 0.5762055158255525, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5457063711911359, 0.31, 0.37, 0.8972375690607735, 0.625, 0.6943749926141566, 0.6920685052751842, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.1344423], dtype=float32), -1.0885768]. 
=============================================
[2019-04-06 15:01:07,266] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 37532: loss 32.7653
[2019-04-06 15:01:07,267] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 37532: learning rate 0.0000
[2019-04-06 15:01:17,903] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 38952: loss 15.6770
[2019-04-06 15:01:17,998] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 38952: learning rate 0.0000
[2019-04-06 15:01:18,243] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2500, global step 38999: loss 25.5301
[2019-04-06 15:01:18,285] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 2500, global step 38999: learning rate 0.0000
[2019-04-06 15:01:19,761] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39340: loss 25.6760
[2019-04-06 15:01:19,762] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39341: learning rate 0.0000
[2019-04-06 15:01:21,554] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39726: loss 34.7024
[2019-04-06 15:01:21,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39726: learning rate 0.0000
[2019-04-06 15:01:21,761] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39774: loss 19.5823
[2019-04-06 15:01:21,762] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39774: learning rate 0.0000
[2019-04-06 15:01:22,506] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39932: loss 39.4033
[2019-04-06 15:01:22,507] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39933: learning rate 0.0000
[2019-04-06 15:01:22,796] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 15:01:22,805] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:01:22,809] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:01:22,811] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run3
[2019-04-06 15:01:22,822] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:01:22,823] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:01:22,824] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:01:22,824] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:01:22,828] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run3
[2019-04-06 15:01:22,847] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run3
[2019-04-06 15:02:56,356] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2617.2055 68311645.2314 289.2572
[2019-04-06 15:03:14,725] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2564.4470 76215894.5712 137.5819
[2019-04-06 15:03:15,844] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2568.6572 79925692.4895 81.7763
[2019-04-06 15:03:16,866] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 40000, evaluation results [40000.0, 2564.4470318021854, 76215894.57118386, 137.5819198153013, 2617.205456061153, 68311645.23143612, 289.25722968891995, 2568.657185811296, 79925692.48953076, 81.77630675085302]
[2019-04-06 15:03:16,896] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40019: loss 27.8306
[2019-04-06 15:03:16,897] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40019: learning rate 0.0000
[2019-04-06 15:03:16,975] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2500, global step 40041: loss 23.4208
[2019-04-06 15:03:16,975] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 2500, global step 40041: learning rate 0.0000
[2019-04-06 15:03:17,017] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40052: loss 27.6415
[2019-04-06 15:03:17,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40052: learning rate 0.0000
[2019-04-06 15:03:17,174] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2500, global step 40090: loss 32.3164
[2019-04-06 15:03:17,175] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 2500, global step 40090: learning rate 0.0000
[2019-04-06 15:03:20,297] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40797: loss 31.0536
[2019-04-06 15:03:20,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40797: learning rate 0.0000
[2019-04-06 15:03:20,602] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40878: loss 38.3344
[2019-04-06 15:03:20,603] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 40878: learning rate 0.0000
[2019-04-06 15:03:20,823] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40938: loss 30.6055
[2019-04-06 15:03:20,824] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 40938: learning rate 0.0000
[2019-04-06 15:03:20,843] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40941: loss 32.1956
[2019-04-06 15:03:20,845] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40942: learning rate 0.0000
[2019-04-06 15:03:22,631] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.07748611 0.20536485 0.0700831  0.38917348 0.03520596 0.13336322
 0.08932321], sum to 1.0000
[2019-04-06 15:03:22,631] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8010
[2019-04-06 15:03:22,763] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 20.0, 24.55605872353649, 0.2878259245441169, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [21.0], 
sim time this is 4651200.0000, 
sim time next is 4653000.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 21.0, 24.41111983349038, 0.254419953083276, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.518005540166205, 0.52, 0.0, 0.0, 0.25, 0.5342599861241982, 0.5848066510277586, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7199864], dtype=float32), 0.10534576]. 
=============================================
[2019-04-06 15:03:22,799] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[8.9650545]
 [9.069093 ]
 [9.272187 ]
 [9.294858 ]
 [9.479596 ]], R is [[ 9.69624996]
 [10.59928799]
 [11.49329567]
 [12.37836266]
 [13.25457954]].
[2019-04-06 15:03:23,318] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 41498: loss 12.4806
[2019-04-06 15:03:23,321] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 41500: learning rate 0.0000
[2019-04-06 15:03:31,633] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.07875459 0.13476864 0.12247322 0.3361142  0.03922985 0.15174267
 0.13691685], sum to 1.0000
[2019-04-06 15:03:31,718] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7656
[2019-04-06 15:03:31,763] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 40.0, 0.0, 0.0, 19.0, 22.16462219245088, -0.4055371956728805, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [20.0], 
sim time this is 4924800.0000, 
sim time next is 4926600.0000, 
raw observation next is [0.5, 41.5, 0.0, 0.0, 20.0, 21.93507162282562, -0.4438613336670699, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.0, 0.4764542936288089, 0.415, 0.0, 0.0, 0.16666666666666666, 0.32792263523546844, 0.35204622211097664, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5348545], dtype=float32), 2.321618]. 
=============================================
[2019-04-06 15:03:33,742] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:33,743] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:33,744] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run2
[2019-04-06 15:03:39,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:39,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:39,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run2
[2019-04-06 15:03:43,899] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:43,899] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:43,914] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run2
[2019-04-06 15:03:48,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:48,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:48,291] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run2
[2019-04-06 15:03:50,489] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:50,489] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:50,491] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run2
[2019-04-06 15:03:50,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:50,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:50,703] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run2
[2019-04-06 15:03:50,843] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:50,843] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:50,847] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run2
[2019-04-06 15:03:52,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:52,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:52,655] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run2
[2019-04-06 15:03:52,720] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:52,720] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:52,722] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run2
[2019-04-06 15:03:54,154] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:54,154] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:54,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run2
[2019-04-06 15:03:55,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:55,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:55,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run2
[2019-04-06 15:03:57,010] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:57,011] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:57,012] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run2
[2019-04-06 15:03:58,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:03:58,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:03:58,367] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run2
[2019-04-06 15:04:00,658] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:00,658] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:00,660] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run2
[2019-04-06 15:04:01,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:01,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:01,347] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run2
[2019-04-06 15:04:03,276] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:03,276] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:03,278] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run2
[2019-04-06 15:04:13,420] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.04959634 0.10674094 0.04401869 0.5060585  0.02759058 0.20537998
 0.06061496], sum to 1.0000
[2019-04-06 15:04:13,420] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5251
[2019-04-06 15:04:13,842] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-7.55, 62.5, 0.0, 0.0, 24.0, 25.1896583110301, 0.2475131122364697, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 153000.0000, 
sim time next is 154800.0000, 
raw observation next is [-7.8, 64.0, 0.0, 0.0, 24.0, 24.55684055521934, 0.1217682182755129, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.24653739612188366, 0.64, 0.0, 0.0, 0.5, 0.5464033796016116, 0.5405894060918376, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.15037413], dtype=float32), -2.0013897]. 
=============================================
[2019-04-06 15:04:47,318] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.05262933 0.07945844 0.10102622 0.5179738  0.03656186 0.1362218
 0.07612851], sum to 1.0000
[2019-04-06 15:04:47,318] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1765
[2019-04-06 15:04:47,403] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-11.15, 51.5, 0.0, 0.0, 23.0, 21.77104976691253, -0.4664845274146883, 0.0, 1.0, 49974.61042112293], 
current ob forecast is [], 
actual action is [22.5], 
sim time this is 426600.0000, 
sim time next is 428400.0000, 
raw observation next is [-11.7, 54.0, 0.0, 0.0, 22.5, 21.72474916629089, -0.4858241851831626, 0.0, 1.0, 49129.146844338014], 
processed observation next is [1.0, 1.0, 0.13850415512465375, 0.54, 0.0, 0.0, 0.375, 0.3103957638575743, 0.3380586049389458, 0.0, 1.0, 0.2339483183063715], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.93779415], dtype=float32), -1.1145535]. 
=============================================
[2019-04-06 15:05:26,784] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.06172658 0.19154015 0.08837605 0.34967262 0.05142886 0.14663975
 0.11061604], sum to 1.0000
[2019-04-06 15:05:26,784] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4761
[2019-04-06 15:05:26,837] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-3.4, 87.0, 0.0, 0.0, 22.5, 22.59622654170557, -0.2793640088586619, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [22.5], 
sim time this is 604800.0000, 
sim time next is 606600.0000, 
raw observation next is [-3.65, 86.5, 0.0, 0.0, 22.5, 22.25976821047251, -0.3446669301896845, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.0, 0.3614958448753463, 0.865, 0.0, 0.0, 0.375, 0.3549806842060426, 0.38511102327010516, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.353267], dtype=float32), -0.028477088]. 
=============================================
[2019-04-06 15:05:43,831] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.05009123 0.12667117 0.04995466 0.33843064 0.02572436 0.33149347
 0.07763446], sum to 1.0000
[2019-04-06 15:05:43,832] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7484
[2019-04-06 15:05:43,938] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.5, 89.0, 0.0, 0.0, 22.5, 22.70006601470539, -0.1567627208193122, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [23.5], 
sim time this is 954000.0000, 
sim time next is 955800.0000, 
raw observation next is [6.05, 85.5, 0.0, 0.0, 23.5, 22.85198359650693, -0.08006423975491955, 0.0, 1.0, 144835.67515807276], 
processed observation next is [1.0, 0.043478260869565216, 0.6301939058171746, 0.855, 0.0, 0.0, 0.4583333333333333, 0.4043319663755775, 0.4733119200816935, 0.0, 1.0, 0.6896936912289179], 
reward next is 0.6674, 
noisyNet noise sample is [array([-1.7102382], dtype=float32), 0.98499936]. 
=============================================
[2019-04-06 15:05:52,527] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.05169739 0.08874206 0.04482841 0.36706048 0.02796253 0.35558677
 0.06412236], sum to 1.0000
[2019-04-06 15:05:52,527] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5852
[2019-04-06 15:05:52,848] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 68.0, 120.0, 58.5, 24.0, 25.29361566533284, 0.174766908760061, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.0], 
sim time this is 727200.0000, 
sim time next is 729000.0000, 
raw observation next is [-1.15, 67.0, 139.0, 68.0, 25.0, 25.23053607026445, 0.1724985914761098, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4307479224376732, 0.67, 0.4633333333333333, 0.07513812154696133, 0.5833333333333334, 0.6025446725220375, 0.5574995304920366, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7732385], dtype=float32), -1.8845118]. 
=============================================
[2019-04-06 15:05:52,866] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[15.300521]
 [15.214635]
 [14.724779]
 [14.372075]
 [14.236941]], R is [[16.4017868 ]
 [17.23776817]
 [18.06539154]
 [18.88473701]
 [19.69589043]].
[2019-04-06 15:06:27,674] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.04986082 0.18783286 0.07710588 0.4692529  0.01315615 0.11496174
 0.08782963], sum to 1.0000
[2019-04-06 15:06:27,674] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8116
[2019-04-06 15:06:28,250] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 90.0, 0.0, 0.0, 21.5, 23.2996432088206, -0.004968915996778668, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [22.5], 
sim time this is 1449000.0000, 
sim time next is 1450800.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 22.5, 23.12062823049661, -0.03843379104841348, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.92, 0.0, 0.0, 0.375, 0.42671901920805083, 0.48718873631719556, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.22561085], dtype=float32), -0.6546292]. 
=============================================
[2019-04-06 15:06:33,167] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.04894094 0.1861066  0.09208427 0.39675352 0.03939797 0.14418247
 0.09253421], sum to 1.0000
[2019-04-06 15:06:33,167] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0248
[2019-04-06 15:06:33,412] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 21.5, 23.96099624111265, 0.2251034687932094, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [19.5], 
sim time this is 1233000.0000, 
sim time next is 1234800.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 19.5, 23.90524848819946, 0.2144580643712551, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.8781163434903049, 0.96, 0.0, 0.0, 0.125, 0.49210404068328845, 0.571486021457085, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3899049], dtype=float32), 0.35075566]. 
=============================================
[2019-04-06 15:06:50,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.01237798 0.08139691 0.01717256 0.43972692 0.00637829 0.4220926
 0.0208548 ], sum to 1.0000
[2019-04-06 15:06:50,697] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0900
[2019-04-06 15:06:50,723] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 24.5, 24.29306111300767, 0.2283269932102495, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [23.5], 
sim time this is 1468800.0000, 
sim time next is 1470600.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 23.5, 24.0424542875406, 0.2028677184562866, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.0, 0.5069252077562327, 0.92, 0.0, 0.0, 0.4583333333333333, 0.5035378572950501, 0.5676225728187622, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2466218], dtype=float32), -0.2973101]. 
=============================================
[2019-04-06 15:06:55,187] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 15:06:55,188] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:06:55,188] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:06:55,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run4
[2019-04-06 15:06:55,222] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:06:55,223] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:06:55,224] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run4
[2019-04-06 15:06:55,287] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:06:55,288] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:06:55,290] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run4
[2019-04-06 15:07:35,311] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.03529704], dtype=float32), 0.054245718]
[2019-04-06 15:07:35,311] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [1.05, 75.0, 0.0, 0.0, 26.0, 25.10114807239613, 0.4334600997165023, 0.0, 1.0, 39831.20510843013]
[2019-04-06 15:07:35,311] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:07:35,312] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [0.02716067 0.14004724 0.06582794 0.3794911  0.01581224 0.29818213
 0.07347871], sampled 0.5409485523539822
[2019-04-06 15:08:40,106] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2567.0201 71501812.8412 378.2476
[2019-04-06 15:09:00,303] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2510.7670 82745900.3714 375.7814
[2019-04-06 15:09:00,915] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2497.5506 84901669.0843 178.3061
[2019-04-06 15:09:01,936] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 60000, evaluation results [60000.0, 2510.7669567285743, 82745900.37140131, 375.7814267385308, 2567.0201400971923, 71501812.84119602, 378.2475790047835, 2497.550588571172, 84901669.08434601, 178.30608639519855]
[2019-04-06 15:09:35,184] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.02956622 0.11725964 0.03351184 0.3577086  0.00561833 0.41948906
 0.03684634], sum to 1.0000
[2019-04-06 15:09:35,184] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3992
[2019-04-06 15:09:35,242] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 22.0, 23.47824136763521, 0.02205275615775125, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [22.0], 
sim time this is 2138400.0000, 
sim time next is 2140200.0000, 
raw observation next is [-5.0, 72.5, 0.0, 0.0, 22.0, 23.51295639293935, -0.02324787274511845, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.32409972299168976, 0.725, 0.0, 0.0, 0.3333333333333333, 0.45941303274494594, 0.49225070908496055, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1908058], dtype=float32), -0.61135805]. 
=============================================
[2019-04-06 15:10:00,785] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.00685982 0.09271635 0.04219958 0.2948085  0.00221989 0.51359725
 0.04759861], sum to 1.0000
[2019-04-06 15:10:00,785] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4893
[2019-04-06 15:10:00,849] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 91.0, 0.0, 0.0, 25.0, 23.20874220456055, -0.1312435417929514, 0.0, 1.0, 67139.83384042354], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2264400.0000, 
sim time next is 2266200.0000, 
raw observation next is [-8.9, 91.0, 0.0, 0.0, 26.0, 23.1265743146266, -0.1489644219482999, 0.0, 1.0, 44864.078435178264], 
processed observation next is [1.0, 0.21739130434782608, 0.21606648199445982, 0.91, 0.0, 0.0, 0.6666666666666666, 0.4272145262188832, 0.4503451926839, 0.0, 1.0, 0.21363846873894413], 
reward next is 0.7864, 
noisyNet noise sample is [array([0.01431596], dtype=float32), 0.50765747]. 
=============================================
[2019-04-06 15:10:56,123] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.00644839 0.04196308 0.00619637 0.35865557 0.00104411 0.55760044
 0.02809205], sum to 1.0000
[2019-04-06 15:10:56,123] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6245
[2019-04-06 15:10:56,225] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.7, 86.0, 109.0, 752.0, 26.0, 26.26765607251252, 0.6059939088373323, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3234600.0000, 
sim time next is 3236400.0000, 
raw observation next is [-2.4, 80.0, 111.0, 781.5, 26.0, 26.26325004276998, 0.6250136157108719, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.39612188365650974, 0.8, 0.37, 0.86353591160221, 0.6666666666666666, 0.6886041702308315, 0.7083378719036239, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.95745075], dtype=float32), 1.6374104]. 
=============================================
[2019-04-06 15:11:07,700] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6310391e-03 5.6371693e-02 9.8008839e-03 7.0999271e-01 4.5308608e-04
 2.0758432e-01 1.2166268e-02], sum to 1.0000
[2019-04-06 15:11:07,700] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3822
[2019-04-06 15:11:07,782] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [7.5, 96.5, 113.0, 823.0, 26.0, 26.29026785602798, 0.6085443310875441, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3155400.0000, 
sim time next is 3157200.0000, 
raw observation next is [7.0, 100.0, 112.5, 814.5, 26.0, 26.25033909110272, 0.6201206305937769, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.6565096952908588, 1.0, 0.375, 0.9, 0.6666666666666666, 0.6875282575918934, 0.7067068768645922, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8507986], dtype=float32), -1.6490264]. 
=============================================
[2019-04-06 15:12:11,686] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.00651159 0.21523759 0.04316156 0.35208154 0.004253   0.3523735
 0.0263812 ], sum to 1.0000
[2019-04-06 15:12:11,686] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9232
[2019-04-06 15:12:11,762] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.0, 25.0, 0.0, 0.0, 26.0, 25.46367862302479, 0.3551989430882289, 0.0, 1.0, 52666.53256730039], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3636000.0000, 
sim time next is 3637800.0000, 
raw observation next is [8.6, 26.0, 0.0, 0.0, 26.0, 25.48907709382931, 0.3536484598277183, 0.0, 1.0, 27313.860692241204], 
processed observation next is [0.0, 0.08695652173913043, 0.700831024930748, 0.26, 0.0, 0.0, 0.6666666666666666, 0.624089757819109, 0.6178828199425728, 0.0, 1.0, 0.13006600329638668], 
reward next is 0.8699, 
noisyNet noise sample is [array([1.0100712], dtype=float32), -0.10706578]. 
=============================================
[2019-04-06 15:12:33,567] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 15:12:33,585] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:12:33,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:12:33,587] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run5
[2019-04-06 15:12:33,661] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:12:33,661] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:12:33,663] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run5
[2019-04-06 15:12:33,738] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:12:33,739] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:12:33,740] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run5
[2019-04-06 15:13:39,754] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.04176078], dtype=float32), 0.071934]
[2019-04-06 15:13:39,754] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [2.65, 63.0, 177.0, 230.0, 25.0, 25.66160988716367, 0.5176468634544086, 1.0, 1.0, 0.0]
[2019-04-06 15:13:39,754] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:13:39,755] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [0.00332487 0.09891497 0.00749177 0.3905573  0.00137672 0.48773915
 0.01059521], sampled 0.9984854239241933
[2019-04-06 15:14:28,306] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2484.5794 78327690.9482 514.5105
[2019-04-06 15:14:48,106] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2443.9010 86939680.7886 489.8321
[2019-04-06 15:14:49,490] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2432.3852 90374150.5282 381.6110
[2019-04-06 15:14:50,511] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 80000, evaluation results [80000.0, 2443.901008427482, 86939680.78859007, 489.83205346141034, 2484.5793586097593, 78327690.94823903, 514.5105375898886, 2432.3852349942877, 90374150.52820277, 381.6109594663095]
[2019-04-06 15:14:52,528] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.2172679e-04 9.9126630e-02 1.1386988e-02 6.5862936e-01 2.8614150e-03
 2.1108036e-01 1.6293399e-02], sum to 1.0000
[2019-04-06 15:14:52,532] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5727
[2019-04-06 15:14:52,678] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-1.0, 55.0, 0.0, 0.0, 25.0, 25.67645415031132, 0.5311800247732396, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.0], 
sim time this is 3880800.0000, 
sim time next is 3882600.0000, 
raw observation next is [-1.0, 57.5, 0.0, 0.0, 25.0, 25.31275893345019, 0.3979803706328508, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4349030470914128, 0.575, 0.0, 0.0, 0.5833333333333334, 0.6093965777875159, 0.6326601235442836, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.101975], dtype=float32), -1.5854639]. 
=============================================
[2019-04-06 15:14:57,052] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.00280136 0.10953017 0.0070332  0.5549057  0.00161606 0.31830654
 0.00580698], sum to 1.0000
[2019-04-06 15:14:57,052] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7950
[2019-04-06 15:14:57,180] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 74.0, 46.0, 245.5, 26.0, 25.46451369324272, 0.3896003318637134, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4348800.0000, 
sim time next is 4350600.0000, 
raw observation next is [4.65, 65.5, 92.0, 491.0, 26.0, 25.81583681145493, 0.5011249053904588, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.5914127423822716, 0.655, 0.30666666666666664, 0.5425414364640884, 0.6666666666666666, 0.6513197342879108, 0.667041635130153, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.33651993], dtype=float32), -0.018569622]. 
=============================================
[2019-04-06 15:15:17,975] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:15:17,975] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:15:17,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run3
[2019-04-06 15:15:18,514] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4834118e-03 5.6866672e-02 4.3893252e-03 3.3585879e-01 9.0467220e-05
 5.8396721e-01 1.7344078e-02], sum to 1.0000
[2019-04-06 15:15:18,515] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5642
[2019-04-06 15:15:18,635] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.3, 57.0, 99.5, 584.0, 26.0, 25.8697835063225, 0.4454711812642909, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4352400.0000, 
sim time next is 4354200.0000, 
raw observation next is [8.15, 49.5, 107.0, 677.0, 26.0, 26.17662362481066, 0.5365847135966294, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6883656509695293, 0.495, 0.3566666666666667, 0.7480662983425415, 0.6666666666666666, 0.681385302067555, 0.6788615711988765, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.30209467], dtype=float32), -0.9593442]. 
=============================================
[2019-04-06 15:15:25,401] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5039731e-04 4.1202266e-02 1.4987855e-03 8.4537756e-01 2.8301438e-04
 1.1023838e-01 1.1496327e-03], sum to 1.0000
[2019-04-06 15:15:25,413] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2298
[2019-04-06 15:15:25,515] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [8.0, 26.0, 53.0, 472.5, 23.0, 27.57271944317758, 0.9111706473789362, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [23.0], 
sim time this is 4986000.0000, 
sim time next is 4987800.0000, 
raw observation next is [7.0, 25.5, 34.0, 304.0, 23.0, 27.10000555348187, 0.7858625111903613, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.6565096952908588, 0.255, 0.11333333333333333, 0.33591160220994476, 0.4166666666666667, 0.7583337961234893, 0.7619541703967871, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0299956], dtype=float32), 0.7656846]. 
=============================================
[2019-04-06 15:15:31,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:15:31,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:15:31,539] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run3
[2019-04-06 15:15:32,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:15:32,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:15:32,683] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run3
[2019-04-06 15:15:33,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:15:33,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:15:33,431] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run3
[2019-04-06 15:15:50,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:15:50,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:15:50,767] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run3
[2019-04-06 15:15:52,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:15:52,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:15:52,079] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run3
[2019-04-06 15:15:57,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:15:57,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:15:57,171] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run3
[2019-04-06 15:16:00,883] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:16:00,883] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:16:00,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run3
[2019-04-06 15:16:02,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:16:02,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:16:02,279] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run3
[2019-04-06 15:16:02,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:16:02,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:16:02,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run3
[2019-04-06 15:16:05,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:16:05,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:16:05,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run3
[2019-04-06 15:16:06,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:16:06,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:16:06,260] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run3
[2019-04-06 15:16:06,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:16:06,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:16:06,479] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run3
[2019-04-06 15:16:07,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:16:07,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:16:07,047] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run3
[2019-04-06 15:16:12,058] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:16:12,059] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:16:12,060] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run3
[2019-04-06 15:16:12,233] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:16:12,234] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:16:12,235] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run3
[2019-04-06 15:16:28,866] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3405816e-04 3.9044861e-02 9.8866469e-04 3.4976953e-01 9.0849477e-05
 6.0655630e-01 3.2157665e-03], sum to 1.0000
[2019-04-06 15:16:28,866] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3911
[2019-04-06 15:16:29,234] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.3, 63.0, 0.0, 0.0, 26.0, 25.38437202425587, 0.3286720888601321, 1.0, 1.0, 48931.2646921863], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 327600.0000, 
sim time next is 329400.0000, 
raw observation next is [-12.55, 66.5, 0.0, 0.0, 26.0, 25.20535452282899, 0.3011428373843547, 0.0, 1.0, 68360.15890072823], 
processed observation next is [1.0, 0.8260869565217391, 0.11495844875346259, 0.665, 0.0, 0.0, 0.6666666666666666, 0.6004462102357492, 0.600380945794785, 0.0, 1.0, 0.32552456619394393], 
reward next is 0.6745, 
noisyNet noise sample is [array([-0.30468062], dtype=float32), 0.05742794]. 
=============================================
[2019-04-06 15:17:04,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8165753e-04 1.9902602e-02 5.5899275e-03 2.4214524e-01 2.3241110e-04
 7.2609013e-01 5.0580609e-03], sum to 1.0000
[2019-04-06 15:17:04,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4435
[2019-04-06 15:17:04,671] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.1, 69.0, 0.0, 0.0, 26.0, 23.76559974906996, -0.01357976077140738, 0.0, 1.0, 45682.12836650063], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 268200.0000, 
sim time next is 270000.0000, 
raw observation next is [-8.9, 67.0, 0.0, 0.0, 26.0, 23.66567812967073, -0.04897886501571732, 0.0, 1.0, 45807.73213172389], 
processed observation next is [1.0, 0.13043478260869565, 0.21606648199445982, 0.67, 0.0, 0.0, 0.6666666666666666, 0.47213984413922755, 0.4836737116614276, 0.0, 1.0, 0.21813205777011377], 
reward next is 0.7819, 
noisyNet noise sample is [array([1.5067989], dtype=float32), 0.5231125]. 
=============================================
[2019-04-06 15:17:04,675] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[41.80413 ]
 [43.27505 ]
 [43.802895]
 [44.84147 ]
 [45.81903 ]], R is [[40.93924713]
 [41.31232071]
 [41.68226242]
 [42.04979324]
 [42.41587067]].
[2019-04-06 15:17:41,547] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0307101e-04 1.9384727e-02 1.7343841e-02 1.1828908e-01 1.9186543e-04
 8.4287137e-01 1.3160548e-03], sum to 1.0000
[2019-04-06 15:17:41,547] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0688
[2019-04-06 15:17:41,630] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-3.4, 83.0, 0.0, 0.0, 26.0, 24.76285148771629, 0.2170893363179995, 0.0, 1.0, 42846.84547817376], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 601200.0000, 
sim time next is 603000.0000, 
raw observation next is [-3.4, 85.0, 0.0, 0.0, 26.0, 24.68322580671635, 0.1965862113620128, 0.0, 1.0, 42599.53711329624], 
processed observation next is [0.0, 1.0, 0.368421052631579, 0.85, 0.0, 0.0, 0.6666666666666666, 0.5569354838930293, 0.5655287371206709, 0.0, 1.0, 0.202854938634744], 
reward next is 0.7971, 
noisyNet noise sample is [array([-0.11418505], dtype=float32), -0.22430894]. 
=============================================
[2019-04-06 15:17:41,640] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[45.213314]
 [45.465992]
 [45.39316 ]
 [45.69057 ]
 [45.36711 ]], R is [[45.61393356]
 [45.95376205]
 [46.28895187]
 [46.6131134 ]
 [46.78869247]].
[2019-04-06 15:17:51,305] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.9163712e-04 4.1516446e-02 4.7506541e-02 1.5560541e-01 4.6233361e-04
 7.4931133e-01 4.6063066e-03], sum to 1.0000
[2019-04-06 15:17:51,306] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0551
[2019-04-06 15:17:51,386] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.65, 70.0, 0.0, 0.0, 26.0, 24.66968461307228, 0.1486748714193092, 0.0, 1.0, 41905.57769939507], 
current ob forecast is [], 
actual action is [25.5], 
sim time this is 685800.0000, 
sim time next is 687600.0000, 
raw observation next is [-3.9, 71.0, 0.0, 0.0, 25.5, 24.60952934921322, 0.1282741291225755, 0.0, 1.0, 41689.28639670283], 
processed observation next is [0.0, 1.0, 0.3545706371191136, 0.71, 0.0, 0.0, 0.625, 0.5507941124344349, 0.5427580430408585, 0.0, 1.0, 0.19852041141287063], 
reward next is 0.8729, 
noisyNet noise sample is [array([0.41905755], dtype=float32), 1.4943639]. 
=============================================
[2019-04-06 15:17:54,338] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.7455134e-04 3.4822930e-02 3.2799653e-04 2.6162833e-01 9.4194285e-05
 7.0260900e-01 3.4291623e-04], sum to 1.0000
[2019-04-06 15:17:54,338] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2636
[2019-04-06 15:17:54,379] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 26.0, 25.98220799255846, 0.5319907698577574, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1015200.0000, 
sim time next is 1017000.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 26.0, 25.63531015558669, 0.4881449636275479, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.8614958448753465, 0.81, 0.0, 0.0, 0.6666666666666666, 0.6362758462988909, 0.6627149878758493, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.4202654], dtype=float32), 0.27305117]. 
=============================================
[2019-04-06 15:17:54,383] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[61.180954]
 [60.85895 ]
 [61.29461 ]
 [61.273037]
 [61.269073]], R is [[61.35972214]
 [61.74612427]
 [62.12866211]
 [62.50737762]
 [62.88230515]].
[2019-04-06 15:18:18,813] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-06 15:18:18,813] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:18:18,814] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:18:18,814] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:18:18,815] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:18:18,815] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:18:18,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run6
[2019-04-06 15:18:18,879] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:18:18,882] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run6
[2019-04-06 15:18:18,947] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run6
[2019-04-06 15:20:20,329] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.03916806], dtype=float32), 0.08355413]
[2019-04-06 15:20:20,330] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [2.9989731825, 43.5251566, 123.9258886, 854.9468693, 26.0, 25.68546616530057, 0.4599213043151814, 1.0, 1.0, 0.0]
[2019-04-06 15:20:20,330] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 15:20:20,331] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [4.1232075e-04 4.9947530e-02 1.5609135e-03 2.9300448e-01 1.5191155e-04
 6.5329683e-01 1.6260471e-03], sampled 0.9753059993187679
[2019-04-06 15:20:25,506] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2465.6791 79488880.6356 530.3926
[2019-04-06 15:20:46,389] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2426.5989 87576299.5648 510.9456
[2019-04-06 15:20:48,380] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2413.9250 91335855.5600 406.8215
[2019-04-06 15:20:49,417] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 100000, evaluation results [100000.0, 2426.598857553303, 87576299.56476367, 510.94555726796744, 2465.679119222618, 79488880.6355787, 530.3926359271078, 2413.9249558837564, 91335855.55998416, 406.8215015785851]
[2019-04-06 15:20:59,521] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.00325037 0.12938172 0.01283318 0.22719322 0.00090206 0.62049717
 0.00594228], sum to 1.0000
[2019-04-06 15:20:59,521] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9471
[2019-04-06 15:20:59,542] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [17.7, 67.0, 0.0, 0.0, 26.0, 24.71677902061132, 0.4044026662707368, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1191600.0000, 
sim time next is 1193400.0000, 
raw observation next is [17.7, 67.0, 0.0, 0.0, 26.0, 24.64398245671469, 0.3904237186420905, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.9529085872576178, 0.67, 0.0, 0.0, 0.6666666666666666, 0.553665204726224, 0.6301412395473635, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.14141206], dtype=float32), -1.4667616]. 
=============================================
[2019-04-06 15:21:04,852] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.00099931 0.15715449 0.00265899 0.39475298 0.00123417 0.43853474
 0.00466542], sum to 1.0000
[2019-04-06 15:21:04,852] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9714
[2019-04-06 15:21:04,856] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3507518e-03 7.4344024e-02 2.4248904e-03 1.5919727e-01 6.6687539e-04
 7.5332570e-01 8.6904317e-03], sum to 1.0000
[2019-04-06 15:21:04,856] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6385
[2019-04-06 15:21:04,873] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [18.3, 65.0, 128.0, 0.0, 26.0, 25.34295504292263, 0.5564491980262155, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1175400.0000, 
sim time next is 1177200.0000, 
raw observation next is [18.3, 65.0, 104.0, 0.0, 26.0, 25.33289874976185, 0.5572209865224081, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.9695290858725764, 0.65, 0.3466666666666667, 0.0, 0.6666666666666666, 0.6110748958134874, 0.6857403288408027, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.74646735], dtype=float32), 0.086966455]. 
=============================================
[2019-04-06 15:21:04,908] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [18.3, 65.0, 104.0, 0.0, 26.0, 25.04037752047432, 0.4973386534973344, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1177200.0000, 
sim time next is 1179000.0000, 
raw observation next is [18.55, 64.0, 80.0, 0.0, 26.0, 25.04559441786365, 0.489371303287729, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.976454293628809, 0.64, 0.26666666666666666, 0.0, 0.6666666666666666, 0.5871328681553042, 0.6631237677625763, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.13907151], dtype=float32), 0.39524695]. 
=============================================
[2019-04-06 15:21:04,916] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[42.150597]
 [42.082592]
 [41.819954]
 [41.63325 ]
 [41.42086 ]], R is [[42.6277771 ]
 [43.20149994]
 [43.76948547]
 [44.33179092]
 [44.88847351]].
[2019-04-06 15:21:05,711] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.00090809 0.01705005 0.00469221 0.54561293 0.00086349 0.42823392
 0.00263918], sum to 1.0000
[2019-04-06 15:21:05,711] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3963
[2019-04-06 15:21:05,785] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-5.6, 78.0, 0.0, 0.0, 25.5, 24.18863647707486, 0.1203115853407179, 0.0, 1.0, 46201.26423188476], 
current ob forecast is [], 
actual action is [25.5], 
sim time this is 1818000.0000, 
sim time next is 1819800.0000, 
raw observation next is [-5.8, 80.5, 0.0, 0.0, 25.5, 24.11331397203914, 0.1039077136351661, 0.0, 1.0, 46367.77590237004], 
processed observation next is [0.0, 0.043478260869565216, 0.30193905817174516, 0.805, 0.0, 0.0, 0.625, 0.5094428310032617, 0.5346359045450554, 0.0, 1.0, 0.22079893286842878], 
reward next is 0.8506, 
noisyNet noise sample is [array([1.5319507], dtype=float32), -0.7799398]. 
=============================================
[2019-04-06 15:21:42,620] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2055246e-04 5.0858364e-02 2.5099362e-03 4.6232052e-02 4.7196436e-04
 8.9738846e-01 1.7186883e-03], sum to 1.0000
[2019-04-06 15:21:42,620] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4934
[2019-04-06 15:21:42,717] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 75.0, 0.0, 0.0, 26.0, 24.14371364482411, 0.04525084184602673, 0.0, 1.0, 45135.36716064526], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1904400.0000, 
sim time next is 1906200.0000, 
raw observation next is [-7.55, 76.5, 0.0, 0.0, 26.0, 24.05124133246578, 0.02340000546366668, 0.0, 1.0, 45195.21787022517], 
processed observation next is [1.0, 0.043478260869565216, 0.25346260387811637, 0.765, 0.0, 0.0, 0.6666666666666666, 0.5042701110388149, 0.5078000018212222, 0.0, 1.0, 0.21521532319154843], 
reward next is 0.7848, 
noisyNet noise sample is [array([-0.15295555], dtype=float32), 0.2124402]. 
=============================================
[2019-04-06 15:21:44,267] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.1973162e-06 3.2153961e-03 2.7680642e-04 2.9590771e-01 1.9885501e-06
 7.0052308e-01 7.3778938e-05], sum to 1.0000
[2019-04-06 15:21:44,267] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0916
[2019-04-06 15:21:44,343] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-2.45, 54.5, 262.0, 74.0, 26.0, 25.6910512498954, 0.3592772345574076, 1.0, 1.0, 15585.643037038739], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2291400.0000, 
sim time next is 2293200.0000, 
raw observation next is [-1.7, 51.0, 241.5, 71.5, 26.0, 25.21767665463975, 0.3198146170359611, 1.0, 1.0, 15581.376999437243], 
processed observation next is [1.0, 0.5652173913043478, 0.4155124653739613, 0.51, 0.805, 0.07900552486187845, 0.6666666666666666, 0.6014730545533125, 0.6066048723453203, 1.0, 1.0, 0.07419703333065354], 
reward next is 0.9258, 
noisyNet noise sample is [array([-0.06187701], dtype=float32), 1.0918384]. 
=============================================
[2019-04-06 15:22:21,271] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3160231e-04 4.2018257e-02 6.6241315e-03 2.2082350e-01 1.4910286e-05
 7.2938174e-01 4.0585885e-04], sum to 1.0000
[2019-04-06 15:22:21,272] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3083
[2019-04-06 15:22:21,346] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1934795e-04 3.3488519e-02 2.9471965e-04 1.1890044e-01 1.3475702e-05
 8.4646142e-01 4.2202455e-04], sum to 1.0000
[2019-04-06 15:22:21,347] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6485
[2019-04-06 15:22:21,358] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 75.0, 0.0, 0.0, 26.0, 24.3973649195729, 0.1701955121592203, 0.0, 1.0, 44233.036492506566], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2250000.0000, 
sim time next is 2251800.0000, 
raw observation next is [-7.0, 78.5, 0.0, 0.0, 26.0, 24.27632137014515, 0.1480505153476035, 0.0, 1.0, 44086.45808306858], 
processed observation next is [1.0, 0.043478260869565216, 0.2686980609418283, 0.785, 0.0, 0.0, 0.6666666666666666, 0.5230267808454293, 0.5493501717825345, 0.0, 1.0, 0.20993551468127897], 
reward next is 0.7901, 
noisyNet noise sample is [array([-0.07193809], dtype=float32), 0.42786947]. 
=============================================
[2019-04-06 15:22:21,473] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 75.0, 0.0, 0.0, 26.0, 24.2260771145612, 0.1278359193874872, 0.0, 1.0, 44343.18474997862], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2250000.0000, 
sim time next is 2251800.0000, 
raw observation next is [-7.0, 78.5, 0.0, 0.0, 26.0, 24.1093813618556, 0.1063552497831907, 0.0, 1.0, 44196.42213474729], 
processed observation next is [1.0, 0.043478260869565216, 0.2686980609418283, 0.785, 0.0, 0.0, 0.6666666666666666, 0.5091151134879667, 0.5354517499277303, 0.0, 1.0, 0.21045915302260615], 
reward next is 0.7895, 
noisyNet noise sample is [array([0.86486137], dtype=float32), 1.1988815]. 
=============================================
[2019-04-06 15:22:33,982] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.4554489e-05 6.1508395e-02 9.8579167e-04 5.7985735e-01 7.1423252e-05
 3.5623774e-01 1.2447684e-03], sum to 1.0000
[2019-04-06 15:22:33,982] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7881
[2019-04-06 15:22:34,049] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 65.0, 0.0, 0.0, 26.0, 24.94663349123545, 0.3093543213595071, 0.0, 1.0, 38632.93909706649], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2332800.0000, 
sim time next is 2334600.0000, 
raw observation next is [-2.3, 63.5, 0.0, 0.0, 26.0, 24.92667531745881, 0.2883872065785745, 0.0, 1.0, 38517.98935038731], 
processed observation next is [0.0, 0.0, 0.3988919667590028, 0.635, 0.0, 0.0, 0.6666666666666666, 0.5772229431215674, 0.5961290688595248, 0.0, 1.0, 0.18341899690660624], 
reward next is 0.8166, 
noisyNet noise sample is [array([-1.6919798], dtype=float32), 1.2826021]. 
=============================================
[2019-04-06 15:22:43,592] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5827309e-03 3.0624777e-02 2.9086415e-03 3.2557327e-01 1.0381218e-04
 6.3399535e-01 5.2113868e-03], sum to 1.0000
[2019-04-06 15:22:43,592] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2272
[2019-04-06 15:22:43,814] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-1.7, 44.0, 0.0, 0.0, 26.0, 24.92665131227721, 0.1765344237468669, 0.0, 1.0, 38642.67921820071], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2516400.0000, 
sim time next is 2518200.0000, 
raw observation next is [-1.7, 46.5, 0.0, 0.0, 26.0, 25.01600004394609, 0.1892979305386843, 0.0, 1.0, 38515.481957321346], 
processed observation next is [1.0, 0.13043478260869565, 0.4155124653739613, 0.465, 0.0, 0.0, 0.6666666666666666, 0.5846666703288408, 0.5630993101795615, 0.0, 1.0, 0.18340705693962545], 
reward next is 0.8166, 
noisyNet noise sample is [array([-0.2528225], dtype=float32), -0.04852672]. 
=============================================
[2019-04-06 15:23:09,988] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7750200e-05 2.1627627e-02 1.4298140e-03 3.0737299e-01 1.1079293e-05
 6.6927153e-01 2.5922732e-04], sum to 1.0000
[2019-04-06 15:23:09,988] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1684
[2019-04-06 15:23:10,074] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-2.15, 67.0, 0.0, 0.0, 26.0, 25.44360425699151, 0.4392062213870628, 0.0, 1.0, 24050.403136761815], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2669400.0000, 
sim time next is 2671200.0000, 
raw observation next is [-3.1, 69.0, 0.0, 0.0, 26.0, 25.40953006807742, 0.4399267715912549, 0.0, 1.0, 52631.35037191932], 
processed observation next is [1.0, 0.9565217391304348, 0.37673130193905824, 0.69, 0.0, 0.0, 0.6666666666666666, 0.6174608390064517, 0.646642257197085, 0.0, 1.0, 0.25062547796152057], 
reward next is 0.7494, 
noisyNet noise sample is [array([-0.32170656], dtype=float32), -0.066189535]. 
=============================================
[2019-04-06 15:23:54,372] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 15:23:54,409] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:23:54,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:23:54,411] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run7
[2019-04-06 15:23:54,471] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:23:54,471] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:23:54,474] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run7
[2019-04-06 15:23:54,573] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:23:54,573] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:23:54,576] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run7
[2019-04-06 15:25:36,695] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.03403804], dtype=float32), 0.09114371]
[2019-04-06 15:25:36,695] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-2.3, 57.0, 0.0, 0.0, 26.0, 24.80833866886415, 0.1435977733368645, 0.0, 1.0, 38370.798765558495]
[2019-04-06 15:25:36,695] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:25:36,696] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.4473133e-04 3.4941435e-02 2.7870706e-03 2.1372119e-01 7.8577301e-05
 7.4624306e-01 1.7840212e-03], sampled 0.7934747442059343
[2019-04-06 15:26:06,658] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2458.8132 79737753.4290 533.9218
[2019-04-06 15:26:25,502] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2420.6758 87729452.8517 513.8296
[2019-04-06 15:26:30,045] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2402.6594 91681493.8826 408.8271
[2019-04-06 15:26:31,066] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 120000, evaluation results [120000.0, 2420.6757712565873, 87729452.85174312, 513.829566743494, 2458.8131906738076, 79737753.42900942, 533.9218057178238, 2402.659356577464, 91681493.88261038, 408.8270523677427]
[2019-04-06 15:26:39,039] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.03341255e-04 1.60311490e-01 3.30696627e-03 2.42754355e-01
 7.16379509e-06 5.92343211e-01 1.17350230e-03], sum to 1.0000
[2019-04-06 15:26:39,039] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7060
[2019-04-06 15:26:39,128] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 77.0, 0.0, 0.0, 26.0, 24.78218282477702, 0.2432658791054843, 0.0, 1.0, 43159.249615926106], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3825000.0000, 
sim time next is 3826800.0000, 
raw observation next is [-5.0, 77.0, 0.0, 0.0, 26.0, 24.70870713519498, 0.2305197937074012, 0.0, 1.0, 42922.21172951458], 
processed observation next is [1.0, 0.30434782608695654, 0.32409972299168976, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5590589279329151, 0.5768399312358005, 0.0, 1.0, 0.2043914844262599], 
reward next is 0.7956, 
noisyNet noise sample is [array([-0.67315495], dtype=float32), 1.3361539]. 
=============================================
[2019-04-06 15:26:41,365] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.2385491e-05 1.6820650e-01 6.4078229e-04 3.8400486e-01 2.1444530e-06
 4.4646510e-01 6.5828359e-04], sum to 1.0000
[2019-04-06 15:26:41,365] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5477
[2019-04-06 15:26:41,485] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-4.5, 36.0, 66.0, 536.0, 26.0, 26.97881508661241, 0.7727220141358391, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3947400.0000, 
sim time next is 3949200.0000, 
raw observation next is [-5.0, 38.0, 42.5, 352.5, 26.0, 26.35328767145905, 0.6642344281124826, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.32409972299168976, 0.38, 0.14166666666666666, 0.38950276243093923, 0.6666666666666666, 0.6961073059549209, 0.7214114760374942, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.3841813], dtype=float32), -0.72288]. 
=============================================
[2019-04-06 15:26:43,039] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.17609646e-06 8.66332185e-03 1.05750274e-04 3.37320387e-01
 2.14891315e-06 6.53152227e-01 7.48970488e-04], sum to 1.0000
[2019-04-06 15:26:43,040] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4182
[2019-04-06 15:26:43,113] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 38.0, 42.5, 352.5, 26.0, 26.66455861555987, 0.6756830456609194, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3949200.0000, 
sim time next is 3951000.0000, 
raw observation next is [-5.5, 39.5, 19.0, 169.0, 26.0, 26.40367175364834, 0.5500933650017902, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3102493074792244, 0.395, 0.06333333333333334, 0.1867403314917127, 0.6666666666666666, 0.700305979470695, 0.6833644550005967, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6369228], dtype=float32), 1.1208756]. 
=============================================
[2019-04-06 15:26:43,116] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[71.17148 ]
 [71.61339 ]
 [72.216675]
 [72.599236]
 [72.90722 ]], R is [[70.6097641 ]
 [70.90366364]
 [71.19462585]
 [71.48268127]
 [71.76785278]].
[2019-04-06 15:27:15,177] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:27:15,177] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:27:15,179] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run4
[2019-04-06 15:27:39,576] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:27:39,576] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:27:39,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run4
[2019-04-06 15:27:40,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:27:40,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:27:40,631] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run4
[2019-04-06 15:27:41,038] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.4096056e-07 4.6884693e-04 1.1758141e-05 2.0389894e-02 9.5200619e-08
 9.7909099e-01 3.7579935e-05], sum to 1.0000
[2019-04-06 15:27:41,038] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2169
[2019-04-06 15:27:41,399] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 92.0, 63.0, 0.0, 26.0, 25.96121119287625, 0.5203689701259709, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4696200.0000, 
sim time next is 4698000.0000, 
raw observation next is [0.0, 92.0, 89.0, 0.0, 26.0, 26.1447235091217, 0.5239777916559153, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.46260387811634357, 0.92, 0.2966666666666667, 0.0, 0.6666666666666666, 0.678726959093475, 0.6746592638853052, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7921102], dtype=float32), 1.0002536]. 
=============================================
[2019-04-06 15:27:41,421] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.218025]
 [69.708305]
 [68.5301  ]
 [67.81587 ]
 [67.46498 ]], R is [[72.00819397]
 [72.28811646]
 [72.56523895]
 [72.75499725]
 [72.84285736]].
[2019-04-06 15:27:46,737] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:27:46,737] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:27:46,739] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run4
[2019-04-06 15:28:01,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:28:01,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:28:01,755] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run4
[2019-04-06 15:28:06,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9822457e-05 3.8540639e-02 1.2130998e-04 5.4940522e-01 2.3319151e-06
 4.1147363e-01 3.5703098e-04], sum to 1.0000
[2019-04-06 15:28:06,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3770
[2019-04-06 15:28:07,332] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-7.8, 67.5, 45.0, 0.0, 26.0, 25.35832444602691, 0.2558585562517223, 1.0, 1.0, 6246.0968611943135], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 120600.0000, 
sim time next is 122400.0000, 
raw observation next is [-7.8, 74.0, 117.5, 18.0, 26.0, 25.31813686460116, 0.259059292213894, 1.0, 1.0, 36781.697748444414], 
processed observation next is [1.0, 0.43478260869565216, 0.24653739612188366, 0.74, 0.39166666666666666, 0.019889502762430938, 0.6666666666666666, 0.6098447387167635, 0.5863530974046314, 1.0, 1.0, 0.17515094165925912], 
reward next is 0.8248, 
noisyNet noise sample is [array([-0.14410064], dtype=float32), -0.017950429]. 
=============================================
[2019-04-06 15:28:10,255] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:28:10,256] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:28:10,262] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run4
[2019-04-06 15:28:10,809] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:28:10,809] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:28:10,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run4
[2019-04-06 15:28:17,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:28:17,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:28:17,183] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run4
[2019-04-06 15:28:18,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:28:18,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:28:18,092] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run4
[2019-04-06 15:28:22,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:28:22,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:28:22,028] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run4
[2019-04-06 15:28:22,509] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1217307e-06 2.1009423e-02 7.3701347e-05 1.1868890e-01 3.1318797e-07
 8.5927969e-01 9.4286370e-04], sum to 1.0000
[2019-04-06 15:28:22,509] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3320
[2019-04-06 15:28:22,954] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 59.0, 86.5, 0.0, 26.0, 25.52724785621204, 0.2742192593796887, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 226800.0000, 
sim time next is 228600.0000, 
raw observation next is [-3.1, 60.5, 56.0, 0.0, 26.0, 25.54970852573094, 0.3445653931950798, 1.0, 1.0, 68239.00042866306], 
processed observation next is [1.0, 0.6521739130434783, 0.37673130193905824, 0.605, 0.18666666666666668, 0.0, 0.6666666666666666, 0.6291423771442449, 0.6148551310650266, 1.0, 1.0, 0.3249476210888717], 
reward next is 0.6751, 
noisyNet noise sample is [array([0.1896435], dtype=float32), -0.082749784]. 
=============================================
[2019-04-06 15:28:25,886] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:28:25,886] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:28:25,888] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run4
[2019-04-06 15:28:27,620] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:28:27,620] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:28:27,622] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run4
[2019-04-06 15:28:27,737] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:28:27,737] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:28:27,739] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run4
[2019-04-06 15:28:31,070] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:28:31,070] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:28:31,072] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run4
[2019-04-06 15:28:31,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:28:31,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:28:31,187] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run4
[2019-04-06 15:28:31,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:28:31,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:28:31,291] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run4
[2019-04-06 15:28:53,426] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4291814e-05 2.7267062e-03 8.2762947e-04 3.3288142e-01 4.5101960e-06
 6.6332626e-01 2.0925191e-04], sum to 1.0000
[2019-04-06 15:28:53,426] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5145
[2019-04-06 15:28:53,504] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 85.0, 0.0, 0.0, 26.0, 24.66392510822999, 0.2198849776865507, 0.0, 1.0, 40717.16477010369], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 75600.0000, 
sim time next is 77400.0000, 
raw observation next is [1.05, 90.5, 0.0, 0.0, 26.0, 24.59815194212583, 0.2077316745265956, 0.0, 1.0, 40586.59141281037], 
processed observation next is [0.0, 0.9130434782608695, 0.49168975069252085, 0.905, 0.0, 0.0, 0.6666666666666666, 0.5498459951771526, 0.5692438915088652, 0.0, 1.0, 0.1932694829181446], 
reward next is 0.8067, 
noisyNet noise sample is [array([-0.3116878], dtype=float32), 1.3306562]. 
=============================================
[2019-04-06 15:29:07,759] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.9337353e-07 1.1871155e-02 8.0778445e-05 3.2686736e-02 4.8816014e-07
 9.5530295e-01 5.7367197e-05], sum to 1.0000
[2019-04-06 15:29:07,759] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5052
[2019-04-06 15:29:08,105] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 26.0, 24.98254210866697, 0.2137686007983224, 1.0, 1.0, 59768.18927937779], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 239400.0000, 
sim time next is 241200.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 26.0, 25.00938759832779, 0.3015950105218792, 1.0, 1.0, 103940.0137415551], 
processed observation next is [1.0, 0.8260869565217391, 0.368421052631579, 0.65, 0.0, 0.0, 0.6666666666666666, 0.5841156331939826, 0.6005316701739597, 1.0, 1.0, 0.4949524463883576], 
reward next is 0.5050, 
noisyNet noise sample is [array([0.19077338], dtype=float32), 0.9811574]. 
=============================================
[2019-04-06 15:29:22,907] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-06 15:29:22,907] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:29:22,907] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:22,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run8
[2019-04-06 15:29:22,955] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:29:22,956] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:22,970] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run8
[2019-04-06 15:29:23,026] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:29:23,026] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:23,028] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run8
[2019-04-06 15:31:41,132] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.9019 79906128.0279 533.9317
[2019-04-06 15:32:01,672] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2417.6750 87765776.8262 516.2433
[2019-04-06 15:32:03,679] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2399.0195 91872288.8203 408.4858
[2019-04-06 15:32:04,701] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 140000, evaluation results [140000.0, 2417.675048089699, 87765776.8261541, 516.2432661678114, 2454.90193141347, 79906128.02788313, 533.9316522547061, 2399.0195408289164, 91872288.82029504, 408.4857717327511]
[2019-04-06 15:32:14,714] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.1117025e-05 2.6622561e-03 1.2892407e-03 1.4068398e-01 4.9453065e-06
 8.5498071e-01 2.9771458e-04], sum to 1.0000
[2019-04-06 15:32:14,715] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5447
[2019-04-06 15:32:14,957] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 91.0, 89.0, 103.5, 26.0, 25.12058592772083, 0.2949890975136364, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 550800.0000, 
sim time next is 552600.0000, 
raw observation next is [-0.3, 89.0, 144.0, 103.0, 26.0, 24.97551848481425, 0.2679522346909654, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.4542936288088643, 0.89, 0.48, 0.1138121546961326, 0.6666666666666666, 0.581293207067854, 0.5893174115636551, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1769296], dtype=float32), -0.52359605]. 
=============================================
[2019-04-06 15:32:44,470] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1134063e-05 1.4756556e-03 3.5857919e-04 3.9474770e-02 2.1987935e-07
 9.5851249e-01 1.6718011e-04], sum to 1.0000
[2019-04-06 15:32:44,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3137
[2019-04-06 15:32:44,795] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.75, 71.0, 120.0, 0.0, 26.0, 24.96764348608033, 0.2530067892922169, 0.0, 1.0, 40540.26458323861], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1859400.0000, 
sim time next is 1861200.0000, 
raw observation next is [-4.5, 71.0, 145.0, 20.0, 26.0, 24.96074384747436, 0.2670649741612272, 0.0, 1.0, 49394.9806996113], 
processed observation next is [0.0, 0.5652173913043478, 0.3379501385041552, 0.71, 0.48333333333333334, 0.022099447513812154, 0.6666666666666666, 0.5800619872895302, 0.5890216580537424, 0.0, 1.0, 0.23521419380767283], 
reward next is 0.7648, 
noisyNet noise sample is [array([-0.9901416], dtype=float32), 0.5114037]. 
=============================================
[2019-04-06 15:32:47,909] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.8275706e-07 3.2336561e-03 4.2294287e-05 1.6645451e-01 2.1119149e-06
 8.3020437e-01 6.2634244e-05], sum to 1.0000
[2019-04-06 15:32:47,909] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0685
[2019-04-06 15:32:47,964] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [2.2, 94.0, 0.0, 0.0, 26.0, 25.38783802042684, 0.453272985092065, 0.0, 1.0, 40448.95237257737], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1479600.0000, 
sim time next is 1481400.0000, 
raw observation next is [2.2, 95.0, 0.0, 0.0, 26.0, 25.40199659091357, 0.4706813917984966, 0.0, 1.0, 41943.65434452465], 
processed observation next is [1.0, 0.13043478260869565, 0.5235457063711911, 0.95, 0.0, 0.0, 0.6666666666666666, 0.6168330492427975, 0.6568937972661656, 0.0, 1.0, 0.19973168735487928], 
reward next is 0.8003, 
noisyNet noise sample is [array([0.10339838], dtype=float32), 0.6813412]. 
=============================================
[2019-04-06 15:32:48,311] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3693275e-07 1.1753658e-02 4.4439195e-05 1.8431375e-02 2.9481022e-08
 9.6974021e-01 2.9579691e-05], sum to 1.0000
[2019-04-06 15:32:48,311] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7406
[2019-04-06 15:32:48,429] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.7, 92.5, 27.0, 0.0, 26.0, 25.71442642155425, 0.5088656896611348, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 981000.0000, 
sim time next is 982800.0000, 
raw observation next is [10.0, 92.0, 43.5, 0.0, 26.0, 26.14951600021678, 0.5746553490454934, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.739612188365651, 0.92, 0.145, 0.0, 0.6666666666666666, 0.6791263333513985, 0.6915517830151644, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.62484306], dtype=float32), 2.7580678]. 
=============================================
[2019-04-06 15:32:55,514] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1218689e-06 2.8422882e-03 3.5596790e-04 8.1442215e-02 4.9913780e-07
 9.1518354e-01 1.7333573e-04], sum to 1.0000
[2019-04-06 15:32:55,516] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6285
[2019-04-06 15:32:55,577] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.8, 83.0, 0.0, 0.0, 26.0, 25.55183185131312, 0.4724778511996126, 0.0, 1.0, 31856.714591058208], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 972000.0000, 
sim time next is 973800.0000, 
raw observation next is [9.4, 83.0, 0.0, 0.0, 26.0, 25.59040771552882, 0.4447218532004657, 0.0, 1.0, 6246.165996939463], 
processed observation next is [1.0, 0.2608695652173913, 0.7229916897506927, 0.83, 0.0, 0.0, 0.6666666666666666, 0.6325339762940683, 0.6482406177334886, 0.0, 1.0, 0.029743647604473636], 
reward next is 0.9703, 
noisyNet noise sample is [array([1.1964808], dtype=float32), 0.90398544]. 
=============================================
[2019-04-06 15:32:56,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2310670e-06 2.8069052e-03 2.7416923e-05 1.2218720e-01 2.4237343e-08
 8.7495691e-01 2.0288533e-05], sum to 1.0000
[2019-04-06 15:32:56,822] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5179
[2019-04-06 15:32:56,897] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.55, 79.0, 0.0, 0.0, 26.0, 25.71003712912121, 0.6086977949510106, 0.0, 1.0, 27440.853858329483], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1056600.0000, 
sim time next is 1058400.0000, 
raw observation next is [13.3, 80.0, 0.0, 0.0, 26.0, 25.80999851487382, 0.5967857912647473, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.8310249307479226, 0.8, 0.0, 0.0, 0.6666666666666666, 0.6508332095728182, 0.6989285970882491, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7019031], dtype=float32), 0.31047216]. 
=============================================
[2019-04-06 15:33:03,578] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6806471e-04 3.6105603e-02 5.8601139e-04 5.4430157e-01 9.0408976e-05
 4.1708222e-01 1.6661353e-03], sum to 1.0000
[2019-04-06 15:33:03,578] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5848
[2019-04-06 15:33:03,617] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.0, 100.0, 74.0, 0.0, 23.0, 23.31709509265256, 0.1231667402827118, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1243800.0000, 
sim time next is 1245600.0000, 
raw observation next is [15.0, 100.0, 76.0, 0.0, 24.0, 23.30221945987492, 0.1224674633390447, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.8781163434903049, 1.0, 0.25333333333333335, 0.0, 0.5, 0.4418516216562433, 0.5408224877796816, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5215641], dtype=float32), 0.24878201]. 
=============================================
[2019-04-06 15:33:06,612] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9989889e-07 1.1025938e-03 3.7338614e-05 7.6259740e-02 6.4711907e-07
 9.2259514e-01 4.1311537e-06], sum to 1.0000
[2019-04-06 15:33:06,612] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2252
[2019-04-06 15:33:06,734] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 26.0, 25.14586631289958, 0.4804145129655035, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1366200.0000, 
sim time next is 1368000.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 26.0, 24.90865107179368, 0.4626300913964649, 1.0, 1.0, 53878.377107877575], 
processed observation next is [1.0, 0.8695652173913043, 0.4764542936288089, 0.96, 0.0, 0.0, 0.6666666666666666, 0.5757209226494734, 0.6542100304654883, 1.0, 1.0, 0.25656370051370275], 
reward next is 0.7434, 
noisyNet noise sample is [array([-0.22112946], dtype=float32), 0.32024616]. 
=============================================
[2019-04-06 15:33:06,737] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[82.15066 ]
 [83.186195]
 [82.559135]
 [82.57639 ]
 [82.73733 ]], R is [[81.97543335]
 [82.1556778 ]
 [81.8350296 ]
 [82.01667786]
 [82.19651031]].
[2019-04-06 15:33:21,814] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.4816122e-05 2.0200863e-02 8.9851115e-04 4.8787981e-02 2.2190982e-06
 9.2984205e-01 2.0359221e-04], sum to 1.0000
[2019-04-06 15:33:21,814] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8730
[2019-04-06 15:33:21,919] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 87.0, 0.0, 0.0, 26.0, 24.70868890652511, 0.3069496690716653, 0.0, 1.0, 44044.87989954856], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1755000.0000, 
sim time next is 1756800.0000, 
raw observation next is [-1.7, 87.0, 13.5, 0.0, 26.0, 24.71535660580413, 0.2949088249880059, 0.0, 1.0, 44078.98076636457], 
processed observation next is [0.0, 0.34782608695652173, 0.4155124653739613, 0.87, 0.045, 0.0, 0.6666666666666666, 0.5596130504836774, 0.5983029416626686, 0.0, 1.0, 0.20989990841125986], 
reward next is 0.7901, 
noisyNet noise sample is [array([-1.3969376], dtype=float32), -1.4360435]. 
=============================================
[2019-04-06 15:33:48,975] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5318412e-05 8.6817035e-04 1.2038514e-04 1.1476402e-02 3.0584374e-07
 9.8730415e-01 2.1529933e-04], sum to 1.0000
[2019-04-06 15:33:48,976] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9218
[2019-04-06 15:33:49,321] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 75.0, 50.5, 0.0, 26.0, 25.012340718067, 0.2587711321379002, 0.0, 1.0, 51227.437006914115], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1872000.0000, 
sim time next is 1873800.0000, 
raw observation next is [-4.5, 79.0, 29.0, 0.0, 26.0, 25.04284015325651, 0.2619233253990034, 0.0, 1.0, 41803.753711410034], 
processed observation next is [0.0, 0.6956521739130435, 0.3379501385041552, 0.79, 0.09666666666666666, 0.0, 0.6666666666666666, 0.5869033461047092, 0.5873077751330011, 0.0, 1.0, 0.1990654938638573], 
reward next is 0.8009, 
noisyNet noise sample is [array([-0.56864315], dtype=float32), 1.0689948]. 
=============================================
[2019-04-06 15:34:46,311] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1005895e-06 2.1810881e-03 3.7201702e-05 6.8745297e-01 2.2661121e-07
 3.1032348e-01 1.8246940e-06], sum to 1.0000
[2019-04-06 15:34:46,312] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5634
[2019-04-06 15:34:46,352] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [7.0, 100.0, 111.0, 775.5, 26.0, 27.03927071723088, 0.7433727440396761, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3150000.0000, 
sim time next is 3151800.0000, 
raw observation next is [7.5, 96.5, 114.0, 805.0, 26.0, 27.11464274792437, 0.7805227875352537, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.6703601108033241, 0.965, 0.38, 0.8895027624309392, 0.6666666666666666, 0.759553562327031, 0.7601742625117512, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.07652036], dtype=float32), -2.0045736]. 
=============================================
[2019-04-06 15:35:10,511] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 15:35:10,512] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:35:10,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:35:10,514] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run9
[2019-04-06 15:35:10,598] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:35:10,598] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:35:10,600] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run9
[2019-04-06 15:35:10,657] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:35:10,657] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:35:10,659] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run9
[2019-04-06 15:37:32,138] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.5615 79891012.6558 535.4136
[2019-04-06 15:37:50,133] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2418.1284 87731696.1798 514.5716
[2019-04-06 15:37:53,574] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.9746 91903842.5897 409.4516
[2019-04-06 15:37:54,596] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 160000, evaluation results [160000.0, 2418.1284382507033, 87731696.17984195, 514.5715682738362, 2454.561458604762, 79891012.65577243, 535.4136045224456, 2397.974597921606, 91903842.58973339, 409.4515875854071]
[2019-04-06 15:37:58,625] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2579598e-07 4.6776244e-04 2.3986819e-05 2.0068087e-01 3.7109526e-08
 7.9880542e-01 2.1618722e-05], sum to 1.0000
[2019-04-06 15:37:58,626] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0053
[2019-04-06 15:37:58,821] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [1.6, 32.0, 0.0, 0.0, 26.0, 25.66079830386374, 0.1748812430610284, 1.0, 1.0, 3113.4019450384226], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2568600.0000, 
sim time next is 2570400.0000, 
raw observation next is [0.5, 35.0, 0.0, 0.0, 26.0, 25.01491004861527, 0.3388731691225208, 1.0, 1.0, 93861.16208890756], 
processed observation next is [1.0, 0.782608695652174, 0.4764542936288089, 0.35, 0.0, 0.0, 0.6666666666666666, 0.5845758373846058, 0.6129577230408403, 1.0, 1.0, 0.4469579147090836], 
reward next is 0.5530, 
noisyNet noise sample is [array([0.37672305], dtype=float32), 2.0732794]. 
=============================================
[2019-04-06 15:38:15,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7049758e-05 1.3006701e-02 2.7335042e-04 1.9448745e-01 9.7267748e-06
 7.9157853e-01 6.0724240e-04], sum to 1.0000
[2019-04-06 15:38:15,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8074
[2019-04-06 15:38:16,034] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 166.0, 78.0, 26.0, 24.9772160830222, 0.2861371581597432, 0.0, 1.0, 22189.767890583393], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2973600.0000, 
sim time next is 2975400.0000, 
raw observation next is [-3.5, 68.0, 178.0, 24.0, 26.0, 24.88827527233212, 0.3160789997139004, 0.0, 1.0, 81908.23650285079], 
processed observation next is [0.0, 0.43478260869565216, 0.36565096952908593, 0.68, 0.5933333333333334, 0.026519337016574586, 0.6666666666666666, 0.57402293936101, 0.6053596665713001, 0.0, 1.0, 0.39003922144214664], 
reward next is 0.6100, 
noisyNet noise sample is [array([0.7480521], dtype=float32), -1.0232513]. 
=============================================
[2019-04-06 15:38:24,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0492296e-05 6.3139149e-03 5.1318249e-04 8.9167811e-02 1.0624665e-05
 9.0363252e-01 3.5134199e-04], sum to 1.0000
[2019-04-06 15:38:24,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0828
[2019-04-06 15:38:24,578] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-4.0, 71.0, 166.0, 78.0, 26.0, 24.96148498999644, 0.2873417749344172, 0.0, 1.0, 26139.69058266365], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2973600.0000, 
sim time next is 2975400.0000, 
raw observation next is [-3.5, 68.0, 178.0, 24.0, 26.0, 24.89526537378678, 0.3174255370636319, 0.0, 1.0, 78236.75567677684], 
processed observation next is [0.0, 0.43478260869565216, 0.36565096952908593, 0.68, 0.5933333333333334, 0.026519337016574586, 0.6666666666666666, 0.5746054478155651, 0.6058085123545439, 0.0, 1.0, 0.37255597941322305], 
reward next is 0.6274, 
noisyNet noise sample is [array([0.67225736], dtype=float32), -0.8620989]. 
=============================================
[2019-04-06 15:38:26,795] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.6171154e-08 1.9452986e-04 6.7251960e-05 3.2888748e-02 2.6207299e-08
 9.6684754e-01 1.7886302e-06], sum to 1.0000
[2019-04-06 15:38:26,795] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0413
[2019-04-06 15:38:26,884] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.5, 100.0, 0.0, 0.0, 26.0, 25.47259226354692, 0.5807088965783388, 0.0, 1.0, 53199.492150225735], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3205800.0000, 
sim time next is 3207600.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.56828854140773, 0.5398264333454853, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.4349030470914128, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6306907117839774, 0.6799421444484951, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.97174144], dtype=float32), 0.6944143]. 
=============================================
[2019-04-06 15:38:29,083] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8382789e-06 4.1683912e-03 2.1668411e-05 1.5686536e-01 9.9831450e-09
 8.3893222e-01 1.0646252e-05], sum to 1.0000
[2019-04-06 15:38:29,083] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8922
[2019-04-06 15:38:29,118] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 54.0, 117.0, 804.5, 26.0, 26.35541336385647, 0.6046343201761224, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3326400.0000, 
sim time next is 3328200.0000, 
raw observation next is [-5.5, 54.0, 118.0, 811.0, 26.0, 26.24355867432544, 0.5767483550382534, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.3102493074792244, 0.54, 0.3933333333333333, 0.8961325966850828, 0.6666666666666666, 0.6869632228604532, 0.6922494516794178, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4992306], dtype=float32), 0.1172809]. 
=============================================
[2019-04-06 15:38:52,516] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2615557e-07 4.1609671e-04 3.2392234e-06 1.6552331e-01 3.3515282e-09
 8.3405513e-01 2.1104620e-06], sum to 1.0000
[2019-04-06 15:38:52,516] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2891
[2019-04-06 15:38:52,567] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 28.0, 120.5, 828.5, 26.0, 26.54644354334039, 0.4078033861066039, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4104000.0000, 
sim time next is 4105800.0000, 
raw observation next is [2.0, 28.5, 120.0, 841.0, 26.0, 26.35789811351332, 0.4747843519406343, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.518005540166205, 0.285, 0.4, 0.9292817679558011, 0.6666666666666666, 0.6964915094594432, 0.6582614506468781, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.59515876], dtype=float32), -0.50787866]. 
=============================================
[2019-04-06 15:38:57,432] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.5954200e-07 7.6334632e-04 1.8886121e-05 5.5235531e-02 1.9819728e-08
 9.4388300e-01 9.8641212e-05], sum to 1.0000
[2019-04-06 15:38:57,432] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7404
[2019-04-06 15:38:57,611] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 74.0, 5.0, 136.0, 26.0, 25.22061976342765, 0.2867479719014725, 1.0, 1.0, 14150.424142822782], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3742200.0000, 
sim time next is 3744000.0000, 
raw observation next is [-4.0, 71.0, 47.0, 282.5, 26.0, 25.24331302182367, 0.298843688733644, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3518005540166205, 0.71, 0.15666666666666668, 0.31215469613259667, 0.6666666666666666, 0.6036094184853059, 0.5996145629112147, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1286077], dtype=float32), 0.20621577]. 
=============================================
[2019-04-06 15:38:57,614] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[71.07275]
 [70.21205]
 [69.5052 ]
 [69.26443]
 [69.06039]], R is [[72.30850983]
 [72.51804352]
 [72.59146881]
 [72.66549683]
 [72.74009705]].
[2019-04-06 15:39:17,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:39:17,397] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:39:17,399] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run5
[2019-04-06 15:39:19,132] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4982245e-08 9.9145435e-04 3.8241302e-07 4.8958515e-03 9.5815933e-10
 9.9410594e-01 6.3940861e-06], sum to 1.0000
[2019-04-06 15:39:19,132] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3203
[2019-04-06 15:39:19,263] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 34.0, 0.0, 0.0, 26.0, 26.55489696407201, 0.6753196597697997, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4125600.0000, 
sim time next is 4127400.0000, 
raw observation next is [3.0, 35.5, 0.0, 0.0, 26.0, 25.83506401552917, 0.5116823309308898, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.5457063711911359, 0.355, 0.0, 0.0, 0.6666666666666666, 0.6529220012940975, 0.6705607769769633, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.70714027], dtype=float32), 0.54380465]. 
=============================================
[2019-04-06 15:39:48,735] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.64859220e-08 2.45604635e-04 5.65635401e-06 1.38999885e-02
 1.00016151e-09 9.85825121e-01 2.36659362e-05], sum to 1.0000
[2019-04-06 15:39:48,735] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1370
[2019-04-06 15:39:49,038] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 78.0, 0.0, 0.0, 26.0, 25.04319315133799, 0.4480157264600064, 1.0, 1.0, 87569.14125378914], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4734000.0000, 
sim time next is 4735800.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 26.0, 25.28557051658855, 0.4517165115553934, 1.0, 1.0, 6236.029463199917], 
processed observation next is [1.0, 0.8260869565217391, 0.4349030470914128, 0.78, 0.0, 0.0, 0.6666666666666666, 0.6071308763823792, 0.6505721705184645, 1.0, 1.0, 0.02969537839619008], 
reward next is 0.9703, 
noisyNet noise sample is [array([1.6267829], dtype=float32), 2.1937654]. 
=============================================
[2019-04-06 15:39:58,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:39:58,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:39:58,319] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run5
[2019-04-06 15:40:01,096] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:40:01,096] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:40:01,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run5
[2019-04-06 15:40:01,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:40:01,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:40:01,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run5
[2019-04-06 15:40:14,166] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.3946143e-06 8.7599577e-03 1.2946840e-04 1.3051032e-01 3.3764236e-06
 8.6040658e-01 1.8880417e-04], sum to 1.0000
[2019-04-06 15:40:14,167] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3497
[2019-04-06 15:40:14,292] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 34.0, 57.5, 367.0, 26.0, 25.2250546779056, 0.4024367401440496, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4813200.0000, 
sim time next is 4815000.0000, 
raw observation next is [2.5, 37.0, 33.0, 185.0, 26.0, 25.12705076723828, 0.375166078365369, 0.0, 1.0, 26034.572821154823], 
processed observation next is [0.0, 0.7391304347826086, 0.5318559556786704, 0.37, 0.11, 0.20441988950276244, 0.6666666666666666, 0.5939208972698568, 0.625055359455123, 0.0, 1.0, 0.12397415629121344], 
reward next is 0.8760, 
noisyNet noise sample is [array([-0.6534533], dtype=float32), 0.9686668]. 
=============================================
[2019-04-06 15:40:14,394] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[68.797  ]
 [69.66237]
 [70.54956]
 [71.136  ]
 [70.96658]], R is [[68.16537476]
 [68.48371887]
 [68.79888153]
 [69.11089325]
 [69.41978455]].
[2019-04-06 15:40:17,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:40:17,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:40:17,075] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run5
[2019-04-06 15:40:20,921] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 15:40:20,925] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:40:20,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:40:20,927] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run10
[2019-04-06 15:40:21,045] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:40:21,045] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:40:21,048] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run10
[2019-04-06 15:40:21,153] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:40:21,154] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:40:21,156] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run10
[2019-04-06 15:42:35,020] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.3437 79935594.1366 535.1776
[2019-04-06 15:42:53,615] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.9905 87819414.5379 516.0624
[2019-04-06 15:42:57,221] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.2203 91895035.1445 409.3981
[2019-04-06 15:42:58,244] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 180000, evaluation results [180000.0, 2415.990482562714, 87819414.53790195, 516.0624026357644, 2454.3437067558766, 79935594.1366011, 535.1776196519511, 2397.2202729332007, 91895035.14445265, 409.3981005019669]
[2019-04-06 15:42:58,693] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2162194e-06 2.7933817e-03 1.0489727e-04 5.8743162e-03 1.1441548e-06
 9.9116147e-01 6.2557323e-05], sum to 1.0000
[2019-04-06 15:42:58,694] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5861
[2019-04-06 15:42:58,762] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 93.0, 0.0, 0.0, 26.0, 24.00174436641615, 0.1094807173850851, 0.0, 1.0, 41758.493989368755], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4777200.0000, 
sim time next is 4779000.0000, 
raw observation next is [-6.1, 92.5, 0.0, 0.0, 26.0, 23.90818268863903, 0.08892924637740385, 0.0, 1.0, 41863.2223067531], 
processed observation next is [0.0, 0.30434782608695654, 0.29362880886426596, 0.925, 0.0, 0.0, 0.6666666666666666, 0.49234855738658584, 0.5296430821258012, 0.0, 1.0, 0.19934867765120523], 
reward next is 0.8007, 
noisyNet noise sample is [array([-1.8657017], dtype=float32), 2.146283]. 
=============================================
[2019-04-06 15:42:58,770] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.493996]
 [65.51644 ]
 [65.57343 ]
 [65.335236]
 [64.9795  ]], R is [[65.59830475]
 [65.74346924]
 [65.88790894]
 [66.03181458]
 [66.17497253]].
[2019-04-06 15:43:01,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:43:01,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:43:01,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run5
[2019-04-06 15:43:03,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:43:03,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:43:03,659] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run5
[2019-04-06 15:43:06,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:43:06,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:43:06,364] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run5
[2019-04-06 15:43:08,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:43:08,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:43:08,966] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run5
[2019-04-06 15:43:09,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:43:09,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:43:09,743] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run5
[2019-04-06 15:43:12,470] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:43:12,471] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:43:12,472] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run5
[2019-04-06 15:43:13,854] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:43:13,854] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:43:13,856] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run5
[2019-04-06 15:43:14,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:43:14,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:43:14,899] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run5
[2019-04-06 15:43:15,430] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:43:15,431] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:43:15,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run5
[2019-04-06 15:43:15,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:43:15,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:43:15,795] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run5
[2019-04-06 15:43:16,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:43:16,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:43:16,151] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run5
[2019-04-06 15:43:58,826] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.0096575e-05 2.9700389e-02 1.2272704e-04 3.9029408e-01 6.4342004e-07
 5.7977855e-01 9.3595110e-05], sum to 1.0000
[2019-04-06 15:43:58,826] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3840
[2019-04-06 15:43:59,131] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-8.1, 41.5, 0.0, 0.0, 26.0, 22.86491147645042, -0.1746725933990925, 1.0, 1.0, 150614.0754927632], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 459000.0000, 
sim time next is 460800.0000, 
raw observation next is [-7.8, 40.0, 11.5, 0.0, 26.0, 24.42873982725387, 0.0584942762081064, 1.0, 1.0, 120373.10552690814], 
processed observation next is [1.0, 0.34782608695652173, 0.24653739612188366, 0.4, 0.03833333333333333, 0.0, 0.6666666666666666, 0.5357283189378226, 0.5194980920693688, 1.0, 1.0, 0.5732052644138483], 
reward next is 0.4268, 
noisyNet noise sample is [array([1.0241978], dtype=float32), 0.47100213]. 
=============================================
[2019-04-06 15:43:59,277] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0680580e-07 5.6021074e-03 7.3932053e-05 1.0649895e-01 1.3013653e-07
 8.8780260e-01 2.1801066e-05], sum to 1.0000
[2019-04-06 15:43:59,277] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0739
[2019-04-06 15:43:59,291] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [13.8, 100.0, 64.0, 0.0, 26.0, 24.72517045532816, 0.4377534516716671, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1263600.0000, 
sim time next is 1265400.0000, 
raw observation next is [13.8, 100.0, 51.0, 0.0, 26.0, 24.67191006760398, 0.4278970705200904, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.844875346260388, 1.0, 0.17, 0.0, 0.6666666666666666, 0.5559925056336651, 0.6426323568400302, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.74994445], dtype=float32), 0.7127232]. 
=============================================
[2019-04-06 15:44:21,955] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.6888291e-07 2.1942959e-03 3.9873179e-05 4.0749922e-02 1.9409242e-07
 9.5695138e-01 6.3719104e-05], sum to 1.0000
[2019-04-06 15:44:21,955] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8098
[2019-04-06 15:44:22,043] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.7, 82.0, 0.0, 0.0, 26.0, 25.67747834386289, 0.6160826060184275, 0.0, 1.0, 18725.043737806092], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1150200.0000, 
sim time next is 1152000.0000, 
raw observation next is [12.7, 84.0, 16.0, 0.5, 26.0, 25.69345848361701, 0.6064991791841136, 0.0, 1.0, 7515.9376850470035], 
processed observation next is [0.0, 0.34782608695652173, 0.8144044321329641, 0.84, 0.05333333333333334, 0.0005524861878453039, 0.6666666666666666, 0.6411215403014175, 0.7021663930613712, 0.0, 1.0, 0.03579017945260478], 
reward next is 0.9642, 
noisyNet noise sample is [array([-0.6738189], dtype=float32), 0.5115863]. 
=============================================
[2019-04-06 15:44:22,089] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[73.37787 ]
 [73.08574 ]
 [72.80427 ]
 [72.52759 ]
 [72.137924]], R is [[74.00748444]
 [74.17824554]
 [74.34728241]
 [74.45275879]
 [74.56855774]].
[2019-04-06 15:44:32,051] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0300398e-08 2.4716722e-04 4.2795273e-07 1.9116995e-03 3.9262047e-09
 9.9783957e-01 1.0434086e-06], sum to 1.0000
[2019-04-06 15:44:32,051] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5833
[2019-04-06 15:44:32,345] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.55, 76.0, 29.0, 0.0, 26.0, 25.11607919834545, 0.2711372143676233, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 894600.0000, 
sim time next is 896400.0000, 
raw observation next is [1.1, 80.0, 38.5, 0.0, 26.0, 25.43878077809019, 0.2926537435043026, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49307479224376743, 0.8, 0.12833333333333333, 0.0, 0.6666666666666666, 0.6198983981741826, 0.5975512478347675, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7387644], dtype=float32), 0.5348092]. 
=============================================
[2019-04-06 15:44:51,107] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6588764e-08 3.4063373e-04 2.4112462e-06 8.4499270e-03 1.8221820e-09
 9.9120671e-01 2.9089441e-07], sum to 1.0000
[2019-04-06 15:44:51,108] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2911
[2019-04-06 15:44:51,504] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 86.0, 0.0, 0.0, 26.0, 25.04349926205397, 0.3205550003861851, 1.0, 1.0, 59344.16712280067], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 846000.0000, 
sim time next is 847800.0000, 
raw observation next is [-3.65, 84.5, 0.0, 0.0, 26.0, 25.04785602586008, 0.2682243767370442, 1.0, 1.0, 8229.87710034308], 
processed observation next is [1.0, 0.8260869565217391, 0.3614958448753463, 0.845, 0.0, 0.0, 0.6666666666666666, 0.5873213354883401, 0.5894081255790148, 1.0, 1.0, 0.039189890954014664], 
reward next is 0.9608, 
noisyNet noise sample is [array([-0.31323767], dtype=float32), 0.7149327]. 
=============================================
[2019-04-06 15:45:35,532] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8636922e-06 8.5135503e-03 1.2737430e-05 2.0714235e-02 1.9133257e-07
 9.7074372e-01 1.1648406e-05], sum to 1.0000
[2019-04-06 15:45:35,532] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1525
[2019-04-06 15:45:35,652] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 87.0, 0.0, 0.0, 26.0, 24.5860790341612, 0.2951045279708209, 0.0, 1.0, 44111.01267247976], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1755000.0000, 
sim time next is 1756800.0000, 
raw observation next is [-1.7, 87.0, 13.5, 0.0, 26.0, 24.59489850858942, 0.2832121277321994, 0.0, 1.0, 44144.613522965694], 
processed observation next is [0.0, 0.34782608695652173, 0.4155124653739613, 0.87, 0.045, 0.0, 0.6666666666666666, 0.549574875715785, 0.5944040425773998, 0.0, 1.0, 0.21021244534745567], 
reward next is 0.7898, 
noisyNet noise sample is [array([-0.25908068], dtype=float32), 3.163635]. 
=============================================
[2019-04-06 15:46:27,848] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-06 15:46:27,853] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:46:27,854] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:46:27,856] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run11
[2019-04-06 15:46:27,938] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:46:27,939] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:46:27,964] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run11
[2019-04-06 15:46:28,009] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:46:28,010] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:46:28,039] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run11
[2019-04-06 15:48:42,850] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.6746 79951928.4648 535.1630
[2019-04-06 15:49:01,196] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.3631 87764636.9936 514.7901
[2019-04-06 15:49:05,114] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.8087 91898289.6619 409.3341
[2019-04-06 15:49:06,136] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 200000, evaluation results [200000.0, 2416.363112931383, 87764636.99361183, 514.7900711698758, 2453.674609339221, 79951928.46481901, 535.1629652497085, 2396.808698067052, 91898289.66188976, 409.33411217924044]
[2019-04-06 15:49:26,299] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0494929e-06 2.9823661e-03 1.9760587e-06 1.8480383e-02 9.3346770e-09
 9.7851974e-01 1.4490096e-05], sum to 1.0000
[2019-04-06 15:49:26,299] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6540
[2019-04-06 15:49:26,464] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 217.0, 154.0, 26.0, 24.97840076598299, 0.3390474844670638, 0.0, 1.0, 18747.51182876671], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2977200.0000, 
sim time next is 2979000.0000, 
raw observation next is [-3.0, 65.0, 256.0, 284.0, 26.0, 24.96447392811545, 0.3548924365744697, 0.0, 1.0, 33797.875377647375], 
processed observation next is [0.0, 0.4782608695652174, 0.3795013850415513, 0.65, 0.8533333333333334, 0.3138121546961326, 0.6666666666666666, 0.5803728273429541, 0.6182974788581566, 0.0, 1.0, 0.16094226370308273], 
reward next is 0.8391, 
noisyNet noise sample is [array([0.5780737], dtype=float32), -2.639418]. 
=============================================
[2019-04-06 15:49:26,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[73.382454]
 [72.48821 ]
 [71.06025 ]
 [70.216515]
 [68.90602 ]], R is [[74.66065979]
 [74.82478333]
 [74.68634033]
 [74.83411407]
 [75.08577728]].
[2019-04-06 15:49:38,881] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1412016e-05 2.2376068e-02 1.2818821e-04 8.3774209e-02 3.3554593e-06
 8.9363331e-01 7.3537289e-05], sum to 1.0000
[2019-04-06 15:49:38,882] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6319
[2019-04-06 15:49:39,206] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 58.0, 21.5, 228.0, 26.0, 22.83183973254064, -0.2197042142669335, 0.0, 1.0, 44162.01522394849], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2448000.0000, 
sim time next is 2449800.0000, 
raw observation next is [-8.4, 54.0, 40.0, 416.0, 26.0, 23.307452643372, -0.005567154395533842, 0.0, 1.0, 149924.3154864598], 
processed observation next is [0.0, 0.34782608695652173, 0.2299168975069252, 0.54, 0.13333333333333333, 0.45966850828729283, 0.6666666666666666, 0.4422877202809999, 0.4981442818681554, 0.0, 1.0, 0.7139253118402847], 
reward next is 0.2861, 
noisyNet noise sample is [array([1.1764622], dtype=float32), 0.6325329]. 
=============================================
[2019-04-06 15:49:42,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.5233763e-08 1.4412765e-04 1.1458254e-05 1.4358899e-01 3.6842913e-08
 8.5625398e-01 1.4647009e-06], sum to 1.0000
[2019-04-06 15:49:42,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0758
[2019-04-06 15:49:42,190] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [1.0, 96.5, 0.0, 0.0, 26.0, 24.94780224616036, 0.2604435772381321, 0.0, 1.0, 55905.31990140843], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2871000.0000, 
sim time next is 2872800.0000, 
raw observation next is [1.0, 100.0, 0.0, 0.0, 26.0, 24.87847385569986, 0.2362690559644343, 0.0, 1.0, 55682.805040349136], 
processed observation next is [1.0, 0.2608695652173913, 0.4903047091412743, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5732061546416549, 0.5787563519881448, 0.0, 1.0, 0.26515621447785304], 
reward next is 0.7348, 
noisyNet noise sample is [array([0.86793965], dtype=float32), -0.06459133]. 
=============================================
[2019-04-06 15:49:45,742] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3474777e-08 7.2371756e-04 1.0169579e-06 2.3596505e-02 5.0163362e-10
 9.7567844e-01 4.0266656e-07], sum to 1.0000
[2019-04-06 15:49:45,742] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4539
[2019-04-06 15:49:45,926] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 100.0, 127.0, 0.0, 26.0, 25.44155878919508, 0.3422358337661091, 1.0, 1.0, 12453.607780153694], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2901600.0000, 
sim time next is 2903400.0000, 
raw observation next is [2.0, 100.0, 90.0, 0.0, 26.0, 24.24520672414499, 0.3103777028761467, 1.0, 1.0, 134239.47932746427], 
processed observation next is [1.0, 0.6086956521739131, 0.518005540166205, 1.0, 0.3, 0.0, 0.6666666666666666, 0.520433893678749, 0.603459234292049, 1.0, 1.0, 0.6392356158450679], 
reward next is 0.3608, 
noisyNet noise sample is [array([-0.72822237], dtype=float32), 0.81554854]. 
=============================================
[2019-04-06 15:49:46,383] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0614749e-05 3.0876980e-03 3.2179814e-04 8.0917157e-02 3.0298957e-06
 9.1556352e-01 8.6180655e-05], sum to 1.0000
[2019-04-06 15:49:46,395] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7359
[2019-04-06 15:49:46,434] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.9, 45.5, 0.0, 0.0, 26.0, 24.55085843104266, 0.1344305312626496, 0.0, 1.0, 43145.87368432306], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2421000.0000, 
sim time next is 2422800.0000, 
raw observation next is [-6.2, 48.0, 0.0, 0.0, 26.0, 24.40066704526821, 0.1007958527468742, 0.0, 1.0, 43255.27626405021], 
processed observation next is [0.0, 0.043478260869565216, 0.2908587257617729, 0.48, 0.0, 0.0, 0.6666666666666666, 0.5333889204390175, 0.5335986175822914, 0.0, 1.0, 0.20597750601928672], 
reward next is 0.7940, 
noisyNet noise sample is [array([0.20565394], dtype=float32), 0.15215592]. 
=============================================
[2019-04-06 15:49:51,043] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.2618898e-09 7.6294167e-04 4.1495059e-06 4.3962523e-03 9.6077324e-09
 9.9483263e-01 3.9813795e-06], sum to 1.0000
[2019-04-06 15:49:51,043] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4947
[2019-04-06 15:49:51,096] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 59.0, 0.0, 0.0, 26.0, 25.08136845025923, 0.3091726106034495, 0.0, 1.0, 45319.835884642285], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2588400.0000, 
sim time next is 2590200.0000, 
raw observation next is [-4.2, 60.5, 0.0, 0.0, 26.0, 24.9121962864968, 0.28259708005976, 0.0, 1.0, 41992.273700288344], 
processed observation next is [1.0, 1.0, 0.34626038781163443, 0.605, 0.0, 0.0, 0.6666666666666666, 0.5760163572080668, 0.5941990266865866, 0.0, 1.0, 0.19996320809661117], 
reward next is 0.8000, 
noisyNet noise sample is [array([-1.6297026], dtype=float32), -1.2896013]. 
=============================================
[2019-04-06 15:50:04,142] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.08505795e-07 2.16963599e-04 1.73200476e-06 1.72442924e-02
 7.46952633e-09 9.82536614e-01 2.79330720e-07], sum to 1.0000
[2019-04-06 15:50:04,142] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7396
[2019-04-06 15:50:04,457] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-14.0, 91.0, 88.5, 471.0, 26.0, 26.08008021801346, 0.4238451299646266, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2710800.0000, 
sim time next is 2712600.0000, 
raw observation next is [-13.0, 83.5, 97.0, 612.0, 26.0, 25.94190253985238, 0.4320239306989677, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.10249307479224376, 0.835, 0.3233333333333333, 0.6762430939226519, 0.6666666666666666, 0.6618252116543649, 0.6440079768996559, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8758902], dtype=float32), -0.61763567]. 
=============================================
[2019-04-06 15:50:06,763] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.8459650e-07 8.2909493e-03 2.5049441e-05 1.2386141e-01 9.5136897e-08
 8.6781538e-01 6.4458363e-06], sum to 1.0000
[2019-04-06 15:50:06,763] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5628
[2019-04-06 15:50:06,817] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 81.5, 0.0, 0.0, 26.0, 25.27637149490747, 0.4124649635220121, 0.0, 1.0, 44965.451823950454], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2932200.0000, 
sim time next is 2934000.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 26.0, 25.08304527564121, 0.3827045508319559, 0.0, 1.0, 43796.78864543826], 
processed observation next is [1.0, 1.0, 0.40720221606648205, 0.85, 0.0, 0.0, 0.6666666666666666, 0.590253772970101, 0.627568183610652, 0.0, 1.0, 0.20855613640684886], 
reward next is 0.7914, 
noisyNet noise sample is [array([1.0496949], dtype=float32), -1.1336352]. 
=============================================
[2019-04-06 15:50:06,825] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[82.859314]
 [83.48195 ]
 [84.25806 ]
 [85.72769 ]
 [85.97832 ]], R is [[82.49565125]
 [82.45657349]
 [82.39316559]
 [82.39324188]
 [82.32263184]].
[2019-04-06 15:50:15,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3061520e-08 1.9099614e-04 1.4012048e-06 9.8959684e-02 1.2578527e-08
 9.0084189e-01 5.9785393e-06], sum to 1.0000
[2019-04-06 15:50:15,347] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0322
[2019-04-06 15:50:15,390] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-1.0, 78.0, 0.0, 0.0, 26.0, 25.3735714543536, 0.4843088022830329, 0.0, 1.0, 50246.87319795549], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2930400.0000, 
sim time next is 2932200.0000, 
raw observation next is [-1.5, 81.5, 0.0, 0.0, 26.0, 25.27689706223298, 0.4128582348569454, 0.0, 1.0, 45033.163608682946], 
processed observation next is [1.0, 0.9565217391304348, 0.4210526315789474, 0.815, 0.0, 0.0, 0.6666666666666666, 0.606408088519415, 0.6376194116189818, 0.0, 1.0, 0.21444363623182355], 
reward next is 0.7856, 
noisyNet noise sample is [array([-0.48444822], dtype=float32), -1.4963282]. 
=============================================
[2019-04-06 15:50:15,608] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6255765e-06 1.3739467e-03 1.0227954e-05 6.5846690e-03 3.9876582e-08
 9.9202204e-01 7.5004850e-06], sum to 1.0000
[2019-04-06 15:50:15,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3371
[2019-04-06 15:50:15,666] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 26.0, 24.88047435427785, 0.3311729191229979, 0.0, 1.0, 43319.26986096395], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2941200.0000, 
sim time next is 2943000.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 26.0, 24.78911270492233, 0.3112337361544276, 0.0, 1.0, 43286.57324834806], 
processed observation next is [0.0, 0.043478260869565216, 0.40720221606648205, 0.85, 0.0, 0.0, 0.6666666666666666, 0.565759392076861, 0.6037445787181426, 0.0, 1.0, 0.2061265392778479], 
reward next is 0.7939, 
noisyNet noise sample is [array([-0.2782931], dtype=float32), -0.13329327]. 
=============================================
[2019-04-06 15:50:15,691] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[76.701195]
 [79.52909 ]
 [81.44846 ]
 [84.42849 ]
 [84.536674]], R is [[74.53305817]
 [74.58144379]
 [74.62918854]
 [74.67632294]
 [74.72231293]].
[2019-04-06 15:50:40,335] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6186047e-07 1.0449063e-03 6.3461562e-06 8.3769150e-02 2.2969033e-09
 9.1517884e-01 5.7515297e-07], sum to 1.0000
[2019-04-06 15:50:40,336] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0389
[2019-04-06 15:50:40,424] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-7.0, 64.0, 113.5, 769.0, 26.0, 26.3774386243289, 0.5952035666366523, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3322800.0000, 
sim time next is 3324600.0000, 
raw observation next is [-6.5, 59.0, 116.0, 798.0, 26.0, 26.36449393933419, 0.6019312321573994, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.28254847645429365, 0.59, 0.38666666666666666, 0.881767955801105, 0.6666666666666666, 0.6970411616111823, 0.7006437440524665, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9165788], dtype=float32), 0.15212661]. 
=============================================
[2019-04-06 15:50:45,556] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.2541041e-10 5.4772891e-04 4.9777125e-08 2.2774456e-01 2.2057720e-09
 7.7170742e-01 2.1526913e-07], sum to 1.0000
[2019-04-06 15:50:45,556] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9347
[2019-04-06 15:50:45,659] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 92.5, 111.0, 812.0, 26.0, 25.98038791380439, 0.7333958261672966, 1.0, 1.0, 87091.45929150218], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3245400.0000, 
sim time next is 3247200.0000, 
raw observation next is [-4.0, 100.0, 106.0, 790.5, 26.0, 26.69097520980048, 0.8016904718721111, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3518005540166205, 1.0, 0.35333333333333333, 0.8734806629834254, 0.6666666666666666, 0.7242479341500401, 0.7672301572907037, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.06717016], dtype=float32), 0.18725204]. 
=============================================
[2019-04-06 15:51:15,387] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0600094e-06 3.2452892e-03 2.1564696e-05 1.8341264e-02 1.7232805e-06
 9.7833645e-01 4.9553768e-05], sum to 1.0000
[2019-04-06 15:51:15,387] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2627
[2019-04-06 15:51:15,490] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 49.0, 0.0, 0.0, 26.0, 24.62598549911646, 0.209306375771408, 0.0, 1.0, 40052.35553698816], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4172400.0000, 
sim time next is 4174200.0000, 
raw observation next is [-5.0, 51.5, 0.0, 0.0, 26.0, 24.69393801624113, 0.2097508988071516, 0.0, 1.0, 40400.63263866949], 
processed observation next is [0.0, 0.30434782608695654, 0.32409972299168976, 0.515, 0.0, 0.0, 0.6666666666666666, 0.5578281680200942, 0.5699169662690505, 0.0, 1.0, 0.1923839649460452], 
reward next is 0.8076, 
noisyNet noise sample is [array([-1.0248907], dtype=float32), -0.006918067]. 
=============================================
[2019-04-06 15:51:50,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:51:50,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:51:50,340] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run6
[2019-04-06 15:51:59,908] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 15:51:59,913] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:51:59,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:51:59,915] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run12
[2019-04-06 15:51:59,938] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:51:59,969] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:51:59,971] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run12
[2019-04-06 15:51:59,945] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:52:00,070] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:52:00,073] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run12
[2019-04-06 15:53:18,731] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00213874], dtype=float32), 0.10503382]
[2019-04-06 15:53:18,732] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-4.2, 82.5, 0.0, 0.0, 26.0, 25.00170275479142, 0.3164936431256818, 0.0, 1.0, 48424.696119428285]
[2019-04-06 15:53:18,732] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:53:18,733] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [6.9527340e-07 2.2997991e-03 1.5816473e-05 5.1344477e-02 1.7712141e-07
 9.4632971e-01 9.3046074e-06], sampled 0.5362825221186984
[2019-04-06 15:54:06,040] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00213874], dtype=float32), 0.10503382]
[2019-04-06 15:54:06,040] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [16.9, 44.0, 0.0, 0.0, 26.0, 27.93097032468076, 1.146767586984432, 0.0, 0.0, 0.0]
[2019-04-06 15:54:06,040] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:54:06,041] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [2.7780115e-06 7.0233643e-03 3.9452734e-05 9.6442811e-02 1.0433213e-06
 8.9645439e-01 3.6157147e-05], sampled 0.2467521834992733
[2019-04-06 15:54:11,737] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7923 79858606.1840 536.0106
[2019-04-06 15:54:29,132] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.9162 87789421.7934 515.2882
[2019-04-06 15:54:32,603] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.1014 91920472.6058 407.6671
[2019-04-06 15:54:33,625] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 220000, evaluation results [220000.0, 2415.916161221269, 87789421.79336932, 515.2881890531158, 2454.7923188486734, 79858606.18400194, 536.0106148228666, 2397.1013521750115, 91920472.60576996, 407.66708825361377]
[2019-04-06 15:54:46,786] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2310233e-08 1.4348715e-04 5.7799789e-06 2.5506226e-02 2.5307234e-09
 9.7433883e-01 5.7355023e-06], sum to 1.0000
[2019-04-06 15:54:46,786] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2498
[2019-04-06 15:54:46,819] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.95, 61.5, 0.0, 0.0, 26.0, 26.13078833747404, 0.6391227605328367, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4401000.0000, 
sim time next is 4402800.0000, 
raw observation next is [8.5, 62.0, 0.0, 0.0, 26.0, 25.79377749197793, 0.5816984237289474, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.698060941828255, 0.62, 0.0, 0.0, 0.6666666666666666, 0.6494814576648276, 0.6938994745763157, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4018693], dtype=float32), -0.35363445]. 
=============================================
[2019-04-06 15:54:49,805] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:54:49,805] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:54:49,809] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run6
[2019-04-06 15:54:50,771] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:54:50,772] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:54:50,780] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run6
[2019-04-06 15:54:51,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:54:51,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:54:51,136] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run6
[2019-04-06 15:54:54,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:54:54,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:54:54,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run6
[2019-04-06 15:54:54,927] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6668840e-07 2.5007671e-03 1.2184958e-05 5.0091062e-02 2.1552180e-08
 9.4739449e-01 1.2007052e-06], sum to 1.0000
[2019-04-06 15:54:54,927] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4143
[2019-04-06 15:54:55,174] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.9, 72.0, 0.0, 0.0, 26.0, 25.52362641353152, 0.4339540227632665, 1.0, 1.0, 13476.652074078598], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4519800.0000, 
sim time next is 4521600.0000, 
raw observation next is [-0.8, 73.0, 55.5, 33.0, 26.0, 25.46194628813734, 0.4159744759580596, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4404432132963989, 0.73, 0.185, 0.036464088397790057, 0.6666666666666666, 0.6218288573447784, 0.6386581586526865, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.51073265], dtype=float32), -0.99932903]. 
=============================================
[2019-04-06 15:55:05,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:55:05,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:55:05,690] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run6
[2019-04-06 15:55:07,480] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.8929526e-07 2.1341310e-03 5.3174413e-06 1.6337432e-02 1.1485585e-07
 9.8151958e-01 3.1225125e-06], sum to 1.0000
[2019-04-06 15:55:07,481] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8127
[2019-04-06 15:55:07,597] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 47.0, 282.0, 349.0, 26.0, 25.05533979050573, 0.3511034060152212, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4881600.0000, 
sim time next is 4883400.0000, 
raw observation next is [1.2, 46.0, 281.0, 390.0, 26.0, 25.11237278324765, 0.3599913338222122, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.4958448753462604, 0.46, 0.9366666666666666, 0.430939226519337, 0.6666666666666666, 0.5926977319373042, 0.6199971112740708, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2265714], dtype=float32), 0.9992335]. 
=============================================
[2019-04-06 15:55:09,737] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:55:09,737] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:55:09,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run6
[2019-04-06 15:55:13,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:55:13,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:55:13,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run6
[2019-04-06 15:55:14,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:55:14,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:55:14,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run6
[2019-04-06 15:55:17,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:55:17,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:55:17,384] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run6
[2019-04-06 15:55:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:55:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:55:19,428] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run6
[2019-04-06 15:55:19,769] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:55:19,769] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:55:19,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run6
[2019-04-06 15:55:21,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:55:21,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:55:21,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run6
[2019-04-06 15:55:21,634] A3C_AGENT_WORKER-Thread-11 INFO:Local step 14500, global step 227573: loss 5.2138
[2019-04-06 15:55:21,635] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 14500, global step 227573: learning rate 0.0000
[2019-04-06 15:55:22,178] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:55:22,178] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:55:22,183] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run6
[2019-04-06 15:55:22,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:55:22,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:55:22,764] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run6
[2019-04-06 15:55:23,787] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.7589757e-06 4.0740129e-03 9.9679091e-06 4.7674824e-02 5.2586961e-07
 9.4822884e-01 1.0064923e-05], sum to 1.0000
[2019-04-06 15:55:23,787] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6773
[2019-04-06 15:55:23,855] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:55:23,855] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:55:23,859] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run6
[2019-04-06 15:55:24,050] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 93.0, 21.0, 0.0, 26.0, 21.86021157526779, -0.3630627024095884, 0.0, 1.0, 91031.79052649335], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 30600.0000, 
sim time next is 32400.0000, 
raw observation next is [7.7, 93.0, 29.5, 0.0, 26.0, 22.70467281687016, -0.2297165032386036, 0.0, 1.0, 66405.74778985199], 
processed observation next is [0.0, 0.391304347826087, 0.6759002770083103, 0.93, 0.09833333333333333, 0.0, 0.6666666666666666, 0.3920560680725134, 0.4234278322537988, 0.0, 1.0, 0.3162178466183428], 
reward next is 0.6838, 
noisyNet noise sample is [array([2.593402], dtype=float32), -0.810066]. 
=============================================
[2019-04-06 15:55:38,906] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.9091997e-06 1.1469630e-02 2.0482110e-04 2.0421657e-01 4.0977243e-06
 7.8400242e-01 9.4488860e-05], sum to 1.0000
[2019-04-06 15:55:38,907] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6008
[2019-04-06 15:55:39,091] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 40.0, 11.5, 0.0, 26.0, 24.44067290145825, 0.06095602382963166, 1.0, 1.0, 120336.84590128697], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 460800.0000, 
sim time next is 462600.0000, 
raw observation next is [-7.0, 36.5, 23.0, 0.0, 26.0, 25.15193571918552, 0.1707052975094747, 1.0, 1.0, 21453.684946290676], 
processed observation next is [1.0, 0.34782608695652173, 0.2686980609418283, 0.365, 0.07666666666666666, 0.0, 0.6666666666666666, 0.59599464326546, 0.5569017658364915, 1.0, 1.0, 0.10216040450614608], 
reward next is 0.8978, 
noisyNet noise sample is [array([-1.8215405], dtype=float32), -1.1402371]. 
=============================================
[2019-04-06 15:55:43,593] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9281263e-08 1.1124507e-03 3.7267671e-07 3.3795085e-02 5.4178031e-09
 9.6509147e-01 6.2083978e-07], sum to 1.0000
[2019-04-06 15:55:43,593] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2599
[2019-04-06 15:55:43,663] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 71.0, 0.0, 0.0, 26.0, 24.29287266623632, 0.1440526799793897, 0.0, 1.0, 45589.364607958734], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 165600.0000, 
sim time next is 167400.0000, 
raw observation next is [-8.4, 71.0, 0.0, 0.0, 26.0, 24.21224405446669, 0.1207716649491928, 0.0, 1.0, 45085.87092743214], 
processed observation next is [1.0, 0.9565217391304348, 0.2299168975069252, 0.71, 0.0, 0.0, 0.6666666666666666, 0.5176870045388909, 0.5402572216497309, 0.0, 1.0, 0.21469462346396256], 
reward next is 0.7853, 
noisyNet noise sample is [array([1.6617196], dtype=float32), -1.1340759]. 
=============================================
[2019-04-06 15:55:53,575] A3C_AGENT_WORKER-Thread-17 INFO:Local step 14500, global step 230130: loss 5.8756
[2019-04-06 15:55:53,576] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 14500, global step 230130: learning rate 0.0000
[2019-04-06 15:55:55,647] A3C_AGENT_WORKER-Thread-5 INFO:Local step 14500, global step 230299: loss 5.4099
[2019-04-06 15:55:55,647] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 14500, global step 230299: learning rate 0.0000
[2019-04-06 15:55:56,879] A3C_AGENT_WORKER-Thread-13 INFO:Local step 14500, global step 230407: loss 5.2834
[2019-04-06 15:55:56,880] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 14500, global step 230407: learning rate 0.0000
[2019-04-06 15:56:03,880] A3C_AGENT_WORKER-Thread-3 INFO:Local step 14500, global step 230916: loss 3.2906
[2019-04-06 15:56:03,880] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 14500, global step 230916: learning rate 0.0000
[2019-04-06 15:56:16,874] A3C_AGENT_WORKER-Thread-11 INFO:Local step 15000, global step 231871: loss 29.3711
[2019-04-06 15:56:16,874] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 15000, global step 231871: learning rate 0.0000
[2019-04-06 15:56:20,476] A3C_AGENT_WORKER-Thread-16 INFO:Local step 14500, global step 232075: loss 4.8986
[2019-04-06 15:56:20,476] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 14500, global step 232075: learning rate 0.0000
[2019-04-06 15:56:26,077] A3C_AGENT_WORKER-Thread-12 INFO:Local step 14500, global step 232467: loss 0.1760
[2019-04-06 15:56:26,077] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 14500, global step 232467: learning rate 0.0000
[2019-04-06 15:56:31,505] A3C_AGENT_WORKER-Thread-18 INFO:Local step 14500, global step 232833: loss 0.1665
[2019-04-06 15:56:31,506] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 14500, global step 232833: learning rate 0.0000
[2019-04-06 15:56:34,984] A3C_AGENT_WORKER-Thread-6 INFO:Local step 14500, global step 233049: loss 3.4620
[2019-04-06 15:56:34,984] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 14500, global step 233049: learning rate 0.0000
[2019-04-06 15:56:37,494] A3C_AGENT_WORKER-Thread-4 INFO:Local step 14500, global step 233293: loss 2.7407
[2019-04-06 15:56:37,495] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 14500, global step 233293: learning rate 0.0000
[2019-04-06 15:56:45,807] A3C_AGENT_WORKER-Thread-15 INFO:Local step 14500, global step 234057: loss -0.7342
[2019-04-06 15:56:45,808] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 14500, global step 234057: learning rate 0.0000
[2019-04-06 15:56:46,674] A3C_AGENT_WORKER-Thread-10 INFO:Local step 14500, global step 234148: loss -0.9249
[2019-04-06 15:56:46,675] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 14500, global step 234148: learning rate 0.0000
[2019-04-06 15:56:46,868] A3C_AGENT_WORKER-Thread-19 INFO:Local step 14500, global step 234168: loss 3.7444
[2019-04-06 15:56:46,873] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 14500, global step 234168: learning rate 0.0000
[2019-04-06 15:56:47,845] A3C_AGENT_WORKER-Thread-2 INFO:Local step 14500, global step 234286: loss 4.8484
[2019-04-06 15:56:47,846] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 14500, global step 234286: learning rate 0.0000
[2019-04-06 15:56:50,387] A3C_AGENT_WORKER-Thread-20 INFO:Local step 14500, global step 234511: loss -0.1213
[2019-04-06 15:56:50,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 14500, global step 234511: learning rate 0.0000
[2019-04-06 15:56:50,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9666075e-07 2.3178207e-03 1.3142910e-05 7.8673884e-03 7.9543611e-08
 9.8978502e-01 1.5878933e-05], sum to 1.0000
[2019-04-06 15:56:50,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5317
[2019-04-06 15:56:50,738] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.05, 63.0, 89.0, 38.0, 26.0, 24.84900592234366, 0.2076093521417634, 0.0, 1.0, 48654.58358766225], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 646200.0000, 
sim time next is 648000.0000, 
raw observation next is [-2.7, 61.0, 100.5, 69.0, 26.0, 24.87410637072929, 0.2233090754189258, 0.0, 1.0, 42239.70622581582], 
processed observation next is [0.0, 0.5217391304347826, 0.38781163434903054, 0.61, 0.335, 0.07624309392265194, 0.6666666666666666, 0.5728421975607741, 0.5744363584729753, 0.0, 1.0, 0.20114145821817056], 
reward next is 0.7989, 
noisyNet noise sample is [array([-0.29685435], dtype=float32), -0.64481413]. 
=============================================
[2019-04-06 15:56:50,748] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.05246]
 [67.68348]
 [67.35344]
 [65.94572]
 [65.22381]], R is [[67.79236603]
 [67.88275146]
 [68.05170441]
 [67.9553299 ]
 [68.27577972]].
[2019-04-06 15:56:52,726] A3C_AGENT_WORKER-Thread-14 INFO:Local step 14500, global step 234730: loss 5.1762
[2019-04-06 15:56:52,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 14500, global step 234730: learning rate 0.0000
[2019-04-06 15:57:09,961] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15000, global step 236183: loss 28.0982
[2019-04-06 15:57:09,962] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 15000, global step 236183: learning rate 0.0000
[2019-04-06 15:57:12,996] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15000, global step 236445: loss 29.4348
[2019-04-06 15:57:12,997] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 15000, global step 236445: learning rate 0.0000
[2019-04-06 15:57:13,935] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15000, global step 236489: loss 28.1787
[2019-04-06 15:57:13,936] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 15000, global step 236489: learning rate 0.0000
[2019-04-06 15:57:20,239] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15000, global step 237050: loss 54.8591
[2019-04-06 15:57:20,269] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 15000, global step 237050: learning rate 0.0000
[2019-04-06 15:57:42,888] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15000, global step 239301: loss 27.8918
[2019-04-06 15:57:42,889] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 15000, global step 239301: learning rate 0.0000
[2019-04-06 15:57:50,457] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 15:57:50,465] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:57:50,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:57:50,486] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run13
[2019-04-06 15:57:50,610] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:57:50,611] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:57:50,622] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run13
[2019-04-06 15:57:50,704] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:57:50,704] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:57:50,718] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run13
[2019-04-06 15:59:02,859] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.00210302], dtype=float32), 0.10650495]
[2019-04-06 15:59:02,859] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.1, 92.0, 106.0, 0.0, 26.0, 25.71212612429986, 0.5298191685862697, 1.0, 1.0, 37772.21406978421]
[2019-04-06 15:59:02,859] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:59:02,859] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [3.6950624e-08 5.3838576e-04 5.9760708e-07 2.2755465e-02 6.7026158e-09
 9.7670501e-01 4.6792874e-07], sampled 0.7874043454890896
[2019-04-06 16:00:03,471] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 16:00:24,700] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.4230 87807247.9128 516.3399
[2019-04-06 16:00:26,505] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.7434 91892637.3272 409.2762
[2019-04-06 16:00:27,526] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 240000, evaluation results [240000.0, 2416.423017317144, 87807247.91279733, 516.3398882961512, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.743350972985, 91892637.32716763, 409.27623668503827]
[2019-04-06 16:00:29,144] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15000, global step 240314: loss 27.5690
[2019-04-06 16:00:29,153] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 15000, global step 240314: learning rate 0.0000
[2019-04-06 16:00:32,620] A3C_AGENT_WORKER-Thread-18 INFO:Local step 15000, global step 240882: loss 27.5512
[2019-04-06 16:00:32,620] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 15000, global step 240882: learning rate 0.0000
[2019-04-06 16:00:34,298] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15000, global step 241180: loss 27.0797
[2019-04-06 16:00:34,299] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 15000, global step 241180: learning rate 0.0000
[2019-04-06 16:00:35,283] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15000, global step 241306: loss 28.2903
[2019-04-06 16:00:35,286] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 15000, global step 241306: learning rate 0.0000
[2019-04-06 16:00:35,882] A3C_AGENT_WORKER-Thread-11 INFO:Local step 15500, global step 241389: loss 0.1567
[2019-04-06 16:00:35,883] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 15500, global step 241389: learning rate 0.0000
[2019-04-06 16:00:41,160] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15000, global step 242156: loss 27.5106
[2019-04-06 16:00:41,161] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 15000, global step 242156: learning rate 0.0000
[2019-04-06 16:00:41,613] A3C_AGENT_WORKER-Thread-19 INFO:Local step 15000, global step 242218: loss 27.3776
[2019-04-06 16:00:41,614] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 15000, global step 242218: learning rate 0.0000
[2019-04-06 16:00:42,806] A3C_AGENT_WORKER-Thread-10 INFO:Local step 15000, global step 242383: loss 27.8015
[2019-04-06 16:00:42,807] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 15000, global step 242383: learning rate 0.0000
[2019-04-06 16:00:43,765] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15000, global step 242522: loss 26.9192
[2019-04-06 16:00:43,766] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 15000, global step 242522: learning rate 0.0000
[2019-04-06 16:00:45,544] A3C_AGENT_WORKER-Thread-20 INFO:Local step 15000, global step 242797: loss 28.3094
[2019-04-06 16:00:45,589] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 15000, global step 242797: learning rate 0.0000
[2019-04-06 16:00:46,093] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15000, global step 242878: loss 27.7473
[2019-04-06 16:00:46,093] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 15000, global step 242878: learning rate 0.0000
[2019-04-06 16:01:08,342] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15500, global step 245622: loss 0.1327
[2019-04-06 16:01:08,344] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 15500, global step 245622: learning rate 0.0000
[2019-04-06 16:01:10,277] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15500, global step 245827: loss 0.6133
[2019-04-06 16:01:10,277] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 15500, global step 245827: learning rate 0.0000
[2019-04-06 16:01:11,412] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15500, global step 245953: loss 0.8603
[2019-04-06 16:01:11,413] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 15500, global step 245953: learning rate 0.0000
[2019-04-06 16:01:12,935] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15500, global step 246146: loss 0.3529
[2019-04-06 16:01:12,936] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 15500, global step 246146: learning rate 0.0000
[2019-04-06 16:01:27,108] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15500, global step 247876: loss 1.5601
[2019-04-06 16:01:27,108] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 15500, global step 247876: learning rate 0.0000
[2019-04-06 16:01:30,398] A3C_AGENT_WORKER-Thread-11 INFO:Local step 16000, global step 248278: loss 9.4644
[2019-04-06 16:01:30,398] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 16000, global step 248278: learning rate 0.0000
[2019-04-06 16:01:31,835] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15500, global step 248406: loss 0.5704
[2019-04-06 16:01:31,836] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 15500, global step 248406: learning rate 0.0000
[2019-04-06 16:01:39,821] A3C_AGENT_WORKER-Thread-18 INFO:Local step 15500, global step 249041: loss 0.2451
[2019-04-06 16:01:39,821] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 15500, global step 249041: learning rate 0.0000
[2019-04-06 16:01:41,629] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15500, global step 249195: loss 0.1925
[2019-04-06 16:01:41,630] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 15500, global step 249195: learning rate 0.0000
[2019-04-06 16:01:49,029] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15500, global step 249806: loss 1.1516
[2019-04-06 16:01:49,030] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 15500, global step 249806: learning rate 0.0000
[2019-04-06 16:01:54,825] A3C_AGENT_WORKER-Thread-10 INFO:Local step 15500, global step 250316: loss 0.3156
[2019-04-06 16:01:54,825] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 15500, global step 250316: learning rate 0.0000
[2019-04-06 16:01:54,871] A3C_AGENT_WORKER-Thread-19 INFO:Local step 15500, global step 250318: loss -0.9337
[2019-04-06 16:01:54,871] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 15500, global step 250318: learning rate 0.0000
[2019-04-06 16:01:54,907] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15500, global step 250326: loss 0.4434
[2019-04-06 16:01:54,907] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 15500, global step 250326: learning rate 0.0000
[2019-04-06 16:01:55,276] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4131225e-07 9.1445836e-05 1.6368737e-06 5.4758852e-03 3.4348762e-08
 9.9442989e-01 8.3725246e-07], sum to 1.0000
[2019-04-06 16:01:55,276] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7676
[2019-04-06 16:01:55,357] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.2, 27.0, 0.0, 0.0, 26.0, 25.47871024647758, 0.3601882259906886, 0.0, 1.0, 37729.33291241803], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3639600.0000, 
sim time next is 3641400.0000, 
raw observation next is [8.1, 28.0, 0.0, 0.0, 26.0, 25.62562514922067, 0.3759987328806789, 0.0, 1.0, 12363.704530303517], 
processed observation next is [0.0, 0.13043478260869565, 0.6869806094182825, 0.28, 0.0, 0.0, 0.6666666666666666, 0.6354687624350559, 0.6253329109602263, 0.0, 1.0, 0.0588747834776358], 
reward next is 0.9411, 
noisyNet noise sample is [array([-0.2656343], dtype=float32), 0.6212174]. 
=============================================
[2019-04-06 16:01:58,964] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15500, global step 250743: loss 0.4927
[2019-04-06 16:01:58,964] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 15500, global step 250743: learning rate 0.0000
[2019-04-06 16:02:00,251] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0207013e-05 1.2882715e-02 3.5104647e-04 1.4148098e-01 4.9403093e-06
 8.4519148e-01 6.8591726e-05], sum to 1.0000
[2019-04-06 16:02:00,251] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9775
[2019-04-06 16:02:00,313] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 61.0, 0.0, 0.0, 26.0, 23.46360232964497, -0.09440490365322433, 0.0, 1.0, 44399.02375512818], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2435400.0000, 
sim time next is 2437200.0000, 
raw observation next is [-8.4, 61.0, 0.0, 0.0, 26.0, 23.35569456204613, -0.1147849762043692, 0.0, 1.0, 44404.215894863264], 
processed observation next is [0.0, 0.21739130434782608, 0.2299168975069252, 0.61, 0.0, 0.0, 0.6666666666666666, 0.4463078801705107, 0.4617383412652103, 0.0, 1.0, 0.2114486471183965], 
reward next is 0.7886, 
noisyNet noise sample is [array([-2.1092768], dtype=float32), -0.17085554]. 
=============================================
[2019-04-06 16:02:00,803] A3C_AGENT_WORKER-Thread-20 INFO:Local step 15500, global step 250899: loss 1.2490
[2019-04-06 16:02:00,807] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 15500, global step 250899: learning rate 0.0000
[2019-04-06 16:02:04,734] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15500, global step 251262: loss 0.1556
[2019-04-06 16:02:04,735] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 15500, global step 251262: learning rate 0.0000
[2019-04-06 16:02:14,193] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.1569362e-07 1.4734920e-03 2.5159050e-05 5.4359909e-02 1.0815861e-07
 9.4413823e-01 2.2287206e-06], sum to 1.0000
[2019-04-06 16:02:14,194] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4719
[2019-04-06 16:02:14,349] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 69.0, 0.0, 0.0, 26.0, 24.98025940792077, 0.321085953844231, 0.0, 1.0, 45501.98041369403], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2674800.0000, 
sim time next is 2676600.0000, 
raw observation next is [-6.0, 70.5, 0.0, 0.0, 26.0, 24.80783612949547, 0.2936923932810925, 0.0, 1.0, 44458.061518834635], 
processed observation next is [1.0, 1.0, 0.296398891966759, 0.705, 0.0, 0.0, 0.6666666666666666, 0.5673196774579559, 0.5978974644270308, 0.0, 1.0, 0.2117050548515935], 
reward next is 0.7883, 
noisyNet noise sample is [array([-0.3998864], dtype=float32), 0.41734824]. 
=============================================
[2019-04-06 16:02:21,876] A3C_AGENT_WORKER-Thread-17 INFO:Local step 16000, global step 252808: loss 9.0499
[2019-04-06 16:02:21,878] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 16000, global step 252808: learning rate 0.0000
[2019-04-06 16:02:24,236] A3C_AGENT_WORKER-Thread-5 INFO:Local step 16000, global step 252996: loss 16.8602
[2019-04-06 16:02:24,237] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 16000, global step 252996: learning rate 0.0000
[2019-04-06 16:02:26,613] A3C_AGENT_WORKER-Thread-13 INFO:Local step 16000, global step 253193: loss 8.5888
[2019-04-06 16:02:26,614] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 16000, global step 253193: learning rate 0.0000
[2019-04-06 16:02:28,325] A3C_AGENT_WORKER-Thread-3 INFO:Local step 16000, global step 253339: loss 8.3453
[2019-04-06 16:02:28,338] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 16000, global step 253339: learning rate 0.0000
[2019-04-06 16:02:40,214] A3C_AGENT_WORKER-Thread-11 INFO:Local step 16500, global step 254350: loss -2.4523
[2019-04-06 16:02:40,214] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 16500, global step 254350: learning rate 0.0000
[2019-04-06 16:02:52,284] A3C_AGENT_WORKER-Thread-16 INFO:Local step 16000, global step 255526: loss 17.0499
[2019-04-06 16:02:52,284] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 16000, global step 255526: learning rate 0.0000
[2019-04-06 16:02:56,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6742074e-07 2.3323325e-03 3.6059762e-06 1.8590771e-02 1.3180946e-07
 9.7907054e-01 2.1789845e-06], sum to 1.0000
[2019-04-06 16:02:56,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8484
[2019-04-06 16:02:56,882] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 26.0, 24.66827618968199, 0.2747443324819389, 0.0, 1.0, 42830.64964730615], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2948400.0000, 
sim time next is 2950200.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 26.0, 24.5773541328747, 0.2571752578337035, 0.0, 1.0, 42670.77872213738], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.84, 0.0, 0.0, 0.6666666666666666, 0.548112844406225, 0.5857250859445678, 0.0, 1.0, 0.20319418439113038], 
reward next is 0.7968, 
noisyNet noise sample is [array([-1.8716606], dtype=float32), -2.4043195]. 
=============================================
[2019-04-06 16:02:59,651] A3C_AGENT_WORKER-Thread-12 INFO:Local step 16000, global step 256281: loss 9.0414
[2019-04-06 16:02:59,681] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 16000, global step 256281: learning rate 0.0000
[2019-04-06 16:03:10,045] A3C_AGENT_WORKER-Thread-18 INFO:Local step 16000, global step 257301: loss 13.3839
[2019-04-06 16:03:10,046] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 16000, global step 257301: learning rate 0.0000
[2019-04-06 16:03:10,713] A3C_AGENT_WORKER-Thread-6 INFO:Local step 16000, global step 257363: loss 9.2450
[2019-04-06 16:03:10,713] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 16000, global step 257363: learning rate 0.0000
[2019-04-06 16:03:18,807] A3C_AGENT_WORKER-Thread-4 INFO:Local step 16000, global step 258167: loss 8.5050
[2019-04-06 16:03:18,807] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 16000, global step 258167: learning rate 0.0000
[2019-04-06 16:03:26,152] A3C_AGENT_WORKER-Thread-10 INFO:Local step 16000, global step 258902: loss 8.3247
[2019-04-06 16:03:26,152] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 16000, global step 258902: learning rate 0.0000
[2019-04-06 16:03:27,923] A3C_AGENT_WORKER-Thread-15 INFO:Local step 16000, global step 259088: loss 16.7883
[2019-04-06 16:03:27,993] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 16000, global step 259088: learning rate 0.0000
[2019-04-06 16:03:28,469] A3C_AGENT_WORKER-Thread-19 INFO:Local step 16000, global step 259142: loss 8.5920
[2019-04-06 16:03:28,478] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 16000, global step 259143: learning rate 0.0000
[2019-04-06 16:03:33,489] A3C_AGENT_WORKER-Thread-2 INFO:Local step 16000, global step 259656: loss 8.4788
[2019-04-06 16:03:33,489] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 16000, global step 259656: learning rate 0.0000
[2019-04-06 16:03:35,011] A3C_AGENT_WORKER-Thread-20 INFO:Local step 16000, global step 259802: loss 15.2696
[2019-04-06 16:03:35,028] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 16000, global step 259804: learning rate 0.0000
[2019-04-06 16:03:36,286] A3C_AGENT_WORKER-Thread-17 INFO:Local step 16500, global step 259923: loss 5.6144
[2019-04-06 16:03:36,287] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 16500, global step 259923: learning rate 0.0000
[2019-04-06 16:03:37,048] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-06 16:03:37,049] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:03:37,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:03:37,051] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run14
[2019-04-06 16:03:37,077] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:03:37,077] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:03:37,080] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run14
[2019-04-06 16:03:37,114] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:03:37,124] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:03:37,126] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run14
[2019-04-06 16:04:43,668] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.00680393], dtype=float32), 0.10665634]
[2019-04-06 16:04:43,668] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [3.8, 93.0, 96.0, 0.0, 26.0, 25.06159378071878, 0.1595961227258618, 1.0, 1.0, 32719.34075762116]
[2019-04-06 16:04:43,668] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:04:43,669] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [5.20641095e-08 4.82643518e-04 4.84505904e-07 1.99777838e-02
 1.16963355e-08 9.79538620e-01 4.45047533e-07], sampled 0.30571487403338615
[2019-04-06 16:05:50,736] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.1051 79959984.5800 535.1579
[2019-04-06 16:06:10,578] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.9975 87830352.8773 516.5543
[2019-04-06 16:06:11,380] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.4832 91904148.5226 409.3187
[2019-04-06 16:06:12,402] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 260000, evaluation results [260000.0, 2415.997469398107, 87830352.877312, 516.5542744756061, 2454.105139513481, 79959984.58002774, 535.1579115189242, 2396.4831670634676, 91904148.5226061, 409.31866208201393]
[2019-04-06 16:06:13,275] A3C_AGENT_WORKER-Thread-14 INFO:Local step 16000, global step 260198: loss 8.8180
[2019-04-06 16:06:13,282] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 16000, global step 260198: learning rate 0.0000
[2019-04-06 16:06:13,345] A3C_AGENT_WORKER-Thread-5 INFO:Local step 16500, global step 260213: loss 6.7562
[2019-04-06 16:06:13,345] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 16500, global step 260213: learning rate 0.0000
[2019-04-06 16:06:15,329] A3C_AGENT_WORKER-Thread-13 INFO:Local step 16500, global step 260597: loss 5.8232
[2019-04-06 16:06:15,330] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 16500, global step 260597: learning rate 0.0000
[2019-04-06 16:06:16,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2133669e-09 1.7012596e-03 2.3133346e-06 2.0219518e-01 1.0611856e-09
 7.9610127e-01 1.8254626e-08], sum to 1.0000
[2019-04-06 16:06:16,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5916
[2019-04-06 16:06:16,446] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.0, 20.0, 114.5, 839.5, 26.0, 27.82042494621329, 0.9872356462467797, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5061600.0000, 
sim time next is 5063400.0000, 
raw observation next is [11.5, 19.5, 111.0, 819.0, 26.0, 28.43074026150424, 0.9517132102830561, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.7811634349030472, 0.195, 0.37, 0.9049723756906077, 0.6666666666666666, 0.8692283551253533, 0.8172377367610187, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.03023189], dtype=float32), -0.45017195]. 
=============================================
[2019-04-06 16:06:16,571] A3C_AGENT_WORKER-Thread-3 INFO:Local step 16500, global step 260814: loss 6.0479
[2019-04-06 16:06:16,573] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 16500, global step 260814: learning rate 0.0000
[2019-04-06 16:06:18,548] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:06:18,548] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:06:18,584] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run7
[2019-04-06 16:06:21,455] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2563958e-08 3.4688201e-05 1.3336098e-07 2.8799387e-02 5.3944510e-10
 9.7116584e-01 2.1162581e-08], sum to 1.0000
[2019-04-06 16:06:21,455] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2472
[2019-04-06 16:06:21,559] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 60.0, 105.5, 727.5, 26.0, 26.42965275622866, 0.5906564346787707, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3837600.0000, 
sim time next is 3839400.0000, 
raw observation next is [-1.5, 60.0, 110.0, 775.0, 26.0, 26.54756764361896, 0.6210183324523845, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4210526315789474, 0.6, 0.36666666666666664, 0.856353591160221, 0.6666666666666666, 0.7122973036349135, 0.7070061108174616, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8592528], dtype=float32), -0.7749718]. 
=============================================
[2019-04-06 16:06:30,207] A3C_AGENT_WORKER-Thread-16 INFO:Local step 16500, global step 263345: loss 6.6584
[2019-04-06 16:06:30,213] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 16500, global step 263345: learning rate 0.0000
[2019-04-06 16:06:35,866] A3C_AGENT_WORKER-Thread-12 INFO:Local step 16500, global step 264386: loss 5.9855
[2019-04-06 16:06:35,896] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 16500, global step 264386: learning rate 0.0000
[2019-04-06 16:06:37,126] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2399390e-10 7.3094925e-05 6.6552062e-08 1.5271880e-02 3.4230747e-09
 9.8465478e-01 1.0153690e-07], sum to 1.0000
[2019-04-06 16:06:37,126] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8956
[2019-04-06 16:06:37,148] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 46.5, 87.0, 717.0, 26.0, 26.39763121011023, 0.7012187360222173, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3857400.0000, 
sim time next is 3859200.0000, 
raw observation next is [3.0, 45.0, 75.5, 634.0, 26.0, 26.88092078567565, 0.7511743345537164, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.45, 0.25166666666666665, 0.7005524861878453, 0.6666666666666666, 0.7400767321396374, 0.7503914448512389, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5125777], dtype=float32), -0.58207595]. 
=============================================
[2019-04-06 16:06:39,816] A3C_AGENT_WORKER-Thread-18 INFO:Local step 16500, global step 265118: loss 7.6301
[2019-04-06 16:06:39,821] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 16500, global step 265119: learning rate 0.0000
[2019-04-06 16:06:40,212] A3C_AGENT_WORKER-Thread-6 INFO:Local step 16500, global step 265193: loss 6.3043
[2019-04-06 16:06:40,213] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 16500, global step 265193: learning rate 0.0000
[2019-04-06 16:06:45,704] A3C_AGENT_WORKER-Thread-4 INFO:Local step 16500, global step 266169: loss 5.5179
[2019-04-06 16:06:45,704] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 16500, global step 266169: learning rate 0.0000
[2019-04-06 16:06:48,945] A3C_AGENT_WORKER-Thread-10 INFO:Local step 16500, global step 266853: loss 0.2813
[2019-04-06 16:06:48,957] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 16500, global step 266853: learning rate 0.0000
[2019-04-06 16:06:50,621] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2290668e-06 1.1863937e-03 3.0918882e-06 7.7565014e-02 6.1559797e-07
 9.2123514e-01 6.4948308e-06], sum to 1.0000
[2019-04-06 16:06:50,621] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7788
[2019-04-06 16:06:50,656] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 40.0, 200.5, 379.0, 25.0, 25.12434065635774, 0.3912397827016876, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4197600.0000, 
sim time next is 4199400.0000, 
raw observation next is [2.0, 42.0, 187.0, 89.0, 26.0, 25.07301872456883, 0.3501596631145098, 0.0, 1.0, 20667.2266973518], 
processed observation next is [0.0, 0.6086956521739131, 0.518005540166205, 0.42, 0.6233333333333333, 0.09834254143646409, 0.6666666666666666, 0.5894182270474024, 0.6167198877048367, 0.0, 1.0, 0.09841536522548477], 
reward next is 0.9016, 
noisyNet noise sample is [array([1.0093023], dtype=float32), 2.273786]. 
=============================================
[2019-04-06 16:06:50,773] A3C_AGENT_WORKER-Thread-19 INFO:Local step 16500, global step 267200: loss 3.8307
[2019-04-06 16:06:50,773] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 16500, global step 267200: learning rate 0.0000
[2019-04-06 16:06:51,050] A3C_AGENT_WORKER-Thread-15 INFO:Local step 16500, global step 267250: loss 3.6292
[2019-04-06 16:06:51,050] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 16500, global step 267250: learning rate 0.0000
[2019-04-06 16:06:52,080] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:06:52,080] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:06:52,084] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run7
[2019-04-06 16:06:52,781] A3C_AGENT_WORKER-Thread-20 INFO:Local step 16500, global step 267606: loss 5.7525
[2019-04-06 16:06:52,782] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 16500, global step 267606: learning rate 0.0000
[2019-04-06 16:06:53,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:06:53,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:06:53,082] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run7
[2019-04-06 16:06:54,166] A3C_AGENT_WORKER-Thread-2 INFO:Local step 16500, global step 267860: loss 5.8325
[2019-04-06 16:06:54,168] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 16500, global step 267860: learning rate 0.0000
[2019-04-06 16:06:55,496] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:06:55,496] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:06:55,500] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run7
[2019-04-06 16:06:56,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:06:56,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:06:56,388] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run7
[2019-04-06 16:06:57,098] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7656613e-07 6.1288901e-04 6.0253655e-07 2.3230614e-02 3.8889976e-08
 9.7615451e-01 1.0280210e-06], sum to 1.0000
[2019-04-06 16:06:57,098] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6573
[2019-04-06 16:06:57,129] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 55.0, 162.5, 713.0, 26.0, 25.2650731328005, 0.3965171808260921, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4273200.0000, 
sim time next is 4275000.0000, 
raw observation next is [6.0, 53.5, 121.0, 822.0, 26.0, 25.21210474663869, 0.3935706122934932, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.6288088642659281, 0.535, 0.4033333333333333, 0.9082872928176795, 0.6666666666666666, 0.6010087288865575, 0.6311902040978311, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.52678436], dtype=float32), 0.10598183]. 
=============================================
[2019-04-06 16:06:57,132] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.62051 ]
 [71.540146]
 [69.82004 ]
 [68.24762 ]
 [67.08313 ]], R is [[73.87187958]
 [74.13316345]
 [74.39183044]
 [74.64791107]
 [74.90143585]].
[2019-04-06 16:06:57,322] A3C_AGENT_WORKER-Thread-14 INFO:Local step 16500, global step 268354: loss 6.7947
[2019-04-06 16:06:57,323] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 16500, global step 268354: learning rate 0.0000
[2019-04-06 16:07:01,900] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6376162e-09 3.9224506e-05 2.2443908e-08 3.4822349e-03 1.4968663e-09
 9.9647850e-01 3.2086746e-08], sum to 1.0000
[2019-04-06 16:07:01,900] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2970
[2019-04-06 16:07:01,966] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 122.0, 0.0, 26.0, 26.44503622701552, 0.6305601078817732, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4449600.0000, 
sim time next is 4451400.0000, 
raw observation next is [0.5, 89.0, 102.0, 0.0, 26.0, 26.32384990510064, 0.4834184163150969, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4764542936288089, 0.89, 0.34, 0.0, 0.6666666666666666, 0.6936541587583868, 0.6611394721050323, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.071362], dtype=float32), -0.0974357]. 
=============================================
[2019-04-06 16:07:09,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:09,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:09,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run7
[2019-04-06 16:07:15,420] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9847239e-07 4.4569542e-04 1.1543900e-06 1.5624657e-02 3.0021027e-08
 9.8392338e-01 4.9273303e-06], sum to 1.0000
[2019-04-06 16:07:15,420] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7880
[2019-04-06 16:07:15,465] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 37.0, 0.0, 0.0, 26.0, 25.79999429471826, 0.5671272834932591, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5004000.0000, 
sim time next is 5005800.0000, 
raw observation next is [3.0, 35.5, 0.0, 0.0, 26.0, 25.60643548398854, 0.4701372322106088, 0.0, 1.0, 38814.516775707096], 
processed observation next is [1.0, 0.9565217391304348, 0.5457063711911359, 0.355, 0.0, 0.0, 0.6666666666666666, 0.6338696236657118, 0.6567124107368696, 0.0, 1.0, 0.1848310322652719], 
reward next is 0.8152, 
noisyNet noise sample is [array([0.49395075], dtype=float32), -0.76313233]. 
=============================================
[2019-04-06 16:07:15,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:15,507] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:15,511] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run7
[2019-04-06 16:07:15,548] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2833794e-07 5.3901278e-04 1.1051683e-06 1.7919317e-02 3.1392023e-08
 9.8153621e-01 4.1226117e-06], sum to 1.0000
[2019-04-06 16:07:15,549] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6613
[2019-04-06 16:07:15,606] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 34.0, 0.0, 0.0, 26.0, 25.47039447917531, 0.4961368392839391, 0.0, 1.0, 95359.96877996107], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5007600.0000, 
sim time next is 5009400.0000, 
raw observation next is [2.5, 37.0, 0.0, 0.0, 26.0, 25.57478832111214, 0.482169891983931, 0.0, 1.0, 12496.33035314435], 
processed observation next is [1.0, 1.0, 0.5318559556786704, 0.37, 0.0, 0.0, 0.6666666666666666, 0.6312323600926785, 0.660723297327977, 0.0, 1.0, 0.0595063350149731], 
reward next is 0.9405, 
noisyNet noise sample is [array([0.49395075], dtype=float32), -0.76313233]. 
=============================================
[2019-04-06 16:07:21,562] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:21,562] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:21,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run7
[2019-04-06 16:07:21,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:21,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:21,804] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run7
[2019-04-06 16:07:23,095] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3367113e-08 6.2489707e-05 3.3426198e-07 9.2282668e-03 2.0118264e-08
 9.9070883e-01 1.2074389e-07], sum to 1.0000
[2019-04-06 16:07:23,096] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7094
[2019-04-06 16:07:23,373] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.1, 60.5, 56.0, 0.0, 26.0, 25.68845401686039, 0.3681068131155139, 1.0, 1.0, 66314.45782864194], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 228600.0000, 
sim time next is 230400.0000, 
raw observation next is [-3.4, 62.0, 37.0, 0.0, 26.0, 25.95206135447208, 0.3621809550169493, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.368421052631579, 0.62, 0.12333333333333334, 0.0, 0.6666666666666666, 0.6626717795393399, 0.6207269850056497, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.12619755], dtype=float32), -0.24963208]. 
=============================================
[2019-04-06 16:07:28,393] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:28,393] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:28,396] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run7
[2019-04-06 16:07:32,953] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:32,953] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:32,956] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run7
[2019-04-06 16:07:34,522] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:34,523] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:34,528] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run7
[2019-04-06 16:07:36,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:36,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:36,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run7
[2019-04-06 16:07:40,294] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:40,295] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:40,298] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run7
[2019-04-06 16:07:40,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:40,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:40,592] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run7
[2019-04-06 16:07:46,572] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:46,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:46,576] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run7
[2019-04-06 16:07:52,064] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1619153e-06 7.9632114e-04 1.0922148e-06 5.0560422e-02 4.6703246e-08
 9.4862795e-01 1.2022577e-05], sum to 1.0000
[2019-04-06 16:07:52,064] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9044
[2019-04-06 16:07:52,503] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.0, 42.0, 0.0, 0.0, 26.0, 25.12014219735149, 0.2961372925881773, 0.0, 1.0, 59336.30158458511], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 417600.0000, 
sim time next is 419400.0000, 
raw observation next is [-10.3, 44.5, 0.0, 0.0, 26.0, 25.0864246213246, 0.2612295203926241, 0.0, 1.0, 44989.54737624937], 
processed observation next is [1.0, 0.8695652173913043, 0.1772853185595568, 0.445, 0.0, 0.0, 0.6666666666666666, 0.5905353851103833, 0.5870765067975413, 0.0, 1.0, 0.21423593988690176], 
reward next is 0.7858, 
noisyNet noise sample is [array([0.5193818], dtype=float32), -1.5603142]. 
=============================================
[2019-04-06 16:08:04,486] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7060189e-06 7.4856268e-04 9.6055355e-06 4.0387180e-02 2.4883045e-07
 9.5885092e-01 1.8317003e-06], sum to 1.0000
[2019-04-06 16:08:04,486] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4859
[2019-04-06 16:08:04,585] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 26.0, 20.8844513483732, -0.6672416305840813, 0.0, 1.0, 41368.006301912086], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 14400.0000, 
sim time next is 16200.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 26.0, 20.97624214665809, -0.64399463141878, 0.0, 1.0, 41028.202843681756], 
processed observation next is [0.0, 0.17391304347826086, 0.6759002770083103, 0.93, 0.0, 0.0, 0.6666666666666666, 0.24802017888817426, 0.2853351228604067, 0.0, 1.0, 0.19537239449372265], 
reward next is 0.8046, 
noisyNet noise sample is [array([1.4373182], dtype=float32), -1.3547595]. 
=============================================
[2019-04-06 16:08:13,710] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1369768e-07 2.2747391e-04 1.5248277e-07 1.7210986e-03 3.0470342e-09
 9.9805009e-01 1.0733911e-06], sum to 1.0000
[2019-04-06 16:08:13,710] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2823
[2019-04-06 16:08:14,005] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8, 81.0, 109.5, 265.5, 26.0, 24.83443617190222, 0.3077082237853833, 0.0, 1.0, 54232.71171367655], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 561600.0000, 
sim time next is 563400.0000, 
raw observation next is [-1.0, 80.5, 130.0, 396.0, 26.0, 24.96660776031433, 0.3144073528175434, 0.0, 1.0, 9366.718988183738], 
processed observation next is [0.0, 0.5217391304347826, 0.4349030470914128, 0.805, 0.43333333333333335, 0.4375690607734807, 0.6666666666666666, 0.5805506466928607, 0.6048024509391811, 0.0, 1.0, 0.0446034237532559], 
reward next is 0.9554, 
noisyNet noise sample is [array([-1.3711163], dtype=float32), 0.39446244]. 
=============================================
[2019-04-06 16:08:20,365] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6533551e-07 3.4558325e-04 4.0646366e-05 1.9681547e-02 3.3741429e-07
 9.7992939e-01 1.8957079e-06], sum to 1.0000
[2019-04-06 16:08:20,365] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2485
[2019-04-06 16:08:20,738] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.65, 65.0, 100.0, 0.0, 26.0, 24.79831943433511, 0.1968325416897575, 0.0, 1.0, 87342.6066072861], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 642600.0000, 
sim time next is 644400.0000, 
raw observation next is [-3.4, 65.0, 94.5, 19.0, 26.0, 24.8939728215518, 0.2093451330349605, 0.0, 1.0, 31966.615843664662], 
processed observation next is [0.0, 0.4782608695652174, 0.368421052631579, 0.65, 0.315, 0.020994475138121547, 0.6666666666666666, 0.5744977351293166, 0.5697817110116535, 0.0, 1.0, 0.15222198020792696], 
reward next is 0.8478, 
noisyNet noise sample is [array([-0.07627773], dtype=float32), 0.2555]. 
=============================================
[2019-04-06 16:08:40,211] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9648052e-08 7.9359437e-05 2.4091270e-07 1.8396336e-03 4.1247525e-09
 9.9808049e-01 2.6216148e-07], sum to 1.0000
[2019-04-06 16:08:40,212] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7579
[2019-04-06 16:08:40,583] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 44.0, 89.0, 694.5, 26.0, 25.47917807508892, 0.4482549874252428, 1.0, 1.0, 100980.07585546124], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 306000.0000, 
sim time next is 307800.0000, 
raw observation next is [-9.5, 44.0, 95.0, 631.0, 26.0, 26.1539903877546, 0.5193985730406858, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.1994459833795014, 0.44, 0.31666666666666665, 0.6972375690607735, 0.6666666666666666, 0.67949919897955, 0.6731328576802286, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.79961425], dtype=float32), -1.3387424]. 
=============================================
[2019-04-06 16:08:47,719] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0922309e-08 1.6487250e-04 5.1118536e-07 1.6493464e-02 3.6571774e-09
 9.8334092e-01 1.7632615e-07], sum to 1.0000
[2019-04-06 16:08:47,719] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5510
[2019-04-06 16:08:47,870] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.4, 93.0, 0.0, 0.0, 26.0, 24.85487225568064, 0.2364483946037064, 0.0, 1.0, 39714.76268870133], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 520200.0000, 
sim time next is 522000.0000, 
raw observation next is [5.0, 89.0, 0.0, 0.0, 26.0, 24.84415360919341, 0.2556615983851087, 0.0, 1.0, 39733.73885236025], 
processed observation next is [0.0, 0.043478260869565216, 0.6011080332409973, 0.89, 0.0, 0.0, 0.6666666666666666, 0.5703461340994508, 0.5852205327950363, 0.0, 1.0, 0.18920828024933453], 
reward next is 0.8108, 
noisyNet noise sample is [array([-0.18429834], dtype=float32), 1.1713172]. 
=============================================
[2019-04-06 16:08:47,872] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[82.28593 ]
 [83.608   ]
 [86.119255]
 [85.98094 ]
 [85.9998  ]], R is [[79.90549469]
 [79.91732025]
 [79.92836761]
 [79.93801117]
 [79.94562531]].
[2019-04-06 16:09:11,254] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0118791e-07 3.8654450e-04 1.7093294e-07 2.7188503e-03 1.8917392e-09
 9.9689436e-01 4.8466568e-08], sum to 1.0000
[2019-04-06 16:09:11,255] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8695
[2019-04-06 16:09:11,335] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.5, 100.0, 0.0, 0.0, 26.0, 25.45218193917252, 0.5873592916686885, 0.0, 1.0, 42254.664817724064], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1287000.0000, 
sim time next is 1288800.0000, 
raw observation next is [5.5, 100.0, 0.0, 0.0, 26.0, 25.44109694368745, 0.5955407493997366, 0.0, 1.0, 44302.1250187314], 
processed observation next is [0.0, 0.9565217391304348, 0.6149584487534627, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6200914119739543, 0.6985135831332455, 0.0, 1.0, 0.21096250008919715], 
reward next is 0.7890, 
noisyNet noise sample is [array([-0.22481246], dtype=float32), 0.955587]. 
=============================================
[2019-04-06 16:09:15,505] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-06 16:09:15,506] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:09:15,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:15,508] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run15
[2019-04-06 16:09:15,551] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:09:15,554] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:15,556] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run15
[2019-04-06 16:09:15,705] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:09:15,705] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:15,707] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run15
[2019-04-06 16:10:03,426] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.0112653], dtype=float32), 0.10744074]
[2019-04-06 16:10:03,426] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [6.226566371, 94.07491618, 0.0, 0.0, 26.0, 24.93754519033885, 0.226272151856796, 0.0, 1.0, 39738.25287585644]
[2019-04-06 16:10:03,427] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 16:10:03,428] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.4607711e-07 8.8378316e-04 1.5237504e-06 3.6318969e-02 4.4407201e-08
 9.6279436e-01 1.1406073e-06], sampled 0.531137015999234
[2019-04-06 16:11:21,166] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.0112653], dtype=float32), 0.10744074]
[2019-04-06 16:11:21,166] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [0.0133157145, 64.17955273999999, 142.6065293, 558.7925463, 26.0, 24.92036009963817, 0.3282497500715059, 0.0, 1.0, 39590.98390063256]
[2019-04-06 16:11:21,166] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 16:11:21,167] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.8735790e-07 7.6540431e-04 2.0828825e-06 2.0181226e-02 5.4395557e-08
 9.7904974e-01 1.2355873e-06], sampled 0.9013198258456978
[2019-04-06 16:11:38,352] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.1818 79982636.1692 535.2331
[2019-04-06 16:11:51,853] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.0112653], dtype=float32), 0.10744074]
[2019-04-06 16:11:51,853] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [0.962554297, 100.0, 0.0, 0.0, 26.0, 25.40633997270728, 0.4497657997727423, 0.0, 1.0, 36865.71195782014]
[2019-04-06 16:11:51,853] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 16:11:51,854] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.1134869e-07 8.2517084e-04 2.2811710e-06 1.9622983e-02 5.4122623e-08
 9.7954798e-01 1.3599376e-06], sampled 0.05485400771498106
[2019-04-06 16:11:56,428] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.9816 87801499.8082 515.2233
[2019-04-06 16:11:58,649] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.0814 91915458.1356 408.6921
[2019-04-06 16:11:59,671] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 280000, evaluation results [280000.0, 2415.98158354462, 87801499.80816428, 515.2233012185044, 2453.181817917266, 79982636.1691788, 535.233134815934, 2397.0813932800797, 91915458.13555223, 408.69211260165497]
[2019-04-06 16:12:10,714] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4953932e-07 4.8396370e-04 1.2387336e-06 1.5764055e-01 1.4445764e-08
 8.4187359e-01 5.4910998e-07], sum to 1.0000
[2019-04-06 16:12:10,715] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7517
[2019-04-06 16:12:10,786] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.6, 76.0, 0.0, 0.0, 26.0, 26.11633602668142, 0.691661208756877, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1548000.0000, 
sim time next is 1549800.0000, 
raw observation next is [6.05, 79.0, 0.0, 0.0, 26.0, 25.85390465507268, 0.5829289039635663, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.6301939058171746, 0.79, 0.0, 0.0, 0.6666666666666666, 0.6544920545893899, 0.694309634654522, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4655169], dtype=float32), -1.2621901]. 
=============================================
[2019-04-06 16:12:11,486] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1487068e-09 2.0090833e-04 9.8442264e-08 8.2226470e-03 5.2147615e-09
 9.9157578e-01 5.8662408e-07], sum to 1.0000
[2019-04-06 16:12:11,486] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1778
[2019-04-06 16:12:11,525] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.04999999999999999, 53.5, 131.0, 449.0, 26.0, 25.74944009794772, 0.3609433284946277, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 736200.0000, 
sim time next is 738000.0000, 
raw observation next is [0.5, 50.0, 110.0, 611.0, 26.0, 25.5846418459126, 0.3591689360095076, 1.0, 1.0, 24840.882722231076], 
processed observation next is [1.0, 0.5652173913043478, 0.4764542936288089, 0.5, 0.36666666666666664, 0.6751381215469613, 0.6666666666666666, 0.6320534871593834, 0.6197229786698358, 1.0, 1.0, 0.11828991772490989], 
reward next is 0.8817, 
noisyNet noise sample is [array([1.8187182], dtype=float32), 0.84619683]. 
=============================================
[2019-04-06 16:12:11,534] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[86.68393 ]
 [86.48777 ]
 [86.259254]
 [85.11686 ]
 [84.480034]], R is [[87.0007782 ]
 [87.13076782]
 [87.25946045]
 [87.38686371]
 [87.51299286]].
[2019-04-06 16:12:18,567] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2986961e-09 3.2576514e-05 2.4070451e-07 3.4204081e-03 1.0865778e-08
 9.9654680e-01 3.5488682e-08], sum to 1.0000
[2019-04-06 16:12:18,605] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9026
[2019-04-06 16:12:18,789] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 84.0, 0.0, 0.0, 26.0, 25.66227049589999, 0.3218705241351468, 1.0, 1.0, 3118.603922064169], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 840600.0000, 
sim time next is 842400.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 26.0, 25.13046795485179, 0.2835610417059661, 1.0, 1.0, 46250.55140135018], 
processed observation next is [1.0, 0.782608695652174, 0.3545706371191136, 0.82, 0.0, 0.0, 0.6666666666666666, 0.594205662904316, 0.594520347235322, 1.0, 1.0, 0.2202407209588104], 
reward next is 0.7798, 
noisyNet noise sample is [array([0.6982445], dtype=float32), 0.118014455]. 
=============================================
[2019-04-06 16:12:23,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.11322784e-07 4.58385504e-04 4.00701055e-07 1.26988795e-02
 4.54262334e-08 9.86841679e-01 5.75863908e-07], sum to 1.0000
[2019-04-06 16:12:23,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9617
[2019-04-06 16:12:23,233] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 85.0, 119.0, 0.0, 26.0, 24.92740073126638, 0.3481351404698002, 0.0, 1.0, 43439.320275754806], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1769400.0000, 
sim time next is 1771200.0000, 
raw observation next is [-2.3, 83.0, 122.5, 0.0, 26.0, 24.94555756033002, 0.3452309069133553, 0.0, 1.0, 34762.317900320486], 
processed observation next is [0.0, 0.5217391304347826, 0.3988919667590028, 0.83, 0.4083333333333333, 0.0, 0.6666666666666666, 0.578796463360835, 0.6150769689711184, 0.0, 1.0, 0.16553484714438327], 
reward next is 0.8345, 
noisyNet noise sample is [array([-0.09500374], dtype=float32), 2.2987113]. 
=============================================
[2019-04-06 16:12:30,096] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.4966196e-08 4.6765908e-05 1.7212528e-08 1.3198123e-03 1.2420007e-09
 9.9863333e-01 1.5538156e-08], sum to 1.0000
[2019-04-06 16:12:30,096] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9340
[2019-04-06 16:12:30,220] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 92.0, 31.5, 0.0, 26.0, 26.07992163602695, 0.5890905538349235, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1328400.0000, 
sim time next is 1330200.0000, 
raw observation next is [0.5, 92.0, 45.0, 0.0, 26.0, 26.03727975521004, 0.5885748887177599, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4764542936288089, 0.92, 0.15, 0.0, 0.6666666666666666, 0.66977331293417, 0.6961916295725866, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.25006396], dtype=float32), 1.8566453]. 
=============================================
[2019-04-06 16:12:35,148] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5683152e-06 9.0108337e-03 6.9850066e-05 3.6291701e-01 5.0335325e-06
 6.2797266e-01 2.1116010e-05], sum to 1.0000
[2019-04-06 16:12:35,148] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0945
[2019-04-06 16:12:35,158] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 26.0, 23.60773151998413, 0.1763772076774978, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1229400.0000, 
sim time next is 1231200.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 26.0, 23.58217611442369, 0.1637956103262533, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.8781163434903049, 0.96, 0.0, 0.0, 0.6666666666666666, 0.4651813428686407, 0.5545985367754177, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6584964], dtype=float32), -0.09423399]. 
=============================================
[2019-04-06 16:12:35,349] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3576373e-08 1.1286566e-03 4.3698012e-07 8.8179201e-02 1.8516246e-07
 9.1068763e-01 3.8439202e-06], sum to 1.0000
[2019-04-06 16:12:35,353] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0567
[2019-04-06 16:12:35,392] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [13.8, 60.0, 0.0, 0.0, 26.0, 25.78715509828956, 0.6562293210730072, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1108800.0000, 
sim time next is 1110600.0000, 
raw observation next is [13.55, 61.0, 0.0, 0.0, 26.0, 25.62692946912231, 0.6719597002671064, 0.0, 1.0, 114958.49009037337], 
processed observation next is [1.0, 0.8695652173913043, 0.8379501385041552, 0.61, 0.0, 0.0, 0.6666666666666666, 0.6355774557601924, 0.723986566755702, 0.0, 1.0, 0.5474213813827303], 
reward next is 0.4526, 
noisyNet noise sample is [array([1.2765381], dtype=float32), 0.0071384525]. 
=============================================
[2019-04-06 16:12:46,956] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5475035e-09 1.5202298e-05 1.8777746e-08 4.8939086e-04 5.5995175e-10
 9.9949539e-01 4.6115630e-08], sum to 1.0000
[2019-04-06 16:12:46,957] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9263
[2019-04-06 16:12:47,022] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.9, 92.0, 0.0, 0.0, 26.0, 25.45606954537006, 0.4624518757139954, 0.0, 1.0, 27990.879016694696], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1474200.0000, 
sim time next is 1476000.0000, 
raw observation next is [2.2, 92.0, 0.0, 0.0, 26.0, 25.34436778081519, 0.4660643946582343, 0.0, 1.0, 63192.89849305694], 
processed observation next is [1.0, 0.08695652173913043, 0.5235457063711911, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6120306484012659, 0.6553547982194114, 0.0, 1.0, 0.3009185642526521], 
reward next is 0.6991, 
noisyNet noise sample is [array([1.8414766], dtype=float32), 0.38863325]. 
=============================================
[2019-04-06 16:12:47,025] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[82.40201]
 [82.92166]
 [83.63724]
 [83.71093]
 [85.00354]], R is [[82.45355225]
 [82.49572754]
 [82.67076874]
 [82.66577148]
 [82.64865112]].
[2019-04-06 16:12:48,165] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2719559e-08 7.1672566e-04 4.5533159e-07 3.5065347e-01 8.1634077e-09
 6.4862919e-01 8.2557172e-08], sum to 1.0000
[2019-04-06 16:12:48,165] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4687
[2019-04-06 16:12:48,223] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 26.0, 25.33598949308114, 0.4939157545433466, 0.0, 1.0, 49671.67051914814], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1465200.0000, 
sim time next is 1467000.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 26.0, 25.38711596534263, 0.4887599591815752, 0.0, 1.0, 32949.803897916936], 
processed observation next is [1.0, 1.0, 0.5069252077562327, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6155929971118859, 0.6629199863938584, 0.0, 1.0, 0.15690382808531875], 
reward next is 0.8431, 
noisyNet noise sample is [array([-0.68616307], dtype=float32), 0.070082895]. 
=============================================
[2019-04-06 16:12:48,249] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[85.70213 ]
 [85.68319 ]
 [85.4252  ]
 [85.53311 ]
 [85.572685]], R is [[85.48131561]
 [85.38996887]
 [85.20834351]
 [85.20180511]
 [85.34978485]].
[2019-04-06 16:12:53,601] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9349214e-08 2.0238663e-04 1.4706474e-07 7.5579570e-03 3.2654042e-09
 9.9223912e-01 3.2698046e-07], sum to 1.0000
[2019-04-06 16:12:53,602] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8163
[2019-04-06 16:12:53,681] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 26.0, 25.36643174460426, 0.4838741097814017, 0.0, 1.0, 38521.63046263182], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1467000.0000, 
sim time next is 1468800.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 26.0, 25.3622052452742, 0.4792910034434051, 0.0, 1.0, 37370.90650521446], 
processed observation next is [1.0, 0.0, 0.5069252077562327, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6135171037728501, 0.6597636678144684, 0.0, 1.0, 0.17795669764387836], 
reward next is 0.8220, 
noisyNet noise sample is [array([2.3460886], dtype=float32), 0.03902879]. 
=============================================
[2019-04-06 16:13:06,085] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.8606962e-07 1.1841553e-02 4.1968378e-06 2.8905358e-02 3.5260237e-07
 9.5921987e-01 2.7937363e-05], sum to 1.0000
[2019-04-06 16:13:06,085] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9713
[2019-04-06 16:13:06,239] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 75.0, 152.0, 66.0, 26.0, 24.97364834431342, 0.2529526014032684, 0.0, 1.0, 31185.03213434371], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1854000.0000, 
sim time next is 1855800.0000, 
raw observation next is [-5.3, 73.0, 184.0, 81.0, 26.0, 24.94883343695355, 0.2630583269730716, 0.0, 1.0, 47522.205206598475], 
processed observation next is [0.0, 0.4782608695652174, 0.31578947368421056, 0.73, 0.6133333333333333, 0.08950276243093923, 0.6666666666666666, 0.5790694530794624, 0.5876861089910238, 0.0, 1.0, 0.22629621526951654], 
reward next is 0.7737, 
noisyNet noise sample is [array([0.5252654], dtype=float32), -1.4729083]. 
=============================================
[2019-04-06 16:13:06,477] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.95498829e-07 3.68731469e-03 1.25359775e-05 1.34459019e-01
 2.59752454e-07 8.61833036e-01 6.84152064e-06], sum to 1.0000
[2019-04-06 16:13:06,477] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7390
[2019-04-06 16:13:06,555] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.39566288479931, 0.3440416079066153, 0.0, 1.0, 40445.38752170193], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3103200.0000, 
sim time next is 3105000.0000, 
raw observation next is [-0.5, 100.0, 0.0, 0.0, 26.0, 25.36166843141427, 0.341550172884884, 0.0, 1.0, 43285.67933432283], 
processed observation next is [0.0, 0.9565217391304348, 0.44875346260387816, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6134723692845224, 0.6138500576282947, 0.0, 1.0, 0.2061222825443944], 
reward next is 0.7939, 
noisyNet noise sample is [array([1.3057818], dtype=float32), 0.5632376]. 
=============================================
[2019-04-06 16:13:06,561] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.94758 ]
 [74.43916 ]
 [73.81066 ]
 [72.995674]
 [72.459984]], R is [[75.22403717]
 [75.27919769]
 [75.33841705]
 [75.27178955]
 [75.42315674]].
[2019-04-06 16:14:49,927] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.0513245e-08 3.3351828e-04 8.6836440e-09 8.9298226e-02 4.0005949e-10
 9.1036820e-01 7.0063639e-09], sum to 1.0000
[2019-04-06 16:14:49,927] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6933
[2019-04-06 16:14:49,997] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 93.0, 82.5, 0.0, 26.0, 25.45344190809055, 0.3258998502637101, 1.0, 1.0, 18680.41167023054], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2890800.0000, 
sim time next is 2892600.0000, 
raw observation next is [1.0, 96.5, 87.0, 0.0, 26.0, 25.39045322238184, 0.3194300572092436, 1.0, 1.0, 18680.41167023054], 
processed observation next is [1.0, 0.4782608695652174, 0.4903047091412743, 0.965, 0.29, 0.0, 0.6666666666666666, 0.6158711018651534, 0.6064766857364146, 1.0, 1.0, 0.0889543412868121], 
reward next is 0.9110, 
noisyNet noise sample is [array([0.05814185], dtype=float32), 2.579036]. 
=============================================
[2019-04-06 16:14:52,692] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2900704e-07 8.0490549e-04 4.0844188e-07 3.7619522e-01 1.6842476e-07
 6.2299621e-01 2.7280155e-06], sum to 1.0000
[2019-04-06 16:14:52,692] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8678
[2019-04-06 16:14:52,788] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.73237559882469, 0.2635667117967943, 0.0, 1.0, 44136.75631676131], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2764800.0000, 
sim time next is 2766600.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.64121297114099, 0.2461570980956388, 0.0, 1.0, 43369.06681027276], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5534344142617492, 0.5820523660318796, 0.0, 1.0, 0.20651936576320362], 
reward next is 0.7935, 
noisyNet noise sample is [array([0.24688329], dtype=float32), -1.1241564]. 
=============================================
[2019-04-06 16:14:56,372] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 16:14:56,373] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:14:56,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:14:56,375] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run16
[2019-04-06 16:14:56,458] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:14:56,458] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:14:56,460] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run16
[2019-04-06 16:14:56,535] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:14:56,535] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:14:56,538] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run16
[2019-04-06 16:17:19,237] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.1299 79931953.7453 535.1746
[2019-04-06 16:17:37,672] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.01478808], dtype=float32), 0.10775682]
[2019-04-06 16:17:37,672] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [4.818209728, 27.41932034, 70.456920675, 445.0148159, 26.0, 25.25011090745177, 0.4211812415847143, 0.0, 1.0, 0.0]
[2019-04-06 16:17:37,672] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 16:17:37,673] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [4.8528619e-07 1.6384497e-03 4.0779296e-06 4.0453833e-02 2.1538922e-07
 9.5789975e-01 3.1763491e-06], sampled 0.21292930382697894
[2019-04-06 16:17:39,241] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.3889 87801518.6400 515.1711
[2019-04-06 16:17:41,862] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.8736 91883583.2578 409.3282
[2019-04-06 16:17:42,884] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 300000, evaluation results [300000.0, 2416.3888900780075, 87801518.63997366, 515.1710642426044, 2454.12989221002, 79931953.74532805, 535.1746169758466, 2396.8736095308204, 91883583.25776215, 409.32819464005235]
[2019-04-06 16:17:44,045] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2196735e-08 3.0274477e-04 8.5847844e-08 1.1019353e-01 2.6887950e-08
 8.8950294e-01 6.2798313e-07], sum to 1.0000
[2019-04-06 16:17:44,045] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9912
[2019-04-06 16:17:44,091] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.0, 24.0, 106.5, 0.0, 26.0, 24.73770426666353, 0.3005908671371672, 1.0, 1.0, 63583.37067177333], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2818800.0000, 
sim time next is 2820600.0000, 
raw observation next is [6.8, 24.5, 95.0, 0.0, 26.0, 25.6605720502975, 0.3820055265428106, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.6509695290858727, 0.245, 0.31666666666666665, 0.0, 0.6666666666666666, 0.6383810041914583, 0.6273351755142702, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1818416], dtype=float32), -1.5988734]. 
=============================================
[2019-04-06 16:17:48,169] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.18515162e-08 2.46610492e-04 5.58976971e-08 1.12899775e-02
 4.58893101e-09 9.88463342e-01 3.50240121e-08], sum to 1.0000
[2019-04-06 16:17:48,170] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7103
[2019-04-06 16:17:48,208] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 100.0, 0.0, 0.0, 26.0, 25.30830175422471, 0.4896551301587411, 0.0, 1.0, 40617.945717699506], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3218400.0000, 
sim time next is 3220200.0000, 
raw observation next is [-3.0, 96.0, 0.0, 0.0, 26.0, 25.25597764847435, 0.4617082916991829, 0.0, 1.0, 40781.35803740807], 
processed observation next is [1.0, 0.2608695652173913, 0.3795013850415513, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6046648040395292, 0.6539027638997276, 0.0, 1.0, 0.19419694303527651], 
reward next is 0.8058, 
noisyNet noise sample is [array([1.0785257], dtype=float32), 0.44489926]. 
=============================================
[2019-04-06 16:17:48,726] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2533765e-08 1.1359903e-04 2.7049005e-06 2.2814440e-02 1.7710043e-08
 9.7706848e-01 7.3296934e-07], sum to 1.0000
[2019-04-06 16:17:48,727] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5422
[2019-04-06 16:17:48,856] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 92.0, 85.0, 370.0, 26.0, 25.59862912786325, 0.5619432672238318, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3227400.0000, 
sim time next is 3229200.0000, 
raw observation next is [-3.0, 92.0, 93.0, 511.5, 26.0, 26.00474802424819, 0.606518018572629, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.92, 0.31, 0.5651933701657459, 0.6666666666666666, 0.6670623353540158, 0.702172672857543, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.13207942], dtype=float32), 0.0024423166]. 
=============================================
[2019-04-06 16:17:52,754] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5683641e-08 4.5878708e-04 8.8216062e-08 9.2402017e-03 3.2085541e-09
 9.9030089e-01 5.5916757e-08], sum to 1.0000
[2019-04-06 16:17:52,754] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0216
[2019-04-06 16:17:52,924] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.0, 100.0, 42.0, 237.0, 26.0, 25.37605322309899, 0.3723247320670045, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3139200.0000, 
sim time next is 3141000.0000, 
raw observation next is [6.5, 100.0, 83.0, 392.0, 26.0, 25.7689513437804, 0.4473848667362679, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.6426592797783934, 1.0, 0.27666666666666667, 0.4331491712707182, 0.6666666666666666, 0.6474126119817001, 0.6491282889120893, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6024876], dtype=float32), -1.1166823]. 
=============================================
[2019-04-06 16:17:52,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[87.554596]
 [85.65567 ]
 [84.62349 ]
 [84.4747  ]
 [84.12788 ]], R is [[88.98212433]
 [89.09230042]
 [89.17160034]
 [89.05954742]
 [88.88224792]].
[2019-04-06 16:17:53,848] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2146792e-07 1.0156267e-03 1.2900581e-07 1.1737443e-02 4.1237691e-08
 9.8724627e-01 2.9860720e-07], sum to 1.0000
[2019-04-06 16:17:53,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9844
[2019-04-06 16:17:53,913] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 45.0, 199.5, 398.0, 26.0, 25.07366714159137, 0.3692793708155484, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4892400.0000, 
sim time next is 4894200.0000, 
raw observation next is [3.0, 45.0, 163.0, 422.0, 26.0, 25.09822475462483, 0.3762346476339296, 0.0, 1.0, 6228.543613801543], 
processed observation next is [0.0, 0.6521739130434783, 0.5457063711911359, 0.45, 0.5433333333333333, 0.4662983425414365, 0.6666666666666666, 0.5915187295520692, 0.6254115492113098, 0.0, 1.0, 0.029659731494293063], 
reward next is 0.9703, 
noisyNet noise sample is [array([1.0444769], dtype=float32), 2.0179148]. 
=============================================
[2019-04-06 16:17:58,284] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.2303499e-08 4.3209977e-03 3.1270054e-06 6.6180187e-01 3.8950628e-08
 3.3387282e-01 1.1569964e-06], sum to 1.0000
[2019-04-06 16:17:58,284] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6562
[2019-04-06 16:17:58,349] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-8.0, 49.0, 0.0, 0.0, 26.0, 25.41069813887286, 0.4953389335990186, 0.0, 1.0, 58957.700637742535], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3967200.0000, 
sim time next is 3969000.0000, 
raw observation next is [-8.5, 51.0, 0.0, 0.0, 26.0, 25.33247398620171, 0.4210178842393519, 0.0, 1.0, 54187.598532134434], 
processed observation next is [1.0, 0.9565217391304348, 0.22714681440443216, 0.51, 0.0, 0.0, 0.6666666666666666, 0.6110394988501424, 0.6403392947464507, 0.0, 1.0, 0.25803618348635443], 
reward next is 0.7420, 
noisyNet noise sample is [array([0.25589463], dtype=float32), 0.9412942]. 
=============================================
[2019-04-06 16:17:58,354] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[73.64395]
 [74.5166 ]
 [75.29147]
 [75.53486]
 [76.38193]], R is [[73.73266602]
 [73.71458435]
 [73.77589417]
 [73.81039429]
 [73.80860901]].
[2019-04-06 16:17:58,798] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7432093e-07 2.3570424e-03 8.1609721e-07 7.3932016e-01 8.8190951e-08
 2.5831684e-01 4.5669995e-06], sum to 1.0000
[2019-04-06 16:17:58,798] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4830
[2019-04-06 16:17:58,948] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-2.0, 60.0, 105.5, 775.5, 26.0, 25.1153271402212, 0.406596265344702, 0.0, 1.0, 18715.155863897715], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2988000.0000, 
sim time next is 2989800.0000, 
raw observation next is [-2.0, 60.0, 101.0, 751.0, 26.0, 25.18710797210551, 0.416638115867612, 0.0, 1.0, 12485.509124145887], 
processed observation next is [0.0, 0.6086956521739131, 0.40720221606648205, 0.6, 0.33666666666666667, 0.8298342541436464, 0.6666666666666666, 0.5989256643421257, 0.6388793719558706, 0.0, 1.0, 0.05945480535307565], 
reward next is 0.9405, 
noisyNet noise sample is [array([-0.19666065], dtype=float32), -0.4132164]. 
=============================================
[2019-04-06 16:18:04,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:18:04,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:18:04,276] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run8
[2019-04-06 16:18:12,294] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.2807580e-08 1.3280906e-03 6.7471854e-07 1.6039750e-01 6.9980508e-08
 8.3827275e-01 7.4979488e-07], sum to 1.0000
[2019-04-06 16:18:12,295] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8757
[2019-04-06 16:18:12,358] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 47.5, 0.0, 0.0, 26.0, 25.40086428922697, 0.3625154755627631, 0.0, 1.0, 42879.709731555726], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4231800.0000, 
sim time next is 4233600.0000, 
raw observation next is [2.0, 48.0, 0.0, 0.0, 26.0, 25.42919761701521, 0.3582626220071327, 0.0, 1.0, 31334.718933132564], 
processed observation next is [0.0, 0.0, 0.518005540166205, 0.48, 0.0, 0.0, 0.6666666666666666, 0.6190998014179341, 0.6194208740023776, 0.0, 1.0, 0.14921294730063125], 
reward next is 0.8508, 
noisyNet noise sample is [array([-1.1148748], dtype=float32), 0.24436827]. 
=============================================
[2019-04-06 16:18:12,580] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6116145e-06 6.6654792e-04 4.8905313e-06 4.7192238e-02 4.9831681e-07
 9.5212311e-01 1.1258788e-05], sum to 1.0000
[2019-04-06 16:18:12,580] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5209
[2019-04-06 16:18:12,636] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 50.0, 0.0, 0.0, 26.0, 25.22667841846152, 0.360209749835825, 0.0, 1.0, 39484.9115374663], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4159800.0000, 
sim time next is 4161600.0000, 
raw observation next is [-3.0, 50.0, 0.0, 0.0, 26.0, 25.1920609186063, 0.3461639523808918, 0.0, 1.0, 39486.44640076482], 
processed observation next is [0.0, 0.17391304347826086, 0.3795013850415513, 0.5, 0.0, 0.0, 0.6666666666666666, 0.5993384098838582, 0.6153879841269639, 0.0, 1.0, 0.18803069714649914], 
reward next is 0.8120, 
noisyNet noise sample is [array([-0.06863768], dtype=float32), -0.67093915]. 
=============================================
[2019-04-06 16:18:19,139] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0140524e-08 4.7969930e-05 4.0355724e-07 6.0863897e-02 1.3137056e-09
 9.3908757e-01 6.9909376e-08], sum to 1.0000
[2019-04-06 16:18:19,141] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5170
[2019-04-06 16:18:19,399] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 26.0, 24.31207211332712, 0.462587300182882, 1.0, 1.0, 131033.81200973457], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3263400.0000, 
sim time next is 3265200.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 26.0, 25.65566814705287, 0.6189332250161678, 1.0, 1.0, 66204.54775059174], 
processed observation next is [1.0, 0.8260869565217391, 0.3518005540166205, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6379723455877393, 0.7063110750053893, 1.0, 1.0, 0.31525975119329397], 
reward next is 0.6847, 
noisyNet noise sample is [array([0.48716635], dtype=float32), -0.88550246]. 
=============================================
[2019-04-06 16:18:43,204] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2624536e-09 3.1450955e-04 2.3424568e-07 1.7976256e-02 2.8080635e-10
 9.8170900e-01 1.3656375e-08], sum to 1.0000
[2019-04-06 16:18:43,204] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2604
[2019-04-06 16:18:43,233] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 31.0, 120.0, 828.0, 26.0, 27.8568774110513, 0.9431760992652176, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4361400.0000, 
sim time next is 4363200.0000, 
raw observation next is [15.0, 28.0, 119.0, 840.5, 26.0, 28.17605094769244, 1.016430121632029, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.8781163434903049, 0.28, 0.39666666666666667, 0.9287292817679558, 0.6666666666666666, 0.8480042456410365, 0.8388100405440096, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5419995], dtype=float32), 0.47272098]. 
=============================================
[2019-04-06 16:18:43,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:18:43,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:18:43,460] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run8
[2019-04-06 16:18:50,326] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.0954961e-08 1.4258694e-04 2.1687965e-08 4.1844300e-03 5.2782432e-09
 9.9567288e-01 4.1536875e-08], sum to 1.0000
[2019-04-06 16:18:50,326] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9455
[2019-04-06 16:18:50,398] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.6, 69.0, 0.0, 0.0, 26.0, 25.43908824320584, 0.3679642524674633, 0.0, 1.0, 66336.67086272364], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4338000.0000, 
sim time next is 4339800.0000, 
raw observation next is [3.45, 70.0, 0.0, 0.0, 26.0, 25.48973656419408, 0.3818409502374376, 0.0, 1.0, 41621.022634371126], 
processed observation next is [1.0, 0.21739130434782608, 0.5581717451523546, 0.7, 0.0, 0.0, 0.6666666666666666, 0.6241447136828399, 0.6272803167458125, 0.0, 1.0, 0.19819534587795773], 
reward next is 0.8018, 
noisyNet noise sample is [array([0.9364649], dtype=float32), -0.43900388]. 
=============================================
[2019-04-06 16:18:50,543] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:18:50,543] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:18:50,547] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run8
[2019-04-06 16:18:51,674] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:18:51,674] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:18:51,678] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run8
[2019-04-06 16:18:53,210] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:18:53,210] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:18:53,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run8
[2019-04-06 16:18:56,161] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.0405758e-09 2.8885255e-04 3.0713547e-08 7.4534714e-02 3.9474286e-09
 9.2517620e-01 1.0779861e-07], sum to 1.0000
[2019-04-06 16:18:56,161] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2620
[2019-04-06 16:18:56,217] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 25.44697918949257, 0.5152177921215295, 1.0, 1.0, 25951.456472667167], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4471200.0000, 
sim time next is 4473000.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 25.45904930796294, 0.4888693275287007, 1.0, 1.0, 20042.81630747345], 
processed observation next is [1.0, 0.782608695652174, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.6215874423302449, 0.662956442509567, 1.0, 1.0, 0.09544198241654024], 
reward next is 0.9046, 
noisyNet noise sample is [array([1.396009], dtype=float32), -1.3618046]. 
=============================================
[2019-04-06 16:18:56,222] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[85.9564  ]
 [86.96514 ]
 [87.88759 ]
 [87.89791 ]
 [89.147026]], R is [[85.15740204]
 [85.18225098]
 [85.33042908]
 [85.27145386]
 [85.41873932]].
[2019-04-06 16:19:28,583] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9064123e-09 1.6575992e-05 4.0610231e-09 3.2436459e-03 4.8953319e-10
 9.9673980e-01 2.7559719e-09], sum to 1.0000
[2019-04-06 16:19:28,583] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3438
[2019-04-06 16:19:28,654] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 72.0, 147.0, 0.0, 26.0, 25.99934562788326, 0.5363189669848928, 1.0, 1.0, 4151.202593384563], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4721400.0000, 
sim time next is 4723200.0000, 
raw observation next is [1.0, 72.0, 123.5, 5.5, 26.0, 26.16190359874682, 0.5469021113050396, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4903047091412743, 0.72, 0.4116666666666667, 0.0060773480662983425, 0.6666666666666666, 0.6801586332289018, 0.6823007037683465, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6525481], dtype=float32), -0.2811648]. 
=============================================
[2019-04-06 16:19:31,791] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:19:31,791] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:19:31,827] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run8
[2019-04-06 16:19:39,843] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:19:39,843] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:19:39,847] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run8
[2019-04-06 16:19:40,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:19:40,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:19:40,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run8
[2019-04-06 16:19:40,863] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7598789e-10 6.3787673e-05 4.8060389e-08 1.4087052e-02 5.7946989e-09
 9.8584902e-01 8.2119641e-08], sum to 1.0000
[2019-04-06 16:19:40,863] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4221
[2019-04-06 16:19:40,966] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 26.0, 25.58088947841261, 0.5168118955852283, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1018800.0000, 
sim time next is 1020600.0000, 
raw observation next is [14.4, 79.0, 0.0, 0.0, 26.0, 25.33391713212659, 0.4556063814586357, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.8614958448753465, 0.79, 0.0, 0.0, 0.6666666666666666, 0.6111597610105491, 0.6518687938195452, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.81690335], dtype=float32), 1.0630798]. 
=============================================
[2019-04-06 16:19:43,576] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:19:43,577] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:19:43,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run8
[2019-04-06 16:19:49,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7649963e-08 1.9525520e-03 6.4382493e-07 4.1189633e-02 2.8658752e-08
 9.5685697e-01 9.0428721e-08], sum to 1.0000
[2019-04-06 16:19:49,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3876
[2019-04-06 16:19:49,232] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 100.0, 35.0, 0.0, 26.0, 24.62567464672173, 0.4217672600232574, 0.0, 1.0, 12453.607780153694], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1267200.0000, 
sim time next is 1269000.0000, 
raw observation next is [13.0, 100.0, 19.0, 0.0, 26.0, 24.60035834077116, 0.4213069488616505, 0.0, 1.0, 23593.46055207059], 
processed observation next is [0.0, 0.6956521739130435, 0.8227146814404434, 1.0, 0.06333333333333334, 0.0, 0.6666666666666666, 0.5500298617309299, 0.6404356496205502, 0.0, 1.0, 0.11234981215271711], 
reward next is 0.8877, 
noisyNet noise sample is [array([-0.62268037], dtype=float32), 1.5283915]. 
=============================================
[2019-04-06 16:19:49,245] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[80.84172 ]
 [81.06942 ]
 [81.309074]
 [81.53716 ]
 [81.798386]], R is [[80.62784576]
 [80.76226807]
 [80.95464325]
 [81.14509583]
 [81.33364868]].
[2019-04-06 16:19:50,965] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:19:50,965] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:19:50,968] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run8
[2019-04-06 16:19:57,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:19:57,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:19:57,516] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run8
[2019-04-06 16:19:58,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:19:58,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:19:58,112] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run8
[2019-04-06 16:20:01,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:20:01,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:20:01,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run8
[2019-04-06 16:20:10,966] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:20:10,966] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:20:10,969] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run8
[2019-04-06 16:20:11,690] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:20:11,690] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:20:11,694] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run8
[2019-04-06 16:20:12,107] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:20:12,107] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:20:12,110] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run8
[2019-04-06 16:20:19,454] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-06 16:20:19,459] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:20:19,460] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:20:19,460] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:20:19,461] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:20:19,463] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run17
[2019-04-06 16:20:19,460] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:20:19,517] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:20:19,519] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run17
[2019-04-06 16:20:19,540] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run17
[2019-04-06 16:20:44,758] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.0187901], dtype=float32), 0.10900666]
[2019-04-06 16:20:44,758] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-3.9, 75.0, 0.0, 0.0, 26.0, 24.51369520840438, 0.1730210927603322, 0.0, 1.0, 44224.22776051789]
[2019-04-06 16:20:44,758] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:20:44,759] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [3.0198115e-07 1.2292031e-03 1.9239965e-06 5.0067592e-02 1.1657388e-07
 9.4869900e-01 1.9209879e-06], sampled 0.5606592999396046
[2019-04-06 16:20:45,529] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.0187901], dtype=float32), 0.10900666]
[2019-04-06 16:20:45,530] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-12.3, 67.0, 0.0, 0.0, 26.0, 22.52900624515986, -0.2781489002776362, 0.0, 1.0, 47921.32834811371]
[2019-04-06 16:20:45,530] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:20:45,531] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.6924060e-06 2.1837093e-03 9.0571075e-06 4.8186067e-02 5.7116222e-07
 9.4961196e-01 6.8635459e-06], sampled 0.963286282051866
[2019-04-06 16:22:40,684] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2375 79970932.4725 534.7588
[2019-04-06 16:23:02,030] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.8869 91926888.8708 408.9056
[2019-04-06 16:23:02,098] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.2691 87766559.3728 515.5785
[2019-04-06 16:23:03,120] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 320000, evaluation results [320000.0, 2416.269092918485, 87766559.37275952, 515.57848091798, 2453.2375498061447, 79970932.47251444, 534.7588262095061, 2396.886910364652, 91926888.87082382, 408.9055947080265]
[2019-04-06 16:23:04,306] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.5421068e-07 2.9087362e-03 8.8389015e-07 3.2027818e-02 2.0356730e-07
 9.6505994e-01 1.6880678e-06], sum to 1.0000
[2019-04-06 16:23:04,306] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6861
[2019-04-06 16:23:04,382] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 79.0, 0.0, 0.0, 26.0, 24.15697131838285, 0.09158307175050973, 0.0, 1.0, 44356.754949578666], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 259200.0000, 
sim time next is 261000.0000, 
raw observation next is [-5.6, 73.0, 0.0, 0.0, 26.0, 24.09470057067003, 0.08441054939680871, 0.0, 1.0, 44435.87529985688], 
processed observation next is [1.0, 0.0, 0.30747922437673136, 0.73, 0.0, 0.0, 0.6666666666666666, 0.5078917142225027, 0.5281368497989363, 0.0, 1.0, 0.21159940618979467], 
reward next is 0.7884, 
noisyNet noise sample is [array([-0.26094082], dtype=float32), -0.019210551]. 
=============================================
[2019-04-06 16:23:04,481] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[79.71956]
 [80.54153]
 [80.831  ]
 [80.09912]
 [80.37935]], R is [[79.41576385]
 [79.41038513]
 [79.4053421 ]
 [79.40078735]
 [79.39638519]].
[2019-04-06 16:24:00,236] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2883318e-08 5.5280881e-04 3.2990241e-07 6.0527381e-03 2.2800371e-08
 9.9339384e-01 1.8928158e-07], sum to 1.0000
[2019-04-06 16:24:00,236] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5995
[2019-04-06 16:24:00,485] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 76.0, 14.5, 0.0, 26.0, 25.61769542097878, 0.2849815435848437, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 720000.0000, 
sim time next is 721800.0000, 
raw observation next is [-2.3, 76.0, 29.0, 0.0, 26.0, 25.62580209631368, 0.286670489603526, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3988919667590028, 0.76, 0.09666666666666666, 0.0, 0.6666666666666666, 0.6354835080261401, 0.595556829867842, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7800577], dtype=float32), 1.2511206]. 
=============================================
[2019-04-06 16:24:18,832] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.9813720e-09 8.7659988e-05 2.9948264e-08 7.2174740e-04 2.5524451e-09
 9.9919051e-01 3.0808355e-08], sum to 1.0000
[2019-04-06 16:24:18,832] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0048
[2019-04-06 16:24:18,998] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.75, 96.0, 0.0, 0.0, 26.0, 24.69624132444284, 0.4427827125320376, 0.0, 1.0, 24265.951339878433], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1276200.0000, 
sim time next is 1278000.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 26.0, 24.69477488338485, 0.4477861460481818, 0.0, 1.0, 34274.35163350787], 
processed observation next is [0.0, 0.8260869565217391, 0.662049861495845, 0.96, 0.0, 0.0, 0.6666666666666666, 0.5578979069487374, 0.6492620486827273, 0.0, 1.0, 0.16321119825479938], 
reward next is 0.8368, 
noisyNet noise sample is [array([1.6333416], dtype=float32), -0.81689435]. 
=============================================
[2019-04-06 16:24:19,057] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[79.719406]
 [80.04637 ]
 [80.46018 ]
 [80.753716]
 [80.989876]], R is [[79.50837708]
 [79.59774017]
 [79.67900085]
 [79.67445374]
 [79.73968506]].
[2019-04-06 16:24:19,820] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.6429865e-06 7.6001039e-04 2.9126422e-06 7.7336214e-02 6.2793241e-08
 9.2189842e-01 7.0234319e-07], sum to 1.0000
[2019-04-06 16:24:19,822] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4413
[2019-04-06 16:24:19,870] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 75.0, 0.0, 0.0, 26.0, 24.14778201160068, 0.04419508165796427, 0.0, 1.0, 45131.03027500277], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1904400.0000, 
sim time next is 1906200.0000, 
raw observation next is [-7.55, 76.5, 0.0, 0.0, 26.0, 24.05550209178518, 0.02241602765477617, 0.0, 1.0, 45190.922818516614], 
processed observation next is [1.0, 0.043478260869565216, 0.25346260387811637, 0.765, 0.0, 0.0, 0.6666666666666666, 0.5046251743154316, 0.5074720092182587, 0.0, 1.0, 0.21519487056436482], 
reward next is 0.7848, 
noisyNet noise sample is [array([-0.04292413], dtype=float32), 0.590346]. 
=============================================
[2019-04-06 16:24:31,058] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2342241e-07 2.4363068e-04 1.3246690e-06 2.6108152e-01 2.0042863e-08
 7.3867315e-01 2.4326141e-07], sum to 1.0000
[2019-04-06 16:24:31,058] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5620
[2019-04-06 16:24:31,474] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 26.0, 25.4116341129438, 0.5165732873313283, 0.0, 1.0, 32211.024856368458], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1321200.0000, 
sim time next is 1323000.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 26.0, 25.62138785328938, 0.5839453896731768, 1.0, 1.0, 18813.463709743406], 
processed observation next is [1.0, 0.30434782608695654, 0.49307479224376743, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6351156544407818, 0.6946484632243922, 1.0, 1.0, 0.08958792242734956], 
reward next is 0.9104, 
noisyNet noise sample is [array([1.2815945], dtype=float32), 1.1903615]. 
=============================================
[2019-04-06 16:24:31,478] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[84.2208 ]
 [84.41096]
 [84.27205]
 [84.11119]
 [84.58776]], R is [[85.02937317]
 [85.02568817]
 [84.83300781]
 [84.77625275]
 [84.89873505]].
[2019-04-06 16:25:24,373] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8327538e-07 1.9419063e-03 5.1237412e-06 2.8155772e-02 7.9027636e-08
 9.6987277e-01 2.4212872e-05], sum to 1.0000
[2019-04-06 16:25:24,373] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5814
[2019-04-06 16:25:24,767] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 77.0, 186.0, 84.0, 26.0, 25.02389119516518, 0.284839190570521, 0.0, 1.0, 40255.04357223123], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1866600.0000, 
sim time next is 1868400.0000, 
raw observation next is [-4.5, 83.0, 129.0, 42.0, 26.0, 25.05680813480531, 0.285637615622056, 0.0, 1.0, 36755.96448324531], 
processed observation next is [0.0, 0.6521739130434783, 0.3379501385041552, 0.83, 0.43, 0.04640883977900553, 0.6666666666666666, 0.5880673445671091, 0.5952125385406853, 0.0, 1.0, 0.17502840230116815], 
reward next is 0.8250, 
noisyNet noise sample is [array([0.22158621], dtype=float32), -0.5966998]. 
=============================================
[2019-04-06 16:26:01,135] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1330552e-07 1.2688789e-03 1.0213790e-06 8.2327053e-02 1.4748738e-07
 9.1640228e-01 5.1431635e-07], sum to 1.0000
[2019-04-06 16:26:01,135] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9582
[2019-04-06 16:26:01,238] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.84461597200549, 0.2886444682916275, 0.0, 1.0, 44997.252550591824], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2763000.0000, 
sim time next is 2764800.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.7323638617833, 0.2635584372672933, 0.0, 1.0, 44136.693718841234], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5610303218152749, 0.587852812422431, 0.0, 1.0, 0.21017473199448206], 
reward next is 0.7898, 
noisyNet noise sample is [array([0.43751547], dtype=float32), 0.85779285]. 
=============================================
[2019-04-06 16:26:13,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3908438e-07 2.7667619e-03 3.2672506e-06 2.2894725e-01 7.3695425e-08
 7.6828086e-01 1.0887392e-06], sum to 1.0000
[2019-04-06 16:26:13,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1448
[2019-04-06 16:26:13,834] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-8.1, 86.5, 0.0, 0.0, 26.0, 24.17360182163461, 0.08459785616029693, 0.0, 1.0, 43687.56456832172], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2259000.0000, 
sim time next is 2260800.0000, 
raw observation next is [-8.4, 87.0, 0.0, 0.0, 26.0, 24.05992734416179, 0.06347764354143509, 0.0, 1.0, 43631.85764805307], 
processed observation next is [1.0, 0.17391304347826086, 0.2299168975069252, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5049939453468157, 0.5211592145138116, 0.0, 1.0, 0.2077707507050146], 
reward next is 0.7922, 
noisyNet noise sample is [array([-1.062383], dtype=float32), -0.18113871]. 
=============================================
[2019-04-06 16:26:13,889] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 16:26:13,890] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:26:13,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:26:13,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run18
[2019-04-06 16:26:13,910] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:26:13,911] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:26:13,913] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run18
[2019-04-06 16:26:13,945] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:26:13,945] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:26:13,948] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run18
[2019-04-06 16:28:38,166] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.8527 79933131.6166 535.2619
[2019-04-06 16:28:56,651] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.7480 87777799.9006 514.6558
[2019-04-06 16:28:58,833] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.5720 91932853.8921 409.3020
[2019-04-06 16:28:59,854] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 340000, evaluation results [340000.0, 2415.7479736968926, 87777799.90060535, 514.6557664922071, 2453.8527000718373, 79933131.6166035, 535.2618562070612, 2396.571995250126, 91932853.89214352, 409.3019501072503]
[2019-04-06 16:29:10,881] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2255624e-07 4.1261650e-04 8.7895029e-07 5.5066757e-02 1.7496917e-07
 9.4451797e-01 1.3503774e-06], sum to 1.0000
[2019-04-06 16:29:10,881] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6402
[2019-04-06 16:29:11,069] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 47.0, 123.0, 170.5, 26.0, 24.93716445702231, 0.3041045039285362, 0.0, 1.0, 39981.424946915125], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2386800.0000, 
sim time next is 2388600.0000, 
raw observation next is [0.0, 47.0, 86.0, 341.0, 26.0, 24.98032339755874, 0.3186798131928667, 0.0, 1.0, 22601.37877314624], 
processed observation next is [0.0, 0.6521739130434783, 0.46260387811634357, 0.47, 0.2866666666666667, 0.37679558011049724, 0.6666666666666666, 0.5816936164632285, 0.6062266043976222, 0.0, 1.0, 0.10762561320545828], 
reward next is 0.8924, 
noisyNet noise sample is [array([-0.8391035], dtype=float32), 0.2660994]. 
=============================================
[2019-04-06 16:29:25,986] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3709105e-07 1.6524948e-04 2.8031886e-07 2.1302624e-02 2.8731995e-09
 9.7853136e-01 3.0414049e-07], sum to 1.0000
[2019-04-06 16:29:25,987] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7584
[2019-04-06 16:29:26,084] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 78.0, 0.0, 0.0, 26.0, 24.50105894423117, 0.1484872762049006, 0.0, 1.0, 42317.115269197], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2606400.0000, 
sim time next is 2608200.0000, 
raw observation next is [-5.9, 80.5, 0.0, 0.0, 26.0, 24.36945552896036, 0.1327234670371795, 0.0, 1.0, 42632.61456498333], 
processed observation next is [1.0, 0.17391304347826086, 0.2991689750692521, 0.805, 0.0, 0.0, 0.6666666666666666, 0.5307879607466965, 0.5442411556790598, 0.0, 1.0, 0.20301245030944443], 
reward next is 0.7970, 
noisyNet noise sample is [array([0.28922537], dtype=float32), 0.052198377]. 
=============================================
[2019-04-06 16:29:43,692] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.9326924e-08 2.6799753e-04 1.4318438e-07 2.4730259e-01 1.6882018e-08
 7.5242883e-01 3.5238693e-07], sum to 1.0000
[2019-04-06 16:29:43,692] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1999
[2019-04-06 16:29:43,764] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-1.5, 81.5, 0.0, 0.0, 26.0, 25.28612346300073, 0.4208359246967084, 0.0, 1.0, 46402.542182432175], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2932200.0000, 
sim time next is 2934000.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 26.0, 25.09895513147076, 0.3913546469154445, 0.0, 1.0, 44206.91940719763], 
processed observation next is [1.0, 1.0, 0.40720221606648205, 0.85, 0.0, 0.0, 0.6666666666666666, 0.59157959428923, 0.6304515489718149, 0.0, 1.0, 0.21050914003427443], 
reward next is 0.7895, 
noisyNet noise sample is [array([0.58993554], dtype=float32), 0.5210935]. 
=============================================
[2019-04-06 16:29:43,787] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[83.77862 ]
 [84.00607 ]
 [84.5562  ]
 [85.527596]
 [85.89839 ]], R is [[84.17354584]
 [84.11084747]
 [84.01933289]
 [84.0220108 ]
 [83.95160675]].
[2019-04-06 16:29:45,864] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:29:45,864] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:29:45,867] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run9
[2019-04-06 16:29:57,805] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.38011367e-07 1.59874838e-02 8.08487641e-07 1.18618906e-01
 1.09052088e-07 8.65390360e-01 2.03243690e-06], sum to 1.0000
[2019-04-06 16:29:57,806] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6944
[2019-04-06 16:29:57,994] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 55.0, 112.5, 811.0, 26.0, 25.03641690837548, 0.3378622108117832, 0.0, 1.0, 34829.511647357394], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3067200.0000, 
sim time next is 3069000.0000, 
raw observation next is [-2.5, 52.5, 114.0, 817.0, 26.0, 25.08222114792523, 0.3566079822579058, 0.0, 1.0, 15740.837764547874], 
processed observation next is [0.0, 0.5217391304347826, 0.39335180055401664, 0.525, 0.38, 0.9027624309392265, 0.6666666666666666, 0.590185095660436, 0.6188693274193019, 0.0, 1.0, 0.07495637030737083], 
reward next is 0.9250, 
noisyNet noise sample is [array([-2.3477848], dtype=float32), -1.2623543]. 
=============================================
[2019-04-06 16:29:58,001] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.22683]
 [71.23448]
 [71.06474]
 [70.68932]
 [70.14959]], R is [[71.66123199]
 [71.77876282]
 [72.06097412]
 [72.12934113]
 [72.40805054]].
[2019-04-06 16:30:09,295] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.8547818e-09 2.9132370e-04 6.6167826e-07 2.3167664e-01 1.4860510e-08
 7.6803118e-01 2.2296582e-07], sum to 1.0000
[2019-04-06 16:30:09,308] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0467
[2019-04-06 16:30:09,353] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-0.5, 75.0, 0.0, 0.0, 26.0, 25.92037956262328, 0.6035268306385627, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3533400.0000, 
sim time next is 3535200.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 26.0, 25.78850703776746, 0.5639896626371925, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4349030470914128, 0.78, 0.0, 0.0, 0.6666666666666666, 0.6490422531472883, 0.6879965542123975, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.493063], dtype=float32), -1.4305147]. 
=============================================
[2019-04-06 16:30:09,753] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5104479e-09 1.8840903e-04 8.7772754e-08 5.1143844e-02 2.9513949e-09
 9.4866765e-01 1.5956489e-08], sum to 1.0000
[2019-04-06 16:30:09,753] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3913
[2019-04-06 16:30:09,854] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 52.0, 114.0, 800.0, 26.0, 26.00723200250915, 0.5800729919039723, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3331800.0000, 
sim time next is 3333600.0000, 
raw observation next is [-4.0, 50.0, 110.0, 776.0, 26.0, 25.73024404469379, 0.5232023892210799, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3518005540166205, 0.5, 0.36666666666666664, 0.8574585635359117, 0.6666666666666666, 0.6441870037244826, 0.6744007964070265, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1078004], dtype=float32), 1.4037373]. 
=============================================
[2019-04-06 16:30:20,172] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3164274e-07 1.3963602e-03 8.0364171e-06 5.6751933e-02 1.0119039e-07
 9.4184244e-01 5.7889196e-07], sum to 1.0000
[2019-04-06 16:30:20,173] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4983
[2019-04-06 16:30:20,221] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-16.2, 78.0, 0.0, 0.0, 26.0, 21.90715070334919, -0.4508103619597377, 0.0, 1.0, 48661.99583914641], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 367200.0000, 
sim time next is 369000.0000, 
raw observation next is [-16.2, 78.0, 0.0, 0.0, 26.0, 21.80754624491719, -0.4697822219495657, 0.0, 1.0, 48937.13790738505], 
processed observation next is [1.0, 0.2608695652173913, 0.013850415512465375, 0.78, 0.0, 0.0, 0.6666666666666666, 0.3172955204097659, 0.3434059260168114, 0.0, 1.0, 0.2330339900351669], 
reward next is 0.7670, 
noisyNet noise sample is [array([0.9773218], dtype=float32), 0.2874602]. 
=============================================
[2019-04-06 16:30:20,228] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.17882 ]
 [67.320015]
 [67.52347 ]
 [67.792755]
 [68.049644]], R is [[67.15689087]
 [67.25360107]
 [67.34952545]
 [67.44158173]
 [67.53209686]].
[2019-04-06 16:30:22,342] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.9468217e-10 6.2345884e-05 8.5041229e-08 2.8697890e-03 4.3033424e-10
 9.9706775e-01 1.8363449e-08], sum to 1.0000
[2019-04-06 16:30:22,343] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3517
[2019-04-06 16:30:22,408] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 60.0, 117.0, 822.0, 26.0, 26.49430718695409, 0.6395277116563579, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3843000.0000, 
sim time next is 3844800.0000, 
raw observation next is [-1.0, 60.0, 117.0, 828.5, 26.0, 26.5895647883959, 0.661326321682878, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4349030470914128, 0.6, 0.39, 0.9154696132596685, 0.6666666666666666, 0.7157970656996584, 0.720442107227626, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3481386], dtype=float32), -0.11485267]. 
=============================================
[2019-04-06 16:30:41,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2680503e-07 1.6356421e-03 1.1981942e-06 1.9581964e-02 1.5575607e-08
 9.7878039e-01 6.9481604e-07], sum to 1.0000
[2019-04-06 16:30:41,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5665
[2019-04-06 16:30:42,033] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 30.0, 0.0, 0.0, 26.0, 25.62586784166809, 0.4893836376863798, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4051800.0000, 
sim time next is 4053600.0000, 
raw observation next is [-5.0, 31.0, 0.0, 0.0, 26.0, 25.44573811787602, 0.4721519869198841, 0.0, 1.0, 62709.78886389779], 
processed observation next is [1.0, 0.9565217391304348, 0.32409972299168976, 0.31, 0.0, 0.0, 0.6666666666666666, 0.6204781764896682, 0.6573839956399613, 0.0, 1.0, 0.2986180422090371], 
reward next is 0.7014, 
noisyNet noise sample is [array([0.4183572], dtype=float32), -0.96927834]. 
=============================================
[2019-04-06 16:30:46,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:30:46,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:30:46,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run9
[2019-04-06 16:31:03,267] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2649185e-07 2.3896908e-03 2.8214006e-06 1.3328496e-01 1.6310267e-07
 8.6432201e-01 5.5540429e-08], sum to 1.0000
[2019-04-06 16:31:03,267] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3512
[2019-04-06 16:31:03,386] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 43.0, 0.0, 0.0, 26.0, 25.32386740851987, 0.4614986836231901, 0.0, 1.0, 104126.58620486768], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4143600.0000, 
sim time next is 4145400.0000, 
raw observation next is [-0.5, 42.5, 0.0, 0.0, 26.0, 25.44875557148053, 0.4620280820493912, 0.0, 1.0, 27710.84210281276], 
processed observation next is [1.0, 1.0, 0.44875346260387816, 0.425, 0.0, 0.0, 0.6666666666666666, 0.6207296309567107, 0.6540093606831304, 0.0, 1.0, 0.13195639096577505], 
reward next is 0.8680, 
noisyNet noise sample is [array([0.71947896], dtype=float32), -0.51581764]. 
=============================================
[2019-04-06 16:31:07,169] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6741154e-07 9.9365157e-04 1.3499277e-06 4.4731855e-01 7.4659908e-08
 5.5168426e-01 1.8574824e-06], sum to 1.0000
[2019-04-06 16:31:07,169] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3129
[2019-04-06 16:31:07,185] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [8.25, 27.5, 0.0, 0.0, 26.0, 25.93549276288753, 0.5559143171089902, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5095800.0000, 
sim time next is 5097600.0000, 
raw observation next is [8.1, 35.0, 0.0, 0.0, 26.0, 25.75533414097265, 0.5119989677760163, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.0, 0.6869806094182825, 0.35, 0.0, 0.0, 0.6666666666666666, 0.6462778450810541, 0.6706663225920054, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4327066], dtype=float32), -1.9084986]. 
=============================================
[2019-04-06 16:31:07,441] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:31:07,441] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:31:07,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run9
[2019-04-06 16:31:08,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:31:08,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:31:08,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run9
[2019-04-06 16:31:08,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:31:08,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:31:08,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run9
[2019-04-06 16:31:23,990] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.795845]
 [75.08799 ]], R is [[1.  ]
 [1.99]].
[2019-04-06 16:31:29,177] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 16:31:29,178] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:31:29,178] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:31:29,192] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run19
[2019-04-06 16:31:29,332] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:31:29,332] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:31:29,346] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run19
[2019-04-06 16:31:29,402] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:31:29,403] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:31:29,405] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run19
[2019-04-06 16:31:44,893] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.02528786], dtype=float32), 0.11077916]
[2019-04-06 16:31:44,893] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-5.646859253500001, 74.33108192, 194.3593645, 145.6539674, 26.0, 25.14787395546285, 0.2907773248139742, 1.0, 1.0, 62014.786988050735]
[2019-04-06 16:31:44,893] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 16:31:44,895] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [4.73846846e-08 3.01417516e-04 1.24553623e-07 1.44705465e-02
 1.56475526e-08 9.85227704e-01 1.47329942e-07], sampled 0.7556863388356994
[2019-04-06 16:33:11,633] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.02528786], dtype=float32), 0.11077916]
[2019-04-06 16:33:11,633] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [2.3, 67.0, 165.5, 226.5, 26.0, 26.08426949473338, 0.5341931602687171, 1.0, 1.0, 0.0]
[2019-04-06 16:33:11,633] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:33:11,634] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.3094307e-08 1.6976657e-04 5.0611977e-08 1.1033072e-02 6.3661307e-09
 9.8879695e-01 6.7448759e-08], sampled 0.9164365478953597
[2019-04-06 16:33:42,022] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.02528786], dtype=float32), 0.11077916]
[2019-04-06 16:33:42,023] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [0.647422801, 76.73938663, 0.0, 0.0, 26.0, 25.40818494325122, 0.4087975649978974, 0.0, 1.0, 31063.00264619733]
[2019-04-06 16:33:42,023] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 16:33:42,023] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [7.9713523e-08 5.0167413e-04 3.7943485e-07 1.8473374e-02 2.9269367e-08
 9.8102415e-01 3.2363420e-07], sampled 0.9431343984406639
[2019-04-06 16:33:47,586] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.8034 79991956.7854 535.1864
[2019-04-06 16:34:06,929] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.2160 87794384.7162 515.1643
[2019-04-06 16:34:08,933] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2891 91944900.5891 409.3749
[2019-04-06 16:34:09,954] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 360000, evaluation results [360000.0, 2416.215983275552, 87794384.71615136, 515.1643021633942, 2453.803381032483, 79991956.78540477, 535.1864255395496, 2396.2891096038065, 91944900.58913434, 409.3749352301794]
[2019-04-06 16:34:10,473] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.1552705e-08 3.4619260e-04 1.9091058e-07 4.2721881e-03 7.2893669e-09
 9.9538124e-01 6.3885352e-08], sum to 1.0000
[2019-04-06 16:34:10,473] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9328
[2019-04-06 16:34:10,560] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 62.0, 0.0, 0.0, 26.0, 25.48363254602915, 0.4690355008461591, 0.0, 1.0, 54335.732269538894], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4672800.0000, 
sim time next is 4674600.0000, 
raw observation next is [2.0, 62.0, 0.0, 0.0, 26.0, 25.6177399148885, 0.497646731526185, 0.0, 1.0, 34784.940182106046], 
processed observation next is [1.0, 0.08695652173913043, 0.518005540166205, 0.62, 0.0, 0.0, 0.6666666666666666, 0.6348116595740416, 0.6658822438420616, 0.0, 1.0, 0.16564257229574308], 
reward next is 0.8344, 
noisyNet noise sample is [array([0.39806908], dtype=float32), 0.6158838]. 
=============================================
[2019-04-06 16:34:12,133] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5702414e-09 1.0501457e-05 8.0290681e-09 5.9451535e-03 4.0518472e-10
 9.9404436e-01 2.7307852e-08], sum to 1.0000
[2019-04-06 16:34:12,133] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8622
[2019-04-06 16:34:12,224] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 50.0, 127.0, 0.0, 26.0, 26.08204985176587, 0.4949678431727944, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4537800.0000, 
sim time next is 4539600.0000, 
raw observation next is [2.0, 52.0, 187.0, 24.0, 26.0, 25.74173473354739, 0.3669781948200848, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.518005540166205, 0.52, 0.6233333333333333, 0.026519337016574586, 0.6666666666666666, 0.6451445611289491, 0.6223260649400283, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.39345133], dtype=float32), 1.7237154]. 
=============================================
[2019-04-06 16:34:23,618] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:34:23,619] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:34:23,622] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run9
[2019-04-06 16:34:32,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:34:32,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:34:32,301] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run9
[2019-04-06 16:34:32,696] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:34:32,696] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:34:32,710] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run9
[2019-04-06 16:34:32,879] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:34:32,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:34:32,883] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run9
[2019-04-06 16:34:37,327] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:34:37,327] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:34:37,351] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run9
[2019-04-06 16:34:38,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:34:38,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:34:38,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run9
[2019-04-06 16:34:39,412] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:34:39,423] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:34:39,427] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run9
[2019-04-06 16:34:39,755] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:34:39,755] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:34:39,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run9
[2019-04-06 16:34:41,334] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:34:41,334] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:34:41,338] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run9
[2019-04-06 16:34:41,382] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:34:41,382] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:34:41,386] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run9
[2019-04-06 16:34:42,162] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:34:42,162] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:34:42,166] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run9
[2019-04-06 16:34:51,360] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0700710e-07 9.5449196e-04 3.9775239e-07 1.7358679e-02 2.3406873e-08
 9.8168576e-01 3.9738003e-07], sum to 1.0000
[2019-04-06 16:34:51,360] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9739
[2019-04-06 16:34:51,399] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.1, 67.0, 0.0, 0.0, 26.0, 25.02646061907004, 0.2199066901648537, 0.0, 1.0, 43214.548980145286], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 678600.0000, 
sim time next is 680400.0000, 
raw observation next is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.95621280847466, 0.2059363531815844, 0.0, 1.0, 42444.25972710476], 
processed observation next is [0.0, 0.9130434782608695, 0.368421052631579, 0.69, 0.0, 0.0, 0.6666666666666666, 0.5796844007062217, 0.5686454510605281, 0.0, 1.0, 0.20211552251002268], 
reward next is 0.7979, 
noisyNet noise sample is [array([1.2031422], dtype=float32), -0.29839608]. 
=============================================
[2019-04-06 16:36:10,863] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.2539700e-08 8.6507353e-04 1.7535781e-08 4.5941271e-02 5.6763614e-08
 9.5319319e-01 3.0215878e-07], sum to 1.0000
[2019-04-06 16:36:10,863] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2927
[2019-04-06 16:36:11,142] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.35, 73.0, 87.0, 0.0, 26.0, 25.643273063073, 0.2898477204121061, 1.0, 1.0, 20289.451370652812], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 815400.0000, 
sim time next is 817200.0000, 
raw observation next is [-4.5, 71.0, 98.5, 0.0, 26.0, 25.6036748028863, 0.2981830232050141, 1.0, 1.0, 19290.86808979666], 
processed observation next is [1.0, 0.4782608695652174, 0.3379501385041552, 0.71, 0.3283333333333333, 0.0, 0.6666666666666666, 0.6336395669071916, 0.5993943410683381, 1.0, 1.0, 0.09186127661807933], 
reward next is 0.9081, 
noisyNet noise sample is [array([0.04494767], dtype=float32), -0.039384745]. 
=============================================
[2019-04-06 16:36:26,225] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.30819760e-09 1.68201543e-04 6.88437751e-09 4.18900466e-03
 4.08885037e-10 9.95642662e-01 1.06261325e-07], sum to 1.0000
[2019-04-06 16:36:26,225] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2983
[2019-04-06 16:36:26,329] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 96.0, 0.0, 0.0, 26.0, 25.17542196720087, 0.398189473813938, 0.0, 1.0, 39960.39999397271], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 943200.0000, 
sim time next is 945000.0000, 
raw observation next is [5.0, 96.0, 0.0, 0.0, 26.0, 25.20718371499349, 0.4033737966205865, 0.0, 1.0, 39416.727109913525], 
processed observation next is [1.0, 0.9565217391304348, 0.6011080332409973, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6005986429161242, 0.6344579322068622, 0.0, 1.0, 0.18769870052339774], 
reward next is 0.8123, 
noisyNet noise sample is [array([-0.77079964], dtype=float32), 2.2049494]. 
=============================================
[2019-04-06 16:36:26,345] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[86.90632 ]
 [87.250084]
 [86.45452 ]
 [87.613335]
 [86.97168 ]], R is [[87.03570557]
 [86.97506714]
 [86.91137695]
 [86.80200958]
 [86.42723846]].
[2019-04-06 16:36:33,513] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.2565402e-09 1.9572049e-05 9.4694608e-10 4.5896852e-03 1.9704720e-09
 9.9539077e-01 2.4168219e-08], sum to 1.0000
[2019-04-06 16:36:33,514] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1138
[2019-04-06 16:36:33,598] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.95, 79.5, 0.0, 0.0, 26.0, 26.55035580718764, 0.6485726634314323, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1013400.0000, 
sim time next is 1015200.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 26.0, 26.08880203670217, 0.5706335839835012, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.8614958448753465, 0.81, 0.0, 0.0, 0.6666666666666666, 0.6740668363918475, 0.690211194661167, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.9893417], dtype=float32), -0.008010994]. 
=============================================
[2019-04-06 16:37:17,384] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2166629e-09 7.6976110e-05 9.1689989e-09 5.9912249e-02 6.3342515e-10
 9.4001073e-01 5.1120672e-08], sum to 1.0000
[2019-04-06 16:37:17,385] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6496
[2019-04-06 16:37:17,496] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.25, 59.0, 0.0, 0.0, 26.0, 26.69498067541669, 0.67790894166669, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1531800.0000, 
sim time next is 1533600.0000, 
raw observation next is [10.0, 60.0, 0.0, 0.0, 26.0, 26.37819820007794, 0.7009120979463281, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.739612188365651, 0.6, 0.0, 0.0, 0.6666666666666666, 0.6981831833398283, 0.7336373659821094, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7189105], dtype=float32), 0.26570067]. 
=============================================
[2019-04-06 16:37:21,249] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-06 16:37:21,266] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:37:21,266] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:37:21,268] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run20
[2019-04-06 16:37:21,355] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:37:21,357] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:37:21,359] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run20
[2019-04-06 16:37:21,444] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:37:21,444] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:37:21,446] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run20
[2019-04-06 16:39:42,964] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.6368 79991956.7854 535.1864
[2019-04-06 16:40:02,684] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.6084 87824056.8254 516.5307
[2019-04-06 16:40:04,709] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.6152 91928833.8001 409.0865
[2019-04-06 16:40:05,731] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 380000, evaluation results [380000.0, 2415.608375354548, 87824056.82538112, 516.530723766998, 2453.636826180812, 79991956.78540477, 535.1864255395496, 2396.6152098938037, 91928833.80011736, 409.0865248877264]
[2019-04-06 16:40:12,569] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3244637e-07 2.4001061e-03 5.8182985e-07 2.7024385e-01 4.6684249e-07
 7.2735411e-01 6.0672460e-07], sum to 1.0000
[2019-04-06 16:40:12,570] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3821
[2019-04-06 16:40:12,771] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 85.0, 99.0, 0.0, 26.0, 24.96520802652209, 0.3382100961755444, 0.0, 1.0, 51449.57433786411], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1780200.0000, 
sim time next is 1782000.0000, 
raw observation next is [-2.8, 87.0, 82.5, 0.0, 26.0, 24.98251051612204, 0.346242458642291, 0.0, 1.0, 46540.95738867189], 
processed observation next is [0.0, 0.6521739130434783, 0.38504155124653744, 0.87, 0.275, 0.0, 0.6666666666666666, 0.5818758763435034, 0.6154141528807636, 0.0, 1.0, 0.2216236066127233], 
reward next is 0.7784, 
noisyNet noise sample is [array([2.626984], dtype=float32), 2.1905568]. 
=============================================
[2019-04-06 16:40:12,799] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.40614]
 [74.55179]
 [74.87717]
 [75.14104]
 [75.12552]], R is [[74.19309235]
 [74.20616913]
 [74.35540009]
 [74.38331604]
 [74.50253296]].
[2019-04-06 16:40:26,576] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6951612e-08 1.7879449e-05 1.3723278e-08 6.0029984e-03 2.4051947e-09
 9.9397898e-01 1.1556187e-07], sum to 1.0000
[2019-04-06 16:40:26,577] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9307
[2019-04-06 16:40:26,694] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.65, 63.5, 137.0, 0.0, 26.0, 25.54633656131591, 0.3306396502598146, 1.0, 1.0, 22865.421125049743], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1949400.0000, 
sim time next is 1951200.0000, 
raw observation next is [-3.4, 62.0, 124.5, 0.0, 26.0, 25.74436302516578, 0.3451961188619516, 1.0, 1.0, 15370.05330874514], 
processed observation next is [1.0, 0.6086956521739131, 0.368421052631579, 0.62, 0.415, 0.0, 0.6666666666666666, 0.6453635854304816, 0.6150653729539839, 1.0, 1.0, 0.07319073004164353], 
reward next is 0.9268, 
noisyNet noise sample is [array([0.9858532], dtype=float32), -0.48173502]. 
=============================================
[2019-04-06 16:40:32,580] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.3370183e-08 2.8378723e-04 5.9529434e-08 5.0875300e-01 1.3978455e-08
 4.9096295e-01 1.4693545e-07], sum to 1.0000
[2019-04-06 16:40:32,581] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0924
[2019-04-06 16:40:32,829] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-5.0, 72.5, 0.0, 0.0, 26.0, 25.9151276654384, 0.4684589302436604, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2140200.0000, 
sim time next is 2142000.0000, 
raw observation next is [-5.0, 74.0, 0.0, 0.0, 26.0, 25.51222367326598, 0.4275946573942078, 1.0, 1.0, 6239.044457127897], 
processed observation next is [1.0, 0.8260869565217391, 0.32409972299168976, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6260186394388315, 0.6425315524647359, 1.0, 1.0, 0.029709735510132843], 
reward next is 0.9703, 
noisyNet noise sample is [array([-0.28575036], dtype=float32), 0.92822456]. 
=============================================
[2019-04-06 16:40:32,833] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[81.96856 ]
 [82.31534 ]
 [81.767426]
 [82.058624]
 [82.39966 ]], R is [[82.26700592]
 [82.44433594]
 [81.98762512]
 [82.02333069]
 [82.20309448]].
[2019-04-06 16:40:45,380] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1428129e-08 4.3845601e-05 1.5870452e-07 1.1612125e-02 5.4521578e-09
 9.8834372e-01 7.1681789e-08], sum to 1.0000
[2019-04-06 16:40:45,380] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6664
[2019-04-06 16:40:45,702] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.75, 66.5, 86.0, 0.0, 26.0, 26.23143363261792, 0.4832101305465199, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2129400.0000, 
sim time next is 2131200.0000, 
raw observation next is [-4.5, 65.0, 56.0, 0.0, 26.0, 24.85993739196615, 0.3745897238052687, 1.0, 1.0, 91354.96769544568], 
processed observation next is [1.0, 0.6956521739130435, 0.3379501385041552, 0.65, 0.18666666666666668, 0.0, 0.6666666666666666, 0.5716614493305124, 0.6248632412684229, 1.0, 1.0, 0.4350236556925985], 
reward next is 0.5650, 
noisyNet noise sample is [array([0.749266], dtype=float32), -1.5511439]. 
=============================================
[2019-04-06 16:40:47,670] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6280422e-08 2.9164378e-04 1.5001235e-07 1.5492306e-02 7.1432216e-09
 9.8421580e-01 1.2178739e-07], sum to 1.0000
[2019-04-06 16:40:47,671] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4043
[2019-04-06 16:40:47,758] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 26.0, 24.70190838251716, 0.2351849390202091, 0.0, 1.0, 38820.81243419496], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2340000.0000, 
sim time next is 2341800.0000, 
raw observation next is [-2.3, 62.0, 0.0, 0.0, 26.0, 24.72690218128972, 0.2265365186498923, 0.0, 1.0, 39080.34543889879], 
processed observation next is [0.0, 0.08695652173913043, 0.3988919667590028, 0.62, 0.0, 0.0, 0.6666666666666666, 0.5605751817741433, 0.5755121728832974, 0.0, 1.0, 0.18609688304237518], 
reward next is 0.8139, 
noisyNet noise sample is [array([0.46341038], dtype=float32), 0.8721981]. 
=============================================
[2019-04-06 16:41:06,366] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.95055315e-07 2.80480646e-03 2.31404144e-07 4.91683930e-02
 1.14423315e-07 9.48025346e-01 7.54341670e-07], sum to 1.0000
[2019-04-06 16:41:06,366] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0030
[2019-04-06 16:41:06,429] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-1.0, 96.0, 0.0, 0.0, 26.0, 25.46850402106184, 0.346091826324633, 0.0, 1.0, 20113.924353692517], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3097800.0000, 
sim time next is 3099600.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.36092268538857, 0.343598101555377, 0.0, 1.0, 65782.84450803], 
processed observation next is [0.0, 0.9130434782608695, 0.4349030470914128, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6134102237823807, 0.614532700518459, 0.0, 1.0, 0.31325164051442855], 
reward next is 0.6867, 
noisyNet noise sample is [array([-0.68839836], dtype=float32), 0.9519798]. 
=============================================
[2019-04-06 16:41:09,082] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.5362244e-11 3.7354726e-05 4.5083348e-10 1.1510846e-03 3.2116110e-10
 9.9881160e-01 4.5031268e-10], sum to 1.0000
[2019-04-06 16:41:09,082] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9291
[2019-04-06 16:41:09,177] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.0, 100.0, 33.0, 307.5, 26.0, 27.61536287044544, 0.9760002371542661, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3171600.0000, 
sim time next is 3173400.0000, 
raw observation next is [6.0, 100.0, 8.0, 116.0, 26.0, 27.24165300982388, 0.8478160968316354, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.6288088642659281, 1.0, 0.02666666666666667, 0.1281767955801105, 0.6666666666666666, 0.7701377508186568, 0.7826053656105452, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.28174937], dtype=float32), -0.46686783]. 
=============================================
[2019-04-06 16:41:20,694] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.8101623e-08 2.1886890e-04 1.3800511e-07 3.7220508e-02 3.2038695e-08
 9.6256006e-01 3.2268602e-07], sum to 1.0000
[2019-04-06 16:41:20,695] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4885
[2019-04-06 16:41:20,776] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 65.0, 0.0, 0.0, 26.0, 25.36226522974282, 0.4588503715614802, 0.0, 1.0, 56502.969629349594], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2667600.0000, 
sim time next is 2669400.0000, 
raw observation next is [-2.15, 67.0, 0.0, 0.0, 26.0, 25.46140667707178, 0.4427867433000333, 0.0, 1.0, 16645.27805186849], 
processed observation next is [1.0, 0.9130434782608695, 0.4030470914127424, 0.67, 0.0, 0.0, 0.6666666666666666, 0.6217838897559815, 0.6475955811000111, 0.0, 1.0, 0.07926322881842138], 
reward next is 0.9207, 
noisyNet noise sample is [array([0.22311053], dtype=float32), 0.80905735]. 
=============================================
[2019-04-06 16:41:31,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:41:31,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:41:31,584] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run10
[2019-04-06 16:42:00,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1722419e-08 2.9774537e-04 1.5709608e-07 6.2529586e-04 1.0457697e-08
 9.9907660e-01 8.2065277e-08], sum to 1.0000
[2019-04-06 16:42:00,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5086
[2019-04-06 16:42:00,958] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 45.0, 0.0, 0.0, 26.0, 25.38181243764518, 0.3409264530193248, 0.0, 1.0, 43023.92526381458], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4244400.0000, 
sim time next is 4246200.0000, 
raw observation next is [3.0, 45.0, 0.0, 0.0, 26.0, 25.41629652291917, 0.3386477187264487, 0.0, 1.0, 32665.608098990957], 
processed observation next is [0.0, 0.13043478260869565, 0.5457063711911359, 0.45, 0.0, 0.0, 0.6666666666666666, 0.618024710243264, 0.6128825729088162, 0.0, 1.0, 0.1555505147570998], 
reward next is 0.8444, 
noisyNet noise sample is [array([0.24933615], dtype=float32), 1.9462489]. 
=============================================
[2019-04-06 16:42:29,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3714390e-08 8.1031918e-05 2.0677428e-08 8.3723441e-03 6.7588961e-09
 9.9154657e-01 3.5099706e-08], sum to 1.0000
[2019-04-06 16:42:29,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3177
[2019-04-06 16:42:29,184] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 79.0, 0.0, 0.0, 26.0, 25.52304570007948, 0.4316777886790957, 0.0, 1.0, 8691.555673588946], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3463200.0000, 
sim time next is 3465000.0000, 
raw observation next is [1.0, 75.5, 0.0, 0.0, 26.0, 25.40353631335341, 0.429566570499933, 0.0, 1.0, 69402.19480999482], 
processed observation next is [1.0, 0.08695652173913043, 0.4903047091412743, 0.755, 0.0, 0.0, 0.6666666666666666, 0.6169613594461175, 0.643188856833311, 0.0, 1.0, 0.3304866419523563], 
reward next is 0.6695, 
noisyNet noise sample is [array([1.3693566], dtype=float32), -0.13861619]. 
=============================================
[2019-04-06 16:42:29,192] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[83.307976]
 [83.352325]
 [83.677925]
 [84.01704 ]
 [83.85607 ]], R is [[82.76737213]
 [82.8983078 ]
 [82.88939667]
 [82.88580322]
 [82.92041779]].
[2019-04-06 16:42:44,398] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8119846e-09 6.3395116e-04 1.3416367e-08 7.7683991e-01 5.4929643e-09
 2.2252603e-01 1.0333089e-07], sum to 1.0000
[2019-04-06 16:42:44,398] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2538
[2019-04-06 16:42:44,508] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [3.0, 49.0, 37.5, 338.0, 26.0, 26.55110770653898, 0.6863401346980001, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3517200.0000, 
sim time next is 3519000.0000, 
raw observation next is [2.5, 50.5, 13.0, 151.0, 26.0, 26.41088023992873, 0.5897358280233959, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5318559556786704, 0.505, 0.043333333333333335, 0.16685082872928178, 0.6666666666666666, 0.7009066866607275, 0.6965786093411319, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.04612485], dtype=float32), 0.19920811]. 
=============================================
[2019-04-06 16:42:44,512] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[83.23184]
 [84.09239]
 [84.5601 ]
 [85.22162]
 [85.54155]], R is [[82.3477478 ]
 [82.5242691 ]
 [82.69902802]
 [82.87203979]
 [83.01367188]].
[2019-04-06 16:43:03,401] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 16:43:03,420] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:43:03,420] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:43:03,445] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:43:03,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:43:03,447] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run21
[2019-04-06 16:43:03,492] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:43:03,492] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:43:03,494] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run21
[2019-04-06 16:43:03,554] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run21
[2019-04-06 16:45:19,990] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.0234 79899447.0836 535.5664
[2019-04-06 16:45:38,781] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2782 91926150.9563 409.7703
[2019-04-06 16:45:39,533] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.9731 87803285.7563 514.7094
[2019-04-06 16:45:40,555] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 400000, evaluation results [400000.0, 2415.973079029552, 87803285.7563282, 514.7094491225716, 2454.023389615132, 79899447.08359534, 535.5664149093349, 2396.2782471077417, 91926150.95632724, 409.7703098520023]
[2019-04-06 16:45:44,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:45:44,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:45:44,618] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run10
[2019-04-06 16:45:54,080] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4046322e-08 3.9768052e-05 1.5430176e-08 6.5268110e-03 4.6169859e-09
 9.9343336e-01 1.7737378e-08], sum to 1.0000
[2019-04-06 16:45:54,081] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4288
[2019-04-06 16:45:54,154] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.25, 73.0, 0.0, 0.0, 26.0, 25.7853651542548, 0.4747755927121395, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4307400.0000, 
sim time next is 4309200.0000, 
raw observation next is [5.1, 73.0, 0.0, 0.0, 26.0, 25.78375704763455, 0.4502270529119898, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.6038781163434903, 0.73, 0.0, 0.0, 0.6666666666666666, 0.6486464206362124, 0.6500756843039966, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6618268], dtype=float32), 0.18772754]. 
=============================================
[2019-04-06 16:45:57,536] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:45:57,536] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:45:57,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run10
[2019-04-06 16:45:59,903] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:45:59,903] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:45:59,907] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run10
[2019-04-06 16:46:00,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:46:00,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:46:00,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run10
[2019-04-06 16:46:23,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:46:23,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:46:23,056] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run10
[2019-04-06 16:46:31,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:46:31,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:46:31,548] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run10
[2019-04-06 16:46:32,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:46:32,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:46:32,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run10
[2019-04-06 16:46:33,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:46:33,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:46:33,673] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run10
[2019-04-06 16:46:38,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:46:38,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:46:38,174] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run10
[2019-04-06 16:46:39,668] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.56762849e-08 2.77006067e-04 1.07548146e-07 8.93133432e-02
 1.04125178e-07 9.10408735e-01 6.26635483e-07], sum to 1.0000
[2019-04-06 16:46:39,668] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4642
[2019-04-06 16:46:39,734] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.65, 86.5, 0.0, 0.0, 26.0, 24.5236715339534, 0.1730076792756635, 0.0, 1.0, 42279.57909869374], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 606600.0000, 
sim time next is 608400.0000, 
raw observation next is [-3.9, 86.0, 0.0, 0.0, 26.0, 24.46377126457555, 0.1531159267595269, 0.0, 1.0, 42189.00729246616], 
processed observation next is [0.0, 0.043478260869565216, 0.3545706371191136, 0.86, 0.0, 0.0, 0.6666666666666666, 0.5386476053812957, 0.5510386422531757, 0.0, 1.0, 0.20090003472602933], 
reward next is 0.7991, 
noisyNet noise sample is [array([-1.2074213], dtype=float32), -0.5983715]. 
=============================================
[2019-04-06 16:46:40,742] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:46:40,743] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:46:40,746] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run10
[2019-04-06 16:46:44,530] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:46:44,530] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:46:44,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run10
[2019-04-06 16:46:45,447] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:46:45,447] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:46:45,450] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run10
[2019-04-06 16:46:45,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:46:45,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:46:45,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run10
[2019-04-06 16:46:49,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:46:49,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:46:49,334] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run10
[2019-04-06 16:46:49,396] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:46:49,396] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:46:49,400] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run10
[2019-04-06 16:47:12,789] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0180014e-07 8.9566493e-05 5.1935677e-07 2.8242685e-02 1.1228851e-08
 9.7166699e-01 1.6798002e-07], sum to 1.0000
[2019-04-06 16:47:12,790] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9929
[2019-04-06 16:47:12,845] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.9, 85.0, 0.0, 0.0, 26.0, 24.37618060937896, 0.1664459118544107, 0.0, 1.0, 42431.62904752074], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1989000.0000, 
sim time next is 1990800.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.34865421782067, 0.1508961795616905, 0.0, 1.0, 42111.12212028597], 
processed observation next is [1.0, 0.043478260869565216, 0.2908587257617729, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5290545181517224, 0.5502987265205636, 0.0, 1.0, 0.2005291529537427], 
reward next is 0.7995, 
noisyNet noise sample is [array([1.458022], dtype=float32), -0.01987857]. 
=============================================
[2019-04-06 16:47:40,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0295714e-08 1.7770730e-04 2.5226092e-07 2.5220459e-02 8.2332932e-08
 9.7460133e-01 5.8237422e-08], sum to 1.0000
[2019-04-06 16:47:40,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8641
[2019-04-06 16:47:40,982] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 60.0, 0.0, 0.0, 26.0, 25.80006643502578, 0.6585828730586667, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1108800.0000, 
sim time next is 1110600.0000, 
raw observation next is [13.55, 61.0, 0.0, 0.0, 26.0, 25.63610964779359, 0.6736127673441131, 0.0, 1.0, 113046.28356057091], 
processed observation next is [1.0, 0.8695652173913043, 0.8379501385041552, 0.61, 0.0, 0.0, 0.6666666666666666, 0.6363424706494657, 0.7245375891147043, 0.0, 1.0, 0.5383156360027186], 
reward next is 0.4617, 
noisyNet noise sample is [array([0.59940743], dtype=float32), 0.012260234]. 
=============================================
[2019-04-06 16:48:15,997] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.5881313e-10 6.0962434e-06 1.7343540e-09 4.6375105e-03 2.4429206e-10
 9.9535638e-01 1.5881690e-10], sum to 1.0000
[2019-04-06 16:48:15,997] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1011
[2019-04-06 16:48:16,138] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.7, 53.0, 149.0, 124.0, 26.0, 27.21915923153279, 0.7207054413119707, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1600200.0000, 
sim time next is 1602000.0000, 
raw observation next is [13.8, 49.0, 162.5, 62.0, 26.0, 26.32359755233874, 0.7420907349572793, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.844875346260388, 0.49, 0.5416666666666666, 0.06850828729281767, 0.6666666666666666, 0.6936331293615616, 0.7473635783190931, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.39345014], dtype=float32), -1.2109174]. 
=============================================
[2019-04-06 16:48:16,142] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[89.87758 ]
 [90.298   ]
 [90.430275]
 [89.69032 ]
 [88.991196]], R is [[89.32289886]
 [89.42967224]
 [89.5353775 ]
 [89.64002228]
 [89.74362183]].
[2019-04-06 16:48:24,448] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.3377462e-09 2.3436967e-06 4.6863402e-10 6.0555461e-04 4.9071202e-11
 9.9939203e-01 7.1449435e-10], sum to 1.0000
[2019-04-06 16:48:24,448] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1082
[2019-04-06 16:48:24,587] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 26.0, 25.45296846620495, 0.5459771931962883, 0.0, 1.0, 82405.7852350461], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1717200.0000, 
sim time next is 1719000.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 26.0, 25.53800174805895, 0.5518448503889042, 0.0, 1.0, 21461.126807993904], 
processed observation next is [1.0, 0.9130434782608695, 0.4764542936288089, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6281668123382458, 0.6839482834629681, 0.0, 1.0, 0.10219584194282812], 
reward next is 0.8978, 
noisyNet noise sample is [array([-0.75326186], dtype=float32), 0.80678415]. 
=============================================
[2019-04-06 16:48:24,598] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[87.76443 ]
 [86.596214]
 [86.96647 ]
 [87.25991 ]
 [87.42698 ]], R is [[87.01905823]
 [86.75645447]
 [86.70751953]
 [86.84044647]
 [86.84469604]].
[2019-04-06 16:48:31,276] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.2752808e-09 3.9026057e-05 2.1687150e-08 1.5459406e-02 3.5098120e-09
 9.8450154e-01 2.5881274e-08], sum to 1.0000
[2019-04-06 16:48:31,277] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3477
[2019-04-06 16:48:31,519] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 68.0, 120.0, 58.5, 26.0, 25.94305560447102, 0.3373113275027964, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 727200.0000, 
sim time next is 729000.0000, 
raw observation next is [-1.15, 67.0, 139.0, 68.0, 26.0, 25.87350514096686, 0.3330410024407361, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4307479224376732, 0.67, 0.4633333333333333, 0.07513812154696133, 0.6666666666666666, 0.656125428413905, 0.6110136674802454, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.134122], dtype=float32), 0.20152053]. 
=============================================
[2019-04-06 16:48:31,522] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[83.77325 ]
 [84.000145]
 [83.2756  ]
 [82.23166 ]
 [81.772545]], R is [[83.58113861]
 [83.74533081]
 [83.90787506]
 [84.06879425]
 [84.22810364]].
[2019-04-06 16:48:32,967] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.4421831e-07 4.2412989e-04 1.4160005e-07 9.2571760e-03 9.2219068e-08
 9.9031746e-01 6.0706969e-07], sum to 1.0000
[2019-04-06 16:48:32,967] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1797
[2019-04-06 16:48:33,272] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 87.0, 82.5, 0.0, 26.0, 24.98261964575688, 0.3462249273719269, 0.0, 1.0, 46477.77421369171], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1782000.0000, 
sim time next is 1783800.0000, 
raw observation next is [-3.1, 87.0, 66.0, 0.0, 26.0, 25.01627420998967, 0.3453636456095948, 0.0, 1.0, 35262.05427313267], 
processed observation next is [0.0, 0.6521739130434783, 0.37673130193905824, 0.87, 0.22, 0.0, 0.6666666666666666, 0.5846895174991392, 0.6151212152031983, 0.0, 1.0, 0.16791454415777463], 
reward next is 0.8321, 
noisyNet noise sample is [array([0.4280716], dtype=float32), 0.4179925]. 
=============================================
[2019-04-06 16:48:46,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4228206e-09 4.0301825e-06 5.9302501e-09 4.2178873e-03 1.3058443e-10
 9.9577808e-01 1.1435914e-08], sum to 1.0000
[2019-04-06 16:48:46,559] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7448
[2019-04-06 16:48:46,854] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.45, 64.0, 151.0, 134.0, 26.0, 25.74971126880936, 0.3664344281507947, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2118600.0000, 
sim time next is 2120400.0000, 
raw observation next is [-6.2, 64.0, 150.0, 67.0, 26.0, 25.57202333493578, 0.2698654837304661, 1.0, 1.0, 100021.53780235222], 
processed observation next is [1.0, 0.5652173913043478, 0.2908587257617729, 0.64, 0.5, 0.07403314917127071, 0.6666666666666666, 0.6310019445779815, 0.5899551612434887, 1.0, 1.0, 0.4762930371540582], 
reward next is 0.5237, 
noisyNet noise sample is [array([0.3240023], dtype=float32), 1.2933743]. 
=============================================
[2019-04-06 16:48:51,550] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 16:48:51,550] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:48:51,550] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:51,552] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run22
[2019-04-06 16:48:51,658] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:48:51,659] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:51,661] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run22
[2019-04-06 16:48:51,771] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:48:51,771] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:51,773] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run22
[2019-04-06 16:50:02,943] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.03370421], dtype=float32), 0.11337878]
[2019-04-06 16:50:02,943] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [5.308090444999999, 98.76635905500001, 0.0, 0.0, 26.0, 25.25205814210435, 0.3786605909357525, 0.0, 1.0, 39445.87113416843]
[2019-04-06 16:50:02,944] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 16:50:02,945] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.4755819e-08 1.3637901e-04 4.9597514e-08 1.5807040e-02 5.1044573e-09
 9.8405647e-01 4.7307505e-08], sampled 0.5947592506198268
[2019-04-06 16:50:45,601] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.03370421], dtype=float32), 0.11337878]
[2019-04-06 16:50:45,601] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-1.7, 39.0, 0.0, 0.0, 26.0, 24.98778296987645, 0.202517220981547, 0.0, 1.0, 39091.370115599326]
[2019-04-06 16:50:45,601] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:50:45,602] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.6084941e-07 5.8289815e-04 1.2213303e-06 3.1377986e-02 1.4417155e-07
 9.6803623e-01 1.0181656e-06], sampled 0.04727159162424277
[2019-04-06 16:51:16,871] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 16:51:34,714] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 16:51:36,287] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.4969 91918616.4840 409.3016
[2019-04-06 16:51:37,310] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 420000, evaluation results [420000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.49693528905, 91918616.48397109, 409.30161690514404]
[2019-04-06 16:51:51,403] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.0571625e-08 8.4608479e-04 4.1174122e-08 2.0622632e-02 9.2107747e-08
 9.7853112e-01 3.7872752e-08], sum to 1.0000
[2019-04-06 16:51:51,403] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0522
[2019-04-06 16:51:51,433] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 100.0, 86.0, 0.0, 26.0, 24.77633314570834, 0.4485801134079856, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1260000.0000, 
sim time next is 1261800.0000, 
raw observation next is [13.8, 100.0, 77.0, 0.0, 26.0, 24.73242245057791, 0.4468600329811203, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.844875346260388, 1.0, 0.25666666666666665, 0.0, 0.6666666666666666, 0.5610352042148259, 0.6489533443270401, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.19146638], dtype=float32), -0.40553197]. 
=============================================
[2019-04-06 16:52:09,635] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1636306e-08 1.5967136e-04 3.6061845e-08 6.4174342e-03 3.4692296e-09
 9.9342293e-01 2.2293253e-08], sum to 1.0000
[2019-04-06 16:52:09,635] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6756
[2019-04-06 16:52:09,948] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 26.0, 25.20185479313338, 0.3301053906154282, 1.0, 1.0, 19890.102776878648], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1708200.0000, 
sim time next is 1710000.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 26.0, 24.05003450036898, 0.4185834549163055, 1.0, 1.0, 198099.6307470263], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.88, 0.0, 0.0, 0.6666666666666666, 0.504169541697415, 0.6395278183054351, 1.0, 1.0, 0.9433315749858395], 
reward next is 0.0567, 
noisyNet noise sample is [array([-0.07513008], dtype=float32), -0.29657996]. 
=============================================
[2019-04-06 16:52:09,954] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[86.379395]
 [86.48082 ]
 [86.81338 ]
 [87.18598 ]
 [87.6158  ]], R is [[86.52042389]
 [86.56050873]
 [86.66526031]
 [86.79860687]
 [86.92073059]].
[2019-04-06 16:52:15,847] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5661631e-08 2.1593581e-04 4.5134152e-07 4.4700433e-02 5.5269439e-08
 9.5508295e-01 2.3162477e-07], sum to 1.0000
[2019-04-06 16:52:15,847] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0433
[2019-04-06 16:52:15,900] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-6.75, 50.5, 0.0, 0.0, 26.0, 24.28429252483744, 0.07836128158181198, 0.0, 1.0, 43427.32184626765], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2424600.0000, 
sim time next is 2426400.0000, 
raw observation next is [-7.3, 53.0, 0.0, 0.0, 26.0, 24.13110919262682, 0.04509301730108482, 0.0, 1.0, 43523.92156706639], 
processed observation next is [0.0, 0.08695652173913043, 0.26038781163434904, 0.53, 0.0, 0.0, 0.6666666666666666, 0.5109257660522349, 0.5150310057670283, 0.0, 1.0, 0.2072567693669828], 
reward next is 0.7927, 
noisyNet noise sample is [array([-1.1220405], dtype=float32), 0.70108354]. 
=============================================
[2019-04-06 16:52:18,550] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0643702e-08 1.3840569e-03 7.3657083e-07 1.4284302e-02 2.6608465e-08
 9.8433048e-01 3.3036054e-07], sum to 1.0000
[2019-04-06 16:52:18,550] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8370
[2019-04-06 16:52:18,623] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 26.0, 23.29107496167131, -0.09363154536304692, 0.0, 1.0, 47187.28250132961], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1841400.0000, 
sim time next is 1843200.0000, 
raw observation next is [-6.7, 78.0, 14.0, 0.0, 26.0, 23.21336146354057, -0.108682403510682, 0.0, 1.0, 47143.01916669929], 
processed observation next is [0.0, 0.34782608695652173, 0.2770083102493075, 0.78, 0.04666666666666667, 0.0, 0.6666666666666666, 0.4344467886283807, 0.46377253216310604, 0.0, 1.0, 0.2244905674604728], 
reward next is 0.7755, 
noisyNet noise sample is [array([-2.6631184], dtype=float32), 0.91263163]. 
=============================================
[2019-04-06 16:52:39,296] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.4089170e-08 3.0149142e-05 3.7145449e-07 7.0011839e-02 1.2440624e-07
 9.2995739e-01 1.3162318e-07], sum to 1.0000
[2019-04-06 16:52:39,296] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8091
[2019-04-06 16:52:39,346] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 75.0, 0.0, 0.0, 26.0, 24.00136814149153, 0.0544200177485234, 0.0, 1.0, 42014.36936633193], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2178000.0000, 
sim time next is 2179800.0000, 
raw observation next is [-6.2, 77.0, 0.0, 0.0, 26.0, 23.86699548524596, 0.03272881416724058, 0.0, 1.0, 41951.308962007264], 
processed observation next is [1.0, 0.21739130434782608, 0.2908587257617729, 0.77, 0.0, 0.0, 0.6666666666666666, 0.48891629043716317, 0.5109096047224135, 0.0, 1.0, 0.1997681379143203], 
reward next is 0.8002, 
noisyNet noise sample is [array([0.3257524], dtype=float32), 0.0012056055]. 
=============================================
[2019-04-06 16:53:19,608] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6240275e-08 4.4453953e-04 8.7985875e-08 2.4246408e-02 2.7715452e-09
 9.7530884e-01 1.6228455e-07], sum to 1.0000
[2019-04-06 16:53:19,608] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1860
[2019-04-06 16:53:19,660] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 82.5, 0.0, 0.0, 26.0, 25.66539437651131, 0.5556077945580452, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3447000.0000, 
sim time next is 3448800.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 26.0, 25.67008933012714, 0.5362759210109388, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4903047091412743, 0.86, 0.0, 0.0, 0.6666666666666666, 0.6391741108439284, 0.6787586403369796, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.14471163], dtype=float32), 0.121826254]. 
=============================================
[2019-04-06 16:53:19,751] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.2086378e-09 2.6485054e-06 2.3544759e-09 2.9669553e-02 3.4993242e-09
 9.7032779e-01 2.5669569e-09], sum to 1.0000
[2019-04-06 16:53:19,751] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3317
[2019-04-06 16:53:19,835] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 67.0, 36.5, 317.0, 26.0, 26.45305410220712, 0.4663800902808646, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3430800.0000, 
sim time next is 3432600.0000, 
raw observation next is [2.0, 67.0, 12.0, 121.0, 26.0, 25.96465843107598, 0.4852071028955678, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.67, 0.04, 0.13370165745856355, 0.6666666666666666, 0.6637215359229982, 0.6617357009651893, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.22293149], dtype=float32), 0.8035856]. 
=============================================
[2019-04-06 16:53:36,459] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6935583e-08 1.0475019e-04 6.7548093e-08 1.3647442e-02 4.4606388e-08
 9.8624772e-01 4.2248516e-08], sum to 1.0000
[2019-04-06 16:53:36,460] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8099
[2019-04-06 16:53:36,515] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 59.0, 15.0, 165.0, 26.0, 25.30588531740213, 0.390044103750067, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3691800.0000, 
sim time next is 3693600.0000, 
raw observation next is [4.0, 59.0, 0.0, 0.0, 26.0, 25.14706641197287, 0.3406807772580641, 0.0, 1.0, 9862.9210952228], 
processed observation next is [0.0, 0.782608695652174, 0.5734072022160666, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5955888676644058, 0.6135602590860213, 0.0, 1.0, 0.046966290929632386], 
reward next is 0.9530, 
noisyNet noise sample is [array([2.484436], dtype=float32), 1.0599154]. 
=============================================
[2019-04-06 16:53:48,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:53:48,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:53:48,856] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run11
[2019-04-06 16:53:57,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9621280e-08 4.9095834e-04 1.4991399e-07 7.6167798e-04 1.9774149e-08
 9.9874699e-01 7.1195593e-08], sum to 1.0000
[2019-04-06 16:53:57,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5701
[2019-04-06 16:53:58,064] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 26.0, 24.42346484431128, 0.1540426015147497, 0.0, 1.0, 38385.649819982464], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3031200.0000, 
sim time next is 3033000.0000, 
raw observation next is [-5.5, 74.0, 0.0, 0.0, 26.0, 24.36361217295942, 0.1326868515724793, 0.0, 1.0, 38746.56471275404], 
processed observation next is [0.0, 0.08695652173913043, 0.3102493074792244, 0.74, 0.0, 0.0, 0.6666666666666666, 0.530301014413285, 0.5442289505241598, 0.0, 1.0, 0.1845074510131145], 
reward next is 0.8155, 
noisyNet noise sample is [array([0.60350263], dtype=float32), -1.1521376]. 
=============================================
[2019-04-06 16:53:58,071] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.36873]
 [68.84271]
 [68.92739]
 [69.30019]
 [69.12405]], R is [[69.37640381]
 [69.49985504]
 [69.62341309]
 [69.74666595]
 [69.86886597]].
[2019-04-06 16:54:27,531] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-06 16:54:27,534] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:54:27,534] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:54:27,536] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run23
[2019-04-06 16:54:27,581] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:54:27,582] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:54:27,584] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run23
[2019-04-06 16:54:27,600] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:54:27,601] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:54:27,603] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run23
[2019-04-06 16:56:52,007] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.5648 79959984.5800 535.1579
[2019-04-06 16:57:09,504] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 16:57:12,866] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 16:57:13,888] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 440000, evaluation results [440000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.564818314419, 79959984.58002774, 535.1579115189242, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 16:57:21,902] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1661943e-10 1.9921310e-06 3.2087528e-09 7.9409266e-04 1.0282918e-09
 9.9920398e-01 1.2213667e-09], sum to 1.0000
[2019-04-06 16:57:21,902] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8620
[2019-04-06 16:57:21,959] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 84.0, 0.0, 0.0, 26.0, 25.13817496371624, 0.4206207370527537, 0.0, 1.0, 43346.47187546355], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3283200.0000, 
sim time next is 3285000.0000, 
raw observation next is [-7.0, 77.0, 0.0, 0.0, 26.0, 25.04908559702345, 0.3997994728558273, 0.0, 1.0, 43562.245627895936], 
processed observation next is [1.0, 0.0, 0.2686980609418283, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5874237997519541, 0.6332664909519424, 0.0, 1.0, 0.20743926489474254], 
reward next is 0.7926, 
noisyNet noise sample is [array([-0.45365825], dtype=float32), -1.3625112]. 
=============================================
[2019-04-06 16:57:21,979] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[85.283264]
 [86.29322 ]
 [86.112015]
 [84.71094 ]
 [83.768456]], R is [[85.04272461]
 [84.98588562]
 [84.9287262 ]
 [84.82909393]
 [84.71292877]].
[2019-04-06 16:57:28,525] A3C_AGENT_WORKER-Thread-11 INFO:Local step 28500, global step 442579: loss 1.8624
[2019-04-06 16:57:28,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 28500, global step 442579: learning rate 0.0000
[2019-04-06 16:57:38,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:57:38,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:57:38,464] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run11
[2019-04-06 16:57:38,668] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2864713e-07 5.3964154e-04 8.0850981e-07 8.2162870e-03 1.4149883e-08
 9.9124122e-01 1.8441821e-06], sum to 1.0000
[2019-04-06 16:57:38,669] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7161
[2019-04-06 16:57:38,752] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 50.0, 0.0, 0.0, 26.0, 25.11965333407306, 0.33926237293488, 0.0, 1.0, 39476.927755826975], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4161600.0000, 
sim time next is 4163400.0000, 
raw observation next is [-3.5, 52.0, 0.0, 0.0, 26.0, 25.0415699050763, 0.3143863740593216, 0.0, 1.0, 39466.92318893588], 
processed observation next is [0.0, 0.17391304347826086, 0.36565096952908593, 0.52, 0.0, 0.0, 0.6666666666666666, 0.5867974920896918, 0.6047954580197739, 0.0, 1.0, 0.18793772947112322], 
reward next is 0.8121, 
noisyNet noise sample is [array([0.20479812], dtype=float32), -1.5603011]. 
=============================================
[2019-04-06 16:57:49,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:57:49,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:57:49,764] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run11
[2019-04-06 16:57:50,994] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:57:50,994] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:57:50,998] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run11
[2019-04-06 16:57:52,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8771451e-08 9.9447243e-05 7.3043132e-08 2.4004050e-03 5.1248275e-08
 9.9749976e-01 2.1156706e-07], sum to 1.0000
[2019-04-06 16:57:52,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4584
[2019-04-06 16:57:52,548] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 45.0, 0.0, 0.0, 26.0, 25.3507504844987, 0.3337566982238151, 0.0, 1.0, 46087.58649163635], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4251600.0000, 
sim time next is 4253400.0000, 
raw observation next is [3.0, 47.0, 0.0, 0.0, 26.0, 25.38564703726764, 0.3276520814851718, 0.0, 1.0, 34579.86256674365], 
processed observation next is [0.0, 0.21739130434782608, 0.5457063711911359, 0.47, 0.0, 0.0, 0.6666666666666666, 0.6154705864389699, 0.6092173604950573, 0.0, 1.0, 0.1646660122225888], 
reward next is 0.8353, 
noisyNet noise sample is [array([0.89495397], dtype=float32), 0.5505498]. 
=============================================
[2019-04-06 16:57:56,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:57:56,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:57:56,092] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run11
[2019-04-06 16:57:59,551] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5196115e-08 1.2448324e-05 1.1287232e-09 7.1052485e-03 7.4822082e-10
 9.9288225e-01 5.5576754e-10], sum to 1.0000
[2019-04-06 16:57:59,552] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1607
[2019-04-06 16:57:59,624] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.8, 68.0, 0.0, 0.0, 26.0, 25.55220233288243, 0.5255330432226165, 0.0, 1.0, 68066.49964612], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4424400.0000, 
sim time next is 4426200.0000, 
raw observation next is [3.4, 68.0, 0.0, 0.0, 26.0, 25.73642921034546, 0.5386532381937502, 0.0, 1.0, 19788.289729934168], 
processed observation next is [1.0, 0.21739130434782608, 0.556786703601108, 0.68, 0.0, 0.0, 0.6666666666666666, 0.6447024341954549, 0.6795510793979167, 0.0, 1.0, 0.0942299510949246], 
reward next is 0.9058, 
noisyNet noise sample is [array([0.69275147], dtype=float32), -1.2460064]. 
=============================================
[2019-04-06 16:58:00,238] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.4757685e-09 6.4209848e-06 1.0500688e-08 6.2460005e-03 8.3883223e-10
 9.9374759e-01 1.5591107e-08], sum to 1.0000
[2019-04-06 16:58:00,239] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1426
[2019-04-06 16:58:00,317] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.3, 57.0, 99.5, 584.0, 26.0, 26.37378845354358, 0.5779263155712183, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4352400.0000, 
sim time next is 4354200.0000, 
raw observation next is [8.15, 49.5, 107.0, 677.0, 26.0, 26.68445465848415, 0.6675386106891549, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6883656509695293, 0.495, 0.3566666666666667, 0.7480662983425415, 0.6666666666666666, 0.7237045548736791, 0.7225128702297182, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3534869], dtype=float32), -1.1773934]. 
=============================================
[2019-04-06 16:58:12,203] A3C_AGENT_WORKER-Thread-17 INFO:Local step 28500, global step 449922: loss 1.6567
[2019-04-06 16:58:12,204] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 28500, global step 449922: learning rate 0.0000
[2019-04-06 16:58:21,307] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:58:21,307] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:58:21,311] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run11
[2019-04-06 16:58:21,781] A3C_AGENT_WORKER-Thread-11 INFO:Local step 29000, global step 451753: loss 8.0414
[2019-04-06 16:58:21,789] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 29000, global step 451753: learning rate 0.0000
[2019-04-06 16:58:22,679] A3C_AGENT_WORKER-Thread-3 INFO:Local step 28500, global step 451910: loss 1.6012
[2019-04-06 16:58:22,680] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 28500, global step 451910: learning rate 0.0000
[2019-04-06 16:58:23,549] A3C_AGENT_WORKER-Thread-5 INFO:Local step 28500, global step 452043: loss 1.8455
[2019-04-06 16:58:23,552] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 28500, global step 452043: learning rate 0.0000
[2019-04-06 16:58:25,598] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.33661968e-08 1.13892034e-04 3.69385333e-07 3.17964293e-02
 2.83401924e-08 9.68089283e-01 1.14593002e-08], sum to 1.0000
[2019-04-06 16:58:25,599] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2561
[2019-04-06 16:58:25,649] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.0, 24.0, 0.0, 0.0, 26.0, 27.07511708003049, 0.6571102212158207, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4991400.0000, 
sim time next is 4993200.0000, 
raw observation next is [6.0, 23.0, 0.0, 0.0, 26.0, 25.6625483726351, 0.5940220088887146, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.6288088642659281, 0.23, 0.0, 0.0, 0.6666666666666666, 0.6385456977195917, 0.6980073362962381, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.24760252], dtype=float32), -0.27612093]. 
=============================================
[2019-04-06 16:58:26,565] A3C_AGENT_WORKER-Thread-13 INFO:Local step 28500, global step 452611: loss 1.4734
[2019-04-06 16:58:26,565] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 28500, global step 452611: learning rate 0.0000
[2019-04-06 16:58:33,138] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:58:33,138] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:58:33,282] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run11
[2019-04-06 16:58:36,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:58:36,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:58:36,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run11
[2019-04-06 16:58:41,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4631830e-09 2.5176597e-04 1.3107990e-08 5.9647240e-02 5.2041194e-10
 9.4010103e-01 6.6924808e-09], sum to 1.0000
[2019-04-06 16:58:41,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7872
[2019-04-06 16:58:41,748] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.41062209303725, 0.41761799495554, 0.0, 1.0, 35507.43773404475], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4689000.0000, 
sim time next is 4690800.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.44951927296766, 0.421330477239809, 0.0, 1.0, 38841.57654663358], 
processed observation next is [1.0, 0.30434782608695654, 0.4349030470914128, 1.0, 0.0, 0.0, 0.6666666666666666, 0.620793272747305, 0.6404434924132697, 0.0, 1.0, 0.18495988831730276], 
reward next is 0.8150, 
noisyNet noise sample is [array([-0.65172553], dtype=float32), -1.2705036]. 
=============================================
[2019-04-06 16:58:43,977] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.89448190e-08 1.65397250e-05 1.00680303e-07 9.26753227e-03
 1.41577345e-08 9.90715504e-01 3.85765247e-07], sum to 1.0000
[2019-04-06 16:58:43,977] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4830
[2019-04-06 16:58:44,041] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 45.0, 102.0, 317.0, 26.0, 25.21631520609998, 0.3720363539786365, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4897800.0000, 
sim time next is 4899600.0000, 
raw observation next is [3.0, 45.0, 67.5, 252.0, 26.0, 25.14214810492108, 0.339012537510585, 0.0, 1.0, 6226.803890076847], 
processed observation next is [0.0, 0.7391304347826086, 0.5457063711911359, 0.45, 0.225, 0.27845303867403315, 0.6666666666666666, 0.5951790087434233, 0.613004179170195, 0.0, 1.0, 0.029651447095604033], 
reward next is 0.9703, 
noisyNet noise sample is [array([-2.0070202], dtype=float32), 0.58983755]. 
=============================================
[2019-04-06 16:58:44,441] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:58:44,441] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:58:44,470] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run11
[2019-04-06 16:58:56,270] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.0981891e-09 8.2122358e-05 1.1207503e-07 2.0453934e-01 1.3452941e-09
 7.9537827e-01 2.0323024e-07], sum to 1.0000
[2019-04-06 16:58:56,270] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0700
[2019-04-06 16:58:56,319] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [9.0, 19.0, 0.0, 0.0, 26.0, 27.12339838059854, 0.8544114793263605, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5086800.0000, 
sim time next is 5088600.0000, 
raw observation next is [8.85, 19.0, 0.0, 0.0, 26.0, 26.93989040781812, 0.8161162524804394, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.7077562326869806, 0.19, 0.0, 0.0, 0.6666666666666666, 0.7449908673181765, 0.7720387508268131, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9460472], dtype=float32), 1.2073606]. 
=============================================
[2019-04-06 16:58:57,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:58:57,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:58:57,252] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run11
[2019-04-06 16:58:57,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:58:57,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:58:57,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run11
[2019-04-06 16:58:59,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:58:59,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:58:59,072] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run11
[2019-04-06 16:58:59,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:58:59,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:58:59,234] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run11
[2019-04-06 16:59:04,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:59:04,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:59:04,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run11
[2019-04-06 16:59:06,216] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:59:06,217] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:59:06,220] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run11
[2019-04-06 16:59:12,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:59:12,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:59:12,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run11
[2019-04-06 16:59:18,517] A3C_AGENT_WORKER-Thread-16 INFO:Local step 28500, global step 456624: loss 1.6493
[2019-04-06 16:59:18,519] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 28500, global step 456624: learning rate 0.0000
[2019-04-06 16:59:23,410] A3C_AGENT_WORKER-Thread-17 INFO:Local step 29000, global step 456962: loss 7.5043
[2019-04-06 16:59:23,410] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 29000, global step 456962: learning rate 0.0000
[2019-04-06 16:59:25,377] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4210128e-08 4.1652587e-05 2.2150580e-08 6.5412181e-03 2.1189908e-09
 9.9341691e-01 6.4476282e-08], sum to 1.0000
[2019-04-06 16:59:25,378] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2545
[2019-04-06 16:59:25,788] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 93.0, 60.0, 0.0, 26.0, 23.52666517546031, -0.07004964434390881, 0.0, 1.0, 57598.79401202174], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 37800.0000, 
sim time next is 39600.0000, 
raw observation next is [7.7, 93.0, 67.5, 0.0, 26.0, 23.79287378587199, -0.009772031749228019, 0.0, 1.0, 56849.722084690235], 
processed observation next is [0.0, 0.4782608695652174, 0.6759002770083103, 0.93, 0.225, 0.0, 0.6666666666666666, 0.48273948215599916, 0.49674265608359064, 0.0, 1.0, 0.27071296230804875], 
reward next is 0.7293, 
noisyNet noise sample is [array([0.27061293], dtype=float32), -0.34395146]. 
=============================================
[2019-04-06 16:59:32,344] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5131267e-08 1.7461524e-04 2.3258140e-06 2.2629046e-01 2.3509654e-07
 7.7353185e-01 3.5578469e-07], sum to 1.0000
[2019-04-06 16:59:32,345] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6741
[2019-04-06 16:59:32,753] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 40.0, 0.0, 0.0, 26.0, 25.24588514323816, 0.2856648368103498, 1.0, 1.0, 46890.36606221236], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 414000.0000, 
sim time next is 415800.0000, 
raw observation next is [-9.75, 41.0, 0.0, 0.0, 26.0, 25.08809878328874, 0.2949728106018701, 1.0, 1.0, 97021.53273428876], 
processed observation next is [1.0, 0.8260869565217391, 0.19252077562326872, 0.41, 0.0, 0.0, 0.6666666666666666, 0.590674898607395, 0.5983242702006234, 1.0, 1.0, 0.46200729873470836], 
reward next is 0.5380, 
noisyNet noise sample is [array([-0.2722824], dtype=float32), 1.4085462]. 
=============================================
[2019-04-06 16:59:35,320] A3C_AGENT_WORKER-Thread-12 INFO:Local step 28500, global step 457756: loss 0.5627
[2019-04-06 16:59:35,320] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 28500, global step 457756: learning rate 0.0000
[2019-04-06 16:59:37,806] A3C_AGENT_WORKER-Thread-18 INFO:Local step 28500, global step 457907: loss 1.3844
[2019-04-06 16:59:37,813] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 28500, global step 457907: learning rate 0.0000
[2019-04-06 16:59:47,610] A3C_AGENT_WORKER-Thread-6 INFO:Local step 28500, global step 458793: loss 1.5436
[2019-04-06 16:59:47,611] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 28500, global step 458793: learning rate 0.0000
[2019-04-06 16:59:47,901] A3C_AGENT_WORKER-Thread-3 INFO:Local step 29000, global step 458823: loss 8.0170
[2019-04-06 16:59:47,919] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 29000, global step 458823: learning rate 0.0000
[2019-04-06 16:59:48,148] A3C_AGENT_WORKER-Thread-5 INFO:Local step 29000, global step 458851: loss 7.4171
[2019-04-06 16:59:48,160] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 29000, global step 458851: learning rate 0.0000
[2019-04-06 16:59:49,173] A3C_AGENT_WORKER-Thread-11 INFO:Local step 29500, global step 458935: loss 4.9757
[2019-04-06 16:59:49,204] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 29500, global step 458935: learning rate 0.0000
[2019-04-06 16:59:53,642] A3C_AGENT_WORKER-Thread-13 INFO:Local step 29000, global step 459380: loss 8.2812
[2019-04-06 16:59:53,644] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 29000, global step 459381: learning rate 0.0000
[2019-04-06 17:00:01,247] A3C_AGENT_WORKER-Thread-19 INFO:Local step 28500, global step 459938: loss 1.2406
[2019-04-06 17:00:01,248] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 28500, global step 459938: learning rate 0.0000
[2019-04-06 17:00:01,389] A3C_AGENT_WORKER-Thread-4 INFO:Local step 28500, global step 459947: loss 1.1294
[2019-04-06 17:00:01,390] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 28500, global step 459947: learning rate 0.0000
[2019-04-06 17:00:01,891] A3C_AGENT_WORKER-Thread-10 INFO:Local step 28500, global step 459971: loss 1.3483
[2019-04-06 17:00:01,891] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 28500, global step 459971: learning rate 0.0000
[2019-04-06 17:00:02,049] A3C_AGENT_WORKER-Thread-14 INFO:Local step 28500, global step 459984: loss 0.8962
[2019-04-06 17:00:02,049] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 28500, global step 459984: learning rate 0.0000
[2019-04-06 17:00:02,441] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-06 17:00:02,441] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:00:02,441] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:02,443] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run24
[2019-04-06 17:00:02,444] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:00:02,444] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:02,446] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run24
[2019-04-06 17:00:02,519] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:00:02,519] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:02,683] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run24
[2019-04-06 17:02:11,628] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.03722994], dtype=float32), 0.115891196]
[2019-04-06 17:02:11,628] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [8.2, 68.0, 124.5, 235.0, 26.0, 24.96648086784993, 0.4229166453236437, 0.0, 1.0, 12453.607780153694]
[2019-04-06 17:02:11,628] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 17:02:11,629] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [8.82673046e-09 7.48204693e-05 3.40406139e-08 1.23692015e-02
 3.89043597e-09 9.87555921e-01 3.31259642e-08], sampled 0.01567850446617758
[2019-04-06 17:02:27,880] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3171 79954231.1999 534.8688
[2019-04-06 17:02:39,054] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.03722994], dtype=float32), 0.115891196]
[2019-04-06 17:02:39,054] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [3.736985872, 81.1149983, 222.5300916, 75.16076705, 26.0, 25.77912829275357, 0.5395383961971694, 1.0, 1.0, 0.0]
[2019-04-06 17:02:39,054] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 17:02:39,054] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [4.2109356e-09 3.7385897e-05 1.0564345e-08 9.1189956e-03 1.7435401e-09
 9.9084365e-01 1.5061028e-08], sampled 0.49460352952118547
[2019-04-06 17:02:48,280] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.3334 87773462.1143 515.3349
[2019-04-06 17:02:49,702] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 17:02:50,724] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 460000, evaluation results [460000.0, 2416.3333700591375, 87773462.11425272, 515.334937381388, 2453.3170796759696, 79954231.19985014, 534.8688192188417, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 17:02:52,446] A3C_AGENT_WORKER-Thread-20 INFO:Local step 28500, global step 460201: loss 1.7761
[2019-04-06 17:02:52,446] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 28500, global step 460201: learning rate 0.0000
[2019-04-06 17:02:55,743] A3C_AGENT_WORKER-Thread-15 INFO:Local step 28500, global step 460560: loss -7.2390
[2019-04-06 17:02:55,744] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 28500, global step 460560: learning rate 0.0000
[2019-04-06 17:02:57,553] A3C_AGENT_WORKER-Thread-2 INFO:Local step 28500, global step 460757: loss 1.5485
[2019-04-06 17:02:57,559] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 28500, global step 460757: learning rate 0.0000
[2019-04-06 17:03:21,100] A3C_AGENT_WORKER-Thread-16 INFO:Local step 29000, global step 463555: loss 9.4966
[2019-04-06 17:03:21,100] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 29000, global step 463555: learning rate 0.0000
[2019-04-06 17:03:22,990] A3C_AGENT_WORKER-Thread-17 INFO:Local step 29500, global step 463792: loss 4.6787
[2019-04-06 17:03:22,993] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 29500, global step 463792: learning rate 0.0000
[2019-04-06 17:03:33,825] A3C_AGENT_WORKER-Thread-12 INFO:Local step 29000, global step 465270: loss 7.5764
[2019-04-06 17:03:33,826] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 29000, global step 465270: learning rate 0.0000
[2019-04-06 17:03:34,347] A3C_AGENT_WORKER-Thread-18 INFO:Local step 29000, global step 465360: loss 7.7857
[2019-04-06 17:03:34,359] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 29000, global step 465360: learning rate 0.0000
[2019-04-06 17:03:38,183] A3C_AGENT_WORKER-Thread-3 INFO:Local step 29500, global step 465973: loss 6.2948
[2019-04-06 17:03:38,183] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 29500, global step 465973: learning rate 0.0000
[2019-04-06 17:03:38,437] A3C_AGENT_WORKER-Thread-5 INFO:Local step 29500, global step 466000: loss 5.5963
[2019-04-06 17:03:38,439] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 29500, global step 466000: learning rate 0.0000
[2019-04-06 17:03:40,426] A3C_AGENT_WORKER-Thread-13 INFO:Local step 29500, global step 466327: loss 5.8698
[2019-04-06 17:03:40,427] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 29500, global step 466327: learning rate 0.0000
[2019-04-06 17:03:40,795] A3C_AGENT_WORKER-Thread-6 INFO:Local step 29000, global step 466393: loss 7.5947
[2019-04-06 17:03:40,806] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 29000, global step 466393: learning rate 0.0000
[2019-04-06 17:03:45,446] A3C_AGENT_WORKER-Thread-11 INFO:Local step 30000, global step 467251: loss 1.7478
[2019-04-06 17:03:45,462] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 30000, global step 467251: learning rate 0.0000
[2019-04-06 17:03:47,219] A3C_AGENT_WORKER-Thread-19 INFO:Local step 29000, global step 467653: loss 7.4414
[2019-04-06 17:03:47,221] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 29000, global step 467653: learning rate 0.0000
[2019-04-06 17:03:47,609] A3C_AGENT_WORKER-Thread-4 INFO:Local step 29000, global step 467753: loss 7.5729
[2019-04-06 17:03:47,626] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 29000, global step 467753: learning rate 0.0000
[2019-04-06 17:03:48,258] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.8508639e-08 1.6750954e-04 4.4632628e-08 2.5206584e-01 4.1386650e-09
 7.4776649e-01 9.1294353e-08], sum to 1.0000
[2019-04-06 17:03:48,258] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7354
[2019-04-06 17:03:48,459] A3C_AGENT_WORKER-Thread-10 INFO:Local step 29000, global step 467939: loss 16.1814
[2019-04-06 17:03:48,466] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.95, 89.0, 45.0, 16.0, 26.0, 25.36045366477146, 0.2907088628769009, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2277000.0000, 
sim time next is 2278800.0000, 
raw observation next is [-8.4, 87.0, 73.0, 27.5, 26.0, 25.62777169225272, 0.3082038359260359, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.2299168975069252, 0.87, 0.24333333333333335, 0.03038674033149171, 0.6666666666666666, 0.6356476410210599, 0.6027346119753453, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3891889], dtype=float32), 0.793572]. 
=============================================
[2019-04-06 17:03:48,469] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 29000, global step 467939: learning rate 0.0000
[2019-04-06 17:03:49,586] A3C_AGENT_WORKER-Thread-14 INFO:Local step 29000, global step 468216: loss 7.4925
[2019-04-06 17:03:49,596] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 29000, global step 468216: learning rate 0.0000
[2019-04-06 17:03:49,704] A3C_AGENT_WORKER-Thread-20 INFO:Local step 29000, global step 468253: loss 8.3047
[2019-04-06 17:03:49,706] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 29000, global step 468253: learning rate 0.0000
[2019-04-06 17:03:52,039] A3C_AGENT_WORKER-Thread-15 INFO:Local step 29000, global step 468751: loss 7.7535
[2019-04-06 17:03:52,043] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 29000, global step 468751: learning rate 0.0000
[2019-04-06 17:03:53,830] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7896493e-07 1.0148339e-03 1.4850697e-06 6.0533937e-02 2.2999464e-07
 9.3844849e-01 6.4211378e-07], sum to 1.0000
[2019-04-06 17:03:53,830] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4168
[2019-04-06 17:03:53,855] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [18.55, 64.0, 80.0, 0.0, 26.0, 25.04595080441617, 0.4888573530871059, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1179000.0000, 
sim time next is 1180800.0000, 
raw observation next is [18.8, 63.0, 54.5, 0.0, 26.0, 25.0512970710659, 0.4855475590262818, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.9833795013850417, 0.63, 0.18166666666666667, 0.0, 0.6666666666666666, 0.5876080892554917, 0.661849186342094, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0535257], dtype=float32), 0.6957078]. 
=============================================
[2019-04-06 17:03:54,898] A3C_AGENT_WORKER-Thread-2 INFO:Local step 29000, global step 469302: loss 13.4856
[2019-04-06 17:03:54,900] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 29000, global step 469302: learning rate 0.0000
[2019-04-06 17:04:08,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6812375e-10 2.3616433e-04 7.5557764e-09 2.3915346e-03 2.3952091e-09
 9.9737227e-01 4.4370614e-09], sum to 1.0000
[2019-04-06 17:04:08,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1486
[2019-04-06 17:04:09,044] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.5, 79.0, 0.0, 0.0, 26.0, 25.45258762528018, 0.4923535551238775, 0.0, 1.0, 64176.85155724281], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1580400.0000, 
sim time next is 1582200.0000, 
raw observation next is [5.25, 80.5, 0.0, 0.0, 26.0, 25.51871549721075, 0.4951419856266259, 1.0, 1.0, 13101.934301352238], 
processed observation next is [1.0, 0.30434782608695654, 0.60803324099723, 0.805, 0.0, 0.0, 0.6666666666666666, 0.6265596247675624, 0.6650473285422086, 1.0, 1.0, 0.06239016333977256], 
reward next is 0.9376, 
noisyNet noise sample is [array([2.3476012], dtype=float32), 0.88365257]. 
=============================================
[2019-04-06 17:04:09,278] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.8397640e-08 1.0317247e-04 9.6897986e-07 3.0936848e-02 2.0094204e-08
 9.6895885e-01 1.4467025e-07], sum to 1.0000
[2019-04-06 17:04:09,279] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4765
[2019-04-06 17:04:09,439] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 26.0, 24.88616492465761, 0.2471875603564896, 0.0, 1.0, 41728.776014036], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2597400.0000, 
sim time next is 2599200.0000, 
raw observation next is [-5.0, 74.0, 0.0, 0.0, 26.0, 24.97989800763679, 0.2524244890903467, 0.0, 1.0, 41638.98498927798], 
processed observation next is [1.0, 0.08695652173913043, 0.32409972299168976, 0.74, 0.0, 0.0, 0.6666666666666666, 0.581658167303066, 0.5841414963634489, 0.0, 1.0, 0.19828088090132373], 
reward next is 0.8017, 
noisyNet noise sample is [array([0.4078187], dtype=float32), 0.15322088]. 
=============================================
[2019-04-06 17:04:15,767] A3C_AGENT_WORKER-Thread-16 INFO:Local step 29500, global step 472198: loss 5.3447
[2019-04-06 17:04:15,768] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 29500, global step 472198: learning rate 0.0000
[2019-04-06 17:04:31,104] A3C_AGENT_WORKER-Thread-17 INFO:Local step 30000, global step 473293: loss 1.2281
[2019-04-06 17:04:31,104] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 30000, global step 473293: learning rate 0.0000
[2019-04-06 17:04:37,686] A3C_AGENT_WORKER-Thread-11 INFO:Local step 30500, global step 473779: loss 0.2867
[2019-04-06 17:04:37,687] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 30500, global step 473779: learning rate 0.0000
[2019-04-06 17:04:41,440] A3C_AGENT_WORKER-Thread-12 INFO:Local step 29500, global step 474055: loss -3.8709
[2019-04-06 17:04:41,440] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 29500, global step 474055: learning rate 0.0000
[2019-04-06 17:04:41,882] A3C_AGENT_WORKER-Thread-18 INFO:Local step 29500, global step 474089: loss 5.7114
[2019-04-06 17:04:41,883] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 29500, global step 474089: learning rate 0.0000
[2019-04-06 17:04:55,052] A3C_AGENT_WORKER-Thread-6 INFO:Local step 29500, global step 475040: loss 4.9345
[2019-04-06 17:04:55,052] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 29500, global step 475040: learning rate 0.0000
[2019-04-06 17:04:55,600] A3C_AGENT_WORKER-Thread-5 INFO:Local step 30000, global step 475077: loss -2.4966
[2019-04-06 17:04:55,600] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 30000, global step 475077: learning rate 0.0000
[2019-04-06 17:04:57,589] A3C_AGENT_WORKER-Thread-3 INFO:Local step 30000, global step 475233: loss 1.7199
[2019-04-06 17:04:57,589] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 30000, global step 475233: learning rate 0.0000
[2019-04-06 17:05:00,538] A3C_AGENT_WORKER-Thread-13 INFO:Local step 30000, global step 475436: loss 1.7330
[2019-04-06 17:05:00,538] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 30000, global step 475436: learning rate 0.0000
[2019-04-06 17:05:08,192] A3C_AGENT_WORKER-Thread-4 INFO:Local step 29500, global step 476054: loss -6.4284
[2019-04-06 17:05:08,193] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 29500, global step 476054: learning rate 0.0000
[2019-04-06 17:05:08,285] A3C_AGENT_WORKER-Thread-19 INFO:Local step 29500, global step 476061: loss 5.3505
[2019-04-06 17:05:08,286] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 29500, global step 476061: learning rate 0.0000
[2019-04-06 17:05:09,592] A3C_AGENT_WORKER-Thread-10 INFO:Local step 29500, global step 476186: loss 5.3230
[2019-04-06 17:05:09,592] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 29500, global step 476186: learning rate 0.0000
[2019-04-06 17:05:12,504] A3C_AGENT_WORKER-Thread-20 INFO:Local step 29500, global step 476470: loss 4.4176
[2019-04-06 17:05:12,505] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 29500, global step 476470: learning rate 0.0000
[2019-04-06 17:05:12,956] A3C_AGENT_WORKER-Thread-14 INFO:Local step 29500, global step 476515: loss 2.3638
[2019-04-06 17:05:12,956] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 29500, global step 476515: learning rate 0.0000
[2019-04-06 17:05:15,156] A3C_AGENT_WORKER-Thread-15 INFO:Local step 29500, global step 476697: loss 3.1708
[2019-04-06 17:05:15,156] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 29500, global step 476697: learning rate 0.0000
[2019-04-06 17:05:15,968] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3871002e-08 3.3956003e-05 2.0078904e-08 1.2654010e-03 7.4252640e-09
 9.9870050e-01 1.6073261e-07], sum to 1.0000
[2019-04-06 17:05:15,968] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4379
[2019-04-06 17:05:16,363] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 82.0, 174.0, 118.0, 26.0, 25.66157080511408, 0.3846013362781366, 1.0, 1.0, 26280.79682948317], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2107800.0000, 
sim time next is 2109600.0000, 
raw observation next is [-7.8, 82.0, 191.0, 89.0, 26.0, 25.84290749822868, 0.4027765957121397, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.24653739612188366, 0.82, 0.6366666666666667, 0.09834254143646409, 0.6666666666666666, 0.65357562485239, 0.6342588652373798, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2079265], dtype=float32), 1.6052234]. 
=============================================
[2019-04-06 17:05:18,923] A3C_AGENT_WORKER-Thread-2 INFO:Local step 29500, global step 476974: loss 5.1153
[2019-04-06 17:05:18,923] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 29500, global step 476974: learning rate 0.0000
[2019-04-06 17:05:22,777] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.7755039e-09 2.9544335e-05 8.7303484e-08 1.2281892e-02 6.3241949e-09
 9.8768848e-01 4.2154046e-08], sum to 1.0000
[2019-04-06 17:05:22,778] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1545
[2019-04-06 17:05:22,903] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 55.0, 0.0, 0.0, 26.0, 25.90882112233753, 0.5413404249119625, 1.0, 1.0, 10664.901007079274], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3349800.0000, 
sim time next is 3351600.0000, 
raw observation next is [-3.0, 55.0, 0.0, 0.0, 26.0, 25.54471925316669, 0.5118592687953242, 1.0, 1.0, 33076.106775475295], 
processed observation next is [1.0, 0.8260869565217391, 0.3795013850415513, 0.55, 0.0, 0.0, 0.6666666666666666, 0.6287266044305575, 0.6706197562651081, 1.0, 1.0, 0.15750527035940617], 
reward next is 0.8425, 
noisyNet noise sample is [array([-1.0418472], dtype=float32), -0.77243096]. 
=============================================
[2019-04-06 17:05:37,397] A3C_AGENT_WORKER-Thread-17 INFO:Local step 30500, global step 478702: loss 0.2841
[2019-04-06 17:05:37,397] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 30500, global step 478702: learning rate 0.0000
[2019-04-06 17:05:38,560] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.40593883e-08 6.60941078e-05 5.00622832e-08 8.60815495e-02
 6.56690524e-09 9.13852274e-01 1.35239535e-08], sum to 1.0000
[2019-04-06 17:05:38,560] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8874
[2019-04-06 17:05:38,658] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 26.0, 24.7644080772961, 0.2040996431129971, 0.0, 1.0, 41774.75775972893], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2602800.0000, 
sim time next is 2604600.0000, 
raw observation next is [-5.3, 76.0, 0.0, 0.0, 26.0, 24.64618611442685, 0.1712804273826825, 0.0, 1.0, 42006.96492823767], 
processed observation next is [1.0, 0.13043478260869565, 0.31578947368421056, 0.76, 0.0, 0.0, 0.6666666666666666, 0.5538488428689042, 0.5570934757942275, 0.0, 1.0, 0.20003316632494128], 
reward next is 0.8000, 
noisyNet noise sample is [array([-1.5567695], dtype=float32), -0.005857535]. 
=============================================
[2019-04-06 17:05:40,601] A3C_AGENT_WORKER-Thread-11 INFO:Local step 31000, global step 478998: loss 5.1195
[2019-04-06 17:05:40,601] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 31000, global step 478998: learning rate 0.0000
[2019-04-06 17:05:51,108] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 17:05:51,113] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:05:51,114] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:05:51,116] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run25
[2019-04-06 17:05:51,181] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:05:51,183] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:05:51,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run25
[2019-04-06 17:05:51,293] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:05:51,294] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:05:51,295] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run25
[2019-04-06 17:08:15,312] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3436 79948665.1614 535.1956
[2019-04-06 17:08:36,478] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 17:08:36,781] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.6009 91915844.0444 409.1903
[2019-04-06 17:08:37,803] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 480000, evaluation results [480000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.343584620766, 79948665.16144353, 535.1956258387099, 2396.6008904089267, 91915844.04443675, 409.19028368873524]
[2019-04-06 17:08:40,732] A3C_AGENT_WORKER-Thread-16 INFO:Local step 30000, global step 480441: loss 1.8578
[2019-04-06 17:08:40,747] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 30000, global step 480445: learning rate 0.0000
[2019-04-06 17:08:44,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:08:44,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:08:44,157] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run12
[2019-04-06 17:08:46,538] A3C_AGENT_WORKER-Thread-5 INFO:Local step 30500, global step 481338: loss 0.2706
[2019-04-06 17:08:46,543] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 30500, global step 481338: learning rate 0.0000
[2019-04-06 17:08:46,931] A3C_AGENT_WORKER-Thread-3 INFO:Local step 30500, global step 481396: loss 0.2843
[2019-04-06 17:08:46,932] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 30500, global step 481396: learning rate 0.0000
[2019-04-06 17:08:48,296] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0145200e-08 1.4353178e-04 1.6962879e-08 1.2900668e-02 9.0448156e-09
 9.8695576e-01 5.7969931e-08], sum to 1.0000
[2019-04-06 17:08:48,296] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5503
[2019-04-06 17:08:48,390] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 36.0, 66.0, 536.0, 26.0, 26.79071619126584, 0.7024874416371829, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3947400.0000, 
sim time next is 3949200.0000, 
raw observation next is [-5.0, 38.0, 42.5, 352.5, 26.0, 26.57316849409621, 0.6568961158571157, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.32409972299168976, 0.38, 0.14166666666666666, 0.38950276243093923, 0.6666666666666666, 0.7144307078413507, 0.7189653719523719, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.25965735], dtype=float32), -0.06396326]. 
=============================================
[2019-04-06 17:08:49,020] A3C_AGENT_WORKER-Thread-13 INFO:Local step 30500, global step 481671: loss 0.3393
[2019-04-06 17:08:49,021] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 30500, global step 481671: learning rate 0.0000
[2019-04-06 17:08:57,475] A3C_AGENT_WORKER-Thread-12 INFO:Local step 30000, global step 482772: loss 1.6893
[2019-04-06 17:08:57,475] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 30000, global step 482772: learning rate 0.0000
[2019-04-06 17:08:58,260] A3C_AGENT_WORKER-Thread-18 INFO:Local step 30000, global step 482882: loss 1.8702
[2019-04-06 17:08:58,260] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 30000, global step 482882: learning rate 0.0000
[2019-04-06 17:08:58,289] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0347262e-08 1.8991505e-04 2.3180226e-07 3.2793429e-02 1.9916500e-08
 9.6701628e-01 1.5966108e-07], sum to 1.0000
[2019-04-06 17:08:58,291] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7046
[2019-04-06 17:08:58,352] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 38.0, 0.0, 0.0, 26.0, 25.04308266887181, 0.2853601855585977, 0.0, 1.0, 40760.72238017967], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4071600.0000, 
sim time next is 4073400.0000, 
raw observation next is [-5.0, 39.5, 0.0, 0.0, 26.0, 24.96935545911798, 0.2593090097604158, 0.0, 1.0, 40641.05333562461], 
processed observation next is [1.0, 0.13043478260869565, 0.32409972299168976, 0.395, 0.0, 0.0, 0.6666666666666666, 0.5807796215931651, 0.5864363365868053, 0.0, 1.0, 0.19352882540773622], 
reward next is 0.8065, 
noisyNet noise sample is [array([1.144042], dtype=float32), -0.12508613]. 
=============================================
[2019-04-06 17:09:00,186] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.7430945e-08 2.9533333e-04 1.6118862e-07 4.6313880e-03 8.2651518e-08
 9.9507141e-01 1.5205196e-06], sum to 1.0000
[2019-04-06 17:09:00,186] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1339
[2019-04-06 17:09:00,238] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 49.5, 0.0, 0.0, 26.0, 24.66624883727935, 0.228169010907319, 0.0, 1.0, 39784.6208368394], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4170600.0000, 
sim time next is 4172400.0000, 
raw observation next is [-5.0, 49.0, 0.0, 0.0, 26.0, 24.54933233385236, 0.2015715232084849, 0.0, 1.0, 40084.219152492406], 
processed observation next is [0.0, 0.30434782608695654, 0.32409972299168976, 0.49, 0.0, 0.0, 0.6666666666666666, 0.5457776944876965, 0.5671905077361616, 0.0, 1.0, 0.19087723405948764], 
reward next is 0.8091, 
noisyNet noise sample is [array([0.28173453], dtype=float32), 0.36004373]. 
=============================================
[2019-04-06 17:09:04,480] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.2269504e-08 3.7963805e-04 1.2614176e-07 9.4597489e-03 6.7171875e-08
 9.9016005e-01 3.4158788e-07], sum to 1.0000
[2019-04-06 17:09:04,480] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9270
[2019-04-06 17:09:04,533] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 49.0, 0.0, 0.0, 26.0, 25.37327553684235, 0.3279786889461311, 0.0, 1.0, 43103.659111130575], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4255200.0000, 
sim time next is 4257000.0000, 
raw observation next is [3.0, 49.0, 0.0, 0.0, 26.0, 25.35806686583346, 0.3251900715328933, 0.0, 1.0, 40375.18592343569], 
processed observation next is [0.0, 0.2608695652173913, 0.5457063711911359, 0.49, 0.0, 0.0, 0.6666666666666666, 0.613172238819455, 0.6083966905109645, 0.0, 1.0, 0.19226279011159852], 
reward next is 0.8077, 
noisyNet noise sample is [array([-1.2482243], dtype=float32), -0.8490644]. 
=============================================
[2019-04-06 17:09:04,610] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[73.41514 ]
 [73.26038 ]
 [73.20866 ]
 [73.226204]
 [73.22147 ]], R is [[73.59030151]
 [73.64914703]
 [73.74803925]
 [73.79108429]
 [73.83125305]].
[2019-04-06 17:09:05,675] A3C_AGENT_WORKER-Thread-6 INFO:Local step 30000, global step 484046: loss 1.7329
[2019-04-06 17:09:05,685] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 30000, global step 484046: learning rate 0.0000
[2019-04-06 17:09:06,122] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.08572276e-10 5.89597175e-06 2.04737324e-10 1.56793930e-03
 4.31786079e-10 9.98426199e-01 2.37148767e-09], sum to 1.0000
[2019-04-06 17:09:06,122] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0642
[2019-04-06 17:09:06,277] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 121.5, 0.0, 26.0, 25.77949146244591, 0.4401186315574351, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4712400.0000, 
sim time next is 4714200.0000, 
raw observation next is [1.5, 79.5, 135.0, 0.0, 26.0, 24.35241864320522, 0.3896335580149104, 1.0, 1.0, 165799.42851502326], 
processed observation next is [1.0, 0.5652173913043478, 0.5041551246537397, 0.795, 0.45, 0.0, 0.6666666666666666, 0.5293682202671016, 0.6298778526716368, 1.0, 1.0, 0.7895210881667775], 
reward next is 0.2105, 
noisyNet noise sample is [array([-0.5058495], dtype=float32), 1.366817]. 
=============================================
[2019-04-06 17:09:06,711] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4526302e-09 7.3824471e-05 9.8097352e-09 8.6261956e-03 3.1475194e-09
 9.9129993e-01 2.4709463e-08], sum to 1.0000
[2019-04-06 17:09:06,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5757
[2019-04-06 17:09:06,793] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.6, 60.0, 47.0, 392.0, 26.0, 25.5946414043206, 0.4484948287698404, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4294800.0000, 
sim time next is 4296600.0000, 
raw observation next is [6.4, 62.0, 24.0, 228.0, 26.0, 25.47525669330046, 0.4095121895349016, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.6398891966759004, 0.62, 0.08, 0.25193370165745854, 0.6666666666666666, 0.6229380577750382, 0.6365040631783005, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.07707605], dtype=float32), -0.57270414]. 
=============================================
[2019-04-06 17:09:07,852] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.4384133e-09 6.6879252e-06 1.3216758e-09 3.6800015e-03 3.8047544e-11
 9.9631327e-01 3.6727608e-09], sum to 1.0000
[2019-04-06 17:09:07,852] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5974
[2019-04-06 17:09:07,896] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.5, 72.0, 0.0, 0.0, 26.0, 25.75880497995296, 0.4055938446966663, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4327200.0000, 
sim time next is 4329000.0000, 
raw observation next is [4.25, 71.5, 0.0, 0.0, 26.0, 25.52773701442874, 0.3724560590545778, 0.0, 1.0, 52334.03725055236], 
processed observation next is [1.0, 0.08695652173913043, 0.5803324099722993, 0.715, 0.0, 0.0, 0.6666666666666666, 0.6273114178690617, 0.6241520196848592, 0.0, 1.0, 0.24920970119310648], 
reward next is 0.7508, 
noisyNet noise sample is [array([0.8265242], dtype=float32), 0.5120727]. 
=============================================
[2019-04-06 17:09:07,909] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[84.89222 ]
 [84.16572 ]
 [83.87013 ]
 [82.50882 ]
 [81.292404]], R is [[86.14160919]
 [86.28019714]
 [86.35696411]
 [86.31887817]
 [86.36138153]].
[2019-04-06 17:09:12,334] A3C_AGENT_WORKER-Thread-17 INFO:Local step 31000, global step 485135: loss 5.5767
[2019-04-06 17:09:12,335] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 31000, global step 485135: learning rate 0.0000
[2019-04-06 17:09:12,872] A3C_AGENT_WORKER-Thread-19 INFO:Local step 30000, global step 485220: loss -2.0629
[2019-04-06 17:09:12,873] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 30000, global step 485220: learning rate 0.0000
[2019-04-06 17:09:14,436] A3C_AGENT_WORKER-Thread-4 INFO:Local step 30000, global step 485500: loss 2.1305
[2019-04-06 17:09:14,449] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 30000, global step 485500: learning rate 0.0000
[2019-04-06 17:09:14,897] A3C_AGENT_WORKER-Thread-10 INFO:Local step 30000, global step 485574: loss 1.9932
[2019-04-06 17:09:14,899] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 30000, global step 485574: learning rate 0.0000
[2019-04-06 17:09:15,337] A3C_AGENT_WORKER-Thread-20 INFO:Local step 30000, global step 485655: loss 1.9670
[2019-04-06 17:09:15,338] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 30000, global step 485655: learning rate 0.0000
[2019-04-06 17:09:16,375] A3C_AGENT_WORKER-Thread-14 INFO:Local step 30000, global step 485819: loss 1.7319
[2019-04-06 17:09:16,375] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 30000, global step 485819: learning rate 0.0000
[2019-04-06 17:09:16,913] A3C_AGENT_WORKER-Thread-15 INFO:Local step 30000, global step 485894: loss 1.9162
[2019-04-06 17:09:16,913] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 30000, global step 485894: learning rate 0.0000
[2019-04-06 17:09:18,598] A3C_AGENT_WORKER-Thread-2 INFO:Local step 30000, global step 486175: loss 1.4244
[2019-04-06 17:09:18,599] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 30000, global step 486175: learning rate 0.0000
[2019-04-06 17:09:24,714] A3C_AGENT_WORKER-Thread-16 INFO:Local step 30500, global step 487372: loss 0.4357
[2019-04-06 17:09:24,715] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 30500, global step 487372: learning rate 0.0000
[2019-04-06 17:09:24,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:09:24,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:09:24,822] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run12
[2019-04-06 17:09:25,517] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0449963e-08 4.2842497e-05 6.0827993e-08 3.9984724e-03 1.3149450e-09
 9.9595851e-01 7.2294029e-08], sum to 1.0000
[2019-04-06 17:09:25,517] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0698
[2019-04-06 17:09:25,567] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 26.0, 24.95777376207931, 0.3527455055012281, 0.0, 1.0, 40950.904490824265], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4757400.0000, 
sim time next is 4759200.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 26.0, 24.8572702512129, 0.3338287806118811, 0.0, 1.0, 40738.529015024345], 
processed observation next is [0.0, 0.08695652173913043, 0.3518005540166205, 0.71, 0.0, 0.0, 0.6666666666666666, 0.5714391876010749, 0.6112762602039604, 0.0, 1.0, 0.19399299530963973], 
reward next is 0.8060, 
noisyNet noise sample is [array([1.0883589], dtype=float32), -1.1575816]. 
=============================================
[2019-04-06 17:09:28,705] A3C_AGENT_WORKER-Thread-3 INFO:Local step 31000, global step 488070: loss 5.6447
[2019-04-06 17:09:28,706] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 31000, global step 488070: learning rate 0.0000
[2019-04-06 17:09:31,281] A3C_AGENT_WORKER-Thread-5 INFO:Local step 31000, global step 488448: loss 9.4518
[2019-04-06 17:09:31,289] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 31000, global step 488448: learning rate 0.0000
[2019-04-06 17:09:31,904] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.4791299e-08 1.6301123e-05 3.3876571e-08 6.3696224e-03 4.9051128e-09
 9.9361390e-01 1.1949437e-07], sum to 1.0000
[2019-04-06 17:09:31,906] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4258
[2019-04-06 17:09:31,976] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 37.0, 0.0, 0.0, 26.0, 25.04753752059984, 0.338924979652256, 0.0, 1.0, 40594.24641056364], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4060800.0000, 
sim time next is 4062600.0000, 
raw observation next is [-6.0, 39.0, 0.0, 0.0, 26.0, 24.96397495968164, 0.3225076702493556, 0.0, 1.0, 40586.798492240654], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.39, 0.0, 0.0, 0.6666666666666666, 0.5803312466401366, 0.6075025567497853, 0.0, 1.0, 0.19327046901066977], 
reward next is 0.8067, 
noisyNet noise sample is [array([-0.5110553], dtype=float32), -1.6699688]. 
=============================================
[2019-04-06 17:09:32,675] A3C_AGENT_WORKER-Thread-13 INFO:Local step 31000, global step 488723: loss 5.8181
[2019-04-06 17:09:32,675] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 31000, global step 488723: learning rate 0.0000
[2019-04-06 17:09:33,928] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4852114e-07 2.2021514e-04 4.2148727e-07 6.7834826e-03 5.5564495e-08
 9.9299556e-01 1.3023750e-07], sum to 1.0000
[2019-04-06 17:09:33,928] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3544
[2019-04-06 17:09:33,991] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 65.5, 0.0, 0.0, 26.0, 24.78700076481125, 0.2365795699205004, 0.0, 1.0, 39204.19913276512], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4854600.0000, 
sim time next is 4856400.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 26.0, 24.81231797652025, 0.2260834154608569, 0.0, 1.0, 39299.253768829534], 
processed observation next is [0.0, 0.21739130434782608, 0.3518005540166205, 0.71, 0.0, 0.0, 0.6666666666666666, 0.567693164710021, 0.5753611384869523, 0.0, 1.0, 0.18713930366109302], 
reward next is 0.8129, 
noisyNet noise sample is [array([-1.9703898], dtype=float32), 1.7371854]. 
=============================================
[2019-04-06 17:09:35,953] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4920534e-09 2.1358121e-06 4.3965191e-09 3.6427185e-02 7.6042411e-10
 9.6357065e-01 1.7396955e-09], sum to 1.0000
[2019-04-06 17:09:35,953] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1552
[2019-04-06 17:09:35,989] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 49.0, 113.0, 806.0, 26.0, 26.07258370242763, 0.5982666989217815, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3418200.0000, 
sim time next is 3420000.0000, 
raw observation next is [3.0, 49.0, 108.0, 790.5, 26.0, 26.47925063134953, 0.5327824164610927, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5457063711911359, 0.49, 0.36, 0.8734806629834254, 0.6666666666666666, 0.7066042192791274, 0.6775941388203642, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.06690527], dtype=float32), 1.6009303]. 
=============================================
[2019-04-06 17:09:35,995] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[84.52631]
 [84.58445]
 [84.87051]
 [84.80366]
 [84.83198]], R is [[84.54800415]
 [84.70252228]
 [84.85549927]
 [84.86302185]
 [85.01438904]].
[2019-04-06 17:09:37,285] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8696203e-09 6.6891298e-05 8.8521837e-08 1.3470117e-02 8.4907921e-09
 9.8646289e-01 2.0578558e-08], sum to 1.0000
[2019-04-06 17:09:37,285] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2346
[2019-04-06 17:09:37,316] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 57.5, 0.0, 0.0, 26.0, 25.72852329772437, 0.5698083066406942, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3879000.0000, 
sim time next is 3880800.0000, 
raw observation next is [-1.0, 55.0, 0.0, 0.0, 26.0, 25.69703294916989, 0.5366921988639753, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4349030470914128, 0.55, 0.0, 0.0, 0.6666666666666666, 0.6414194124308242, 0.6788973996213251, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.45017993], dtype=float32), -0.76587427]. 
=============================================
[2019-04-06 17:09:39,273] A3C_AGENT_WORKER-Thread-12 INFO:Local step 30500, global step 489931: loss 0.3616
[2019-04-06 17:09:39,273] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 30500, global step 489931: learning rate 0.0000
[2019-04-06 17:09:39,975] A3C_AGENT_WORKER-Thread-18 INFO:Local step 30500, global step 490069: loss 0.5088
[2019-04-06 17:09:39,975] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 30500, global step 490069: learning rate 0.0000
[2019-04-06 17:09:41,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:09:41,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:09:41,428] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run12
[2019-04-06 17:09:42,522] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.1493362e-09 1.6652647e-04 2.3189578e-08 2.3209294e-03 5.6642375e-09
 9.9751234e-01 7.5043289e-08], sum to 1.0000
[2019-04-06 17:09:42,522] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2389
[2019-04-06 17:09:42,563] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.0, 29.0, 0.0, 0.0, 26.0, 25.51816745164147, 0.3448339185521915, 0.0, 1.0, 24602.19701932109], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3643200.0000, 
sim time next is 3645000.0000, 
raw observation next is [8.5, 28.0, 0.0, 0.0, 26.0, 25.44905325909852, 0.3582354581305204, 0.0, 1.0, 57709.37288316768], 
processed observation next is [0.0, 0.17391304347826086, 0.698060941828255, 0.28, 0.0, 0.0, 0.6666666666666666, 0.62075443825821, 0.6194118193768401, 0.0, 1.0, 0.2748065375388937], 
reward next is 0.7252, 
noisyNet noise sample is [array([-0.16649696], dtype=float32), -2.486014]. 
=============================================
[2019-04-06 17:09:42,567] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.71165 ]
 [72.58273 ]
 [72.512634]
 [72.114525]
 [72.3547  ]], R is [[72.92111969]
 [73.07475281]
 [73.28569031]
 [73.37545776]
 [73.50183105]].
[2019-04-06 17:09:44,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:09:44,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:09:44,351] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run12
[2019-04-06 17:09:44,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:09:44,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:09:44,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run12
[2019-04-06 17:09:48,879] A3C_AGENT_WORKER-Thread-6 INFO:Local step 30500, global step 491575: loss 0.4967
[2019-04-06 17:09:48,880] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 30500, global step 491575: learning rate 0.0000
[2019-04-06 17:09:54,812] A3C_AGENT_WORKER-Thread-19 INFO:Local step 30500, global step 492449: loss 0.6072
[2019-04-06 17:09:54,812] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 30500, global step 492449: learning rate 0.0000
[2019-04-06 17:09:57,693] A3C_AGENT_WORKER-Thread-10 INFO:Local step 30500, global step 492743: loss 0.5018
[2019-04-06 17:09:57,694] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 30500, global step 492743: learning rate 0.0000
[2019-04-06 17:09:59,388] A3C_AGENT_WORKER-Thread-14 INFO:Local step 30500, global step 492904: loss 0.5755
[2019-04-06 17:09:59,389] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 30500, global step 492904: learning rate 0.0000
[2019-04-06 17:09:59,484] A3C_AGENT_WORKER-Thread-20 INFO:Local step 30500, global step 492916: loss 0.4801
[2019-04-06 17:09:59,484] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 30500, global step 492916: learning rate 0.0000
[2019-04-06 17:09:59,664] A3C_AGENT_WORKER-Thread-4 INFO:Local step 30500, global step 492936: loss 0.5026
[2019-04-06 17:09:59,664] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 30500, global step 492936: learning rate 0.0000
[2019-04-06 17:10:04,076] A3C_AGENT_WORKER-Thread-15 INFO:Local step 30500, global step 493353: loss 0.4369
[2019-04-06 17:10:04,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 30500, global step 493353: learning rate 0.0000
[2019-04-06 17:10:05,797] A3C_AGENT_WORKER-Thread-2 INFO:Local step 30500, global step 493546: loss 0.4988
[2019-04-06 17:10:05,797] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 30500, global step 493546: learning rate 0.0000
[2019-04-06 17:10:13,522] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.31633735e-08 2.60117580e-04 2.22277080e-07 1.27488762e-01
 2.32313333e-08 8.72249305e-01 1.51798622e-06], sum to 1.0000
[2019-04-06 17:10:13,522] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9205
[2019-04-06 17:10:13,603] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 38.0, 0.0, 0.0, 26.0, 25.04288992214074, 0.2849126080900399, 0.0, 1.0, 40762.19613073687], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4071600.0000, 
sim time next is 4073400.0000, 
raw observation next is [-5.0, 39.5, 0.0, 0.0, 26.0, 24.96915110747197, 0.2588688546182062, 0.0, 1.0, 40642.267601035855], 
processed observation next is [1.0, 0.13043478260869565, 0.32409972299168976, 0.395, 0.0, 0.0, 0.6666666666666666, 0.5807625922893308, 0.5862896182060687, 0.0, 1.0, 0.19353460762398025], 
reward next is 0.8065, 
noisyNet noise sample is [array([1.7921281], dtype=float32), -0.636313]. 
=============================================
[2019-04-06 17:10:15,058] A3C_AGENT_WORKER-Thread-16 INFO:Local step 31000, global step 494371: loss 5.8969
[2019-04-06 17:10:15,059] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 31000, global step 494371: learning rate 0.0000
[2019-04-06 17:10:20,831] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.12425615e-08 1.36926283e-05 2.82437668e-07 6.76139863e-03
 1.47592449e-09 9.93224561e-01 3.44750539e-08], sum to 1.0000
[2019-04-06 17:10:20,831] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4266
[2019-04-06 17:10:20,886] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.7, 44.5, 272.0, 388.0, 26.0, 25.07063891066383, 0.3665799096049037, 0.0, 1.0, 12904.66412698957], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4887000.0000, 
sim time next is 4888800.0000, 
raw observation next is [2.0, 44.0, 254.0, 381.0, 26.0, 25.09910198082859, 0.3680211530898378, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.518005540166205, 0.44, 0.8466666666666667, 0.42099447513812155, 0.6666666666666666, 0.5915918317357157, 0.6226737176966126, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5405338], dtype=float32), 0.17827564]. 
=============================================
[2019-04-06 17:10:33,462] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.9626250e-09 8.4339035e-06 3.8332210e-08 1.5236180e-02 2.4364679e-09
 9.8475522e-01 9.1894059e-08], sum to 1.0000
[2019-04-06 17:10:33,462] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3235
[2019-04-06 17:10:33,559] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.2, 75.0, 0.0, 0.0, 26.0, 25.50258129104036, 0.4063201318972559, 0.0, 1.0, 36637.001523444684], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4323600.0000, 
sim time next is 4325400.0000, 
raw observation next is [4.35, 73.5, 0.0, 0.0, 26.0, 25.6859099440361, 0.4331339262078898, 0.0, 1.0, 12898.543083176875], 
processed observation next is [1.0, 0.043478260869565216, 0.5831024930747922, 0.735, 0.0, 0.0, 0.6666666666666666, 0.6404924953363418, 0.6443779754026299, 0.0, 1.0, 0.06142163372941369], 
reward next is 0.9386, 
noisyNet noise sample is [array([0.10187309], dtype=float32), 0.4988789]. 
=============================================
[2019-04-06 17:10:35,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:10:35,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:10:35,577] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run12
[2019-04-06 17:10:37,477] A3C_AGENT_WORKER-Thread-12 INFO:Local step 31000, global step 496744: loss 12.9946
[2019-04-06 17:10:37,479] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 31000, global step 496744: learning rate 0.0000
[2019-04-06 17:10:39,041] A3C_AGENT_WORKER-Thread-18 INFO:Local step 31000, global step 496888: loss 6.0916
[2019-04-06 17:10:39,051] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 31000, global step 496888: learning rate 0.0000
[2019-04-06 17:10:53,901] A3C_AGENT_WORKER-Thread-6 INFO:Local step 31000, global step 498343: loss 6.0314
[2019-04-06 17:10:53,927] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 31000, global step 498343: learning rate 0.0000
[2019-04-06 17:10:59,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:10:59,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:10:59,756] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run12
[2019-04-06 17:10:59,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:10:59,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:10:59,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run12
[2019-04-06 17:11:03,835] A3C_AGENT_WORKER-Thread-19 INFO:Local step 31000, global step 499329: loss 6.0624
[2019-04-06 17:11:03,835] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 31000, global step 499329: learning rate 0.0000
[2019-04-06 17:11:03,943] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2323529e-10 3.0417152e-06 1.9967658e-08 2.4783923e-03 4.3916176e-10
 9.9751854e-01 3.5573833e-10], sum to 1.0000
[2019-04-06 17:11:03,943] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5424
[2019-04-06 17:11:04,014] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.41070450152816, 0.4176353987332532, 0.0, 1.0, 35481.823540155056], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4689000.0000, 
sim time next is 4690800.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.44896716035373, 0.4212093371817348, 0.0, 1.0, 38937.73741050038], 
processed observation next is [1.0, 0.30434782608695654, 0.4349030470914128, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6207472633628109, 0.6404031123939116, 0.0, 1.0, 0.18541779719285895], 
reward next is 0.8146, 
noisyNet noise sample is [array([-0.9593631], dtype=float32), -0.40370804]. 
=============================================
[2019-04-06 17:11:05,390] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6667626e-10 8.4645189e-06 8.5833181e-09 9.9519594e-04 1.2558684e-09
 9.9899632e-01 3.3494487e-09], sum to 1.0000
[2019-04-06 17:11:05,390] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8509
[2019-04-06 17:11:05,447] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 72.0, 147.0, 0.0, 26.0, 25.99934111967787, 0.5363202649941156, 1.0, 1.0, 4151.202593384563], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4721400.0000, 
sim time next is 4723200.0000, 
raw observation next is [1.0, 72.0, 123.5, 5.5, 26.0, 26.16190214066036, 0.5469038866843668, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4903047091412743, 0.72, 0.4116666666666667, 0.0060773480662983425, 0.6666666666666666, 0.6801585117216966, 0.6823012955614556, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5584407], dtype=float32), 1.1355028]. 
=============================================
[2019-04-06 17:11:07,702] A3C_AGENT_WORKER-Thread-10 INFO:Local step 31000, global step 499630: loss 14.9139
[2019-04-06 17:11:07,702] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 31000, global step 499630: learning rate 0.0000
[2019-04-06 17:11:10,152] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.17716493e-08 4.74704357e-05 4.28845311e-07 2.03322060e-02
 1.48574255e-08 9.79619682e-01 9.99249892e-08], sum to 1.0000
[2019-04-06 17:11:10,152] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0802
[2019-04-06 17:11:10,424] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 45.5, 0.0, 0.0, 26.0, 24.97257433152551, 0.2953056297428565, 0.0, 1.0, 39540.5462512427], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4905000.0000, 
sim time next is 4906800.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 26.0, 24.97317584666333, 0.2914439917388436, 0.0, 1.0, 33865.208645895706], 
processed observation next is [0.0, 0.8260869565217391, 0.4903047091412743, 0.47, 0.0, 0.0, 0.6666666666666666, 0.5810979872219443, 0.5971479972462812, 0.0, 1.0, 0.16126289831378907], 
reward next is 0.8387, 
noisyNet noise sample is [array([-0.08573212], dtype=float32), -0.1263643]. 
=============================================
[2019-04-06 17:11:10,777] A3C_AGENT_WORKER-Thread-20 INFO:Local step 31000, global step 499870: loss 5.9421
[2019-04-06 17:11:10,778] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 31000, global step 499870: learning rate 0.0000
[2019-04-06 17:11:11,344] A3C_AGENT_WORKER-Thread-14 INFO:Local step 31000, global step 499927: loss 6.1015
[2019-04-06 17:11:11,344] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 31000, global step 499927: learning rate 0.0000
[2019-04-06 17:11:11,503] A3C_AGENT_WORKER-Thread-4 INFO:Local step 31000, global step 499948: loss 12.3350
[2019-04-06 17:11:11,503] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 31000, global step 499948: learning rate 0.0000
[2019-04-06 17:11:12,157] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 17:11:12,158] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:11:12,158] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:11:12,160] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run26
[2019-04-06 17:11:12,194] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:11:12,195] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:11:12,198] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run26
[2019-04-06 17:11:12,273] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:11:12,274] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:11:12,276] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run26
[2019-04-06 17:11:12,893] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:11:12,893] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:11:12,896] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run12
[2019-04-06 17:12:24,254] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.03893008], dtype=float32), 0.11770859]
[2019-04-06 17:12:24,254] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.35, 92.0, 0.0, 0.0, 26.0, 25.30625581143205, 0.5209274681551932, 0.0, 1.0, 71919.69807181541]
[2019-04-06 17:12:24,254] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 17:12:24,255] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.2187453e-09 7.5780226e-06 3.8267709e-09 1.4750748e-03 3.2839084e-10
 9.9851733e-01 2.8078539e-09], sampled 0.4304702588892134
[2019-04-06 17:13:32,721] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.1276 79964688.8054 535.2457
[2019-04-06 17:13:50,582] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 17:13:52,774] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 17:13:53,796] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 500000, evaluation results [500000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2454.1275617030196, 79964688.80543762, 535.245739731326, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 17:13:55,277] A3C_AGENT_WORKER-Thread-15 INFO:Local step 31000, global step 500214: loss 6.0439
[2019-04-06 17:13:55,278] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 31000, global step 500214: learning rate 0.0000
[2019-04-06 17:13:56,145] A3C_AGENT_WORKER-Thread-2 INFO:Local step 31000, global step 500329: loss 6.1367
[2019-04-06 17:13:56,145] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 31000, global step 500329: learning rate 0.0000
[2019-04-06 17:14:01,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:14:01,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:14:01,992] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run12
[2019-04-06 17:14:04,722] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:14:04,722] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:14:04,726] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run12
[2019-04-06 17:14:06,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:14:06,790] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:14:06,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run12
[2019-04-06 17:14:07,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:14:07,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:14:07,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run12
[2019-04-06 17:14:07,551] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:14:07,551] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:14:07,566] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run12
[2019-04-06 17:14:09,810] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:14:09,810] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:14:09,814] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run12
[2019-04-06 17:14:10,354] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:14:10,354] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:14:10,366] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run12
[2019-04-06 17:14:13,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.7202695e-10 6.8887630e-06 6.3816502e-10 1.7290814e-03 8.1623909e-11
 9.9826401e-01 4.3213114e-10], sum to 1.0000
[2019-04-06 17:14:13,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2231
[2019-04-06 17:14:13,855] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 114.5, 0.0, 26.0, 26.1146743801925, 0.5917960672695398, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1335600.0000, 
sim time next is 1337400.0000, 
raw observation next is [1.1, 92.0, 127.0, 0.0, 26.0, 26.11762005351053, 0.5914837078493996, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.49307479224376743, 0.92, 0.42333333333333334, 0.0, 0.6666666666666666, 0.6764683377925443, 0.6971612359498, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.49240422], dtype=float32), -0.43578443]. 
=============================================
[2019-04-06 17:15:04,923] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3874165e-09 2.2463964e-05 3.3635552e-09 2.3037228e-03 6.7641781e-10
 9.9767381e-01 1.5116388e-08], sum to 1.0000
[2019-04-06 17:15:04,923] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8527
[2019-04-06 17:15:05,129] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 59.0, 0.0, 0.0, 26.0, 25.11398295985711, 0.4170764127518058, 0.0, 1.0, 67959.72771199154], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2750400.0000, 
sim time next is 2752200.0000, 
raw observation next is [-5.5, 61.5, 0.0, 0.0, 26.0, 25.20096522452992, 0.4414822326163662, 0.0, 1.0, 103873.19080531127], 
processed observation next is [1.0, 0.8695652173913043, 0.3102493074792244, 0.615, 0.0, 0.0, 0.6666666666666666, 0.6000804353774933, 0.6471607442054554, 0.0, 1.0, 0.4946342419300537], 
reward next is 0.5054, 
noisyNet noise sample is [array([1.4626276], dtype=float32), 0.14906168]. 
=============================================
[2019-04-06 17:15:21,732] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7410142e-09 5.2916416e-06 8.8281826e-10 3.8131556e-04 5.1259347e-10
 9.9961346e-01 2.1245437e-09], sum to 1.0000
[2019-04-06 17:15:21,732] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1218
[2019-04-06 17:15:21,816] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 75.0, 0.0, 0.0, 26.0, 24.27214755433577, 0.05347054969547926, 0.0, 1.0, 41349.14253007646], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 702000.0000, 
sim time next is 703800.0000, 
raw observation next is [-3.1, 75.0, 0.0, 0.0, 26.0, 24.36413690236144, 0.05837372364424442, 0.0, 1.0, 41543.1962738983], 
processed observation next is [1.0, 0.13043478260869565, 0.37673130193905824, 0.75, 0.0, 0.0, 0.6666666666666666, 0.5303447418634534, 0.5194579078814148, 0.0, 1.0, 0.19782474416142046], 
reward next is 0.8022, 
noisyNet noise sample is [array([0.84043896], dtype=float32), 0.5886506]. 
=============================================
[2019-04-06 17:15:57,323] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3619924e-08 2.3568911e-05 1.4139565e-08 5.8230765e-02 7.6535036e-09
 9.4174564e-01 9.4450492e-09], sum to 1.0000
[2019-04-06 17:15:57,323] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9931
[2019-04-06 17:15:57,814] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 79.0, 0.0, 0.0, 26.0, 24.08315824990352, 0.1731443803505517, 1.0, 1.0, 150196.93931457587], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2619000.0000, 
sim time next is 2620800.0000, 
raw observation next is [-7.3, 79.0, 42.0, 4.0, 26.0, 25.35073236114454, 0.2980921106469629, 1.0, 1.0, 29410.457336385884], 
processed observation next is [1.0, 0.34782608695652173, 0.26038781163434904, 0.79, 0.14, 0.004419889502762431, 0.6666666666666666, 0.6125610300953784, 0.599364036882321, 1.0, 1.0, 0.14004979683993277], 
reward next is 0.8600, 
noisyNet noise sample is [array([0.04604483], dtype=float32), -0.0447717]. 
=============================================
[2019-04-06 17:16:57,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4584830e-09 7.8148432e-06 1.1827138e-08 1.5082876e-02 1.6490496e-09
 9.8490924e-01 1.8221312e-09], sum to 1.0000
[2019-04-06 17:16:57,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9478
[2019-04-06 17:16:57,461] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 82.0, 123.0, 77.5, 26.0, 25.48065807651072, 0.3381847230361474, 1.0, 1.0, 6247.16051195282], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2106000.0000, 
sim time next is 2107800.0000, 
raw observation next is [-7.8, 82.0, 174.0, 118.0, 26.0, 25.66157099436104, 0.384601334618856, 1.0, 1.0, 26280.768846567866], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.82, 0.58, 0.13038674033149172, 0.6666666666666666, 0.6384642495300866, 0.628200444872952, 1.0, 1.0, 0.12514651831698984], 
reward next is 0.8749, 
noisyNet noise sample is [array([0.26024637], dtype=float32), -1.4017863]. 
=============================================
[2019-04-06 17:17:09,188] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-06 17:17:09,188] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:17:09,188] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:17:09,189] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:17:09,191] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run27
[2019-04-06 17:17:09,190] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:17:09,214] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:17:09,217] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run27
[2019-04-06 17:17:09,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:17:09,271] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run27
[2019-04-06 17:19:29,405] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3885 79967197.3248 535.2671
[2019-04-06 17:19:48,133] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.2181 87786155.3321 515.2860
[2019-04-06 17:19:50,586] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 17:19:51,610] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 520000, evaluation results [520000.0, 2416.2180852243914, 87786155.33207561, 515.2860057103666, 2453.388471443006, 79967197.3248232, 535.2671102210136, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 17:20:00,415] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8498985e-10 2.7397040e-05 5.5709286e-09 5.3910762e-03 1.8756968e-10
 9.9458152e-01 1.5651966e-09], sum to 1.0000
[2019-04-06 17:20:00,415] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2871
[2019-04-06 17:20:00,452] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.9414683e-10 3.1755611e-05 1.5014635e-08 7.3263841e-03 4.4985457e-10
 9.9264187e-01 3.4001413e-09], sum to 1.0000
[2019-04-06 17:20:00,452] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8029
[2019-04-06 17:20:00,517] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.9, 85.0, 0.0, 0.0, 26.0, 24.37617044239364, 0.1664437117031319, 0.0, 1.0, 42431.633437385804], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1989000.0000, 
sim time next is 1990800.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.34864420744259, 0.1508939989034711, 0.0, 1.0, 42111.1267383309], 
processed observation next is [1.0, 0.043478260869565216, 0.2908587257617729, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5290536839535491, 0.5502979996344903, 0.0, 1.0, 0.20052917494443287], 
reward next is 0.7995, 
noisyNet noise sample is [array([0.8950746], dtype=float32), -1.0632898]. 
=============================================
[2019-04-06 17:20:00,701] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 17.0, 0.0, 26.0, 25.36542506198587, 0.3421721838256519, 1.0, 1.0, 21251.25282001037], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2048400.0000, 
sim time next is 2050200.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 26.0, 24.81971418054982, 0.2448700628492922, 1.0, 1.0, 93463.44777942113], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.82, 0.0, 0.0, 0.6666666666666666, 0.5683095150458183, 0.5816233542830974, 1.0, 1.0, 0.4450640370448625], 
reward next is 0.5549, 
noisyNet noise sample is [array([0.59451455], dtype=float32), 0.2510426]. 
=============================================
[2019-04-06 17:20:32,036] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:20:32,036] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:20:32,040] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run13
[2019-04-06 17:20:44,919] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1508534e-09 8.0104428e-06 2.7903040e-09 2.1072479e-03 1.5709940e-09
 9.9788469e-01 7.8921998e-09], sum to 1.0000
[2019-04-06 17:20:44,919] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9032
[2019-04-06 17:20:45,120] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.0328307e-08 9.1399095e-05 1.2088826e-07 5.6266831e-03 3.4629249e-08
 9.9428177e-01 1.2481864e-08], sum to 1.0000
[2019-04-06 17:20:45,120] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5630
[2019-04-06 17:20:45,170] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 60.0, 0.0, 0.0, 26.0, 25.064255456347, 0.3939407626489026, 1.0, 1.0, 80328.33734739362], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2660400.0000, 
sim time next is 2662200.0000, 
raw observation next is [-1.2, 61.5, 0.0, 0.0, 26.0, 25.11451075228432, 0.3537222564374726, 0.0, 1.0, 7809.80410654721], 
processed observation next is [1.0, 0.8260869565217391, 0.42936288088642666, 0.615, 0.0, 0.0, 0.6666666666666666, 0.5928758960236934, 0.6179074188124909, 0.0, 1.0, 0.037189543364510524], 
reward next is 0.9628, 
noisyNet noise sample is [array([0.19412], dtype=float32), 0.18709263]. 
=============================================
[2019-04-06 17:20:45,202] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 57.5, 83.0, 667.0, 26.0, 25.11493370060965, 0.4137309290075419, 0.0, 1.0, 25851.35284518979], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2993400.0000, 
sim time next is 2995200.0000, 
raw observation next is [-1.0, 55.0, 69.5, 570.5, 26.0, 25.14809414507651, 0.4077000064464505, 0.0, 1.0, 12471.872996823731], 
processed observation next is [0.0, 0.6956521739130435, 0.4349030470914128, 0.55, 0.23166666666666666, 0.6303867403314917, 0.6666666666666666, 0.5956745120897091, 0.6359000021488168, 0.0, 1.0, 0.059389871413446337], 
reward next is 0.9406, 
noisyNet noise sample is [array([-2.1447423], dtype=float32), 1.5838453]. 
=============================================
[2019-04-06 17:21:06,895] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.8796789e-08 8.0581434e-05 5.0947227e-07 1.1287535e-02 2.0976636e-08
 9.8863119e-01 6.4036684e-08], sum to 1.0000
[2019-04-06 17:21:06,895] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5832
[2019-04-06 17:21:07,066] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 166.0, 78.0, 26.0, 24.97749295070201, 0.2861800859435102, 0.0, 1.0, 22121.91670948669], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2973600.0000, 
sim time next is 2975400.0000, 
raw observation next is [-3.5, 68.0, 178.0, 24.0, 26.0, 24.88820229025374, 0.3160736651553991, 0.0, 1.0, 81935.86165238524], 
processed observation next is [0.0, 0.43478260869565216, 0.36565096952908593, 0.68, 0.5933333333333334, 0.026519337016574586, 0.6666666666666666, 0.5740168575211451, 0.605357888385133, 0.0, 1.0, 0.39017076977326304], 
reward next is 0.6098, 
noisyNet noise sample is [array([0.04145681], dtype=float32), -1.1692421]. 
=============================================
[2019-04-06 17:21:08,585] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8344791e-10 5.6568533e-06 3.6045671e-09 1.1964224e-03 8.9783105e-11
 9.9879789e-01 1.6335678e-09], sum to 1.0000
[2019-04-06 17:21:08,585] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8756
[2019-04-06 17:21:08,632] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.0, 42.0, 111.0, 728.5, 26.0, 27.232602144565, 0.7609039229163285, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4356000.0000, 
sim time next is 4357800.0000, 
raw observation next is [11.3, 38.0, 115.0, 780.0, 26.0, 27.51645600346331, 0.8247859615662164, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.7756232686980611, 0.38, 0.38333333333333336, 0.861878453038674, 0.6666666666666666, 0.7930380002886093, 0.7749286538554054, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.18803543], dtype=float32), 0.38066438]. 
=============================================
[2019-04-06 17:21:13,829] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8966828e-09 7.9833189e-06 3.5017995e-09 1.4586125e-03 1.1023100e-10
 9.9853337e-01 4.7012163e-09], sum to 1.0000
[2019-04-06 17:21:13,830] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6358
[2019-04-06 17:21:14,087] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.2, 39.0, 37.0, 707.0, 26.0, 26.33558924052229, 0.3557428223438013, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 401400.0000, 
sim time next is 403200.0000, 
raw observation next is [-8.9, 38.0, 29.0, 555.0, 26.0, 25.76063225726051, 0.3996183246728098, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.21606648199445982, 0.38, 0.09666666666666666, 0.6132596685082873, 0.6666666666666666, 0.6467193547717093, 0.6332061082242699, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1120327], dtype=float32), 0.1049057]. 
=============================================
[2019-04-06 17:21:21,655] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2817726e-11 1.1619336e-05 4.7071232e-11 4.4724139e-04 9.8348808e-11
 9.9954116e-01 7.9138009e-11], sum to 1.0000
[2019-04-06 17:21:21,655] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5771
[2019-04-06 17:21:21,848] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.0, 93.0, 113.5, 814.0, 26.0, 27.22180467989663, 0.814368488653337, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3153600.0000, 
sim time next is 3155400.0000, 
raw observation next is [7.5, 96.5, 113.0, 823.0, 26.0, 27.31869484662328, 0.836357189710843, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6703601108033241, 0.965, 0.37666666666666665, 0.9093922651933701, 0.6666666666666666, 0.7765579038852733, 0.7787857299036144, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7769903], dtype=float32), 0.54001063]. 
=============================================
[2019-04-06 17:21:25,532] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:21:25,532] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:21:25,535] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run13
[2019-04-06 17:21:44,822] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7928243e-10 5.1706547e-06 2.0181685e-09 6.9185731e-04 1.1670280e-10
 9.9930298e-01 1.8530497e-09], sum to 1.0000
[2019-04-06 17:21:44,822] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3861
[2019-04-06 17:21:44,939] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 67.0, 61.0, 513.0, 26.0, 26.13145752213483, 0.6157530806092221, 1.0, 1.0, 32044.191108062776], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3429000.0000, 
sim time next is 3430800.0000, 
raw observation next is [2.0, 67.0, 36.5, 317.0, 26.0, 26.4530671401735, 0.4663873598456376, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.67, 0.12166666666666667, 0.35027624309392263, 0.6666666666666666, 0.7044222616811249, 0.6554624532818792, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.06436224], dtype=float32), 0.028847465]. 
=============================================
[2019-04-06 17:21:45,038] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.6342037e-09 6.3600737e-06 3.6761938e-09 3.3651851e-03 1.1383886e-09
 9.9662846e-01 2.9875803e-08], sum to 1.0000
[2019-04-06 17:21:45,039] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4035
[2019-04-06 17:21:45,108] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 29.0, 0.0, 0.0, 26.0, 25.6307144646802, 0.5378453309942116, 0.0, 1.0, 130956.6245131941], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5000400.0000, 
sim time next is 5002200.0000, 
raw observation next is [3.5, 33.0, 0.0, 0.0, 26.0, 25.69370977139023, 0.5792816883454509, 0.0, 1.0, 59512.07749713241], 
processed observation next is [1.0, 0.9130434782608695, 0.5595567867036012, 0.33, 0.0, 0.0, 0.6666666666666666, 0.6411424809491857, 0.6930938961151503, 0.0, 1.0, 0.2833908452244401], 
reward next is 0.7166, 
noisyNet noise sample is [array([0.7021445], dtype=float32), 0.1794557]. 
=============================================
[2019-04-06 17:21:46,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:21:46,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:21:46,733] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run13
[2019-04-06 17:21:52,772] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:21:52,772] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:21:52,799] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run13
[2019-04-06 17:22:03,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:22:03,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:22:03,620] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run13
[2019-04-06 17:22:24,051] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.7521395e-09 3.7676211e-05 8.4734531e-09 1.5767403e-02 2.0521056e-09
 9.8419487e-01 1.4744221e-08], sum to 1.0000
[2019-04-06 17:22:24,051] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8126
[2019-04-06 17:22:24,097] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 80.0, 0.0, 0.0, 26.0, 25.61494848365923, 0.5138844977000021, 0.0, 1.0, 13807.001733434916], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4431600.0000, 
sim time next is 4433400.0000, 
raw observation next is [2.0, 80.0, 0.0, 0.0, 26.0, 25.57521569673165, 0.5048154243686821, 1.0, 1.0, 10060.65260821045], 
processed observation next is [1.0, 0.30434782608695654, 0.518005540166205, 0.8, 0.0, 0.0, 0.6666666666666666, 0.6312679747276375, 0.6682718081228941, 1.0, 1.0, 0.04790786956290691], 
reward next is 0.9521, 
noisyNet noise sample is [array([-0.95735663], dtype=float32), -0.916068]. 
=============================================
[2019-04-06 17:22:36,011] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-06 17:22:36,013] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:22:36,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:22:36,015] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run28
[2019-04-06 17:22:36,177] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:22:36,177] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:22:36,179] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run28
[2019-04-06 17:22:36,281] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:22:36,288] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:22:36,298] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run28
[2019-04-06 17:24:55,257] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3748 79991956.7854 535.1864
[2019-04-06 17:25:13,135] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 17:25:16,272] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.5879 91914664.8318 409.3138
[2019-04-06 17:25:17,294] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 540000, evaluation results [540000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.374809603911, 79991956.78540477, 535.1864255395496, 2396.5878639248335, 91914664.83175536, 409.3138131877596]
[2019-04-06 17:25:29,567] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:25:29,567] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:25:29,571] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run13
[2019-04-06 17:25:31,949] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0169291e-09 8.9567345e-07 1.7696507e-10 9.6015853e-04 4.5218496e-10
 9.9903893e-01 4.3648743e-10], sum to 1.0000
[2019-04-06 17:25:31,949] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3397
[2019-04-06 17:25:31,998] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.0, 42.0, 111.0, 728.5, 26.0, 27.23080514595779, 0.7617513785252381, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4356000.0000, 
sim time next is 4357800.0000, 
raw observation next is [11.3, 38.0, 115.0, 780.0, 26.0, 27.51441489806863, 0.825551155142101, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.7756232686980611, 0.38, 0.38333333333333336, 0.861878453038674, 0.6666666666666666, 0.7928679081723858, 0.7751837183807003, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.71890473], dtype=float32), -0.322988]. 
=============================================
[2019-04-06 17:25:43,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:25:43,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:25:43,192] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run13
[2019-04-06 17:25:43,401] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:25:43,402] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:25:43,415] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run13
[2019-04-06 17:25:43,568] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:25:43,572] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:25:43,594] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run13
[2019-04-06 17:25:51,794] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0742411e-10 1.1298089e-06 4.3334225e-09 2.7148507e-03 2.9582603e-10
 9.9728405e-01 1.9162261e-09], sum to 1.0000
[2019-04-06 17:25:51,812] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3061
[2019-04-06 17:25:51,866] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 50.0, 0.0, 0.0, 26.0, 25.01348269307109, 0.2339237049121905, 0.0, 1.0, 38635.529081155546], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4946400.0000, 
sim time next is 4948200.0000, 
raw observation next is [-3.0, 50.0, 0.0, 0.0, 26.0, 25.02455404340505, 0.2279256812161097, 0.0, 1.0, 38644.97982566009], 
processed observation next is [1.0, 0.2608695652173913, 0.3795013850415513, 0.5, 0.0, 0.0, 0.6666666666666666, 0.5853795036170876, 0.5759752270720365, 0.0, 1.0, 0.18402371345552423], 
reward next is 0.8160, 
noisyNet noise sample is [array([1.2134631], dtype=float32), -1.7343712]. 
=============================================
[2019-04-06 17:25:59,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:25:59,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:25:59,780] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run13
[2019-04-06 17:26:01,430] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:26:01,430] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:26:01,435] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run13
[2019-04-06 17:26:03,184] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:26:03,184] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:26:03,188] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run13
[2019-04-06 17:26:04,163] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8674634e-09 1.9771116e-05 1.5160218e-08 8.1049046e-03 5.0164140e-10
 9.9187535e-01 9.9037223e-09], sum to 1.0000
[2019-04-06 17:26:04,164] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2201
[2019-04-06 17:26:04,258] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 40.0, 0.0, 0.0, 26.0, 25.54191001228687, 0.4685572209891618, 0.0, 1.0, 40947.2948606682], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5013000.0000, 
sim time next is 5014800.0000, 
raw observation next is [1.0, 40.0, 0.0, 0.0, 26.0, 25.61258604238947, 0.4561922543479365, 0.0, 1.0, 12495.99023695764], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 0.4, 0.0, 0.0, 0.6666666666666666, 0.6343821701991225, 0.6520640847826454, 0.0, 1.0, 0.059504715414083996], 
reward next is 0.9405, 
noisyNet noise sample is [array([1.0811294], dtype=float32), 1.5102644]. 
=============================================
[2019-04-06 17:26:06,874] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:26:06,874] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:26:06,886] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run13
[2019-04-06 17:26:07,727] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:26:07,728] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:26:07,766] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run13
[2019-04-06 17:26:07,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:26:07,858] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:26:07,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run13
[2019-04-06 17:26:08,827] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:26:08,827] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:26:08,830] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run13
[2019-04-06 17:26:17,218] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0965044e-10 1.3582677e-06 3.1615502e-10 7.5767707e-04 2.8594113e-10
 9.9924099e-01 6.2388494e-10], sum to 1.0000
[2019-04-06 17:26:17,218] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6331
[2019-04-06 17:26:17,427] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 46.0, 0.0, 26.0, 25.90887482389883, 0.5152775641736477, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1438200.0000, 
sim time next is 1440000.0000, 
raw observation next is [1.1, 92.0, 32.0, 0.0, 26.0, 24.68822378149901, 0.4061754533715245, 1.0, 1.0, 65533.871958337935], 
processed observation next is [1.0, 0.6956521739130435, 0.49307479224376743, 0.92, 0.10666666666666667, 0.0, 0.6666666666666666, 0.5573519817915841, 0.6353918177905081, 1.0, 1.0, 0.3120660569444664], 
reward next is 0.6879, 
noisyNet noise sample is [array([-1.6327614], dtype=float32), 0.14711563]. 
=============================================
[2019-04-06 17:26:17,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[92.829834]
 [93.29631 ]
 [93.60211 ]
 [93.740135]
 [93.727844]], R is [[92.56945801]
 [92.64376068]
 [92.7173233 ]
 [92.76002502]
 [92.83242798]].
[2019-04-06 17:26:30,338] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.1550952e-08 2.3471741e-06 1.5506137e-08 2.3951933e-03 5.1555082e-10
 9.9760240e-01 3.1750385e-08], sum to 1.0000
[2019-04-06 17:26:30,338] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3463
[2019-04-06 17:26:30,394] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.2, 52.0, 0.0, 0.0, 26.0, 22.89292956578316, -0.2409242260355984, 0.0, 1.0, 46298.89603337892], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 446400.0000, 
sim time next is 448200.0000, 
raw observation next is [-10.9, 52.0, 0.0, 0.0, 26.0, 22.70768505974769, -0.257841764739923, 0.0, 1.0, 46613.16107874123], 
processed observation next is [1.0, 0.17391304347826086, 0.16066481994459833, 0.52, 0.0, 0.0, 0.6666666666666666, 0.39230708831230743, 0.4140527450866924, 0.0, 1.0, 0.22196743370829156], 
reward next is 0.7780, 
noisyNet noise sample is [array([0.7018135], dtype=float32), -1.5310264]. 
=============================================
[2019-04-06 17:26:44,878] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3323268e-10 3.7266748e-08 1.3975790e-10 1.8377921e-03 6.5813626e-12
 9.9816221e-01 8.7508646e-11], sum to 1.0000
[2019-04-06 17:26:44,878] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1804
[2019-04-06 17:26:45,107] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.3, 92.0, 15.5, 0.0, 26.0, 25.49241399389967, 0.4995711225743403, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1670400.0000, 
sim time next is 1672200.0000, 
raw observation next is [2.75, 92.0, 30.0, 0.0, 26.0, 25.61121932779211, 0.5147705215474657, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.5387811634349031, 0.92, 0.1, 0.0, 0.6666666666666666, 0.6342682773160092, 0.6715901738491552, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.507601], dtype=float32), 0.54613096]. 
=============================================
[2019-04-06 17:26:52,126] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2422925e-07 1.7631057e-04 3.3995214e-08 8.6507060e-02 1.1854519e-08
 9.1331613e-01 2.9371921e-07], sum to 1.0000
[2019-04-06 17:26:52,126] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6615
[2019-04-06 17:26:52,191] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.6, 49.0, 0.0, 0.0, 26.0, 24.35310657660948, 0.1174386925190349, 0.0, 1.0, 44990.234776254474], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 424800.0000, 
sim time next is 426600.0000, 
raw observation next is [-11.15, 51.5, 0.0, 0.0, 26.0, 24.20522547848764, 0.08109497353376048, 0.0, 1.0, 44797.11493299131], 
processed observation next is [1.0, 0.9565217391304348, 0.15373961218836565, 0.515, 0.0, 0.0, 0.6666666666666666, 0.5171021232073034, 0.5270316578445868, 0.0, 1.0, 0.21331959491900623], 
reward next is 0.7867, 
noisyNet noise sample is [array([-1.2425104], dtype=float32), -0.4643012]. 
=============================================
[2019-04-06 17:27:25,170] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.77313705e-09 7.53470522e-05 1.29574875e-08 1.33805405e-02
 6.30302610e-09 9.86543953e-01 7.24699802e-08], sum to 1.0000
[2019-04-06 17:27:25,170] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6356
[2019-04-06 17:27:25,640] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 33.5, 0.0, 0.0, 26.0, 23.53622986955531, 0.1331194530708159, 1.0, 1.0, 130941.06600763433], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2831400.0000, 
sim time next is 2833200.0000, 
raw observation next is [3.0, 37.0, 0.0, 0.0, 26.0, 24.55325106825936, 0.3453595654161898, 1.0, 1.0, 161834.66334123877], 
processed observation next is [1.0, 0.8260869565217391, 0.5457063711911359, 0.37, 0.0, 0.0, 0.6666666666666666, 0.54610425568828, 0.6151198551387299, 1.0, 1.0, 0.7706412540058989], 
reward next is 0.2294, 
noisyNet noise sample is [array([1.0469944], dtype=float32), -0.7347688]. 
=============================================
[2019-04-06 17:27:49,299] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7418426e-10 8.5381765e-07 6.3283059e-11 7.0200249e-04 1.2447735e-10
 9.9929714e-01 5.5113281e-10], sum to 1.0000
[2019-04-06 17:27:49,300] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1185
[2019-04-06 17:27:49,451] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.8, 94.5, 18.0, 0.0, 26.0, 25.69498489815761, 0.4854196809879373, 1.0, 1.0, 17432.152614956867], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1355400.0000, 
sim time next is 1357200.0000, 
raw observation next is [0.5, 96.0, 9.0, 0.0, 26.0, 25.05375484092359, 0.4296938118634375, 1.0, 1.0, 64067.944897116955], 
processed observation next is [1.0, 0.7391304347826086, 0.4764542936288089, 0.96, 0.03, 0.0, 0.6666666666666666, 0.5878129034102993, 0.6432312706211458, 1.0, 1.0, 0.30508545189103314], 
reward next is 0.6949, 
noisyNet noise sample is [array([-0.16867279], dtype=float32), 1.0221059]. 
=============================================
[2019-04-06 17:27:57,143] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0674750e-09 2.3321236e-05 2.0804988e-08 7.9205018e-03 9.0287759e-09
 9.9205619e-01 3.9189679e-08], sum to 1.0000
[2019-04-06 17:27:57,143] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4633
[2019-04-06 17:27:57,528] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.45, 55.5, 0.0, 0.0, 26.0, 25.14303542058654, 0.3185369845387978, 1.0, 1.0, 33234.472908468706], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 761400.0000, 
sim time next is 763200.0000, 
raw observation next is [-5.0, 58.0, 0.0, 0.0, 26.0, 24.92430657300488, 0.3093445848210389, 1.0, 1.0, 84551.03645927824], 
processed observation next is [1.0, 0.8695652173913043, 0.32409972299168976, 0.58, 0.0, 0.0, 0.6666666666666666, 0.5770255477504067, 0.603114861607013, 1.0, 1.0, 0.4026239831394202], 
reward next is 0.5974, 
noisyNet noise sample is [array([2.1217306], dtype=float32), 0.315379]. 
=============================================
[2019-04-06 17:28:02,124] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0465668e-07 4.4776930e-06 1.8480571e-07 4.8947306e-03 2.2736183e-08
 9.9510044e-01 1.1985921e-07], sum to 1.0000
[2019-04-06 17:28:02,124] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8924
[2019-04-06 17:28:02,505] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 45.0, 42.5, 37.0, 26.0, 24.9572562109057, 0.2818868008002627, 0.0, 1.0, 40030.2765305523], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2394000.0000, 
sim time next is 2395800.0000, 
raw observation next is [-1.15, 44.5, 0.0, 0.0, 26.0, 24.95570376541222, 0.2655453558214748, 0.0, 1.0, 40234.161814138984], 
processed observation next is [0.0, 0.7391304347826086, 0.4307479224376732, 0.445, 0.0, 0.0, 0.6666666666666666, 0.5796419804510183, 0.5885151186071583, 0.0, 1.0, 0.19159124673399516], 
reward next is 0.8084, 
noisyNet noise sample is [array([1.9562846], dtype=float32), 1.084758]. 
=============================================
[2019-04-06 17:28:23,532] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.0144918e-09 3.4165356e-07 2.2423843e-09 5.2069203e-04 7.3190365e-10
 9.9947900e-01 6.2414216e-09], sum to 1.0000
[2019-04-06 17:28:23,532] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2472
[2019-04-06 17:28:23,659] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 26.0, 24.79001587163654, 0.268831548007806, 0.0, 1.0, 38501.83959157463], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2336400.0000, 
sim time next is 2338200.0000, 
raw observation next is [-2.3, 62.0, 0.0, 0.0, 26.0, 24.78279101768214, 0.2492490475083805, 0.0, 1.0, 38571.34018430544], 
processed observation next is [0.0, 0.043478260869565216, 0.3988919667590028, 0.62, 0.0, 0.0, 0.6666666666666666, 0.565232584806845, 0.5830830158361269, 0.0, 1.0, 0.18367304849669255], 
reward next is 0.8163, 
noisyNet noise sample is [array([-2.2772746], dtype=float32), 0.36035854]. 
=============================================
[2019-04-06 17:28:28,947] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-06 17:28:28,990] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:28:28,990] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:28:28,992] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run29
[2019-04-06 17:28:29,109] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:28:29,109] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:28:29,111] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run29
[2019-04-06 17:28:29,213] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:28:29,214] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:28:29,216] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run29
[2019-04-06 17:30:48,943] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.8856 79991956.7854 535.1864
[2019-04-06 17:31:06,174] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.9138 87799002.1168 515.3043
[2019-04-06 17:31:08,937] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 17:31:09,958] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 560000, evaluation results [560000.0, 2415.913755201966, 87799002.11678837, 515.3042642146117, 2453.885617275453, 79991956.78540477, 535.1864255395496, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 17:31:11,191] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.1419670e-09 3.8273470e-07 1.0845007e-09 4.4615748e-03 4.4326581e-11
 9.9553812e-01 1.6683939e-10], sum to 1.0000
[2019-04-06 17:31:11,191] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1122
[2019-04-06 17:31:11,251] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 26.0, 25.44406321659527, 0.5634002874657053, 0.0, 1.0, 37973.38404411029], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1314000.0000, 
sim time next is 1315800.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 26.0, 25.55343473028335, 0.5325912291564134, 0.0, 1.0, 6248.06674945621], 
processed observation next is [1.0, 0.21739130434782608, 0.5069252077562327, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6294528941902792, 0.6775304097188045, 0.0, 1.0, 0.029752698806934336], 
reward next is 0.9702, 
noisyNet noise sample is [array([0.47574085], dtype=float32), 1.4337922]. 
=============================================
[2019-04-06 17:31:21,270] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5884204e-08 1.3183013e-05 1.2765313e-08 5.0642258e-03 8.2322232e-10
 9.9492258e-01 2.1554916e-08], sum to 1.0000
[2019-04-06 17:31:21,273] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0392
[2019-04-06 17:31:21,334] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 82.0, 0.0, 0.0, 26.0, 24.17710118793788, 0.05934080952268406, 0.0, 1.0, 44982.26308792673], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1900800.0000, 
sim time next is 1902600.0000, 
raw observation next is [-7.3, 78.5, 0.0, 0.0, 26.0, 24.13183527723151, 0.05253248866487997, 0.0, 1.0, 45072.51582671764], 
processed observation next is [1.0, 0.0, 0.26038781163434904, 0.785, 0.0, 0.0, 0.6666666666666666, 0.5109862731026258, 0.51751082955496, 0.0, 1.0, 0.21463102774627446], 
reward next is 0.7854, 
noisyNet noise sample is [array([0.14580558], dtype=float32), -0.54252356]. 
=============================================
[2019-04-06 17:31:29,142] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.8640627e-10 1.4711628e-05 1.9242810e-09 2.8719420e-03 3.6350176e-11
 9.9711335e-01 7.4215667e-10], sum to 1.0000
[2019-04-06 17:31:29,142] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0176
[2019-04-06 17:31:29,372] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 100.0, 0.0, 0.0, 26.0, 25.42849150424978, 0.4161167550133784, 0.0, 1.0, 21884.59912496031], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1494000.0000, 
sim time next is 1495800.0000, 
raw observation next is [1.1, 100.0, 0.0, 0.0, 26.0, 25.49721344961542, 0.4669725934444801, 0.0, 1.0, 27424.501195085915], 
processed observation next is [1.0, 0.30434782608695654, 0.49307479224376743, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6247677874679516, 0.65565753114816, 0.0, 1.0, 0.13059286283374244], 
reward next is 0.8694, 
noisyNet noise sample is [array([-0.6784252], dtype=float32), 0.23175372]. 
=============================================
[2019-04-06 17:31:45,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7303340e-09 3.3885196e-06 1.6088185e-08 9.9071655e-03 2.0763968e-09
 9.9008942e-01 1.3814568e-09], sum to 1.0000
[2019-04-06 17:31:45,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8688
[2019-04-06 17:31:45,742] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.8, 84.5, 69.0, 0.0, 26.0, 25.5078809778751, 0.2841913417377184, 1.0, 1.0, 6241.487953200761], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2021400.0000, 
sim time next is 2023200.0000, 
raw observation next is [-5.6, 83.0, 85.5, 0.0, 26.0, 25.55203511097187, 0.2856968105897141, 1.0, 1.0, 23221.409190029914], 
processed observation next is [1.0, 0.43478260869565216, 0.30747922437673136, 0.83, 0.285, 0.0, 0.6666666666666666, 0.629336259247656, 0.5952322701965714, 1.0, 1.0, 0.11057813900014245], 
reward next is 0.8894, 
noisyNet noise sample is [array([-0.55826235], dtype=float32), 1.2630864]. 
=============================================
[2019-04-06 17:31:51,297] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4966525e-09 1.7062261e-07 2.5954512e-09 7.8997947e-04 1.2970816e-09
 9.9920976e-01 4.1319566e-09], sum to 1.0000
[2019-04-06 17:31:51,297] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0477
[2019-04-06 17:31:51,347] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.35, 73.5, 0.0, 0.0, 26.0, 25.68874446386926, 0.4318304200702539, 0.0, 1.0, 12680.089974220618], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4325400.0000, 
sim time next is 4327200.0000, 
raw observation next is [4.5, 72.0, 0.0, 0.0, 26.0, 25.75996148426364, 0.4042384615017142, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.5872576177285319, 0.72, 0.0, 0.0, 0.6666666666666666, 0.6466634570219701, 0.6347461538339048, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.41999394], dtype=float32), 0.64962894]. 
=============================================
[2019-04-06 17:32:30,050] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:32:30,050] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:32:30,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run14
[2019-04-06 17:32:32,926] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0489595e-08 3.5713415e-06 6.4788949e-08 4.2626918e-03 1.4065888e-09
 9.9573368e-01 2.5093973e-08], sum to 1.0000
[2019-04-06 17:32:32,926] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5336
[2019-04-06 17:32:33,003] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.0, 25.0, 0.0, 0.0, 26.0, 25.52662177378309, 0.4014924312083527, 0.0, 1.0, 8716.014409621543], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3628800.0000, 
sim time next is 3630600.0000, 
raw observation next is [9.0, 25.0, 0.0, 0.0, 26.0, 25.62636124295758, 0.3908884888868768, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.0, 0.7119113573407203, 0.25, 0.0, 0.0, 0.6666666666666666, 0.6355301035797982, 0.6302961629622922, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.04174], dtype=float32), 0.27959126]. 
=============================================
[2019-04-06 17:32:36,352] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9629723e-10 3.9149454e-06 1.6468203e-09 7.4003367e-03 1.2230844e-10
 9.9259573e-01 6.7521594e-10], sum to 1.0000
[2019-04-06 17:32:36,353] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6329
[2019-04-06 17:32:36,491] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 26.0, 25.36210841115112, 0.4368001200300304, 0.0, 1.0, 39892.59313842866], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3891600.0000, 
sim time next is 3893400.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 26.0, 25.46512751628713, 0.4225176580688575, 0.0, 1.0, 14510.397715974404], 
processed observation next is [1.0, 0.043478260869565216, 0.40720221606648205, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6220939596905941, 0.6408392193562858, 0.0, 1.0, 0.06909713198083049], 
reward next is 0.9309, 
noisyNet noise sample is [array([-0.2873583], dtype=float32), -0.73546046]. 
=============================================
[2019-04-06 17:33:22,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9128577e-08 1.2295712e-05 1.7454418e-08 3.2005955e-02 1.1000786e-08
 9.6798170e-01 2.0387841e-08], sum to 1.0000
[2019-04-06 17:33:22,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8377
[2019-04-06 17:33:23,265] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 33.5, 0.0, 0.0, 26.0, 23.5362317550865, 0.133118365163699, 1.0, 1.0, 130941.05855622457], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2831400.0000, 
sim time next is 2833200.0000, 
raw observation next is [3.0, 37.0, 0.0, 0.0, 26.0, 24.55321676239638, 0.3453600803666241, 1.0, 1.0, 161841.59860862765], 
processed observation next is [1.0, 0.8260869565217391, 0.5457063711911359, 0.37, 0.0, 0.0, 0.6666666666666666, 0.5461013968663652, 0.6151200267888747, 1.0, 1.0, 0.7706742790887031], 
reward next is 0.2293, 
noisyNet noise sample is [array([-0.85856605], dtype=float32), -1.2390704]. 
=============================================
[2019-04-06 17:33:25,803] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.96757660e-10 2.50828157e-06 7.55484209e-09 1.00410385e-02
 1.42222290e-09 9.89956498e-01 1.83206639e-09], sum to 1.0000
[2019-04-06 17:33:25,803] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0845
[2019-04-06 17:33:25,894] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 82.5, 0.0, 0.0, 26.0, 25.10685237876208, 0.2943295384197511, 0.0, 1.0, 56205.19898518595], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2860200.0000, 
sim time next is 2862000.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 26.0, 25.07550529949948, 0.2961366071193756, 0.0, 1.0, 54700.58553421086], 
processed observation next is [1.0, 0.13043478260869565, 0.4903047091412743, 0.86, 0.0, 0.0, 0.6666666666666666, 0.5896254416249566, 0.5987122023731252, 0.0, 1.0, 0.26047897873433745], 
reward next is 0.7395, 
noisyNet noise sample is [array([0.41623685], dtype=float32), 0.37378496]. 
=============================================
[2019-04-06 17:33:25,926] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[89.39806 ]
 [89.01915 ]
 [87.843765]
 [86.90859 ]
 [86.5137  ]], R is [[90.12524414]
 [89.9563446 ]
 [89.79399109]
 [89.65387726]
 [89.505867  ]].
[2019-04-06 17:33:26,892] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.2788195e-09 2.5509430e-06 3.3800864e-09 4.7365660e-03 8.6623053e-10
 9.9526089e-01 1.4057011e-09], sum to 1.0000
[2019-04-06 17:33:26,892] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4090
[2019-04-06 17:33:26,986] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.15, 72.0, 0.0, 0.0, 26.0, 25.38788823057259, 0.4855666871971596, 0.0, 1.0, 71698.03228247496], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4487400.0000, 
sim time next is 4489200.0000, 
raw observation next is [-0.3, 72.0, 0.0, 0.0, 26.0, 25.32804796892131, 0.4843999350408912, 0.0, 1.0, 55532.954647366976], 
processed observation next is [1.0, 1.0, 0.4542936288088643, 0.72, 0.0, 0.0, 0.6666666666666666, 0.610670664076776, 0.6614666450136304, 0.0, 1.0, 0.264442641177938], 
reward next is 0.7356, 
noisyNet noise sample is [array([1.181483], dtype=float32), -0.45273945]. 
=============================================
[2019-04-06 17:33:30,140] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9811601e-08 2.1177044e-05 1.9523296e-07 1.4763074e-02 5.3115055e-08
 9.8521543e-01 1.1241670e-07], sum to 1.0000
[2019-04-06 17:33:30,140] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7480
[2019-04-06 17:33:30,438] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.01216597481954, 0.3165066491434173, 0.0, 1.0, 35483.40464793868], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3006000.0000, 
sim time next is 3007800.0000, 
raw observation next is [-2.5, 62.5, 0.0, 0.0, 26.0, 25.01409270491582, 0.3576850908076021, 0.0, 1.0, 105770.56061863713], 
processed observation next is [0.0, 0.8260869565217391, 0.39335180055401664, 0.625, 0.0, 0.0, 0.6666666666666666, 0.5845077254096518, 0.6192283636025341, 0.0, 1.0, 0.5036693362792244], 
reward next is 0.4963, 
noisyNet noise sample is [array([1.1814057], dtype=float32), 0.54425067]. 
=============================================
[2019-04-06 17:33:30,862] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3282687e-11 1.0841366e-07 4.0080758e-11 2.2517532e-04 1.2866853e-11
 9.9977475e-01 1.6727852e-11], sum to 1.0000
[2019-04-06 17:33:30,862] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9740
[2019-04-06 17:33:30,920] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 100.0, 175.0, 0.0, 26.0, 25.24585538241987, 0.3028196724364338, 1.0, 1.0, 15567.009725192116], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2896200.0000, 
sim time next is 2898000.0000, 
raw observation next is [2.0, 100.0, 169.5, 0.0, 26.0, 25.20088421720227, 0.3151777457167335, 1.0, 1.0, 18680.41167023054], 
processed observation next is [1.0, 0.5652173913043478, 0.518005540166205, 1.0, 0.565, 0.0, 0.6666666666666666, 0.6000736847668557, 0.6050592485722445, 1.0, 1.0, 0.0889543412868121], 
reward next is 0.9110, 
noisyNet noise sample is [array([-0.03342541], dtype=float32), 0.26027325]. 
=============================================
[2019-04-06 17:33:30,926] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[93.43944]
 [92.6766 ]
 [91.93547]
 [91.5648 ]
 [91.69128]], R is [[93.72528839]
 [93.71391296]
 [93.68782043]
 [93.66199493]
 [93.6364212 ]].
[2019-04-06 17:33:31,399] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2694324e-08 1.0014976e-05 5.4733803e-08 1.8793320e-03 4.9788423e-10
 9.9811053e-01 6.9555570e-09], sum to 1.0000
[2019-04-06 17:33:31,400] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3849
[2019-04-06 17:33:31,801] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 71.0, 61.5, 85.5, 26.0, 25.46517348092254, 0.4038579169924736, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4608000.0000, 
sim time next is 4609800.0000, 
raw observation next is [-2.0, 71.0, 123.0, 171.0, 26.0, 25.63566599506286, 0.4738534092556028, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.40720221606648205, 0.71, 0.41, 0.18895027624309393, 0.6666666666666666, 0.6363054995885715, 0.6579511364185343, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8788006], dtype=float32), 1.9380249]. 
=============================================
[2019-04-06 17:33:49,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:33:49,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:33:49,390] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run14
[2019-04-06 17:34:04,626] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.2827372e-09 4.5526761e-07 6.7225114e-09 2.6145282e-03 1.9187096e-09
 9.9738497e-01 4.6315156e-09], sum to 1.0000
[2019-04-06 17:34:04,627] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2813
[2019-04-06 17:34:05,063] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 48.0, 0.0, 0.0, 26.0, 25.15228429029612, 0.265186539599125, 1.0, 1.0, 15695.879198925228], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4951800.0000, 
sim time next is 4953600.0000, 
raw observation next is [-2.0, 46.0, 46.5, 280.0, 26.0, 25.22750673147654, 0.27510961673412, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.40720221606648205, 0.46, 0.155, 0.30939226519337015, 0.6666666666666666, 0.6022922276230451, 0.59170320557804, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.01258084], dtype=float32), 0.28916192]. 
=============================================
[2019-04-06 17:34:05,935] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.0468161e-08 5.8807677e-06 3.8303338e-09 2.3073377e-02 1.7345138e-09
 9.7692072e-01 3.2318195e-09], sum to 1.0000
[2019-04-06 17:34:05,935] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9899
[2019-04-06 17:34:06,113] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 34.5, 108.0, 717.0, 26.0, 26.08216394692588, 0.4704168524656509, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4959000.0000, 
sim time next is 4960800.0000, 
raw observation next is [1.0, 30.0, 112.5, 760.0, 26.0, 26.43286376580593, 0.5375894342753825, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4903047091412743, 0.3, 0.375, 0.8397790055248618, 0.6666666666666666, 0.7027386471504942, 0.6791964780917942, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.75530034], dtype=float32), -0.9585617]. 
=============================================
[2019-04-06 17:34:06,580] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-06 17:34:06,581] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:34:06,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:34:06,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run30
[2019-04-06 17:34:06,678] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:34:06,700] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:34:06,713] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:34:06,715] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run30
[2019-04-06 17:34:06,713] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:34:06,804] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run30
[2019-04-06 17:36:23,938] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2462 79987260.4995 535.2506
[2019-04-06 17:36:43,017] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 17:36:44,558] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2395.7428 91944900.5891 409.3749
[2019-04-06 17:36:45,580] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 580000, evaluation results [580000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.2461995019034, 79987260.49946941, 535.2506232687274, 2395.7427787780084, 91944900.58913434, 409.3749352301794]
[2019-04-06 17:36:48,985] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:36:48,985] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:36:49,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run14
[2019-04-06 17:36:51,980] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:36:51,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:36:51,984] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run14
[2019-04-06 17:36:55,325] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.44708908e-09 1.02948325e-05 9.45820204e-08 4.22908878e-03
 1.00810924e-08 9.95760500e-01 2.49342929e-08], sum to 1.0000
[2019-04-06 17:36:55,326] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2342
[2019-04-06 17:36:55,454] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 40.0, 0.0, 0.0, 26.0, 25.89865916672775, 0.5579851871939586, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4140000.0000, 
sim time next is 4141800.0000, 
raw observation next is [0.5, 41.5, 0.0, 0.0, 26.0, 25.57164739206479, 0.4415206232283804, 0.0, 1.0, 34100.73271363234], 
processed observation next is [1.0, 0.9565217391304348, 0.4764542936288089, 0.415, 0.0, 0.0, 0.6666666666666666, 0.6309706160053992, 0.6471735410761268, 0.0, 1.0, 0.16238444149348732], 
reward next is 0.8376, 
noisyNet noise sample is [array([-0.23671733], dtype=float32), -0.71409535]. 
=============================================
[2019-04-06 17:36:59,117] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:36:59,117] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:36:59,128] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run14
[2019-04-06 17:37:02,559] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8434123e-09 1.6580922e-06 4.0452343e-11 2.1750298e-04 7.3805219e-11
 9.9978083e-01 1.2045122e-09], sum to 1.0000
[2019-04-06 17:37:02,559] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0565
[2019-04-06 17:37:02,581] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 65.0, 117.0, 825.5, 26.0, 26.47693814238087, 0.5986487725730729, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3758400.0000, 
sim time next is 3760200.0000, 
raw observation next is [-1.5, 62.5, 119.0, 829.0, 26.0, 26.52180556122578, 0.595263536014987, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4210526315789474, 0.625, 0.39666666666666667, 0.9160220994475138, 0.6666666666666666, 0.7101504634354816, 0.6984211786716624, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09334487], dtype=float32), 1.8824654]. 
=============================================
[2019-04-06 17:37:20,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:37:20,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:37:20,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run14
[2019-04-06 17:37:29,309] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3053796e-10 2.9524892e-06 1.9458570e-09 3.7736327e-03 1.9091726e-11
 9.9622345e-01 1.0638569e-09], sum to 1.0000
[2019-04-06 17:37:29,309] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5081
[2019-04-06 17:37:29,364] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 25.57526696879204, 0.5112236109623566, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4474800.0000, 
sim time next is 4476600.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 25.18335599676378, 0.4430125536859917, 1.0, 1.0, 8003.434664955257], 
processed observation next is [1.0, 0.8260869565217391, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.598612999730315, 0.6476708512286639, 1.0, 1.0, 0.03811159364264408], 
reward next is 0.9619, 
noisyNet noise sample is [array([0.31399208], dtype=float32), 0.25366363]. 
=============================================
[2019-04-06 17:37:40,393] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:37:40,393] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:37:40,397] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run14
[2019-04-06 17:37:40,681] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0679533e-09 1.6408864e-06 3.4853006e-08 7.2841472e-03 3.3211359e-10
 9.9271423e-01 4.1154991e-09], sum to 1.0000
[2019-04-06 17:37:40,681] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5483
[2019-04-06 17:37:40,741] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 49.0, 255.5, 80.5, 26.0, 26.2535873643987, 0.5877257402748526, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4543200.0000, 
sim time next is 4545000.0000, 
raw observation next is [3.0, 47.0, 264.0, 113.0, 26.0, 25.85809030721598, 0.5500216834967403, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5457063711911359, 0.47, 0.88, 0.12486187845303867, 0.6666666666666666, 0.6548408589346651, 0.6833405611655801, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.41066313], dtype=float32), 0.24140361]. 
=============================================
[2019-04-06 17:37:40,755] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[87.82042 ]
 [87.51582 ]
 [87.301605]
 [87.472244]
 [87.57372 ]], R is [[88.20304871]
 [88.32102203]
 [88.43781281]
 [88.48267365]
 [88.25663757]].
[2019-04-06 17:37:42,342] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:37:42,343] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:37:42,346] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run14
[2019-04-06 17:37:42,466] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:37:42,466] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:37:42,470] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run14
[2019-04-06 17:37:43,971] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.4416350e-09 1.2071493e-05 2.8702319e-08 5.6902289e-02 5.0386584e-10
 9.4308561e-01 5.6257301e-09], sum to 1.0000
[2019-04-06 17:37:43,971] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2724
[2019-04-06 17:37:44,044] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.65, 86.5, 0.0, 0.0, 26.0, 24.52241537196069, 0.1724485502042322, 0.0, 1.0, 42280.53580479259], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 606600.0000, 
sim time next is 608400.0000, 
raw observation next is [-3.9, 86.0, 0.0, 0.0, 26.0, 24.46248971573678, 0.1525586964270502, 0.0, 1.0, 42190.01000451984], 
processed observation next is [0.0, 0.043478260869565216, 0.3545706371191136, 0.86, 0.0, 0.0, 0.6666666666666666, 0.5385408096447316, 0.5508528988090168, 0.0, 1.0, 0.20090480954533257], 
reward next is 0.7991, 
noisyNet noise sample is [array([-0.43758538], dtype=float32), -1.5140707]. 
=============================================
[2019-04-06 17:37:58,860] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.2353797e-09 5.2826526e-06 1.1192022e-08 3.4611081e-03 2.9136165e-09
 9.9653351e-01 8.1652892e-08], sum to 1.0000
[2019-04-06 17:37:58,860] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5563
[2019-04-06 17:37:59,091] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 47.0, 0.0, 0.0, 26.0, 24.97307284129002, 0.2913881259848979, 0.0, 1.0, 33913.22809987331], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4906800.0000, 
sim time next is 4908600.0000, 
raw observation next is [1.0, 43.5, 0.0, 0.0, 26.0, 25.12713939175858, 0.3479835325957756, 0.0, 1.0, 126905.04824705073], 
processed observation next is [0.0, 0.8260869565217391, 0.4903047091412743, 0.435, 0.0, 0.0, 0.6666666666666666, 0.5939282826465483, 0.6159945108652586, 0.0, 1.0, 0.6043097535573844], 
reward next is 0.3957, 
noisyNet noise sample is [array([0.6049756], dtype=float32), -1.110764]. 
=============================================
[2019-04-06 17:37:59,763] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:37:59,763] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:37:59,776] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run14
[2019-04-06 17:38:09,367] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:38:09,367] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:38:09,371] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run14
[2019-04-06 17:38:12,223] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:38:12,223] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:38:12,226] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run14
[2019-04-06 17:38:12,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:38:12,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:38:12,879] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run14
[2019-04-06 17:38:21,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:38:21,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:38:21,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run14
[2019-04-06 17:38:21,217] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:38:21,218] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:38:21,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run14
[2019-04-06 17:38:22,174] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:38:22,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:38:22,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run14
[2019-04-06 17:38:35,317] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.12716315e-10 4.60235974e-08 1.67549752e-10 3.33577220e-04
 1.70563858e-11 9.99666333e-01 1.15197990e-10], sum to 1.0000
[2019-04-06 17:38:35,318] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1490
[2019-04-06 17:38:35,395] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.1, 77.5, 0.0, 0.0, 26.0, 25.74390679199832, 0.5520758903503288, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1045800.0000, 
sim time next is 1047600.0000, 
raw observation next is [14.4, 77.0, 0.0, 0.0, 26.0, 25.56514719131741, 0.6136301183643341, 0.0, 1.0, 107772.85122014723], 
processed observation next is [1.0, 0.13043478260869565, 0.8614958448753465, 0.77, 0.0, 0.0, 0.6666666666666666, 0.6304289326097843, 0.7045433727881113, 0.0, 1.0, 0.5132040534292726], 
reward next is 0.4868, 
noisyNet noise sample is [array([1.0386498], dtype=float32), 1.5377923]. 
=============================================
[2019-04-06 17:38:54,982] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8216209e-09 6.7037536e-06 1.0519829e-08 2.2540232e-03 1.9412350e-09
 9.9773932e-01 3.8655581e-09], sum to 1.0000
[2019-04-06 17:38:54,983] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5557
[2019-04-06 17:38:55,046] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 74.0, 0.0, 0.0, 26.0, 23.62762680305556, -0.0336945460902464, 0.0, 1.0, 44418.69599713453], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 178200.0000, 
sim time next is 180000.0000, 
raw observation next is [-8.9, 74.0, 0.0, 0.0, 26.0, 23.54568417995201, -0.05218857429541362, 0.0, 1.0, 44333.559411405666], 
processed observation next is [1.0, 0.08695652173913043, 0.21606648199445982, 0.74, 0.0, 0.0, 0.6666666666666666, 0.46214034832933404, 0.48260380856819546, 0.0, 1.0, 0.21111218767336032], 
reward next is 0.7889, 
noisyNet noise sample is [array([-0.7700899], dtype=float32), 0.15181346]. 
=============================================
[2019-04-06 17:38:55,070] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[81.28818]
 [81.46082]
 [81.78788]
 [81.64846]
 [82.54102]], R is [[81.55802155]
 [81.53092194]
 [81.50415802]
 [81.47728729]
 [81.44992065]].
[2019-04-06 17:39:33,839] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2486047e-09 1.8905240e-07 7.9916296e-09 6.3352813e-03 1.0838500e-09
 9.9366450e-01 5.0570903e-09], sum to 1.0000
[2019-04-06 17:39:33,839] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5109
[2019-04-06 17:39:34,000] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 62.0, 74.0, 0.0, 26.0, 25.63432904141165, 0.3237720360911077, 1.0, 1.0, 55841.93988942296], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1956600.0000, 
sim time next is 1958400.0000, 
raw observation next is [-2.8, 62.0, 52.0, 0.0, 26.0, 25.55532408247431, 0.3160022003522833, 1.0, 1.0, 27584.077586886986], 
processed observation next is [1.0, 0.6956521739130435, 0.38504155124653744, 0.62, 0.17333333333333334, 0.0, 0.6666666666666666, 0.6296103402061926, 0.6053340667840944, 1.0, 1.0, 0.13135275041374755], 
reward next is 0.8686, 
noisyNet noise sample is [array([0.13230756], dtype=float32), 0.95815444]. 
=============================================
[2019-04-06 17:39:41,104] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.1765762e-11 5.2858894e-08 1.6001164e-10 7.6243590e-04 3.9055939e-11
 9.9923754e-01 5.1869986e-10], sum to 1.0000
[2019-04-06 17:39:41,104] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5029
[2019-04-06 17:39:41,561] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 84.0, 29.0, 0.0, 26.0, 25.89865160785523, 0.2949726098893448, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 837000.0000, 
sim time next is 838800.0000, 
raw observation next is [-3.9, 86.0, 14.5, 0.0, 26.0, 25.19637476233867, 0.3549696438440492, 1.0, 1.0, 81734.88603116888], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.86, 0.04833333333333333, 0.0, 0.6666666666666666, 0.599697896861556, 0.6183232146146831, 1.0, 1.0, 0.3892137430055661], 
reward next is 0.6108, 
noisyNet noise sample is [array([1.0808864], dtype=float32), -0.21764743]. 
=============================================
[2019-04-06 17:39:45,186] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.2759331e-09 1.2105447e-07 8.1739815e-10 1.3803552e-03 2.1179253e-10
 9.9861956e-01 5.4648481e-09], sum to 1.0000
[2019-04-06 17:39:45,187] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5961
[2019-04-06 17:39:45,483] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 80.0, 38.5, 0.0, 26.0, 25.43876838303224, 0.2926772511049878, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 896400.0000, 
sim time next is 898200.0000, 
raw observation next is [1.1, 82.0, 48.0, 0.0, 26.0, 25.44412123393289, 0.2931815274754219, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49307479224376743, 0.82, 0.16, 0.0, 0.6666666666666666, 0.6203434361610741, 0.5977271758251407, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.12786098], dtype=float32), 0.6906726]. 
=============================================
[2019-04-06 17:39:53,076] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 17:39:53,085] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:39:53,086] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:39:53,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run31
[2019-04-06 17:39:53,217] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:39:53,224] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:39:53,217] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:39:53,226] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:39:53,228] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run31
[2019-04-06 17:39:53,334] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run31
[2019-04-06 17:42:15,701] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 17:42:35,580] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 17:42:35,698] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 17:42:36,720] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 600000, evaluation results [600000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 17:42:49,360] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3460312e-09 1.1149524e-06 1.0257258e-08 6.4831497e-03 8.1087248e-10
 9.9351573e-01 1.4108211e-08], sum to 1.0000
[2019-04-06 17:42:49,360] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7118
[2019-04-06 17:42:49,439] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.55, 84.0, 0.0, 0.0, 26.0, 24.28488139374885, 0.1386221362680926, 0.0, 1.0, 44090.75920714152], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2255400.0000, 
sim time next is 2257200.0000, 
raw observation next is [-7.8, 86.0, 0.0, 0.0, 26.0, 24.12912042207584, 0.09778009698763086, 0.0, 1.0, 43932.62730954619], 
processed observation next is [1.0, 0.13043478260869565, 0.24653739612188366, 0.86, 0.0, 0.0, 0.6666666666666666, 0.5107600351729866, 0.5325933656625436, 0.0, 1.0, 0.20920298718831518], 
reward next is 0.7908, 
noisyNet noise sample is [array([-1.276085], dtype=float32), 0.48053798]. 
=============================================
[2019-04-06 17:42:52,966] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1686605e-09 7.0973110e-06 8.9077112e-10 1.9158430e-02 2.1166266e-10
 9.8083442e-01 2.1169114e-08], sum to 1.0000
[2019-04-06 17:42:52,966] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9373
[2019-04-06 17:42:53,051] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 71.0, 0.0, 0.0, 26.0, 24.08230103202318, 0.08038269859009423, 0.0, 1.0, 41541.70510614879], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 784800.0000, 
sim time next is 786600.0000, 
raw observation next is [-7.8, 72.5, 0.0, 0.0, 26.0, 23.95357094598801, 0.05416769340211649, 0.0, 1.0, 41499.36255540507], 
processed observation next is [1.0, 0.08695652173913043, 0.24653739612188366, 0.725, 0.0, 0.0, 0.6666666666666666, 0.4961309121656674, 0.5180558978007055, 0.0, 1.0, 0.19761601216859556], 
reward next is 0.8024, 
noisyNet noise sample is [array([0.6661323], dtype=float32), 0.50718755]. 
=============================================
[2019-04-06 17:43:10,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9262753e-08 4.9535060e-06 4.1312770e-08 7.5568521e-04 2.6472857e-09
 9.9923933e-01 2.5801885e-08], sum to 1.0000
[2019-04-06 17:43:10,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9931
[2019-04-06 17:43:10,302] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 60.0, 0.0, 0.0, 26.0, 23.20077125284541, -0.1548906862954874, 0.0, 1.0, 44168.87904714127], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2440800.0000, 
sim time next is 2442600.0000, 
raw observation next is [-9.2, 60.5, 0.0, 0.0, 26.0, 23.11099747469434, -0.1810983650481657, 0.0, 1.0, 44048.908229642], 
processed observation next is [0.0, 0.2608695652173913, 0.20775623268698065, 0.605, 0.0, 0.0, 0.6666666666666666, 0.42591645622452834, 0.4396338783172781, 0.0, 1.0, 0.2097567058554381], 
reward next is 0.7902, 
noisyNet noise sample is [array([-0.5138674], dtype=float32), 0.6687367]. 
=============================================
[2019-04-06 17:43:16,128] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0668412e-09 2.0208154e-06 6.1901577e-09 4.6187520e-04 9.8898341e-11
 9.9953616e-01 1.9545380e-08], sum to 1.0000
[2019-04-06 17:43:16,128] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8169
[2019-04-06 17:43:16,255] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 83.0, 0.0, 0.0, 26.0, 25.00881123001391, 0.3151793856278191, 0.0, 1.0, 48584.55565869831], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1796400.0000, 
sim time next is 1798200.0000, 
raw observation next is [-4.5, 83.0, 0.0, 0.0, 26.0, 25.0110534130681, 0.3322551698539133, 0.0, 1.0, 81961.70228978527], 
processed observation next is [0.0, 0.8260869565217391, 0.3379501385041552, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5842544510890084, 0.6107517232846378, 0.0, 1.0, 0.3902938204275489], 
reward next is 0.6097, 
noisyNet noise sample is [array([-0.5831902], dtype=float32), 1.2589564]. 
=============================================
[2019-04-06 17:43:20,741] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6059672e-09 2.6923037e-06 1.8464135e-09 1.0063903e-02 5.5682070e-10
 9.8993343e-01 6.5375452e-09], sum to 1.0000
[2019-04-06 17:43:20,741] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5241
[2019-04-06 17:43:20,791] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.2, 73.0, 0.0, 0.0, 26.0, 25.5123490436757, 0.5502679511737978, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1540800.0000, 
sim time next is 1542600.0000, 
raw observation next is [7.45, 73.5, 0.0, 0.0, 26.0, 25.29618828228098, 0.5533616159602812, 0.0, 1.0, 130960.59931338373], 
processed observation next is [1.0, 0.8695652173913043, 0.6689750692520776, 0.735, 0.0, 0.0, 0.6666666666666666, 0.6080156901900816, 0.6844538719867604, 0.0, 1.0, 0.6236219014923035], 
reward next is 0.3764, 
noisyNet noise sample is [array([1.0508163], dtype=float32), -0.29815492]. 
=============================================
[2019-04-06 17:43:21,114] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.3156249e-10 1.2324446e-06 3.6059646e-09 2.4554352e-04 2.8207919e-10
 9.9975318e-01 9.9857267e-10], sum to 1.0000
[2019-04-06 17:43:21,114] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0899
[2019-04-06 17:43:21,249] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 100.0, 9.0, 0.0, 26.0, 25.41889772240422, 0.4415864414770851, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1411200.0000, 
sim time next is 1413000.0000, 
raw observation next is [-0.6, 100.0, 18.0, 0.0, 26.0, 25.55988724041561, 0.4802937192224375, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.44598337950138506, 1.0, 0.06, 0.0, 0.6666666666666666, 0.6299906033679674, 0.6600979064074791, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.10382769], dtype=float32), -1.3815163]. 
=============================================
[2019-04-06 17:43:21,257] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[92.090385]
 [91.68555 ]
 [92.02953 ]
 [92.0466  ]
 [92.1179  ]], R is [[92.38050079]
 [92.45669556]
 [92.47080231]
 [92.36222076]
 [92.25518799]].
[2019-04-06 17:43:21,383] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.6929372e-09 2.8479120e-08 7.1929723e-10 8.6230529e-04 9.3889355e-11
 9.9913764e-01 3.6400398e-09], sum to 1.0000
[2019-04-06 17:43:21,383] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6964
[2019-04-06 17:43:21,454] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-15.0, 91.0, 0.0, 0.0, 26.0, 23.51198337818814, -0.0113693896599986, 0.0, 1.0, 44516.198522559665], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2692800.0000, 
sim time next is 2694600.0000, 
raw observation next is [-15.0, 87.0, 0.0, 0.0, 26.0, 23.40177423720182, -0.03558880278801726, 0.0, 1.0, 44403.65760268524], 
processed observation next is [1.0, 0.17391304347826086, 0.04709141274238226, 0.87, 0.0, 0.0, 0.6666666666666666, 0.4501478531001517, 0.48813706573732757, 0.0, 1.0, 0.21144598858421543], 
reward next is 0.7886, 
noisyNet noise sample is [array([-1.2931359], dtype=float32), 0.33962718]. 
=============================================
[2019-04-06 17:43:27,292] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1325135e-11 2.6286114e-07 1.1631272e-10 3.7520765e-03 1.4534780e-10
 9.9624771e-01 1.1008026e-10], sum to 1.0000
[2019-04-06 17:43:27,292] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0795
[2019-04-06 17:43:27,376] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.3, 96.0, 80.5, 354.0, 26.0, 26.06658065194552, 0.5663758513927363, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1508400.0000, 
sim time next is 1510200.0000, 
raw observation next is [3.85, 94.5, 88.0, 708.0, 26.0, 26.27395049979543, 0.6351597503977434, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.569252077562327, 0.945, 0.29333333333333333, 0.7823204419889502, 0.6666666666666666, 0.6894958749829524, 0.7117199167992477, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.49005085], dtype=float32), 1.5117253]. 
=============================================
[2019-04-06 17:43:45,178] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.78445729e-08 1.65920505e-06 1.40809115e-08 3.41831427e-03
 1.80873783e-09 9.96579945e-01 2.85823063e-08], sum to 1.0000
[2019-04-06 17:43:45,179] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3063
[2019-04-06 17:43:45,224] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 87.0, 0.0, 0.0, 26.0, 24.75683393378661, 0.3139666278372978, 0.0, 1.0, 44006.056214706776], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1753200.0000, 
sim time next is 1755000.0000, 
raw observation next is [-1.7, 87.0, 0.0, 0.0, 26.0, 24.70836647528725, 0.3069099521571578, 0.0, 1.0, 44044.66710649405], 
processed observation next is [0.0, 0.30434782608695654, 0.4155124653739613, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5590305396072708, 0.6023033173857192, 0.0, 1.0, 0.20973651003092406], 
reward next is 0.7903, 
noisyNet noise sample is [array([1.0019879], dtype=float32), 0.8704219]. 
=============================================
[2019-04-06 17:43:45,228] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[81.95263 ]
 [82.24906 ]
 [82.59652 ]
 [82.881935]
 [83.21517 ]], R is [[81.68593597]
 [81.65953064]
 [81.63381958]
 [81.60914612]
 [81.58541107]].
[2019-04-06 17:44:23,757] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8740072e-09 9.9140614e-08 3.1915051e-09 2.2732744e-03 3.0690499e-11
 9.9772662e-01 1.9870390e-10], sum to 1.0000
[2019-04-06 17:44:23,758] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8162
[2019-04-06 17:44:23,959] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.19878067515547, 0.09549961067089048, 0.0, 1.0, 43446.261928019485], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2091600.0000, 
sim time next is 2093400.0000, 
raw observation next is [-6.45, 85.0, 0.0, 0.0, 26.0, 24.2189630706375, 0.09926074059078693, 0.0, 1.0, 43576.14699280337], 
processed observation next is [1.0, 0.21739130434782608, 0.28393351800554023, 0.85, 0.0, 0.0, 0.6666666666666666, 0.518246922553125, 0.5330869135302624, 0.0, 1.0, 0.20750546187049224], 
reward next is 0.7925, 
noisyNet noise sample is [array([-0.77945226], dtype=float32), -0.1783993]. 
=============================================
[2019-04-06 17:44:29,535] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.63574562e-09 2.46731724e-06 1.37722305e-08 2.36835913e-03
 2.62522959e-09 9.97629225e-01 4.60207206e-09], sum to 1.0000
[2019-04-06 17:44:29,535] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4419
[2019-04-06 17:44:29,653] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.0, 69.0, 0.0, 0.0, 26.0, 24.52658468258294, 0.2248489767914036, 0.0, 1.0, 44410.774554185504], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2682000.0000, 
sim time next is 2683800.0000, 
raw observation next is [-10.0, 72.5, 0.0, 0.0, 26.0, 24.37633053274087, 0.1749680135208345, 0.0, 1.0, 44412.12508299027], 
processed observation next is [1.0, 0.043478260869565216, 0.18559556786703602, 0.725, 0.0, 0.0, 0.6666666666666666, 0.5313608777284058, 0.5583226711736115, 0.0, 1.0, 0.2114863099190013], 
reward next is 0.7885, 
noisyNet noise sample is [array([-0.09739008], dtype=float32), -0.31485447]. 
=============================================
[2019-04-06 17:44:30,644] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7245194e-09 1.9275851e-07 2.2396638e-09 5.1035443e-03 5.4031900e-11
 9.9489623e-01 2.8719043e-09], sum to 1.0000
[2019-04-06 17:44:30,644] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7481
[2019-04-06 17:44:30,692] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 74.0, 111.0, 769.0, 26.0, 26.34119722485291, 0.5505675109896396, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3753000.0000, 
sim time next is 3754800.0000, 
raw observation next is [-3.0, 71.0, 113.0, 795.5, 26.0, 26.42042521017812, 0.5675738566548758, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.3795013850415513, 0.71, 0.37666666666666665, 0.8790055248618784, 0.6666666666666666, 0.7017021008481766, 0.6891912855516252, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4718132], dtype=float32), -0.9107321]. 
=============================================
[2019-04-06 17:44:57,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:44:57,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:44:57,675] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run15
[2019-04-06 17:45:28,210] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 17:45:28,213] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:45:28,213] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:45:28,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run32
[2019-04-06 17:45:28,253] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:45:28,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:45:28,256] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run32
[2019-04-06 17:45:28,358] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:45:28,359] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:45:28,361] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run32
[2019-04-06 17:47:51,861] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 17:48:09,271] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 17:48:09,851] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 17:48:10,873] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 620000, evaluation results [620000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 17:48:12,455] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8279258e-08 4.7869551e-05 4.9465761e-08 3.9891182e-03 2.5540519e-08
 9.9596280e-01 1.0558463e-07], sum to 1.0000
[2019-04-06 17:48:12,456] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0008
[2019-04-06 17:48:12,531] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-1.0, 55.0, 0.0, 0.0, 26.0, 25.38949725837604, 0.4004439696458449, 0.0, 1.0, 43622.36116079755], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4831200.0000, 
sim time next is 4833000.0000, 
raw observation next is [-1.0, 55.0, 0.0, 0.0, 26.0, 25.37970209879177, 0.3897163277249688, 0.0, 1.0, 39800.100601705875], 
processed observation next is [0.0, 0.9565217391304348, 0.4349030470914128, 0.55, 0.0, 0.0, 0.6666666666666666, 0.6149751748993143, 0.6299054425749896, 0.0, 1.0, 0.18952428857955178], 
reward next is 0.8105, 
noisyNet noise sample is [array([-1.524491], dtype=float32), -0.19728047]. 
=============================================
[2019-04-06 17:48:12,566] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[77.70617 ]
 [77.644966]
 [77.46139 ]
 [77.24851 ]
 [76.78704 ]], R is [[77.947258  ]
 [77.96006012]
 [77.9094696 ]
 [77.97409821]
 [78.16457367]].
[2019-04-06 17:48:25,631] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:48:25,631] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:48:25,634] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run15
[2019-04-06 17:48:38,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:48:38,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:48:38,521] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run15
[2019-04-06 17:48:40,151] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:48:40,152] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:48:40,167] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run15
[2019-04-06 17:48:46,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:48:46,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:48:46,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run15
[2019-04-06 17:48:53,666] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5608829e-11 4.0120863e-08 3.1091027e-10 2.3537655e-03 1.4943347e-11
 9.9764615e-01 3.7918984e-09], sum to 1.0000
[2019-04-06 17:48:53,666] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2836
[2019-04-06 17:48:53,711] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 72.0, 147.0, 0.0, 26.0, 25.99933506360876, 0.5363192379363596, 1.0, 1.0, 4151.202593384563], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4721400.0000, 
sim time next is 4723200.0000, 
raw observation next is [1.0, 72.0, 123.5, 5.5, 26.0, 26.16189625911497, 0.5469027826656908, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4903047091412743, 0.72, 0.4116666666666667, 0.0060773480662983425, 0.6666666666666666, 0.6801580215929143, 0.6823009275552302, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.39802778], dtype=float32), -0.012139438]. 
=============================================
[2019-04-06 17:49:04,969] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2030482e-09 1.0150860e-06 8.5168628e-09 2.9444571e-03 3.3918760e-11
 9.9705458e-01 5.1608828e-09], sum to 1.0000
[2019-04-06 17:49:04,969] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8984
[2019-04-06 17:49:05,062] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 79.0, 0.0, 0.0, 26.0, 25.5230460017363, 0.4316779369506045, 0.0, 1.0, 8691.513676686833], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3463200.0000, 
sim time next is 3465000.0000, 
raw observation next is [1.0, 75.5, 0.0, 0.0, 26.0, 25.40353650111889, 0.4295666940187861, 0.0, 1.0, 69402.1754830918], 
processed observation next is [1.0, 0.08695652173913043, 0.4903047091412743, 0.755, 0.0, 0.0, 0.6666666666666666, 0.6169613750932408, 0.643188898006262, 0.0, 1.0, 0.3304865499194848], 
reward next is 0.6695, 
noisyNet noise sample is [array([1.0274802], dtype=float32), -1.058881]. 
=============================================
[2019-04-06 17:49:05,066] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[90.40263]
 [90.52765]
 [90.84447]
 [91.22919]
 [91.07448]], R is [[89.84190369]
 [89.90209961]
 [89.82315063]
 [89.75022125]
 [89.71619415]].
[2019-04-06 17:49:11,666] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:49:11,666] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:49:11,670] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run15
[2019-04-06 17:49:41,901] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5416759e-08 6.2970594e-07 1.2124733e-08 3.4861458e-03 8.3847085e-10
 9.9651319e-01 2.2017373e-08], sum to 1.0000
[2019-04-06 17:49:41,902] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2156
[2019-04-06 17:49:41,977] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 71.0, 0.0, 0.0, 26.0, 23.56504269423273, -0.05507237168146999, 0.0, 1.0, 42066.943123878686], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 799200.0000, 
sim time next is 801000.0000, 
raw observation next is [-7.0, 69.0, 0.0, 0.0, 26.0, 23.48517860840921, -0.06564596099565388, 0.0, 1.0, 42115.10444196433], 
processed observation next is [1.0, 0.2608695652173913, 0.2686980609418283, 0.69, 0.0, 0.0, 0.6666666666666666, 0.4570982173674342, 0.4781180130014487, 0.0, 1.0, 0.20054811639030634], 
reward next is 0.7995, 
noisyNet noise sample is [array([-0.19279328], dtype=float32), 0.32866943]. 
=============================================
[2019-04-06 17:49:42,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[82.84387 ]
 [82.985374]
 [83.13502 ]
 [83.33336 ]
 [83.48839 ]], R is [[82.57262421]
 [82.54658508]
 [82.52154541]
 [82.49806213]
 [82.47585297]].
[2019-04-06 17:49:46,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:49:46,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:49:46,584] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run15
[2019-04-06 17:49:48,041] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:49:48,041] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:49:48,044] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run15
[2019-04-06 17:49:49,500] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4770481e-10 1.7048128e-06 7.3484996e-09 1.3748467e-03 2.1765162e-10
 9.9862349e-01 6.7879180e-10], sum to 1.0000
[2019-04-06 17:49:49,513] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7593
[2019-04-06 17:49:49,574] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.65, 86.5, 0.0, 0.0, 26.0, 24.52241537196069, 0.1724485502042322, 0.0, 1.0, 42280.53580479259], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 606600.0000, 
sim time next is 608400.0000, 
raw observation next is [-3.9, 86.0, 0.0, 0.0, 26.0, 24.46248971573678, 0.1525586964270502, 0.0, 1.0, 42190.01000451984], 
processed observation next is [0.0, 0.043478260869565216, 0.3545706371191136, 0.86, 0.0, 0.0, 0.6666666666666666, 0.5385408096447316, 0.5508528988090168, 0.0, 1.0, 0.20090480954533257], 
reward next is 0.7991, 
noisyNet noise sample is [array([0.81473744], dtype=float32), -1.4965359]. 
=============================================
[2019-04-06 17:49:50,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:49:50,602] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:49:50,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run15
[2019-04-06 17:50:22,643] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:50:22,643] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:50:22,646] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run15
[2019-04-06 17:50:28,615] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1979130e-08 1.2657879e-06 1.1433007e-08 4.8458311e-03 4.2640784e-09
 9.9515283e-01 4.5610118e-08], sum to 1.0000
[2019-04-06 17:50:28,615] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7289
[2019-04-06 17:50:28,651] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 26.0, 23.58347076702589, 0.1641174065662103, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1231200.0000, 
sim time next is 1233000.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 26.0, 23.54150564836344, 0.1569367935697974, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.8781163434903049, 0.96, 0.0, 0.0, 0.6666666666666666, 0.46179213736362, 0.5523122645232658, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.17682117], dtype=float32), -0.5441984]. 
=============================================
[2019-04-06 17:50:28,668] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[70.862755]
 [70.80121 ]
 [70.6487  ]
 [70.44658 ]
 [70.250534]], R is [[71.06686401]
 [71.35619354]
 [71.64263153]
 [71.9262085 ]
 [72.20694733]].
[2019-04-06 17:50:33,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:50:33,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:50:33,192] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run15
[2019-04-06 17:50:35,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:50:35,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:50:35,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run15
[2019-04-06 17:50:39,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:50:39,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:50:39,376] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run15
[2019-04-06 17:50:42,703] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:50:42,703] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:50:42,706] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run15
[2019-04-06 17:50:48,217] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:50:48,217] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:50:48,220] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run15
[2019-04-06 17:50:51,604] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 17:50:51,606] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:50:51,606] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:50:51,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run33
[2019-04-06 17:50:51,718] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:50:51,718] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:50:51,721] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:50:51,721] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:50:51,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run33
[2019-04-06 17:50:51,858] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run33
[2019-04-06 17:50:51,922] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:50:51,923] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:50:51,926] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run15
[2019-04-06 17:52:07,491] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.04075545], dtype=float32), 0.12222644]
[2019-04-06 17:52:07,491] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [5.2645084125, 93.83516998, 0.0, 0.0, 26.0, 25.58604731849655, 0.6258769454257388, 0.0, 1.0, 17947.740752374477]
[2019-04-06 17:52:07,491] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 17:52:07,492] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.5959821e-10 1.5887923e-07 5.1891319e-10 8.5831090e-04 4.8172081e-11
 9.9914145e-01 3.1712782e-10], sampled 0.3606730313148062
[2019-04-06 17:52:23,349] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.04075545], dtype=float32), 0.12222644]
[2019-04-06 17:52:23,349] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.1, 88.0, 0.0, 0.0, 26.0, 25.72610137554177, 0.5582619574670711, 0.0, 1.0, 0.0]
[2019-04-06 17:52:23,349] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 17:52:23,350] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [3.5546530e-10 2.6731186e-07 8.5994106e-10 1.3647515e-03 1.0483572e-10
 9.9863499e-01 8.6157298e-10], sampled 0.8559002214275208
[2019-04-06 17:53:17,755] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3748 79991956.7854 535.1864
[2019-04-06 17:53:37,101] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 17:53:38,222] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.4221 91945532.2806 409.4069
[2019-04-06 17:53:39,245] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 640000, evaluation results [640000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.374809603911, 79991956.78540477, 535.1864255395496, 2396.422113191321, 91945532.28064376, 409.4068523341436]
[2019-04-06 17:53:56,677] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.57876367e-11 1.66483545e-07 8.14438961e-10 1.06538460e-02
 1.34980195e-11 9.89345968e-01 2.38904385e-09], sum to 1.0000
[2019-04-06 17:53:56,677] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3254
[2019-04-06 17:53:56,734] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 75.0, 0.0, 0.0, 26.0, 25.85261723437053, 0.5938972745220825, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1033200.0000, 
sim time next is 1035000.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 26.0, 25.67955764624934, 0.5683818872314095, 0.0, 1.0, 20256.358660860384], 
processed observation next is [1.0, 1.0, 0.8614958448753465, 0.75, 0.0, 0.0, 0.6666666666666666, 0.6399631371874449, 0.6894606290771366, 0.0, 1.0, 0.09645885076600183], 
reward next is 0.9035, 
noisyNet noise sample is [array([-0.06699178], dtype=float32), -1.5389552]. 
=============================================
[2019-04-06 17:53:56,762] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[ 99.74712 ]
 [100.348305]
 [101.00365 ]
 [100.63148 ]
 [100.27663 ]], R is [[99.32868195]
 [99.33539581]
 [99.34204102]
 [99.34862518]
 [99.35514069]].
[2019-04-06 17:54:00,015] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2866027e-10 5.0422841e-07 2.7887939e-09 1.5146832e-03 2.3921282e-10
 9.9848479e-01 1.1696774e-09], sum to 1.0000
[2019-04-06 17:54:00,015] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7331
[2019-04-06 17:54:00,064] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.2, 80.5, 0.0, 0.0, 26.0, 24.27641569989559, 0.1158062645253328, 0.0, 1.0, 44295.99359454986], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 257400.0000, 
sim time next is 259200.0000, 
raw observation next is [-4.5, 79.0, 0.0, 0.0, 26.0, 24.15870167770939, 0.09203649788015399, 0.0, 1.0, 44355.97385117086], 
processed observation next is [1.0, 0.0, 0.3379501385041552, 0.79, 0.0, 0.0, 0.6666666666666666, 0.513225139809116, 0.530678832626718, 0.0, 1.0, 0.2112189231008136], 
reward next is 0.7888, 
noisyNet noise sample is [array([0.6161804], dtype=float32), -1.4813371]. 
=============================================
[2019-04-06 17:54:31,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1421022e-10 2.9695948e-07 1.4989480e-08 7.7348184e-03 4.7018978e-10
 9.9226487e-01 9.3135730e-09], sum to 1.0000
[2019-04-06 17:54:31,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8871
[2019-04-06 17:54:31,291] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 83.0, 100.0, 73.0, 26.0, 24.96315828282824, 0.3250534469827184, 0.0, 1.0, 45054.2251663026], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 574200.0000, 
sim time next is 576000.0000, 
raw observation next is [-1.2, 83.0, 70.5, 59.0, 26.0, 24.97687942152307, 0.3141035153311245, 0.0, 1.0, 29497.097658455943], 
processed observation next is [0.0, 0.6956521739130435, 0.42936288088642666, 0.83, 0.235, 0.06519337016574586, 0.6666666666666666, 0.5814066184602558, 0.6047011717770415, 0.0, 1.0, 0.14046236980217117], 
reward next is 0.8595, 
noisyNet noise sample is [array([1.0675697], dtype=float32), 0.21912117]. 
=============================================
[2019-04-06 17:54:31,311] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[81.61758 ]
 [82.15063 ]
 [82.774574]
 [83.163345]
 [83.69442 ]], R is [[81.59561157]
 [81.56510925]
 [81.64304352]
 [81.67997742]
 [81.7740097 ]].
[2019-04-06 17:54:31,318] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9169721e-10 8.8523244e-08 3.7839998e-10 1.3623961e-04 1.7294492e-11
 9.9986362e-01 1.0296651e-10], sum to 1.0000
[2019-04-06 17:54:31,318] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4721
[2019-04-06 17:54:31,475] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 80.0, 134.0, 495.5, 26.0, 24.95924833644794, 0.3231414502448967, 0.0, 1.0, 29092.313824222092], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 565200.0000, 
sim time next is 567000.0000, 
raw observation next is [-1.2, 80.0, 138.0, 595.0, 26.0, 24.96673458437692, 0.3485818976415422, 0.0, 1.0, 37410.95909327694], 
processed observation next is [0.0, 0.5652173913043478, 0.42936288088642666, 0.8, 0.46, 0.6574585635359116, 0.6666666666666666, 0.5805612153647433, 0.6161939658805141, 0.0, 1.0, 0.17814742425369973], 
reward next is 0.8219, 
noisyNet noise sample is [array([-0.35785097], dtype=float32), -1.513746]. 
=============================================
[2019-04-06 17:54:31,480] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[84.034546]
 [83.881744]
 [84.228195]
 [84.16879 ]
 [84.33504 ]], R is [[84.27326202]
 [84.29199219]
 [84.40447235]
 [84.30180359]
 [84.28829193]].
[2019-04-06 17:54:32,004] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0022213e-09 5.6162304e-07 8.6138154e-09 3.8427790e-03 2.0658208e-10
 9.9615663e-01 3.7461536e-09], sum to 1.0000
[2019-04-06 17:54:32,006] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7659
[2019-04-06 17:54:32,095] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 68.0, 0.0, 0.0, 26.0, 25.24353129099646, 0.4157177522781175, 0.0, 1.0, 53045.062438550696], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2235600.0000, 
sim time next is 2237400.0000, 
raw observation next is [-5.3, 69.5, 0.0, 0.0, 26.0, 25.28408674332292, 0.4094846065481109, 0.0, 1.0, 45521.43072477699], 
processed observation next is [1.0, 0.9130434782608695, 0.31578947368421056, 0.695, 0.0, 0.0, 0.6666666666666666, 0.6070072286102434, 0.6364948688493702, 0.0, 1.0, 0.2167687177370333], 
reward next is 0.7832, 
noisyNet noise sample is [array([-1.8536396], dtype=float32), -0.952464]. 
=============================================
[2019-04-06 17:54:39,931] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5781115e-09 5.1333850e-06 8.8025525e-09 6.1315363e-03 4.6092133e-10
 9.9386334e-01 4.3731855e-08], sum to 1.0000
[2019-04-06 17:54:39,931] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8307
[2019-04-06 17:54:39,968] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 75.0, 0.0, 0.0, 26.0, 24.26523504692249, 0.03782312590707997, 0.0, 1.0, 41631.81010505788], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 705600.0000, 
sim time next is 707400.0000, 
raw observation next is [-2.55, 75.5, 0.0, 0.0, 26.0, 24.29850858851402, 0.04532546472089293, 0.0, 1.0, 41595.9209494355], 
processed observation next is [1.0, 0.17391304347826086, 0.3919667590027701, 0.755, 0.0, 0.0, 0.6666666666666666, 0.5248757157095018, 0.5151084882402976, 0.0, 1.0, 0.19807581404493096], 
reward next is 0.8019, 
noisyNet noise sample is [array([-0.6379522], dtype=float32), -1.070847]. 
=============================================
[2019-04-06 17:54:59,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5445683e-10 2.9948728e-07 1.6605486e-10 1.6660621e-02 3.0661115e-10
 9.8333907e-01 1.1509378e-09], sum to 1.0000
[2019-04-06 17:54:59,516] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3921
[2019-04-06 17:54:59,560] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.9, 86.0, 120.0, 0.0, 26.0, 26.68260426297955, 0.681979206479023, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 991800.0000, 
sim time next is 993600.0000, 
raw observation next is [12.2, 86.0, 124.0, 0.0, 26.0, 26.69808929051296, 0.699505017245413, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.8005540166204987, 0.86, 0.41333333333333333, 0.0, 0.6666666666666666, 0.7248407742094134, 0.7331683390818043, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1837677], dtype=float32), 1.3978963]. 
=============================================
[2019-04-06 17:55:00,378] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.36885309e-10 3.70173638e-07 1.57364599e-09 4.03878232e-03
 2.37590569e-09 9.95960891e-01 1.07278595e-08], sum to 1.0000
[2019-04-06 17:55:00,378] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4940
[2019-04-06 17:55:00,403] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 26.0, 25.77412938651967, 0.5305121336836213, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1017000.0000, 
sim time next is 1018800.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 26.0, 25.58436454402348, 0.5173942298570683, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.8614958448753465, 0.81, 0.0, 0.0, 0.6666666666666666, 0.6320303786686233, 0.6724647432856895, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2676506], dtype=float32), -0.5162669]. 
=============================================
[2019-04-06 17:55:10,307] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.3438939e-09 2.5061397e-07 1.1266808e-08 6.4010504e-03 5.6632293e-10
 9.9359870e-01 3.9253516e-09], sum to 1.0000
[2019-04-06 17:55:10,307] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3019
[2019-04-06 17:55:10,684] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 65.0, 130.0, 405.0, 26.0, 25.10843577683385, 0.2964394507876238, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2368800.0000, 
sim time next is 2370600.0000, 
raw observation next is [-2.55, 63.5, 139.0, 450.0, 26.0, 24.91671519974378, 0.2886576858217527, 0.0, 1.0, 39493.91171495171], 
processed observation next is [0.0, 0.43478260869565216, 0.3919667590027701, 0.635, 0.4633333333333333, 0.4972375690607735, 0.6666666666666666, 0.5763929333119817, 0.5962192286072509, 0.0, 1.0, 0.1880662462616748], 
reward next is 0.8119, 
noisyNet noise sample is [array([-1.0457919], dtype=float32), 0.37712234]. 
=============================================
[2019-04-06 17:55:12,475] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0280021e-10 1.6834895e-07 2.8249525e-09 5.3810715e-03 2.8851002e-10
 9.9461877e-01 1.8763825e-10], sum to 1.0000
[2019-04-06 17:55:12,481] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4940
[2019-04-06 17:55:12,605] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 80.5, 0.0, 0.0, 26.0, 25.68059774911281, 0.5520716517138778, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1560600.0000, 
sim time next is 1562400.0000, 
raw observation next is [5.0, 79.0, 0.0, 0.0, 26.0, 25.43413442192882, 0.5186253966383201, 0.0, 1.0, 69540.766751563], 
processed observation next is [1.0, 0.08695652173913043, 0.6011080332409973, 0.79, 0.0, 0.0, 0.6666666666666666, 0.6195112018274017, 0.6728751322127734, 0.0, 1.0, 0.3311465083407762], 
reward next is 0.6689, 
noisyNet noise sample is [array([0.28113392], dtype=float32), -1.7440152]. 
=============================================
[2019-04-06 17:55:32,390] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0024532e-11 6.2954875e-08 5.0308879e-10 3.7353981e-02 6.0158636e-12
 9.6264589e-01 1.9021595e-10], sum to 1.0000
[2019-04-06 17:55:32,390] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4293
[2019-04-06 17:55:32,481] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.5, 97.0, 0.0, 0.0, 26.0, 25.47897680408785, 0.5520913445030906, 0.0, 1.0, 64236.32779250494], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1663200.0000, 
sim time next is 1665000.0000, 
raw observation next is [5.25, 94.5, 0.0, 0.0, 26.0, 25.6557705609013, 0.5483603087562321, 0.0, 1.0, 6249.0182520710505], 
processed observation next is [1.0, 0.2608695652173913, 0.60803324099723, 0.945, 0.0, 0.0, 0.6666666666666666, 0.6379808800751082, 0.6827867695854106, 0.0, 1.0, 0.029757229771766907], 
reward next is 0.9702, 
noisyNet noise sample is [array([-0.4030351], dtype=float32), -0.046250496]. 
=============================================
[2019-04-06 17:55:32,523] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[97.48833]
 [97.26402]
 [97.42901]
 [97.29243]
 [97.28964]], R is [[97.02707672]
 [96.75092316]
 [96.67695618]
 [96.46723938]
 [96.50257111]].
[2019-04-06 17:55:33,452] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.9382148e-08 2.1571992e-07 1.1071355e-08 3.4724562e-03 7.9662801e-09
 9.9652725e-01 1.5218832e-08], sum to 1.0000
[2019-04-06 17:55:33,452] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0069
[2019-04-06 17:55:33,522] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 26.0, 23.73107201408202, -0.02568021301216675, 0.0, 1.0, 40422.4307655973], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3049200.0000, 
sim time next is 3051000.0000, 
raw observation next is [-6.0, 70.5, 0.0, 0.0, 26.0, 23.63688093836484, -0.04756457574431707, 0.0, 1.0, 40689.019968263376], 
processed observation next is [0.0, 0.30434782608695654, 0.296398891966759, 0.705, 0.0, 0.0, 0.6666666666666666, 0.46974007819707, 0.48414514141856096, 0.0, 1.0, 0.19375723794411132], 
reward next is 0.8062, 
noisyNet noise sample is [array([-0.01346093], dtype=float32), 0.18532649]. 
=============================================
[2019-04-06 17:55:33,525] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[74.800674]
 [74.921585]
 [75.163445]
 [75.547844]
 [75.82703 ]], R is [[74.44932556]
 [74.51234436]
 [74.57550049]
 [74.63847351]
 [74.70083618]].
[2019-04-06 17:56:20,125] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0395862e-10 3.5916750e-07 4.5719646e-09 7.9409993e-04 1.5464589e-10
 9.9920553e-01 1.9379569e-09], sum to 1.0000
[2019-04-06 17:56:20,126] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3377
[2019-04-06 17:56:20,454] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 75.0, 151.5, 0.0, 26.0, 25.69511802084746, 0.3523479874246633, 1.0, 1.0, 22892.377149720098], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2030400.0000, 
sim time next is 2032200.0000, 
raw observation next is [-4.5, 77.0, 156.0, 0.0, 26.0, 25.53486147436868, 0.3023591702177633, 1.0, 1.0, 17523.8948549152], 
processed observation next is [1.0, 0.5217391304347826, 0.3379501385041552, 0.77, 0.52, 0.0, 0.6666666666666666, 0.6279051228640565, 0.6007863900725877, 1.0, 1.0, 0.08344711835673906], 
reward next is 0.9166, 
noisyNet noise sample is [array([0.76450557], dtype=float32), 1.3928409]. 
=============================================
[2019-04-06 17:56:23,945] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3097725e-10 5.0385403e-08 1.5138363e-09 5.1119988e-04 9.0810165e-11
 9.9948871e-01 3.8891512e-10], sum to 1.0000
[2019-04-06 17:56:23,945] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3566
[2019-04-06 17:56:24,034] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.32442518229505, 0.3890801625929163, 0.0, 1.0, 39873.54565978945], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3902400.0000, 
sim time next is 3904200.0000, 
raw observation next is [-3.5, 74.0, 0.0, 0.0, 26.0, 25.33044107573318, 0.3774649202982756, 0.0, 1.0, 40330.577876371935], 
processed observation next is [1.0, 0.17391304347826086, 0.36565096952908593, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6108700896444317, 0.6258216400994252, 0.0, 1.0, 0.19205037083986637], 
reward next is 0.8079, 
noisyNet noise sample is [array([0.29256672], dtype=float32), 1.0673835]. 
=============================================
[2019-04-06 17:56:33,128] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.5996182e-11 6.3820671e-08 1.8212060e-10 1.0832219e-03 7.8681461e-10
 9.9891675e-01 2.0527048e-10], sum to 1.0000
[2019-04-06 17:56:33,128] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0779
[2019-04-06 17:56:33,493] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 82.0, 123.0, 77.5, 26.0, 25.48065782655767, 0.3381846907180577, 1.0, 1.0, 6247.160504678734], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2106000.0000, 
sim time next is 2107800.0000, 
raw observation next is [-7.8, 82.0, 174.0, 118.0, 26.0, 25.66157078064239, 0.3846013359714656, 1.0, 1.0, 26280.80044852894], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.82, 0.58, 0.13038674033149172, 0.6666666666666666, 0.6384642317201991, 0.6282004453238219, 1.0, 1.0, 0.12514666880251876], 
reward next is 0.8749, 
noisyNet noise sample is [array([-0.3360088], dtype=float32), 0.16794841]. 
=============================================
[2019-04-06 17:56:37,760] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-06 17:56:37,760] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:56:37,760] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:56:37,763] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run34
[2019-04-06 17:56:37,831] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:56:37,832] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:56:37,834] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run34
[2019-04-06 17:56:37,937] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:56:37,937] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:56:37,943] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run34
[2019-04-06 17:58:08,052] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.04201443], dtype=float32), 0.121109255]
[2019-04-06 17:58:08,052] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [17.1, 56.0, 74.0, 297.0, 26.0, 25.96874107649246, 0.7218645468740172, 0.0, 0.0, 0.0]
[2019-04-06 17:58:08,053] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 17:58:08,054] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [3.93142905e-08 7.51596554e-06 1.06303176e-07 6.14736276e-03
 2.62037023e-08 9.93844867e-01 8.39217691e-08], sampled 0.4311657741696947
[2019-04-06 17:59:03,585] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3885 79967197.3248 535.2671
[2019-04-06 17:59:22,177] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.3733 87830352.8773 516.5543
[2019-04-06 17:59:24,049] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 17:59:25,071] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 660000, evaluation results [660000.0, 2415.3732858760764, 87830352.877312, 516.5542744756061, 2453.388471443006, 79967197.3248232, 535.2671102210136, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 17:59:42,188] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0170628e-08 6.1440542e-06 1.5954384e-08 6.4163692e-02 5.2943268e-09
 9.3583012e-01 4.9679016e-08], sum to 1.0000
[2019-04-06 17:59:42,202] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6470
[2019-04-06 17:59:42,317] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 38.5, 116.0, 809.0, 26.0, 27.25293283142322, 0.7854391571095292, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5049000.0000, 
sim time next is 5050800.0000, 
raw observation next is [5.0, 36.0, 119.5, 827.0, 26.0, 27.31158912825403, 0.8135071036138046, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.6011080332409973, 0.36, 0.3983333333333333, 0.9138121546961326, 0.6666666666666666, 0.775965760687836, 0.7711690345379348, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1500071], dtype=float32), -0.87619334]. 
=============================================
[2019-04-06 17:59:44,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:59:44,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:59:44,884] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run16
[2019-04-06 17:59:55,088] A3C_AGENT_WORKER-Thread-11 INFO:Local step 42500, global step 664245: loss 7.9171
[2019-04-06 17:59:55,088] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 42500, global step 664245: learning rate 0.0000
[2019-04-06 18:00:15,457] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.0976041e-09 4.1274197e-06 3.4503053e-08 9.8862441e-04 5.9557368e-09
 9.9900728e-01 1.5802646e-08], sum to 1.0000
[2019-04-06 18:00:15,458] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5843
[2019-04-06 18:00:15,516] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 52.0, 0.0, 0.0, 26.0, 24.92328381814866, 0.278139541603662, 0.0, 1.0, 39437.510834673616], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4167000.0000, 
sim time next is 4168800.0000, 
raw observation next is [-4.0, 50.0, 0.0, 0.0, 26.0, 24.81479291462604, 0.2553438816734373, 0.0, 1.0, 39548.867941108394], 
processed observation next is [0.0, 0.2608695652173913, 0.3518005540166205, 0.5, 0.0, 0.0, 0.6666666666666666, 0.56789940955217, 0.585114627224479, 0.0, 1.0, 0.18832794257670663], 
reward next is 0.8117, 
noisyNet noise sample is [array([0.21032992], dtype=float32), -0.9908523]. 
=============================================
[2019-04-06 18:00:17,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:00:17,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:00:17,424] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run16
[2019-04-06 18:00:23,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:00:23,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:00:23,428] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run16
[2019-04-06 18:00:26,767] A3C_AGENT_WORKER-Thread-17 INFO:Local step 42500, global step 669098: loss 8.0220
[2019-04-06 18:00:26,767] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 42500, global step 669098: learning rate 0.0000
[2019-04-06 18:00:27,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:00:27,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:00:27,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run16
[2019-04-06 18:00:29,614] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:00:29,615] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:00:29,618] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run16
[2019-04-06 18:00:32,740] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5426786e-09 6.7465874e-07 1.5618000e-09 5.2663533e-04 2.6714508e-10
 9.9947268e-01 1.0505394e-08], sum to 1.0000
[2019-04-06 18:00:32,740] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1070
[2019-04-06 18:00:32,773] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 59.0, 15.0, 165.0, 26.0, 25.30659093338998, 0.3902015901878302, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3691800.0000, 
sim time next is 3693600.0000, 
raw observation next is [4.0, 59.0, 0.0, 0.0, 26.0, 25.14782173598343, 0.3408101011779068, 0.0, 1.0, 9733.371465456134], 
processed observation next is [0.0, 0.782608695652174, 0.5734072022160666, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5956518113319526, 0.6136033670593023, 0.0, 1.0, 0.046349387930743495], 
reward next is 0.9537, 
noisyNet noise sample is [array([1.1820196], dtype=float32), 0.67874366]. 
=============================================
[2019-04-06 18:00:33,034] A3C_AGENT_WORKER-Thread-3 INFO:Local step 42500, global step 669994: loss 7.9554
[2019-04-06 18:00:33,034] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 42500, global step 669994: learning rate 0.0000
[2019-04-06 18:00:37,226] A3C_AGENT_WORKER-Thread-5 INFO:Local step 42500, global step 670669: loss 7.9954
[2019-04-06 18:00:37,226] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 42500, global step 670669: learning rate 0.0000
[2019-04-06 18:00:39,431] A3C_AGENT_WORKER-Thread-13 INFO:Local step 42500, global step 671045: loss 8.4552
[2019-04-06 18:00:39,432] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 42500, global step 671045: learning rate 0.0000
[2019-04-06 18:00:58,842] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:00:58,842] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:00:58,846] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run16
[2019-04-06 18:01:06,720] A3C_AGENT_WORKER-Thread-11 INFO:Local step 43000, global step 675098: loss 0.3097
[2019-04-06 18:01:06,721] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 43000, global step 675098: learning rate 0.0000
[2019-04-06 18:01:18,088] A3C_AGENT_WORKER-Thread-16 INFO:Local step 42500, global step 676193: loss 7.9299
[2019-04-06 18:01:18,088] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 42500, global step 676193: learning rate 0.0000
[2019-04-06 18:01:37,933] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.9752871e-10 1.5894294e-07 4.9127973e-09 2.4632444e-03 1.2621825e-09
 9.9753654e-01 6.2220953e-09], sum to 1.0000
[2019-04-06 18:01:37,933] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8221
[2019-04-06 18:01:38,056] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.35, 86.5, 0.0, 0.0, 26.0, 24.48483456272314, 0.1694155659677331, 0.0, 1.0, 40681.827073565444], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 538200.0000, 
sim time next is 540000.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 26.0, 24.49112501410858, 0.166598400830193, 0.0, 1.0, 40770.53809683354], 
processed observation next is [0.0, 0.2608695652173913, 0.49307479224376743, 0.88, 0.0, 0.0, 0.6666666666666666, 0.5409270845090483, 0.555532800276731, 0.0, 1.0, 0.19414541950873113], 
reward next is 0.8059, 
noisyNet noise sample is [array([-0.55682826], dtype=float32), -0.82024246]. 
=============================================
[2019-04-06 18:01:38,095] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[84.40965 ]
 [84.79497 ]
 [85.24609 ]
 [85.68345 ]
 [86.215004]], R is [[84.07749176]
 [84.04299164]
 [84.00987244]
 [83.97814941]
 [83.94748688]].
[2019-04-06 18:01:41,807] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0120691e-09 1.1307974e-07 4.3201484e-10 2.8986108e-04 4.9539223e-11
 9.9971002e-01 8.4483148e-10], sum to 1.0000
[2019-04-06 18:01:41,807] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3932
[2019-04-06 18:01:42,118] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 174.0, 246.0, 26.0, 25.55629831862137, 0.3864860495151419, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4870800.0000, 
sim time next is 4872600.0000, 
raw observation next is [-2.5, 62.5, 207.0, 179.0, 26.0, 25.47851517295761, 0.3653689733810569, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.39335180055401664, 0.625, 0.69, 0.19779005524861878, 0.6666666666666666, 0.6232095977464676, 0.6217896577936856, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0067291], dtype=float32), 1.1577576]. 
=============================================
[2019-04-06 18:01:56,189] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 18:01:56,190] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:01:56,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:01:56,192] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run35
[2019-04-06 18:01:56,261] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:01:56,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:01:56,269] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run35
[2019-04-06 18:01:56,370] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:01:56,371] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:01:56,373] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run35
[2019-04-06 18:01:56,646] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:01:56,647] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:01:56,650] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run16
[2019-04-06 18:04:20,437] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 18:04:39,895] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 18:04:41,389] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 18:04:42,410] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 680000, evaluation results [680000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 18:04:44,556] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3147202e-10 1.0125848e-07 1.4960223e-09 1.2432584e-04 6.8300046e-11
 9.9987555e-01 7.6716011e-10], sum to 1.0000
[2019-04-06 18:04:44,556] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6996
[2019-04-06 18:04:44,587] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.5, 18.0, 0.0, 0.0, 26.0, 27.76012808678516, 0.9772095793829733, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5081400.0000, 
sim time next is 5083200.0000, 
raw observation next is [10.0, 19.0, 0.0, 0.0, 26.0, 27.48734861998543, 0.9290641152306298, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.739612188365651, 0.19, 0.0, 0.0, 0.6666666666666666, 0.7906123849987857, 0.80968803841021, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3973914], dtype=float32), -0.11048074]. 
=============================================
[2019-04-06 18:04:44,780] A3C_AGENT_WORKER-Thread-6 INFO:Local step 42500, global step 680402: loss 10.5454
[2019-04-06 18:04:44,781] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 42500, global step 680402: learning rate 0.0000
[2019-04-06 18:04:45,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:04:45,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:04:45,200] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run16
[2019-04-06 18:04:45,929] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:04:45,929] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:04:45,932] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run16
[2019-04-06 18:04:47,372] A3C_AGENT_WORKER-Thread-17 INFO:Local step 43000, global step 680719: loss 0.2848
[2019-04-06 18:04:47,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 43000, global step 680719: learning rate 0.0000
[2019-04-06 18:04:50,884] A3C_AGENT_WORKER-Thread-11 INFO:Local step 43500, global step 681185: loss 1.2109
[2019-04-06 18:04:50,885] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 43500, global step 681185: learning rate 0.0000
[2019-04-06 18:04:54,080] A3C_AGENT_WORKER-Thread-3 INFO:Local step 43000, global step 681621: loss 0.2966
[2019-04-06 18:04:54,080] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 43000, global step 681621: learning rate 0.0000
[2019-04-06 18:04:54,375] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.1768030e-09 3.2763273e-06 1.3350973e-07 1.0059796e-02 4.0491530e-09
 9.8993683e-01 8.6868432e-09], sum to 1.0000
[2019-04-06 18:04:54,375] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8480
[2019-04-06 18:04:54,417] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.29481957390757, 0.3512173502164108, 0.0, 1.0, 48950.71901433718], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4840200.0000, 
sim time next is 4842000.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.22881678936268, 0.3396806594485327, 0.0, 1.0, 41212.35734507404], 
processed observation next is [0.0, 0.043478260869565216, 0.40720221606648205, 0.6, 0.0, 0.0, 0.6666666666666666, 0.6024013991135565, 0.6132268864828442, 0.0, 1.0, 0.19624932069082876], 
reward next is 0.8038, 
noisyNet noise sample is [array([0.00704752], dtype=float32), -0.2890166]. 
=============================================
[2019-04-06 18:04:54,423] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.81784]
 [77.37435]
 [77.91802]
 [78.01803]
 [78.03222]], R is [[77.62680817]
 [77.61743927]
 [77.6660614 ]
 [77.76010132]
 [77.76811981]].
[2019-04-06 18:04:54,425] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2113059e-10 9.0581608e-08 4.5906054e-10 3.2375809e-02 1.4733141e-10
 9.6762407e-01 2.7392904e-09], sum to 1.0000
[2019-04-06 18:04:54,425] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4323
[2019-04-06 18:04:54,475] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.7, 64.0, 0.0, 0.0, 26.0, 25.83341115732189, 0.6744956126921328, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1116000.0000, 
sim time next is 1117800.0000, 
raw observation next is [12.45, 65.0, 0.0, 0.0, 26.0, 25.7085730270639, 0.6426826377960357, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.8074792243767314, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6423810855886583, 0.7142275459320119, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5191932], dtype=float32), -0.48789456]. 
=============================================
[2019-04-06 18:04:55,103] A3C_AGENT_WORKER-Thread-12 INFO:Local step 42500, global step 681758: loss 8.0071
[2019-04-06 18:04:55,103] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 42500, global step 681758: learning rate 0.0000
[2019-04-06 18:04:55,607] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0831671e-09 1.6423405e-07 1.4689279e-09 3.8559563e-03 3.7788273e-10
 9.9614382e-01 4.0186778e-09], sum to 1.0000
[2019-04-06 18:04:55,608] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4323
[2019-04-06 18:04:55,678] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.8, 83.0, 0.0, 0.0, 26.0, 25.4487260330341, 0.454379210618008, 0.0, 1.0, 30079.737653720542], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 968400.0000, 
sim time next is 970200.0000, 
raw observation next is [8.8, 83.0, 0.0, 0.0, 26.0, 25.51860625686706, 0.4408839200837117, 0.0, 1.0, 12502.283091366764], 
processed observation next is [1.0, 0.21739130434782608, 0.7063711911357342, 0.83, 0.0, 0.0, 0.6666666666666666, 0.6265505214055883, 0.6469613066945706, 0.0, 1.0, 0.05953468138746078], 
reward next is 0.9405, 
noisyNet noise sample is [array([0.9301418], dtype=float32), 0.1901366]. 
=============================================
[2019-04-06 18:04:56,410] A3C_AGENT_WORKER-Thread-18 INFO:Local step 42500, global step 681942: loss 7.8902
[2019-04-06 18:04:56,411] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 42500, global step 681942: learning rate 0.0000
[2019-04-06 18:04:57,888] A3C_AGENT_WORKER-Thread-5 INFO:Local step 43000, global step 682188: loss 0.2694
[2019-04-06 18:04:57,889] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 43000, global step 682188: learning rate 0.0000
[2019-04-06 18:04:59,484] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1465786e-11 4.4066010e-08 1.5982084e-10 4.2357021e-03 1.6545857e-11
 9.9576426e-01 1.5148340e-10], sum to 1.0000
[2019-04-06 18:04:59,484] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2647
[2019-04-06 18:04:59,718] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.1, 82.5, 85.0, 549.0, 26.0, 25.64493418666689, 0.300471492740175, 1.0, 1.0, 12495.071156465327], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1935000.0000, 
sim time next is 1936800.0000, 
raw observation next is [-7.3, 79.0, 128.0, 392.5, 26.0, 25.64573485180795, 0.3195491509297663, 1.0, 1.0, 21207.610620639323], 
processed observation next is [1.0, 0.43478260869565216, 0.26038781163434904, 0.79, 0.4266666666666667, 0.43370165745856354, 0.6666666666666666, 0.6371445709839959, 0.6065163836432554, 1.0, 1.0, 0.1009886220030444], 
reward next is 0.8990, 
noisyNet noise sample is [array([-0.05692538], dtype=float32), 0.089272045]. 
=============================================
[2019-04-06 18:05:00,142] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6434877e-09 2.3336752e-06 4.5007673e-09 3.0799655e-03 3.2396222e-10
 9.9691772e-01 7.1387127e-09], sum to 1.0000
[2019-04-06 18:05:00,142] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1415
[2019-04-06 18:05:00,315] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 163.5, 575.5, 26.0, 25.57728604302401, 0.4616023054892034, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4788000.0000, 
sim time next is 4789800.0000, 
raw observation next is [-2.5, 55.5, 153.0, 730.0, 26.0, 25.4236649068223, 0.4520745132523146, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.39335180055401664, 0.555, 0.51, 0.8066298342541437, 0.6666666666666666, 0.6186387422351917, 0.6506915044174382, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.35481825], dtype=float32), -0.465902]. 
=============================================
[2019-04-06 18:05:02,037] A3C_AGENT_WORKER-Thread-13 INFO:Local step 43000, global step 682846: loss 0.2782
[2019-04-06 18:05:02,044] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 43000, global step 682846: learning rate 0.0000
[2019-04-06 18:05:08,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:05:08,183] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:05:08,188] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run16
[2019-04-06 18:05:13,792] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:05:13,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:05:13,799] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run16
[2019-04-06 18:05:13,940] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:05:13,940] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:05:13,952] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run16
[2019-04-06 18:05:14,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:05:14,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:05:14,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run16
[2019-04-06 18:05:15,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:05:15,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:05:15,484] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run16
[2019-04-06 18:05:15,591] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:05:15,591] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:05:15,596] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run16
[2019-04-06 18:05:16,392] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:05:16,392] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:05:16,395] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run16
[2019-04-06 18:05:18,043] A3C_AGENT_WORKER-Thread-19 INFO:Local step 42500, global step 685181: loss 7.8903
[2019-04-06 18:05:18,043] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 42500, global step 685181: learning rate 0.0000
[2019-04-06 18:05:24,718] A3C_AGENT_WORKER-Thread-14 INFO:Local step 42500, global step 685742: loss 8.1975
[2019-04-06 18:05:24,720] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 42500, global step 685742: learning rate 0.0000
[2019-04-06 18:05:24,935] A3C_AGENT_WORKER-Thread-4 INFO:Local step 42500, global step 685764: loss 8.0893
[2019-04-06 18:05:24,936] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 42500, global step 685764: learning rate 0.0000
[2019-04-06 18:05:26,250] A3C_AGENT_WORKER-Thread-15 INFO:Local step 42500, global step 685899: loss 7.8693
[2019-04-06 18:05:26,251] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 42500, global step 685899: learning rate 0.0000
[2019-04-06 18:05:26,832] A3C_AGENT_WORKER-Thread-20 INFO:Local step 42500, global step 685960: loss 7.8655
[2019-04-06 18:05:26,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 42500, global step 685960: learning rate 0.0000
[2019-04-06 18:05:27,113] A3C_AGENT_WORKER-Thread-2 INFO:Local step 42500, global step 685988: loss 19.6283
[2019-04-06 18:05:27,114] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 42500, global step 685988: learning rate 0.0000
[2019-04-06 18:05:28,564] A3C_AGENT_WORKER-Thread-10 INFO:Local step 42500, global step 686129: loss 7.7999
[2019-04-06 18:05:28,564] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 42500, global step 686129: learning rate 0.0000
[2019-04-06 18:05:29,933] A3C_AGENT_WORKER-Thread-17 INFO:Local step 43500, global step 686307: loss 1.2946
[2019-04-06 18:05:29,933] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 43500, global step 686307: learning rate 0.0000
[2019-04-06 18:05:34,642] A3C_AGENT_WORKER-Thread-16 INFO:Local step 43000, global step 686866: loss 0.2792
[2019-04-06 18:05:34,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 43000, global step 686866: learning rate 0.0000
[2019-04-06 18:05:36,180] A3C_AGENT_WORKER-Thread-3 INFO:Local step 43500, global step 687018: loss 1.1704
[2019-04-06 18:05:36,180] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 43500, global step 687018: learning rate 0.0000
[2019-04-06 18:05:41,522] A3C_AGENT_WORKER-Thread-5 INFO:Local step 43500, global step 687638: loss 1.2229
[2019-04-06 18:05:41,523] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 43500, global step 687638: learning rate 0.0000
[2019-04-06 18:05:43,923] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.2730819e-09 5.1748093e-06 1.7575918e-08 1.3985636e-03 2.2806819e-09
 9.9859625e-01 4.9551518e-09], sum to 1.0000
[2019-04-06 18:05:43,923] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0617
[2019-04-06 18:05:43,929] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 26.0, 23.66923643627832, 0.1823068529155665, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1227600.0000, 
sim time next is 1229400.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 26.0, 23.60900915761398, 0.1766954195630129, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.8781163434903049, 0.96, 0.0, 0.0, 0.6666666666666666, 0.4674174298011649, 0.5588984731876709, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.33902517], dtype=float32), -1.4125426]. 
=============================================
[2019-04-06 18:05:47,037] A3C_AGENT_WORKER-Thread-13 INFO:Local step 43500, global step 688283: loss 1.2320
[2019-04-06 18:05:47,038] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 43500, global step 688283: learning rate 0.0000
[2019-04-06 18:05:59,135] A3C_AGENT_WORKER-Thread-6 INFO:Local step 43000, global step 689612: loss 0.2327
[2019-04-06 18:05:59,135] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 43000, global step 689612: learning rate 0.0000
[2019-04-06 18:05:59,759] A3C_AGENT_WORKER-Thread-11 INFO:Local step 44000, global step 689673: loss 0.1407
[2019-04-06 18:05:59,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 44000, global step 689673: learning rate 0.0000
[2019-04-06 18:06:04,562] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2405096e-09 8.3227746e-07 1.3313118e-08 9.7162666e-04 1.7403788e-09
 9.9902749e-01 2.2693583e-09], sum to 1.0000
[2019-04-06 18:06:04,563] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7368
[2019-04-06 18:06:04,616] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.2, 55.0, 0.0, 0.0, 26.0, 23.55292639111366, -0.09126930718491787, 0.0, 1.0, 45493.42967307327], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 437400.0000, 
sim time next is 439200.0000, 
raw observation next is [-11.2, 55.0, 0.0, 0.0, 26.0, 23.34835189932226, -0.1233808306614423, 0.0, 1.0, 45687.690140601415], 
processed observation next is [1.0, 0.08695652173913043, 0.15235457063711913, 0.55, 0.0, 0.0, 0.6666666666666666, 0.44569599161018836, 0.45887305644618587, 0.0, 1.0, 0.2175604292409591], 
reward next is 0.7824, 
noisyNet noise sample is [array([-0.33279788], dtype=float32), -2.4696212]. 
=============================================
[2019-04-06 18:06:09,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5054230e-10 1.4053066e-07 3.3504483e-10 1.4327485e-03 1.7610545e-11
 9.9856710e-01 1.8555176e-09], sum to 1.0000
[2019-04-06 18:06:09,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4125
[2019-04-06 18:06:09,700] A3C_AGENT_WORKER-Thread-12 INFO:Local step 43000, global step 690956: loss 0.2872
[2019-04-06 18:06:09,701] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 43000, global step 690956: learning rate 0.0000
[2019-04-06 18:06:09,703] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 89.0, 0.0, 0.0, 26.0, 24.84415048591606, 0.2556609209663292, 0.0, 1.0, 39733.73959195702], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 522000.0000, 
sim time next is 523800.0000, 
raw observation next is [4.65, 88.5, 0.0, 0.0, 26.0, 25.02892288957022, 0.2584819736073531, 0.0, 1.0, 39547.704440021385], 
processed observation next is [0.0, 0.043478260869565216, 0.5914127423822716, 0.885, 0.0, 0.0, 0.6666666666666666, 0.5857435741308518, 0.5861606578691178, 0.0, 1.0, 0.18832240209533993], 
reward next is 0.8117, 
noisyNet noise sample is [array([0.08083893], dtype=float32), -0.7002001]. 
=============================================
[2019-04-06 18:06:11,958] A3C_AGENT_WORKER-Thread-18 INFO:Local step 43000, global step 691267: loss 0.2816
[2019-04-06 18:06:11,958] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 43000, global step 691267: learning rate 0.0000
[2019-04-06 18:06:16,477] A3C_AGENT_WORKER-Thread-16 INFO:Local step 43500, global step 691897: loss 1.1938
[2019-04-06 18:06:16,477] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 43500, global step 691897: learning rate 0.0000
[2019-04-06 18:06:42,054] A3C_AGENT_WORKER-Thread-19 INFO:Local step 43000, global step 694429: loss 0.2273
[2019-04-06 18:06:42,054] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 43000, global step 694429: learning rate 0.0000
[2019-04-06 18:06:47,917] A3C_AGENT_WORKER-Thread-17 INFO:Local step 44000, global step 694975: loss 0.0608
[2019-04-06 18:06:47,917] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 44000, global step 694975: learning rate 0.0000
[2019-04-06 18:06:49,700] A3C_AGENT_WORKER-Thread-6 INFO:Local step 43500, global step 695147: loss 1.1245
[2019-04-06 18:06:49,700] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 43500, global step 695147: learning rate 0.0000
[2019-04-06 18:06:50,415] A3C_AGENT_WORKER-Thread-4 INFO:Local step 43000, global step 695216: loss 0.2366
[2019-04-06 18:06:50,415] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 43000, global step 695216: learning rate 0.0000
[2019-04-06 18:06:51,003] A3C_AGENT_WORKER-Thread-14 INFO:Local step 43000, global step 695269: loss 0.2745
[2019-04-06 18:06:51,005] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 43000, global step 695269: learning rate 0.0000
[2019-04-06 18:06:51,234] A3C_AGENT_WORKER-Thread-15 INFO:Local step 43000, global step 695289: loss 0.2364
[2019-04-06 18:06:51,234] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 43000, global step 695289: learning rate 0.0000
[2019-04-06 18:06:52,016] A3C_AGENT_WORKER-Thread-20 INFO:Local step 43000, global step 695366: loss 0.2480
[2019-04-06 18:06:52,016] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 43000, global step 695366: learning rate 0.0000
[2019-04-06 18:06:52,443] A3C_AGENT_WORKER-Thread-10 INFO:Local step 43000, global step 695410: loss 0.2865
[2019-04-06 18:06:52,444] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 43000, global step 695410: learning rate 0.0000
[2019-04-06 18:06:54,435] A3C_AGENT_WORKER-Thread-2 INFO:Local step 43000, global step 695616: loss 0.2702
[2019-04-06 18:06:54,435] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 43000, global step 695616: learning rate 0.0000
[2019-04-06 18:06:55,286] A3C_AGENT_WORKER-Thread-3 INFO:Local step 44000, global step 695696: loss 0.0829
[2019-04-06 18:06:55,286] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 44000, global step 695696: learning rate 0.0000
[2019-04-06 18:06:56,978] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6604753e-10 6.3400347e-07 3.3973224e-09 3.9490978e-03 1.8111405e-10
 9.9605030e-01 8.7427204e-10], sum to 1.0000
[2019-04-06 18:06:56,978] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3494
[2019-04-06 18:06:57,299] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 26.0, 25.5775831022252, 0.5656489720744424, 1.0, 1.0, 25963.524992309005], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1711800.0000, 
sim time next is 1713600.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 26.0, 25.72034688623292, 0.5568630551187341, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.49307479224376743, 0.88, 0.0, 0.0, 0.6666666666666666, 0.64336224051941, 0.6856210183729115, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.319578], dtype=float32), 0.09421308]. 
=============================================
[2019-04-06 18:07:02,613] A3C_AGENT_WORKER-Thread-5 INFO:Local step 44000, global step 696470: loss 0.0579
[2019-04-06 18:07:02,614] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 44000, global step 696470: learning rate 0.0000
[2019-04-06 18:07:05,221] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.5083101e-08 9.9263593e-07 8.7054282e-08 2.5771095e-03 2.2779254e-09
 9.9742162e-01 6.8285132e-08], sum to 1.0000
[2019-04-06 18:07:05,233] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4003
[2019-04-06 18:07:05,324] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 79.0, 0.0, 0.0, 26.0, 23.67762435678983, -0.003772973246268347, 0.0, 1.0, 47023.84659186555], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1832400.0000, 
sim time next is 1834200.0000, 
raw observation next is [-6.2, 79.0, 0.0, 0.0, 26.0, 23.6663558450124, -0.006170422184799619, 0.0, 1.0, 47096.987476853676], 
processed observation next is [0.0, 0.21739130434782608, 0.2908587257617729, 0.79, 0.0, 0.0, 0.6666666666666666, 0.47219632041770004, 0.4979431926050668, 0.0, 1.0, 0.22427136893739846], 
reward next is 0.7757, 
noisyNet noise sample is [array([1.0029567], dtype=float32), -0.2698589]. 
=============================================
[2019-04-06 18:07:05,565] A3C_AGENT_WORKER-Thread-12 INFO:Local step 43500, global step 696758: loss 0.9171
[2019-04-06 18:07:05,570] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 43500, global step 696758: learning rate 0.0000
[2019-04-06 18:07:08,870] A3C_AGENT_WORKER-Thread-11 INFO:Local step 44500, global step 697091: loss 2.7585
[2019-04-06 18:07:08,917] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 44500, global step 697091: learning rate 0.0000
[2019-04-06 18:07:13,153] A3C_AGENT_WORKER-Thread-18 INFO:Local step 43500, global step 697522: loss 1.1966
[2019-04-06 18:07:13,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 43500, global step 697522: learning rate 0.0000
[2019-04-06 18:07:16,226] A3C_AGENT_WORKER-Thread-13 INFO:Local step 44000, global step 697788: loss 0.0624
[2019-04-06 18:07:16,226] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 44000, global step 697788: learning rate 0.0000
[2019-04-06 18:07:40,696] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 18:07:40,697] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:07:40,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:07:40,710] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run36
[2019-04-06 18:07:40,787] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:07:40,789] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:07:40,805] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:07:40,808] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run36
[2019-04-06 18:07:40,854] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:07:40,856] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run36
[2019-04-06 18:07:54,343] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.04378649], dtype=float32), 0.12177583]
[2019-04-06 18:07:54,343] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.05, 90.5, 0.0, 0.0, 26.0, 24.60460091242745, 0.2095965362051254, 0.0, 1.0, 40587.636220344946]
[2019-04-06 18:07:54,343] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 18:07:54,345] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.0988476e-09 3.0510100e-07 3.7001568e-09 2.2919259e-03 4.0685172e-10
 9.9770772e-01 2.3706219e-09], sampled 0.1614969918803837
[2019-04-06 18:10:10,862] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2462 79987260.4995 535.2506
[2019-04-06 18:10:31,357] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 18:10:32,768] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 18:10:33,790] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 700000, evaluation results [700000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.2461995019034, 79987260.49946941, 535.2506232687274, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 18:10:36,089] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9931645e-11 2.9456803e-07 1.2147368e-10 1.7705579e-04 6.0663552e-10
 9.9982268e-01 1.9976462e-10], sum to 1.0000
[2019-04-06 18:10:36,104] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2801
[2019-04-06 18:10:36,128] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 49.0, 162.5, 62.0, 26.0, 26.32359755233874, 0.7420907349572793, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1602000.0000, 
sim time next is 1603800.0000, 
raw observation next is [13.8, 49.0, 176.0, 0.0, 26.0, 26.92314386769619, 0.80829624476541, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.844875346260388, 0.49, 0.5866666666666667, 0.0, 0.6666666666666666, 0.7435953223080158, 0.76943208158847, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.9611088], dtype=float32), 1.0502138]. 
=============================================
[2019-04-06 18:10:37,689] A3C_AGENT_WORKER-Thread-19 INFO:Local step 43500, global step 700646: loss 1.1001
[2019-04-06 18:10:37,709] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 43500, global step 700646: learning rate 0.0000
[2019-04-06 18:10:38,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5037776e-12 1.5183867e-08 3.0574152e-10 5.6598242e-04 2.9393649e-12
 9.9943393e-01 1.5723695e-11], sum to 1.0000
[2019-04-06 18:10:38,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8543
[2019-04-06 18:10:38,426] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 92.0, 0.0, 0.0, 26.0, 25.58663884933797, 0.5376786823877437, 0.0, 1.0, 21843.378048289618], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1666800.0000, 
sim time next is 1668600.0000, 
raw observation next is [4.15, 92.0, 0.0, 0.0, 26.0, 25.5432371118846, 0.526966840671152, 1.0, 1.0, 10249.42086184955], 
processed observation next is [1.0, 0.30434782608695654, 0.5775623268698062, 0.92, 0.0, 0.0, 0.6666666666666666, 0.62860309265705, 0.6756556135570507, 1.0, 1.0, 0.04880676600880738], 
reward next is 0.9512, 
noisyNet noise sample is [array([-0.3534792], dtype=float32), 1.1428199]. 
=============================================
[2019-04-06 18:10:46,982] A3C_AGENT_WORKER-Thread-4 INFO:Local step 43500, global step 701865: loss 1.0738
[2019-04-06 18:10:46,988] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 43500, global step 701865: learning rate 0.0000
[2019-04-06 18:10:47,395] A3C_AGENT_WORKER-Thread-10 INFO:Local step 43500, global step 701939: loss 0.8968
[2019-04-06 18:10:47,398] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 43500, global step 701939: learning rate 0.0000
[2019-04-06 18:10:47,464] A3C_AGENT_WORKER-Thread-15 INFO:Local step 43500, global step 701951: loss 1.0279
[2019-04-06 18:10:47,490] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 43500, global step 701951: learning rate 0.0000
[2019-04-06 18:10:47,888] A3C_AGENT_WORKER-Thread-14 INFO:Local step 43500, global step 702007: loss 0.9721
[2019-04-06 18:10:47,889] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 43500, global step 702007: learning rate 0.0000
[2019-04-06 18:10:48,289] A3C_AGENT_WORKER-Thread-20 INFO:Local step 43500, global step 702054: loss 1.1538
[2019-04-06 18:10:48,289] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 43500, global step 702054: learning rate 0.0000
[2019-04-06 18:10:50,366] A3C_AGENT_WORKER-Thread-2 INFO:Local step 43500, global step 702307: loss 0.9216
[2019-04-06 18:10:50,384] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 43500, global step 702307: learning rate 0.0000
[2019-04-06 18:10:50,920] A3C_AGENT_WORKER-Thread-16 INFO:Local step 44000, global step 702363: loss 0.0884
[2019-04-06 18:10:50,920] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 44000, global step 702363: learning rate 0.0000
[2019-04-06 18:10:54,449] A3C_AGENT_WORKER-Thread-17 INFO:Local step 44500, global step 702843: loss 3.4275
[2019-04-06 18:10:54,450] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 44500, global step 702843: learning rate 0.0000
[2019-04-06 18:10:57,870] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.5565451e-09 2.2955785e-06 1.9543897e-08 2.4278097e-02 2.5864039e-10
 9.7571963e-01 9.3586594e-10], sum to 1.0000
[2019-04-06 18:10:57,870] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5966
[2019-04-06 18:10:57,921] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.24828339716705, 0.3021190049009607, 0.0, 1.0, 46186.191216143634], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3733200.0000, 
sim time next is 3735000.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.1099470603839, 0.2868230473576367, 0.0, 1.0, 41723.36883749543], 
processed observation next is [1.0, 0.21739130434782608, 0.3795013850415513, 0.65, 0.0, 0.0, 0.6666666666666666, 0.5924955883653249, 0.5956076824525456, 0.0, 1.0, 0.19868270874997823], 
reward next is 0.8013, 
noisyNet noise sample is [array([-0.6099466], dtype=float32), 0.17656505]. 
=============================================
[2019-04-06 18:10:57,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[83.62769 ]
 [83.72741 ]
 [83.983665]
 [84.17062 ]
 [84.3347  ]], R is [[83.44139862]
 [83.38705444]
 [83.36922455]
 [83.3607254 ]
 [83.33075714]].
[2019-04-06 18:10:58,706] A3C_AGENT_WORKER-Thread-11 INFO:Local step 45000, global step 703413: loss 0.9904
[2019-04-06 18:10:58,745] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 45000, global step 703413: learning rate 0.0000
[2019-04-06 18:11:00,048] A3C_AGENT_WORKER-Thread-3 INFO:Local step 44500, global step 703591: loss 3.0900
[2019-04-06 18:11:00,049] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 44500, global step 703591: learning rate 0.0000
[2019-04-06 18:11:03,889] A3C_AGENT_WORKER-Thread-5 INFO:Local step 44500, global step 704136: loss 9.6696
[2019-04-06 18:11:03,896] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 44500, global step 704136: learning rate 0.0000
[2019-04-06 18:11:09,928] A3C_AGENT_WORKER-Thread-13 INFO:Local step 44500, global step 704953: loss 3.1149
[2019-04-06 18:11:09,929] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 44500, global step 704953: learning rate 0.0000
[2019-04-06 18:11:12,680] A3C_AGENT_WORKER-Thread-6 INFO:Local step 44000, global step 705305: loss 0.7937
[2019-04-06 18:11:12,681] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 44000, global step 705305: learning rate 0.0000
[2019-04-06 18:11:21,957] A3C_AGENT_WORKER-Thread-12 INFO:Local step 44000, global step 706570: loss 0.1005
[2019-04-06 18:11:21,957] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 44000, global step 706570: learning rate 0.0000
[2019-04-06 18:11:24,248] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1713029e-09 5.0039052e-08 2.5230549e-09 1.4215749e-04 1.6331933e-10
 9.9985778e-01 1.6320482e-09], sum to 1.0000
[2019-04-06 18:11:24,248] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9799
[2019-04-06 18:11:24,322] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.45, 77.0, 0.0, 0.0, 26.0, 24.71849180547426, 0.2914614400944307, 0.0, 1.0, 43936.932321852575], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3295800.0000, 
sim time next is 3297600.0000, 
raw observation next is [-8.9, 77.0, 0.0, 0.0, 26.0, 24.76195458024647, 0.2665391113849586, 0.0, 1.0, 43996.59696672202], 
processed observation next is [1.0, 0.17391304347826086, 0.21606648199445982, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5634962150205393, 0.5888463704616529, 0.0, 1.0, 0.2095076046034382], 
reward next is 0.7905, 
noisyNet noise sample is [array([0.22776939], dtype=float32), 0.5283538]. 
=============================================
[2019-04-06 18:11:26,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:11:26,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:11:26,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run17
[2019-04-06 18:11:28,498] A3C_AGENT_WORKER-Thread-18 INFO:Local step 44000, global step 707433: loss 0.0745
[2019-04-06 18:11:28,514] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 44000, global step 707433: learning rate 0.0000
[2019-04-06 18:11:29,233] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.3083627e-10 4.4077328e-08 1.2122218e-09 4.6111023e-04 8.3039292e-10
 9.9953890e-01 1.0931399e-08], sum to 1.0000
[2019-04-06 18:11:29,234] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7004
[2019-04-06 18:11:29,336] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 44.0, 0.0, 0.0, 26.0, 25.22796696632058, 0.4133697882981819, 0.0, 1.0, 80236.5413566898], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2840400.0000, 
sim time next is 2842200.0000, 
raw observation next is [2.0, 44.0, 0.0, 0.0, 26.0, 25.43980669658975, 0.4360329348680684, 0.0, 1.0, 37574.079776421924], 
processed observation next is [1.0, 0.9130434782608695, 0.518005540166205, 0.44, 0.0, 0.0, 0.6666666666666666, 0.619983891382479, 0.6453443116226895, 0.0, 1.0, 0.17892418941153299], 
reward next is 0.8211, 
noisyNet noise sample is [array([0.6610037], dtype=float32), -0.50325364]. 
=============================================
[2019-04-06 18:11:38,233] A3C_AGENT_WORKER-Thread-17 INFO:Local step 45000, global step 708885: loss 0.9319
[2019-04-06 18:11:38,233] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 45000, global step 708885: learning rate 0.0000
[2019-04-06 18:11:41,806] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.3683515e-10 1.3407509e-06 3.9952925e-09 1.0948372e-02 8.7531382e-10
 9.8905027e-01 9.4090034e-09], sum to 1.0000
[2019-04-06 18:11:41,806] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0792
[2019-04-06 18:11:41,826] A3C_AGENT_WORKER-Thread-3 INFO:Local step 45000, global step 709503: loss 1.0732
[2019-04-06 18:11:41,826] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 45000, global step 709503: learning rate 0.0000
[2019-04-06 18:11:41,858] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.55, 27.5, 159.0, 275.0, 26.0, 25.85767306932444, 0.3847255544721113, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2557800.0000, 
sim time next is 2559600.0000, 
raw observation next is [3.3, 29.0, 136.5, 313.0, 26.0, 25.77883724740257, 0.3782907037259416, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.554016620498615, 0.29, 0.455, 0.34585635359116024, 0.6666666666666666, 0.6482364372835475, 0.6260969012419805, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3015376], dtype=float32), 0.30018854]. 
=============================================
[2019-04-06 18:11:42,089] A3C_AGENT_WORKER-Thread-16 INFO:Local step 44500, global step 709557: loss 3.0732
[2019-04-06 18:11:42,089] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 44500, global step 709557: learning rate 0.0000
[2019-04-06 18:11:46,041] A3C_AGENT_WORKER-Thread-19 INFO:Local step 44000, global step 710218: loss 0.0607
[2019-04-06 18:11:46,041] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 44000, global step 710218: learning rate 0.0000
[2019-04-06 18:11:47,908] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.3129372e-09 4.8334556e-07 2.0066508e-08 9.7252607e-02 2.3780291e-09
 9.0274686e-01 2.0333353e-08], sum to 1.0000
[2019-04-06 18:11:47,908] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5958
[2019-04-06 18:11:47,990] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 54.0, 234.5, 159.0, 26.0, 25.75133802897956, 0.3941607581769964, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2635200.0000, 
sim time next is 2637000.0000, 
raw observation next is [-1.45, 50.5, 245.0, 147.0, 26.0, 25.71920442396386, 0.2802442392079482, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.422437673130194, 0.505, 0.8166666666666667, 0.16243093922651933, 0.6666666666666666, 0.6432670353303216, 0.5934147464026495, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7117058], dtype=float32), -0.87124693]. 
=============================================
[2019-04-06 18:11:47,996] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[84.355125]
 [84.46857 ]
 [84.200005]
 [84.46467 ]
 [84.549706]], R is [[84.06626892]
 [84.22560883]
 [84.17549133]
 [84.33374023]
 [84.49040222]].
[2019-04-06 18:11:48,066] A3C_AGENT_WORKER-Thread-5 INFO:Local step 45000, global step 710580: loss 1.1152
[2019-04-06 18:11:48,077] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 45000, global step 710580: learning rate 0.0000
[2019-04-06 18:11:49,895] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4257900e-10 6.3579790e-08 3.6905581e-10 2.0610683e-03 9.2342384e-11
 9.9793881e-01 9.5105568e-10], sum to 1.0000
[2019-04-06 18:11:49,896] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8523
[2019-04-06 18:11:50,069] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 96.0, 563.5, 26.0, 26.07642400611243, 0.5107616365783638, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3834000.0000, 
sim time next is 3835800.0000, 
raw observation next is [-3.0, 65.5, 101.0, 680.0, 26.0, 26.23515037954987, 0.5550730775399934, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.655, 0.33666666666666667, 0.7513812154696132, 0.6666666666666666, 0.686262531629156, 0.6850243591799977, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4008328], dtype=float32), -2.092807]. 
=============================================
[2019-04-06 18:11:52,506] A3C_AGENT_WORKER-Thread-15 INFO:Local step 44000, global step 711284: loss 0.0563
[2019-04-06 18:11:52,509] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 44000, global step 711284: learning rate 0.0000
[2019-04-06 18:11:53,210] A3C_AGENT_WORKER-Thread-13 INFO:Local step 45000, global step 711398: loss 1.3785
[2019-04-06 18:11:53,210] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 45000, global step 711398: learning rate 0.0000
[2019-04-06 18:11:53,525] A3C_AGENT_WORKER-Thread-10 INFO:Local step 44000, global step 711433: loss 0.0506
[2019-04-06 18:11:53,537] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 44000, global step 711433: learning rate 0.0000
[2019-04-06 18:11:54,341] A3C_AGENT_WORKER-Thread-4 INFO:Local step 44000, global step 711542: loss 0.0500
[2019-04-06 18:11:54,343] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 44000, global step 711542: learning rate 0.0000
[2019-04-06 18:11:55,066] A3C_AGENT_WORKER-Thread-20 INFO:Local step 44000, global step 711670: loss 0.0559
[2019-04-06 18:11:55,066] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 44000, global step 711670: learning rate 0.0000
[2019-04-06 18:11:55,493] A3C_AGENT_WORKER-Thread-14 INFO:Local step 44000, global step 711742: loss 0.0503
[2019-04-06 18:11:55,494] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 44000, global step 711742: learning rate 0.0000
[2019-04-06 18:11:58,466] A3C_AGENT_WORKER-Thread-2 INFO:Local step 44000, global step 712212: loss 0.0514
[2019-04-06 18:11:58,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 44000, global step 712212: learning rate 0.0000
[2019-04-06 18:12:01,296] A3C_AGENT_WORKER-Thread-6 INFO:Local step 44500, global step 712665: loss 3.1779
[2019-04-06 18:12:01,298] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 44500, global step 712666: learning rate 0.0000
[2019-04-06 18:12:05,515] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:12:05,516] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:12:05,521] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run17
[2019-04-06 18:12:09,344] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:12:09,344] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:12:09,348] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run17
[2019-04-06 18:12:11,075] A3C_AGENT_WORKER-Thread-12 INFO:Local step 44500, global step 714215: loss 3.1087
[2019-04-06 18:12:11,076] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 44500, global step 714215: learning rate 0.0000
[2019-04-06 18:12:11,701] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.5979769e-09 2.6578309e-07 4.1329558e-09 5.9646540e-03 1.2668185e-10
 9.9403507e-01 5.0134639e-09], sum to 1.0000
[2019-04-06 18:12:11,701] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5055
[2019-04-06 18:12:11,743] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 46.0, 0.0, 0.0, 26.0, 25.37728058647939, 0.3639200877715377, 0.0, 1.0, 51397.89805546686], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5032800.0000, 
sim time next is 5034600.0000, 
raw observation next is [-2.0, 55.5, 0.0, 0.0, 26.0, 25.28980104778433, 0.3499908693783726, 0.0, 1.0, 49199.76890654545], 
processed observation next is [1.0, 0.2608695652173913, 0.40720221606648205, 0.555, 0.0, 0.0, 0.6666666666666666, 0.6074834206486942, 0.6166636231261242, 0.0, 1.0, 0.2342846138406926], 
reward next is 0.7657, 
noisyNet noise sample is [array([2.2088351], dtype=float32), -0.91289335]. 
=============================================
[2019-04-06 18:12:15,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:12:15,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:12:15,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run17
[2019-04-06 18:12:17,228] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3283070e-09 1.7061917e-07 1.4942657e-08 6.5536983e-03 4.9966453e-09
 9.9344593e-01 8.0510056e-08], sum to 1.0000
[2019-04-06 18:12:17,241] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6179
[2019-04-06 18:12:17,505] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 46.0, 109.0, 806.0, 26.0, 25.10572168245595, 0.3593671628727835, 0.0, 1.0, 18714.63351701071], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3072600.0000, 
sim time next is 3074400.0000, 
raw observation next is [-1.0, 42.0, 104.0, 790.5, 26.0, 25.11652534231272, 0.3627545935073575, 0.0, 1.0, 18710.314808443774], 
processed observation next is [0.0, 0.6086956521739131, 0.4349030470914128, 0.42, 0.3466666666666667, 0.8734806629834254, 0.6666666666666666, 0.5930437785260599, 0.6209181978357858, 0.0, 1.0, 0.08909673718306559], 
reward next is 0.9109, 
noisyNet noise sample is [array([0.4714993], dtype=float32), 0.333432]. 
=============================================
[2019-04-06 18:12:18,006] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4466522e-10 5.6979939e-08 1.3560186e-10 6.2701589e-04 3.0761373e-11
 9.9937290e-01 3.3961220e-10], sum to 1.0000
[2019-04-06 18:12:18,006] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4668
[2019-04-06 18:12:18,091] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 60.0, 106.0, 776.0, 26.0, 26.61457986924295, 0.6560353822565802, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3767400.0000, 
sim time next is 3769200.0000, 
raw observation next is [0.0, 60.0, 96.5, 743.5, 26.0, 26.72308134555504, 0.6798919344514333, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.46260387811634357, 0.6, 0.32166666666666666, 0.8215469613259668, 0.6666666666666666, 0.7269234454629201, 0.7266306448171443, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05669798], dtype=float32), -0.8373945]. 
=============================================
[2019-04-06 18:12:18,463] A3C_AGENT_WORKER-Thread-18 INFO:Local step 44500, global step 715035: loss 13.3361
[2019-04-06 18:12:18,464] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 44500, global step 715035: learning rate 0.0000
[2019-04-06 18:12:21,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:12:21,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:12:21,431] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run17
[2019-04-06 18:12:28,102] A3C_AGENT_WORKER-Thread-16 INFO:Local step 45000, global step 715924: loss 1.2042
[2019-04-06 18:12:28,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 45000, global step 715924: learning rate 0.0000
[2019-04-06 18:12:31,498] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6990158e-10 1.5475803e-07 1.1855348e-09 2.0610707e-02 1.2124846e-10
 9.7938913e-01 4.9401971e-10], sum to 1.0000
[2019-04-06 18:12:31,498] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5236
[2019-04-06 18:12:31,616] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.65, 86.5, 0.0, 0.0, 26.0, 24.52241537196069, 0.1724485502042322, 0.0, 1.0, 42280.53580479259], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 606600.0000, 
sim time next is 608400.0000, 
raw observation next is [-3.9, 86.0, 0.0, 0.0, 26.0, 24.46248971573678, 0.1525586964270502, 0.0, 1.0, 42190.01000451984], 
processed observation next is [0.0, 0.043478260869565216, 0.3545706371191136, 0.86, 0.0, 0.0, 0.6666666666666666, 0.5385408096447316, 0.5508528988090168, 0.0, 1.0, 0.20090480954533257], 
reward next is 0.7991, 
noisyNet noise sample is [array([1.1011503], dtype=float32), 0.9333818]. 
=============================================
[2019-04-06 18:12:48,854] A3C_AGENT_WORKER-Thread-19 INFO:Local step 44500, global step 717755: loss 3.1818
[2019-04-06 18:12:48,854] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 44500, global step 717755: learning rate 0.0000
[2019-04-06 18:12:55,802] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5338676e-08 4.8173761e-06 8.4042764e-09 4.0559508e-03 8.8577430e-09
 9.9593914e-01 9.1492474e-08], sum to 1.0000
[2019-04-06 18:12:55,802] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0050
[2019-04-06 18:12:55,902] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0860041e-09 3.1884753e-09 3.2450802e-09 1.2336781e-03 3.7689959e-11
 9.9876630e-01 5.7575683e-10], sum to 1.0000
[2019-04-06 18:12:55,902] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1643
[2019-04-06 18:12:56,022] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 63.0, 0.0, 0.0, 26.0, 25.37034572430062, 0.479889004063579, 0.0, 1.0, 45160.55619928205], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3540600.0000, 
sim time next is 3542400.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.37519670135785, 0.4701609823222057, 0.0, 1.0, 40694.492653205925], 
processed observation next is [0.0, 0.0, 0.40720221606648205, 0.6, 0.0, 0.0, 0.6666666666666666, 0.6145997251131542, 0.6567203274407353, 0.0, 1.0, 0.19378329834859964], 
reward next is 0.8062, 
noisyNet noise sample is [array([0.6206639], dtype=float32), -0.16074991]. 
=============================================
[2019-04-06 18:12:56,096] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 26.0, 25.10883804658567, 0.3476593873961153, 0.0, 1.0, 20729.34949880302], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3609000.0000, 
sim time next is 3610800.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 26.0, 25.11703048605797, 0.3475619179684308, 0.0, 1.0, 32712.064098871342], 
processed observation next is [0.0, 0.8260869565217391, 0.4349030470914128, 0.42, 0.0, 0.0, 0.6666666666666666, 0.5930858738381642, 0.6158539726561436, 0.0, 1.0, 0.15577173380414924], 
reward next is 0.8442, 
noisyNet noise sample is [array([-0.33094794], dtype=float32), 0.2525634]. 
=============================================
[2019-04-06 18:12:57,377] A3C_AGENT_WORKER-Thread-15 INFO:Local step 44500, global step 718563: loss 3.1325
[2019-04-06 18:12:57,378] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 44500, global step 718563: learning rate 0.0000
[2019-04-06 18:13:00,623] A3C_AGENT_WORKER-Thread-4 INFO:Local step 44500, global step 718890: loss 3.0883
[2019-04-06 18:13:00,624] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 44500, global step 718890: learning rate 0.0000
[2019-04-06 18:13:01,792] A3C_AGENT_WORKER-Thread-10 INFO:Local step 44500, global step 719015: loss 3.0470
[2019-04-06 18:13:01,793] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 44500, global step 719015: learning rate 0.0000
[2019-04-06 18:13:01,932] A3C_AGENT_WORKER-Thread-6 INFO:Local step 45000, global step 719030: loss 0.9502
[2019-04-06 18:13:01,932] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 45000, global step 719030: learning rate 0.0000
[2019-04-06 18:13:03,847] A3C_AGENT_WORKER-Thread-14 INFO:Local step 44500, global step 719224: loss 3.0715
[2019-04-06 18:13:03,847] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 44500, global step 719224: learning rate 0.0000
[2019-04-06 18:13:04,345] A3C_AGENT_WORKER-Thread-20 INFO:Local step 44500, global step 719282: loss 3.1267
[2019-04-06 18:13:04,346] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 44500, global step 719282: learning rate 0.0000
[2019-04-06 18:13:11,148] A3C_AGENT_WORKER-Thread-2 INFO:Local step 44500, global step 719950: loss 3.0860
[2019-04-06 18:13:11,155] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 44500, global step 719950: learning rate 0.0000
[2019-04-06 18:13:11,747] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-06 18:13:11,765] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:13:11,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:13:11,767] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run37
[2019-04-06 18:13:11,853] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:13:11,853] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:13:11,856] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run37
[2019-04-06 18:13:11,997] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:13:11,997] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:13:11,999] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run37
[2019-04-06 18:15:04,775] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.04390226], dtype=float32), 0.12281305]
[2019-04-06 18:15:04,775] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [3.8, 59.0, 0.0, 0.0, 26.0, 25.20493487019925, 0.435241287119716, 0.0, 1.0, 67704.05234720565]
[2019-04-06 18:15:04,775] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 18:15:04,776] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.1726918e-09 2.7008116e-07 4.1265689e-09 2.1366721e-03 4.0618772e-10
 9.9786311e-01 3.1770606e-09], sampled 0.5539189745697609
[2019-04-06 18:15:41,815] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 18:16:00,157] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.0955 87782064.9934 515.3076
[2019-04-06 18:16:04,373] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 18:16:05,395] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 720000, evaluation results [720000.0, 2416.0954852919413, 87782064.99340266, 515.3076454950652, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 18:16:06,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:16:06,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:16:06,940] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run17
[2019-04-06 18:16:09,607] A3C_AGENT_WORKER-Thread-12 INFO:Local step 45000, global step 720670: loss 1.2802
[2019-04-06 18:16:09,610] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 45000, global step 720670: learning rate 0.0000
[2019-04-06 18:16:11,932] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0725888e-12 7.1179163e-10 1.2584656e-11 9.3125767e-05 3.1941076e-13
 9.9990690e-01 1.1452386e-11], sum to 1.0000
[2019-04-06 18:16:11,933] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8930
[2019-04-06 18:16:11,984] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 75.0, 114.0, 0.0, 26.0, 27.17288658777657, 0.8638857986559252, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1074600.0000, 
sim time next is 1076400.0000, 
raw observation next is [15.5, 70.0, 184.0, 107.5, 26.0, 27.26126824233825, 0.9081180699825321, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.8919667590027703, 0.7, 0.6133333333333333, 0.11878453038674033, 0.6666666666666666, 0.7717723535281875, 0.8027060233275107, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.06342333], dtype=float32), 1.682604]. 
=============================================
[2019-04-06 18:16:16,598] A3C_AGENT_WORKER-Thread-18 INFO:Local step 45000, global step 721681: loss 1.1426
[2019-04-06 18:16:16,599] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 45000, global step 721681: learning rate 0.0000
[2019-04-06 18:16:27,072] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:16:27,072] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:16:27,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run17
[2019-04-06 18:16:34,178] A3C_AGENT_WORKER-Thread-19 INFO:Local step 45000, global step 724337: loss 1.2833
[2019-04-06 18:16:34,180] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 45000, global step 724338: learning rate 0.0000
[2019-04-06 18:16:39,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:16:39,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:16:39,213] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run17
[2019-04-06 18:16:40,104] A3C_AGENT_WORKER-Thread-15 INFO:Local step 45000, global step 725335: loss 1.2952
[2019-04-06 18:16:40,108] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 45000, global step 725337: learning rate 0.0000
[2019-04-06 18:16:42,377] A3C_AGENT_WORKER-Thread-4 INFO:Local step 45000, global step 725654: loss 1.2132
[2019-04-06 18:16:42,378] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 45000, global step 725654: learning rate 0.0000
[2019-04-06 18:16:43,226] A3C_AGENT_WORKER-Thread-10 INFO:Local step 45000, global step 725773: loss 1.1170
[2019-04-06 18:16:43,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 45000, global step 725773: learning rate 0.0000
[2019-04-06 18:16:44,558] A3C_AGENT_WORKER-Thread-14 INFO:Local step 45000, global step 725937: loss 1.1873
[2019-04-06 18:16:44,558] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 45000, global step 725937: learning rate 0.0000
[2019-04-06 18:16:44,936] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:16:44,936] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:16:44,940] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run17
[2019-04-06 18:16:45,863] A3C_AGENT_WORKER-Thread-20 INFO:Local step 45000, global step 726093: loss 1.0646
[2019-04-06 18:16:45,863] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 45000, global step 726093: learning rate 0.0000
[2019-04-06 18:16:48,331] A3C_AGENT_WORKER-Thread-2 INFO:Local step 45000, global step 726428: loss 1.1449
[2019-04-06 18:16:48,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 45000, global step 726428: learning rate 0.0000
[2019-04-06 18:16:54,767] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6740062e-08 1.7579620e-07 1.8449191e-08 5.2106299e-04 5.6345142e-09
 9.9947876e-01 4.3869339e-09], sum to 1.0000
[2019-04-06 18:16:54,767] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8464
[2019-04-06 18:16:54,811] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 37.0, 97.0, 727.0, 26.0, 25.1831658549809, 0.4428945246894456, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4807800.0000, 
sim time next is 4809600.0000, 
raw observation next is [3.0, 37.0, 89.5, 638.0, 26.0, 25.19233546709675, 0.4360780404680334, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.37, 0.29833333333333334, 0.7049723756906078, 0.6666666666666666, 0.5993612889247292, 0.6453593468226778, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09103521], dtype=float32), 2.3832936]. 
=============================================
[2019-04-06 18:17:02,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:17:02,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:17:02,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run17
[2019-04-06 18:17:08,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:17:08,862] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:17:08,866] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run17
[2019-04-06 18:17:09,923] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:17:09,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:17:09,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run17
[2019-04-06 18:17:10,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:17:10,822] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:17:10,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run17
[2019-04-06 18:17:12,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:17:12,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:17:12,572] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run17
[2019-04-06 18:17:13,319] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:17:13,320] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:17:13,323] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run17
[2019-04-06 18:17:15,790] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:17:15,792] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:17:15,797] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run17
[2019-04-06 18:17:24,730] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5472998e-06 1.4376595e-04 1.6444874e-05 2.5107088e-02 3.6074746e-06
 9.7472125e-01 6.3258044e-06], sum to 1.0000
[2019-04-06 18:17:24,733] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5146
[2019-04-06 18:17:24,788] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.2, 96.0, 0.0, 0.0, 22.0, 20.23131465404035, -0.8056877793662075, 0.0, 1.0, 44514.44468117316], 
current ob forecast is [], 
actual action is [23.0], 
sim time this is 7200.0000, 
sim time next is 9000.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 23.0, 20.4076349632306, -0.7701711223677185, 0.0, 1.0, 43514.734207034744], 
processed observation next is [0.0, 0.08695652173913043, 0.662049861495845, 0.96, 0.0, 0.0, 0.4166666666666667, 0.20063624693588325, 0.24327629254409386, 0.0, 1.0, 0.20721302003349878], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.40818995], dtype=float32), -1.713332]. 
=============================================
[2019-04-06 18:17:24,792] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[50.19708 ]
 [40.380028]
 [31.659101]
 [21.679728]
 [13.076144]], R is [[59.8697319 ]
 [60.27103424]
 [60.66832352]
 [61.06164169]
 [61.45102692]].
[2019-04-06 18:17:41,354] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7795863e-09 5.7926292e-07 1.8975864e-08 6.9086216e-03 1.7913830e-09
 9.9309075e-01 6.1531278e-09], sum to 1.0000
[2019-04-06 18:17:41,354] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2701
[2019-04-06 18:17:41,416] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.55879681494132, 0.2055965407761513, 0.0, 1.0, 42951.25256999396], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1985400.0000, 
sim time next is 1987200.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.45577426068806, 0.1849205436057038, 0.0, 1.0, 42748.40365942241], 
processed observation next is [1.0, 0.0, 0.30747922437673136, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5379811883906717, 0.5616401812019013, 0.0, 1.0, 0.20356382694963052], 
reward next is 0.7964, 
noisyNet noise sample is [array([-0.65804964], dtype=float32), -1.1604757]. 
=============================================
[2019-04-06 18:18:06,711] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5779156e-11 6.5863333e-07 1.2732032e-10 1.5928855e-02 3.8396147e-10
 9.8407042e-01 1.1094963e-09], sum to 1.0000
[2019-04-06 18:18:06,711] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0138
[2019-04-06 18:18:07,101] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [1.1, 86.0, 107.0, 0.0, 26.0, 25.72851100418893, 0.4836106358593664, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1686600.0000, 
sim time next is 1688400.0000, 
raw observation next is [1.1, 88.0, 103.5, 0.0, 26.0, 24.1912879944318, 0.4096249201869147, 1.0, 1.0, 162581.54266453037], 
processed observation next is [1.0, 0.5652173913043478, 0.49307479224376743, 0.88, 0.345, 0.0, 0.6666666666666666, 0.51594066620265, 0.6365416400623048, 1.0, 1.0, 0.7741978222120494], 
reward next is 0.2258, 
noisyNet noise sample is [array([1.1899709], dtype=float32), -0.61476]. 
=============================================
[2019-04-06 18:18:59,669] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 18:18:59,669] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:18:59,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:18:59,671] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run38
[2019-04-06 18:18:59,885] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:18:59,886] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:18:59,888] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run38
[2019-04-06 18:18:59,964] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:18:59,981] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:18:59,984] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run38
[2019-04-06 18:21:02,315] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.04567863], dtype=float32), 0.12248638]
[2019-04-06 18:21:02,316] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-0.1, 69.0, 0.0, 0.0, 26.0, 24.85447690392466, 0.2934221676324582, 0.0, 1.0, 41346.07224765652]
[2019-04-06 18:21:02,316] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 18:21:02,317] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.2380201e-09 2.4887120e-07 4.1857886e-09 1.4883650e-03 4.0801906e-10
 9.9851137e-01 2.7806353e-09], sampled 0.9530489013281956
[2019-04-06 18:21:37,837] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2462 79987260.4995 535.2506
[2019-04-06 18:21:41,199] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.04567863], dtype=float32), 0.12248638]
[2019-04-06 18:21:41,199] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-2.0, 46.0, 0.0, 0.0, 26.0, 25.32729888427691, 0.4001648916184905, 0.0, 1.0, 39313.13413986104]
[2019-04-06 18:21:41,199] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 18:21:41,200] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [6.3529755e-09 8.9537338e-07 1.8520199e-08 3.3642757e-03 2.2514481e-09
 9.9663478e-01 1.4563062e-08], sampled 0.2650622457137899
[2019-04-06 18:21:55,532] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 18:21:56,812] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 18:21:57,834] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 740000, evaluation results [740000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.2461995019034, 79987260.49946941, 535.2506232687274, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 18:22:05,698] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1042731e-09 7.2186634e-07 5.4833325e-09 4.0173721e-03 2.3779052e-09
 9.9598193e-01 2.0937614e-08], sum to 1.0000
[2019-04-06 18:22:05,698] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7738
[2019-04-06 18:22:05,845] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 59.5, 111.0, 758.0, 26.0, 25.57117083339504, 0.4816104547708062, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3580200.0000, 
sim time next is 3582000.0000, 
raw observation next is [-4.0, 54.0, 112.5, 787.0, 26.0, 25.36320656070966, 0.4529625221767962, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.3518005540166205, 0.54, 0.375, 0.8696132596685083, 0.6666666666666666, 0.613600546725805, 0.6509875073922654, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.482437], dtype=float32), -0.3420325]. 
=============================================
[2019-04-06 18:22:05,857] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[78.539246]
 [78.88675 ]
 [79.265305]
 [78.88641 ]
 [78.42006 ]], R is [[78.13235474]
 [78.35102844]
 [78.56752014]
 [78.78184509]
 [78.99402618]].
[2019-04-06 18:22:06,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1921036e-09 1.2494168e-06 9.4304212e-08 1.3999529e-01 7.8133198e-09
 8.6000329e-01 6.1060781e-08], sum to 1.0000
[2019-04-06 18:22:06,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9482
[2019-04-06 18:22:06,374] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 52.5, 118.0, 823.0, 26.0, 25.18007679361539, 0.4491950383833944, 0.0, 1.0, 18711.222352142693], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3587400.0000, 
sim time next is 3589200.0000, 
raw observation next is [-2.0, 50.0, 116.0, 817.5, 26.0, 25.19940909382778, 0.4517316862008456, 0.0, 1.0, 6234.5653446688], 
processed observation next is [0.0, 0.5652173913043478, 0.40720221606648205, 0.5, 0.38666666666666666, 0.9033149171270718, 0.6666666666666666, 0.5999507578189816, 0.6505772287336152, 0.0, 1.0, 0.029688406403184764], 
reward next is 0.9703, 
noisyNet noise sample is [array([0.09157691], dtype=float32), 0.5812091]. 
=============================================
[2019-04-06 18:22:08,589] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.2869368e-10 3.3895392e-07 6.6815153e-09 5.1968107e-03 1.0415434e-10
 9.9480283e-01 1.9390394e-09], sum to 1.0000
[2019-04-06 18:22:08,589] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2481
[2019-04-06 18:22:08,641] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.6, 71.0, 0.0, 0.0, 26.0, 25.76227949362186, 0.6512561721511692, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1123200.0000, 
sim time next is 1125000.0000, 
raw observation next is [11.05, 74.0, 0.0, 0.0, 26.0, 25.67121114306066, 0.6402287578091618, 0.0, 1.0, 37577.57897165854], 
processed observation next is [0.0, 0.0, 0.7686980609418284, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6392675952550549, 0.7134095859363873, 0.0, 1.0, 0.17894085224599307], 
reward next is 0.8211, 
noisyNet noise sample is [array([0.46779072], dtype=float32), -0.11034897]. 
=============================================
[2019-04-06 18:22:08,655] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[92.96973]
 [95.11283]
 [95.22675]
 [94.86759]
 [92.93844]], R is [[92.82830048]
 [92.90001678]
 [92.94129181]
 [92.62899017]
 [92.70269775]].
[2019-04-06 18:22:18,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0904601e-07 2.6328630e-06 1.2707160e-07 2.5114262e-02 1.1042104e-08
 9.7488266e-01 1.7513803e-07], sum to 1.0000
[2019-04-06 18:22:18,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9401
[2019-04-06 18:22:19,213] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.0, 100.0, 76.0, 0.0, 26.0, 23.3039607920819, 0.1228887694719906, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1245600.0000, 
sim time next is 1247400.0000, 
raw observation next is [14.7, 100.0, 78.0, 0.0, 26.0, 23.57924764293016, 0.3218285514259849, 0.0, 1.0, 89141.26443715616], 
processed observation next is [0.0, 0.43478260869565216, 0.8698060941828256, 1.0, 0.26, 0.0, 0.6666666666666666, 0.4649373035775133, 0.6072761838086617, 0.0, 1.0, 0.42448221160550553], 
reward next is 0.5755, 
noisyNet noise sample is [array([1.0773207], dtype=float32), -0.55693793]. 
=============================================
[2019-04-06 18:22:21,805] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6405977e-08 9.8793100e-07 9.6129513e-09 3.8662492e-03 7.9449775e-10
 9.9613273e-01 2.5513030e-08], sum to 1.0000
[2019-04-06 18:22:21,805] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7091
[2019-04-06 18:22:21,889] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.75, 65.0, 0.0, 0.0, 26.0, 25.22241613077153, 0.3371485436748449, 0.0, 1.0, 39509.999951484024], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3015000.0000, 
sim time next is 3016800.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 26.0, 25.14611155455324, 0.3206918422549619, 0.0, 1.0, 39037.15710630052], 
processed observation next is [0.0, 0.9565217391304348, 0.3518005540166205, 0.65, 0.0, 0.0, 0.6666666666666666, 0.59550929621277, 0.606897280751654, 0.0, 1.0, 0.18589122431571675], 
reward next is 0.8141, 
noisyNet noise sample is [array([-0.28250623], dtype=float32), -0.2896758]. 
=============================================
[2019-04-06 18:22:25,786] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.6195304e-11 1.9097867e-07 8.3825663e-10 2.0276657e-03 6.3594803e-11
 9.9797219e-01 3.0890426e-10], sum to 1.0000
[2019-04-06 18:22:25,786] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5067
[2019-04-06 18:22:26,045] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 100.0, 0.0, 0.0, 26.0, 25.42849150273392, 0.416116755263491, 0.0, 1.0, 21884.600121379906], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1494000.0000, 
sim time next is 1495800.0000, 
raw observation next is [1.1, 100.0, 0.0, 0.0, 26.0, 25.49721345123357, 0.466972594605792, 0.0, 1.0, 27424.501435482798], 
processed observation next is [1.0, 0.30434782608695654, 0.49307479224376743, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6247677876027975, 0.655657531535264, 0.0, 1.0, 0.13059286397848952], 
reward next is 0.8694, 
noisyNet noise sample is [array([-0.4235884], dtype=float32), 1.0656548]. 
=============================================
[2019-04-06 18:22:30,712] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.6069038e-09 3.3797667e-06 2.8389167e-08 1.7439901e-03 5.5351124e-10
 9.9825257e-01 7.6881328e-09], sum to 1.0000
[2019-04-06 18:22:30,713] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7783
[2019-04-06 18:22:30,797] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.25, 65.0, 0.0, 0.0, 26.0, 25.35505022859006, 0.3686186618435411, 0.0, 1.0, 40672.517292335746], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3011400.0000, 
sim time next is 3013200.0000, 
raw observation next is [-3.5, 65.0, 0.0, 0.0, 26.0, 25.30598284197608, 0.356281898500943, 0.0, 1.0, 40259.151123772994], 
processed observation next is [0.0, 0.9130434782608695, 0.36565096952908593, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6088319034980065, 0.6187606328336477, 0.0, 1.0, 0.19171024344653806], 
reward next is 0.8083, 
noisyNet noise sample is [array([-0.62119013], dtype=float32), -0.71830976]. 
=============================================
[2019-04-06 18:22:55,670] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3284525e-09 5.9921166e-07 3.0068296e-08 2.6295736e-04 4.8101129e-10
 9.9973601e-01 3.7625483e-07], sum to 1.0000
[2019-04-06 18:22:55,670] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0295
[2019-04-06 18:22:55,715] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 59.0, 39.5, 343.5, 26.0, 25.44486223756817, 0.4365503331484107, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3690000.0000, 
sim time next is 3691800.0000, 
raw observation next is [4.0, 59.0, 15.0, 165.0, 26.0, 25.30659093338998, 0.3902015901878302, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5734072022160666, 0.59, 0.05, 0.18232044198895028, 0.6666666666666666, 0.6088825777824983, 0.6300671967292767, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16024828], dtype=float32), -0.6007773]. 
=============================================
[2019-04-06 18:23:06,159] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1901544e-08 2.4205408e-06 3.9531862e-08 8.6920448e-03 2.1971960e-09
 9.9130517e-01 2.8504883e-07], sum to 1.0000
[2019-04-06 18:23:06,160] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1190
[2019-04-06 18:23:06,278] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 29.5, 90.0, 845.0, 26.0, 24.92205102465552, 0.2570342367615934, 0.0, 1.0, 25600.657565867183], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2464200.0000, 
sim time next is 2466000.0000, 
raw observation next is [1.6, 28.0, 88.5, 838.5, 26.0, 24.94172266057019, 0.2738209550159147, 0.0, 1.0, 14954.415960294153], 
processed observation next is [0.0, 0.5652173913043478, 0.5069252077562327, 0.28, 0.295, 0.9265193370165746, 0.6666666666666666, 0.5784768883808491, 0.5912736516719715, 0.0, 1.0, 0.07121150457282929], 
reward next is 0.9288, 
noisyNet noise sample is [array([-1.4648036], dtype=float32), 0.16579251]. 
=============================================
[2019-04-06 18:23:06,322] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.65008 ]
 [71.519615]
 [71.39087 ]
 [70.91529 ]
 [70.649605]], R is [[71.96677399]
 [72.12519836]
 [72.37421417]
 [72.58231354]
 [72.69736481]].
[2019-04-06 18:23:11,605] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0443879e-09 3.0398635e-07 7.1439588e-10 1.9663689e-03 1.8651962e-09
 9.9803334e-01 9.0608525e-09], sum to 1.0000
[2019-04-06 18:23:11,620] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3985
[2019-04-06 18:23:11,708] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 26.0, 24.50036945683974, 0.1581027190817121, 0.0, 1.0, 42528.856943169434], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2169000.0000, 
sim time next is 2170800.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 26.0, 24.49887715067311, 0.1600646141113659, 0.0, 1.0, 42433.229017361264], 
processed observation next is [1.0, 0.13043478260869565, 0.2770083102493075, 0.78, 0.0, 0.0, 0.6666666666666666, 0.5415730958894258, 0.5533548713704554, 0.0, 1.0, 0.20206299532076794], 
reward next is 0.7979, 
noisyNet noise sample is [array([0.226223], dtype=float32), -0.7223758]. 
=============================================
[2019-04-06 18:23:20,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:23:20,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:23:20,142] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run18
[2019-04-06 18:23:23,709] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.8045169e-10 5.2687401e-08 1.1847692e-09 1.6153613e-03 1.5870709e-11
 9.9838459e-01 1.4845143e-10], sum to 1.0000
[2019-04-06 18:23:23,709] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2896
[2019-04-06 18:23:23,724] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 100.0, 0.0, 0.0, 26.0, 26.76494238257215, 0.8204252162971954, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3177000.0000, 
sim time next is 3178800.0000, 
raw observation next is [4.0, 100.0, 0.0, 0.0, 26.0, 26.44678802630428, 0.7892345006527849, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.5734072022160666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.7038990021920233, 0.7630781668842617, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4202057], dtype=float32), -2.0372496]. 
=============================================
[2019-04-06 18:23:29,985] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9938382e-09 3.0209274e-06 1.0140231e-07 1.6607735e-03 3.2291758e-09
 9.9833614e-01 2.8162056e-08], sum to 1.0000
[2019-04-06 18:23:29,986] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4853
[2019-04-06 18:23:30,156] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 54.5, 111.0, 805.0, 26.0, 25.15223174268277, 0.337292357226428, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3065400.0000, 
sim time next is 3067200.0000, 
raw observation next is [-3.0, 55.0, 112.5, 811.0, 26.0, 25.03642946898411, 0.3378709179309343, 0.0, 1.0, 34828.48683530028], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.55, 0.375, 0.8961325966850828, 0.6666666666666666, 0.5863691224153426, 0.6126236393103114, 0.0, 1.0, 0.16584993731095374], 
reward next is 0.8342, 
noisyNet noise sample is [array([-0.01510953], dtype=float32), 0.8096105]. 
=============================================
[2019-04-06 18:23:32,891] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6965475e-08 2.4978501e-06 4.9282608e-08 5.3654471e-04 1.3554974e-09
 9.9946088e-01 3.6127572e-09], sum to 1.0000
[2019-04-06 18:23:32,891] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6868
[2019-04-06 18:23:32,942] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 35.0, 0.0, 0.0, 26.0, 25.15077048479227, 0.2420143798937117, 0.0, 1.0, 40165.32911349121], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2502000.0000, 
sim time next is 2503800.0000, 
raw observation next is [-1.15, 36.5, 0.0, 0.0, 26.0, 25.11771198914576, 0.2314353388069475, 0.0, 1.0, 39831.626141613146], 
processed observation next is [0.0, 1.0, 0.4307479224376732, 0.365, 0.0, 0.0, 0.6666666666666666, 0.5931426657621467, 0.5771451129356492, 0.0, 1.0, 0.18967441019815784], 
reward next is 0.8103, 
noisyNet noise sample is [array([0.3092352], dtype=float32), 0.86446637]. 
=============================================
[2019-04-06 18:23:35,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.7885858e-10 2.3243049e-07 1.2245271e-09 2.5249124e-03 6.8053357e-10
 9.9747485e-01 5.5539431e-09], sum to 1.0000
[2019-04-06 18:23:35,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7620
[2019-04-06 18:23:35,538] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 93.0, 0.0, 0.0, 26.0, 25.42091567068051, 0.6313337636222295, 0.0, 1.0, 115967.84602291319], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3193200.0000, 
sim time next is 3195000.0000, 
raw observation next is [2.0, 93.0, 0.0, 0.0, 26.0, 25.59432046310412, 0.6257093286045742, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.518005540166205, 0.93, 0.0, 0.0, 0.6666666666666666, 0.6328600385920099, 0.7085697762015247, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1608775], dtype=float32), 0.86298674]. 
=============================================
[2019-04-06 18:23:35,551] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[94.06484 ]
 [94.17202 ]
 [94.521736]
 [95.576324]
 [95.587654]], R is [[93.71539307]
 [93.22600555]
 [93.03178406]
 [93.10146332]
 [93.1704483 ]].
[2019-04-06 18:23:48,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1832061e-10 5.0986941e-06 6.3747261e-09 8.9900587e-03 2.7788412e-09
 9.9100482e-01 8.6192147e-09], sum to 1.0000
[2019-04-06 18:23:48,563] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8279
[2019-04-06 18:23:48,754] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 26.0, 25.02234619193356, 0.3636279260487965, 0.0, 1.0, 41574.14079367], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3369600.0000, 
sim time next is 3371400.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.96371026169886, 0.3429652785585509, 0.0, 1.0, 41454.915175006376], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5803091884749051, 0.614321759519517, 0.0, 1.0, 0.19740435797622083], 
reward next is 0.8026, 
noisyNet noise sample is [array([-0.53908855], dtype=float32), 1.3323824]. 
=============================================
[2019-04-06 18:24:11,614] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.37778597e-08 4.73558475e-06 1.17762395e-08 1.20515525e-02
 1.90820479e-08 9.87943649e-01 3.48403368e-08], sum to 1.0000
[2019-04-06 18:24:11,614] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5693
[2019-04-06 18:24:12,062] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-14.5, 66.0, 55.0, 733.5, 26.0, 25.67645539870376, 0.3260090935012018, 1.0, 1.0, 54803.709824213096], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 381600.0000, 
sim time next is 383400.0000, 
raw observation next is [-13.95, 63.0, 71.0, 729.0, 26.0, 25.92727534350503, 0.3623003975700971, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.07617728531855956, 0.63, 0.23666666666666666, 0.8055248618784531, 0.6666666666666666, 0.6606062786254192, 0.6207667991900324, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.72132754], dtype=float32), 0.5328946]. 
=============================================
[2019-04-06 18:24:12,065] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.98372749e-08 3.16426394e-06 1.10438645e-08 1.15610445e-02
 1.69416552e-08 9.88435745e-01 3.47922686e-08], sum to 1.0000
[2019-04-06 18:24:12,066] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7351
[2019-04-06 18:24:12,317] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.95, 63.0, 71.0, 729.0, 26.0, 25.92727534350503, 0.3623003975700971, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 383400.0000, 
sim time next is 385200.0000, 
raw observation next is [-13.4, 60.0, 64.5, 746.5, 26.0, 25.87398962055461, 0.3450403505080835, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.09141274238227146, 0.6, 0.215, 0.8248618784530387, 0.6666666666666666, 0.6561658017128842, 0.6150134501693612, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.72132754], dtype=float32), 0.5328946]. 
=============================================
[2019-04-06 18:24:13,643] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1481855e-09 6.8183967e-06 7.0624701e-08 1.7461315e-02 1.0715147e-09
 9.8253167e-01 8.8146869e-08], sum to 1.0000
[2019-04-06 18:24:13,644] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6336
[2019-04-06 18:24:13,767] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.55, 19.5, 0.0, 0.0, 26.0, 26.53887574132229, 0.670699141549532, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5092200.0000, 
sim time next is 5094000.0000, 
raw observation next is [8.4, 20.0, 0.0, 0.0, 26.0, 26.18457948647496, 0.609455708325167, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.6952908587257619, 0.2, 0.0, 0.0, 0.6666666666666666, 0.6820482905395799, 0.7031519027750557, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2168375], dtype=float32), 1.0683657]. 
=============================================
[2019-04-06 18:24:13,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[83.67721]
 [84.17454]
 [84.77426]
 [85.56248]
 [85.99978]], R is [[83.49740601]
 [83.66242981]
 [83.82580566]
 [83.98754883]
 [84.14767456]].
[2019-04-06 18:24:15,275] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:24:15,275] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:24:15,279] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run18
[2019-04-06 18:24:22,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:24:22,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:24:22,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run18
[2019-04-06 18:24:27,067] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-06 18:24:27,073] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:24:27,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:24:27,075] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run39
[2019-04-06 18:24:27,166] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:24:27,166] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:24:27,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run39
[2019-04-06 18:24:27,245] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:24:27,247] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:24:27,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run39
[2019-04-06 18:27:02,524] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 18:27:21,784] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 18:27:23,166] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.4693 91908493.8094 409.3428
[2019-04-06 18:27:24,187] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 760000, evaluation results [760000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.469273570502, 91908493.80942969, 409.3427707209749]
[2019-04-06 18:27:25,285] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.3829531e-10 1.7375168e-06 5.6328751e-09 2.4915617e-03 2.8215696e-10
 9.9750668e-01 4.2867945e-09], sum to 1.0000
[2019-04-06 18:27:25,285] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1514
[2019-04-06 18:27:25,332] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 43.0, 0.0, 0.0, 26.0, 25.35947412589913, 0.4620073779433652, 0.0, 1.0, 110633.16658054799], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4143600.0000, 
sim time next is 4145400.0000, 
raw observation next is [-0.5, 42.5, 0.0, 0.0, 26.0, 25.48801611301933, 0.4576954072606491, 0.0, 1.0, 21098.4690417048], 
processed observation next is [1.0, 1.0, 0.44875346260387816, 0.425, 0.0, 0.0, 0.6666666666666666, 0.6240013427516109, 0.6525651357535497, 0.0, 1.0, 0.1004689001985943], 
reward next is 0.8995, 
noisyNet noise sample is [array([0.24390116], dtype=float32), 1.7885197]. 
=============================================
[2019-04-06 18:27:29,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:27:29,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:27:29,564] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run18
[2019-04-06 18:27:33,198] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:27:33,198] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:27:33,213] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run18
[2019-04-06 18:27:35,785] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.3002372e-11 6.8660020e-09 7.1251394e-11 2.6656248e-04 6.0647688e-11
 9.9973339e-01 4.6515303e-10], sum to 1.0000
[2019-04-06 18:27:35,785] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6290
[2019-04-06 18:27:35,823] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 92.0, 161.5, 3.0, 26.0, 26.44149706746047, 0.5779712367486481, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4701600.0000, 
sim time next is 4703400.0000, 
raw observation next is [0.0, 92.0, 208.0, 6.0, 26.0, 26.4486160097959, 0.5934711959171755, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.46260387811634357, 0.92, 0.6933333333333334, 0.0066298342541436465, 0.6666666666666666, 0.7040513341496583, 0.6978237319723918, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5104942], dtype=float32), 0.68612105]. 
=============================================
[2019-04-06 18:27:39,005] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5171812e-10 3.3818977e-09 5.7599353e-10 1.5203963e-03 1.1825779e-11
 9.9847966e-01 3.5826656e-10], sum to 1.0000
[2019-04-06 18:27:39,005] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6056
[2019-04-06 18:27:39,109] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 59.0, 115.0, 810.0, 26.0, 26.31439648263774, 0.6162061040810046, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3497400.0000, 
sim time next is 3499200.0000, 
raw observation next is [2.0, 57.0, 115.5, 816.5, 26.0, 25.85600957788399, 0.5632071504277971, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.518005540166205, 0.57, 0.385, 0.9022099447513812, 0.6666666666666666, 0.654667464823666, 0.6877357168092657, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1179636], dtype=float32), 1.4923439]. 
=============================================
[2019-04-06 18:27:46,555] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0193490e-09 4.9830527e-07 5.2279447e-09 1.2282528e-02 9.7572506e-10
 9.8771697e-01 4.3473424e-08], sum to 1.0000
[2019-04-06 18:27:46,555] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9609
[2019-04-06 18:27:46,618] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.5, 74.0, 0.0, 0.0, 26.0, 25.10521224618351, 0.3854976130159011, 0.0, 1.0, 42259.492394201945], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3367800.0000, 
sim time next is 3369600.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 26.0, 25.02234619193356, 0.3636279260487965, 0.0, 1.0, 41574.14079367], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5851955159944634, 0.6212093086829321, 0.0, 1.0, 0.19797209901747617], 
reward next is 0.8020, 
noisyNet noise sample is [array([0.5779924], dtype=float32), -1.4939637]. 
=============================================
[2019-04-06 18:27:57,523] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:27:57,523] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:27:57,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run18
[2019-04-06 18:28:07,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5693651e-07 7.3795941e-06 3.4063817e-07 1.2948981e-02 1.8111353e-07
 9.8704278e-01 1.4375328e-07], sum to 1.0000
[2019-04-06 18:28:07,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1911
[2019-04-06 18:28:07,233] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [16.6, 75.0, 0.0, 0.0, 26.0, 24.47428849181779, 0.3473751396143964, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1202400.0000, 
sim time next is 1204200.0000, 
raw observation next is [16.6, 75.0, 0.0, 0.0, 26.0, 24.38783406561935, 0.3296011041979662, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.922437673130194, 0.75, 0.0, 0.0, 0.6666666666666666, 0.5323195054682793, 0.6098670347326554, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3859456], dtype=float32), -0.28966674]. 
=============================================
[2019-04-06 18:28:07,279] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.8086856e-08 1.0784932e-05 3.7562452e-07 1.8856699e-02 5.5505637e-08
 9.8113167e-01 3.3444442e-07], sum to 1.0000
[2019-04-06 18:28:07,279] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4805
[2019-04-06 18:28:07,633] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-16.2, 78.0, 0.0, 0.0, 26.0, 21.63918710968239, -0.5058561330646211, 0.0, 1.0, 49269.018545989726], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 370800.0000, 
sim time next is 372600.0000, 
raw observation next is [-16.45, 79.5, 0.0, 0.0, 26.0, 21.92792010392076, -0.3418148870755788, 1.0, 1.0, 151694.24947506626], 
processed observation next is [1.0, 0.30434782608695654, 0.006925207756232688, 0.795, 0.0, 0.0, 0.6666666666666666, 0.3273266753267299, 0.3860617043081404, 1.0, 1.0, 0.7223535689288869], 
reward next is 0.2776, 
noisyNet noise sample is [array([1.6242522], dtype=float32), 0.04662001]. 
=============================================
[2019-04-06 18:28:08,081] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6811632e-09 8.6064396e-08 8.2732510e-10 3.4197752e-04 1.2112654e-10
 9.9965799e-01 3.9763868e-09], sum to 1.0000
[2019-04-06 18:28:08,081] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1690
[2019-04-06 18:28:08,108] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.65, 82.0, 120.0, 232.0, 26.0, 25.6233258237321, 0.5609111228613544, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4437000.0000, 
sim time next is 4438800.0000, 
raw observation next is [1.3, 84.0, 142.5, 131.5, 26.0, 26.17496112394989, 0.5985749268683356, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49861495844875353, 0.84, 0.475, 0.1453038674033149, 0.6666666666666666, 0.6812467603291573, 0.6995249756227785, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4332315], dtype=float32), -0.20712903]. 
=============================================
[2019-04-06 18:28:09,268] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5265373e-09 4.7093345e-06 3.5875104e-08 7.6064346e-03 7.0255241e-10
 9.9238878e-01 7.6709394e-09], sum to 1.0000
[2019-04-06 18:28:09,268] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1086
[2019-04-06 18:28:09,426] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.5, 44.5, 122.0, 839.0, 26.0, 25.07506216708574, 0.4086450877313589, 0.0, 1.0, 6235.968478446243], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4793400.0000, 
sim time next is 4795200.0000, 
raw observation next is [1.0, 43.0, 146.0, 813.0, 26.0, 25.02691614993937, 0.4196863428034339, 0.0, 1.0, 19885.64568517848], 
processed observation next is [0.0, 0.5217391304347826, 0.4903047091412743, 0.43, 0.4866666666666667, 0.8983425414364641, 0.6666666666666666, 0.5855763458282809, 0.6398954476011446, 0.0, 1.0, 0.09469355088180229], 
reward next is 0.9053, 
noisyNet noise sample is [array([-0.7234859], dtype=float32), 0.5179702]. 
=============================================
[2019-04-06 18:28:11,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:28:11,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:28:11,544] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run18
[2019-04-06 18:28:13,988] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0567080e-09 1.4498877e-07 5.6665659e-09 9.5184636e-04 5.3837840e-10
 9.9904794e-01 5.2672227e-09], sum to 1.0000
[2019-04-06 18:28:13,992] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7164
[2019-04-06 18:28:14,133] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 28.5, 0.0, 0.0, 26.0, 25.62175862271571, 0.4875788670927665, 1.0, 1.0, 77961.7876670051], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4041000.0000, 
sim time next is 4042800.0000, 
raw observation next is [-4.0, 31.0, 0.0, 0.0, 26.0, 25.57672021363365, 0.5099243650691185, 1.0, 1.0, 49138.05261332771], 
processed observation next is [1.0, 0.8260869565217391, 0.3518005540166205, 0.31, 0.0, 0.0, 0.6666666666666666, 0.6313933511361375, 0.6699747883563729, 1.0, 1.0, 0.23399072673013194], 
reward next is 0.7660, 
noisyNet noise sample is [array([-0.7462722], dtype=float32), 1.116948]. 
=============================================
[2019-04-06 18:28:14,633] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9959886e-10 3.5883474e-07 8.1550819e-09 3.1466220e-04 5.8839295e-10
 9.9968505e-01 6.0285457e-09], sum to 1.0000
[2019-04-06 18:28:14,633] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4576
[2019-04-06 18:28:14,881] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 49.5, 92.0, 488.0, 26.0, 24.9622207995523, 0.3967066808152895, 0.0, 1.0, 80535.86846981828], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4177800.0000, 
sim time next is 4179600.0000, 
raw observation next is [-4.0, 45.0, 100.0, 574.0, 26.0, 25.64873820379405, 0.4382725169252231, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3518005540166205, 0.45, 0.3333333333333333, 0.6342541436464089, 0.6666666666666666, 0.6373948503161708, 0.6460908389750744, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.83894664], dtype=float32), 1.2242737]. 
=============================================
[2019-04-06 18:28:18,104] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.01756735e-10 6.55489814e-08 1.12826293e-09 4.96374955e-03
 6.15778331e-11 9.95036185e-01 3.12170512e-09], sum to 1.0000
[2019-04-06 18:28:18,111] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5220
[2019-04-06 18:28:18,175] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 69.5, 0.0, 0.0, 26.0, 24.44920493393403, 0.176818895541011, 0.0, 1.0, 45836.61822383307], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 163800.0000, 
sim time next is 165600.0000, 
raw observation next is [-8.4, 71.0, 0.0, 0.0, 26.0, 24.29202042318386, 0.1438395897660938, 0.0, 1.0, 45589.72886058161], 
processed observation next is [1.0, 0.9565217391304348, 0.2299168975069252, 0.71, 0.0, 0.0, 0.6666666666666666, 0.5243350352653217, 0.5479465299220313, 0.0, 1.0, 0.2170939469551505], 
reward next is 0.7829, 
noisyNet noise sample is [array([0.5764972], dtype=float32), 0.047487356]. 
=============================================
[2019-04-06 18:28:20,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.09522519e-09 1.01681565e-07 1.45333112e-09 4.14138398e-04
 1.00051918e-10 9.99585807e-01 4.80763818e-10], sum to 1.0000
[2019-04-06 18:28:20,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6558
[2019-04-06 18:28:21,060] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.65, 78.0, 34.0, 296.0, 26.0, 25.09545963769392, 0.2229433981055746, 1.0, 1.0, 20467.236193305773], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 203400.0000, 
sim time next is 205200.0000, 
raw observation next is [-8.4, 78.0, 56.5, 148.0, 26.0, 25.30988424238895, 0.2203129880719112, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.2299168975069252, 0.78, 0.18833333333333332, 0.16353591160220995, 0.6666666666666666, 0.6091570201990791, 0.5734376626906371, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7225055], dtype=float32), -0.083912924]. 
=============================================
[2019-04-06 18:28:24,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:28:24,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:28:24,797] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run18
[2019-04-06 18:28:40,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:28:40,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:28:40,805] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run18
[2019-04-06 18:28:56,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:28:56,947] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:28:56,951] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run18
[2019-04-06 18:29:02,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:29:02,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:29:02,614] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run18
[2019-04-06 18:29:06,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:29:06,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:29:06,316] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run18
[2019-04-06 18:29:08,358] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3881627e-10 2.1042949e-08 8.2164570e-10 6.7477196e-04 1.2699358e-11
 9.9932528e-01 2.1171069e-10], sum to 1.0000
[2019-04-06 18:29:08,359] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1678
[2019-04-06 18:29:08,417] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.5, 25.5, 124.0, 865.0, 26.0, 27.44755140689433, 0.8705603298880525, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5056200.0000, 
sim time next is 5058000.0000, 
raw observation next is [9.0, 25.0, 121.0, 862.5, 26.0, 27.5800405575392, 0.9038891927213477, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.7119113573407203, 0.25, 0.4033333333333333, 0.9530386740331491, 0.6666666666666666, 0.7983367131282666, 0.8012963975737826, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0253373], dtype=float32), -1.8916574]. 
=============================================
[2019-04-06 18:29:08,430] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[90.05227 ]
 [89.63121 ]
 [89.2595  ]
 [88.763435]
 [88.256546]], R is [[90.57289886]
 [90.66716766]
 [90.76049805]
 [90.85289764]
 [90.94436646]].
[2019-04-06 18:29:09,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:29:09,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:29:09,536] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run18
[2019-04-06 18:29:09,986] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:29:09,986] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:29:09,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run18
[2019-04-06 18:29:11,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:29:11,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:29:11,484] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run18
[2019-04-06 18:29:11,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:29:11,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:29:11,704] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run18
[2019-04-06 18:30:05,520] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-06 18:30:05,525] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:30:05,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:30:05,527] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run40
[2019-04-06 18:30:05,673] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:30:05,673] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:30:05,676] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run40
[2019-04-06 18:30:05,749] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:30:05,749] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:30:05,752] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run40
[2019-04-06 18:32:40,891] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 18:32:41,502] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.04741644], dtype=float32), 0.12365648]
[2019-04-06 18:32:41,503] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-1.284062269, 60.65848521, 159.2664086, 806.19817715, 26.0, 25.69450085233118, 0.4910190240289714, 1.0, 1.0, 27074.296709650534]
[2019-04-06 18:32:41,503] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 18:32:41,503] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [4.45339599e-10 1.03800936e-07 1.28021038e-09 9.21979779e-04
 2.99921282e-10 9.99077916e-01 1.29913114e-09], sampled 0.28826902940271537
[2019-04-06 18:33:00,046] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 18:33:03,581] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 18:33:04,603] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 780000, evaluation results [780000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 18:34:24,540] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3780162e-10 2.7353749e-07 2.7505260e-09 7.6063018e-04 1.2880831e-10
 9.9923909e-01 1.5591732e-09], sum to 1.0000
[2019-04-06 18:34:24,542] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9588
[2019-04-06 18:34:24,601] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 80.5, 0.0, 0.0, 26.0, 25.68074544110529, 0.5521033665109335, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1560600.0000, 
sim time next is 1562400.0000, 
raw observation next is [5.0, 79.0, 0.0, 0.0, 26.0, 25.43431573142675, 0.5186322872518464, 0.0, 1.0, 69493.01272203865], 
processed observation next is [1.0, 0.08695652173913043, 0.6011080332409973, 0.79, 0.0, 0.0, 0.6666666666666666, 0.6195263109522292, 0.6728774290839489, 0.0, 1.0, 0.33091910820018405], 
reward next is 0.6691, 
noisyNet noise sample is [array([-0.25288403], dtype=float32), 0.21192014]. 
=============================================
[2019-04-06 18:34:54,128] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6723632e-10 5.9628185e-08 1.1249108e-09 4.7700875e-03 4.3132170e-10
 9.9522984e-01 1.0832284e-09], sum to 1.0000
[2019-04-06 18:34:54,128] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0497
[2019-04-06 18:34:54,661] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.35, 68.5, 30.0, 0.0, 26.0, 25.53503542476353, 0.3250331878569039, 1.0, 1.0, 33080.40607703469], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1960200.0000, 
sim time next is 1962000.0000, 
raw observation next is [-3.9, 75.0, 17.5, 1.0, 26.0, 24.60894456563421, 0.2902678855665915, 1.0, 1.0, 100948.24910142638], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.75, 0.058333333333333334, 0.0011049723756906078, 0.6666666666666666, 0.5507453804695176, 0.5967559618555305, 1.0, 1.0, 0.4807059481020304], 
reward next is 0.5193, 
noisyNet noise sample is [array([-1.935237], dtype=float32), 1.4563621]. 
=============================================
[2019-04-06 18:34:54,694] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[80.02188 ]
 [79.58372 ]
 [79.43924 ]
 [79.149055]
 [79.451385]], R is [[80.7617569 ]
 [80.7966156 ]
 [80.85729218]
 [80.7828064 ]
 [80.97497559]].
[2019-04-06 18:35:16,057] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.6307722e-09 7.5022842e-07 5.9508167e-09 6.3423469e-04 1.1518639e-09
 9.9936503e-01 2.9150149e-09], sum to 1.0000
[2019-04-06 18:35:16,058] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5229
[2019-04-06 18:35:16,132] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 54.0, 0.0, 0.0, 26.0, 24.93277263365654, 0.2918121303208668, 0.0, 1.0, 39459.622492711576], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4165200.0000, 
sim time next is 4167000.0000, 
raw observation next is [-4.0, 52.0, 0.0, 0.0, 26.0, 24.84588770169342, 0.2707560405732368, 0.0, 1.0, 39456.33513315823], 
processed observation next is [0.0, 0.21739130434782608, 0.3518005540166205, 0.52, 0.0, 0.0, 0.6666666666666666, 0.5704906418077851, 0.5902520135244123, 0.0, 1.0, 0.18788731015789634], 
reward next is 0.8121, 
noisyNet noise sample is [array([0.15439022], dtype=float32), 1.8221943]. 
=============================================
[2019-04-06 18:35:16,147] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.25192 ]
 [75.34529 ]
 [75.348785]
 [75.48303 ]
 [75.58647 ]], R is [[75.04381561]
 [75.10547638]
 [75.16648865]
 [75.22683716]
 [75.28666687]].
[2019-04-06 18:35:19,756] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:35:19,756] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:35:19,759] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run19
[2019-04-06 18:35:38,661] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5806988e-10 6.4496341e-08 1.6747356e-09 1.9087900e-03 1.8207007e-10
 9.9809116e-01 1.0343479e-09], sum to 1.0000
[2019-04-06 18:35:38,661] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1854
[2019-04-06 18:35:39,074] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 71.0, 0.0, 0.0, 26.0, 25.27396457757846, 0.3834569295472356, 0.0, 1.0, 40551.2073049283], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4518000.0000, 
sim time next is 4519800.0000, 
raw observation next is [-0.9, 72.0, 0.0, 0.0, 26.0, 25.54005677721738, 0.4324434484446163, 1.0, 1.0, 13478.927788927858], 
processed observation next is [1.0, 0.30434782608695654, 0.43767313019390586, 0.72, 0.0, 0.0, 0.6666666666666666, 0.628338064768115, 0.6441478161482054, 1.0, 1.0, 0.06418537042346599], 
reward next is 0.9358, 
noisyNet noise sample is [array([0.7479998], dtype=float32), 1.0661131]. 
=============================================
[2019-04-06 18:35:42,744] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3790331e-09 2.8390829e-07 1.0339313e-09 2.7243962e-04 1.6417434e-10
 9.9972731e-01 1.6471201e-09], sum to 1.0000
[2019-04-06 18:35:42,744] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8449
[2019-04-06 18:35:42,790] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.5, 29.0, 5.0, 46.0, 26.0, 25.73447925648009, 0.3608104385382907, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2827800.0000, 
sim time next is 2829600.0000, 
raw observation next is [5.0, 30.0, 0.0, 0.0, 26.0, 25.46153660208835, 0.3652557055671203, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6011080332409973, 0.3, 0.0, 0.0, 0.6666666666666666, 0.621794716840696, 0.6217519018557067, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.9609082], dtype=float32), 0.67234635]. 
=============================================
[2019-04-06 18:35:49,103] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 18:35:49,103] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:35:49,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:35:49,110] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run41
[2019-04-06 18:35:49,205] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:35:49,205] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:35:49,209] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:35:49,209] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:35:49,211] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run41
[2019-04-06 18:35:49,326] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run41
[2019-04-06 18:38:20,054] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 18:38:38,901] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.7963 87811316.9101 515.2837
[2019-04-06 18:38:40,021] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 18:38:41,044] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 800000, evaluation results [800000.0, 2415.796341920238, 87811316.91011576, 515.2836583691358, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 18:38:46,943] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5495563e-09 4.3924308e-07 3.2936320e-08 4.9811038e-03 9.5627638e-11
 9.9501836e-01 2.7560703e-09], sum to 1.0000
[2019-04-06 18:38:46,943] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9769
[2019-04-06 18:38:47,006] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 80.5, 0.0, 0.0, 26.0, 25.34133870879286, 0.4499891747908607, 0.0, 1.0, 45243.99660374897], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4746600.0000, 
sim time next is 4748400.0000, 
raw observation next is [-3.0, 77.0, 0.0, 0.0, 26.0, 25.20352477044725, 0.4318780021123625, 0.0, 1.0, 45345.63073927418], 
processed observation next is [1.0, 1.0, 0.3795013850415513, 0.77, 0.0, 0.0, 0.6666666666666666, 0.6002937308706041, 0.6439593340374542, 0.0, 1.0, 0.21593157494892468], 
reward next is 0.7841, 
noisyNet noise sample is [array([-1.2246106], dtype=float32), 0.84642994]. 
=============================================
[2019-04-06 18:39:05,630] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:39:05,630] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:39:05,634] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run19
[2019-04-06 18:39:05,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:39:05,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:39:05,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run19
[2019-04-06 18:39:11,310] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:39:11,310] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:39:11,336] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run19
[2019-04-06 18:39:14,534] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0189223e-10 1.6930443e-07 3.8892005e-09 5.7893334e-04 4.1746903e-10
 9.9942088e-01 3.5385764e-10], sum to 1.0000
[2019-04-06 18:39:14,534] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5035
[2019-04-06 18:39:14,633] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 26.0, 25.3504427002397, 0.4384887831665745, 0.0, 1.0, 43200.62388708801], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3889800.0000, 
sim time next is 3891600.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 26.0, 25.36896344964662, 0.4373776501385251, 0.0, 1.0, 39879.619391863795], 
processed observation next is [1.0, 0.043478260869565216, 0.40720221606648205, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6140802874705518, 0.6457925500461751, 0.0, 1.0, 0.1899029494850657], 
reward next is 0.8101, 
noisyNet noise sample is [array([-1.0031847], dtype=float32), 0.36162233]. 
=============================================
[2019-04-06 18:39:22,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:39:22,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:39:22,832] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run19
[2019-04-06 18:39:31,975] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9502417e-10 7.7285094e-08 6.6661889e-09 1.0424613e-03 7.7874200e-11
 9.9895740e-01 5.1429139e-10], sum to 1.0000
[2019-04-06 18:39:31,975] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4301
[2019-04-06 18:39:32,253] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 26.0, 25.37675001446094, 0.4571034694356837, 0.0, 1.0, 52522.83820996674], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3456000.0000, 
sim time next is 3457800.0000, 
raw observation next is [1.0, 82.5, 0.0, 0.0, 26.0, 25.48102513275884, 0.4657889219624349, 0.0, 1.0, 27912.057984967232], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.825, 0.0, 0.0, 0.6666666666666666, 0.6234187610632368, 0.6552629739874783, 0.0, 1.0, 0.1329145618331773], 
reward next is 0.8671, 
noisyNet noise sample is [array([-0.7591254], dtype=float32), 1.0747963]. 
=============================================
[2019-04-06 18:39:43,723] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:39:43,723] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:39:43,726] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run19
[2019-04-06 18:39:56,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:39:56,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:39:56,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run19
[2019-04-06 18:40:00,215] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7433253e-10 2.5140253e-07 3.0053924e-09 5.4468017e-04 7.3932326e-11
 9.9945503e-01 5.8642591e-10], sum to 1.0000
[2019-04-06 18:40:00,215] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6908
[2019-04-06 18:40:00,285] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 68.0, 0.0, 0.0, 26.0, 25.55837074611036, 0.5175676318898078, 0.0, 1.0, 35251.34820241365], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4428000.0000, 
sim time next is 4429800.0000, 
raw observation next is [2.5, 74.0, 0.0, 0.0, 26.0, 25.50499192848304, 0.5215523717053085, 0.0, 1.0, 53909.242949403684], 
processed observation next is [1.0, 0.2608695652173913, 0.5318559556786704, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6254159940402534, 0.6738507905684362, 0.0, 1.0, 0.2567106807114461], 
reward next is 0.7433, 
noisyNet noise sample is [array([-0.25561526], dtype=float32), -1.3484783]. 
=============================================
[2019-04-06 18:40:04,078] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2307078e-09 1.2224725e-06 8.0445961e-09 3.7051141e-03 1.4710506e-08
 9.9629360e-01 1.4733138e-08], sum to 1.0000
[2019-04-06 18:40:04,079] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8797
[2019-04-06 18:40:04,261] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 36.0, 10.5, 210.0, 26.0, 25.90601207487276, 0.3998438765743382, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 406800.0000, 
sim time next is 408600.0000, 
raw observation next is [-9.2, 38.0, 0.0, 0.0, 26.0, 25.54305971721173, 0.2922210023663023, 1.0, 1.0, 61618.57573937086], 
processed observation next is [1.0, 0.7391304347826086, 0.20775623268698065, 0.38, 0.0, 0.0, 0.6666666666666666, 0.6285883097676441, 0.5974070007887674, 1.0, 1.0, 0.2934217892350994], 
reward next is 0.7066, 
noisyNet noise sample is [array([-1.6829282], dtype=float32), -0.039127726]. 
=============================================
[2019-04-06 18:40:14,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:40:14,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:40:14,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run19
[2019-04-06 18:40:40,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:40:40,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:40:40,904] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run19
[2019-04-06 18:40:56,214] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5504948e-11 2.6981841e-08 1.7109753e-09 4.6158577e-03 4.4232762e-10
 9.9538416e-01 6.0443106e-10], sum to 1.0000
[2019-04-06 18:40:56,214] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0166
[2019-04-06 18:40:56,323] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 26.0, 25.49335748678988, 0.5820977992745554, 0.0, 1.0, 18758.73866666706], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1373400.0000, 
sim time next is 1375200.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 26.0, 25.44540561275922, 0.5675133295707567, 0.0, 1.0, 37453.53537331435], 
processed observation next is [1.0, 0.9565217391304348, 0.4764542936288089, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6204504677299351, 0.689171109856919, 0.0, 1.0, 0.17835016844435406], 
reward next is 0.8216, 
noisyNet noise sample is [array([-0.7068416], dtype=float32), -0.66855747]. 
=============================================
[2019-04-06 18:41:06,527] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:41:06,527] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:41:06,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run19
[2019-04-06 18:41:13,144] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-06 18:41:13,145] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:41:13,152] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:41:13,152] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:41:13,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:41:13,155] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run42
[2019-04-06 18:41:13,251] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run42
[2019-04-06 18:41:13,278] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:41:13,279] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:41:13,282] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run42
[2019-04-06 18:43:43,573] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 18:44:00,512] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 18:44:03,154] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 18:44:04,176] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 820000, evaluation results [820000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 18:44:09,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:44:09,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:44:09,064] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run19
[2019-04-06 18:44:16,778] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.2054320e-08 8.8302886e-07 6.9704903e-08 5.0548366e-03 2.4590776e-09
 9.9494416e-01 5.3437670e-08], sum to 1.0000
[2019-04-06 18:44:16,782] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6424
[2019-04-06 18:44:16,822] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.95, 43.5, 0.0, 0.0, 26.0, 22.46671812006495, -0.3179246182345194, 0.0, 1.0, 46599.57497812976], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 455400.0000, 
sim time next is 457200.0000, 
raw observation next is [-8.4, 43.0, 0.0, 0.0, 26.0, 22.52220092351903, -0.338422508991559, 0.0, 1.0, 46199.711693041994], 
processed observation next is [1.0, 0.30434782608695654, 0.2299168975069252, 0.43, 0.0, 0.0, 0.6666666666666666, 0.3768500769599192, 0.3871924970028136, 0.0, 1.0, 0.2199986271097238], 
reward next is 0.7800, 
noisyNet noise sample is [array([-0.736514], dtype=float32), -0.3321332]. 
=============================================
[2019-04-06 18:44:17,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:44:17,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:44:17,884] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run19
[2019-04-06 18:44:20,809] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:44:20,809] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:44:20,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run19
[2019-04-06 18:44:21,052] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:44:21,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:44:21,056] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run19
[2019-04-06 18:44:22,772] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2760653e-10 8.3207631e-08 1.6538456e-09 2.6049337e-03 1.7955501e-10
 9.9739492e-01 1.5397582e-09], sum to 1.0000
[2019-04-06 18:44:22,772] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6599
[2019-04-06 18:44:23,015] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.95, 87.5, 0.0, 0.0, 26.0, 24.56746324645813, 0.1887861336654669, 0.0, 1.0, 35259.57656695297], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 63000.0000, 
sim time next is 64800.0000, 
raw observation next is [4.4, 89.0, 0.0, 0.0, 26.0, 24.57945814140816, 0.2025507712376837, 0.0, 1.0, 48919.11843454438], 
processed observation next is [0.0, 0.782608695652174, 0.5844875346260389, 0.89, 0.0, 0.0, 0.6666666666666666, 0.54828817845068, 0.5675169237458946, 0.0, 1.0, 0.23294818302163992], 
reward next is 0.7671, 
noisyNet noise sample is [array([0.6207121], dtype=float32), 0.2548283]. 
=============================================
[2019-04-06 18:44:23,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:44:23,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:44:23,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run19
[2019-04-06 18:44:23,919] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.2358550e-09 7.0106165e-07 1.6603048e-08 2.7970841e-02 4.4939927e-09
 9.7202832e-01 9.0247390e-08], sum to 1.0000
[2019-04-06 18:44:23,919] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9182
[2019-04-06 18:44:24,018] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 26.0, 24.60546972680335, 0.2032493892234127, 0.0, 1.0, 39419.11934424564], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2343600.0000, 
sim time next is 2345400.0000, 
raw observation next is [-2.55, 63.5, 0.0, 0.0, 26.0, 24.52150073818959, 0.1860453205060347, 0.0, 1.0, 39754.64124786041], 
processed observation next is [0.0, 0.13043478260869565, 0.3919667590027701, 0.635, 0.0, 0.0, 0.6666666666666666, 0.5434583948491326, 0.5620151068353448, 0.0, 1.0, 0.18930781546600195], 
reward next is 0.8107, 
noisyNet noise sample is [array([0.00303364], dtype=float32), -0.55471426]. 
=============================================
[2019-04-06 18:44:25,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:44:25,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:44:25,008] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run19
[2019-04-06 18:44:43,045] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.9360104e-09 6.3520079e-06 2.4305930e-07 1.5047317e-03 5.2684124e-09
 9.9848866e-01 3.2193878e-08], sum to 1.0000
[2019-04-06 18:44:43,045] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9233
[2019-04-06 18:44:43,053] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [18.3, 64.0, 0.0, 0.0, 26.0, 24.87230888231235, 0.4417034592322206, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1186200.0000, 
sim time next is 1188000.0000, 
raw observation next is [18.3, 63.0, 0.0, 0.0, 26.0, 24.81376032812682, 0.4297472867661212, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.9695290858725764, 0.63, 0.0, 0.0, 0.6666666666666666, 0.5678133606772349, 0.643249095588707, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.51440424], dtype=float32), -1.3414229]. 
=============================================
[2019-04-06 18:44:43,056] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[71.58834]
 [71.72388]
 [71.75617]
 [71.87101]
 [72.01085]], R is [[71.81954956]
 [72.10135651]
 [72.38034058]
 [72.65653992]
 [72.92997742]].
[2019-04-06 18:44:45,489] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4441540e-09 3.7528949e-07 5.8813607e-09 8.0018137e-03 2.9017440e-09
 9.9199778e-01 4.3593582e-09], sum to 1.0000
[2019-04-06 18:44:45,489] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7525
[2019-04-06 18:44:45,613] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 74.0, 0.0, 0.0, 26.0, 23.62762680305556, -0.0336945460902464, 0.0, 1.0, 44418.69599713453], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 178200.0000, 
sim time next is 180000.0000, 
raw observation next is [-8.9, 74.0, 0.0, 0.0, 26.0, 23.54568417995201, -0.05218857429541362, 0.0, 1.0, 44333.559411405666], 
processed observation next is [1.0, 0.08695652173913043, 0.21606648199445982, 0.74, 0.0, 0.0, 0.6666666666666666, 0.46214034832933404, 0.48260380856819546, 0.0, 1.0, 0.21111218767336032], 
reward next is 0.7889, 
noisyNet noise sample is [array([0.94278944], dtype=float32), -1.4796958]. 
=============================================
[2019-04-06 18:44:45,617] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[77.01546 ]
 [77.04068 ]
 [77.10123 ]
 [76.85377 ]
 [77.424835]], R is [[77.30675507]
 [77.32217407]
 [77.3374939 ]
 [77.35228729]
 [77.36617279]].
[2019-04-06 18:45:07,137] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4587989e-09 6.6928514e-08 2.8917653e-09 1.2263492e-02 1.6980423e-10
 9.8773640e-01 1.1585127e-09], sum to 1.0000
[2019-04-06 18:45:07,137] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1374
[2019-04-06 18:45:07,214] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 80.0, 0.0, 0.0, 26.0, 24.67344829966706, 0.2192631006344836, 0.0, 1.0, 40356.341891790806], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 864000.0000, 
sim time next is 865800.0000, 
raw observation next is [-2.3, 80.0, 0.0, 0.0, 26.0, 24.65257446765129, 0.2233866981183018, 0.0, 1.0, 39911.69475178362], 
processed observation next is [1.0, 0.0, 0.3988919667590028, 0.8, 0.0, 0.0, 0.6666666666666666, 0.5543812056376076, 0.5744622327061006, 0.0, 1.0, 0.19005568929420774], 
reward next is 0.8099, 
noisyNet noise sample is [array([0.09851475], dtype=float32), -0.67986757]. 
=============================================
[2019-04-06 18:45:24,551] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5813867e-11 2.4282921e-08 1.5844740e-09 2.1315871e-03 2.4764951e-10
 9.9786842e-01 2.7552297e-11], sum to 1.0000
[2019-04-06 18:45:24,551] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2277
[2019-04-06 18:45:24,648] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.6, 86.0, 0.0, 0.0, 26.0, 26.06696409266576, 0.7110793476818621, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1634400.0000, 
sim time next is 1636200.0000, 
raw observation next is [6.9, 84.0, 0.0, 0.0, 26.0, 25.82988397425781, 0.6095942438762664, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.6537396121883658, 0.84, 0.0, 0.0, 0.6666666666666666, 0.6524903311881509, 0.7031980812920887, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.13065635], dtype=float32), 0.59446466]. 
=============================================
[2019-04-06 18:47:02,723] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 18:47:02,723] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:47:02,724] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:47:02,733] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:47:02,741] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:47:02,744] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:47:02,744] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:47:02,746] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run43
[2019-04-06 18:47:02,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run43
[2019-04-06 18:47:02,925] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run43
[2019-04-06 18:49:32,718] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3885 79967197.3248 535.2671
[2019-04-06 18:49:50,793] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 18:49:53,864] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2891 91944900.5891 409.3749
[2019-04-06 18:49:54,887] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 840000, evaluation results [840000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.388471443006, 79967197.3248232, 535.2671102210136, 2396.2891096038065, 91944900.58913434, 409.3749352301794]
[2019-04-06 18:50:17,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:50:17,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:50:17,684] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run20
[2019-04-06 18:50:23,126] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.8293038e-10 3.3471605e-07 1.6066422e-09 1.1002165e-03 8.8630631e-10
 9.9889946e-01 1.4090599e-09], sum to 1.0000
[2019-04-06 18:50:23,126] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4891
[2019-04-06 18:50:23,200] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.45, 76.5, 0.0, 0.0, 26.0, 24.61607529525443, 0.2322844172711413, 0.0, 1.0, 44132.80253840889], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2244600.0000, 
sim time next is 2246400.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 26.0, 24.46256172473535, 0.2001795386215073, 0.0, 1.0, 44189.1390302615], 
processed observation next is [1.0, 0.0, 0.2770083102493075, 0.78, 0.0, 0.0, 0.6666666666666666, 0.5385468103946126, 0.5667265128738358, 0.0, 1.0, 0.2104244715726738], 
reward next is 0.7896, 
noisyNet noise sample is [array([0.36652], dtype=float32), -0.17350808]. 
=============================================
[2019-04-06 18:50:26,889] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.2499655e-11 1.9701803e-08 4.0354406e-10 1.0046909e-03 1.1530013e-11
 9.9899524e-01 1.6111441e-10], sum to 1.0000
[2019-04-06 18:50:26,889] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9713
[2019-04-06 18:50:26,921] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.75, 67.0, 0.0, 0.0, 26.0, 25.61884752016483, 0.5637210744817588, 0.0, 1.0, 50702.00620112566], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4419000.0000, 
sim time next is 4420800.0000, 
raw observation next is [4.5, 67.0, 0.0, 0.0, 26.0, 25.79771769075345, 0.5578601896163496, 0.0, 1.0, 9133.32424261039], 
processed observation next is [1.0, 0.17391304347826086, 0.5872576177285319, 0.67, 0.0, 0.0, 0.6666666666666666, 0.6498098075627876, 0.6859533965387832, 0.0, 1.0, 0.04349202020290662], 
reward next is 0.9565, 
noisyNet noise sample is [array([-1.1489364], dtype=float32), -0.47888198]. 
=============================================
[2019-04-06 18:50:57,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:50:57,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:50:57,898] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run20
[2019-04-06 18:50:57,946] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:50:57,946] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:50:57,955] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run20
[2019-04-06 18:51:01,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:51:01,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:51:01,592] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run20
[2019-04-06 18:51:10,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:51:10,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:51:10,914] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run20
[2019-04-06 18:51:37,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:51:37,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:51:37,668] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run20
[2019-04-06 18:52:02,555] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3241830e-09 6.0030601e-07 7.0450508e-09 1.7736614e-02 7.5268708e-10
 9.8226285e-01 1.3667155e-08], sum to 1.0000
[2019-04-06 18:52:02,555] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8087
[2019-04-06 18:52:02,709] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 46.0, 0.0, 0.0, 26.0, 25.41822427316493, 0.3913601890567307, 0.0, 1.0, 54527.266597580885], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3619800.0000, 
sim time next is 3621600.0000, 
raw observation next is [-2.0, 50.0, 0.0, 0.0, 26.0, 25.41378827164085, 0.3905148059942955, 0.0, 1.0, 44915.09334967394], 
processed observation next is [0.0, 0.9565217391304348, 0.40720221606648205, 0.5, 0.0, 0.0, 0.6666666666666666, 0.6178156893034042, 0.6301716019980985, 0.0, 1.0, 0.21388139690320923], 
reward next is 0.7861, 
noisyNet noise sample is [array([-0.56069785], dtype=float32), -0.962977]. 
=============================================
[2019-04-06 18:52:03,414] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:52:03,414] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:52:03,419] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run20
[2019-04-06 18:52:13,889] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3822238e-10 2.0085588e-08 9.3103347e-10 1.0623387e-03 4.0959298e-11
 9.9893767e-01 6.3470862e-10], sum to 1.0000
[2019-04-06 18:52:13,889] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9469
[2019-04-06 18:52:14,008] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 74.0, 0.0, 0.0, 26.0, 25.39492007453062, 0.3764395423191373, 0.0, 1.0, 43018.65239154141], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3810600.0000, 
sim time next is 3812400.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 26.0, 25.12611084809078, 0.3484268146778178, 0.0, 1.0, 53068.22340480204], 
processed observation next is [1.0, 0.13043478260869565, 0.3518005540166205, 0.71, 0.0, 0.0, 0.6666666666666666, 0.5938425706742315, 0.6161422715592726, 0.0, 1.0, 0.25270582573715256], 
reward next is 0.7473, 
noisyNet noise sample is [array([-0.37214562], dtype=float32), 0.14274722]. 
=============================================
[2019-04-06 18:52:35,372] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-06 18:52:35,372] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:52:35,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:52:35,374] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run44
[2019-04-06 18:52:35,426] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:52:35,426] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:52:35,429] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run44
[2019-04-06 18:52:35,488] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:52:35,488] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:52:35,491] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run44
[2019-04-06 18:55:04,743] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.6403 79964688.8054 535.2457
[2019-04-06 18:55:19,277] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 18:55:23,126] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 18:55:24,148] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 860000, evaluation results [860000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.6403132998144, 79964688.80543762, 535.245739731326, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 18:55:25,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:55:25,278] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:55:25,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run20
[2019-04-06 18:55:38,029] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:55:38,029] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:55:38,032] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run20
[2019-04-06 18:55:48,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:55:48,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:55:48,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run20
[2019-04-06 18:55:51,177] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2173095e-11 8.2310745e-09 2.8702011e-11 7.0776202e-04 4.5923434e-12
 9.9929225e-01 4.6338605e-10], sum to 1.0000
[2019-04-06 18:55:51,177] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4003
[2019-04-06 18:55:51,257] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.6, 82.0, 0.0, 0.0, 26.0, 25.55978519492045, 0.4567112556129091, 0.0, 1.0, 14243.16667821431], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 957600.0000, 
sim time next is 959400.0000, 
raw observation next is [7.15, 81.0, 0.0, 0.0, 26.0, 25.51294431229879, 0.429997377023136, 0.0, 1.0, 9626.94057879395], 
processed observation next is [1.0, 0.08695652173913043, 0.6606648199445985, 0.81, 0.0, 0.0, 0.6666666666666666, 0.6260786926915657, 0.643332459007712, 0.0, 1.0, 0.045842574184733094], 
reward next is 0.9542, 
noisyNet noise sample is [array([-1.7267907], dtype=float32), 0.13146883]. 
=============================================
[2019-04-06 18:56:00,933] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:56:00,933] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:56:00,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run20
[2019-04-06 18:56:04,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1238929e-11 5.6893301e-10 9.8796367e-11 2.4051235e-04 1.0638950e-12
 9.9975950e-01 7.3743954e-12], sum to 1.0000
[2019-04-06 18:56:04,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4402
[2019-04-06 18:56:04,805] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 9.0, 0.0, 26.0, 25.72756443157763, 0.5471051852798563, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1324800.0000, 
sim time next is 1326600.0000, 
raw observation next is [0.8, 92.0, 18.0, 0.0, 26.0, 25.72109666919557, 0.5770021191048572, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4847645429362882, 0.92, 0.06, 0.0, 0.6666666666666666, 0.6434247224329642, 0.6923340397016191, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.26957455], dtype=float32), 0.24483706]. 
=============================================
[2019-04-06 18:56:09,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:56:09,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:56:09,376] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run20
[2019-04-06 18:56:13,985] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:56:13,985] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:56:14,004] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run20
[2019-04-06 18:56:16,480] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:56:16,480] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:56:16,484] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run20
[2019-04-06 18:56:16,508] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:56:16,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:56:16,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run20
[2019-04-06 18:56:16,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:56:16,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:56:16,856] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run20
[2019-04-06 18:56:26,705] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.19838218e-11 2.57943960e-08 1.38666661e-10 5.22789604e-04
 1.33809405e-11 9.99477208e-01 2.24270838e-10], sum to 1.0000
[2019-04-06 18:56:26,705] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0627
[2019-04-06 18:56:26,752] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 92.0, 0.0, 0.0, 26.0, 25.47427949047529, 0.5771394058675353, 0.0, 1.0, 21263.33540764169], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1305000.0000, 
sim time next is 1306800.0000, 
raw observation next is [2.7, 92.0, 0.0, 0.0, 26.0, 25.5284559335904, 0.5648619327953855, 0.0, 1.0, 12498.600292799785], 
processed observation next is [1.0, 0.13043478260869565, 0.5373961218836566, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6273713277992, 0.6882873109317952, 0.0, 1.0, 0.059517144251427546], 
reward next is 0.9405, 
noisyNet noise sample is [array([-1.9440242], dtype=float32), 1.0221586]. 
=============================================
[2019-04-06 18:56:37,277] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8087870e-12 7.9419377e-10 3.8686408e-11 3.7020759e-04 5.3383567e-13
 9.9962974e-01 1.0118550e-11], sum to 1.0000
[2019-04-06 18:56:37,277] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8007
[2019-04-06 18:56:37,369] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.2, 96.0, 0.0, 0.0, 26.0, 25.34600600621271, 0.4492001231777651, 0.0, 1.0, 36924.456450639496], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1488600.0000, 
sim time next is 1490400.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 26.0, 25.37515478041007, 0.4504119179700208, 0.0, 1.0, 36347.07119057426], 
processed observation next is [1.0, 0.2608695652173913, 0.5235457063711911, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6145962317008392, 0.650137305990007, 0.0, 1.0, 0.17308129138368694], 
reward next is 0.8269, 
noisyNet noise sample is [array([-1.2903409], dtype=float32), -1.0262648]. 
=============================================
[2019-04-06 18:56:37,583] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3054017e-11 2.3624633e-08 1.6598513e-10 7.4237891e-05 7.4661687e-11
 9.9992573e-01 4.8824189e-10], sum to 1.0000
[2019-04-06 18:56:37,583] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4078
[2019-04-06 18:56:37,825] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 26.0, 24.81972358013049, 0.2448726394124953, 1.0, 1.0, 93463.44356616745], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2050200.0000, 
sim time next is 2052000.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 26.0, 25.50347814278872, 0.5177835002961296, 1.0, 1.0, 133848.00100371378], 
processed observation next is [1.0, 0.782608695652174, 0.3545706371191136, 0.82, 0.0, 0.0, 0.6666666666666666, 0.6252898452323933, 0.6725945000987098, 1.0, 1.0, 0.637371433351018], 
reward next is 0.3626, 
noisyNet noise sample is [array([-0.05829753], dtype=float32), 1.9417148]. 
=============================================
[2019-04-06 18:56:37,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[86.22477 ]
 [85.75727 ]
 [85.6923  ]
 [85.816734]
 [85.58454 ]], R is [[86.62195587]
 [86.31067657]
 [86.34637451]
 [86.48291016]
 [86.30328369]].
[2019-04-06 18:56:38,455] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.9021185e-11 2.4496137e-07 7.3218347e-09 7.3050410e-03 2.9522516e-09
 9.9269474e-01 3.3871499e-09], sum to 1.0000
[2019-04-06 18:56:38,455] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2540
[2019-04-06 18:56:38,762] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.55, 62.5, 0.0, 0.0, 26.0, 25.20881440176757, 0.2981158608242291, 1.0, 1.0, 11579.132671123312], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 153000.0000, 
sim time next is 154800.0000, 
raw observation next is [-7.8, 64.0, 0.0, 0.0, 26.0, 24.98849927632998, 0.3239741497253812, 1.0, 1.0, 122872.0428001418], 
processed observation next is [1.0, 0.8260869565217391, 0.24653739612188366, 0.64, 0.0, 0.0, 0.6666666666666666, 0.5823749396941649, 0.6079913832417937, 1.0, 1.0, 0.585104965714961], 
reward next is 0.4149, 
noisyNet noise sample is [array([-1.1614895], dtype=float32), -0.3248017]. 
=============================================
[2019-04-06 18:58:01,066] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.2256986e-10 1.2009934e-08 2.4862767e-10 2.7645635e-04 4.4303214e-11
 9.9972349e-01 7.1509916e-11], sum to 1.0000
[2019-04-06 18:58:01,066] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7511
[2019-04-06 18:58:01,184] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8999999999999999, 74.0, 0.0, 0.0, 26.0, 24.64434960797146, 0.1757762266129836, 0.0, 1.0, 39019.20305743409], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 880200.0000, 
sim time next is 882000.0000, 
raw observation next is [-0.6, 72.0, 0.0, 0.0, 26.0, 24.54187230738459, 0.1743000245596491, 0.0, 1.0, 39035.93438851671], 
processed observation next is [1.0, 0.21739130434782608, 0.44598337950138506, 0.72, 0.0, 0.0, 0.6666666666666666, 0.5451560256153826, 0.5581000081865497, 0.0, 1.0, 0.18588540185007957], 
reward next is 0.8141, 
noisyNet noise sample is [array([0.5339478], dtype=float32), -0.91499543]. 
=============================================
[2019-04-06 18:58:01,188] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[85.37251 ]
 [85.52605 ]
 [85.602684]
 [85.69406 ]
 [85.34607 ]], R is [[85.12657928]
 [85.08950806]
 [85.05230713]
 [85.01481628]
 [84.97723389]].
[2019-04-06 18:58:08,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1981968e-10 2.4345713e-08 1.1638029e-09 2.0969080e-02 5.2151039e-10
 9.7903091e-01 7.7808637e-10], sum to 1.0000
[2019-04-06 18:58:08,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4390
[2019-04-06 18:58:08,725] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.8, 56.0, 105.5, 760.5, 26.0, 26.50754653438962, 0.6300193399249717, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2728800.0000, 
sim time next is 2730600.0000, 
raw observation next is [-4.4, 55.0, 102.0, 733.0, 26.0, 26.71360305330706, 0.6604479534888882, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3407202216066482, 0.55, 0.34, 0.8099447513812155, 0.6666666666666666, 0.7261335877755885, 0.7201493178296294, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05344349], dtype=float32), 0.2786275]. 
=============================================
[2019-04-06 18:58:18,473] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 18:58:18,486] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:58:18,486] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:58:18,508] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run45
[2019-04-06 18:58:18,555] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:58:18,556] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:58:18,559] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run45
[2019-04-06 18:58:18,701] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:58:18,701] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:58:18,703] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run45
[2019-04-06 18:58:33,442] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05125345], dtype=float32), 0.1253775]
[2019-04-06 18:58:33,443] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-2.25, 89.0, 0.0, 0.0, 26.0, 24.22543183061112, 0.1101228503854664, 0.0, 1.0, 42283.0136401532]
[2019-04-06 18:58:33,443] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 18:58:33,444] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [3.2868178e-10 6.8213005e-08 1.3472573e-09 1.0915097e-03 1.3807745e-10
 9.9890840e-01 7.3087919e-10], sampled 0.7756152008395453
[2019-04-06 19:00:40,073] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05125345], dtype=float32), 0.1253775]
[2019-04-06 19:00:40,074] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-11.0, 80.0, 2.0, 94.0, 26.0, 24.15887029810707, 0.260437760115301, 1.0, 1.0, 149850.01362558384]
[2019-04-06 19:00:40,074] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 19:00:40,074] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.5100973e-09 1.7113750e-07 5.7619713e-09 1.4572967e-03 6.3630817e-10
 9.9854255e-01 2.8960248e-09], sampled 0.4406493434789438
[2019-04-06 19:00:50,585] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.5648 79959984.5800 535.1579
[2019-04-06 19:01:10,001] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 19:01:10,033] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 19:01:11,067] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 880000, evaluation results [880000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.564818314419, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 19:01:24,128] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1068026e-10 1.5880570e-07 5.5854521e-09 1.3223951e-02 3.3342828e-10
 9.8677582e-01 2.9141671e-09], sum to 1.0000
[2019-04-06 19:01:24,128] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5269
[2019-04-06 19:01:24,191] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.34864156963658, 0.1508931052107453, 0.0, 1.0, 42111.12851155061], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1990800.0000, 
sim time next is 1992600.0000, 
raw observation next is [-5.9, 85.0, 0.0, 0.0, 26.0, 24.36716458897913, 0.1432372693430764, 0.0, 1.0, 41830.039333624816], 
processed observation next is [1.0, 0.043478260869565216, 0.2991689750692521, 0.85, 0.0, 0.0, 0.6666666666666666, 0.5305970490815941, 0.5477457564476921, 0.0, 1.0, 0.1991906634934515], 
reward next is 0.8008, 
noisyNet noise sample is [array([1.0454521], dtype=float32), 0.9046974]. 
=============================================
[2019-04-06 19:01:32,492] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0717900e-13 1.8676189e-09 1.0113198e-11 1.9000183e-04 3.4210922e-12
 9.9981004e-01 1.1381249e-11], sum to 1.0000
[2019-04-06 19:01:32,501] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1130
[2019-04-06 19:01:32,605] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 100.0, 0.0, 0.0, 26.0, 25.59873587891578, 0.6658584801243972, 0.0, 1.0, 130887.22467602526], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3184200.0000, 
sim time next is 3186000.0000, 
raw observation next is [3.0, 100.0, 0.0, 0.0, 26.0, 25.66207881722421, 0.720021585372967, 0.0, 1.0, 82978.14975952143], 
processed observation next is [1.0, 0.9130434782608695, 0.5457063711911359, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6385065681020174, 0.7400071951243223, 0.0, 1.0, 0.3951340464739116], 
reward next is 0.6049, 
noisyNet noise sample is [array([0.09008714], dtype=float32), 0.5736063]. 
=============================================
[2019-04-06 19:01:32,644] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[94.72181 ]
 [94.35833 ]
 [94.969826]
 [95.497635]
 [95.371574]], R is [[93.74996185]
 [93.1891861 ]
 [93.2572937 ]
 [93.32472229]
 [93.39147949]].
[2019-04-06 19:01:50,547] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.39495703e-10 1.28241908e-07 1.15780185e-08 1.04348268e-03
 3.20395654e-10 9.98956323e-01 2.54108401e-09], sum to 1.0000
[2019-04-06 19:01:50,548] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5960
[2019-04-06 19:01:50,581] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 59.0, 0.0, 0.0, 26.0, 25.14782173598343, 0.3408101011779068, 0.0, 1.0, 9733.371465456134], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3693600.0000, 
sim time next is 3695400.0000, 
raw observation next is [4.0, 59.0, 0.0, 0.0, 26.0, 25.00275232802323, 0.320051535442822, 0.0, 1.0, 48703.73463823518], 
processed observation next is [0.0, 0.782608695652174, 0.5734072022160666, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5835626940019359, 0.6066838451476073, 0.0, 1.0, 0.23192254589635802], 
reward next is 0.7681, 
noisyNet noise sample is [array([0.42428997], dtype=float32), -0.32622033]. 
=============================================
[2019-04-06 19:01:52,910] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.0156504e-10 1.5620724e-08 3.0049119e-10 4.0122759e-04 5.3025886e-11
 9.9959880e-01 3.0395950e-11], sum to 1.0000
[2019-04-06 19:01:52,911] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7889
[2019-04-06 19:01:52,974] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 100.0, 0.0, 0.0, 26.0, 25.30587637492089, 0.3208571118096517, 0.0, 1.0, 39585.8460044227], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3112200.0000, 
sim time next is 3114000.0000, 
raw observation next is [1.0, 100.0, 0.0, 0.0, 26.0, 25.40560564694231, 0.3402320608669496, 0.0, 1.0, 33206.05764215745], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6171338039118591, 0.6134106869556498, 0.0, 1.0, 0.15812408401027359], 
reward next is 0.8419, 
noisyNet noise sample is [array([0.90260524], dtype=float32), -0.5577642]. 
=============================================
[2019-04-06 19:01:53,002] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[88.98605]
 [87.54162]
 [86.36692]
 [86.0616 ]
 [86.06184]], R is [[90.2296524 ]
 [90.13884735]
 [90.04484558]
 [89.89618683]
 [89.86978912]].
[2019-04-06 19:01:59,819] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4977764e-10 3.8168903e-08 5.8291111e-10 2.1827249e-03 3.2279637e-10
 9.9781728e-01 6.4013422e-10], sum to 1.0000
[2019-04-06 19:01:59,819] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0376
[2019-04-06 19:02:00,007] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.2, 79.0, 148.0, 0.0, 26.0, 25.08356972004286, 0.3985518609932586, 1.0, 1.0, 132788.97293319507], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2035800.0000, 
sim time next is 2037600.0000, 
raw observation next is [-3.9, 79.0, 126.0, 0.0, 26.0, 26.29660625242786, 0.4902889879887155, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3545706371191136, 0.79, 0.42, 0.0, 0.6666666666666666, 0.6913838543689884, 0.6634296626629052, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6570364], dtype=float32), 0.68193674]. 
=============================================
[2019-04-06 19:02:01,755] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:02:01,755] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:02:01,775] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run21
[2019-04-06 19:02:14,897] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.0386402e-10 5.0278963e-08 4.4360173e-09 5.8010098e-02 2.4355715e-10
 9.4198984e-01 2.4829045e-09], sum to 1.0000
[2019-04-06 19:02:14,897] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6083
[2019-04-06 19:02:14,954] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 36.0, 0.0, 0.0, 26.0, 25.71966180432339, 0.5897693970202159, 0.0, 1.0, 75395.17045054414], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4136400.0000, 
sim time next is 4138200.0000, 
raw observation next is [1.0, 38.0, 0.0, 0.0, 26.0, 25.93830672474444, 0.5846819700331713, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4903047091412743, 0.38, 0.0, 0.0, 0.6666666666666666, 0.6615255603953699, 0.6948939900110571, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.19796579], dtype=float32), 0.68543553]. 
=============================================
[2019-04-06 19:02:16,533] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.2343408e-10 9.9543991e-09 2.2278137e-09 2.2140509e-03 2.7184180e-10
 9.9778593e-01 3.0602334e-09], sum to 1.0000
[2019-04-06 19:02:16,533] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4822
[2019-04-06 19:02:16,615] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.3, 93.0, 0.0, 0.0, 26.0, 24.28838611747878, 0.1588570801655074, 0.0, 1.0, 40195.41942648197], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 88200.0000, 
sim time next is 90000.0000, 
raw observation next is [-0.6, 91.0, 0.0, 0.0, 26.0, 24.3714303086828, 0.1490428931985083, 0.0, 1.0, 40564.897596333765], 
processed observation next is [1.0, 0.043478260869565216, 0.44598337950138506, 0.91, 0.0, 0.0, 0.6666666666666666, 0.5309525257235667, 0.5496809643995028, 0.0, 1.0, 0.19316617903016078], 
reward next is 0.8068, 
noisyNet noise sample is [array([0.45211053], dtype=float32), 1.1817493]. 
=============================================
[2019-04-06 19:02:16,629] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[86.25586 ]
 [84.989174]
 [84.137   ]
 [84.43161 ]
 [84.71362 ]], R is [[87.18584442]
 [87.12258148]
 [87.06047821]
 [86.99906158]
 [86.93809509]].
[2019-04-06 19:02:20,272] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6373883e-10 1.9469375e-07 6.1940617e-09 8.5418047e-03 2.0744371e-10
 9.9145800e-01 1.0430652e-09], sum to 1.0000
[2019-04-06 19:02:20,273] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2375
[2019-04-06 19:02:20,377] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 61.0, 143.5, 295.0, 26.0, 25.93254546051917, 0.4538055083411635, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 136800.0000, 
sim time next is 138600.0000, 
raw observation next is [-6.7, 61.0, 148.0, 106.0, 26.0, 25.85933657541719, 0.4225229923978378, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.2770083102493075, 0.61, 0.49333333333333335, 0.11712707182320442, 0.6666666666666666, 0.654944714618099, 0.6408409974659459, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02345942], dtype=float32), 0.34649697]. 
=============================================
[2019-04-06 19:02:48,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:02:48,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:02:48,832] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run21
[2019-04-06 19:02:49,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:02:49,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:02:49,538] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run21
[2019-04-06 19:03:04,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:03:04,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:03:04,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run21
[2019-04-06 19:03:11,861] A3C_AGENT_WORKER-Thread-11 INFO:Local step 57000, global step 896712: loss 0.0146
[2019-04-06 19:03:11,862] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 57000, global step 896712: learning rate 0.0000
[2019-04-06 19:03:15,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:03:15,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:03:15,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run21
[2019-04-06 19:03:29,195] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.7875152e-10 1.7588083e-07 4.1771835e-09 3.5450456e-03 5.2759543e-09
 9.9645483e-01 1.7375005e-09], sum to 1.0000
[2019-04-06 19:03:29,196] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2421
[2019-04-06 19:03:29,292] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 39.0, 0.0, 0.0, 26.0, 25.4231472444615, 0.4226655418279311, 0.0, 1.0, 22826.55551609324], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4150800.0000, 
sim time next is 4152600.0000, 
raw observation next is [-1.5, 42.5, 0.0, 0.0, 26.0, 25.3391475820235, 0.411579838436313, 0.0, 1.0, 51038.65537366662], 
processed observation next is [0.0, 0.043478260869565216, 0.4210526315789474, 0.425, 0.0, 0.0, 0.6666666666666666, 0.6115956318352916, 0.637193279478771, 0.0, 1.0, 0.24304121606507914], 
reward next is 0.7570, 
noisyNet noise sample is [array([-0.04983629], dtype=float32), 0.19904695]. 
=============================================
[2019-04-06 19:03:33,963] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3216991e-10 9.3247628e-08 1.2447615e-09 2.9365174e-03 4.2645748e-11
 9.9706334e-01 1.0315538e-09], sum to 1.0000
[2019-04-06 19:03:33,964] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3180
[2019-04-06 19:03:34,288] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.85, 76.5, 79.0, 0.0, 26.0, 25.40561044885512, 0.2208469208240678, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 207000.0000, 
sim time next is 208800.0000, 
raw observation next is [-7.3, 75.0, 101.5, 0.0, 26.0, 25.3365173608052, 0.2127622456632948, 1.0, 1.0, 12491.246983148098], 
processed observation next is [1.0, 0.43478260869565216, 0.26038781163434904, 0.75, 0.3383333333333333, 0.0, 0.6666666666666666, 0.6113764467337667, 0.5709207485544315, 1.0, 1.0, 0.05948212849118142], 
reward next is 0.9405, 
noisyNet noise sample is [array([-1.3095411], dtype=float32), 2.1689744]. 
=============================================
[2019-04-06 19:03:48,236] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 19:03:48,245] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:03:48,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:03:48,247] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run46
[2019-04-06 19:03:48,312] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:03:48,312] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:03:48,316] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run46
[2019-04-06 19:03:48,462] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:03:48,463] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:03:48,485] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run46
[2019-04-06 19:03:48,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:03:48,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:03:48,616] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run21
[2019-04-06 19:04:03,614] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05149386], dtype=float32), 0.1261248]
[2019-04-06 19:04:03,614] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [3.2, 64.0, 0.0, 0.0, 26.0, 24.47211339984676, 0.109431359537918, 0.0, 1.0, 54989.98737438271]
[2019-04-06 19:04:03,614] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 19:04:03,615] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [7.1899880e-10 9.8413082e-08 2.5443556e-09 1.8460993e-03 2.8070710e-10
 9.9815375e-01 1.1516227e-09], sampled 0.07626878961024286
[2019-04-06 19:04:13,106] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05149386], dtype=float32), 0.1261248]
[2019-04-06 19:04:13,106] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [1.55, 52.5, 190.0, 286.0, 26.0, 25.00727428979596, 0.4359201315446854, 1.0, 1.0, 53713.99073265618]
[2019-04-06 19:04:13,107] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 19:04:13,107] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [3.7867479e-10 7.5350933e-08 1.1033278e-09 1.5682274e-03 2.4512350e-10
 9.9843162e-01 9.9410413e-10], sampled 0.2936878844051668
[2019-04-06 19:06:21,729] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 19:06:39,221] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.0307 87803285.7563 514.7094
[2019-04-06 19:06:42,018] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 19:06:43,040] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 900000, evaluation results [900000.0, 2416.0307402270905, 87803285.7563282, 514.7094491225716, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 19:06:54,006] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.0874751e-10 4.4562405e-08 7.2572339e-09 7.1296459e-03 3.7223519e-10
 9.9287027e-01 1.0079165e-09], sum to 1.0000
[2019-04-06 19:06:54,013] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1797
[2019-04-06 19:06:54,134] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.0, 24.0, 120.0, 862.5, 26.0, 27.06774385596709, 0.6262730499492776, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4971600.0000, 
sim time next is 4973400.0000, 
raw observation next is [7.5, 25.0, 117.0, 860.0, 26.0, 26.50657231853587, 0.6827165538719067, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.6703601108033241, 0.25, 0.39, 0.9502762430939227, 0.6666666666666666, 0.7088810265446558, 0.7275721846239689, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3267658], dtype=float32), -0.72031605]. 
=============================================
[2019-04-06 19:07:00,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:07:00,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:07:00,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run21
[2019-04-06 19:07:09,734] A3C_AGENT_WORKER-Thread-11 INFO:Local step 57500, global step 904058: loss 2.0742
[2019-04-06 19:07:09,743] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 57500, global step 904058: learning rate 0.0000
[2019-04-06 19:07:11,971] A3C_AGENT_WORKER-Thread-17 INFO:Local step 57000, global step 904381: loss 0.0144
[2019-04-06 19:07:11,978] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 57000, global step 904381: learning rate 0.0000
[2019-04-06 19:07:12,490] A3C_AGENT_WORKER-Thread-3 INFO:Local step 57000, global step 904471: loss 0.0138
[2019-04-06 19:07:12,491] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 57000, global step 904471: learning rate 0.0000
[2019-04-06 19:07:16,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:07:16,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:07:16,879] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run21
[2019-04-06 19:07:23,260] A3C_AGENT_WORKER-Thread-5 INFO:Local step 57000, global step 905993: loss 0.0131
[2019-04-06 19:07:23,261] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 57000, global step 905993: learning rate 0.0000
[2019-04-06 19:07:25,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:07:25,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:07:25,384] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run21
[2019-04-06 19:07:29,124] A3C_AGENT_WORKER-Thread-13 INFO:Local step 57000, global step 906779: loss 0.0132
[2019-04-06 19:07:29,125] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 57000, global step 906779: learning rate 0.0000
[2019-04-06 19:07:32,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2654602e-10 2.2107252e-09 4.0085806e-11 5.9637646e-03 6.0638168e-11
 9.9403620e-01 1.1982274e-11], sum to 1.0000
[2019-04-06 19:07:32,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6721
[2019-04-06 19:07:32,613] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.45, 33.5, 103.0, 0.0, 26.0, 28.81764257122221, 0.9760815158106948, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4375800.0000, 
sim time next is 4377600.0000, 
raw observation next is [13.0, 35.0, 71.0, 0.0, 26.0, 28.61407169797473, 0.9379588622291273, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.8227146814404434, 0.35, 0.23666666666666666, 0.0, 0.6666666666666666, 0.8845059748312275, 0.8126529540763757, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6339027], dtype=float32), 0.018790623]. 
=============================================
[2019-04-06 19:07:33,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0736103e-09 1.2102435e-06 2.5609870e-09 1.8661199e-03 7.3107076e-11
 9.9813265e-01 9.0939895e-10], sum to 1.0000
[2019-04-06 19:07:33,949] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4681
[2019-04-06 19:07:34,036] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 26.0, 21.37617623819503, -0.5318050007747428, 0.0, 1.0, 40282.19650029236], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 27000.0000, 
sim time next is 28800.0000, 
raw observation next is [7.7, 93.0, 10.5, 0.0, 26.0, 21.43907996593703, -0.5043931701027918, 0.0, 1.0, 40260.653827986556], 
processed observation next is [0.0, 0.34782608695652173, 0.6759002770083103, 0.93, 0.035, 0.0, 0.6666666666666666, 0.28658999716141914, 0.3318689432990694, 0.0, 1.0, 0.19171739918088837], 
reward next is 0.8083, 
noisyNet noise sample is [array([-1.5228354], dtype=float32), 0.08825457]. 
=============================================
[2019-04-06 19:07:35,470] A3C_AGENT_WORKER-Thread-16 INFO:Local step 57000, global step 907745: loss 0.0144
[2019-04-06 19:07:35,472] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 57000, global step 907745: learning rate 0.0000
[2019-04-06 19:07:40,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:07:40,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:07:40,369] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run21
[2019-04-06 19:07:53,318] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:07:53,318] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:07:53,325] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run21
[2019-04-06 19:07:57,656] A3C_AGENT_WORKER-Thread-3 INFO:Local step 57500, global step 911377: loss 2.2198
[2019-04-06 19:07:57,657] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 57500, global step 911377: learning rate 0.0000
[2019-04-06 19:07:58,240] A3C_AGENT_WORKER-Thread-17 INFO:Local step 57500, global step 911481: loss 2.2345
[2019-04-06 19:07:58,241] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 57500, global step 911481: learning rate 0.0000
[2019-04-06 19:07:59,951] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:07:59,951] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:07:59,955] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run21
[2019-04-06 19:08:00,368] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1308713e-10 2.6219602e-08 1.4558445e-10 6.5212970e-04 1.2973493e-10
 9.9934787e-01 1.0022811e-09], sum to 1.0000
[2019-04-06 19:08:00,370] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3924
[2019-04-06 19:08:00,467] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.0, 26.0, 100.5, 796.5, 26.0, 27.76036828963077, 0.7525818316127547, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4978800.0000, 
sim time next is 4980600.0000, 
raw observation next is [8.5, 25.5, 92.0, 774.0, 26.0, 26.79393048728001, 0.811827658382259, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.698060941828255, 0.255, 0.30666666666666664, 0.8552486187845304, 0.6666666666666666, 0.7328275406066677, 0.770609219460753, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9031507], dtype=float32), -0.80756056]. 
=============================================
[2019-04-06 19:08:00,612] A3C_AGENT_WORKER-Thread-6 INFO:Local step 57000, global step 911866: loss 0.0167
[2019-04-06 19:08:00,613] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 57000, global step 911867: learning rate 0.0000
[2019-04-06 19:08:05,465] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.4473112e-10 1.6139606e-06 1.2739615e-08 7.7545699e-03 4.6835238e-09
 9.9224383e-01 3.1743561e-08], sum to 1.0000
[2019-04-06 19:08:05,469] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7488
[2019-04-06 19:08:05,622] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.4, 52.0, 291.5, 236.0, 26.0, 24.98906449341774, 0.3274819095816194, 0.0, 1.0, 30869.67174188097], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4878000.0000, 
sim time next is 4879800.0000, 
raw observation next is [0.3, 49.5, 283.0, 308.0, 26.0, 25.02244627031235, 0.3505963730420363, 0.0, 1.0, 16910.22848173649], 
processed observation next is [0.0, 0.4782608695652174, 0.47091412742382277, 0.495, 0.9433333333333334, 0.34033149171270716, 0.6666666666666666, 0.5852038558593625, 0.6168654576806788, 0.0, 1.0, 0.08052489753207852], 
reward next is 0.9195, 
noisyNet noise sample is [array([1.0165758], dtype=float32), 1.5190579]. 
=============================================
[2019-04-06 19:08:06,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:08:06,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:08:06,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run21
[2019-04-06 19:08:06,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:08:06,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:08:06,586] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run21
[2019-04-06 19:08:07,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:08:07,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:08:07,568] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run21
[2019-04-06 19:08:08,001] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.0497025e-08 1.3080526e-06 6.9686756e-08 5.0134631e-03 5.9592571e-09
 9.9498498e-01 1.7383626e-07], sum to 1.0000
[2019-04-06 19:08:08,002] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6888
[2019-04-06 19:08:08,054] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.15, 51.5, 0.0, 0.0, 26.0, 24.20524147077828, 0.08109435743744474, 0.0, 1.0, 44796.7306378071], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 426600.0000, 
sim time next is 428400.0000, 
raw observation next is [-11.7, 54.0, 0.0, 0.0, 26.0, 24.03369287088809, 0.04211176503331903, 0.0, 1.0, 44754.33522227432], 
processed observation next is [1.0, 1.0, 0.13850415512465375, 0.54, 0.0, 0.0, 0.6666666666666666, 0.5028077392406741, 0.5140372550111063, 0.0, 1.0, 0.2131158820108301], 
reward next is 0.7869, 
noisyNet noise sample is [array([-0.7817384], dtype=float32), -0.010810269]. 
=============================================
[2019-04-06 19:08:08,297] A3C_AGENT_WORKER-Thread-5 INFO:Local step 57500, global step 913010: loss 2.2566
[2019-04-06 19:08:08,298] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 57500, global step 913010: learning rate 0.0000
[2019-04-06 19:08:12,130] A3C_AGENT_WORKER-Thread-11 INFO:Local step 58000, global step 913390: loss 0.2505
[2019-04-06 19:08:12,131] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 58000, global step 913390: learning rate 0.0000
[2019-04-06 19:08:13,792] A3C_AGENT_WORKER-Thread-13 INFO:Local step 57500, global step 913556: loss 2.3266
[2019-04-06 19:08:13,793] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 57500, global step 913556: learning rate 0.0000
[2019-04-06 19:08:16,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:08:16,446] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:08:16,452] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run21
[2019-04-06 19:08:16,866] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5904364e-11 6.5654561e-08 8.7795277e-10 5.4384896e-04 1.1356375e-09
 9.9945611e-01 1.0059387e-09], sum to 1.0000
[2019-04-06 19:08:16,867] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9236
[2019-04-06 19:08:17,009] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.3920667e-11 4.1448903e-08 1.5864445e-09 1.0925626e-03 4.9416040e-12
 9.9890745e-01 1.0528399e-10], sum to 1.0000
[2019-04-06 19:08:17,009] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0440
[2019-04-06 19:08:17,073] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.9, 89.5, 0.0, 0.0, 26.0, 25.62261450105436, 0.5987663214042377, 0.0, 1.0, 37621.577977582776], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1643400.0000, 
sim time next is 1645200.0000, 
raw observation next is [6.6, 93.0, 0.0, 0.0, 26.0, 25.62783776066102, 0.5848993508354791, 0.0, 1.0, 17830.822392906484], 
processed observation next is [1.0, 0.043478260869565216, 0.6454293628808865, 0.93, 0.0, 0.0, 0.6666666666666666, 0.6356531467217517, 0.694966450278493, 0.0, 1.0, 0.08490867806145945], 
reward next is 0.9151, 
noisyNet noise sample is [array([-0.85333943], dtype=float32), 0.593814]. 
=============================================
[2019-04-06 19:08:17,120] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 75.0, 101.5, 0.0, 26.0, 25.3365173608052, 0.2127622456632948, 1.0, 1.0, 12491.246983148098], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 208800.0000, 
sim time next is 210600.0000, 
raw observation next is [-6.75, 73.5, 124.0, 0.0, 26.0, 25.30217550367282, 0.2101370943510326, 1.0, 1.0, 23852.75550451149], 
processed observation next is [1.0, 0.43478260869565216, 0.275623268698061, 0.735, 0.41333333333333333, 0.0, 0.6666666666666666, 0.6085146253060684, 0.5700456981170109, 1.0, 1.0, 0.11358455002148328], 
reward next is 0.8864, 
noisyNet noise sample is [array([1.4976157], dtype=float32), 0.7230679]. 
=============================================
[2019-04-06 19:08:17,704] A3C_AGENT_WORKER-Thread-12 INFO:Local step 57000, global step 914075: loss 0.0136
[2019-04-06 19:08:17,704] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 57000, global step 914075: learning rate 0.0000
[2019-04-06 19:08:20,795] A3C_AGENT_WORKER-Thread-16 INFO:Local step 57500, global step 914331: loss 2.2610
[2019-04-06 19:08:20,796] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 57500, global step 914331: learning rate 0.0000
[2019-04-06 19:08:23,073] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.3514856e-11 7.7916180e-09 2.3938527e-11 1.3169905e-03 4.3568447e-12
 9.9868304e-01 1.8788419e-11], sum to 1.0000
[2019-04-06 19:08:23,073] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3109
[2019-04-06 19:08:23,272] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.6, 76.0, 76.0, 85.5, 26.0, 26.16468300945385, 0.5959644779414625, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1587600.0000, 
sim time next is 1589400.0000, 
raw observation next is [7.15, 72.0, 115.0, 136.0, 26.0, 26.33567795625265, 0.6556513410079319, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6606648199445985, 0.72, 0.38333333333333336, 0.15027624309392265, 0.6666666666666666, 0.6946398296877208, 0.7185504470026439, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.2943075], dtype=float32), 0.6257452]. 
=============================================
[2019-04-06 19:08:28,232] A3C_AGENT_WORKER-Thread-18 INFO:Local step 57000, global step 914890: loss 0.0153
[2019-04-06 19:08:28,232] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 57000, global step 914890: learning rate 0.0000
[2019-04-06 19:08:56,803] A3C_AGENT_WORKER-Thread-6 INFO:Local step 57500, global step 916879: loss 2.3059
[2019-04-06 19:08:56,804] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 57500, global step 916879: learning rate 0.0000
[2019-04-06 19:08:57,417] A3C_AGENT_WORKER-Thread-19 INFO:Local step 57000, global step 916931: loss 0.0145
[2019-04-06 19:08:57,418] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 57000, global step 916931: learning rate 0.0000
[2019-04-06 19:09:20,994] A3C_AGENT_WORKER-Thread-15 INFO:Local step 57000, global step 918817: loss 0.0144
[2019-04-06 19:09:21,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 57000, global step 918817: learning rate 0.0000
[2019-04-06 19:09:29,282] A3C_AGENT_WORKER-Thread-12 INFO:Local step 57500, global step 919464: loss 2.3883
[2019-04-06 19:09:29,282] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 57500, global step 919464: learning rate 0.0000
[2019-04-06 19:09:30,392] A3C_AGENT_WORKER-Thread-3 INFO:Local step 58000, global step 919556: loss 0.2162
[2019-04-06 19:09:30,393] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 58000, global step 919556: learning rate 0.0000
[2019-04-06 19:09:31,480] A3C_AGENT_WORKER-Thread-10 INFO:Local step 57000, global step 919643: loss 0.0176
[2019-04-06 19:09:31,480] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 57000, global step 919643: learning rate 0.0000
[2019-04-06 19:09:32,904] A3C_AGENT_WORKER-Thread-17 INFO:Local step 58000, global step 919768: loss 0.2164
[2019-04-06 19:09:32,904] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 58000, global step 919768: learning rate 0.0000
[2019-04-06 19:09:36,131] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 19:09:36,132] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:09:36,132] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:09:36,134] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run47
[2019-04-06 19:09:36,207] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:09:36,207] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:09:36,210] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:09:36,211] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:09:36,213] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run47
[2019-04-06 19:09:36,264] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run47
[2019-04-06 19:12:11,126] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3748 79991956.7854 535.1864
[2019-04-06 19:12:27,887] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5098 87830352.8773 516.5543
[2019-04-06 19:12:30,620] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2596 91948398.0424 409.3337
[2019-04-06 19:12:31,642] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 920000, evaluation results [920000.0, 2415.5098238036176, 87830352.877312, 516.5542744756061, 2453.374809603911, 79991956.78540477, 535.1864255395496, 2396.2596068800917, 91948398.04237857, 409.33365754853645]
[2019-04-06 19:12:31,790] A3C_AGENT_WORKER-Thread-11 INFO:Local step 58500, global step 920023: loss 0.1334
[2019-04-06 19:12:31,790] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 58500, global step 920023: learning rate 0.0000
[2019-04-06 19:12:33,396] A3C_AGENT_WORKER-Thread-18 INFO:Local step 57500, global step 920283: loss 2.4560
[2019-04-06 19:12:33,396] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 57500, global step 920283: learning rate 0.0000
[2019-04-06 19:12:35,495] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.2527352e-09 6.2161803e-08 2.3506714e-09 5.6945481e-03 6.4990552e-10
 9.9430543e-01 1.4237976e-09], sum to 1.0000
[2019-04-06 19:12:35,495] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5725
[2019-04-06 19:12:35,511] A3C_AGENT_WORKER-Thread-2 INFO:Local step 57000, global step 920564: loss 0.0155
[2019-04-06 19:12:35,511] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 57000, global step 920564: learning rate 0.0000
[2019-04-06 19:12:35,680] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 26.5, 122.0, 0.0, 26.0, 25.12827208604327, 0.1385448183632547, 1.0, 1.0, 21270.081901965426], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 473400.0000, 
sim time next is 475200.0000, 
raw observation next is [-1.7, 25.0, 125.5, 0.0, 26.0, 25.14699155037999, 0.1672624198964032, 1.0, 1.0, 36264.96055910076], 
processed observation next is [1.0, 0.5217391304347826, 0.4155124653739613, 0.25, 0.41833333333333333, 0.0, 0.6666666666666666, 0.5955826291983325, 0.5557541399654677, 1.0, 1.0, 0.17269028837667028], 
reward next is 0.8273, 
noisyNet noise sample is [array([0.55183107], dtype=float32), -1.4686476]. 
=============================================
[2019-04-06 19:12:37,047] A3C_AGENT_WORKER-Thread-14 INFO:Local step 57000, global step 920780: loss 0.0224
[2019-04-06 19:12:37,048] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 57000, global step 920780: learning rate 0.0000
[2019-04-06 19:12:37,903] A3C_AGENT_WORKER-Thread-20 INFO:Local step 57000, global step 920901: loss 0.0155
[2019-04-06 19:12:37,904] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 57000, global step 920901: learning rate 0.0000
[2019-04-06 19:12:40,806] A3C_AGENT_WORKER-Thread-5 INFO:Local step 58000, global step 921281: loss 0.1629
[2019-04-06 19:12:40,807] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 58000, global step 921281: learning rate 0.0000
[2019-04-06 19:12:45,396] A3C_AGENT_WORKER-Thread-13 INFO:Local step 58000, global step 921850: loss 0.1935
[2019-04-06 19:12:45,402] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 58000, global step 921850: learning rate 0.0000
[2019-04-06 19:12:49,158] A3C_AGENT_WORKER-Thread-4 INFO:Local step 57000, global step 922353: loss 0.0143
[2019-04-06 19:12:49,158] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 57000, global step 922353: learning rate 0.0000
[2019-04-06 19:12:50,602] A3C_AGENT_WORKER-Thread-16 INFO:Local step 58000, global step 922550: loss 0.1669
[2019-04-06 19:12:50,603] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 58000, global step 922550: learning rate 0.0000
[2019-04-06 19:12:54,480] A3C_AGENT_WORKER-Thread-19 INFO:Local step 57500, global step 923091: loss 2.2808
[2019-04-06 19:12:54,482] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 57500, global step 923091: learning rate 0.0000
[2019-04-06 19:13:10,365] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.2595201e-08 8.0877192e-07 1.6946323e-08 1.9083524e-03 5.5939346e-09
 9.9809080e-01 2.2081132e-09], sum to 1.0000
[2019-04-06 19:13:10,365] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2543
[2019-04-06 19:13:10,442] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.75, 50.5, 0.0, 0.0, 26.0, 24.28507624687576, 0.0785151103023059, 0.0, 1.0, 43426.92600927639], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2424600.0000, 
sim time next is 2426400.0000, 
raw observation next is [-7.3, 53.0, 0.0, 0.0, 26.0, 24.13188977343291, 0.0452470433327262, 0.0, 1.0, 43523.504733672795], 
processed observation next is [0.0, 0.08695652173913043, 0.26038781163434904, 0.53, 0.0, 0.0, 0.6666666666666666, 0.5109908144527425, 0.5150823477775753, 0.0, 1.0, 0.20725478444606094], 
reward next is 0.7927, 
noisyNet noise sample is [array([-0.78132844], dtype=float32), -1.8474728]. 
=============================================
[2019-04-06 19:13:10,617] A3C_AGENT_WORKER-Thread-15 INFO:Local step 57500, global step 925655: loss 3.2997
[2019-04-06 19:13:10,617] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 57500, global step 925655: learning rate 0.0000
[2019-04-06 19:13:11,302] A3C_AGENT_WORKER-Thread-6 INFO:Local step 58000, global step 925774: loss 0.2628
[2019-04-06 19:13:11,302] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 58000, global step 925774: learning rate 0.0000
[2019-04-06 19:13:17,318] A3C_AGENT_WORKER-Thread-11 INFO:Local step 59000, global step 926748: loss 0.2899
[2019-04-06 19:13:17,318] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 59000, global step 926748: learning rate 0.0000
[2019-04-06 19:13:17,520] A3C_AGENT_WORKER-Thread-10 INFO:Local step 57500, global step 926781: loss 2.2877
[2019-04-06 19:13:17,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 57500, global step 926781: learning rate 0.0000
[2019-04-06 19:13:23,031] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.53280913e-09 1.04070324e-07 1.51198840e-08 2.13344884e-03
 1.52004054e-09 9.97866452e-01 5.36791012e-09], sum to 1.0000
[2019-04-06 19:13:23,031] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4797
[2019-04-06 19:13:23,137] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 56.0, 57.0, 486.0, 26.0, 25.11706559242841, 0.3344801430347899, 0.0, 1.0, 17067.494466905016], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3083400.0000, 
sim time next is 3085200.0000, 
raw observation next is [0.0, 72.0, 32.0, 287.0, 26.0, 25.07563732752511, 0.3255753948730054, 0.0, 1.0, 42597.72251963074], 
processed observation next is [0.0, 0.7391304347826086, 0.46260387811634357, 0.72, 0.10666666666666667, 0.31712707182320443, 0.6666666666666666, 0.5896364439604259, 0.6085251316243351, 0.0, 1.0, 0.20284629771252732], 
reward next is 0.7972, 
noisyNet noise sample is [array([-0.76478994], dtype=float32), -2.3159413]. 
=============================================
[2019-04-06 19:13:24,238] A3C_AGENT_WORKER-Thread-2 INFO:Local step 57500, global step 927818: loss 2.4142
[2019-04-06 19:13:24,252] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 57500, global step 927818: learning rate 0.0000
[2019-04-06 19:13:24,951] A3C_AGENT_WORKER-Thread-3 INFO:Local step 58500, global step 927940: loss 0.1357
[2019-04-06 19:13:24,951] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 58500, global step 927940: learning rate 0.0000
[2019-04-06 19:13:25,038] A3C_AGENT_WORKER-Thread-17 INFO:Local step 58500, global step 927950: loss 0.1216
[2019-04-06 19:13:25,038] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 58500, global step 927950: learning rate 0.0000
[2019-04-06 19:13:25,483] A3C_AGENT_WORKER-Thread-20 INFO:Local step 57500, global step 928021: loss 2.4157
[2019-04-06 19:13:25,484] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 57500, global step 928021: learning rate 0.0000
[2019-04-06 19:13:26,233] A3C_AGENT_WORKER-Thread-14 INFO:Local step 57500, global step 928148: loss 2.3036
[2019-04-06 19:13:26,234] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 57500, global step 928148: learning rate 0.0000
[2019-04-06 19:13:28,138] A3C_AGENT_WORKER-Thread-12 INFO:Local step 58000, global step 928478: loss 0.2084
[2019-04-06 19:13:28,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 58000, global step 928478: learning rate 0.0000
[2019-04-06 19:13:35,370] A3C_AGENT_WORKER-Thread-5 INFO:Local step 58500, global step 929650: loss 0.0807
[2019-04-06 19:13:35,370] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 58500, global step 929650: learning rate 0.0000
[2019-04-06 19:13:36,100] A3C_AGENT_WORKER-Thread-18 INFO:Local step 58000, global step 929740: loss 0.1537
[2019-04-06 19:13:36,100] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 58000, global step 929740: learning rate 0.0000
[2019-04-06 19:13:37,431] A3C_AGENT_WORKER-Thread-4 INFO:Local step 57500, global step 929936: loss 2.2891
[2019-04-06 19:13:37,433] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 57500, global step 929936: learning rate 0.0000
[2019-04-06 19:13:39,061] A3C_AGENT_WORKER-Thread-13 INFO:Local step 58500, global step 930203: loss 0.0878
[2019-04-06 19:13:39,062] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 58500, global step 930203: learning rate 0.0000
[2019-04-06 19:13:44,003] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.8863363e-09 5.8900650e-07 4.9606674e-10 2.3692967e-03 1.3601402e-09
 9.9763012e-01 4.6996611e-09], sum to 1.0000
[2019-04-06 19:13:44,005] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7281
[2019-04-06 19:13:44,081] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 77.0, 0.0, 0.0, 26.0, 25.45429081399476, 0.510920921717458, 0.0, 1.0, 63838.71463687518], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3794400.0000, 
sim time next is 3796200.0000, 
raw observation next is [-3.0, 74.0, 0.0, 0.0, 26.0, 25.40347150709046, 0.4508907825958369, 0.0, 1.0, 56638.99407682793], 
processed observation next is [1.0, 0.9565217391304348, 0.3795013850415513, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6169559589242052, 0.6502969275319456, 0.0, 1.0, 0.26970949560394253], 
reward next is 0.7303, 
noisyNet noise sample is [array([0.6685611], dtype=float32), -0.2490292]. 
=============================================
[2019-04-06 19:13:44,211] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.9896711e-10 1.3641936e-08 3.7201747e-10 7.3623197e-04 1.4800804e-09
 9.9926370e-01 8.7577190e-10], sum to 1.0000
[2019-04-06 19:13:44,211] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8744
[2019-04-06 19:13:44,359] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 71.0, 145.0, 20.0, 26.0, 24.9649242915969, 0.2644362520724281, 0.0, 1.0, 47690.06669927168], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1861200.0000, 
sim time next is 1863000.0000, 
raw observation next is [-4.5, 71.0, 170.0, 40.0, 26.0, 24.99479993993055, 0.2723999802531521, 0.0, 1.0, 37102.73598458143], 
processed observation next is [0.0, 0.5652173913043478, 0.3379501385041552, 0.71, 0.5666666666666667, 0.04419889502762431, 0.6666666666666666, 0.5828999949942126, 0.5907999934177174, 0.0, 1.0, 0.17667969516467347], 
reward next is 0.8233, 
noisyNet noise sample is [array([0.59359527], dtype=float32), -0.6314905]. 
=============================================
[2019-04-06 19:13:44,363] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[77.828476]
 [77.646126]
 [77.989746]
 [78.260864]
 [77.71684 ]], R is [[77.91300201]
 [77.90677643]
 [77.92124176]
 [77.9548111 ]
 [77.94552612]].
[2019-04-06 19:13:45,709] A3C_AGENT_WORKER-Thread-16 INFO:Local step 58500, global step 931233: loss 0.1285
[2019-04-06 19:13:45,730] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 58500, global step 931233: learning rate 0.0000
[2019-04-06 19:13:55,922] A3C_AGENT_WORKER-Thread-19 INFO:Local step 58000, global step 932721: loss 0.2153
[2019-04-06 19:13:55,922] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 58000, global step 932721: learning rate 0.0000
[2019-04-06 19:13:56,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:13:56,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:13:56,666] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run22
[2019-04-06 19:14:06,168] A3C_AGENT_WORKER-Thread-6 INFO:Local step 58500, global step 934157: loss 0.0699
[2019-04-06 19:14:06,168] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 58500, global step 934157: learning rate 0.0000
[2019-04-06 19:14:07,995] A3C_AGENT_WORKER-Thread-3 INFO:Local step 59000, global step 934401: loss 0.3168
[2019-04-06 19:14:07,995] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 59000, global step 934401: learning rate 0.0000
[2019-04-06 19:14:09,022] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3190669e-10 1.4003548e-07 4.9780629e-09 1.2253419e-03 2.2348140e-10
 9.9877447e-01 3.2192511e-09], sum to 1.0000
[2019-04-06 19:14:09,022] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7182
[2019-04-06 19:14:09,126] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 47.0, 0.0, 0.0, 26.0, 25.425181894845, 0.3692935434976026, 0.0, 1.0, 42240.21790884563], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4228200.0000, 
sim time next is 4230000.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 26.0, 25.41162345860911, 0.3640483394297764, 0.0, 1.0, 42489.47341456783], 
processed observation next is [0.0, 1.0, 0.4903047091412743, 0.47, 0.0, 0.0, 0.6666666666666666, 0.6176352882174259, 0.6213494464765922, 0.0, 1.0, 0.20233082578365633], 
reward next is 0.7977, 
noisyNet noise sample is [array([0.24129966], dtype=float32), -0.008405246]. 
=============================================
[2019-04-06 19:14:09,135] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[77.11184 ]
 [76.95694 ]
 [76.974724]
 [76.92571 ]
 [77.27073 ]], R is [[77.10467529]
 [77.13248444]
 [77.23021698]
 [77.17370605]
 [77.29523468]].
[2019-04-06 19:14:10,114] A3C_AGENT_WORKER-Thread-17 INFO:Local step 59000, global step 934552: loss 0.3478
[2019-04-06 19:14:10,115] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 59000, global step 934552: learning rate 0.0000
[2019-04-06 19:14:13,510] A3C_AGENT_WORKER-Thread-15 INFO:Local step 58000, global step 934871: loss 0.1863
[2019-04-06 19:14:13,512] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 58000, global step 934871: learning rate 0.0000
[2019-04-06 19:14:13,732] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6883793e-11 3.9191095e-09 1.8767392e-10 2.1975276e-04 1.6322469e-11
 9.9978024e-01 1.3620549e-10], sum to 1.0000
[2019-04-06 19:14:13,732] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9769
[2019-04-06 19:14:13,843] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 68.0, 0.0, 0.0, 26.0, 25.24353129099646, 0.4157177522781175, 0.0, 1.0, 53045.062438550696], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2235600.0000, 
sim time next is 2237400.0000, 
raw observation next is [-5.3, 69.5, 0.0, 0.0, 26.0, 25.28408674332292, 0.4094846065481109, 0.0, 1.0, 45521.43072477699], 
processed observation next is [1.0, 0.9130434782608695, 0.31578947368421056, 0.695, 0.0, 0.0, 0.6666666666666666, 0.6070072286102434, 0.6364948688493702, 0.0, 1.0, 0.2167687177370333], 
reward next is 0.7832, 
noisyNet noise sample is [array([-0.7385734], dtype=float32), 1.5985304]. 
=============================================
[2019-04-06 19:14:15,327] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.04149084e-11 6.90797597e-09 1.16252966e-10 2.71554571e-04
 3.47039086e-12 9.99728382e-01 1.90806079e-10], sum to 1.0000
[2019-04-06 19:14:15,327] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8021
[2019-04-06 19:14:15,417] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.75, 69.5, 0.0, 0.0, 26.0, 25.58688397944891, 0.3780071888103713, 0.0, 1.0, 6245.581401144363], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4336200.0000, 
sim time next is 4338000.0000, 
raw observation next is [3.6, 69.0, 0.0, 0.0, 26.0, 25.43905142396177, 0.3679342802282031, 0.0, 1.0, 66319.10025630829], 
processed observation next is [1.0, 0.21739130434782608, 0.5623268698060943, 0.69, 0.0, 0.0, 0.6666666666666666, 0.6199209519968143, 0.6226447600760677, 0.0, 1.0, 0.31580523931575377], 
reward next is 0.6842, 
noisyNet noise sample is [array([-0.13533856], dtype=float32), 2.95946]. 
=============================================
[2019-04-06 19:14:15,421] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[89.92949]
 [90.48456]
 [90.58501]
 [90.94944]
 [89.9176 ]], R is [[89.74082947]
 [89.81368256]
 [89.75514221]
 [89.79186249]
 [89.54319   ]].
[2019-04-06 19:14:24,846] A3C_AGENT_WORKER-Thread-5 INFO:Local step 59000, global step 935927: loss 0.3074
[2019-04-06 19:14:24,853] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 59000, global step 935927: learning rate 0.0000
[2019-04-06 19:14:26,481] A3C_AGENT_WORKER-Thread-10 INFO:Local step 58000, global step 936092: loss 0.1986
[2019-04-06 19:14:26,481] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 58000, global step 936092: learning rate 0.0000
[2019-04-06 19:14:31,780] A3C_AGENT_WORKER-Thread-12 INFO:Local step 58500, global step 936638: loss 0.1390
[2019-04-06 19:14:31,780] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 58500, global step 936638: learning rate 0.0000
[2019-04-06 19:14:32,663] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6385086e-09 6.7012547e-07 5.1821418e-09 5.2180989e-03 3.0433733e-10
 9.9478120e-01 3.7903650e-10], sum to 1.0000
[2019-04-06 19:14:32,663] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4864
[2019-04-06 19:14:32,729] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.6, 74.0, 0.0, 0.0, 26.0, 25.20329430275618, 0.3764481442132184, 0.0, 1.0, 36184.4410150655], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4600800.0000, 
sim time next is 4602600.0000, 
raw observation next is [-2.8, 75.5, 0.0, 0.0, 26.0, 25.10962143196898, 0.3429162598277068, 0.0, 1.0, 36195.40759506303], 
processed observation next is [1.0, 0.2608695652173913, 0.38504155124653744, 0.755, 0.0, 0.0, 0.6666666666666666, 0.5924684526640815, 0.6143054199425689, 0.0, 1.0, 0.17235908378601442], 
reward next is 0.8276, 
noisyNet noise sample is [array([-1.7070746], dtype=float32), 0.50351757]. 
=============================================
[2019-04-06 19:14:33,647] A3C_AGENT_WORKER-Thread-13 INFO:Local step 59000, global step 936827: loss 0.3202
[2019-04-06 19:14:33,648] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 59000, global step 936827: learning rate 0.0000
[2019-04-06 19:14:37,106] A3C_AGENT_WORKER-Thread-2 INFO:Local step 58000, global step 937184: loss 0.1798
[2019-04-06 19:14:37,112] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 58000, global step 937184: learning rate 0.0000
[2019-04-06 19:14:40,338] A3C_AGENT_WORKER-Thread-18 INFO:Local step 58500, global step 937484: loss 0.1228
[2019-04-06 19:14:40,338] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 58500, global step 937484: learning rate 0.0000
[2019-04-06 19:14:40,357] A3C_AGENT_WORKER-Thread-20 INFO:Local step 58000, global step 937486: loss 0.2277
[2019-04-06 19:14:40,360] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 58000, global step 937486: learning rate 0.0000
[2019-04-06 19:14:43,042] A3C_AGENT_WORKER-Thread-14 INFO:Local step 58000, global step 937764: loss 0.2179
[2019-04-06 19:14:43,043] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 58000, global step 937764: learning rate 0.0000
[2019-04-06 19:14:43,988] A3C_AGENT_WORKER-Thread-16 INFO:Local step 59000, global step 937849: loss 0.3302
[2019-04-06 19:14:43,989] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 59000, global step 937849: learning rate 0.0000
[2019-04-06 19:15:03,538] A3C_AGENT_WORKER-Thread-4 INFO:Local step 58000, global step 939817: loss 0.2268
[2019-04-06 19:15:03,538] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 58000, global step 939817: learning rate 0.0000
[2019-04-06 19:15:05,108] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-06 19:15:05,108] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:15:05,108] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:15:05,109] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:15:05,113] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run48
[2019-04-06 19:15:05,199] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:15:05,202] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run48
[2019-04-06 19:15:05,219] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:15:05,220] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:15:05,257] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run48
[2019-04-06 19:17:37,345] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 19:17:53,535] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 19:17:57,154] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 19:17:58,183] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 940000, evaluation results [940000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 19:18:00,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:18:00,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:18:00,110] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run22
[2019-04-06 19:18:01,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:18:01,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:18:01,904] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run22
[2019-04-06 19:18:04,760] A3C_AGENT_WORKER-Thread-6 INFO:Local step 59000, global step 940941: loss 0.2806
[2019-04-06 19:18:04,774] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 59000, global step 940941: learning rate 0.0000
[2019-04-06 19:18:05,865] A3C_AGENT_WORKER-Thread-19 INFO:Local step 58500, global step 941114: loss 0.2026
[2019-04-06 19:18:05,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 58500, global step 941114: learning rate 0.0000
[2019-04-06 19:18:08,725] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4950837e-09 1.2501390e-07 3.3158174e-09 6.5291175e-03 2.2649289e-09
 9.9347079e-01 7.0726709e-09], sum to 1.0000
[2019-04-06 19:18:08,725] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0570
[2019-04-06 19:18:08,759] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.3, 26.5, 71.0, 76.0, 26.0, 24.80755185017973, 0.3045074476617031, 1.0, 1.0, 59329.9159547243], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2824200.0000, 
sim time next is 2826000.0000, 
raw observation next is [6.0, 28.0, 38.0, 61.0, 26.0, 25.63050601806333, 0.391720069364818, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.6288088642659281, 0.28, 0.12666666666666668, 0.06740331491712707, 0.6666666666666666, 0.6358755015052774, 0.6305733564549393, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.2032862], dtype=float32), 0.77458483]. 
=============================================
[2019-04-06 19:18:08,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[81.072235]
 [80.950806]
 [80.870964]
 [81.44675 ]
 [81.62652 ]], R is [[80.88356018]
 [80.79219818]
 [80.98427582]
 [81.17443085]
 [81.05973816]].
[2019-04-06 19:18:13,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:18:13,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:18:13,888] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run22
[2019-04-06 19:18:18,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:18:18,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:18:18,094] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run22
[2019-04-06 19:18:19,944] A3C_AGENT_WORKER-Thread-12 INFO:Local step 59000, global step 943053: loss 0.2977
[2019-04-06 19:18:19,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 59000, global step 943053: learning rate 0.0000
[2019-04-06 19:18:22,644] A3C_AGENT_WORKER-Thread-15 INFO:Local step 58500, global step 943388: loss 0.2383
[2019-04-06 19:18:22,646] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 58500, global step 943388: learning rate 0.0000
[2019-04-06 19:18:25,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:18:25,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:18:25,232] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run22
[2019-04-06 19:18:28,377] A3C_AGENT_WORKER-Thread-18 INFO:Local step 59000, global step 944198: loss 0.2589
[2019-04-06 19:18:28,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 59000, global step 944198: learning rate 0.0000
[2019-04-06 19:18:30,650] A3C_AGENT_WORKER-Thread-10 INFO:Local step 58500, global step 944522: loss 0.2019
[2019-04-06 19:18:30,651] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 58500, global step 944522: learning rate 0.0000
[2019-04-06 19:18:37,322] A3C_AGENT_WORKER-Thread-2 INFO:Local step 58500, global step 945470: loss 0.2357
[2019-04-06 19:18:37,323] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 58500, global step 945470: learning rate 0.0000
[2019-04-06 19:18:40,627] A3C_AGENT_WORKER-Thread-14 INFO:Local step 58500, global step 945985: loss 0.1577
[2019-04-06 19:18:40,628] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 58500, global step 945985: learning rate 0.0000
[2019-04-06 19:18:41,421] A3C_AGENT_WORKER-Thread-20 INFO:Local step 58500, global step 946139: loss 0.1481
[2019-04-06 19:18:41,422] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 58500, global step 946139: learning rate 0.0000
[2019-04-06 19:18:41,899] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.0382145e-10 1.6385398e-08 1.3120523e-10 3.0406525e-03 2.5193684e-11
 9.9695933e-01 3.3134750e-10], sum to 1.0000
[2019-04-06 19:18:41,900] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0431
[2019-04-06 19:18:42,003] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.9, 68.5, 0.0, 0.0, 26.0, 25.73737980849132, 0.6660460143941404, 0.0, 1.0, 6241.487523695344], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1121400.0000, 
sim time next is 1123200.0000, 
raw observation next is [11.6, 71.0, 0.0, 0.0, 26.0, 25.76227933544137, 0.6512561282196073, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.0, 0.7839335180055402, 0.71, 0.0, 0.0, 0.6666666666666666, 0.6468566112867808, 0.7170853760732024, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5162283], dtype=float32), -0.6092376]. 
=============================================
[2019-04-06 19:18:46,096] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:18:46,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:18:46,100] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run22
[2019-04-06 19:18:47,177] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8598722e-11 1.0419190e-08 2.2243550e-10 1.0730738e-02 2.1771150e-12
 9.8926932e-01 7.4353523e-11], sum to 1.0000
[2019-04-06 19:18:47,177] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5624
[2019-04-06 19:18:47,232] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.41075071351842, 0.4176469105796654, 0.0, 1.0, 35467.240098071656], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4689000.0000, 
sim time next is 4690800.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.44897771215563, 0.4212154811969324, 0.0, 1.0, 38942.640828209995], 
processed observation next is [1.0, 0.30434782608695654, 0.4349030470914128, 1.0, 0.0, 0.0, 0.6666666666666666, 0.620748142679636, 0.6404051603989774, 0.0, 1.0, 0.18544114680099996], 
reward next is 0.8146, 
noisyNet noise sample is [array([0.47279426], dtype=float32), -0.32992697]. 
=============================================
[2019-04-06 19:18:49,617] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3902200e-10 4.4827363e-08 6.4623157e-10 1.7615082e-03 5.0155258e-12
 9.9823844e-01 1.0027145e-09], sum to 1.0000
[2019-04-06 19:18:49,617] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1829
[2019-04-06 19:18:49,778] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 74.0, 5.0, 136.0, 26.0, 25.2190214043551, 0.2887672596452079, 1.0, 1.0, 14137.953699977357], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3742200.0000, 
sim time next is 3744000.0000, 
raw observation next is [-4.0, 71.0, 47.0, 282.5, 26.0, 25.25316173021312, 0.301844734431631, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3518005540166205, 0.71, 0.15666666666666668, 0.31215469613259667, 0.6666666666666666, 0.6044301441844265, 0.6006149114772104, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3225621], dtype=float32), 0.21157221]. 
=============================================
[2019-04-06 19:18:49,781] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[86.38031 ]
 [85.35651 ]
 [85.17632 ]
 [85.058235]
 [85.190346]], R is [[86.18156433]
 [86.25242615]
 [86.188591  ]
 [86.12636566]
 [86.06666565]].
[2019-04-06 19:18:52,463] A3C_AGENT_WORKER-Thread-19 INFO:Local step 59000, global step 947782: loss 0.2328
[2019-04-06 19:18:52,463] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 59000, global step 947782: learning rate 0.0000
[2019-04-06 19:18:53,268] A3C_AGENT_WORKER-Thread-4 INFO:Local step 58500, global step 947893: loss 0.1865
[2019-04-06 19:18:53,268] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 58500, global step 947893: learning rate 0.0000
[2019-04-06 19:18:55,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1920341e-11 8.8234211e-09 2.0994220e-10 2.5325414e-04 4.4947271e-12
 9.9974674e-01 4.9715405e-11], sum to 1.0000
[2019-04-06 19:18:55,830] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1948
[2019-04-06 19:18:56,000] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 80.0, 138.0, 595.0, 26.0, 24.96673458437692, 0.3485818976415422, 0.0, 1.0, 37410.95909327694], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 567000.0000, 
sim time next is 568800.0000, 
raw observation next is [-1.2, 80.0, 132.5, 531.0, 26.0, 25.00242490479872, 0.3491824007980825, 0.0, 1.0, 18725.803445938054], 
processed observation next is [0.0, 0.6086956521739131, 0.42936288088642666, 0.8, 0.44166666666666665, 0.5867403314917127, 0.6666666666666666, 0.5835354087332266, 0.6163941335993609, 0.0, 1.0, 0.08917049259970503], 
reward next is 0.9108, 
noisyNet noise sample is [array([0.4750641], dtype=float32), 0.45661467]. 
=============================================
[2019-04-06 19:19:00,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:19:00,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:19:00,634] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run22
[2019-04-06 19:19:06,988] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:19:06,988] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:19:06,991] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run22
[2019-04-06 19:19:07,274] A3C_AGENT_WORKER-Thread-15 INFO:Local step 59000, global step 950054: loss 0.2401
[2019-04-06 19:19:07,276] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 59000, global step 950054: learning rate 0.0000
[2019-04-06 19:19:15,813] A3C_AGENT_WORKER-Thread-10 INFO:Local step 59000, global step 951256: loss 0.2421
[2019-04-06 19:19:15,840] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 59000, global step 951256: learning rate 0.0000
[2019-04-06 19:19:21,102] A3C_AGENT_WORKER-Thread-2 INFO:Local step 59000, global step 952012: loss 0.3089
[2019-04-06 19:19:21,103] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 59000, global step 952012: learning rate 0.0000
[2019-04-06 19:19:24,904] A3C_AGENT_WORKER-Thread-20 INFO:Local step 59000, global step 952648: loss 0.2224
[2019-04-06 19:19:24,904] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 59000, global step 952648: learning rate 0.0000
[2019-04-06 19:19:25,320] A3C_AGENT_WORKER-Thread-14 INFO:Local step 59000, global step 952710: loss 0.2015
[2019-04-06 19:19:25,320] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 59000, global step 952710: learning rate 0.0000
[2019-04-06 19:19:32,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:19:32,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:19:32,684] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run22
[2019-04-06 19:19:37,089] A3C_AGENT_WORKER-Thread-4 INFO:Local step 59000, global step 954692: loss 0.2522
[2019-04-06 19:19:37,093] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 59000, global step 954692: learning rate 0.0000
[2019-04-06 19:19:52,309] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:19:52,309] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:19:52,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run22
[2019-04-06 19:19:59,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1776149e-13 2.9649014e-10 7.8569784e-13 3.2063312e-04 2.1241768e-13
 9.9967933e-01 1.2744940e-12], sum to 1.0000
[2019-04-06 19:19:59,713] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1400
[2019-04-06 19:19:59,937] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.2, 92.0, 41.5, 0.0, 26.0, 25.73567542932583, 0.5358266470612996, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1674000.0000, 
sim time next is 1675800.0000, 
raw observation next is [1.85, 92.0, 53.0, 0.0, 26.0, 25.88312081040042, 0.5534422397795163, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.5138504155124655, 0.92, 0.17666666666666667, 0.0, 0.6666666666666666, 0.656926734200035, 0.684480746593172, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2776697], dtype=float32), -0.5038559]. 
=============================================
[2019-04-06 19:20:07,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:20:07,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:20:07,456] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run22
[2019-04-06 19:20:15,042] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:20:15,042] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:20:15,046] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run22
[2019-04-06 19:20:19,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:20:19,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:20:19,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run22
[2019-04-06 19:20:21,456] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:20:21,456] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:20:21,459] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run22
[2019-04-06 19:20:38,599] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 19:20:38,601] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:20:38,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:20:38,603] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run49
[2019-04-06 19:20:38,686] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:20:38,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:20:38,717] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:20:38,717] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:20:38,719] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run49
[2019-04-06 19:20:38,784] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run49
[2019-04-06 19:23:09,932] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 19:23:28,819] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.7803 87830352.8773 516.5543
[2019-04-06 19:23:29,558] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 19:23:30,581] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 960000, evaluation results [960000.0, 2415.7803254636497, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 19:23:33,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:23:33,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:23:33,036] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run22
[2019-04-06 19:24:34,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.6094309e-10 1.0713987e-07 8.4424584e-10 1.1898320e-02 6.1588595e-10
 9.8810160e-01 1.1233249e-09], sum to 1.0000
[2019-04-06 19:24:34,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6320
[2019-04-06 19:24:34,663] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 59.5, 152.0, 233.0, 26.0, 25.87468273285439, 0.3960684279679203, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2799000.0000, 
sim time next is 2800800.0000, 
raw observation next is [-3.0, 55.0, 163.0, 370.5, 26.0, 25.93284345819335, 0.4203376078668271, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.55, 0.5433333333333333, 0.4093922651933702, 0.6666666666666666, 0.6610702881827791, 0.640112535955609, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05974169], dtype=float32), -1.2625381]. 
=============================================
[2019-04-06 19:24:36,834] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8006842e-11 1.2623590e-09 1.4428192e-10 2.5533367e-04 3.7888411e-11
 9.9974471e-01 1.4282447e-10], sum to 1.0000
[2019-04-06 19:24:36,834] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8078
[2019-04-06 19:24:37,013] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.3010086674011, 0.1886694772678806, 1.0, 1.0, 148568.2658103465], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2014200.0000, 
sim time next is 2016000.0000, 
raw observation next is [-6.2, 87.0, 15.0, 0.0, 26.0, 25.26803006686426, 0.2622786057492357, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.2908587257617729, 0.87, 0.05, 0.0, 0.6666666666666666, 0.6056691722386883, 0.5874262019164119, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6835223], dtype=float32), 1.5690386]. 
=============================================
[2019-04-06 19:24:37,017] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[83.29691 ]
 [81.305016]
 [81.483025]
 [81.60589 ]
 [81.671715]], R is [[83.83757782]
 [83.29174042]
 [83.26293182]
 [83.23432159]
 [83.20622253]].
[2019-04-06 19:24:56,607] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0474606e-10 1.8526611e-08 5.4801103e-10 1.8388810e-02 9.5998723e-11
 9.8161119e-01 1.7847436e-09], sum to 1.0000
[2019-04-06 19:24:56,607] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0153
[2019-04-06 19:24:56,657] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [11.6, 57.0, 182.5, 186.5, 26.0, 27.19698426638199, 0.8360717786781809, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1598400.0000, 
sim time next is 1600200.0000, 
raw observation next is [12.7, 53.0, 149.0, 124.0, 26.0, 27.21921544777122, 0.7207909754409135, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.8144044321329641, 0.53, 0.49666666666666665, 0.13701657458563535, 0.6666666666666666, 0.768267953980935, 0.7402636584803045, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1995219], dtype=float32), 1.2377213]. 
=============================================
[2019-04-06 19:25:32,166] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6104104e-09 7.9004835e-08 1.5616753e-09 9.9775859e-04 2.2504161e-10
 9.9900216e-01 4.2153174e-09], sum to 1.0000
[2019-04-06 19:25:32,167] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1762
[2019-04-06 19:25:32,266] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 56.0, 0.0, 0.0, 26.0, 25.41433630299266, 0.4157892446457611, 0.0, 1.0, 30031.810000247988], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2583000.0000, 
sim time next is 2584800.0000, 
raw observation next is [-2.8, 56.0, 0.0, 0.0, 26.0, 25.37325981555664, 0.4120475456572439, 0.0, 1.0, 50559.01289254826], 
processed observation next is [1.0, 0.9565217391304348, 0.38504155124653744, 0.56, 0.0, 0.0, 0.6666666666666666, 0.6144383179630534, 0.637349181885748, 0.0, 1.0, 0.24075720425022978], 
reward next is 0.7592, 
noisyNet noise sample is [array([2.3438435], dtype=float32), 1.2570074]. 
=============================================
[2019-04-06 19:25:53,298] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:25:53,298] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:25:53,319] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run23
[2019-04-06 19:25:56,999] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1616714e-10 1.3258984e-08 6.4655220e-10 6.9931815e-03 2.1996434e-11
 9.9300683e-01 1.6622967e-09], sum to 1.0000
[2019-04-06 19:25:57,000] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3561
[2019-04-06 19:25:57,076] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.13805997751053, 0.05771806164269403, 0.0, 1.0, 41108.05848512557], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2008800.0000, 
sim time next is 2010600.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.03975449421284, 0.02393326081833424, 0.0, 1.0, 41156.831338213946], 
processed observation next is [1.0, 0.2608695652173913, 0.2908587257617729, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5033128745177367, 0.5079777536061114, 0.0, 1.0, 0.19598491113435212], 
reward next is 0.8040, 
noisyNet noise sample is [array([-0.2421515], dtype=float32), 1.6277379]. 
=============================================
[2019-04-06 19:25:59,533] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1297659e-10 3.5931976e-08 4.3298812e-10 1.6070426e-03 3.8740525e-11
 9.9839288e-01 1.1664352e-09], sum to 1.0000
[2019-04-06 19:25:59,533] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8515
[2019-04-06 19:25:59,606] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 68.0, 115.0, 822.0, 26.0, 26.42956469293616, 0.5864129895181054, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3756600.0000, 
sim time next is 3758400.0000, 
raw observation next is [-2.0, 65.0, 117.0, 825.5, 26.0, 26.47687868957619, 0.5986320575963427, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.40720221606648205, 0.65, 0.39, 0.9121546961325967, 0.6666666666666666, 0.7064065574646824, 0.6995440191987808, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9929644], dtype=float32), 0.71199197]. 
=============================================
[2019-04-06 19:26:17,549] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.0263172e-10 6.0719216e-08 4.5906187e-10 2.3483033e-03 3.8758156e-11
 9.9765164e-01 6.7261524e-10], sum to 1.0000
[2019-04-06 19:26:17,549] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6654
[2019-04-06 19:26:17,675] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.69256069548484, 0.231612183480021, 0.0, 1.0, 42974.46043282249], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1983600.0000, 
sim time next is 1985400.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.55878459860574, 0.2055935695747311, 0.0, 1.0, 42951.256443770006], 
processed observation next is [1.0, 1.0, 0.30747922437673136, 0.83, 0.0, 0.0, 0.6666666666666666, 0.546565383217145, 0.5685311898582437, 0.0, 1.0, 0.20452979258938098], 
reward next is 0.7955, 
noisyNet noise sample is [array([-1.6364125], dtype=float32), -1.3408734]. 
=============================================
[2019-04-06 19:26:17,787] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 19:26:17,787] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:26:17,788] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:26:17,801] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:26:17,801] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:26:17,803] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run50
[2019-04-06 19:26:17,914] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:26:17,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:26:17,931] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run50
[2019-04-06 19:26:18,023] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run50
[2019-04-06 19:27:49,589] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05429179], dtype=float32), 0.12739588]
[2019-04-06 19:27:49,589] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-0.8999999999999999, 85.0, 0.0, 0.0, 26.0, 24.98323078012751, 0.3633682249236067, 0.0, 1.0, 43605.256751664616]
[2019-04-06 19:27:49,590] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 19:27:49,590] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [7.6371097e-11 1.7449089e-08 3.1945713e-10 3.9958264e-04 3.2306238e-11
 9.9960047e-01 1.9002085e-10], sampled 0.8254099833186849
[2019-04-06 19:28:46,179] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05429179], dtype=float32), 0.12739588]
[2019-04-06 19:28:46,179] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [4.2, 43.0, 76.0, 135.5, 26.0, 25.89532535751088, 0.7147911174896339, 0.0, 1.0, 0.0]
[2019-04-06 19:28:46,179] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 19:28:46,180] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.8985852e-10 4.8465569e-08 8.7753027e-10 7.8272983e-04 1.3286913e-10
 9.9921715e-01 6.3358702e-10], sampled 0.3996283702913028
[2019-04-06 19:28:50,020] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 19:29:08,422] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05429179], dtype=float32), 0.12739588]
[2019-04-06 19:29:08,423] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-3.0, 50.0, 0.0, 0.0, 26.0, 24.92972765148836, 0.2053499065420542, 0.0, 1.0, 38701.0712483713]
[2019-04-06 19:29:08,423] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 19:29:08,423] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [9.6177588e-10 1.2888199e-07 3.8408015e-09 1.0924105e-03 4.1006387e-10
 9.9890745e-01 2.3918962e-09], sampled 0.46021721088597234
[2019-04-06 19:29:10,533] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 19:29:12,972] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 19:29:13,994] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 980000, evaluation results [980000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 19:29:31,388] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4426786e-09 6.6343154e-07 1.7266609e-08 1.0597246e-03 6.8124173e-10
 9.9893957e-01 1.2574227e-08], sum to 1.0000
[2019-04-06 19:29:31,388] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2654
[2019-04-06 19:29:31,443] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 53.0, 0.0, 0.0, 26.0, 24.13099443282784, 0.04506271701049594, 0.0, 1.0, 43524.008831276326], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2426400.0000, 
sim time next is 2428200.0000, 
raw observation next is [-7.55, 54.0, 0.0, 0.0, 26.0, 23.99200686395871, 0.01791843073349337, 0.0, 1.0, 43608.52043148115], 
processed observation next is [0.0, 0.08695652173913043, 0.25346260387811637, 0.54, 0.0, 0.0, 0.6666666666666666, 0.4993339053298926, 0.5059728102444978, 0.0, 1.0, 0.2076596211022912], 
reward next is 0.7923, 
noisyNet noise sample is [array([-0.69746566], dtype=float32), -2.0413268]. 
=============================================
[2019-04-06 19:29:40,532] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.0947911e-10 2.7883702e-08 2.1939739e-09 5.4901221e-04 8.6538771e-10
 9.9945098e-01 4.9229176e-10], sum to 1.0000
[2019-04-06 19:29:40,532] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6422
[2019-04-06 19:29:40,660] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.0, 40.0, 115.5, 798.5, 26.0, 26.56591163649881, 0.5814053621988381, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4014000.0000, 
sim time next is 4015800.0000, 
raw observation next is [-7.0, 38.5, 119.0, 816.0, 26.0, 26.45866945388077, 0.5827799361896371, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.2686980609418283, 0.385, 0.39666666666666667, 0.901657458563536, 0.6666666666666666, 0.7048891211567309, 0.6942599787298791, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9234408], dtype=float32), 0.071602695]. 
=============================================
[2019-04-06 19:29:47,065] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.4316479e-09 1.4184678e-06 1.6639412e-08 1.1210053e-02 4.7087634e-10
 9.8878855e-01 1.1696306e-08], sum to 1.0000
[2019-04-06 19:29:47,065] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6548
[2019-04-06 19:29:47,150] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 45.0, 0.0, 0.0, 26.0, 25.02193110140155, 0.3746252504897609, 0.0, 1.0, 135259.23249767502], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4822200.0000, 
sim time next is 4824000.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 26.0, 25.32697611990206, 0.4316866518792944, 0.0, 1.0, 64319.84333723544], 
processed observation next is [0.0, 0.8695652173913043, 0.4903047091412743, 0.47, 0.0, 0.0, 0.6666666666666666, 0.6105813433251717, 0.6438955506264314, 0.0, 1.0, 0.3062849682725497], 
reward next is 0.6937, 
noisyNet noise sample is [array([-2.9069412], dtype=float32), -1.2690961]. 
=============================================
[2019-04-06 19:29:47,158] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[78.18597 ]
 [76.938805]
 [76.772316]
 [76.687874]
 [76.478645]], R is [[78.60139465]
 [78.17129517]
 [78.25274658]
 [78.28591156]
 [78.29611206]].
[2019-04-06 19:29:48,796] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:29:48,796] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:29:48,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run23
[2019-04-06 19:29:51,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:29:51,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:29:51,036] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run23
[2019-04-06 19:29:54,961] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.13437586e-10 1.68138484e-07 6.57796795e-09 1.69355131e-03
 6.33530936e-11 9.98306274e-01 1.10478959e-09], sum to 1.0000
[2019-04-06 19:29:54,961] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3545
[2019-04-06 19:29:55,045] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 46.5, 0.0, 0.0, 26.0, 25.01437014004222, 0.1893786713032001, 0.0, 1.0, 38515.2076210402], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2518200.0000, 
sim time next is 2520000.0000, 
raw observation next is [-1.7, 49.0, 0.0, 0.0, 26.0, 24.97421041369274, 0.1690803763555357, 0.0, 1.0, 38403.0750156048], 
processed observation next is [1.0, 0.17391304347826086, 0.4155124653739613, 0.49, 0.0, 0.0, 0.6666666666666666, 0.5811842011410618, 0.5563601254518452, 0.0, 1.0, 0.18287178578859428], 
reward next is 0.8171, 
noisyNet noise sample is [array([-0.39856076], dtype=float32), -0.2377709]. 
=============================================
[2019-04-06 19:29:55,048] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[80.42927 ]
 [80.21494 ]
 [79.372215]
 [78.7214  ]
 [78.51379 ]], R is [[80.61789703]
 [80.62831879]
 [80.63802338]
 [80.64707947]
 [80.65526581]].
[2019-04-06 19:30:00,993] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:30:00,993] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:30:00,996] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run23
[2019-04-06 19:30:03,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:30:03,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:30:03,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run23
[2019-04-06 19:30:07,850] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4622920e-10 7.8290057e-08 2.8929239e-09 7.3273119e-04 2.0705763e-10
 9.9926716e-01 3.8635624e-09], sum to 1.0000
[2019-04-06 19:30:07,850] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3046
[2019-04-06 19:30:07,888] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.95486878349629, 0.2056499695810395, 0.0, 1.0, 42443.546578984824], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 680400.0000, 
sim time next is 682200.0000, 
raw observation next is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.85303713939475, 0.184685454245594, 0.0, 1.0, 42266.27803130492], 
processed observation next is [0.0, 0.9130434782608695, 0.368421052631579, 0.69, 0.0, 0.0, 0.6666666666666666, 0.5710864282828959, 0.5615618180818647, 0.0, 1.0, 0.20126799062526154], 
reward next is 0.7987, 
noisyNet noise sample is [array([0.29941717], dtype=float32), -1.2114382]. 
=============================================
[2019-04-06 19:30:09,598] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.37889275e-11 8.65027694e-09 2.23209540e-09 1.36145085e-04
 1.43522520e-11 9.99863863e-01 4.28447444e-10], sum to 1.0000
[2019-04-06 19:30:09,598] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7199
[2019-04-06 19:30:09,684] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 26.0, 24.64372066448442, 0.2656114594595926, 0.0, 1.0, 42839.11943902652], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2948400.0000, 
sim time next is 2950200.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 26.0, 24.55311439022909, 0.2481919612132223, 0.0, 1.0, 42681.233149028914], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.84, 0.0, 0.0, 0.6666666666666666, 0.5460928658524242, 0.5827306537377407, 0.0, 1.0, 0.20324396737632816], 
reward next is 0.7968, 
noisyNet noise sample is [array([-0.26691967], dtype=float32), 1.346777]. 
=============================================
[2019-04-06 19:30:09,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:30:09,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:30:09,794] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run23
[2019-04-06 19:30:24,349] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.08877504e-10 1.63275171e-08 6.63733457e-10 4.82275209e-04
 9.05595737e-11 9.99517679e-01 3.02410097e-10], sum to 1.0000
[2019-04-06 19:30:24,350] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2866
[2019-04-06 19:30:24,393] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 91.0, 0.0, 0.0, 26.0, 24.3714303086828, 0.1490428931985083, 0.0, 1.0, 40564.897596333765], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 90000.0000, 
sim time next is 91800.0000, 
raw observation next is [-1.15, 91.0, 0.0, 0.0, 26.0, 24.35063198306668, 0.1370149550293152, 0.0, 1.0, 41209.62650323311], 
processed observation next is [1.0, 0.043478260869565216, 0.4307479224376732, 0.91, 0.0, 0.0, 0.6666666666666666, 0.5292193319222234, 0.5456716516764384, 0.0, 1.0, 0.1962363166820624], 
reward next is 0.8038, 
noisyNet noise sample is [array([-2.3401577], dtype=float32), -0.09211887]. 
=============================================
[2019-04-06 19:30:33,135] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:30:33,135] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:30:33,146] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run23
[2019-04-06 19:30:44,043] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.7698518e-09 2.7025499e-07 1.0188875e-08 7.0391335e-03 8.2888024e-10
 9.9296051e-01 2.6995165e-08], sum to 1.0000
[2019-04-06 19:30:44,043] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1086
[2019-04-06 19:30:44,105] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.2, 55.0, 0.0, 0.0, 26.0, 23.34863172332612, -0.1233059803349223, 0.0, 1.0, 45687.48519501261], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 439200.0000, 
sim time next is 441000.0000, 
raw observation next is [-10.9, 52.0, 0.0, 0.0, 26.0, 23.26837652469059, -0.1430842112157391, 0.0, 1.0, 45835.482248736465], 
processed observation next is [1.0, 0.08695652173913043, 0.16066481994459833, 0.52, 0.0, 0.0, 0.6666666666666666, 0.4390313770575493, 0.452305262928087, 0.0, 1.0, 0.21826420118445936], 
reward next is 0.7817, 
noisyNet noise sample is [array([0.6228107], dtype=float32), -0.36130816]. 
=============================================
[2019-04-06 19:30:44,109] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[72.78238]
 [72.55796]
 [72.55209]
 [72.56984]
 [72.27208]], R is [[72.48728943]
 [72.54486084]
 [72.60277557]
 [72.66062164]
 [72.71869659]].
[2019-04-06 19:30:48,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:30:48,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:30:48,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run23
[2019-04-06 19:30:55,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.50203027e-11 1.11142739e-08 1.23276944e-09 1.01782585e-04
 2.57337068e-11 9.99898195e-01 1.17126558e-10], sum to 1.0000
[2019-04-06 19:30:55,014] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4156
[2019-04-06 19:30:55,104] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 55.5, 0.0, 0.0, 26.0, 25.28980104778433, 0.3499908693783726, 0.0, 1.0, 49199.76890654545], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5034600.0000, 
sim time next is 5036400.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.30367374545067, 0.3454453116383274, 0.0, 1.0, 37523.38476608632], 
processed observation next is [1.0, 0.30434782608695654, 0.3795013850415513, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6086394787875559, 0.6151484372127758, 0.0, 1.0, 0.17868278460041104], 
reward next is 0.8213, 
noisyNet noise sample is [array([1.0868492], dtype=float32), -0.28246507]. 
=============================================
[2019-04-06 19:30:58,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:30:58,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:30:58,850] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run23
[2019-04-06 19:31:41,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:31:41,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:31:41,196] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run23
[2019-04-06 19:31:41,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7034378e-10 1.8691705e-07 7.3117107e-10 6.1912984e-03 3.7036707e-10
 9.9380845e-01 1.4603946e-09], sum to 1.0000
[2019-04-06 19:31:41,320] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1821
[2019-04-06 19:31:41,455] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 71.0, 0.0, 0.0, 26.0, 24.08626046875003, 0.08904929802124084, 0.0, 1.0, 44962.07297796317], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 169200.0000, 
sim time next is 171000.0000, 
raw observation next is [-8.4, 71.0, 0.0, 0.0, 26.0, 23.95617247812843, 0.05982449196822043, 0.0, 1.0, 44810.475893032715], 
processed observation next is [1.0, 1.0, 0.2299168975069252, 0.71, 0.0, 0.0, 0.6666666666666666, 0.4963477065107025, 0.5199414973227402, 0.0, 1.0, 0.213383218538251], 
reward next is 0.7866, 
noisyNet noise sample is [array([-0.4873807], dtype=float32), 0.20310645]. 
=============================================
[2019-04-06 19:31:41,500] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[79.46623 ]
 [79.293686]
 [79.54869 ]
 [79.62804 ]
 [80.04802 ]], R is [[79.00169373]
 [78.99757385]
 [78.99290466]
 [78.98588562]
 [78.97776031]].
[2019-04-06 19:31:47,931] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 19:31:47,937] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:31:47,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:31:47,964] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:31:47,964] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:31:47,992] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:31:47,996] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run51
[2019-04-06 19:31:48,046] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run51
[2019-04-06 19:31:48,164] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:31:48,174] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run51
[2019-04-06 19:34:18,754] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.5648 79959984.5800 535.1579
[2019-04-06 19:34:37,611] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 19:34:40,182] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 19:34:41,204] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1000000, evaluation results [1000000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.564818314419, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 19:34:50,953] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.6916374e-10 3.6191178e-08 3.5512945e-10 5.0944523e-03 3.6832707e-11
 9.9490559e-01 4.7319065e-10], sum to 1.0000
[2019-04-06 19:34:50,954] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6012
[2019-04-06 19:34:51,009] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 26.0, 25.28020019699778, 0.5114929216778009, 0.0, 1.0, 47761.781591251616], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1378800.0000, 
sim time next is 1380600.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 26.0, 25.28773127941155, 0.5022372107894445, 0.0, 1.0, 41710.29427401493], 
processed observation next is [1.0, 1.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.6666666666666666, 0.6073109399509624, 0.6674124035964816, 0.0, 1.0, 0.19862044892388062], 
reward next is 0.8014, 
noisyNet noise sample is [array([0.23249765], dtype=float32), -1.3299226]. 
=============================================
[2019-04-06 19:34:52,076] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:34:52,076] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:34:52,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run23
[2019-04-06 19:34:55,371] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.04674465e-08 2.41222210e-07 1.24624258e-08 1.72569193e-02
 1.85865967e-09 9.82742786e-01 2.66472377e-09], sum to 1.0000
[2019-04-06 19:34:55,372] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5296
[2019-04-06 19:34:55,407] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 40.0, 0.0, 0.0, 26.0, 25.38001104967069, 0.3983179762922611, 0.0, 1.0, 58732.37986362897], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4910400.0000, 
sim time next is 4912200.0000, 
raw observation next is [1.0, 38.0, 0.0, 0.0, 26.0, 25.54324057653847, 0.3897209323935988, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.4903047091412743, 0.38, 0.0, 0.0, 0.6666666666666666, 0.6286033813782058, 0.629906977464533, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6259689], dtype=float32), 0.30723372]. 
=============================================
[2019-04-06 19:35:05,146] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:35:05,147] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:35:05,151] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run23
[2019-04-06 19:35:08,950] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.13980969e-09 1.16297684e-07 1.76424741e-09 1.95640561e-04
 3.40851687e-11 9.99804318e-01 2.03309347e-09], sum to 1.0000
[2019-04-06 19:35:08,950] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0132
[2019-04-06 19:35:09,025] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 60.0, 0.0, 0.0, 26.0, 25.10218947134354, 0.3016203911705981, 0.0, 1.0, 39141.64206453214], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4847400.0000, 
sim time next is 4849200.0000, 
raw observation next is [-3.0, 60.0, 0.0, 0.0, 26.0, 25.01586697539569, 0.2819200046254675, 0.0, 1.0, 39159.87431665755], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.6, 0.0, 0.0, 0.6666666666666666, 0.584655581282974, 0.5939733348751558, 0.0, 1.0, 0.1864755919840836], 
reward next is 0.8135, 
noisyNet noise sample is [array([-0.5488777], dtype=float32), -0.30090427]. 
=============================================
[2019-04-06 19:35:10,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:35:10,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:35:10,031] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run23
[2019-04-06 19:35:14,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:35:14,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:35:14,439] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run23
[2019-04-06 19:35:15,500] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:35:15,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:35:15,504] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run23
[2019-04-06 19:35:21,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:35:21,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:35:21,792] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run23
[2019-04-06 19:35:31,885] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0651242e-10 5.3125589e-08 7.4850454e-10 3.3517480e-03 2.5981650e-10
 9.9664813e-01 4.6305992e-10], sum to 1.0000
[2019-04-06 19:35:31,886] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8155
[2019-04-06 19:35:31,955] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.65, 76.0, 0.0, 0.0, 26.0, 24.08735019697966, 0.07843406833210599, 0.0, 1.0, 47079.46700939374], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 340200.0000, 
sim time next is 342000.0000, 
raw observation next is [-13.9, 70.0, 0.0, 0.0, 26.0, 23.91665674636515, 0.03456156769485059, 0.0, 1.0, 47078.34852789681], 
processed observation next is [1.0, 1.0, 0.07756232686980608, 0.7, 0.0, 0.0, 0.6666666666666666, 0.4930547288637624, 0.5115205225649502, 0.0, 1.0, 0.22418261203760384], 
reward next is 0.7758, 
noisyNet noise sample is [array([1.41957], dtype=float32), 1.6434171]. 
=============================================
[2019-04-06 19:35:31,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[75.98143 ]
 [76.009865]
 [76.005585]
 [75.97633 ]
 [76.09045 ]], R is [[75.34145355]
 [75.36385345]
 [75.38521576]
 [75.40539551]
 [75.44580841]].
[2019-04-06 19:35:38,249] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.2699031e-11 1.6282780e-08 1.3344805e-09 1.0816951e-03 6.9310516e-11
 9.9891829e-01 1.4151189e-10], sum to 1.0000
[2019-04-06 19:35:38,249] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9789
[2019-04-06 19:35:38,291] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.85, 74.5, 0.0, 0.0, 26.0, 23.47530526015477, -0.0409440720040778, 0.0, 1.0, 44371.310240631516], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 106200.0000, 
sim time next is 108000.0000, 
raw observation next is [-6.7, 75.0, 0.0, 0.0, 26.0, 23.31123246563119, -0.07065187662102267, 0.0, 1.0, 44895.85119651454], 
processed observation next is [1.0, 0.2608695652173913, 0.2770083102493075, 0.75, 0.0, 0.0, 0.6666666666666666, 0.4426027054692658, 0.4764493744596591, 0.0, 1.0, 0.21378976760245016], 
reward next is 0.7862, 
noisyNet noise sample is [array([0.34048322], dtype=float32), -1.3863915]. 
=============================================
[2019-04-06 19:35:38,294] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[81.89583]
 [82.95953]
 [84.02303]
 [84.98655]
 [85.8739 ]], R is [[80.80259705]
 [80.78328705]
 [80.76599884]
 [80.75017548]
 [80.73534393]].
[2019-04-06 19:35:42,606] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5003501e-09 4.0543469e-08 4.8415462e-08 4.2100390e-03 1.3158867e-09
 9.9578995e-01 8.5810186e-09], sum to 1.0000
[2019-04-06 19:35:42,607] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1696
[2019-04-06 19:35:42,812] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 28.0, 110.0, 0.0, 26.0, 25.29309381804628, 0.160693168235442, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 471600.0000, 
sim time next is 473400.0000, 
raw observation next is [-2.0, 26.5, 122.0, 0.0, 26.0, 25.12827208604327, 0.1385448183632547, 1.0, 1.0, 21270.081901965426], 
processed observation next is [1.0, 0.4782608695652174, 0.40720221606648205, 0.265, 0.4066666666666667, 0.0, 0.6666666666666666, 0.5940226738369393, 0.5461816061210849, 1.0, 1.0, 0.10128610429507345], 
reward next is 0.8987, 
noisyNet noise sample is [array([-0.6577883], dtype=float32), 0.5573607]. 
=============================================
[2019-04-06 19:35:45,625] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.4380361e-10 3.4320529e-08 2.9200142e-09 2.5346954e-03 5.5918943e-11
 9.9746525e-01 1.7837870e-10], sum to 1.0000
[2019-04-06 19:35:45,625] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0457
[2019-04-06 19:35:45,696] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 71.0, 0.0, 0.0, 26.0, 23.9550975115535, 0.05956478944515864, 0.0, 1.0, 44811.255683425734], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 171000.0000, 
sim time next is 172800.0000, 
raw observation next is [-8.4, 71.0, 0.0, 0.0, 26.0, 23.82990732156794, 0.03007569931532903, 0.0, 1.0, 44645.884561793384], 
processed observation next is [1.0, 0.0, 0.2299168975069252, 0.71, 0.0, 0.0, 0.6666666666666666, 0.4858256101306617, 0.5100252331051097, 0.0, 1.0, 0.2125994502942542], 
reward next is 0.7874, 
noisyNet noise sample is [array([-1.6691916], dtype=float32), 0.06817033]. 
=============================================
[2019-04-06 19:35:51,417] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4749367e-11 6.6317747e-09 9.6504534e-11 8.0754940e-04 2.1330524e-11
 9.9919242e-01 9.3954879e-11], sum to 1.0000
[2019-04-06 19:35:51,417] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4852
[2019-04-06 19:35:51,465] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 80.5, 0.0, 0.0, 26.0, 25.68059774911281, 0.5520716517138778, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1560600.0000, 
sim time next is 1562400.0000, 
raw observation next is [5.0, 79.0, 0.0, 0.0, 26.0, 25.43413442192882, 0.5186253966383201, 0.0, 1.0, 69540.766751563], 
processed observation next is [1.0, 0.08695652173913043, 0.6011080332409973, 0.79, 0.0, 0.0, 0.6666666666666666, 0.6195112018274017, 0.6728751322127734, 0.0, 1.0, 0.3311465083407762], 
reward next is 0.6689, 
noisyNet noise sample is [array([-0.287695], dtype=float32), 1.0627946]. 
=============================================
[2019-04-06 19:35:56,685] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0421069e-10 1.3212723e-07 1.3648405e-10 2.8147373e-02 2.4409221e-11
 9.7185248e-01 1.1768150e-10], sum to 1.0000
[2019-04-06 19:35:56,685] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1779
[2019-04-06 19:35:56,752] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.4, 93.0, 36.0, 0.0, 26.0, 25.80429893368935, 0.4057066860082339, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 921600.0000, 
sim time next is 923400.0000, 
raw observation next is [4.7, 92.5, 18.0, 0.0, 26.0, 25.72357548480072, 0.2908680021155182, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.592797783933518, 0.925, 0.06, 0.0, 0.6666666666666666, 0.64363129040006, 0.5969560007051727, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.43784893], dtype=float32), -0.21423078]. 
=============================================
[2019-04-06 19:36:31,779] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7809556e-11 2.4420697e-09 1.1296364e-12 2.4452078e-04 2.6108104e-12
 9.9975544e-01 2.5984218e-11], sum to 1.0000
[2019-04-06 19:36:31,779] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7814
[2019-04-06 19:36:32,035] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.8, 93.0, 93.0, 0.0, 26.0, 25.32518436896946, 0.385276021637901, 1.0, 1.0, 111077.1251516957], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 914400.0000, 
sim time next is 916200.0000, 
raw observation next is [4.1, 93.0, 90.0, 0.0, 26.0, 25.97486183322127, 0.3419626664910673, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5761772853185596, 0.93, 0.3, 0.0, 0.6666666666666666, 0.6645718194351057, 0.6139875554970224, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.860277], dtype=float32), 0.40733555]. 
=============================================
[2019-04-06 19:37:29,179] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5012622e-12 7.6929696e-10 4.4603514e-12 2.5344110e-04 2.6125504e-12
 9.9974650e-01 5.0777590e-12], sum to 1.0000
[2019-04-06 19:37:29,179] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4616
[2019-04-06 19:37:29,235] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.0, 100.0, 108.0, 746.0, 26.0, 26.89040471629321, 0.6987153005025308, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3148200.0000, 
sim time next is 3150000.0000, 
raw observation next is [7.0, 100.0, 111.0, 775.5, 26.0, 27.03661860448754, 0.7427995284861121, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.6565096952908588, 1.0, 0.37, 0.8569060773480663, 0.6666666666666666, 0.7530515503739617, 0.747599842828704, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9018438], dtype=float32), -0.04684154]. 
=============================================
[2019-04-06 19:37:29,247] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[98.67043 ]
 [98.75315 ]
 [98.58906 ]
 [98.07407 ]
 [97.605675]], R is [[99.2399292 ]
 [99.24752808]
 [99.25505066]
 [99.26250458]
 [99.2698822 ]].
[2019-04-06 19:37:31,252] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-06 19:37:31,253] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:37:31,253] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:37:31,261] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:37:31,261] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:37:31,267] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run52
[2019-04-06 19:37:31,327] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run52
[2019-04-06 19:37:31,446] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:37:31,447] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:37:31,460] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run52
[2019-04-06 19:37:56,658] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05538454], dtype=float32), 0.12822713]
[2019-04-06 19:37:56,658] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-4.5, 65.0, 139.0, 0.0, 26.0, 25.14385069628581, 0.2362619547458984, 1.0, 1.0, 47860.32258580718]
[2019-04-06 19:37:56,658] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 19:37:56,659] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [6.8273370e-10 9.1385928e-08 1.9312130e-09 1.6984973e-03 4.3574525e-10
 9.9830139e-01 2.0190243e-09], sampled 0.10897074832019771
[2019-04-06 19:40:05,334] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 19:40:23,836] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 19:40:26,497] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.5879 91914664.8318 409.3138
[2019-04-06 19:40:27,519] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 1020000, evaluation results [1020000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.5878639248335, 91914664.83175536, 409.3138131877596]
[2019-04-06 19:40:40,973] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2389517e-10 5.1365028e-08 1.0381335e-09 4.3780818e-03 6.0154763e-11
 9.9562186e-01 2.2980131e-09], sum to 1.0000
[2019-04-06 19:40:40,974] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5002
[2019-04-06 19:40:41,149] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 83.0, 122.5, 0.0, 26.0, 24.94534258944141, 0.345227818404622, 0.0, 1.0, 34803.67593069642], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1771200.0000, 
sim time next is 1773000.0000, 
raw observation next is [-2.55, 83.0, 126.0, 0.0, 26.0, 24.94465363246887, 0.3516515446275985, 0.0, 1.0, 45792.086220531906], 
processed observation next is [0.0, 0.5217391304347826, 0.3919667590027701, 0.83, 0.42, 0.0, 0.6666666666666666, 0.5787211360390726, 0.6172171815425328, 0.0, 1.0, 0.2180575534311043], 
reward next is 0.7819, 
noisyNet noise sample is [array([-1.0723761], dtype=float32), 1.0776087]. 
=============================================
[2019-04-06 19:40:41,160] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[83.11023]
 [83.39824]
 [83.46883]
 [83.338  ]
 [83.34506]], R is [[82.93054962]
 [82.93550873]
 [82.89925385]
 [82.82497406]
 [82.86724091]].
[2019-04-06 19:40:51,627] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:40:51,627] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:40:51,631] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run24
[2019-04-06 19:41:32,172] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9446909e-12 7.8687341e-09 8.0159879e-10 7.7666703e-04 1.2288057e-11
 9.9922335e-01 1.6287176e-10], sum to 1.0000
[2019-04-06 19:41:32,172] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6897
[2019-04-06 19:41:32,329] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 25.22024487085626, 0.3507956242875367, 0.0, 1.0, 46390.30955588387], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3481200.0000, 
sim time next is 3483000.0000, 
raw observation next is [-0.5, 71.5, 3.0, 107.0, 26.0, 25.37705207028172, 0.4032276070388975, 1.0, 1.0, 18408.674418333878], 
processed observation next is [1.0, 0.30434782608695654, 0.44875346260387816, 0.715, 0.01, 0.11823204419889503, 0.6666666666666666, 0.6147543391901434, 0.6344092023462992, 1.0, 1.0, 0.08766035437301846], 
reward next is 0.9123, 
noisyNet noise sample is [array([2.1821508], dtype=float32), -0.2886387]. 
=============================================
[2019-04-06 19:41:32,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[88.50202]
 [88.63727]
 [88.83653]
 [89.18527]
 [89.44861]], R is [[89.31655884]
 [89.20248413]
 [89.11165619]
 [89.02110291]
 [88.93127441]].
[2019-04-06 19:41:38,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:41:38,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:41:38,627] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run24
[2019-04-06 19:41:42,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:41:42,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:41:42,324] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run24
[2019-04-06 19:41:48,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:41:48,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:41:48,939] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run24
[2019-04-06 19:41:52,489] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:41:52,489] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:41:52,496] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run24
[2019-04-06 19:41:59,543] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.1904609e-11 4.6623768e-08 9.6719888e-10 1.0698366e-03 3.4993543e-11
 9.9893016e-01 2.0535362e-09], sum to 1.0000
[2019-04-06 19:41:59,543] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4855
[2019-04-06 19:41:59,686] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 61.0, 41.0, 4.5, 26.0, 25.37777015165775, 0.2564031532495906, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 118800.0000, 
sim time next is 120600.0000, 
raw observation next is [-7.8, 67.5, 45.0, 0.0, 26.0, 25.34654103053625, 0.2536974378709775, 1.0, 1.0, 6369.584883859913], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.675, 0.15, 0.0, 0.6666666666666666, 0.6122117525446876, 0.5845658126236591, 1.0, 1.0, 0.03033135658980911], 
reward next is 0.9697, 
noisyNet noise sample is [array([0.5295455], dtype=float32), 0.2001385]. 
=============================================
[2019-04-06 19:42:01,095] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4236994e-10 1.0007424e-08 7.0666079e-10 7.9463579e-04 3.1595310e-11
 9.9920541e-01 6.7039520e-11], sum to 1.0000
[2019-04-06 19:42:01,095] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5749
[2019-04-06 19:42:01,195] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 72.0, 0.0, 0.0, 26.0, 25.14584294954889, 0.3117778658472056, 0.0, 1.0, 47080.7769391998], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2851200.0000, 
sim time next is 2853000.0000, 
raw observation next is [1.0, 72.0, 0.0, 0.0, 26.0, 25.00591539544889, 0.3098522154547808, 0.0, 1.0, 55033.9853667088], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.72, 0.0, 0.0, 0.6666666666666666, 0.5838262829540742, 0.6032840718182603, 0.0, 1.0, 0.26206659698432766], 
reward next is 0.7379, 
noisyNet noise sample is [array([0.9536443], dtype=float32), 0.14685884]. 
=============================================
[2019-04-06 19:42:01,218] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[84.73226 ]
 [84.2016  ]
 [83.50659 ]
 [82.554375]
 [81.98503 ]], R is [[85.73727417]
 [85.65570831]
 [85.59308624]
 [85.48123169]
 [85.32575989]].
[2019-04-06 19:42:01,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:42:01,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:42:01,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run24
[2019-04-06 19:42:05,504] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6879634e-10 2.1634726e-06 3.2338257e-09 9.7152563e-03 7.2106326e-10
 9.9028254e-01 3.3304508e-09], sum to 1.0000
[2019-04-06 19:42:05,504] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3528
[2019-04-06 19:42:05,585] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.15, 87.0, 0.0, 0.0, 26.0, 24.73035002727073, 0.2330378840463251, 0.0, 1.0, 41364.75451221256], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 73800.0000, 
sim time next is 75600.0000, 
raw observation next is [1.6, 85.0, 0.0, 0.0, 26.0, 24.67008688684915, 0.2217246941043787, 0.0, 1.0, 40720.72396731137], 
processed observation next is [0.0, 0.9130434782608695, 0.5069252077562327, 0.85, 0.0, 0.0, 0.6666666666666666, 0.5558405739040957, 0.5739082313681262, 0.0, 1.0, 0.1939082093681494], 
reward next is 0.8061, 
noisyNet noise sample is [array([0.5768643], dtype=float32), -1.7667723]. 
=============================================
[2019-04-06 19:42:07,208] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4477422e-09 3.3095741e-08 5.0421658e-09 9.5082010e-04 4.7863691e-10
 9.9904913e-01 2.1419908e-09], sum to 1.0000
[2019-04-06 19:42:07,209] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5317
[2019-04-06 19:42:07,250] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.6, 67.0, 0.0, 0.0, 26.0, 23.02268296264678, -0.1679508014264516, 0.0, 1.0, 47405.04801607906], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 277200.0000, 
sim time next is 279000.0000, 
raw observation next is [-11.15, 68.5, 0.0, 0.0, 26.0, 22.90986310534367, -0.1891062892917156, 0.0, 1.0, 47717.944509345805], 
processed observation next is [1.0, 0.21739130434782608, 0.15373961218836565, 0.685, 0.0, 0.0, 0.6666666666666666, 0.4091552587786393, 0.43696457023609475, 0.0, 1.0, 0.22722830718736098], 
reward next is 0.7728, 
noisyNet noise sample is [array([0.7578428], dtype=float32), -0.7502166]. 
=============================================
[2019-04-06 19:42:07,254] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[77.53204 ]
 [78.33224 ]
 [78.98261 ]
 [79.74251 ]
 [80.674126]], R is [[76.72399139]
 [76.73101044]
 [76.74033356]
 [76.7521286 ]
 [76.76565552]].
[2019-04-06 19:42:31,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:42:31,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:42:31,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run24
[2019-04-06 19:42:54,411] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:42:54,411] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:42:54,415] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run24
[2019-04-06 19:43:01,608] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 19:43:01,613] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:43:01,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:43:01,631] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run53
[2019-04-06 19:43:01,696] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:43:01,696] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:43:01,701] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run53
[2019-04-06 19:43:01,705] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:43:01,705] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:43:01,797] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run53
[2019-04-06 19:45:18,683] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.05549327], dtype=float32), 0.12902708]
[2019-04-06 19:45:18,683] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-4.317829119, 96.86467401, 0.0, 0.0, 26.0, 24.14191057970131, 0.123404474907908, 0.0, 1.0, 42709.7334503637]
[2019-04-06 19:45:18,684] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 19:45:18,684] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.4423866e-10 2.9493602e-08 5.7942995e-10 1.0086447e-03 6.1303705e-11
 9.9899131e-01 3.4156220e-10], sampled 0.8442534731654048
[2019-04-06 19:45:18,798] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05549327], dtype=float32), 0.12902708]
[2019-04-06 19:45:18,799] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [8.2, 68.0, 124.5, 235.0, 26.0, 24.96647485772113, 0.4229150376209516, 0.0, 1.0, 12453.607780153694]
[2019-04-06 19:45:18,799] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 19:45:18,799] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [5.2523458e-11 1.7411148e-08 2.2940079e-10 1.2328312e-03 3.2523605e-11
 9.9876714e-01 1.6246983e-10], sampled 0.9732576019921113
[2019-04-06 19:45:35,440] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3885 79967197.3248 535.2671
[2019-04-06 19:45:55,587] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 19:45:57,408] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 19:45:58,431] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1040000, evaluation results [1040000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.388471443006, 79967197.3248232, 535.2671102210136, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 19:46:01,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8438266e-11 3.1918671e-07 9.3606078e-10 9.0681983e-04 1.2132204e-10
 9.9909282e-01 7.2627915e-10], sum to 1.0000
[2019-04-06 19:46:01,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1936
[2019-04-06 19:46:01,709] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 87.0, 0.0, 0.0, 26.0, 24.75767210812558, 0.3141055597989104, 0.0, 1.0, 44006.14890595938], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1753200.0000, 
sim time next is 1755000.0000, 
raw observation next is [-1.7, 87.0, 0.0, 0.0, 26.0, 24.70919968527295, 0.3070484568262454, 0.0, 1.0, 44044.67004863454], 
processed observation next is [0.0, 0.30434782608695654, 0.4155124653739613, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5590999737727458, 0.6023494856087485, 0.0, 1.0, 0.20973652404111687], 
reward next is 0.7903, 
noisyNet noise sample is [array([1.0108945], dtype=float32), -0.28141156]. 
=============================================
[2019-04-06 19:46:01,714] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[85.8467 ]
 [86.20454]
 [86.58984]
 [86.92039]
 [87.27675]], R is [[85.50009918]
 [85.43553925]
 [85.37207031]
 [85.31001282]
 [85.24926758]].
[2019-04-06 19:46:06,462] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:46:06,462] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:46:06,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run24
[2019-04-06 19:46:12,738] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.5203766e-11 1.1213030e-07 2.7707900e-09 6.1511318e-04 7.9239955e-11
 9.9938476e-01 5.9110439e-10], sum to 1.0000
[2019-04-06 19:46:12,739] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0664
[2019-04-06 19:46:12,794] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.65, 72.5, 0.0, 0.0, 26.0, 23.77452187090979, 0.01901254074779849, 0.0, 1.0, 44484.256425473715], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 174600.0000, 
sim time next is 176400.0000, 
raw observation next is [-8.9, 74.0, 0.0, 0.0, 26.0, 23.72503635443777, -0.007172114961741953, 0.0, 1.0, 44405.67304668463], 
processed observation next is [1.0, 0.043478260869565216, 0.21606648199445982, 0.74, 0.0, 0.0, 0.6666666666666666, 0.4770863628698141, 0.4976092950127527, 0.0, 1.0, 0.21145558593659347], 
reward next is 0.7885, 
noisyNet noise sample is [array([-1.3045446], dtype=float32), 0.88053954]. 
=============================================
[2019-04-06 19:46:17,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.3725066e-11 6.1029328e-09 2.8513556e-09 1.9655032e-03 3.9119996e-12
 9.9803454e-01 3.6410716e-10], sum to 1.0000
[2019-04-06 19:46:17,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5943
[2019-04-06 19:46:17,796] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 77.0, 0.0, 0.0, 26.0, 25.03445980696389, 0.3307139802111642, 0.0, 1.0, 36237.13586432126], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4604400.0000, 
sim time next is 4606200.0000, 
raw observation next is [-2.5, 74.0, 0.0, 0.0, 26.0, 25.09691386204256, 0.3641323225708768, 1.0, 1.0, 12093.232786801853], 
processed observation next is [1.0, 0.30434782608695654, 0.39335180055401664, 0.74, 0.0, 0.0, 0.6666666666666666, 0.5914094885035466, 0.6213774408569589, 1.0, 1.0, 0.057586822794294536], 
reward next is 0.9424, 
noisyNet noise sample is [array([-2.1801589], dtype=float32), -0.996743]. 
=============================================
[2019-04-06 19:46:19,332] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.78482729e-10 1.22564145e-08 1.31880373e-09 1.93965458e-03
 1.28936903e-10 9.98060286e-01 1.04044184e-09], sum to 1.0000
[2019-04-06 19:46:19,332] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2682
[2019-04-06 19:46:19,442] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.0, 40.0, 115.5, 798.5, 26.0, 26.56591163649881, 0.5814053621988381, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4014000.0000, 
sim time next is 4015800.0000, 
raw observation next is [-7.0, 38.5, 119.0, 816.0, 26.0, 26.45866945388077, 0.5827799361896371, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.2686980609418283, 0.385, 0.39666666666666667, 0.901657458563536, 0.6666666666666666, 0.7048891211567309, 0.6942599787298791, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.13121869], dtype=float32), -0.86555177]. 
=============================================
[2019-04-06 19:46:25,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:46:25,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:46:25,099] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run24
[2019-04-06 19:46:44,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:46:44,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:46:44,072] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run24
[2019-04-06 19:46:49,128] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.3250197e-11 9.9028213e-08 4.3832210e-10 3.6035724e-02 2.3327870e-10
 9.6396416e-01 7.6626411e-10], sum to 1.0000
[2019-04-06 19:46:49,128] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7173
[2019-04-06 19:46:49,293] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 121.5, 0.0, 26.0, 25.77868790887938, 0.4398329018031213, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4712400.0000, 
sim time next is 4714200.0000, 
raw observation next is [1.5, 79.5, 135.0, 0.0, 26.0, 24.3524001494254, 0.3894732343761459, 1.0, 1.0, 165826.2570278632], 
processed observation next is [1.0, 0.5652173913043478, 0.5041551246537397, 0.795, 0.45, 0.0, 0.6666666666666666, 0.5293666791187833, 0.6298244114587153, 1.0, 1.0, 0.7896488429898247], 
reward next is 0.2104, 
noisyNet noise sample is [array([-0.67066497], dtype=float32), 0.20519918]. 
=============================================
[2019-04-06 19:46:56,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:46:56,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:46:56,538] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run24
[2019-04-06 19:46:59,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:46:59,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:46:59,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run24
[2019-04-06 19:47:07,851] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:47:07,851] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:47:07,855] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run24
[2019-04-06 19:47:09,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:47:09,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:47:09,248] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run24
[2019-04-06 19:47:11,283] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0752004e-11 1.2407999e-08 3.3825573e-09 1.2341312e-03 1.4699892e-11
 9.9876583e-01 2.7924094e-10], sum to 1.0000
[2019-04-06 19:47:11,283] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0943
[2019-04-06 19:47:11,335] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.0, 20.0, 114.5, 839.5, 26.0, 27.52131170307823, 0.9527841666404541, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5061600.0000, 
sim time next is 5063400.0000, 
raw observation next is [11.5, 19.5, 111.0, 819.0, 26.0, 28.29822797726312, 1.057243774114189, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.7811634349030472, 0.195, 0.37, 0.9049723756906077, 0.6666666666666666, 0.8581856647719267, 0.8524145913713963, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6254299], dtype=float32), -0.9478606]. 
=============================================
[2019-04-06 19:47:12,224] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.20162599e-10 2.98489660e-08 9.35507158e-11 2.07832828e-03
 1.26589308e-10 9.97921646e-01 1.04839595e-10], sum to 1.0000
[2019-04-06 19:47:12,224] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0368
[2019-04-06 19:47:12,289] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 73.5, 0.0, 0.0, 26.0, 24.4003973064064, 0.08525708954478706, 0.0, 1.0, 41012.19822598254], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 696600.0000, 
sim time next is 698400.0000, 
raw observation next is [-3.4, 75.0, 0.0, 0.0, 26.0, 24.36276020201678, 0.07187817553484525, 0.0, 1.0, 41101.447391318514], 
processed observation next is [1.0, 0.08695652173913043, 0.368421052631579, 0.75, 0.0, 0.0, 0.6666666666666666, 0.5302300168347317, 0.5239593918449484, 0.0, 1.0, 0.1957211780538977], 
reward next is 0.8043, 
noisyNet noise sample is [array([0.5656865], dtype=float32), -0.41144136]. 
=============================================
[2019-04-06 19:47:13,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:47:13,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:47:13,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run24
[2019-04-06 19:47:14,830] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.9676354e-09 4.4771241e-07 6.9378146e-08 6.9634784e-03 1.7568162e-08
 9.9303597e-01 1.8815415e-08], sum to 1.0000
[2019-04-06 19:47:14,830] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7521
[2019-04-06 19:47:14,846] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [18.3, 65.0, 104.0, 0.0, 26.0, 25.04221103518655, 0.4970774331722702, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1177200.0000, 
sim time next is 1179000.0000, 
raw observation next is [18.55, 64.0, 80.0, 0.0, 26.0, 25.045771035041, 0.488817314077735, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.976454293628809, 0.64, 0.26666666666666666, 0.0, 0.6666666666666666, 0.5871475862534167, 0.6629391046925783, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2996547], dtype=float32), 0.18389034]. 
=============================================
[2019-04-06 19:47:14,854] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[74.73504]
 [74.91094]
 [75.09298]
 [75.29626]
 [75.50909]], R is [[74.83003998]
 [75.08174133]
 [75.33092499]
 [75.57761383]
 [75.82183838]].
[2019-04-06 19:47:25,871] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.3444826e-11 1.1856285e-08 1.6044696e-09 1.7451372e-03 1.6187307e-11
 9.9825484e-01 5.7278429e-11], sum to 1.0000
[2019-04-06 19:47:25,871] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1426
[2019-04-06 19:47:25,930] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.13805997751053, 0.05771806164269403, 0.0, 1.0, 41108.05848512557], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2008800.0000, 
sim time next is 2010600.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.03975449421284, 0.02393326081833424, 0.0, 1.0, 41156.831338213946], 
processed observation next is [1.0, 0.2608695652173913, 0.2908587257617729, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5033128745177367, 0.5079777536061114, 0.0, 1.0, 0.19598491113435212], 
reward next is 0.8040, 
noisyNet noise sample is [array([0.14441554], dtype=float32), -0.9135994]. 
=============================================
[2019-04-06 19:47:35,412] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.7843961e-14 2.1072166e-10 2.2098588e-12 3.6336216e-06 3.1818854e-13
 9.9999642e-01 5.2437509e-13], sum to 1.0000
[2019-04-06 19:47:35,413] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0256
[2019-04-06 19:47:35,488] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.05, 97.0, 0.0, 0.0, 26.0, 25.59157854665773, 0.5383218821252674, 0.0, 1.0, 22355.465072312643], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1661400.0000, 
sim time next is 1663200.0000, 
raw observation next is [5.5, 97.0, 0.0, 0.0, 26.0, 25.47898549740312, 0.5520948038697597, 0.0, 1.0, 64236.16253041645], 
processed observation next is [1.0, 0.2608695652173913, 0.6149584487534627, 0.97, 0.0, 0.0, 0.6666666666666666, 0.6232487914502599, 0.6840316012899198, 0.0, 1.0, 0.3058864882400783], 
reward next is 0.6941, 
noisyNet noise sample is [array([0.05400264], dtype=float32), -0.6012148]. 
=============================================
[2019-04-06 19:47:35,683] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3631617e-10 2.6100309e-07 1.6383060e-09 1.1056312e-02 1.6973771e-09
 9.8894346e-01 1.7103742e-08], sum to 1.0000
[2019-04-06 19:47:35,683] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5878
[2019-04-06 19:47:35,740] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [18.55, 49.5, 35.0, 0.0, 26.0, 27.85850073034734, 1.014135601800239, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1096200.0000, 
sim time next is 1098000.0000, 
raw observation next is [17.7, 50.0, 18.0, 1.5, 26.0, 27.96416594652597, 1.027870009688245, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.9529085872576178, 0.5, 0.06, 0.0016574585635359116, 0.6666666666666666, 0.8303471622104975, 0.8426233365627483, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.85906273], dtype=float32), -0.85227114]. 
=============================================
[2019-04-06 19:47:35,749] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[79.75318 ]
 [79.88166 ]
 [79.80712 ]
 [79.380714]
 [79.26553 ]], R is [[79.85649872]
 [80.05793762]
 [80.25736237]
 [80.45478821]
 [80.65023804]].
[2019-04-06 19:47:54,230] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3893552e-10 3.9957683e-08 7.9469844e-09 4.4367486e-03 3.3162337e-10
 9.9556327e-01 8.9129752e-09], sum to 1.0000
[2019-04-06 19:47:54,230] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9523
[2019-04-06 19:47:54,311] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 76.0, 0.0, 0.0, 26.0, 24.21220521382403, 0.02534724635991507, 0.0, 1.0, 41608.36463806755], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 711000.0000, 
sim time next is 712800.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 26.0, 24.27542184069005, 0.04177856570305385, 0.0, 1.0, 41708.68726847635], 
processed observation next is [1.0, 0.2608695652173913, 0.3988919667590028, 0.76, 0.0, 0.0, 0.6666666666666666, 0.5229518200575042, 0.5139261885676846, 0.0, 1.0, 0.19861279651655406], 
reward next is 0.8014, 
noisyNet noise sample is [array([-0.75733435], dtype=float32), -0.36212102]. 
=============================================
[2019-04-06 19:48:09,119] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0528425e-09 1.1374725e-07 2.7614431e-09 1.5085149e-01 1.0955534e-09
 8.4914839e-01 7.5919199e-10], sum to 1.0000
[2019-04-06 19:48:09,120] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9188
[2019-04-06 19:48:09,350] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 25.03506347668743, 0.4561416796046026, 0.0, 1.0, 84694.04040791461], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3528000.0000, 
sim time next is 3529800.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 25.09769264175263, 0.5143159978368382, 0.0, 1.0, 146310.81289030318], 
processed observation next is [1.0, 0.8695652173913043, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.5914743868127191, 0.6714386659456127, 0.0, 1.0, 0.6967181566204913], 
reward next is 0.3033, 
noisyNet noise sample is [array([-1.0728631], dtype=float32), 0.74925226]. 
=============================================
[2019-04-06 19:48:22,384] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5860258e-09 3.5124702e-07 2.5437927e-09 5.1910402e-03 3.3700148e-10
 9.9480861e-01 3.3745318e-09], sum to 1.0000
[2019-04-06 19:48:22,384] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2765
[2019-04-06 19:48:22,507] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.3, 26.0, 55.0, 479.5, 26.0, 24.9777583667717, 0.2701046636139358, 0.0, 1.0, 18697.909280715885], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2476800.0000, 
sim time next is 2478600.0000, 
raw observation next is [3.3, 25.5, 48.0, 279.0, 26.0, 24.96438680540848, 0.2668743133786895, 0.0, 1.0, 18698.178675535644], 
processed observation next is [0.0, 0.6956521739130435, 0.554016620498615, 0.255, 0.16, 0.3082872928176796, 0.6666666666666666, 0.5803655671173734, 0.5889581044595632, 0.0, 1.0, 0.08903894607397926], 
reward next is 0.9110, 
noisyNet noise sample is [array([-0.32231578], dtype=float32), 0.17521174]. 
=============================================
[2019-04-06 19:48:47,829] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-06 19:48:47,830] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:48:47,830] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:48:47,848] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:48:47,848] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:48:47,852] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run54
[2019-04-06 19:48:47,934] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:48:47,934] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:48:47,955] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run54
[2019-04-06 19:48:48,029] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run54
[2019-04-06 19:49:47,975] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05626687], dtype=float32), 0.12897219]
[2019-04-06 19:49:47,975] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-3.1, 67.0, 0.0, 0.0, 26.0, 25.02531972327649, 0.2196593718418808, 0.0, 1.0, 43213.08037453809]
[2019-04-06 19:49:47,975] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 19:49:47,976] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [6.5294342e-10 1.0051785e-07 2.4848694e-09 2.6707163e-03 3.2368636e-10
 9.9732924e-01 1.5486368e-09], sampled 0.06900929072698037
[2019-04-06 19:51:24,528] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2462 79987260.4995 535.2506
[2019-04-06 19:51:44,947] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 19:51:46,643] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2596 91948398.0424 409.3337
[2019-04-06 19:51:47,666] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1060000, evaluation results [1060000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.2461995019034, 79987260.49946941, 535.2506232687274, 2396.2596068800917, 91948398.04237857, 409.33365754853645]
[2019-04-06 19:51:49,792] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.8019905e-11 4.9169270e-08 1.0050054e-09 5.8321754e-04 5.6534596e-11
 9.9941671e-01 1.6452710e-09], sum to 1.0000
[2019-04-06 19:51:49,793] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5390
[2019-04-06 19:51:49,910] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 54.0, 0.0, 0.0, 26.0, 25.12940257565014, 0.3861925234122656, 1.0, 1.0, 40280.641095687], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2656800.0000, 
sim time next is 2658600.0000, 
raw observation next is [-0.8999999999999999, 57.0, 0.0, 0.0, 26.0, 25.16842581032091, 0.346421951251126, 1.0, 1.0, 22133.94453491987], 
processed observation next is [1.0, 0.782608695652174, 0.43767313019390586, 0.57, 0.0, 0.0, 0.6666666666666666, 0.5973688175267426, 0.6154739837503753, 1.0, 1.0, 0.1053997358805708], 
reward next is 0.8946, 
noisyNet noise sample is [array([-0.21193254], dtype=float32), -0.9846834]. 
=============================================
[2019-04-06 19:51:51,332] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5567684e-10 1.2107475e-08 2.6648628e-10 4.0299110e-03 9.7701625e-11
 9.9597013e-01 4.2670734e-10], sum to 1.0000
[2019-04-06 19:51:51,332] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4807
[2019-04-06 19:51:51,395] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 68.0, 0.0, 0.0, 26.0, 25.24353129099646, 0.4157177522781175, 0.0, 1.0, 53045.062438550696], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2235600.0000, 
sim time next is 2237400.0000, 
raw observation next is [-5.3, 69.5, 0.0, 0.0, 26.0, 25.28408674332292, 0.4094846065481109, 0.0, 1.0, 45521.43072477699], 
processed observation next is [1.0, 0.9130434782608695, 0.31578947368421056, 0.695, 0.0, 0.0, 0.6666666666666666, 0.6070072286102434, 0.6364948688493702, 0.0, 1.0, 0.2167687177370333], 
reward next is 0.7832, 
noisyNet noise sample is [array([0.7147155], dtype=float32), 0.59705514]. 
=============================================
[2019-04-06 19:52:16,362] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.10662271e-10 1.06506235e-08 1.65385844e-10 3.15402262e-03
 1.04062679e-11 9.96845901e-01 1.30742344e-11], sum to 1.0000
[2019-04-06 19:52:16,362] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5748
[2019-04-06 19:52:16,439] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.2, 92.0, 0.0, 0.0, 26.0, 25.40707344767688, 0.5492377065225342, 0.0, 1.0, 46335.770346097204], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1310400.0000, 
sim time next is 1312200.0000, 
raw observation next is [1.9, 92.0, 0.0, 0.0, 26.0, 25.47713721699239, 0.5540762232712787, 0.0, 1.0, 26985.323421189543], 
processed observation next is [1.0, 0.17391304347826086, 0.515235457063712, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6230947680826991, 0.6846920744237596, 0.0, 1.0, 0.1285015401009026], 
reward next is 0.8715, 
noisyNet noise sample is [array([-0.6890444], dtype=float32), 0.34448588]. 
=============================================
[2019-04-06 19:52:39,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:52:39,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:52:39,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run25
[2019-04-06 19:52:48,823] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1718620e-10 1.2995324e-07 3.0805358e-09 1.6339144e-02 1.3557616e-10
 9.8366064e-01 1.4100897e-09], sum to 1.0000
[2019-04-06 19:52:48,823] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0216
[2019-04-06 19:52:48,856] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 40.0, 0.0, 0.0, 26.0, 25.69765030801133, 0.5060209799775096, 1.0, 1.0, 13308.234145666249], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4131000.0000, 
sim time next is 4132800.0000, 
raw observation next is [1.0, 43.0, 0.0, 0.0, 26.0, 25.42829169157853, 0.4694982188736101, 0.0, 1.0, 28530.725465893116], 
processed observation next is [1.0, 0.8695652173913043, 0.4903047091412743, 0.43, 0.0, 0.0, 0.6666666666666666, 0.6190243076315441, 0.6564994062912034, 0.0, 1.0, 0.1358605974566339], 
reward next is 0.8641, 
noisyNet noise sample is [array([-0.3714811], dtype=float32), 1.0916604]. 
=============================================
[2019-04-06 19:52:53,730] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.5834498e-11 3.1318734e-08 6.2618410e-11 4.5043475e-04 3.8704043e-11
 9.9954957e-01 1.0134876e-10], sum to 1.0000
[2019-04-06 19:52:53,730] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5154
[2019-04-06 19:52:53,890] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 26.0, 25.51222313925607, 0.4275945113652811, 1.0, 1.0, 6239.0444574976], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2142000.0000, 
sim time next is 2143800.0000, 
raw observation next is [-5.3, 78.5, 0.0, 0.0, 26.0, 25.38064546644452, 0.3814161330258899, 0.0, 1.0, 30647.514239815937], 
processed observation next is [1.0, 0.8260869565217391, 0.31578947368421056, 0.785, 0.0, 0.0, 0.6666666666666666, 0.6150537888703766, 0.62713871100863, 0.0, 1.0, 0.1459405439991235], 
reward next is 0.8541, 
noisyNet noise sample is [array([-1.8704712], dtype=float32), -0.8306111]. 
=============================================
[2019-04-06 19:53:32,192] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:53:32,192] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:53:32,196] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run25
[2019-04-06 19:53:38,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:53:38,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:53:38,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run25
[2019-04-06 19:53:39,353] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4261117e-10 1.1545196e-07 5.5777107e-09 6.8440586e-03 3.1040950e-10
 9.9315578e-01 1.6779843e-09], sum to 1.0000
[2019-04-06 19:53:39,354] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7997
[2019-04-06 19:53:39,458] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 65.0, 0.0, 0.0, 26.0, 24.90289446620255, 0.3145620761235406, 0.0, 1.0, 40873.426508075696], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3560400.0000, 
sim time next is 3562200.0000, 
raw observation next is [-5.5, 67.5, 0.0, 0.0, 26.0, 24.7465652735936, 0.2917969960314624, 0.0, 1.0, 40879.24159154946], 
processed observation next is [0.0, 0.21739130434782608, 0.3102493074792244, 0.675, 0.0, 0.0, 0.6666666666666666, 0.5622137727994666, 0.5972656653438208, 0.0, 1.0, 0.19466305519785457], 
reward next is 0.8053, 
noisyNet noise sample is [array([-0.1973603], dtype=float32), 1.1339395]. 
=============================================
[2019-04-06 19:53:48,262] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:53:48,262] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:53:48,266] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run25
[2019-04-06 19:53:55,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:53:55,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:53:55,325] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run25
[2019-04-06 19:54:08,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:54:08,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:54:08,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run25
[2019-04-06 19:54:13,699] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 19:54:13,713] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:54:13,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:54:13,737] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:54:13,737] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:54:13,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run55
[2019-04-06 19:54:13,843] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run55
[2019-04-06 19:54:13,968] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:54:13,969] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:54:13,973] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run55
[2019-04-06 19:56:49,882] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3885 79967197.3248 535.2671
[2019-04-06 19:57:11,208] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 19:57:12,196] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.05604113], dtype=float32), 0.12996985]
[2019-04-06 19:57:12,196] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [10.501877768, 27.45470837, 49.25885636, 392.2095421, 26.0, 27.93349969239973, 0.9941837385731426, 1.0, 1.0, 0.0]
[2019-04-06 19:57:12,196] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 19:57:12,197] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.66340179e-11 1.07863878e-08 1.00245583e-10 5.97516191e-04
 2.14343283e-11 9.99402523e-01 1.14644225e-10], sampled 0.9212534432745955
[2019-04-06 19:57:12,330] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 19:57:13,352] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1080000, evaluation results [1080000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.388471443006, 79967197.3248232, 535.2671102210136, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 19:57:26,946] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7295730e-11 5.9457790e-09 1.7545927e-11 6.3096988e-05 2.4012272e-12
 9.9993694e-01 1.0044507e-10], sum to 1.0000
[2019-04-06 19:57:26,946] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6479
[2019-04-06 19:57:27,025] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.36092268538857, 0.343598101555377, 0.0, 1.0, 65782.84450803], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3099600.0000, 
sim time next is 3101400.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.3940070120379, 0.3473421495864902, 0.0, 1.0, 39429.11188222884], 
processed observation next is [0.0, 0.9130434782608695, 0.4349030470914128, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6161672510031583, 0.61578071652883, 0.0, 1.0, 0.18775767562966114], 
reward next is 0.8122, 
noisyNet noise sample is [array([-1.2919375], dtype=float32), 0.52915734]. 
=============================================
[2019-04-06 19:57:36,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:57:36,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:57:36,480] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run25
[2019-04-06 19:57:36,781] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:57:36,781] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:57:36,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run25
[2019-04-06 19:57:54,458] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.8207341e-10 1.5364930e-07 4.3734345e-09 2.3045842e-02 2.0586415e-10
 9.7695404e-01 2.2201356e-09], sum to 1.0000
[2019-04-06 19:57:54,458] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0875
[2019-04-06 19:57:54,509] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.5, 48.5, 87.0, 705.0, 26.0, 25.51941498399081, 0.4881972776262326, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3684600.0000, 
sim time next is 3686400.0000, 
raw observation next is [5.0, 50.0, 75.5, 613.5, 26.0, 25.49304729780676, 0.4776415467619023, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.6011080332409973, 0.5, 0.25166666666666665, 0.6779005524861879, 0.6666666666666666, 0.6244206081505634, 0.6592138489206341, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.011841], dtype=float32), 1.8298154]. 
=============================================
[2019-04-06 19:57:55,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:57:55,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:57:55,684] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run25
[2019-04-06 19:58:07,170] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9666829e-12 9.2343004e-09 3.0801264e-10 1.5396823e-04 1.8730557e-12
 9.9984598e-01 3.8462986e-11], sum to 1.0000
[2019-04-06 19:58:07,171] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5120
[2019-04-06 19:58:07,224] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 74.0, 0.0, 0.0, 26.0, 25.33085793636566, 0.3775121851072272, 0.0, 1.0, 40271.3549919922], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3904200.0000, 
sim time next is 3906000.0000, 
raw observation next is [-4.0, 77.0, 0.0, 0.0, 26.0, 25.23270954542609, 0.3544184390559098, 0.0, 1.0, 41340.853534352114], 
processed observation next is [1.0, 0.21739130434782608, 0.3518005540166205, 0.77, 0.0, 0.0, 0.6666666666666666, 0.6027257954521742, 0.6181394796853033, 0.0, 1.0, 0.19686120730643863], 
reward next is 0.8031, 
noisyNet noise sample is [array([-0.25082678], dtype=float32), 1.3225543]. 
=============================================
[2019-04-06 19:58:07,228] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[87.26428 ]
 [87.15512 ]
 [87.08263 ]
 [86.85928 ]
 [86.574425]], R is [[87.30844116]
 [87.24359131]
 [87.18135834]
 [87.01837921]
 [87.0068512 ]].
[2019-04-06 19:58:07,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:58:07,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:58:07,502] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run25
[2019-04-06 19:58:07,757] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8031776e-09 3.0599035e-06 2.2891689e-08 1.6137606e-02 4.0748862e-09
 9.8385936e-01 7.1348625e-09], sum to 1.0000
[2019-04-06 19:58:07,757] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8483
[2019-04-06 19:58:07,913] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.7, 41.0, 0.0, 0.0, 26.0, 25.02834591687204, 0.3188826164234378, 0.0, 1.0, 57688.13935449056], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4212000.0000, 
sim time next is 4213800.0000, 
raw observation next is [1.55, 41.5, 0.0, 0.0, 26.0, 25.03316562767169, 0.3072938291436379, 0.0, 1.0, 26925.121331423914], 
processed observation next is [0.0, 0.782608695652174, 0.5055401662049862, 0.415, 0.0, 0.0, 0.6666666666666666, 0.5860971356393074, 0.6024312763812126, 0.0, 1.0, 0.128214863482971], 
reward next is 0.8718, 
noisyNet noise sample is [array([0.59425557], dtype=float32), -0.76514035]. 
=============================================
[2019-04-06 19:58:15,992] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.3771261e-04 6.8958346e-03 1.1547467e-03 6.1687481e-02 6.3944224e-04
 9.2774886e-01 9.3587220e-04], sum to 1.0000
[2019-04-06 19:58:15,992] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6695
[2019-04-06 19:58:16,091] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.6, 95.5, 0.0, 0.0, 19.0, 18.69357862774905, -1.093296861457242, 0.0, 1.0, 51704.652975104815], 
current ob forecast is [], 
actual action is [20.0], 
sim time this is 1800.0000, 
sim time next is 3600.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 20.0, 19.06689536769832, -0.95494373999879, 0.0, 1.0, 144479.86856899265], 
processed observation next is [0.0, 0.043478260869565216, 0.662049861495845, 0.96, 0.0, 0.0, 0.16666666666666666, 0.08890794730819322, 0.18168542000040333, 0.0, 1.0, 0.6879993741380602], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.27797318], dtype=float32), -0.7352775]. 
=============================================
[2019-04-06 19:58:20,510] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.7090990e-12 2.5694646e-09 1.1455811e-10 3.5522468e-04 8.2184797e-12
 9.9964476e-01 3.7774808e-11], sum to 1.0000
[2019-04-06 19:58:20,510] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3059
[2019-04-06 19:58:20,730] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.9, 84.0, 50.0, 0.0, 26.0, 24.46259378192199, 0.1783520910273357, 0.0, 1.0, 47724.75234094206], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 55800.0000, 
sim time next is 57600.0000, 
raw observation next is [6.6, 82.0, 34.0, 0.0, 26.0, 24.55241772515879, 0.1827622786994275, 0.0, 1.0, 20743.654902988303], 
processed observation next is [0.0, 0.6956521739130435, 0.6454293628808865, 0.82, 0.11333333333333333, 0.0, 0.6666666666666666, 0.5460348104298992, 0.5609207595664758, 0.0, 1.0, 0.09877930906184906], 
reward next is 0.9012, 
noisyNet noise sample is [array([0.8793559], dtype=float32), -0.17065106]. 
=============================================
[2019-04-06 19:58:32,788] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:58:32,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:58:32,794] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run25
[2019-04-06 19:58:48,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:58:48,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:58:48,041] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run25
[2019-04-06 19:58:48,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:58:48,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:58:48,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run25
[2019-04-06 19:58:53,666] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.7774461e-11 8.3074916e-09 3.4494627e-10 4.2003088e-04 8.3534811e-11
 9.9957997e-01 3.1011976e-10], sum to 1.0000
[2019-04-06 19:58:53,667] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0156
[2019-04-06 19:58:53,740] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 45.0, 102.0, 317.0, 26.0, 25.21747103968977, 0.3725478846618929, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4897800.0000, 
sim time next is 4899600.0000, 
raw observation next is [3.0, 45.0, 67.5, 252.0, 26.0, 25.14416612682507, 0.3395420879280033, 0.0, 1.0, 6226.803890076847], 
processed observation next is [0.0, 0.7391304347826086, 0.5457063711911359, 0.45, 0.225, 0.27845303867403315, 0.6666666666666666, 0.5953471772354225, 0.6131806959760011, 0.0, 1.0, 0.029651447095604033], 
reward next is 0.9703, 
noisyNet noise sample is [array([-0.55924463], dtype=float32), 0.6812008]. 
=============================================
[2019-04-06 19:58:56,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4031062e-09 1.4466382e-07 2.6077718e-10 7.7642500e-04 1.5011838e-10
 9.9922347e-01 3.3774783e-09], sum to 1.0000
[2019-04-06 19:58:56,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9799
[2019-04-06 19:58:57,165] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8999999999999999, 55.5, 27.0, 15.0, 26.0, 24.88816834411265, 0.2118235446818274, 0.0, 1.0, 38833.514800953584], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 664200.0000, 
sim time next is 666000.0000, 
raw observation next is [-1.2, 57.0, 13.5, 8.5, 26.0, 24.87701618131871, 0.2133100491544616, 0.0, 1.0, 50116.65315980398], 
processed observation next is [0.0, 0.7391304347826086, 0.42936288088642666, 0.57, 0.045, 0.009392265193370166, 0.6666666666666666, 0.573084681776559, 0.5711033497181539, 0.0, 1.0, 0.23865072933239992], 
reward next is 0.7613, 
noisyNet noise sample is [array([-0.45297578], dtype=float32), 0.4778905]. 
=============================================
[2019-04-06 19:58:57,188] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.25767]
 [77.38584]
 [77.46415]
 [77.48336]
 [77.60215]], R is [[77.44950104]
 [77.49008179]
 [77.50182343]
 [77.57261658]
 [77.60652161]].
[2019-04-06 19:58:58,801] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2884721e-11 3.2804245e-08 2.9628333e-10 9.8743604e-04 5.1362543e-11
 9.9901247e-01 5.1169741e-10], sum to 1.0000
[2019-04-06 19:58:58,801] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5499
[2019-04-06 19:58:58,829] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.0, 23.0, 0.0, 0.0, 26.0, 26.32342122620019, 0.6623494498911211, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4993200.0000, 
sim time next is 4995000.0000, 
raw observation next is [6.0, 23.0, 0.0, 0.0, 26.0, 26.22363183191851, 0.6209345036504753, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.6288088642659281, 0.23, 0.0, 0.0, 0.6666666666666666, 0.6853026526598759, 0.7069781678834918, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4351281], dtype=float32), 0.122876965]. 
=============================================
[2019-04-06 19:58:58,839] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[83.091156]
 [83.556175]
 [84.82553 ]
 [85.758644]
 [86.35211 ]], R is [[81.66921997]
 [81.85253143]
 [82.03400421]
 [82.21366119]
 [82.39152527]].
[2019-04-06 19:59:04,636] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:59:04,636] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:59:04,710] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run25
[2019-04-06 19:59:06,052] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:59:06,052] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:59:06,056] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run25
[2019-04-06 19:59:09,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:59:09,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:59:09,408] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run25
[2019-04-06 19:59:55,259] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-06 19:59:55,260] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:59:55,260] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:59:55,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run56
[2019-04-06 19:59:55,331] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:59:55,332] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:59:55,336] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run56
[2019-04-06 19:59:55,441] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:59:55,441] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:59:55,498] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run56
[2019-04-06 20:02:23,268] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.05748722], dtype=float32), 0.12961595]
[2019-04-06 20:02:23,268] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-2.6449416605, 100.0, 0.0, 0.0, 26.0, 25.16542991904698, 0.4180406100115175, 0.0, 1.0, 40482.62278793679]
[2019-04-06 20:02:23,269] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 20:02:23,269] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.9623454e-11 4.6333928e-09 8.4669535e-11 2.4865221e-04 8.0016818e-12
 9.9975139e-01 4.7871651e-11], sampled 0.18837182190413992
[2019-04-06 20:02:32,535] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 20:02:51,685] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 20:02:55,585] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 20:02:56,607] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1100000, evaluation results [1100000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 20:03:00,582] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5651265e-12 1.1514566e-09 1.5393723e-11 1.5343462e-04 2.4810752e-12
 9.9984658e-01 4.8108441e-11], sum to 1.0000
[2019-04-06 20:03:00,582] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4676
[2019-04-06 20:03:00,633] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.6, 52.0, 76.0, 570.5, 26.0, 26.59934325803482, 0.7492587467748754, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1522800.0000, 
sim time next is 1524600.0000, 
raw observation next is [11.9, 51.0, 77.0, 478.0, 26.0, 26.64565434061007, 0.7562809618292756, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.7922437673130196, 0.51, 0.25666666666666665, 0.5281767955801105, 0.6666666666666666, 0.720471195050839, 0.7520936539430919, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.311962], dtype=float32), 1.5245816]. 
=============================================
[2019-04-06 20:03:02,594] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1466228e-10 2.3838286e-08 9.7012939e-11 4.2474407e-04 1.3247002e-10
 9.9957520e-01 1.0343578e-09], sum to 1.0000
[2019-04-06 20:03:02,594] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7048
[2019-04-06 20:03:02,852] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 49.5, 160.0, 0.0, 26.0, 24.97493198295167, 0.2913658895181717, 0.0, 1.0, 20536.494464620027], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2385000.0000, 
sim time next is 2386800.0000, 
raw observation next is [0.0, 47.0, 123.0, 170.5, 26.0, 24.9370314296676, 0.3037809761694005, 0.0, 1.0, 40071.96449388441], 
processed observation next is [0.0, 0.6521739130434783, 0.46260387811634357, 0.47, 0.41, 0.18839779005524862, 0.6666666666666666, 0.5780859524722999, 0.6012603253898002, 0.0, 1.0, 0.1908188785423067], 
reward next is 0.8092, 
noisyNet noise sample is [array([-1.0081961], dtype=float32), -1.3849461]. 
=============================================
[2019-04-06 20:03:04,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7980594e-13 1.0263420e-10 3.0283673e-12 7.1163529e-05 1.6486631e-12
 9.9992883e-01 9.2675199e-12], sum to 1.0000
[2019-04-06 20:03:04,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0208
[2019-04-06 20:03:04,147] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.2, 54.0, 25.5, 18.5, 26.0, 26.08202742299844, 0.712893538228387, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1616400.0000, 
sim time next is 1618200.0000, 
raw observation next is [11.35, 57.5, 0.0, 0.0, 26.0, 26.80886280212101, 0.7371826134265312, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.7770083102493075, 0.575, 0.0, 0.0, 0.6666666666666666, 0.7340719001767507, 0.7457275378088437, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6713452], dtype=float32), 0.088960126]. 
=============================================
[2019-04-06 20:03:08,240] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.4330689e-12 1.3008408e-09 2.7199876e-11 7.9501751e-06 1.3164546e-11
 9.9999201e-01 2.2976262e-11], sum to 1.0000
[2019-04-06 20:03:08,241] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0686
[2019-04-06 20:03:08,400] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.3, 70.0, 232.0, 10.0, 26.0, 25.71277014747887, 0.3022091877809206, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1942200.0000, 
sim time next is 1944000.0000, 
raw observation next is [-5.0, 65.0, 229.5, 7.0, 26.0, 25.68895625749398, 0.3449459525407813, 1.0, 1.0, 63157.88199816312], 
processed observation next is [1.0, 0.5217391304347826, 0.32409972299168976, 0.65, 0.765, 0.0077348066298342545, 0.6666666666666666, 0.640746354791165, 0.6149819841802605, 1.0, 1.0, 0.300751819038872], 
reward next is 0.6992, 
noisyNet noise sample is [array([0.39636958], dtype=float32), -1.5451574]. 
=============================================
[2019-04-06 20:03:08,404] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[80.57455 ]
 [81.45852 ]
 [81.56591 ]
 [81.601295]
 [81.73864 ]], R is [[80.71842194]
 [80.91123962]
 [81.10212708]
 [81.29110718]
 [81.3772049 ]].
[2019-04-06 20:03:13,796] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.2471927e-11 1.1592113e-08 2.0207634e-10 4.3027234e-04 6.6476227e-11
 9.9956971e-01 2.1975548e-10], sum to 1.0000
[2019-04-06 20:03:13,798] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0510
[2019-04-06 20:03:13,929] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.8, 84.5, 69.0, 0.0, 26.0, 25.50788034628935, 0.2841911672042438, 1.0, 1.0, 6241.487952887416], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2021400.0000, 
sim time next is 2023200.0000, 
raw observation next is [-5.6, 83.0, 85.5, 0.0, 26.0, 25.55203447368532, 0.2856966352467873, 1.0, 1.0, 23221.411018620347], 
processed observation next is [1.0, 0.43478260869565216, 0.30747922437673136, 0.83, 0.285, 0.0, 0.6666666666666666, 0.6293362061404434, 0.5952322117489292, 1.0, 1.0, 0.11057814770771594], 
reward next is 0.8894, 
noisyNet noise sample is [array([1.7801785], dtype=float32), 1.9914391]. 
=============================================
[2019-04-06 20:03:15,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6929414e-10 1.0532901e-07 2.9186771e-09 3.3926356e-03 8.3603158e-10
 9.9660730e-01 4.3305644e-09], sum to 1.0000
[2019-04-06 20:03:15,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3812
[2019-04-06 20:03:15,761] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 24.4960108266166, 0.1544406927818006, 0.0, 1.0, 38859.3650328936], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 885600.0000, 
sim time next is 887400.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 24.41645935052396, 0.1437951009507819, 0.0, 1.0, 38688.29013289749], 
processed observation next is [1.0, 0.2608695652173913, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.5347049458769968, 0.5479317003169273, 0.0, 1.0, 0.18422995301379758], 
reward next is 0.8158, 
noisyNet noise sample is [array([0.2960253], dtype=float32), 0.51864177]. 
=============================================
[2019-04-06 20:03:44,005] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2608154e-13 2.1511451e-10 2.7878880e-12 3.1555792e-05 4.7769883e-13
 9.9996841e-01 7.7481104e-13], sum to 1.0000
[2019-04-06 20:03:44,006] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7492
[2019-04-06 20:03:44,097] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.5, 70.0, 184.0, 107.5, 26.0, 27.25627117994822, 0.9072228599497213, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1076400.0000, 
sim time next is 1078200.0000, 
raw observation next is [16.05, 67.5, 254.0, 215.0, 26.0, 27.48251350326041, 0.6451802355916257, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.9072022160664821, 0.675, 0.8466666666666667, 0.23756906077348067, 0.6666666666666666, 0.7902094586050342, 0.7150600785305419, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.01259127], dtype=float32), 1.5559417]. 
=============================================
[2019-04-06 20:03:52,780] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.5747854e-11 6.9911348e-09 6.6255879e-10 4.5901290e-04 6.6407414e-11
 9.9954104e-01 1.6581370e-10], sum to 1.0000
[2019-04-06 20:03:52,780] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9308
[2019-04-06 20:03:52,841] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 26.0, 25.14664953271598, 0.3208038920991313, 0.0, 1.0, 39036.86097715297], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3016800.0000, 
sim time next is 3018600.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 26.0, 25.11651660741074, 0.3075667506177209, 0.0, 1.0, 38647.044897021595], 
processed observation next is [0.0, 0.9565217391304348, 0.3518005540166205, 0.65, 0.0, 0.0, 0.6666666666666666, 0.5930430506175618, 0.602522250205907, 0.0, 1.0, 0.18403354712867426], 
reward next is 0.8160, 
noisyNet noise sample is [array([-0.78917974], dtype=float32), -0.27903998]. 
=============================================
[2019-04-06 20:04:05,577] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.36903697e-10 8.29569036e-09 1.02103256e-10 8.36180348e-04
 2.56027949e-10 9.99163866e-01 3.09456627e-10], sum to 1.0000
[2019-04-06 20:04:05,577] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1163
[2019-04-06 20:04:05,664] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.4, 55.0, 102.0, 733.0, 26.0, 26.71360305330706, 0.6604479534888882, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2730600.0000, 
sim time next is 2732400.0000, 
raw observation next is [-4.0, 54.0, 94.0, 673.5, 26.0, 26.03710124918757, 0.5715649199430146, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.3518005540166205, 0.54, 0.31333333333333335, 0.7441988950276243, 0.6666666666666666, 0.6697584374322977, 0.6905216399810049, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.12306396], dtype=float32), 1.4527436]. 
=============================================
[2019-04-06 20:04:12,778] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9631658e-11 1.8415306e-09 1.4637580e-10 1.6952663e-04 6.0469425e-12
 9.9983048e-01 2.4252376e-11], sum to 1.0000
[2019-04-06 20:04:12,779] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7303
[2019-04-06 20:04:12,838] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 85.0, 0.0, 0.0, 26.0, 25.03447141501843, 0.3801653565444728, 0.0, 1.0, 43326.82654633067], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1744200.0000, 
sim time next is 1746000.0000, 
raw observation next is [-0.6, 83.0, 0.0, 0.0, 26.0, 24.97827663177165, 0.3670123059693582, 0.0, 1.0, 43468.549499592445], 
processed observation next is [0.0, 0.21739130434782608, 0.44598337950138506, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5815230526476375, 0.6223374353231194, 0.0, 1.0, 0.20699309285520212], 
reward next is 0.7930, 
noisyNet noise sample is [array([-0.5322291], dtype=float32), -0.31830955]. 
=============================================
[2019-04-06 20:04:12,845] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[86.92389 ]
 [87.401825]
 [87.81151 ]
 [88.10433 ]
 [88.10112 ]], R is [[86.34349823]
 [86.27374268]
 [86.20531464]
 [86.13812256]
 [86.072052  ]].
[2019-04-06 20:04:13,855] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5311728e-11 8.3991897e-10 9.2266316e-12 1.6884084e-04 7.6834605e-13
 9.9983108e-01 1.7108301e-11], sum to 1.0000
[2019-04-06 20:04:13,856] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1776
[2019-04-06 20:04:13,997] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 93.0, 52.5, 91.5, 26.0, 24.98842371852726, 0.253854084539368, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2880000.0000, 
sim time next is 2881800.0000, 
raw observation next is [1.5, 93.0, 105.0, 156.0, 26.0, 25.08078242628812, 0.3143476209099918, 1.0, 1.0, 35846.19611820005], 
processed observation next is [1.0, 0.34782608695652173, 0.5041551246537397, 0.93, 0.35, 0.1723756906077348, 0.6666666666666666, 0.5900652021906767, 0.6047825403033306, 1.0, 1.0, 0.1706961719914288], 
reward next is 0.8293, 
noisyNet noise sample is [array([0.6237914], dtype=float32), 0.28551447]. 
=============================================
[2019-04-06 20:04:26,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:04:26,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:04:26,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run26
[2019-04-06 20:04:52,543] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5785288e-10 3.1636446e-08 8.5526569e-10 3.1351930e-04 1.6737386e-11
 9.9968648e-01 1.4532003e-09], sum to 1.0000
[2019-04-06 20:04:52,543] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8960
[2019-04-06 20:04:52,665] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.5, 70.0, 3.0, 121.0, 26.0, 24.28499659213479, 0.190301685303057, 0.0, 1.0, 41448.820539610366], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3569400.0000, 
sim time next is 3571200.0000, 
raw observation next is [-7.0, 70.0, 45.5, 273.0, 26.0, 24.20483961964074, 0.1987446204206891, 0.0, 1.0, 41493.96885949317], 
processed observation next is [0.0, 0.34782608695652173, 0.2686980609418283, 0.7, 0.15166666666666667, 0.30165745856353593, 0.6666666666666666, 0.517069968303395, 0.5662482068068964, 0.0, 1.0, 0.19759032790234843], 
reward next is 0.8024, 
noisyNet noise sample is [array([-0.10377857], dtype=float32), -0.13217333]. 
=============================================
[2019-04-06 20:05:22,473] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1119062: loss 1.0902
[2019-04-06 20:05:22,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1119062: learning rate 0.0000
[2019-04-06 20:05:32,399] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 20:05:32,408] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:05:32,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:05:32,411] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:05:32,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:05:32,448] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run57
[2019-04-06 20:05:32,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run57
[2019-04-06 20:05:32,441] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:05:32,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:05:32,564] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run57
[2019-04-06 20:08:04,538] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 20:08:11,260] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.05710941], dtype=float32), 0.13032098]
[2019-04-06 20:08:11,260] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-2.629681945, 41.64125651, 124.27894845, 677.6225492, 26.0, 25.95684584557387, 0.5028943447898291, 0.0, 1.0, 0.0]
[2019-04-06 20:08:11,260] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 20:08:11,261] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [5.4482746e-10 6.9811215e-08 1.9084367e-09 8.1664155e-04 2.4312158e-10
 9.9918324e-01 1.0962576e-09], sampled 0.09939964626351527
[2019-04-06 20:08:24,676] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 20:08:25,000] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 20:08:26,022] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 1120000, evaluation results [1120000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 20:08:26,270] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3094295e-09 7.1694387e-08 3.2325902e-09 2.2176523e-03 9.9023767e-10
 9.9778229e-01 2.6645546e-09], sum to 1.0000
[2019-04-06 20:08:26,270] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5166
[2019-04-06 20:08:26,330] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 78.0, 0.0, 0.0, 26.0, 25.47277622334502, 0.4758369423317878, 1.0, 1.0, 19092.729031546678], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4730400.0000, 
sim time next is 4732200.0000, 
raw observation next is [-0.5, 78.0, 0.0, 0.0, 26.0, 25.29608925911901, 0.4381451884449509, 1.0, 1.0, 24592.031234396494], 
processed observation next is [1.0, 0.782608695652174, 0.44875346260387816, 0.78, 0.0, 0.0, 0.6666666666666666, 0.6080074382599175, 0.6460483961483169, 1.0, 1.0, 0.11710491063998331], 
reward next is 0.8829, 
noisyNet noise sample is [array([0.3741496], dtype=float32), 0.2849533]. 
=============================================
[2019-04-06 20:08:35,233] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:08:35,234] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:08:35,238] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run26
[2019-04-06 20:08:35,308] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.5338848e-10 4.4224763e-08 6.4912392e-10 2.3080339e-04 2.3087775e-10
 9.9976915e-01 1.7022763e-09], sum to 1.0000
[2019-04-06 20:08:35,308] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0485
[2019-04-06 20:08:35,371] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 42.0, 0.0, 0.0, 26.0, 25.10599215965886, 0.2782895728653361, 0.0, 1.0, 43142.207474303556], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2408400.0000, 
sim time next is 2410200.0000, 
raw observation next is [-3.95, 43.0, 0.0, 0.0, 26.0, 25.08302442326526, 0.2547449836129242, 0.0, 1.0, 43039.23730896957], 
processed observation next is [0.0, 0.9130434782608695, 0.3531855955678671, 0.43, 0.0, 0.0, 0.6666666666666666, 0.5902520352721051, 0.5849149945376414, 0.0, 1.0, 0.20494874909033128], 
reward next is 0.7951, 
noisyNet noise sample is [array([0.3489045], dtype=float32), 1.2694651]. 
=============================================
[2019-04-06 20:08:40,187] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8210994e-11 3.6798251e-09 2.0000901e-10 2.6883479e-04 9.1901493e-11
 9.9973112e-01 2.2348479e-10], sum to 1.0000
[2019-04-06 20:08:40,187] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7781
[2019-04-06 20:08:40,335] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 59.0, 0.0, 0.0, 26.0, 25.19700174799399, 0.4040963297201236, 1.0, 1.0, 67112.69864454605], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2746800.0000, 
sim time next is 2748600.0000, 
raw observation next is [-5.0, 59.0, 0.0, 0.0, 26.0, 25.11098199006575, 0.3914203512781357, 1.0, 1.0, 72986.23016978013], 
processed observation next is [1.0, 0.8260869565217391, 0.32409972299168976, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5925818325054791, 0.6304734504260452, 1.0, 1.0, 0.347553476998953], 
reward next is 0.6524, 
noisyNet noise sample is [array([-0.01534046], dtype=float32), -1.3761016]. 
=============================================
[2019-04-06 20:08:45,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:08:45,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:08:45,684] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run26
[2019-04-06 20:08:50,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:08:50,903] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:08:50,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run26
[2019-04-06 20:08:52,744] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:08:52,744] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:08:52,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run26
[2019-04-06 20:08:58,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:08:58,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:08:58,780] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run26
[2019-04-06 20:09:12,283] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4921493e-12 5.9669125e-10 3.2812965e-12 1.5334353e-03 5.1348843e-12
 9.9846661e-01 3.6853996e-12], sum to 1.0000
[2019-04-06 20:09:12,283] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7050
[2019-04-06 20:09:12,310] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 26.0, 25.77412938651967, 0.5305121336836213, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1017000.0000, 
sim time next is 1018800.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 26.0, 25.58436454402348, 0.5173942298570683, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.8614958448753465, 0.81, 0.0, 0.0, 0.6666666666666666, 0.6320303786686233, 0.6724647432856895, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.13738006], dtype=float32), -0.6761218]. 
=============================================
[2019-04-06 20:09:13,079] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1126666: loss 1.2879
[2019-04-06 20:09:13,080] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1126666: learning rate 0.0000
[2019-04-06 20:09:15,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:09:15,354] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:09:15,358] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run26
[2019-04-06 20:09:18,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:09:18,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:09:18,564] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run26
[2019-04-06 20:09:19,833] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1127633: loss 47.8689
[2019-04-06 20:09:19,833] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1127633: learning rate 0.0000
[2019-04-06 20:09:25,203] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1128303: loss 1.0711
[2019-04-06 20:09:25,203] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1128303: learning rate 0.0000
[2019-04-06 20:09:30,156] A3C_AGENT_WORKER-Thread-5 INFO:Local step 71000, global step 1129012: loss 1.0665
[2019-04-06 20:09:30,157] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 71000, global step 1129012: learning rate 0.0000
[2019-04-06 20:09:32,506] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1129365: loss 1.0229
[2019-04-06 20:09:32,508] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1129365: learning rate 0.0000
[2019-04-06 20:09:35,527] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0664143e-12 2.6683609e-09 8.3587148e-12 4.8895119e-05 1.1150087e-12
 9.9995112e-01 6.4812539e-12], sum to 1.0000
[2019-04-06 20:09:35,527] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8355
[2019-04-06 20:09:35,611] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.36290277390425, 0.3459303169926668, 0.0, 1.0, 41238.41344175023], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3727800.0000, 
sim time next is 3729600.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.35882300479779, 0.3341321401568108, 0.0, 1.0, 36673.611234303666], 
processed observation next is [1.0, 0.17391304347826086, 0.3795013850415513, 0.65, 0.0, 0.0, 0.6666666666666666, 0.613235250399816, 0.6113773800522703, 0.0, 1.0, 0.1746362439728746], 
reward next is 0.8254, 
noisyNet noise sample is [array([-1.459303], dtype=float32), 0.46248]. 
=============================================
[2019-04-06 20:09:36,802] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1130015: loss 0.9940
[2019-04-06 20:09:36,802] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1130015: learning rate 0.0000
[2019-04-06 20:09:37,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:09:37,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:09:37,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run26
[2019-04-06 20:09:47,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5333099e-12 3.0353047e-09 4.9550125e-12 1.6866338e-04 1.1599148e-12
 9.9983132e-01 1.4233066e-11], sum to 1.0000
[2019-04-06 20:09:47,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6466
[2019-04-06 20:09:47,499] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 68.0, 0.0, 0.0, 26.0, 25.55757847594083, 0.5177421987567605, 0.0, 1.0, 35560.08208497379], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4428000.0000, 
sim time next is 4429800.0000, 
raw observation next is [2.5, 74.0, 0.0, 0.0, 26.0, 25.50549092837258, 0.5215598352460594, 0.0, 1.0, 53610.278153832325], 
processed observation next is [1.0, 0.2608695652173913, 0.5318559556786704, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6254575773643817, 0.6738532784153531, 0.0, 1.0, 0.255287038827773], 
reward next is 0.7447, 
noisyNet noise sample is [array([-0.3155799], dtype=float32), -0.9916345]. 
=============================================
[2019-04-06 20:09:51,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:09:51,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:09:51,592] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run26
[2019-04-06 20:09:54,181] A3C_AGENT_WORKER-Thread-6 INFO:Local step 71000, global step 1132499: loss 1.0635
[2019-04-06 20:09:54,184] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 71000, global step 1132499: learning rate 0.0000
[2019-04-06 20:09:55,125] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1132619: loss 1.0889
[2019-04-06 20:09:55,141] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1132619: learning rate 0.0000
[2019-04-06 20:10:01,673] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.3317641e-13 1.6349395e-09 3.6555779e-11 2.3980661e-05 1.5390122e-13
 9.9997604e-01 1.4664094e-12], sum to 1.0000
[2019-04-06 20:10:01,673] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4380
[2019-04-06 20:10:01,713] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.1, 76.5, 0.0, 0.0, 26.0, 25.98255608218427, 0.6082810337642185, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1042200.0000, 
sim time next is 1044000.0000, 
raw observation next is [13.8, 78.0, 0.0, 0.0, 26.0, 25.75338101221673, 0.5766470308466106, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.844875346260388, 0.78, 0.0, 0.0, 0.6666666666666666, 0.6461150843513943, 0.6922156769488702, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0982774], dtype=float32), -1.8865443]. 
=============================================
[2019-04-06 20:10:01,717] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[100.88588 ]
 [100.63706 ]
 [100.49268 ]
 [100.150925]
 [ 99.924995]], R is [[101.04523468]
 [101.03478241]
 [101.02443695]
 [100.98445892]
 [100.71659851]].
[2019-04-06 20:10:07,784] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1134517: loss 47.3513
[2019-04-06 20:10:07,784] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1134517: learning rate 0.0000
[2019-04-06 20:10:15,297] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1135357: loss 1.0074
[2019-04-06 20:10:15,298] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1135357: learning rate 0.0000
[2019-04-06 20:10:20,584] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1135888: loss 47.8255
[2019-04-06 20:10:20,585] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1135888: learning rate 0.0000
[2019-04-06 20:10:22,513] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1136074: loss 2.1727
[2019-04-06 20:10:22,514] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1136074: learning rate 0.0000
[2019-04-06 20:10:25,568] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:10:25,568] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:10:25,592] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run26
[2019-04-06 20:10:32,081] A3C_AGENT_WORKER-Thread-5 INFO:Local step 71500, global step 1137046: loss 47.1741
[2019-04-06 20:10:32,081] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 71500, global step 1137046: learning rate 0.0000
[2019-04-06 20:10:33,569] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.1264036e-12 1.1957102e-08 3.1728061e-11 3.9143681e-05 1.0099224e-11
 9.9996090e-01 7.7185125e-12], sum to 1.0000
[2019-04-06 20:10:33,582] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3211
[2019-04-06 20:10:33,770] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.8, 76.0, 0.0, 0.0, 26.0, 25.50574536854075, 0.4144086941815637, 0.0, 1.0, 65727.14733790683], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4312800.0000, 
sim time next is 4314600.0000, 
raw observation next is [4.6, 75.5, 0.0, 0.0, 26.0, 25.51600948862468, 0.418101007912997, 0.0, 1.0, 37193.33194457283], 
processed observation next is [0.0, 0.9565217391304348, 0.590027700831025, 0.755, 0.0, 0.0, 0.6666666666666666, 0.6263341240520566, 0.6393670026376657, 0.0, 1.0, 0.17711110449796585], 
reward next is 0.8229, 
noisyNet noise sample is [array([0.8682895], dtype=float32), -0.27010334]. 
=============================================
[2019-04-06 20:10:37,209] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1137563: loss 47.0955
[2019-04-06 20:10:37,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1137563: learning rate 0.0000
[2019-04-06 20:10:43,009] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1138165: loss 48.0978
[2019-04-06 20:10:43,009] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1138165: learning rate 0.0000
[2019-04-06 20:10:44,298] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1138303: loss 1.1185
[2019-04-06 20:10:44,298] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1138303: learning rate 0.0000
[2019-04-06 20:11:01,574] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:11:01,574] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:11:01,578] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run26
[2019-04-06 20:11:01,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:11:01,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:11:01,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run26
[2019-04-06 20:11:03,044] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-06 20:11:03,044] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:11:03,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:11:03,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run58
[2019-04-06 20:11:03,049] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:11:03,049] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:11:03,053] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run58
[2019-04-06 20:11:03,247] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:11:03,247] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:11:03,251] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run58
[2019-04-06 20:12:07,193] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.05796244], dtype=float32), 0.13081911]
[2019-04-06 20:12:07,193] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-1.2962168625, 82.1429262, 0.0, 0.0, 26.0, 24.98198413133714, 0.2532389392099121, 0.0, 1.0, 6252.0524286315995]
[2019-04-06 20:12:07,193] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 20:12:07,194] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.5560088e-10 2.8309895e-08 4.5528328e-10 6.0241838e-04 8.3016427e-11
 9.9939752e-01 4.1606896e-10], sampled 0.21074801989460978
[2019-04-06 20:13:00,592] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05796244], dtype=float32), 0.13081911]
[2019-04-06 20:13:00,592] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-0.6, 49.0, 23.0, 0.0, 26.0, 25.72903004241165, 0.2707561817074189, 1.0, 1.0, 0.0]
[2019-04-06 20:13:00,592] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 20:13:00,593] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.1229293e-10 3.8338666e-08 6.8439909e-10 5.9476297e-04 1.5883911e-10
 9.9940515e-01 7.5939371e-10], sampled 0.4297703412656717
[2019-04-06 20:13:36,003] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3885 79967197.3248 535.2671
[2019-04-06 20:13:42,368] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.05796244], dtype=float32), 0.13081911]
[2019-04-06 20:13:42,368] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [2.522637681, 34.19778596, 60.807806445, 730.5990658999999, 26.0, 26.50763583490971, 0.644326675236127, 1.0, 1.0, 0.0]
[2019-04-06 20:13:42,368] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 20:13:42,369] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.0842339e-10 2.6296368e-08 4.2342529e-10 4.8859190e-04 9.5552906e-11
 9.9951136e-01 4.2529746e-10], sampled 0.7334508246859939
[2019-04-06 20:13:54,578] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 20:13:57,210] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 20:13:58,233] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1140000, evaluation results [1140000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.388471443006, 79967197.3248232, 535.2671102210136, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 20:14:07,855] A3C_AGENT_WORKER-Thread-6 INFO:Local step 71500, global step 1141505: loss 47.3513
[2019-04-06 20:14:07,856] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 71500, global step 1141505: learning rate 0.0000
[2019-04-06 20:14:08,359] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1141583: loss 46.9474
[2019-04-06 20:14:08,360] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1141583: learning rate 0.0000
[2019-04-06 20:14:12,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3565936e-10 1.2248941e-07 6.5359018e-10 9.0557116e-04 8.3799280e-11
 9.9909437e-01 9.4908903e-10], sum to 1.0000
[2019-04-06 20:14:12,143] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4780
[2019-04-06 20:14:12,202] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 80.5, 0.0, 0.0, 26.0, 24.62126590546995, 0.2120908213666982, 0.0, 1.0, 45505.6369354391], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1812600.0000, 
sim time next is 1814400.0000, 
raw observation next is [-5.0, 79.0, 0.0, 0.0, 26.0, 24.53150451713169, 0.1924357489712392, 0.0, 1.0, 45511.650219054], 
processed observation next is [0.0, 0.0, 0.32409972299168976, 0.79, 0.0, 0.0, 0.6666666666666666, 0.5442920430943076, 0.5641452496570797, 0.0, 1.0, 0.21672214390025712], 
reward next is 0.7833, 
noisyNet noise sample is [array([0.62525225], dtype=float32), 0.4771612]. 
=============================================
[2019-04-06 20:14:14,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:14:14,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:14:14,504] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run26
[2019-04-06 20:14:15,025] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1142401: loss 1.0523
[2019-04-06 20:14:15,025] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1142401: learning rate 0.0000
[2019-04-06 20:14:17,538] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1845341e-10 4.6571200e-09 4.5177434e-10 8.0720591e-04 6.0825880e-12
 9.9919277e-01 1.7117324e-10], sum to 1.0000
[2019-04-06 20:14:17,538] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0057
[2019-04-06 20:14:17,646] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.63572359200448, 0.2053311772977749, 0.0, 1.0, 41500.16206392083], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2773800.0000, 
sim time next is 2775600.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.58887075889803, 0.1876280185218771, 0.0, 1.0, 41158.497092620026], 
processed observation next is [1.0, 0.13043478260869565, 0.296398891966759, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5490725632415024, 0.5625426728406256, 0.0, 1.0, 0.1959928432981906], 
reward next is 0.8040, 
noisyNet noise sample is [array([-0.6118696], dtype=float32), -0.30227187]. 
=============================================
[2019-04-06 20:14:18,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:14:18,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:14:18,272] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run26
[2019-04-06 20:14:20,005] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.84875334e-12 1.11045697e-08 1.12315553e-10 1.16983574e-04
 2.98628969e-11 9.99882936e-01 1.35885761e-10], sum to 1.0000
[2019-04-06 20:14:20,006] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0209
[2019-04-06 20:14:20,201] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 62.0, 74.0, 0.0, 26.0, 25.63432904141165, 0.3237720360911077, 1.0, 1.0, 55841.93988942296], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1956600.0000, 
sim time next is 1958400.0000, 
raw observation next is [-2.8, 62.0, 52.0, 0.0, 26.0, 25.55532408247431, 0.3160022003522833, 1.0, 1.0, 27584.077586886986], 
processed observation next is [1.0, 0.6956521739130435, 0.38504155124653744, 0.62, 0.17333333333333334, 0.0, 0.6666666666666666, 0.6296103402061926, 0.6053340667840944, 1.0, 1.0, 0.13135275041374755], 
reward next is 0.8686, 
noisyNet noise sample is [array([-0.64393705], dtype=float32), -2.2429194]. 
=============================================
[2019-04-06 20:14:20,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:14:20,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:14:20,557] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run26
[2019-04-06 20:14:23,320] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1143334: loss 1.8079
[2019-04-06 20:14:23,321] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1143334: learning rate 0.0000
[2019-04-06 20:14:27,128] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1143791: loss 46.4525
[2019-04-06 20:14:27,141] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1143791: learning rate 0.0000
[2019-04-06 20:14:29,777] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1144086: loss 0.9788
[2019-04-06 20:14:29,777] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1144086: learning rate 0.0000
[2019-04-06 20:14:30,320] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1144153: loss 0.8930
[2019-04-06 20:14:30,321] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1144153: learning rate 0.0000
[2019-04-06 20:14:30,959] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1144233: loss 1.8021
[2019-04-06 20:14:30,959] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1144233: learning rate 0.0000
[2019-04-06 20:14:34,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8368381e-11 3.3594633e-10 2.3682748e-11 6.3119782e-04 2.1301781e-13
 9.9936885e-01 5.2828336e-12], sum to 1.0000
[2019-04-06 20:14:34,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7618
[2019-04-06 20:14:34,435] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 26.0, 25.08757110537641, 0.4078779651696632, 0.0, 1.0, 38516.55390687348], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1405800.0000, 
sim time next is 1407600.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 26.0, 25.05670201850242, 0.4145965825798845, 0.0, 1.0, 38613.70837920005], 
processed observation next is [1.0, 0.30434782608695654, 0.44598337950138506, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5880585015418683, 0.6381988608599615, 0.0, 1.0, 0.18387480180571453], 
reward next is 0.8161, 
noisyNet noise sample is [array([0.83724636], dtype=float32), 0.23018081]. 
=============================================
[2019-04-06 20:14:37,037] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1144880: loss 1.5162
[2019-04-06 20:14:37,038] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1144880: learning rate 0.0000
[2019-04-06 20:14:37,831] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5260135e-10 6.4885555e-08 4.8008830e-10 1.5482213e-03 1.5639372e-10
 9.9845171e-01 5.2311172e-10], sum to 1.0000
[2019-04-06 20:14:37,832] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3567
[2019-04-06 20:14:38,039] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.2, 82.5, 0.0, 0.0, 26.0, 25.00167010552898, 0.3164695372976147, 0.0, 1.0, 48419.40237856472], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1794600.0000, 
sim time next is 1796400.0000, 
raw observation next is [-4.5, 83.0, 0.0, 0.0, 26.0, 25.00881123001391, 0.3151793856278191, 0.0, 1.0, 48584.55565869831], 
processed observation next is [0.0, 0.8260869565217391, 0.3379501385041552, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5840676025011593, 0.605059795209273, 0.0, 1.0, 0.23135502694618243], 
reward next is 0.7686, 
noisyNet noise sample is [array([-0.6690122], dtype=float32), -0.53591716]. 
=============================================
[2019-04-06 20:14:38,764] A3C_AGENT_WORKER-Thread-5 INFO:Local step 72000, global step 1145112: loss 1.7595
[2019-04-06 20:14:38,765] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 72000, global step 1145112: learning rate 0.0000
[2019-04-06 20:14:42,567] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1145605: loss 1.6256
[2019-04-06 20:14:42,569] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1145605: learning rate 0.0000
[2019-04-06 20:14:43,728] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1145732: loss 46.0230
[2019-04-06 20:14:43,729] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1145732: learning rate 0.0000
[2019-04-06 20:14:46,039] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1146051: loss 1.8485
[2019-04-06 20:14:46,042] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1146051: learning rate 0.0000
[2019-04-06 20:14:55,336] A3C_AGENT_WORKER-Thread-4 INFO:Local step 71000, global step 1147122: loss 0.9382
[2019-04-06 20:14:55,336] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 71000, global step 1147122: learning rate 0.0000
[2019-04-06 20:14:58,317] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1147456: loss 0.9633
[2019-04-06 20:14:58,317] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1147456: learning rate 0.0000
[2019-04-06 20:15:00,913] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1147807: loss 0.9399
[2019-04-06 20:15:00,913] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1147807: learning rate 0.0000
[2019-04-06 20:15:08,213] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1148782: loss 1.8696
[2019-04-06 20:15:08,213] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1148782: learning rate 0.0000
[2019-04-06 20:15:08,451] A3C_AGENT_WORKER-Thread-6 INFO:Local step 72000, global step 1148824: loss 1.7458
[2019-04-06 20:15:08,452] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 72000, global step 1148824: learning rate 0.0000
[2019-04-06 20:15:12,687] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1345896e-10 1.6082353e-08 1.3024420e-10 2.2313430e-04 4.4772384e-11
 9.9977690e-01 1.9500870e-10], sum to 1.0000
[2019-04-06 20:15:12,687] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3418
[2019-04-06 20:15:12,762] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 72.0, 0.0, 0.0, 26.0, 25.00597136422827, 0.3098661387250015, 0.0, 1.0, 55033.954427191115], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2853000.0000, 
sim time next is 2854800.0000, 
raw observation next is [1.0, 72.0, 0.0, 0.0, 26.0, 25.11578080683762, 0.3200387353983909, 0.0, 1.0, 52808.71121440632], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 0.72, 0.0, 0.0, 0.6666666666666666, 0.592981733903135, 0.6066795784661303, 0.0, 1.0, 0.25147005340193485], 
reward next is 0.7485, 
noisyNet noise sample is [array([-0.5627702], dtype=float32), 0.5675426]. 
=============================================
[2019-04-06 20:15:13,203] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1149501: loss 45.4568
[2019-04-06 20:15:13,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1149501: learning rate 0.0000
[2019-04-06 20:15:21,329] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1079812e-11 7.3540352e-09 4.3830148e-11 2.7160198e-04 3.7954046e-11
 9.9972838e-01 1.2559667e-09], sum to 1.0000
[2019-04-06 20:15:21,329] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5271
[2019-04-06 20:15:21,400] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 55.0, 0.0, 0.0, 26.0, 25.43301926057366, 0.4261490673601802, 0.0, 1.0, 23286.565548119295], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2323800.0000, 
sim time next is 2325600.0000, 
raw observation next is [-1.7, 56.0, 0.0, 0.0, 26.0, 25.35589019679706, 0.4260993855719952, 0.0, 1.0, 53888.33174610557], 
processed observation next is [1.0, 0.9565217391304348, 0.4155124653739613, 0.56, 0.0, 0.0, 0.6666666666666666, 0.6129908497330883, 0.6420331285239984, 0.0, 1.0, 0.2566111035528837], 
reward next is 0.7434, 
noisyNet noise sample is [array([1.0700059], dtype=float32), 1.4066876]. 
=============================================
[2019-04-06 20:15:21,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7987512e-11 6.1448611e-09 4.0740699e-11 2.5533172e-04 3.4271138e-11
 9.9974471e-01 1.1484091e-09], sum to 1.0000
[2019-04-06 20:15:21,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0225
[2019-04-06 20:15:21,479] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 56.0, 0.0, 0.0, 26.0, 25.35589019679706, 0.4260993855719952, 0.0, 1.0, 53888.33174610557], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2325600.0000, 
sim time next is 2327400.0000, 
raw observation next is [-2.0, 57.5, 0.0, 0.0, 26.0, 25.33105744933168, 0.3653145147663617, 0.0, 1.0, 40466.58199493157], 
processed observation next is [1.0, 0.9565217391304348, 0.40720221606648205, 0.575, 0.0, 0.0, 0.6666666666666666, 0.6109214541109734, 0.6217715049221205, 0.0, 1.0, 0.19269800949967414], 
reward next is 0.8073, 
noisyNet noise sample is [array([1.0700059], dtype=float32), 1.4066876]. 
=============================================
[2019-04-06 20:15:21,921] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1150757: loss 0.6004
[2019-04-06 20:15:21,921] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1150757: learning rate 0.0000
[2019-04-06 20:15:23,962] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1151064: loss 1.9340
[2019-04-06 20:15:23,963] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1151064: learning rate 0.0000
[2019-04-06 20:15:26,407] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1151459: loss 1.4574
[2019-04-06 20:15:26,419] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1151459: learning rate 0.0000
[2019-04-06 20:15:26,845] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1151512: loss 45.2202
[2019-04-06 20:15:26,846] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1151512: learning rate 0.0000
[2019-04-06 20:15:27,068] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1151550: loss 46.2485
[2019-04-06 20:15:27,068] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1151550: learning rate 0.0000
[2019-04-06 20:15:32,801] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1152438: loss 1.5170
[2019-04-06 20:15:32,805] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1152438: learning rate 0.0000
[2019-04-06 20:15:39,958] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1153483: loss 1.8467
[2019-04-06 20:15:39,959] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1153483: learning rate 0.0000
[2019-04-06 20:15:40,663] A3C_AGENT_WORKER-Thread-5 INFO:Local step 72500, global step 1153551: loss 1.4967
[2019-04-06 20:15:40,663] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 72500, global step 1153551: learning rate 0.0000
[2019-04-06 20:15:44,872] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.8931506e-11 2.9762026e-09 8.1246992e-10 5.6599192e-03 1.7701106e-10
 9.9434012e-01 9.3469599e-10], sum to 1.0000
[2019-04-06 20:15:44,872] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9599
[2019-04-06 20:15:44,943] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1154002: loss 1.5856
[2019-04-06 20:15:44,944] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1154002: learning rate 0.0000
[2019-04-06 20:15:45,014] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [17.7, 50.0, 18.0, 1.5, 26.0, 27.96416594652597, 1.027870009688245, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1098000.0000, 
sim time next is 1099800.0000, 
raw observation next is [16.9, 51.5, 0.0, 0.0, 26.0, 27.24659713796627, 0.8507023690461204, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.9307479224376731, 0.515, 0.0, 0.0, 0.6666666666666666, 0.7705497614971891, 0.7835674563487068, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8774794], dtype=float32), -0.09665744]. 
=============================================
[2019-04-06 20:15:50,993] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1154619: loss 1.5914
[2019-04-06 20:15:50,993] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1154619: learning rate 0.0000
[2019-04-06 20:15:52,478] A3C_AGENT_WORKER-Thread-4 INFO:Local step 71500, global step 1154754: loss 46.3628
[2019-04-06 20:15:52,479] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 71500, global step 1154754: learning rate 0.0000
[2019-04-06 20:16:00,085] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1155521: loss 45.3944
[2019-04-06 20:16:00,085] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1155521: learning rate 0.0000
[2019-04-06 20:16:06,348] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1156101: loss 45.3206
[2019-04-06 20:16:06,349] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1156101: learning rate 0.0000
[2019-04-06 20:16:20,732] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1157381: loss 0.4026
[2019-04-06 20:16:20,733] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1157381: learning rate 0.0000
[2019-04-06 20:16:28,256] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1158113: loss 1.6668
[2019-04-06 20:16:28,256] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1158113: learning rate 0.0000
[2019-04-06 20:16:29,866] A3C_AGENT_WORKER-Thread-6 INFO:Local step 72500, global step 1158247: loss 1.5382
[2019-04-06 20:16:29,867] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 72500, global step 1158247: learning rate 0.0000
[2019-04-06 20:16:31,301] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1158394: loss 0.5894
[2019-04-06 20:16:31,331] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1158394: learning rate 0.0000
[2019-04-06 20:16:35,624] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1158863: loss 1.7757
[2019-04-06 20:16:35,624] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1158863: learning rate 0.0000
[2019-04-06 20:16:37,878] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.7736367e-13 4.4755971e-10 5.1010487e-13 6.3891137e-05 2.5863565e-14
 9.9993610e-01 4.3829927e-13], sum to 1.0000
[2019-04-06 20:16:37,878] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4394
[2019-04-06 20:16:38,032] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.0, 100.0, 91.0, 519.5, 26.0, 26.21321621812274, 0.517651594364045, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3142800.0000, 
sim time next is 3144600.0000, 
raw observation next is [7.0, 100.0, 99.0, 647.0, 26.0, 26.42575208627393, 0.5733638321052582, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6565096952908588, 1.0, 0.33, 0.7149171270718232, 0.6666666666666666, 0.7021460071894943, 0.6911212773684193, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0848347], dtype=float32), 0.27211598]. 
=============================================
[2019-04-06 20:16:39,441] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:16:39,441] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:16:39,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run27
[2019-04-06 20:16:41,372] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1159387: loss 0.9041
[2019-04-06 20:16:41,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1159387: learning rate 0.0000
[2019-04-06 20:16:48,767] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 20:16:48,773] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:16:48,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:16:48,793] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:16:48,793] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:16:48,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run59
[2019-04-06 20:16:48,908] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:16:48,908] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:16:48,919] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run59
[2019-04-06 20:16:48,994] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run59
[2019-04-06 20:18:02,402] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.05810431], dtype=float32), 0.13071643]
[2019-04-06 20:18:02,403] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [18.24309476, 70.83038084, 0.0, 0.0, 26.0, 24.6879418508684, 0.4146759896773345, 0.0, 0.0, 0.0]
[2019-04-06 20:18:02,403] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 20:18:02,404] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [6.2165723e-10 1.2900941e-07 1.7400622e-09 1.0341409e-03 4.4125167e-10
 9.9896574e-01 1.2003870e-09], sampled 0.7017778317408595
[2019-04-06 20:19:21,246] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 20:19:21,582] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05810431], dtype=float32), 0.13071643]
[2019-04-06 20:19:21,582] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-3.5, 27.5, 114.0, 830.0, 26.0, 26.12655661295751, 0.5758524217684317, 1.0, 1.0, 0.0]
[2019-04-06 20:19:21,583] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 20:19:21,583] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.8905296e-10 7.1003392e-08 1.5646799e-09 8.7436300e-04 3.9379494e-10
 9.9912554e-01 1.4755971e-09], sampled 0.6969543720743548
[2019-04-06 20:19:38,104] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 20:19:42,547] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 20:19:43,570] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 1160000, evaluation results [1160000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 20:19:46,733] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.6264955e-11 1.5893752e-09 6.3009313e-11 2.0503935e-04 2.5353783e-11
 9.9979502e-01 9.7010226e-11], sum to 1.0000
[2019-04-06 20:19:46,733] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0215
[2019-04-06 20:19:46,919] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.15, 48.0, 221.0, 69.0, 26.0, 25.02727036528653, 0.3269679426024676, 1.0, 1.0, 42419.26773334809], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2295000.0000, 
sim time next is 2296800.0000, 
raw observation next is [-0.6, 45.0, 171.0, 64.5, 26.0, 25.78047078038266, 0.4593223187893572, 1.0, 1.0, 66177.00459944004], 
processed observation next is [1.0, 0.6086956521739131, 0.44598337950138506, 0.45, 0.57, 0.0712707182320442, 0.6666666666666666, 0.6483725650318884, 0.6531074395964523, 1.0, 1.0, 0.3151285933306669], 
reward next is 0.6849, 
noisyNet noise sample is [array([-0.1540292], dtype=float32), -2.1475234]. 
=============================================
[2019-04-06 20:19:47,742] A3C_AGENT_WORKER-Thread-5 INFO:Local step 73000, global step 1160496: loss 0.9079
[2019-04-06 20:19:47,743] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 73000, global step 1160496: learning rate 0.0000
[2019-04-06 20:19:48,872] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1160686: loss 1.6493
[2019-04-06 20:19:48,873] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1160686: learning rate 0.0000
[2019-04-06 20:19:49,862] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1160814: loss 1.0364
[2019-04-06 20:19:49,863] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1160814: learning rate 0.0000
[2019-04-06 20:19:49,999] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1160829: loss 1.7208
[2019-04-06 20:19:49,999] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1160829: learning rate 0.0000
[2019-04-06 20:19:50,065] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1160835: loss 1.5546
[2019-04-06 20:19:50,066] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1160835: learning rate 0.0000
[2019-04-06 20:19:51,813] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.0517619e-11 2.8675226e-08 2.7833166e-10 1.6395932e-02 4.2391948e-11
 9.8360401e-01 7.4347167e-10], sum to 1.0000
[2019-04-06 20:19:51,813] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7217
[2019-04-06 20:19:52,027] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 75.0, 17.5, 1.0, 26.0, 24.60894456563421, 0.2902678855665915, 1.0, 1.0, 100948.24910142638], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1962000.0000, 
sim time next is 1963800.0000, 
raw observation next is [-4.45, 77.0, 0.0, 0.0, 26.0, 25.7073952775297, 0.3211616720650468, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3393351800554017, 0.77, 0.0, 0.0, 0.6666666666666666, 0.6422829397941415, 0.6070538906883489, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9155416], dtype=float32), -0.61445284]. 
=============================================
[2019-04-06 20:19:54,255] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1161385: loss 0.7255
[2019-04-06 20:19:54,255] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1161385: learning rate 0.0000
[2019-04-06 20:20:00,399] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7819479e-11 3.7036387e-09 6.6983370e-11 1.0085270e-03 3.6403505e-11
 9.9899143e-01 1.2806941e-11], sum to 1.0000
[2019-04-06 20:20:00,400] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9104
[2019-04-06 20:20:00,442] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.9, 73.0, 0.0, 0.0, 26.0, 25.37505867678677, 0.4220829356303913, 0.0, 1.0, 51694.1981528541], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4507200.0000, 
sim time next is 4509000.0000, 
raw observation next is [-0.8500000000000001, 72.0, 0.0, 0.0, 26.0, 25.22924997502624, 0.4101028844527055, 0.0, 1.0, 43322.685428267745], 
processed observation next is [1.0, 0.17391304347826086, 0.43905817174515244, 0.72, 0.0, 0.0, 0.6666666666666666, 0.6024374979188533, 0.6367009614842352, 0.0, 1.0, 0.20629850203937022], 
reward next is 0.7937, 
noisyNet noise sample is [array([0.32729745], dtype=float32), -1.2051953]. 
=============================================
[2019-04-06 20:20:00,507] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[87.68338 ]
 [87.71649 ]
 [87.92191 ]
 [87.708176]
 [87.74663 ]], R is [[87.47559357]
 [87.35467529]
 [87.32955933]
 [87.28250885]
 [87.20220184]].
[2019-04-06 20:20:07,986] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1163486: loss 1.6877
[2019-04-06 20:20:08,009] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1163486: learning rate 0.0000
[2019-04-06 20:20:08,870] A3C_AGENT_WORKER-Thread-4 INFO:Local step 72000, global step 1163611: loss 2.0005
[2019-04-06 20:20:08,872] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 72000, global step 1163611: learning rate 0.0000
[2019-04-06 20:20:09,798] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6530469e-11 2.6034910e-10 1.5333682e-10 5.3709379e-04 1.2895069e-11
 9.9946290e-01 5.1260593e-11], sum to 1.0000
[2019-04-06 20:20:09,798] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6577
[2019-04-06 20:20:10,022] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 64.0, 150.0, 67.0, 26.0, 25.57202650785641, 0.2698663998387741, 1.0, 1.0, 100021.5714835322], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2120400.0000, 
sim time next is 2122200.0000, 
raw observation next is [-5.9, 66.0, 149.0, 0.0, 26.0, 25.55038993310917, 0.4209790844966266, 1.0, 1.0, 32526.749108420423], 
processed observation next is [1.0, 0.5652173913043478, 0.2991689750692521, 0.66, 0.49666666666666665, 0.0, 0.6666666666666666, 0.6291991610924308, 0.6403263614988756, 1.0, 1.0, 0.15488928146866868], 
reward next is 0.8451, 
noisyNet noise sample is [array([2.2805402], dtype=float32), -0.40779805]. 
=============================================
[2019-04-06 20:20:12,701] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6092031e-10 1.1686486e-08 7.1006440e-10 4.7220694e-04 6.3651188e-11
 9.9952781e-01 2.8591141e-10], sum to 1.0000
[2019-04-06 20:20:12,701] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5047
[2019-04-06 20:20:12,763] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.0, 70.5, 0.0, 0.0, 26.0, 24.61962412549099, 0.2403375035680656, 0.0, 1.0, 44424.99401461807], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2680200.0000, 
sim time next is 2682000.0000, 
raw observation next is [-9.0, 69.0, 0.0, 0.0, 26.0, 24.52676946398164, 0.2248890897432774, 0.0, 1.0, 44410.99645187095], 
processed observation next is [1.0, 0.043478260869565216, 0.21329639889196678, 0.69, 0.0, 0.0, 0.6666666666666666, 0.5438974553318033, 0.5749630299144258, 0.0, 1.0, 0.21148093548509977], 
reward next is 0.7885, 
noisyNet noise sample is [array([-1.2344314], dtype=float32), 0.40489706]. 
=============================================
[2019-04-06 20:20:12,768] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[82.78184]
 [83.18952]
 [83.72709]
 [84.32338]
 [84.64256]], R is [[81.9875412 ]
 [81.95611572]
 [81.9250946 ]
 [81.89413452]
 [81.85852814]].
[2019-04-06 20:20:13,492] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1164355: loss 1.9802
[2019-04-06 20:20:13,493] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1164355: learning rate 0.0000
[2019-04-06 20:20:16,057] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1164748: loss 1.5796
[2019-04-06 20:20:16,059] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1164748: learning rate 0.0000
[2019-04-06 20:20:17,344] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1164947: loss 1.1210
[2019-04-06 20:20:17,352] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1164947: learning rate 0.0000
[2019-04-06 20:20:17,649] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1164985: loss 0.4725
[2019-04-06 20:20:17,665] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1164985: learning rate 0.0000
[2019-04-06 20:20:17,797] A3C_AGENT_WORKER-Thread-6 INFO:Local step 73000, global step 1165008: loss 1.0663
[2019-04-06 20:20:17,798] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 73000, global step 1165008: learning rate 0.0000
[2019-04-06 20:20:23,673] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1165886: loss 0.3672
[2019-04-06 20:20:23,675] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1165886: learning rate 0.0000
[2019-04-06 20:20:29,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:20:29,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:20:29,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run27
[2019-04-06 20:20:31,355] A3C_AGENT_WORKER-Thread-5 INFO:Local step 73500, global step 1167073: loss 0.5408
[2019-04-06 20:20:31,355] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 73500, global step 1167073: learning rate 0.0000
[2019-04-06 20:20:34,409] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1167490: loss 0.5210
[2019-04-06 20:20:34,412] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1167490: learning rate 0.0000
[2019-04-06 20:20:34,967] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1167580: loss 1.0494
[2019-04-06 20:20:34,969] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1167580: learning rate 0.0000
[2019-04-06 20:20:35,106] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3046957e-09 3.8899424e-07 1.9809567e-09 2.4447110e-02 2.3675644e-09
 9.7555250e-01 1.6628034e-08], sum to 1.0000
[2019-04-06 20:20:35,106] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1479
[2019-04-06 20:20:35,240] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.5, 27.0, 118.0, 0.0, 26.0, 25.92091289639496, 0.4121785671108053, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2817000.0000, 
sim time next is 2818800.0000, 
raw observation next is [7.0, 24.0, 106.5, 0.0, 26.0, 24.73713558470553, 0.3004726809290693, 1.0, 1.0, 63622.263296057296], 
processed observation next is [1.0, 0.6521739130434783, 0.6565096952908588, 0.24, 0.355, 0.0, 0.6666666666666666, 0.5614279653921276, 0.6001575603096897, 1.0, 1.0, 0.30296315855265377], 
reward next is 0.6970, 
noisyNet noise sample is [array([-0.8177631], dtype=float32), -1.551823]. 
=============================================
[2019-04-06 20:20:36,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:20:36,202] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:20:36,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run27
[2019-04-06 20:20:37,984] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1168020: loss 1.7529
[2019-04-06 20:20:37,986] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1168020: learning rate 0.0000
[2019-04-06 20:20:38,337] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1168074: loss 0.5448
[2019-04-06 20:20:38,340] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1168074: learning rate 0.0000
[2019-04-06 20:20:43,430] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:20:43,430] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:20:43,434] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run27
[2019-04-06 20:20:46,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:20:46,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:20:46,390] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run27
[2019-04-06 20:20:49,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:20:49,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:20:49,612] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run27
[2019-04-06 20:20:49,881] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1169785: loss 1.6314
[2019-04-06 20:20:49,881] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1169785: learning rate 0.0000
[2019-04-06 20:20:51,490] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1169980: loss 1.6578
[2019-04-06 20:20:51,517] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1169984: learning rate 0.0000
[2019-04-06 20:20:53,482] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1170236: loss 1.0751
[2019-04-06 20:20:53,500] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1170237: learning rate 0.0000
[2019-04-06 20:20:54,868] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0110074e-09 2.1434332e-08 6.2748935e-09 4.9648868e-05 1.6055395e-10
 9.9995029e-01 1.4873820e-09], sum to 1.0000
[2019-04-06 20:20:54,868] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7638
[2019-04-06 20:20:54,961] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.0, 63.0, 0.0, 0.0, 26.0, 24.29170067719379, 0.1472875693109435, 0.0, 1.0, 43603.84702058331], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3987000.0000, 
sim time next is 3988800.0000, 
raw observation next is [-12.0, 63.0, 0.0, 0.0, 26.0, 24.18022256450548, 0.1137711891745468, 0.0, 1.0, 43619.76619633297], 
processed observation next is [1.0, 0.17391304347826086, 0.13019390581717452, 0.63, 0.0, 0.0, 0.6666666666666666, 0.5150185470421235, 0.5379237297248489, 0.0, 1.0, 0.20771317236349032], 
reward next is 0.7923, 
noisyNet noise sample is [array([0.8499566], dtype=float32), 1.5880852]. 
=============================================
[2019-04-06 20:21:00,025] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1171185: loss 0.5158
[2019-04-06 20:21:00,025] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1171185: learning rate 0.0000
[2019-04-06 20:21:00,280] A3C_AGENT_WORKER-Thread-6 INFO:Local step 73500, global step 1171225: loss 0.5013
[2019-04-06 20:21:00,280] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 73500, global step 1171225: learning rate 0.0000
[2019-04-06 20:21:09,357] A3C_AGENT_WORKER-Thread-4 INFO:Local step 72500, global step 1172663: loss 1.8199
[2019-04-06 20:21:09,358] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 72500, global step 1172663: learning rate 0.0000
[2019-04-06 20:21:11,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:21:11,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:21:11,916] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run27
[2019-04-06 20:21:12,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:21:12,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:21:12,287] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run27
[2019-04-06 20:21:13,397] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1173259: loss 1.7254
[2019-04-06 20:21:13,397] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1173259: learning rate 0.0000
[2019-04-06 20:21:15,422] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3162892e-10 2.1800810e-07 2.5277107e-09 5.0693768e-04 5.3047775e-11
 9.9949276e-01 7.8588508e-10], sum to 1.0000
[2019-04-06 20:21:15,422] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0406
[2019-04-06 20:21:15,604] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 61.5, 83.0, 359.0, 26.0, 24.05591541764306, 0.2163551831022688, 0.0, 1.0, 148236.07027220214], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3054600.0000, 
sim time next is 3056400.0000, 
raw observation next is [-6.0, 59.0, 91.0, 497.0, 26.0, 25.40515271968389, 0.3242826105664272, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.296398891966759, 0.59, 0.30333333333333334, 0.549171270718232, 0.6666666666666666, 0.6170960599736576, 0.6080942035221424, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0933337], dtype=float32), 0.94362867]. 
=============================================
[2019-04-06 20:21:16,008] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1173630: loss 1.7429
[2019-04-06 20:21:16,016] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1173630: learning rate 0.0000
[2019-04-06 20:21:17,745] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1173855: loss 0.5405
[2019-04-06 20:21:17,746] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1173855: learning rate 0.0000
[2019-04-06 20:21:22,409] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1174506: loss 0.6686
[2019-04-06 20:21:22,413] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1174506: learning rate 0.0000
[2019-04-06 20:21:33,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:21:33,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:21:33,888] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run27
[2019-04-06 20:21:41,261] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1176078: loss 0.9410
[2019-04-06 20:21:41,261] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1176078: learning rate 0.0000
[2019-04-06 20:21:43,956] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1176298: loss 0.6880
[2019-04-06 20:21:43,956] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1176298: learning rate 0.0000
[2019-04-06 20:21:44,998] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1176390: loss 0.4427
[2019-04-06 20:21:45,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1176390: learning rate 0.0000
[2019-04-06 20:21:57,294] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.16995674e-11 7.49366720e-08 8.60568977e-11 1.53848971e-03
 3.12835209e-11 9.98461485e-01 1.07549886e-10], sum to 1.0000
[2019-04-06 20:21:57,295] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1723
[2019-04-06 20:21:57,362] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 59.0, 0.0, 0.0, 26.0, 25.00275232802323, 0.320051535442822, 0.0, 1.0, 48703.73463823518], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3695400.0000, 
sim time next is 3697200.0000, 
raw observation next is [4.0, 59.0, 0.0, 0.0, 26.0, 24.96789006163709, 0.3203569391271602, 0.0, 1.0, 38075.402120424544], 
processed observation next is [0.0, 0.8260869565217391, 0.5734072022160666, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5806575051364241, 0.6067856463757201, 0.0, 1.0, 0.1813114386686883], 
reward next is 0.8187, 
noisyNet noise sample is [array([0.5649014], dtype=float32), 0.017785517]. 
=============================================
[2019-04-06 20:22:02,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:22:02,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:22:02,824] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run27
[2019-04-06 20:22:10,450] A3C_AGENT_WORKER-Thread-4 INFO:Local step 73000, global step 1178636: loss 0.8503
[2019-04-06 20:22:10,451] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 73000, global step 1178636: learning rate 0.0000
[2019-04-06 20:22:17,520] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1179260: loss 1.1224
[2019-04-06 20:22:17,520] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1179260: learning rate 0.0000
[2019-04-06 20:22:21,591] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1179612: loss 0.7149
[2019-04-06 20:22:21,592] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1179612: learning rate 0.0000
[2019-04-06 20:22:25,729] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-06 20:22:25,732] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:22:25,732] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:22:25,736] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run60
[2019-04-06 20:22:25,798] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:22:25,798] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:22:25,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run60
[2019-04-06 20:22:25,853] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:22:25,853] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:22:25,874] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run60
[2019-04-06 20:23:59,503] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05850385], dtype=float32), 0.13158743]
[2019-04-06 20:23:59,503] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [1.7, 86.5, 0.0, 0.0, 26.0, 24.98735199034719, 0.4876384471377634, 0.0, 1.0, 33947.01630579839]
[2019-04-06 20:23:59,503] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 20:23:59,504] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.6119129e-11 4.6210786e-09 6.0974212e-11 4.0173510e-04 8.5964092e-12
 9.9959832e-01 4.3586114e-11], sampled 0.2400248558905358
[2019-04-06 20:24:53,697] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 20:25:14,571] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 20:25:14,981] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 20:25:16,003] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1180000, evaluation results [1180000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 20:25:17,789] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1180273: loss 0.5029
[2019-04-06 20:25:17,790] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1180273: learning rate 0.0000
[2019-04-06 20:25:22,442] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7584875e-12 3.3299576e-09 4.6301109e-11 1.6270863e-04 8.8148881e-12
 9.9983728e-01 3.1281609e-11], sum to 1.0000
[2019-04-06 20:25:22,443] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2432
[2019-04-06 20:25:22,506] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 92.0, 210.5, 6.0, 26.0, 26.47532109893728, 0.5922298287576077, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4705200.0000, 
sim time next is 4707000.0000, 
raw observation next is [0.5, 89.0, 213.0, 6.0, 26.0, 26.36192307471804, 0.5747291562402949, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4764542936288089, 0.89, 0.71, 0.0066298342541436465, 0.6666666666666666, 0.6968269228931699, 0.6915763854134317, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1603993], dtype=float32), -0.12043582]. 
=============================================
[2019-04-06 20:25:22,510] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[93.41857]
 [93.47722]
 [93.70584]
 [93.67866]
 [93.83888]], R is [[93.42427826]
 [93.49003601]
 [93.55513763]
 [93.61959076]
 [93.68339539]].
[2019-04-06 20:25:25,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6161705e-12 1.2002518e-08 8.1945110e-11 2.1138028e-04 1.0064330e-12
 9.9978858e-01 6.2636250e-11], sum to 1.0000
[2019-04-06 20:25:25,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2872
[2019-04-06 20:25:26,287] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.1, 66.0, 0.0, 0.0, 26.0, 25.1238693376273, 0.3019215855228873, 1.0, 1.0, 18864.36527523991], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 156600.0000, 
sim time next is 158400.0000, 
raw observation next is [-8.4, 68.0, 0.0, 0.0, 26.0, 24.98698591364652, 0.3143169160407694, 0.0, 1.0, 97182.40514493028], 
processed observation next is [1.0, 0.8695652173913043, 0.2299168975069252, 0.68, 0.0, 0.0, 0.6666666666666666, 0.5822488261372101, 0.6047723053469231, 0.0, 1.0, 0.46277335783300133], 
reward next is 0.5372, 
noisyNet noise sample is [array([-1.2633166], dtype=float32), 0.006933928]. 
=============================================
[2019-04-06 20:25:30,166] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1182221: loss 0.5256
[2019-04-06 20:25:30,179] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1182221: learning rate 0.0000
[2019-04-06 20:25:30,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:25:30,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:25:30,680] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run27
[2019-04-06 20:25:31,803] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1182509: loss 0.4729
[2019-04-06 20:25:31,804] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1182509: learning rate 0.0000
[2019-04-06 20:25:40,553] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3794154e-11 6.9093525e-10 2.6982208e-11 1.3477514e-04 4.8952652e-12
 9.9986517e-01 1.0948009e-12], sum to 1.0000
[2019-04-06 20:25:40,553] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9997
[2019-04-06 20:25:40,601] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.05, 79.0, 0.0, 0.0, 26.0, 25.85445954048084, 0.5830336300500613, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1549800.0000, 
sim time next is 1551600.0000, 
raw observation next is [5.5, 82.0, 0.0, 0.0, 26.0, 25.50403678362255, 0.565824456699438, 0.0, 1.0, 73722.78742520163], 
processed observation next is [1.0, 1.0, 0.6149584487534627, 0.82, 0.0, 0.0, 0.6666666666666666, 0.6253363986352124, 0.688608152233146, 0.0, 1.0, 0.3510608925009602], 
reward next is 0.6489, 
noisyNet noise sample is [array([0.70269275], dtype=float32), 0.2326569]. 
=============================================
[2019-04-06 20:25:43,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:25:43,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:25:43,068] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run27
[2019-04-06 20:25:44,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:25:44,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:25:44,610] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run27
[2019-04-06 20:25:51,419] A3C_AGENT_WORKER-Thread-4 INFO:Local step 73500, global step 1185321: loss 0.4544
[2019-04-06 20:25:51,420] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 73500, global step 1185321: learning rate 0.0000
[2019-04-06 20:25:52,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2496144e-08 1.2058322e-07 7.3726616e-09 2.4156873e-03 3.5085124e-10
 9.9758410e-01 2.2984352e-09], sum to 1.0000
[2019-04-06 20:25:52,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3770
[2019-04-06 20:25:52,551] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 36.5, 23.0, 0.0, 26.0, 25.1516387895333, 0.1718001631319643, 1.0, 1.0, 22072.195803245635], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 462600.0000, 
sim time next is 464400.0000, 
raw observation next is [-6.2, 33.0, 42.5, 0.0, 26.0, 25.48329997913473, 0.2023595037835793, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.2908587257617729, 0.33, 0.14166666666666666, 0.0, 0.6666666666666666, 0.623608331594561, 0.5674531679278597, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4889061], dtype=float32), 0.8184207]. 
=============================================
[2019-04-06 20:25:55,307] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1185861: loss 0.4473
[2019-04-06 20:25:55,308] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1185861: learning rate 0.0000
[2019-04-06 20:25:57,926] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1186274: loss 0.5164
[2019-04-06 20:25:57,926] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1186274: learning rate 0.0000
[2019-04-06 20:26:03,397] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:26:03,397] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:26:03,400] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run27
[2019-04-06 20:26:07,547] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:26:07,548] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:26:07,551] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run27
[2019-04-06 20:26:11,071] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:26:11,072] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:26:11,075] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run27
[2019-04-06 20:26:58,874] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.6905039e-11 2.3533016e-07 4.2773629e-10 2.1895664e-03 3.0577606e-11
 9.9781018e-01 1.0539530e-09], sum to 1.0000
[2019-04-06 20:26:58,874] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1985
[2019-04-06 20:26:59,237] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 51.5, 0.0, 26.0, 25.65918749531373, 0.4100955334997765, 1.0, 1.0, 66106.4989966006], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2044800.0000, 
sim time next is 2046600.0000, 
raw observation next is [-3.9, 82.0, 32.0, 0.0, 26.0, 25.81851380572238, 0.4026359148166687, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.3545706371191136, 0.82, 0.10666666666666667, 0.0, 0.6666666666666666, 0.6515428171435316, 0.6342119716055562, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1126739], dtype=float32), 0.0061636055]. 
=============================================
[2019-04-06 20:27:05,160] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.1323494e-11 6.9814181e-09 5.8642216e-11 1.3710510e-04 3.2318033e-12
 9.9986291e-01 1.6762042e-10], sum to 1.0000
[2019-04-06 20:27:05,161] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1812
[2019-04-06 20:27:05,400] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 81.5, 127.0, 467.0, 26.0, 24.98975120024329, 0.3543634204015632, 0.0, 1.0, 30845.11821144247], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 570600.0000, 
sim time next is 572400.0000, 
raw observation next is [-1.2, 83.0, 113.5, 270.0, 26.0, 25.01440437319049, 0.3346088925272113, 0.0, 1.0, 22310.238160776917], 
processed observation next is [0.0, 0.6521739130434783, 0.42936288088642666, 0.83, 0.37833333333333335, 0.2983425414364641, 0.6666666666666666, 0.5845336977658743, 0.6115362975090705, 0.0, 1.0, 0.10623922933703293], 
reward next is 0.8938, 
noisyNet noise sample is [array([-1.2258786], dtype=float32), -0.111811094]. 
=============================================
[2019-04-06 20:27:41,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.28246388e-11 6.09868991e-08 7.72196473e-11 1.43731125e-02
 5.46588122e-12 9.85626876e-01 1.25881372e-09], sum to 1.0000
[2019-04-06 20:27:41,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4909
[2019-04-06 20:27:41,341] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 26.0, 25.49362319842711, 0.5819280653212496, 0.0, 1.0, 18758.52761507565], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1373400.0000, 
sim time next is 1375200.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 26.0, 25.44440264307963, 0.5674828395390242, 0.0, 1.0, 37960.09018100767], 
processed observation next is [1.0, 0.9565217391304348, 0.4764542936288089, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6203668869233026, 0.6891609465130081, 0.0, 1.0, 0.1807623341952746], 
reward next is 0.8192, 
noisyNet noise sample is [array([0.65288335], dtype=float32), 0.40700996]. 
=============================================
[2019-04-06 20:28:08,199] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 20:28:08,199] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:28:08,199] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:28:08,203] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run61
[2019-04-06 20:28:08,325] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:28:08,337] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:28:08,341] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:28:08,341] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:28:08,348] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run61
[2019-04-06 20:28:08,486] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run61
[2019-04-06 20:29:30,232] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05875263], dtype=float32), 0.13147612]
[2019-04-06 20:29:30,232] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-0.6, 100.0, 32.0, 0.0, 26.0, 25.90604498365613, 0.5150207673105102, 1.0, 1.0, 0.0]
[2019-04-06 20:29:30,232] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 20:29:30,234] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [5.7982287e-12 1.9409627e-09 2.2149478e-11 1.5660813e-04 2.9659959e-12
 9.9984336e-01 1.4324774e-11], sampled 0.5728981264156093
[2019-04-06 20:29:38,258] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05875263], dtype=float32), 0.13147612]
[2019-04-06 20:29:38,258] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.3, 92.0, 66.0, 0.0, 26.0, 25.99062880149873, 0.5387483243434137, 1.0, 1.0, 0.0]
[2019-04-06 20:29:38,258] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 20:29:38,260] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [6.6713024e-12 2.2332889e-09 2.1428697e-11 2.0040938e-04 3.7558051e-12
 9.9979955e-01 1.9999322e-11], sampled 0.6347659324061262
[2019-04-06 20:30:40,601] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 20:30:58,069] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 20:31:00,709] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 20:31:01,731] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1200000, evaluation results [1200000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 20:31:01,761] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9102092e-11 2.3736529e-08 1.3025256e-09 2.3042741e-03 2.3242384e-11
 9.9769562e-01 2.1612581e-10], sum to 1.0000
[2019-04-06 20:31:01,794] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2352
[2019-04-06 20:31:02,042] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.0, 80.5, 86.0, 396.0, 26.0, 25.72936242432628, 0.4591962670261521, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3313800.0000, 
sim time next is 3315600.0000, 
raw observation next is [-9.0, 77.0, 95.0, 505.5, 26.0, 26.02541596587943, 0.5086785713378104, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.21329639889196678, 0.77, 0.31666666666666665, 0.5585635359116022, 0.6666666666666666, 0.6687846638232857, 0.6695595237792702, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0285662], dtype=float32), 0.23969932]. 
=============================================
[2019-04-06 20:31:04,320] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.2319316e-12 8.0979392e-09 3.0100439e-10 5.0669699e-04 9.6149130e-12
 9.9949324e-01 2.5215840e-11], sum to 1.0000
[2019-04-06 20:31:04,320] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5733
[2019-04-06 20:31:04,454] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 83.0, 45.5, 0.0, 26.0, 25.18859009105246, 0.3570922791250357, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1760400.0000, 
sim time next is 1762200.0000, 
raw observation next is [-2.0, 85.0, 65.0, 0.0, 26.0, 24.97069762139525, 0.3100581199270108, 0.0, 1.0, 16756.275329800275], 
processed observation next is [0.0, 0.391304347826087, 0.40720221606648205, 0.85, 0.21666666666666667, 0.0, 0.6666666666666666, 0.5808914684496042, 0.6033527066423369, 0.0, 1.0, 0.07979178728476322], 
reward next is 0.9202, 
noisyNet noise sample is [array([0.02675546], dtype=float32), 0.87279177]. 
=============================================
[2019-04-06 20:31:19,741] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.8824907e-12 2.9107441e-10 1.4660414e-11 1.4762545e-04 9.0918858e-13
 9.9985230e-01 5.5526438e-12], sum to 1.0000
[2019-04-06 20:31:19,741] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3316
[2019-04-06 20:31:19,817] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 49.0, 102.0, 781.0, 26.0, 26.62334812393632, 0.7140793057123616, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3508200.0000, 
sim time next is 3510000.0000, 
raw observation next is [3.0, 49.0, 95.0, 734.0, 26.0, 26.75395516488047, 0.73161404399916, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.49, 0.31666666666666665, 0.8110497237569061, 0.6666666666666666, 0.7294962637400392, 0.74387134799972, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6933236], dtype=float32), 1.5975398]. 
=============================================
[2019-04-06 20:31:19,821] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[87.53172 ]
 [87.62816 ]
 [87.720375]
 [87.82978 ]
 [87.936325]], R is [[87.45265198]
 [87.578125  ]
 [87.67269897]
 [87.79597473]
 [87.91801453]].
[2019-04-06 20:31:22,240] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:31:22,240] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:31:22,272] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run28
[2019-04-06 20:31:59,721] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2386382e-10 1.0701483e-08 8.8586649e-10 6.0731656e-04 1.2176421e-10
 9.9939263e-01 1.0911964e-09], sum to 1.0000
[2019-04-06 20:31:59,722] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5639
[2019-04-06 20:31:59,791] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 50.0, 0.0, 0.0, 26.0, 25.16239852096293, 0.3551703592650315, 0.0, 1.0, 39459.126564397004], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4159800.0000, 
sim time next is 4161600.0000, 
raw observation next is [-3.0, 50.0, 0.0, 0.0, 26.0, 25.11979425208401, 0.3393010670447045, 0.0, 1.0, 39476.94009941491], 
processed observation next is [0.0, 0.17391304347826086, 0.3795013850415513, 0.5, 0.0, 0.0, 0.6666666666666666, 0.5933161876736675, 0.6131003556815682, 0.0, 1.0, 0.1879854290448329], 
reward next is 0.8120, 
noisyNet noise sample is [array([-0.01563347], dtype=float32), -1.8482674]. 
=============================================
[2019-04-06 20:32:04,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9489011e-11 4.0154906e-09 7.8629901e-11 2.4548825e-03 1.7282353e-11
 9.9754506e-01 6.9275460e-11], sum to 1.0000
[2019-04-06 20:32:04,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9565
[2019-04-06 20:32:04,150] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 26.0, 25.06698795635407, 0.4193171312771608, 1.0, 1.0, 49016.593533490035], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4561200.0000, 
sim time next is 4563000.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 26.0, 25.02129069221632, 0.407355202263519, 1.0, 1.0, 31930.735364787633], 
processed observation next is [1.0, 0.8260869565217391, 0.518005540166205, 0.52, 0.0, 0.0, 0.6666666666666666, 0.5851075576846932, 0.635785067421173, 1.0, 1.0, 0.152051120784703], 
reward next is 0.8479, 
noisyNet noise sample is [array([0.4418014], dtype=float32), -1.510399]. 
=============================================
[2019-04-06 20:32:04,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[83.19903]
 [83.05602]
 [82.88625]
 [83.03035]
 [83.39234]], R is [[83.1095047 ]
 [83.04499817]
 [83.08874512]
 [83.1813736 ]
 [83.3495636 ]].
[2019-04-06 20:32:17,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:32:17,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:32:17,848] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run28
[2019-04-06 20:32:25,594] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5299656e-11 2.8477789e-08 3.0570829e-10 1.5796294e-03 1.4944485e-10
 9.9842036e-01 1.5517947e-10], sum to 1.0000
[2019-04-06 20:32:25,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4678
[2019-04-06 20:32:25,645] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 29.0, 0.0, 0.0, 26.0, 25.6307144646802, 0.5378453309942116, 0.0, 1.0, 130956.6245131941], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5000400.0000, 
sim time next is 5002200.0000, 
raw observation next is [3.5, 33.0, 0.0, 0.0, 26.0, 25.69370977139023, 0.5792816883454509, 0.0, 1.0, 59512.07749713241], 
processed observation next is [1.0, 0.9130434782608695, 0.5595567867036012, 0.33, 0.0, 0.0, 0.6666666666666666, 0.6411424809491857, 0.6930938961151503, 0.0, 1.0, 0.2833908452244401], 
reward next is 0.7166, 
noisyNet noise sample is [array([-1.4737132], dtype=float32), 0.26363975]. 
=============================================
[2019-04-06 20:32:30,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:32:30,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:32:30,603] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run28
[2019-04-06 20:32:36,029] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:32:36,029] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:32:36,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run28
[2019-04-06 20:32:40,827] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4301181e-10 3.4363479e-09 3.5058068e-10 4.4551687e-04 6.4217860e-11
 9.9955446e-01 2.4573454e-10], sum to 1.0000
[2019-04-06 20:32:40,828] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9265
[2019-04-06 20:32:40,922] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 74.0, 0.0, 0.0, 26.0, 23.62762680305556, -0.0336945460902464, 0.0, 1.0, 44418.69599713453], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 178200.0000, 
sim time next is 180000.0000, 
raw observation next is [-8.9, 74.0, 0.0, 0.0, 26.0, 23.54568417995201, -0.05218857429541362, 0.0, 1.0, 44333.559411405666], 
processed observation next is [1.0, 0.08695652173913043, 0.21606648199445982, 0.74, 0.0, 0.0, 0.6666666666666666, 0.46214034832933404, 0.48260380856819546, 0.0, 1.0, 0.21111218767336032], 
reward next is 0.7889, 
noisyNet noise sample is [array([-1.3733714], dtype=float32), -0.924014]. 
=============================================
[2019-04-06 20:32:40,926] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[79.18793 ]
 [79.19861 ]
 [79.181725]
 [78.941635]
 [78.975555]], R is [[79.31345367]
 [79.30879974]
 [79.30425262]
 [79.29937744]
 [79.29379272]].
[2019-04-06 20:32:45,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:32:45,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:32:45,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run28
[2019-04-06 20:32:48,442] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7460148e-12 1.5731807e-08 2.9764655e-10 8.5653336e-04 2.7635269e-11
 9.9914348e-01 7.7058802e-12], sum to 1.0000
[2019-04-06 20:32:48,442] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6928
[2019-04-06 20:32:48,570] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 25.21945579521984, 0.3898764214750214, 0.0, 1.0, 41919.85378751662], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3475800.0000, 
sim time next is 3477600.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 25.28544079368365, 0.3838751132060712, 0.0, 1.0, 41882.41290237039], 
processed observation next is [1.0, 0.2608695652173913, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.6071200661403043, 0.6279583710686903, 0.0, 1.0, 0.199440061439859], 
reward next is 0.8006, 
noisyNet noise sample is [array([1.0258744], dtype=float32), 0.924072]. 
=============================================
[2019-04-06 20:32:49,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:32:49,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:32:49,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run28
[2019-04-06 20:33:00,729] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.6506735e-13 1.0572505e-10 1.3295574e-12 1.4017259e-05 2.8053874e-14
 9.9998593e-01 1.5586081e-12], sum to 1.0000
[2019-04-06 20:33:00,729] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7769
[2019-04-06 20:33:00,788] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 108.0, 0.0, 26.0, 26.18942768150499, 0.507045081338826, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4710600.0000, 
sim time next is 4712400.0000, 
raw observation next is [1.0, 86.0, 121.5, 0.0, 26.0, 25.77949146244591, 0.4401186315574351, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.4903047091412743, 0.86, 0.405, 0.0, 0.6666666666666666, 0.648290955203826, 0.646706210519145, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.36096117], dtype=float32), -0.39111602]. 
=============================================
[2019-04-06 20:33:06,510] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.66658222e-12 7.98793753e-10 1.13575555e-11 9.19022641e-05
 1.11444198e-12 9.99908090e-01 7.08057571e-11], sum to 1.0000
[2019-04-06 20:33:06,510] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6785
[2019-04-06 20:33:06,993] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 96.0, 9.0, 0.0, 26.0, 25.05206540054802, 0.4296557459549815, 1.0, 1.0, 64407.78654499692], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1357200.0000, 
sim time next is 1359000.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 26.0, 25.23016461444415, 0.4476352517849304, 1.0, 1.0, 70456.0379295622], 
processed observation next is [1.0, 0.7391304347826086, 0.4764542936288089, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6025137178703458, 0.6492117505949768, 1.0, 1.0, 0.33550494252172475], 
reward next is 0.6645, 
noisyNet noise sample is [array([1.1699816], dtype=float32), 1.6725398]. 
=============================================
[2019-04-06 20:33:06,997] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[92.569115]
 [92.21096 ]
 [92.135796]
 [91.93163 ]
 [92.17388 ]], R is [[92.69444275]
 [92.46080017]
 [92.45317078]
 [92.32933807]
 [92.40604401]].
[2019-04-06 20:33:18,156] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5562363e-11 1.5685039e-09 6.0265078e-11 2.6302482e-04 1.4898021e-12
 9.9973696e-01 2.4153169e-11], sum to 1.0000
[2019-04-06 20:33:18,156] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1580
[2019-04-06 20:33:18,238] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 74.0, 0.0, 0.0, 26.0, 25.33061779116491, 0.3774866062497326, 0.0, 1.0, 40305.76909346514], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3904200.0000, 
sim time next is 3906000.0000, 
raw observation next is [-4.0, 77.0, 0.0, 0.0, 26.0, 25.23177332830274, 0.3542915745484712, 0.0, 1.0, 41309.402258936454], 
processed observation next is [1.0, 0.21739130434782608, 0.3518005540166205, 0.77, 0.0, 0.0, 0.6666666666666666, 0.6026477773585617, 0.618097191516157, 0.0, 1.0, 0.19671143932826882], 
reward next is 0.8033, 
noisyNet noise sample is [array([-0.7311501], dtype=float32), 1.9704796]. 
=============================================
[2019-04-06 20:33:18,242] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[86.0697  ]
 [85.97359 ]
 [85.91527 ]
 [85.719444]
 [85.46133 ]], R is [[86.10753632]
 [86.05452728]
 [86.00414276]
 [85.85311127]
 [85.85303497]].
[2019-04-06 20:33:20,538] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5234340e-10 5.9585940e-08 6.1946870e-10 1.5922944e-03 4.6411881e-11
 9.9840766e-01 4.9497273e-10], sum to 1.0000
[2019-04-06 20:33:20,538] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6629
[2019-04-06 20:33:20,653] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 75.0, 0.0, 0.0, 26.0, 23.31655173008694, -0.06945395021849109, 0.0, 1.0, 44891.3283310394], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 108000.0000, 
sim time next is 109800.0000, 
raw observation next is [-7.0, 71.5, 0.0, 0.0, 26.0, 23.23874929656838, -0.08962474816215937, 0.0, 1.0, 45437.14863550841], 
processed observation next is [1.0, 0.2608695652173913, 0.2686980609418283, 0.715, 0.0, 0.0, 0.6666666666666666, 0.4365624413806983, 0.4701250839459468, 0.0, 1.0, 0.21636737445480198], 
reward next is 0.7836, 
noisyNet noise sample is [array([0.2426051], dtype=float32), 0.71339947]. 
=============================================
[2019-04-06 20:33:26,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:33:26,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:33:26,486] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run28
[2019-04-06 20:33:31,996] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:33:31,996] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:33:31,999] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run28
[2019-04-06 20:33:38,787] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-06 20:33:38,789] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:33:38,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:33:38,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run62
[2019-04-06 20:33:38,904] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:33:38,904] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:33:38,908] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run62
[2019-04-06 20:33:39,089] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:33:39,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:33:39,093] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run62
[2019-04-06 20:36:11,004] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.5648 79959984.5800 535.1579
[2019-04-06 20:36:31,337] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 20:36:31,549] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 20:36:32,572] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1220000, evaluation results [1220000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.564818314419, 79959984.58002774, 535.1579115189242, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 20:36:34,795] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7950693e-12 1.0006349e-09 7.9865677e-11 2.2291634e-04 1.3691913e-12
 9.9977714e-01 2.0856750e-11], sum to 1.0000
[2019-04-06 20:36:34,795] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9326
[2019-04-06 20:36:34,932] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.3, 68.0, 0.0, 0.0, 26.0, 25.47147141795237, 0.4330141496297703, 0.0, 1.0, 25472.813883864572], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4591800.0000, 
sim time next is 4593600.0000, 
raw observation next is [-1.5, 69.0, 0.0, 0.0, 26.0, 25.41576766497441, 0.4035105577577499, 0.0, 1.0, 30405.626455395017], 
processed observation next is [1.0, 0.17391304347826086, 0.4210526315789474, 0.69, 0.0, 0.0, 0.6666666666666666, 0.6179806387478676, 0.6345035192525833, 0.0, 1.0, 0.14478869740664294], 
reward next is 0.8552, 
noisyNet noise sample is [array([-1.5930895], dtype=float32), 0.42691663]. 
=============================================
[2019-04-06 20:36:41,326] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:36:41,327] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:36:41,330] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run28
[2019-04-06 20:36:42,889] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2051223e-09 2.5751081e-07 5.3952082e-08 3.4129224e-03 5.5331979e-09
 9.9658680e-01 1.7491672e-08], sum to 1.0000
[2019-04-06 20:36:42,898] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3931
[2019-04-06 20:36:42,992] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-15.6, 73.0, 0.0, 0.0, 26.0, 22.15079648645574, -0.3633485886600996, 0.0, 1.0, 49383.659540473775], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 361800.0000, 
sim time next is 363600.0000, 
raw observation next is [-15.6, 73.0, 0.0, 0.0, 26.0, 22.21446572366201, -0.3689905473893969, 0.0, 1.0, 49253.545066771294], 
processed observation next is [1.0, 0.21739130434782608, 0.030470914127423816, 0.73, 0.0, 0.0, 0.6666666666666666, 0.3512054769718341, 0.37700315087020103, 0.0, 1.0, 0.23454069079414902], 
reward next is 0.7655, 
noisyNet noise sample is [array([-1.203352], dtype=float32), 0.991101]. 
=============================================
[2019-04-06 20:37:01,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:37:01,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:37:01,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run28
[2019-04-06 20:37:21,420] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.9805772e-13 2.2275377e-10 2.4956925e-12 3.7137643e-04 4.4266850e-14
 9.9962866e-01 1.2013628e-12], sum to 1.0000
[2019-04-06 20:37:21,421] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4709
[2019-04-06 20:37:21,473] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.2, 31.5, 195.0, 629.0, 26.0, 28.73307649749894, 1.061406811481945, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4372200.0000, 
sim time next is 4374000.0000, 
raw observation next is [13.9, 32.0, 149.0, 314.5, 26.0, 28.05282531527876, 1.08504975634544, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.847645429362881, 0.32, 0.49666666666666665, 0.3475138121546961, 0.6666666666666666, 0.8377354429398967, 0.8616832521151467, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.510142], dtype=float32), 1.0747682]. 
=============================================
[2019-04-06 20:37:21,478] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[98.86279 ]
 [98.44401 ]
 [98.0083  ]
 [97.76935 ]
 [97.332535]], R is [[98.05542755]
 [98.07487488]
 [98.09412384]
 [98.11318207]
 [98.13204956]].
[2019-04-06 20:37:22,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:37:22,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:37:22,324] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run28
[2019-04-06 20:37:27,427] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0169931e-12 2.4057081e-09 6.6759575e-12 4.6504858e-05 2.0388085e-11
 9.9995351e-01 1.1498074e-11], sum to 1.0000
[2019-04-06 20:37:27,427] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3067
[2019-04-06 20:37:27,471] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.0, 25.5, 34.0, 304.0, 26.0, 27.50523803938095, 0.8256053838767308, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4987800.0000, 
sim time next is 4989600.0000, 
raw observation next is [6.0, 25.0, 17.0, 152.0, 26.0, 27.21147079733535, 0.6694008929908072, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6288088642659281, 0.25, 0.056666666666666664, 0.16795580110497238, 0.6666666666666666, 0.7676225664446124, 0.7231336309969357, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2271137], dtype=float32), 1.3533856]. 
=============================================
[2019-04-06 20:37:32,544] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:37:32,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:37:32,548] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run28
[2019-04-06 20:37:37,329] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:37:37,329] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:37:37,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run28
[2019-04-06 20:37:50,379] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.4644084e-11 1.9051267e-09 9.3585251e-10 1.0038539e-03 3.3059427e-11
 9.9899620e-01 3.0481939e-10], sum to 1.0000
[2019-04-06 20:37:50,402] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5798
[2019-04-06 20:37:50,491] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 37.0, 0.0, 0.0, 26.0, 25.80009934946773, 0.5672273438275154, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5004000.0000, 
sim time next is 5005800.0000, 
raw observation next is [3.0, 35.5, 0.0, 0.0, 26.0, 25.60721299289824, 0.4702107288534719, 0.0, 1.0, 38590.829804635665], 
processed observation next is [1.0, 0.9565217391304348, 0.5457063711911359, 0.355, 0.0, 0.0, 0.6666666666666666, 0.6339344160748533, 0.656736909617824, 0.0, 1.0, 0.1837658562125508], 
reward next is 0.8162, 
noisyNet noise sample is [array([0.17098112], dtype=float32), 0.21128291]. 
=============================================
[2019-04-06 20:37:54,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3659738e-11 4.6979700e-09 3.3507752e-10 1.0249814e-03 9.6849341e-11
 9.9897504e-01 6.0774419e-10], sum to 1.0000
[2019-04-06 20:37:54,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6268
[2019-04-06 20:37:54,653] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.55, 55.0, 0.0, 0.0, 26.0, 26.47225836474515, 0.7600301564570654, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1103400.0000, 
sim time next is 1105200.0000, 
raw observation next is [15.0, 57.0, 0.0, 0.0, 26.0, 26.27744130050078, 0.7354246004738254, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.8781163434903049, 0.57, 0.0, 0.0, 0.6666666666666666, 0.6897867750417316, 0.7451415334912751, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.28351542], dtype=float32), 0.88818353]. 
=============================================
[2019-04-06 20:37:55,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:37:55,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:37:55,616] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run28
[2019-04-06 20:38:00,995] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.3878686e-11 8.0931724e-09 7.1903324e-11 1.0894939e-03 5.1233146e-11
 9.9891055e-01 2.1160507e-10], sum to 1.0000
[2019-04-06 20:38:00,995] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9057
[2019-04-06 20:38:01,140] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 26.0, 25.00094296955248, 0.3190635547795515, 0.0, 1.0, 45636.23658199465], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1792800.0000, 
sim time next is 1794600.0000, 
raw observation next is [-4.2, 82.5, 0.0, 0.0, 26.0, 25.00170275479142, 0.3164936431256818, 0.0, 1.0, 48424.696119428285], 
processed observation next is [0.0, 0.782608695652174, 0.34626038781163443, 0.825, 0.0, 0.0, 0.6666666666666666, 0.5834752295659517, 0.605497881041894, 0.0, 1.0, 0.2305937910448966], 
reward next is 0.7694, 
noisyNet noise sample is [array([0.7609078], dtype=float32), -2.2797933]. 
=============================================
[2019-04-06 20:38:02,470] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:38:02,470] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:38:02,474] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run28
[2019-04-06 20:38:07,731] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:38:07,732] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:38:07,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run28
[2019-04-06 20:38:28,219] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.21589413e-12 8.05879585e-10 9.20835348e-13 1.10456436e-04
 2.97500002e-12 9.99889493e-01 8.30574064e-12], sum to 1.0000
[2019-04-06 20:38:28,219] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2861
[2019-04-06 20:38:28,546] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 82.0, 123.0, 77.5, 26.0, 25.48065807651072, 0.3381847230361474, 1.0, 1.0, 6247.16051195282], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2106000.0000, 
sim time next is 2107800.0000, 
raw observation next is [-7.8, 82.0, 174.0, 118.0, 26.0, 25.66157099436104, 0.384601334618856, 1.0, 1.0, 26280.768846567866], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.82, 0.58, 0.13038674033149172, 0.6666666666666666, 0.6384642495300866, 0.628200444872952, 1.0, 1.0, 0.12514651831698984], 
reward next is 0.8749, 
noisyNet noise sample is [array([1.364452], dtype=float32), -0.28037968]. 
=============================================
[2019-04-06 20:38:45,296] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0400064e-11 2.7845093e-08 1.6046107e-10 4.4495126e-05 3.0657261e-11
 9.9995542e-01 1.6966697e-10], sum to 1.0000
[2019-04-06 20:38:45,296] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4179
[2019-04-06 20:38:45,664] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 87.0, 0.0, 0.0, 26.0, 24.94341702800877, 0.289773327911177, 0.0, 1.0, 45664.5030274184], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 581400.0000, 
sim time next is 583200.0000, 
raw observation next is [-2.3, 87.0, 0.0, 0.0, 26.0, 24.94950143947172, 0.2874057213154576, 0.0, 1.0, 44764.85659138769], 
processed observation next is [0.0, 0.782608695652174, 0.3988919667590028, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5791251199559767, 0.5958019071051526, 0.0, 1.0, 0.2131659837685128], 
reward next is 0.7868, 
noisyNet noise sample is [array([0.89257836], dtype=float32), 0.7982609]. 
=============================================
[2019-04-06 20:39:00,756] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6630724e-11 9.1713490e-09 2.0721218e-10 2.6271720e-03 7.4747854e-11
 9.9737287e-01 1.3709114e-10], sum to 1.0000
[2019-04-06 20:39:00,756] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4844
[2019-04-06 20:39:00,847] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.38947844442468, 0.1217054601969802, 0.0, 1.0, 41525.27562063403], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1998000.0000, 
sim time next is 1999800.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.38120711482748, 0.1178963331155424, 0.0, 1.0, 41354.057980619014], 
processed observation next is [1.0, 0.13043478260869565, 0.30747922437673136, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5317672595689565, 0.5392987777051809, 0.0, 1.0, 0.19692408562199532], 
reward next is 0.8031, 
noisyNet noise sample is [array([0.26087976], dtype=float32), 0.59905523]. 
=============================================
[2019-04-06 20:39:21,700] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-06 20:39:21,701] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:39:21,702] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:39:21,705] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:39:21,705] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:39:21,709] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run63
[2019-04-06 20:39:21,745] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:39:21,745] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:39:21,766] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run63
[2019-04-06 20:39:21,802] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run63
[2019-04-06 20:40:35,489] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.06001969], dtype=float32), 0.13186891]
[2019-04-06 20:40:35,490] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [13.83113011, 84.37445868, 32.10977657, 0.0, 26.0, 26.20658781305883, 0.5818903946588733, 1.0, 1.0, 0.0]
[2019-04-06 20:40:35,490] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 20:40:35,491] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [3.6527335e-12 1.6158924e-09 1.1129509e-11 1.9539842e-04 2.9966667e-12
 9.9980468e-01 1.1959799e-11], sampled 0.7225065533164463
[2019-04-06 20:41:59,125] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 20:42:18,229] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 20:42:18,752] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2891 91944900.5891 409.3749
[2019-04-06 20:42:19,774] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1240000, evaluation results [1240000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.2891096038065, 91944900.58913434, 409.3749352301794]
[2019-04-06 20:42:26,425] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9009057e-11 5.2493920e-09 1.6562578e-10 1.7777782e-04 9.3303785e-12
 9.9982220e-01 2.0478597e-10], sum to 1.0000
[2019-04-06 20:42:26,425] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0512
[2019-04-06 20:42:26,551] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 82.0, 174.0, 118.0, 26.0, 25.66157099436104, 0.384601334618856, 1.0, 1.0, 26280.768846567866], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2107800.0000, 
sim time next is 2109600.0000, 
raw observation next is [-7.8, 82.0, 191.0, 89.0, 26.0, 25.84290754779257, 0.4027765732773818, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.24653739612188366, 0.82, 0.6366666666666667, 0.09834254143646409, 0.6666666666666666, 0.6535756289827143, 0.6342588577591273, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17367043], dtype=float32), 0.117044345]. 
=============================================
[2019-04-06 20:42:39,862] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0960762e-09 8.7781107e-09 6.2556982e-10 1.7744073e-03 4.0186472e-11
 9.9822563e-01 2.4238087e-10], sum to 1.0000
[2019-04-06 20:42:39,862] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5840
[2019-04-06 20:42:39,931] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 72.5, 0.0, 0.0, 26.0, 23.95344360510399, 0.05413602745979349, 0.0, 1.0, 41499.41500860982], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 786600.0000, 
sim time next is 788400.0000, 
raw observation next is [-7.8, 74.0, 0.0, 0.0, 26.0, 23.8706405318644, 0.04652192901628693, 0.0, 1.0, 41385.3046296609], 
processed observation next is [1.0, 0.13043478260869565, 0.24653739612188366, 0.74, 0.0, 0.0, 0.6666666666666666, 0.4892200443220333, 0.5155073096720956, 0.0, 1.0, 0.19707287918886143], 
reward next is 0.8029, 
noisyNet noise sample is [array([-0.22353001], dtype=float32), 1.5747308]. 
=============================================
[2019-04-06 20:42:51,289] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.8488746e-10 2.2058762e-07 1.3536683e-10 8.1848196e-04 1.3151195e-10
 9.9918133e-01 4.1294791e-11], sum to 1.0000
[2019-04-06 20:42:51,289] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5023
[2019-04-06 20:42:51,316] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 54.0, 116.0, 805.5, 26.0, 25.94001885601104, 0.5578672511731724, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3330000.0000, 
sim time next is 3331800.0000, 
raw observation next is [-4.5, 52.0, 114.0, 800.0, 26.0, 26.01127376304867, 0.5806633954306307, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3379501385041552, 0.52, 0.38, 0.8839779005524862, 0.6666666666666666, 0.6676061469207225, 0.6935544651435436, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.201229], dtype=float32), -1.9297559]. 
=============================================
[2019-04-06 20:42:52,920] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.5918950e-11 1.6009611e-07 4.1843773e-10 4.5149522e-03 2.2502725e-11
 9.9548495e-01 5.9692690e-10], sum to 1.0000
[2019-04-06 20:42:52,921] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8114
[2019-04-06 20:42:53,060] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 55.0, 31.0, 286.5, 26.0, 25.09527684634763, 0.3689477632659163, 0.0, 1.0, 34431.35245905115], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2998800.0000, 
sim time next is 3000600.0000, 
raw observation next is [-1.5, 57.5, 6.0, 99.0, 26.0, 25.05503100006522, 0.3403752114116368, 0.0, 1.0, 38354.748020471576], 
processed observation next is [0.0, 0.7391304347826086, 0.4210526315789474, 0.575, 0.02, 0.10939226519337017, 0.6666666666666666, 0.587919250005435, 0.613458403803879, 0.0, 1.0, 0.18264165724034084], 
reward next is 0.8174, 
noisyNet noise sample is [array([0.46998644], dtype=float32), 1.1243651]. 
=============================================
[2019-04-06 20:43:09,522] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:43:09,522] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:43:09,526] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run29
[2019-04-06 20:43:19,329] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.29497540e-12 7.74543596e-10 1.23771115e-11 3.57320620e-04
 2.31616271e-11 9.99642611e-01 3.97769422e-11], sum to 1.0000
[2019-04-06 20:43:19,329] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8842
[2019-04-06 20:43:19,414] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 26.0, 25.3558234533264, 0.4832139204532866, 0.0, 1.0, 41402.151586451306], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1468800.0000, 
sim time next is 1470600.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 26.0, 25.35270305277118, 0.510984316300366, 0.0, 1.0, 38120.16805905291], 
processed observation next is [1.0, 0.0, 0.5069252077562327, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6127252543975983, 0.6703281054334553, 0.0, 1.0, 0.18152460980501384], 
reward next is 0.8185, 
noisyNet noise sample is [array([0.44909245], dtype=float32), -0.8652458]. 
=============================================
[2019-04-06 20:43:25,457] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2482828e-11 1.9629953e-09 5.5983652e-11 2.6372416e-04 1.5228409e-11
 9.9973625e-01 4.2167134e-11], sum to 1.0000
[2019-04-06 20:43:25,457] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1593
[2019-04-06 20:43:25,610] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8, 87.0, 0.0, 0.0, 26.0, 25.00175268903764, 0.2827527888802362, 0.0, 1.0, 35835.64141317395], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3090600.0000, 
sim time next is 3092400.0000, 
raw observation next is [-1.0, 92.0, 0.0, 0.0, 26.0, 24.99748039798364, 0.27530477630989, 0.0, 1.0, 34588.026742982496], 
processed observation next is [0.0, 0.8260869565217391, 0.4349030470914128, 0.92, 0.0, 0.0, 0.6666666666666666, 0.5831233664986367, 0.5917682587699633, 0.0, 1.0, 0.1647048892522976], 
reward next is 0.8353, 
noisyNet noise sample is [array([-1.7118379], dtype=float32), -0.6538779]. 
=============================================
[2019-04-06 20:44:16,952] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8501682e-12 4.7725229e-10 1.2963279e-11 6.4231834e-05 1.3372302e-11
 9.9993575e-01 6.3879067e-12], sum to 1.0000
[2019-04-06 20:44:16,952] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6900
[2019-04-06 20:44:17,063] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 100.0, 0.0, 0.0, 26.0, 25.29962031211526, 0.3234255689822552, 0.0, 1.0, 40448.93808602036], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3110400.0000, 
sim time next is 3112200.0000, 
raw observation next is [0.5, 100.0, 0.0, 0.0, 26.0, 25.30590056233434, 0.320850936082458, 0.0, 1.0, 39585.58331613363], 
processed observation next is [1.0, 0.0, 0.4764542936288089, 1.0, 0.0, 0.0, 0.6666666666666666, 0.608825046861195, 0.6069503120274861, 0.0, 1.0, 0.18850277769587442], 
reward next is 0.8115, 
noisyNet noise sample is [array([1.0860724], dtype=float32), 0.2225085]. 
=============================================
[2019-04-06 20:44:26,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:44:26,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:44:26,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run29
[2019-04-06 20:44:27,523] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4125283e-11 3.0123768e-09 3.6906967e-11 1.5983876e-04 2.2325681e-11
 9.9984014e-01 1.6661629e-11], sum to 1.0000
[2019-04-06 20:44:27,527] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3367
[2019-04-06 20:44:27,606] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 44.0, 0.0, 0.0, 26.0, 25.22788796881627, 0.4133522363374943, 0.0, 1.0, 80238.5798685838], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2840400.0000, 
sim time next is 2842200.0000, 
raw observation next is [2.0, 44.0, 0.0, 0.0, 26.0, 25.43974332867863, 0.4360251709378224, 0.0, 1.0, 37587.373308700095], 
processed observation next is [1.0, 0.9130434782608695, 0.518005540166205, 0.44, 0.0, 0.0, 0.6666666666666666, 0.6199786107232192, 0.6453417236459408, 0.0, 1.0, 0.17898749194619093], 
reward next is 0.8210, 
noisyNet noise sample is [array([-1.4385253], dtype=float32), -0.600315]. 
=============================================
[2019-04-06 20:44:46,485] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:44:46,485] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:44:46,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run29
[2019-04-06 20:44:46,923] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5284959e-11 6.5528823e-08 4.3916545e-10 1.0620963e-03 2.0445373e-11
 9.9893779e-01 2.9338881e-10], sum to 1.0000
[2019-04-06 20:44:46,923] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9465
[2019-04-06 20:44:47,145] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 26.0, 25.14611155455324, 0.3206918422549619, 0.0, 1.0, 39037.15710630052], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3016800.0000, 
sim time next is 3018600.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 26.0, 25.11595390443992, 0.3074501131134546, 0.0, 1.0, 38647.34915227209], 
processed observation next is [0.0, 0.9565217391304348, 0.3518005540166205, 0.65, 0.0, 0.0, 0.6666666666666666, 0.5929961587033267, 0.6024833710378182, 0.0, 1.0, 0.18403499596320042], 
reward next is 0.8160, 
noisyNet noise sample is [array([1.1496172], dtype=float32), -0.21083447]. 
=============================================
[2019-04-06 20:44:47,511] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-06 20:44:47,512] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:44:47,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:44:47,516] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run64
[2019-04-06 20:44:47,626] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:44:47,626] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:44:47,667] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run64
[2019-04-06 20:44:47,723] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:44:47,724] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:44:47,744] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run64
[2019-04-06 20:46:35,131] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.05936808], dtype=float32), 0.13290648]
[2019-04-06 20:46:35,131] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-1.9, 75.0, 0.0, 0.0, 26.0, 24.71270242539802, 0.280346365546803, 0.0, 1.0, 50073.831199613625]
[2019-04-06 20:46:35,131] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 20:46:35,133] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.8414097e-11 4.4150927e-09 8.1690592e-11 1.8654816e-04 8.3862752e-12
 9.9981350e-01 4.4203967e-11], sampled 0.5591617825214882
[2019-04-06 20:47:21,519] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 20:47:41,474] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.05936808], dtype=float32), 0.13290648]
[2019-04-06 20:47:41,475] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [3.437766773, 44.53439737, 77.067527555, 412.53484605, 26.0, 25.30169560052846, 0.3754708330567413, 0.0, 1.0, 0.0]
[2019-04-06 20:47:41,475] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 20:47:41,475] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [5.7370674e-11 1.4907396e-08 2.9954600e-10 3.8151606e-04 4.2646546e-11
 9.9961841e-01 1.8203244e-10], sampled 0.0589242791762723
[2019-04-06 20:47:42,468] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.9138 87799002.1168 515.3043
[2019-04-06 20:47:44,217] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 20:47:45,239] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1260000, evaluation results [1260000.0, 2415.913755201966, 87799002.11678837, 515.3042642146117, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 20:47:48,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:47:48,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:47:48,439] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run29
[2019-04-06 20:47:54,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:47:54,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:47:54,184] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run29
[2019-04-06 20:47:57,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:47:57,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:47:57,888] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run29
[2019-04-06 20:48:12,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:48:12,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:48:12,183] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run29
[2019-04-06 20:48:18,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:48:18,554] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:48:18,574] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run29
[2019-04-06 20:48:21,740] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5582425e-12 5.5015836e-10 1.5795337e-11 3.1552743e-04 7.0127991e-13
 9.9968445e-01 1.3163258e-11], sum to 1.0000
[2019-04-06 20:48:21,740] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8532
[2019-04-06 20:48:21,796] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 100.0, 0.0, 0.0, 26.0, 25.41875754680582, 0.3466451376122295, 0.0, 1.0, 33120.7430389734], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3119400.0000, 
sim time next is 3121200.0000, 
raw observation next is [2.0, 100.0, 0.0, 0.0, 26.0, 25.48563922086829, 0.2997385861561997, 0.0, 1.0, 13982.698991874533], 
processed observation next is [1.0, 0.13043478260869565, 0.518005540166205, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6238032684056908, 0.5999128620520665, 0.0, 1.0, 0.06658428091368825], 
reward next is 0.9334, 
noisyNet noise sample is [array([-1.1561037], dtype=float32), -0.13620166]. 
=============================================
[2019-04-06 20:48:26,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:48:26,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:48:26,858] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run29
[2019-04-06 20:48:43,796] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:48:43,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:48:43,816] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run29
[2019-04-06 20:48:52,932] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.5252805e-10 2.5737886e-08 1.0092658e-09 3.8110953e-05 2.4164594e-11
 9.9996185e-01 3.2179415e-10], sum to 1.0000
[2019-04-06 20:48:52,933] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0168
[2019-04-06 20:48:53,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3993840e-11 7.5448039e-09 4.1525498e-11 2.9386041e-05 1.7520557e-12
 9.9997056e-01 5.0306144e-12], sum to 1.0000
[2019-04-06 20:48:53,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3032
[2019-04-06 20:48:53,202] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-16.7, 81.0, 12.5, 263.5, 26.0, 23.34937087830939, -0.1171762221104732, 0.0, 1.0, 127555.53272090649], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 374400.0000, 
sim time next is 376200.0000, 
raw observation next is [-16.15, 85.5, 25.0, 477.0, 26.0, 24.29385977118951, 0.07869889706107712, 1.0, 1.0, 86759.60851540334], 
processed observation next is [1.0, 0.34782608695652173, 0.015235457063711934, 0.855, 0.08333333333333333, 0.5270718232044199, 0.6666666666666666, 0.5244883142657925, 0.5262329656870257, 1.0, 1.0, 0.41314099293049206], 
reward next is 0.5869, 
noisyNet noise sample is [array([0.37137234], dtype=float32), 0.8678117]. 
=============================================
[2019-04-06 20:48:53,364] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.65, 84.5, 0.0, 0.0, 26.0, 25.04763792917684, 0.2727077749240627, 1.0, 1.0, 8187.350731190733], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 847800.0000, 
sim time next is 849600.0000, 
raw observation next is [-3.4, 83.0, 0.0, 0.0, 26.0, 24.89297718104966, 0.296338623743397, 0.0, 1.0, 89734.77931251843], 
processed observation next is [1.0, 0.8695652173913043, 0.368421052631579, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5744147650874716, 0.598779541247799, 0.0, 1.0, 0.4273084729167544], 
reward next is 0.5727, 
noisyNet noise sample is [array([-0.16959733], dtype=float32), -0.030024488]. 
=============================================
[2019-04-06 20:48:54,101] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4775212e-10 2.4638347e-09 2.5035829e-10 2.5662624e-03 2.7750368e-11
 9.9743372e-01 3.8209377e-11], sum to 1.0000
[2019-04-06 20:48:54,101] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1786
[2019-04-06 20:48:54,152] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 75.0, 25.0, 55.0, 26.0, 25.89782284037953, 0.5010175922278068, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4469400.0000, 
sim time next is 4471200.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 25.44504234336573, 0.5148626060936525, 1.0, 1.0, 26038.68921655045], 
processed observation next is [1.0, 0.782608695652174, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.6204201952804776, 0.6716208686978842, 1.0, 1.0, 0.12399375817404977], 
reward next is 0.8760, 
noisyNet noise sample is [array([-1.0617254], dtype=float32), 1.5558001]. 
=============================================
[2019-04-06 20:49:03,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:49:03,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:49:03,303] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run29
[2019-04-06 20:49:24,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:49:24,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:49:24,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run29
[2019-04-06 20:49:25,378] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4019446e-11 2.0835178e-09 1.4632524e-10 2.1932763e-04 2.4546756e-12
 9.9978071e-01 1.0779386e-11], sum to 1.0000
[2019-04-06 20:49:25,378] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9546
[2019-04-06 20:49:25,423] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 47.5, 89.0, 773.0, 26.0, 25.35882971036455, 0.382069213817876, 1.0, 1.0, 18680.597996368397], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 739800.0000, 
sim time next is 741600.0000, 
raw observation next is [0.5, 45.0, 84.5, 743.5, 26.0, 25.75822559584118, 0.4251256806359776, 1.0, 1.0, 6226.81391460893], 
processed observation next is [1.0, 0.6086956521739131, 0.4764542936288089, 0.45, 0.2816666666666667, 0.8215469613259668, 0.6666666666666666, 0.6465187996534315, 0.6417085602119925, 1.0, 1.0, 0.029651494831471094], 
reward next is 0.9703, 
noisyNet noise sample is [array([-1.7433962], dtype=float32), -2.3638906]. 
=============================================
[2019-04-06 20:49:28,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:49:28,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:49:28,132] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run29
[2019-04-06 20:49:54,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6048481e-14 1.9580993e-12 9.2248117e-13 1.4385715e-06 1.4537077e-15
 9.9999857e-01 2.2183410e-14], sum to 1.0000
[2019-04-06 20:49:54,563] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4024
[2019-04-06 20:49:54,602] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.3, 80.0, 0.0, 0.0, 26.0, 25.82268626879889, 0.5983144068625639, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1058400.0000, 
sim time next is 1060200.0000, 
raw observation next is [13.3, 80.0, 0.0, 0.0, 26.0, 25.66772719070872, 0.5789715453115704, 0.0, 1.0, 20654.27882965609], 
processed observation next is [1.0, 0.2608695652173913, 0.8310249307479226, 0.8, 0.0, 0.0, 0.6666666666666666, 0.6389772658923935, 0.6929905151038568, 0.0, 1.0, 0.09835370871264805], 
reward next is 0.9016, 
noisyNet noise sample is [array([-1.5422547], dtype=float32), -0.65794927]. 
=============================================
[2019-04-06 20:49:57,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:49:57,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:49:57,568] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run29
[2019-04-06 20:50:06,522] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:50:06,522] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:50:06,534] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run29
[2019-04-06 20:50:10,186] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:50:10,187] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:50:10,195] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run29
[2019-04-06 20:50:26,902] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 20:50:26,902] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:50:26,903] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:50:26,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run65
[2019-04-06 20:50:27,045] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:50:27,046] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:50:27,050] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run65
[2019-04-06 20:50:27,154] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:50:27,166] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:50:27,197] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run65
[2019-04-06 20:52:54,995] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.06078569], dtype=float32), 0.13287292]
[2019-04-06 20:52:54,995] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-4.4529735325, 76.610060945, 0.0, 0.0, 26.0, 24.16881223845303, 0.1366550359726501, 0.0, 1.0, 42373.24896906474]
[2019-04-06 20:52:54,995] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 20:52:54,996] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [5.2023923e-11 8.1668059e-09 2.2275920e-10 2.0599680e-04 2.2505069e-11
 9.9979407e-01 1.1879085e-10], sampled 0.9933574433265043
[2019-04-06 20:53:00,499] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 20:53:21,872] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 20:53:23,684] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 20:53:24,708] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 1280000, evaluation results [1280000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 20:54:02,471] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.6678900e-10 1.1826720e-07 1.4581990e-09 3.4123950e-04 1.3756736e-10
 9.9965858e-01 5.1352772e-10], sum to 1.0000
[2019-04-06 20:54:02,472] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7124
[2019-04-06 20:54:02,646] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.3, 36.0, 94.0, 0.0, 26.0, 24.44096525628457, 0.1806223074810993, 1.0, 1.0, 66131.976932777], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 484200.0000, 
sim time next is 486000.0000, 
raw observation next is [0.0, 37.0, 75.0, 0.0, 26.0, 25.59504763784712, 0.2857197871753176, 1.0, 1.0, 7971.582388175833], 
processed observation next is [1.0, 0.6521739130434783, 0.46260387811634357, 0.37, 0.25, 0.0, 0.6666666666666666, 0.63292063648726, 0.5952399290584393, 1.0, 1.0, 0.037959916134170636], 
reward next is 0.9620, 
noisyNet noise sample is [array([-0.31637922], dtype=float32), 1.5115014]. 
=============================================
[2019-04-06 20:54:02,650] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[75.24407 ]
 [74.650475]
 [74.42039 ]
 [73.85883 ]
 [73.20014 ]], R is [[75.58266449]
 [75.51192474]
 [75.75680542]
 [75.78025055]
 [75.68170166]].
[2019-04-06 20:54:39,338] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6308879e-14 5.3648395e-11 1.0280280e-12 1.9593466e-05 1.3265555e-13
 9.9998045e-01 1.2503835e-13], sum to 1.0000
[2019-04-06 20:54:39,338] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8061
[2019-04-06 20:54:39,458] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.4, 96.0, 0.0, 0.0, 26.0, 25.13118846047306, 0.3063244988459518, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 928800.0000, 
sim time next is 930600.0000, 
raw observation next is [4.4, 98.0, 0.0, 0.0, 26.0, 24.66757603789744, 0.2628617678631753, 1.0, 1.0, 91438.4710606904], 
processed observation next is [1.0, 0.782608695652174, 0.5844875346260389, 0.98, 0.0, 0.0, 0.6666666666666666, 0.5556313364914534, 0.5876205892877251, 1.0, 1.0, 0.43542129076519237], 
reward next is 0.5646, 
noisyNet noise sample is [array([1.1351402], dtype=float32), 0.47635913]. 
=============================================
[2019-04-06 20:54:59,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:54:59,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:54:59,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run30
[2019-04-06 20:55:04,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.7411922e-12 1.6206178e-08 3.8593208e-11 1.9401679e-04 2.0957834e-12
 9.9980599e-01 1.0177983e-11], sum to 1.0000
[2019-04-06 20:55:04,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7287
[2019-04-06 20:55:04,984] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 74.0, 0.0, 0.0, 26.0, 25.61425544687022, 0.5259566444359961, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3792600.0000, 
sim time next is 3794400.0000, 
raw observation next is [-3.0, 77.0, 0.0, 0.0, 26.0, 25.46033115782626, 0.5102853591504805, 0.0, 1.0, 60132.39192467623], 
processed observation next is [1.0, 0.9565217391304348, 0.3795013850415513, 0.77, 0.0, 0.0, 0.6666666666666666, 0.6216942631521883, 0.6700951197168269, 0.0, 1.0, 0.28634472345083917], 
reward next is 0.7137, 
noisyNet noise sample is [array([-0.41278118], dtype=float32), -1.7401766]. 
=============================================
[2019-04-06 20:55:21,296] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0051827e-10 2.7529522e-08 7.1736972e-10 8.1428280e-04 3.4476793e-11
 9.9918562e-01 2.2465403e-10], sum to 1.0000
[2019-04-06 20:55:21,296] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8450
[2019-04-06 20:55:21,577] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 59.5, 111.0, 758.0, 26.0, 25.57117083339504, 0.4816104547708062, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3580200.0000, 
sim time next is 3582000.0000, 
raw observation next is [-4.0, 54.0, 112.5, 787.0, 26.0, 25.36320656070966, 0.4529625221767962, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.3518005540166205, 0.54, 0.375, 0.8696132596685083, 0.6666666666666666, 0.613600546725805, 0.6509875073922654, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.70938706], dtype=float32), 4.192162]. 
=============================================
[2019-04-06 20:55:21,582] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[80.39978 ]
 [80.63556 ]
 [80.94977 ]
 [80.544716]
 [79.955505]], R is [[80.24040222]
 [80.43799591]
 [80.63361359]
 [80.82727814]
 [81.01900482]].
[2019-04-06 20:55:35,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0723845e-11 3.3302243e-09 3.9465234e-10 2.6000911e-04 2.3119070e-12
 9.9973994e-01 9.1600248e-11], sum to 1.0000
[2019-04-06 20:55:35,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4521
[2019-04-06 20:55:35,721] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 84.5, 0.0, 0.0, 26.0, 24.69544765937357, 0.2803102193037262, 0.0, 1.0, 43045.703782208606], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2946600.0000, 
sim time next is 2948400.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 26.0, 24.64372066448442, 0.2656114594595926, 0.0, 1.0, 42839.11943902652], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.84, 0.0, 0.0, 0.6666666666666666, 0.553643388707035, 0.5885371531531975, 0.0, 1.0, 0.20399580685250726], 
reward next is 0.7960, 
noisyNet noise sample is [array([-1.8044392], dtype=float32), 0.035616513]. 
=============================================
[2019-04-06 20:56:06,889] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 20:56:06,890] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:56:06,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:56:06,894] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:56:06,894] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:56:06,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run66
[2019-04-06 20:56:06,939] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:56:06,939] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:56:06,944] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run66
[2019-04-06 20:56:06,983] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run66
[2019-04-06 20:56:31,308] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.0603359], dtype=float32), 0.13327189]
[2019-04-06 20:56:31,308] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-3.4, 65.0, 0.0, 0.0, 26.0, 25.17668406079945, 0.2444036135847378, 1.0, 1.0, 0.0]
[2019-04-06 20:56:31,308] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 20:56:31,310] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.7292174e-11 8.1403755e-09 1.4966603e-10 3.0789684e-04 2.8525278e-11
 9.9969208e-01 1.3050369e-10], sampled 0.18927936028621906
[2019-04-06 20:58:38,773] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 20:58:57,097] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 20:58:58,804] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 20:58:59,826] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1300000, evaluation results [1300000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 20:59:03,822] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.62151217e-10 1.85654325e-09 1.77131559e-10 1.67721382e-03
 3.33553705e-11 9.98322785e-01 1.07341906e-10], sum to 1.0000
[2019-04-06 20:59:03,833] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9766
[2019-04-06 20:59:03,933] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 38.0, 0.0, 0.0, 26.0, 24.97773290196645, 0.1891119151999523, 0.0, 1.0, 38921.15513617144], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2512800.0000, 
sim time next is 2514600.0000, 
raw observation next is [-1.7, 41.0, 0.0, 0.0, 26.0, 24.97616346904096, 0.1852008749238173, 0.0, 1.0, 38758.96979778014], 
processed observation next is [1.0, 0.08695652173913043, 0.4155124653739613, 0.41, 0.0, 0.0, 0.6666666666666666, 0.5813469557534132, 0.5617336249746058, 0.0, 1.0, 0.1845665228465721], 
reward next is 0.8154, 
noisyNet noise sample is [array([-1.2309679], dtype=float32), 1.7426833]. 
=============================================
[2019-04-06 20:59:03,979] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4587659e-11 7.7722957e-09 8.4423118e-10 7.6022098e-04 7.7629049e-12
 9.9923980e-01 3.3946512e-11], sum to 1.0000
[2019-04-06 20:59:03,980] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7290
[2019-04-06 20:59:04,221] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.0, 58.0, 48.5, 314.5, 26.0, 25.70954889667954, 0.4402178677905227, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3916800.0000, 
sim time next is 3918600.0000, 
raw observation next is [-8.0, 55.5, 91.0, 466.0, 26.0, 25.77258075045681, 0.4679726537523053, 1.0, 1.0, 3123.54834102421], 
processed observation next is [1.0, 0.34782608695652173, 0.24099722991689754, 0.555, 0.30333333333333334, 0.5149171270718232, 0.6666666666666666, 0.6477150625380675, 0.6559908845841017, 1.0, 1.0, 0.014874039719162905], 
reward next is 0.9851, 
noisyNet noise sample is [array([-1.916704], dtype=float32), -0.70299494]. 
=============================================
[2019-04-06 20:59:09,710] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0217497e-10 5.1212292e-09 2.5992831e-11 3.2503458e-04 3.4414797e-12
 9.9967492e-01 5.7127159e-10], sum to 1.0000
[2019-04-06 20:59:09,710] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5059
[2019-04-06 20:59:09,818] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 43.0, 0.0, 0.0, 26.0, 24.99841747513477, 0.3293910075378421, 0.0, 1.0, 28734.896800474304], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4820400.0000, 
sim time next is 4822200.0000, 
raw observation next is [1.0, 45.0, 0.0, 0.0, 26.0, 25.02193110140155, 0.3746252504897609, 0.0, 1.0, 135259.23249767502], 
processed observation next is [0.0, 0.8260869565217391, 0.4903047091412743, 0.45, 0.0, 0.0, 0.6666666666666666, 0.5851609251167957, 0.6248750834965869, 0.0, 1.0, 0.644091583322262], 
reward next is 0.3559, 
noisyNet noise sample is [array([-0.2705378], dtype=float32), 0.5117191]. 
=============================================
[2019-04-06 20:59:18,908] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2576723e-12 6.2676257e-08 3.0709152e-10 1.0274373e-03 3.9556209e-11
 9.9897254e-01 1.8157486e-09], sum to 1.0000
[2019-04-06 20:59:18,908] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9749
[2019-04-06 20:59:18,943] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 71.0, 114.0, 817.0, 26.0, 26.63800912173961, 0.7595149352770812, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3240000.0000, 
sim time next is 3241800.0000, 
raw observation next is [-2.0, 78.0, 115.0, 823.0, 26.0, 26.65085786355317, 0.7526323983432257, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.40720221606648205, 0.78, 0.38333333333333336, 0.9093922651933701, 0.6666666666666666, 0.7209048219627642, 0.7508774661144085, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.283157], dtype=float32), -1.4833425]. 
=============================================
[2019-04-06 20:59:23,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:59:23,550] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:59:23,555] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run30
[2019-04-06 20:59:24,383] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8523008e-12 8.3084810e-09 9.8589305e-12 1.5222406e-04 2.3265657e-11
 9.9984777e-01 1.2649204e-10], sum to 1.0000
[2019-04-06 20:59:24,384] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2701
[2019-04-06 20:59:24,498] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.7, 71.0, 0.0, 0.0, 26.0, 24.87557183568607, 0.3223028093602953, 0.0, 1.0, 150572.2726494495], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4303800.0000, 
sim time next is 4305600.0000, 
raw observation next is [5.4, 73.0, 0.0, 0.0, 26.0, 25.35342120228236, 0.4478364881411214, 0.0, 1.0, 112685.32806709124], 
processed observation next is [0.0, 0.8695652173913043, 0.6121883656509697, 0.73, 0.0, 0.0, 0.6666666666666666, 0.6127851001901966, 0.6492788293803738, 0.0, 1.0, 0.5365968003194821], 
reward next is 0.4634, 
noisyNet noise sample is [array([0.6284151], dtype=float32), 0.22813797]. 
=============================================
[2019-04-06 20:59:28,209] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0148032e-12 3.0246414e-09 3.3099048e-11 7.1028061e-04 5.8549091e-13
 9.9928963e-01 9.9868004e-12], sum to 1.0000
[2019-04-06 20:59:28,209] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8117
[2019-04-06 20:59:28,255] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.5, 19.5, 111.0, 819.0, 26.0, 28.29822797726312, 1.057243774114189, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5063400.0000, 
sim time next is 5065200.0000, 
raw observation next is [12.0, 19.0, 103.5, 782.0, 26.0, 28.55247690706437, 1.108481634662004, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.7950138504155125, 0.19, 0.345, 0.8640883977900552, 0.6666666666666666, 0.8793730755886976, 0.869493878220668, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8546942], dtype=float32), 1.1950322]. 
=============================================
[2019-04-06 20:59:29,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5237192e-11 2.5298066e-09 1.5815965e-10 2.6124027e-03 5.2549315e-12
 9.9738759e-01 1.5391971e-10], sum to 1.0000
[2019-04-06 20:59:29,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6103
[2019-04-06 20:59:29,679] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 45.0, 67.5, 252.0, 26.0, 25.14214810492108, 0.339012537510585, 0.0, 1.0, 6226.803890076847], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4899600.0000, 
sim time next is 4901400.0000, 
raw observation next is [2.5, 44.5, 33.0, 187.0, 26.0, 25.02982166320326, 0.3204341676432377, 0.0, 1.0, 40499.63141744026], 
processed observation next is [0.0, 0.7391304347826086, 0.5318559556786704, 0.445, 0.11, 0.20662983425414364, 0.6666666666666666, 0.5858184719336051, 0.6068113892144126, 0.0, 1.0, 0.19285538770209645], 
reward next is 0.8071, 
noisyNet noise sample is [array([-0.49492526], dtype=float32), -0.35901046]. 
=============================================
[2019-04-06 20:59:30,221] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:59:30,221] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:59:30,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run30
[2019-04-06 20:59:30,670] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2800900e-13 9.3448818e-11 3.5352715e-12 9.7990487e-06 8.3397482e-14
 9.9999022e-01 1.6473717e-12], sum to 1.0000
[2019-04-06 20:59:30,670] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4683
[2019-04-06 20:59:30,826] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 93.0, 105.0, 156.0, 26.0, 25.08078242628812, 0.3143476209099918, 1.0, 1.0, 35846.19611820005], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2881800.0000, 
sim time next is 2883600.0000, 
raw observation next is [1.0, 93.0, 77.0, 78.0, 26.0, 25.34201775090492, 0.3161023597650016, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4903047091412743, 0.93, 0.25666666666666665, 0.0861878453038674, 0.6666666666666666, 0.61183481257541, 0.6053674532550005, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.68275124], dtype=float32), 1.0461477]. 
=============================================
[2019-04-06 20:59:37,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:59:37,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:59:37,916] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run30
[2019-04-06 20:59:39,177] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1522471e-13 1.7857037e-11 3.2380492e-13 4.3532041e-06 8.0132163e-15
 9.9999559e-01 7.4003812e-14], sum to 1.0000
[2019-04-06 20:59:39,177] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9564
[2019-04-06 20:59:39,237] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.25, 92.5, 0.0, 0.0, 26.0, 25.31963184388946, 0.4260466376212028, 0.0, 1.0, 38121.74753078892], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 952200.0000, 
sim time next is 954000.0000, 
raw observation next is [5.5, 89.0, 0.0, 0.0, 26.0, 25.30799646871146, 0.425069209294445, 0.0, 1.0, 38035.04296869299], 
processed observation next is [1.0, 0.043478260869565216, 0.6149584487534627, 0.89, 0.0, 0.0, 0.6666666666666666, 0.6089997057259549, 0.6416897364314816, 0.0, 1.0, 0.1811192522318714], 
reward next is 0.8189, 
noisyNet noise sample is [array([2.2608798], dtype=float32), -0.7483329]. 
=============================================
[2019-04-06 20:59:39,249] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[96.326035]
 [95.96394 ]
 [95.94327 ]
 [95.60838 ]
 [95.715195]], R is [[96.14666748]
 [96.00366974]
 [95.86103821]
 [95.71839142]
 [95.57559204]].
[2019-04-06 20:59:39,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:59:39,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:59:39,915] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run30
[2019-04-06 20:59:46,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:59:46,762] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:59:46,766] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run30
[2019-04-06 20:59:51,273] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3048914e-11 7.7061074e-10 1.3399153e-10 8.6390501e-05 4.5851478e-12
 9.9991357e-01 3.3751564e-11], sum to 1.0000
[2019-04-06 20:59:51,276] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7004
[2019-04-06 20:59:51,363] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 26.0, 25.26267830552031, 0.4025018251259354, 0.0, 1.0, 57230.88163258362], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3895200.0000, 
sim time next is 3897000.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 26.0, 25.69747306426743, 0.4425194377114887, 0.0, 1.0, 20534.93149879975], 
processed observation next is [1.0, 0.08695652173913043, 0.40720221606648205, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6414560886889525, 0.6475064792371629, 0.0, 1.0, 0.09778538808952261], 
reward next is 0.9022, 
noisyNet noise sample is [array([1.9884025], dtype=float32), 0.20662864]. 
=============================================
[2019-04-06 20:59:51,414] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[87.70333 ]
 [87.333916]
 [87.216934]
 [87.13552 ]
 [86.833374]], R is [[87.49959564]
 [87.35207367]
 [87.40945435]
 [87.34539795]
 [87.26556396]].
[2019-04-06 20:59:57,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:59:57,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:59:57,662] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run30
[2019-04-06 21:00:03,320] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:00:03,320] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:00:03,324] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run30
[2019-04-06 21:00:07,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:00:07,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:00:07,797] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run30
[2019-04-06 21:00:08,558] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5409042e-10 2.9420555e-08 1.1290087e-10 8.8183682e-05 6.1418738e-11
 9.9991179e-01 7.6942414e-10], sum to 1.0000
[2019-04-06 21:00:08,559] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9998
[2019-04-06 21:00:08,619] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 30.0, 118.5, 834.5, 26.0, 25.11174259382972, 0.3942277463157997, 0.0, 1.0, 13876.265721359372], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4190400.0000, 
sim time next is 4192200.0000, 
raw observation next is [1.5, 32.0, 118.0, 847.0, 26.0, 25.13511929871345, 0.3980628710535705, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.5041551246537397, 0.32, 0.3933333333333333, 0.9359116022099447, 0.6666666666666666, 0.5945932748927877, 0.6326876236845235, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.41178966], dtype=float32), -0.084255874]. 
=============================================
[2019-04-06 21:00:18,353] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5252133e-10 1.6485906e-08 2.0979626e-10 4.4878526e-04 2.8856121e-12
 9.9955112e-01 1.5254810e-10], sum to 1.0000
[2019-04-06 21:00:18,355] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2456
[2019-04-06 21:00:18,385] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 37.0, 122.5, 734.5, 26.0, 25.12872383741856, 0.4430403473779829, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4806000.0000, 
sim time next is 4807800.0000, 
raw observation next is [3.0, 37.0, 97.0, 727.0, 26.0, 25.18501721192654, 0.4432620315263363, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.5457063711911359, 0.37, 0.3233333333333333, 0.8033149171270718, 0.6666666666666666, 0.5987514343272116, 0.6477540105087788, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47635287], dtype=float32), 0.19524045]. 
=============================================
[2019-04-06 21:00:33,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:00:33,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:00:33,078] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run30
[2019-04-06 21:00:33,150] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.24348229e-12 1.15764465e-08 1.21948479e-10 4.87537269e-04
 9.20013371e-11 9.99512434e-01 6.23507981e-11], sum to 1.0000
[2019-04-06 21:00:33,150] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5750
[2019-04-06 21:00:33,178] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.0, 47.0, 95.5, 740.5, 26.0, 25.47949943248313, 0.484377192906331, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3682800.0000, 
sim time next is 3684600.0000, 
raw observation next is [5.5, 48.5, 87.0, 705.0, 26.0, 25.5168452757637, 0.4879658518173212, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.6149584487534627, 0.485, 0.29, 0.7790055248618785, 0.6666666666666666, 0.6264037729803084, 0.662655283939107, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2561595], dtype=float32), -2.1545022]. 
=============================================
[2019-04-06 21:00:43,471] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9111017e-12 4.3546406e-09 1.6594323e-11 5.7220979e-05 5.3825786e-13
 9.9994278e-01 9.5937685e-12], sum to 1.0000
[2019-04-06 21:00:43,471] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1292
[2019-04-06 21:00:43,546] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.85303713939475, 0.184685454245594, 0.0, 1.0, 42266.27803130492], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 682200.0000, 
sim time next is 684000.0000, 
raw observation next is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.82335476107525, 0.1772773127207492, 0.0, 1.0, 42055.82811339398], 
processed observation next is [0.0, 0.9565217391304348, 0.368421052631579, 0.69, 0.0, 0.0, 0.6666666666666666, 0.5686128967562709, 0.5590924375735831, 0.0, 1.0, 0.20026584815901896], 
reward next is 0.7997, 
noisyNet noise sample is [array([-0.06657325], dtype=float32), 0.5203669]. 
=============================================
[2019-04-06 21:00:43,549] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[79.04764]
 [79.14575]
 [79.16626]
 [79.09551]
 [78.90689]], R is [[78.93920898]
 [78.94854736]
 [78.95695496]
 [78.96160889]
 [78.93869019]].
[2019-04-06 21:00:52,577] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:00:52,577] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:00:52,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run30
[2019-04-06 21:00:54,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.4291529e-14 2.3217796e-10 6.9827770e-13 1.3299145e-04 4.9756979e-14
 9.9986696e-01 2.8736789e-13], sum to 1.0000
[2019-04-06 21:00:54,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0559
[2019-04-06 21:00:54,430] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.15, 81.5, 0.0, 0.0, 26.0, 25.62829114679203, 0.6127366466710383, 0.0, 1.0, 31731.2438334708], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1146600.0000, 
sim time next is 1148400.0000, 
raw observation next is [12.7, 80.0, 0.0, 0.0, 26.0, 25.666165853522, 0.6142114277117167, 0.0, 1.0, 18727.03825273127], 
processed observation next is [0.0, 0.30434782608695654, 0.8144044321329641, 0.8, 0.0, 0.0, 0.6666666666666666, 0.6388471544601666, 0.7047371425705723, 0.0, 1.0, 0.08917637263205366], 
reward next is 0.9108, 
noisyNet noise sample is [array([0.89409363], dtype=float32), -0.19354877]. 
=============================================
[2019-04-06 21:00:59,972] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3641729e-11 2.6204476e-09 5.5110838e-12 6.5489432e-05 2.3067932e-12
 9.9993455e-01 7.5294120e-12], sum to 1.0000
[2019-04-06 21:00:59,973] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9960
[2019-04-06 21:01:00,278] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 48.0, 122.5, 0.0, 26.0, 26.19201331313189, 0.5356320453702064, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4536000.0000, 
sim time next is 4537800.0000, 
raw observation next is [2.0, 50.0, 127.0, 0.0, 26.0, 24.69909721220045, 0.3710985224292727, 1.0, 1.0, 71654.59873802908], 
processed observation next is [1.0, 0.5217391304347826, 0.518005540166205, 0.5, 0.42333333333333334, 0.0, 0.6666666666666666, 0.5582581010167041, 0.6236995074764242, 1.0, 1.0, 0.3412123749429956], 
reward next is 0.6588, 
noisyNet noise sample is [array([0.63895816], dtype=float32), 0.122824386]. 
=============================================
[2019-04-06 21:01:33,035] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3017007e-13 2.8917993e-10 4.3012018e-12 4.8231959e-04 2.1937237e-12
 9.9951768e-01 2.0370055e-12], sum to 1.0000
[2019-04-06 21:01:33,035] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1106
[2019-04-06 21:01:33,101] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.6, 58.5, 0.0, 0.0, 26.0, 26.8822386108151, 0.8462062717266637, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4393800.0000, 
sim time next is 4395600.0000, 
raw observation next is [10.2, 59.0, 0.0, 0.0, 26.0, 26.75895101660684, 0.8205654105905432, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.7451523545706372, 0.59, 0.0, 0.0, 0.6666666666666666, 0.7299125847172366, 0.7735218035301811, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0796148], dtype=float32), 1.2927868]. 
=============================================
[2019-04-06 21:01:35,987] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-06 21:01:35,988] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:01:35,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:01:35,993] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run67
[2019-04-06 21:01:36,047] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:01:36,096] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:01:36,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run67
[2019-04-06 21:01:36,184] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:01:36,185] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:01:36,191] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run67
[2019-04-06 21:04:05,061] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3885 79967197.3248 535.2671
[2019-04-06 21:04:27,292] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 21:04:27,539] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.9177 87811373.4032 517.1093
[2019-04-06 21:04:28,561] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 1320000, evaluation results [1320000.0, 2415.917741800095, 87811373.40318337, 517.1093044981922, 2453.388471443006, 79967197.3248232, 535.2671102210136, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 21:04:33,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:04:33,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:04:33,179] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run30
[2019-04-06 21:04:33,891] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5525401e-11 7.5865207e-09 1.4319579e-10 2.9340324e-03 1.1093223e-11
 9.9706596e-01 6.5017498e-11], sum to 1.0000
[2019-04-06 21:04:33,891] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3076
[2019-04-06 21:04:33,948] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 86.0, 0.0, 0.0, 26.0, 25.03818408107514, 0.3103507950750172, 0.0, 1.0, 46023.26349695352], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1803600.0000, 
sim time next is 1805400.0000, 
raw observation next is [-5.0, 86.0, 0.0, 0.0, 26.0, 24.98629822425945, 0.2942398070869985, 0.0, 1.0, 45965.64618523638], 
processed observation next is [0.0, 0.9130434782608695, 0.32409972299168976, 0.86, 0.0, 0.0, 0.6666666666666666, 0.5821915186882874, 0.5980799356956662, 0.0, 1.0, 0.21888402945350657], 
reward next is 0.7811, 
noisyNet noise sample is [array([0.24126916], dtype=float32), 1.0322489]. 
=============================================
[2019-04-06 21:04:34,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:04:34,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:04:34,415] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run30
[2019-04-06 21:04:42,126] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.25952286e-11 1.40381251e-09 1.42165975e-11 1.03950570e-05
 6.38705625e-12 9.99989629e-01 8.10161313e-11], sum to 1.0000
[2019-04-06 21:04:42,126] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6933
[2019-04-06 21:04:42,328] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 64.0, 54.0, 103.5, 26.0, 25.38640044371159, 0.3333955925624055, 1.0, 1.0, 64123.54382514576], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2793600.0000, 
sim time next is 2795400.0000, 
raw observation next is [-6.0, 64.0, 108.0, 207.0, 26.0, 25.78978380306109, 0.3891604267470986, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.296398891966759, 0.64, 0.36, 0.2287292817679558, 0.6666666666666666, 0.6491486502550909, 0.6297201422490328, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9160664], dtype=float32), -1.1278493]. 
=============================================
[2019-04-06 21:04:50,384] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1931198e-12 3.0328895e-09 1.1081229e-11 7.5845870e-05 2.7336267e-11
 9.9992418e-01 2.4707944e-11], sum to 1.0000
[2019-04-06 21:04:50,384] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3687
[2019-04-06 21:04:50,587] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 71.0, 77.0, 25.5, 26.0, 25.13008609069737, 0.2543150253935838, 0.0, 1.0, 51599.183664149234], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 637200.0000, 
sim time next is 639000.0000, 
raw observation next is [-3.9, 68.0, 135.0, 51.0, 26.0, 25.18753304071021, 0.2427406720562342, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3545706371191136, 0.68, 0.45, 0.056353591160221, 0.6666666666666666, 0.5989610867258509, 0.5809135573520781, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.18894593], dtype=float32), 0.29487884]. 
=============================================
[2019-04-06 21:04:50,592] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.181755]
 [76.18309 ]
 [75.1991  ]
 [75.02326 ]
 [75.083885]], R is [[77.89000702]
 [77.86539459]
 [77.37321472]
 [77.39013672]
 [77.40724182]].
[2019-04-06 21:04:56,526] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:04:56,539] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:04:56,550] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run30
[2019-04-06 21:04:57,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:04:57,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:04:57,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run30
[2019-04-06 21:04:59,084] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.1853056e-13 1.2725007e-10 4.9304912e-13 5.5802804e-05 5.6336304e-14
 9.9994421e-01 1.4057454e-12], sum to 1.0000
[2019-04-06 21:04:59,084] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7778
[2019-04-06 21:04:59,190] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.0, 17.0, 56.0, 438.5, 26.0, 28.83864837015823, 1.170333138054214, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5072400.0000, 
sim time next is 5074200.0000, 
raw observation next is [11.5, 17.0, 36.0, 292.0, 26.0, 28.96697712594188, 1.131509961521361, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.7811634349030472, 0.17, 0.12, 0.32265193370165746, 0.6666666666666666, 0.9139147604951567, 0.877169987173787, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03892127], dtype=float32), 1.3772489]. 
=============================================
[2019-04-06 21:05:00,758] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:05:00,758] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:05:00,762] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run30
[2019-04-06 21:05:05,188] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.7071257e-12 2.7087748e-09 6.7204450e-11 1.2970595e-03 7.1666418e-12
 9.9870288e-01 9.8135583e-11], sum to 1.0000
[2019-04-06 21:05:05,188] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5173
[2019-04-06 21:05:05,364] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.2, 82.5, 0.0, 0.0, 26.0, 25.00170275479142, 0.3164936431256818, 0.0, 1.0, 48424.696119428285], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1794600.0000, 
sim time next is 1796400.0000, 
raw observation next is [-4.5, 83.0, 0.0, 0.0, 26.0, 25.00880322946809, 0.3151774601432937, 0.0, 1.0, 48575.364595249855], 
processed observation next is [0.0, 0.8260869565217391, 0.3379501385041552, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5840669357890075, 0.605059153381098, 0.0, 1.0, 0.23131125997738025], 
reward next is 0.7687, 
noisyNet noise sample is [array([-1.2600455], dtype=float32), 0.6636482]. 
=============================================
[2019-04-06 21:05:07,781] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0520735e-11 4.8581505e-08 6.9417916e-10 5.4552527e-03 5.1357647e-11
 9.9454474e-01 9.9401687e-10], sum to 1.0000
[2019-04-06 21:05:07,781] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6380
[2019-04-06 21:05:08,021] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.05, 46.5, 83.0, 758.0, 26.0, 25.40183558346839, 0.3538394279610702, 1.0, 1.0, 47583.68053220003], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 304200.0000, 
sim time next is 306000.0000, 
raw observation next is [-9.5, 44.0, 89.0, 694.5, 26.0, 25.47917807508892, 0.4482549874252428, 1.0, 1.0, 100980.07585546124], 
processed observation next is [1.0, 0.5652173913043478, 0.1994459833795014, 0.44, 0.2966666666666667, 0.7674033149171271, 0.6666666666666666, 0.6232648395907434, 0.6494183291417476, 1.0, 1.0, 0.48085750407362493], 
reward next is 0.5191, 
noisyNet noise sample is [array([-0.05839664], dtype=float32), -1.0028849]. 
=============================================
[2019-04-06 21:05:08,026] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[78.262054]
 [78.31686 ]
 [78.3336  ]
 [77.79226 ]
 [77.47274 ]], R is [[78.14402771]
 [78.13600159]
 [78.13614655]
 [78.03911591]
 [78.25872803]].
[2019-04-06 21:05:15,674] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6917388e-12 1.4998930e-09 2.3419496e-11 1.1156560e-04 2.2225795e-12
 9.9988842e-01 8.3128313e-12], sum to 1.0000
[2019-04-06 21:05:15,675] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2395
[2019-04-06 21:05:15,808] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.5, 86.0, 0.0, 0.0, 26.0, 24.54659692194853, 0.1947913318725229, 0.0, 1.0, 37151.99185405776], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 61200.0000, 
sim time next is 63000.0000, 
raw observation next is [4.95, 87.5, 0.0, 0.0, 26.0, 24.56896975712736, 0.189475279799225, 0.0, 1.0, 35186.734164281814], 
processed observation next is [0.0, 0.7391304347826086, 0.5997229916897507, 0.875, 0.0, 0.0, 0.6666666666666666, 0.5474141464272799, 0.5631584265997417, 0.0, 1.0, 0.16755587697277055], 
reward next is 0.8324, 
noisyNet noise sample is [array([1.7091763], dtype=float32), -0.07885619]. 
=============================================
[2019-04-06 21:05:15,812] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[87.61328 ]
 [87.822365]
 [87.947685]
 [88.40354 ]
 [88.615486]], R is [[87.45774841]
 [87.40625   ]
 [87.3127594 ]
 [87.34059143]
 [87.24053955]].
[2019-04-06 21:05:18,641] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2890515e-10 8.9851131e-09 3.0907052e-10 5.2841217e-04 3.2516573e-11
 9.9947160e-01 4.5219617e-10], sum to 1.0000
[2019-04-06 21:05:18,641] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0993
[2019-04-06 21:05:18,927] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 69.0, 19.5, 0.0, 26.0, 23.91025932750486, 0.0692235181926783, 0.0, 1.0, 41889.048633156846], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2361600.0000, 
sim time next is 2363400.0000, 
raw observation next is [-3.4, 69.0, 37.0, 0.0, 26.0, 24.32616350540608, 0.2247776263781931, 0.0, 1.0, 149018.4806212506], 
processed observation next is [0.0, 0.34782608695652173, 0.368421052631579, 0.69, 0.12333333333333334, 0.0, 0.6666666666666666, 0.5271802921171732, 0.5749258754593977, 0.0, 1.0, 0.7096118124821458], 
reward next is 0.2904, 
noisyNet noise sample is [array([0.5026252], dtype=float32), 0.46136063]. 
=============================================
[2019-04-06 21:05:40,796] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2190093e-12 4.1401145e-09 1.6176085e-11 1.0129102e-03 2.0168847e-12
 9.9898702e-01 7.1065202e-12], sum to 1.0000
[2019-04-06 21:05:40,796] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1960
[2019-04-06 21:05:40,879] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.2, 100.0, 9.5, 0.0, 26.0, 24.58320464984704, 0.4225531050944498, 0.0, 1.0, 28984.352730395552], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1270800.0000, 
sim time next is 1272600.0000, 
raw observation next is [10.25, 98.0, 0.0, 0.0, 26.0, 24.58899121160405, 0.4336768092553977, 0.0, 1.0, 43628.856983150115], 
processed observation next is [0.0, 0.7391304347826086, 0.7465373961218837, 0.98, 0.0, 0.0, 0.6666666666666666, 0.5490826009670041, 0.644558936418466, 0.0, 1.0, 0.20775646182452437], 
reward next is 0.7922, 
noisyNet noise sample is [array([0.8784697], dtype=float32), -0.7320647]. 
=============================================
[2019-04-06 21:05:45,870] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2874533e-10 1.8057888e-08 1.3547957e-10 4.3743465e-05 4.7173303e-11
 9.9995625e-01 2.2393583e-10], sum to 1.0000
[2019-04-06 21:05:45,870] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1752
[2019-04-06 21:05:45,947] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 61.0, 0.0, 0.0, 26.0, 22.98791668446414, -0.2090736264484151, 0.0, 1.0, 44060.97811916883], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2444400.0000, 
sim time next is 2446200.0000, 
raw observation next is [-9.5, 59.5, 0.0, 0.0, 26.0, 22.88092063536656, -0.2324413760878249, 0.0, 1.0, 44172.866811175154], 
processed observation next is [0.0, 0.30434782608695654, 0.1994459833795014, 0.595, 0.0, 0.0, 0.6666666666666666, 0.40674338628054674, 0.42251954130405833, 0.0, 1.0, 0.2103469848151198], 
reward next is 0.7897, 
noisyNet noise sample is [array([0.08222023], dtype=float32), -0.005349513]. 
=============================================
[2019-04-06 21:05:51,062] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.5582448e-12 1.0460525e-09 3.9427375e-11 4.6316312e-05 5.0791191e-13
 9.9995363e-01 4.2052091e-12], sum to 1.0000
[2019-04-06 21:05:51,063] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6106
[2019-04-06 21:05:51,125] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 26.0, 24.58862794337909, 0.1688898611986422, 0.0, 1.0, 40777.84903642185], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 543600.0000, 
sim time next is 545400.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 26.0, 24.40232091629741, 0.1438157751995564, 0.0, 1.0, 41008.30239742708], 
processed observation next is [0.0, 0.30434782608695654, 0.4764542936288089, 0.92, 0.0, 0.0, 0.6666666666666666, 0.5335267430247841, 0.5479385917331855, 0.0, 1.0, 0.1952776304639385], 
reward next is 0.8047, 
noisyNet noise sample is [array([-0.48341706], dtype=float32), 0.53720844]. 
=============================================
[2019-04-06 21:06:04,722] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0991885e-11 3.3045375e-09 8.8335415e-12 7.0615359e-05 1.5161294e-11
 9.9992943e-01 8.1747881e-12], sum to 1.0000
[2019-04-06 21:06:04,722] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2148
[2019-04-06 21:06:04,867] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 75.0, 17.5, 1.0, 26.0, 24.60894456563421, 0.2902678855665915, 1.0, 1.0, 100948.24910142638], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1962000.0000, 
sim time next is 1963800.0000, 
raw observation next is [-4.45, 77.0, 0.0, 0.0, 26.0, 25.7073952775297, 0.3211616720650468, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3393351800554017, 0.77, 0.0, 0.0, 0.6666666666666666, 0.6422829397941415, 0.6070538906883489, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.9118489], dtype=float32), 0.5778039]. 
=============================================
[2019-04-06 21:06:08,630] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5318845e-10 2.8797965e-08 2.2320824e-10 1.1249448e-03 2.7203196e-11
 9.9887496e-01 1.0150489e-10], sum to 1.0000
[2019-04-06 21:06:08,630] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5648
[2019-04-06 21:06:08,755] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 59.5, 152.0, 233.0, 26.0, 25.87468273285439, 0.3960684279679203, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2799000.0000, 
sim time next is 2800800.0000, 
raw observation next is [-3.0, 55.0, 163.0, 370.5, 26.0, 25.93284345819335, 0.4203376078668271, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.55, 0.5433333333333333, 0.4093922651933702, 0.6666666666666666, 0.6610702881827791, 0.640112535955609, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.41256708], dtype=float32), -0.5341087]. 
=============================================
[2019-04-06 21:06:12,528] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.55384844e-10 1.03757385e-08 1.95155156e-10 6.14062045e-03
 8.79002166e-12 9.93859351e-01 1.86291899e-10], sum to 1.0000
[2019-04-06 21:06:12,529] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1487
[2019-04-06 21:06:12,601] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 59.0, 0.0, 0.0, 26.0, 25.0812523447461, 0.30917607444671, 0.0, 1.0, 45318.659905707056], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2588400.0000, 
sim time next is 2590200.0000, 
raw observation next is [-4.2, 60.5, 0.0, 0.0, 26.0, 24.91212441621767, 0.2826067804803121, 0.0, 1.0, 41992.92409374237], 
processed observation next is [1.0, 1.0, 0.34626038781163443, 0.605, 0.0, 0.0, 0.6666666666666666, 0.5760103680181391, 0.594202260160104, 0.0, 1.0, 0.19996630520829697], 
reward next is 0.8000, 
noisyNet noise sample is [array([-0.95209986], dtype=float32), -0.073692985]. 
=============================================
[2019-04-06 21:06:24,919] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0223160e-11 9.2869907e-09 5.7449011e-11 3.1226047e-04 1.4404432e-11
 9.9968779e-01 2.1711238e-10], sum to 1.0000
[2019-04-06 21:06:24,919] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5956
[2019-04-06 21:06:25,034] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.45, 80.5, 0.0, 0.0, 26.0, 24.06125077468531, 0.05793485594257933, 0.0, 1.0, 43273.1352560551], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2611800.0000, 
sim time next is 2613600.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 26.0, 23.87129836886393, 0.02380963135099029, 0.0, 1.0, 43799.36404317078], 
processed observation next is [1.0, 0.2608695652173913, 0.2770083102493075, 0.78, 0.0, 0.0, 0.6666666666666666, 0.4892748640719941, 0.5079365437836635, 0.0, 1.0, 0.20856840020557516], 
reward next is 0.7914, 
noisyNet noise sample is [array([1.008468], dtype=float32), 0.18275605]. 
=============================================
[2019-04-06 21:06:29,268] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.8288816e-12 3.7951104e-09 1.0540701e-11 8.3248946e-05 1.6933835e-11
 9.9991679e-01 2.9824858e-11], sum to 1.0000
[2019-04-06 21:06:29,268] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6696
[2019-04-06 21:06:29,551] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 71.0, 109.5, 225.5, 26.0, 26.01552172714307, 0.4176920555865027, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2196000.0000, 
sim time next is 2197800.0000, 
raw observation next is [-4.75, 71.0, 117.0, 0.0, 26.0, 25.9642075830378, 0.3852730545837105, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3310249307479225, 0.71, 0.39, 0.0, 0.6666666666666666, 0.6636839652531501, 0.6284243515279034, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4474467], dtype=float32), 0.37298626]. 
=============================================
[2019-04-06 21:06:38,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2646123e-11 1.5648393e-09 2.7864978e-11 6.0693442e-04 3.1939174e-12
 9.9939311e-01 4.6809116e-11], sum to 1.0000
[2019-04-06 21:06:38,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0946
[2019-04-06 21:06:38,134] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 60.0, 0.0, 0.0, 26.0, 24.651321954251, 0.1928671791374717, 0.0, 1.0, 39554.318880313476], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4860000.0000, 
sim time next is 4861800.0000, 
raw observation next is [-3.5, 62.5, 0.0, 0.0, 26.0, 24.57684250125638, 0.1767932969518152, 0.0, 1.0, 39494.829456844505], 
processed observation next is [0.0, 0.2608695652173913, 0.36565096952908593, 0.625, 0.0, 0.0, 0.6666666666666666, 0.5480702084380317, 0.5589310989839383, 0.0, 1.0, 0.18807061646116432], 
reward next is 0.8119, 
noisyNet noise sample is [array([0.37652674], dtype=float32), -0.2733871]. 
=============================================
[2019-04-06 21:06:57,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.16395105e-11 2.35862014e-08 2.98480435e-10 2.38734610e-05
 4.07321815e-11 9.99976158e-01 1.92109731e-10], sum to 1.0000
[2019-04-06 21:06:57,049] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1608
[2019-04-06 21:06:57,286] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:06:57,286] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:06:57,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run31
[2019-04-06 21:06:57,487] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.15, 44.5, 0.0, 0.0, 26.0, 24.95557783111534, 0.2654938209473628, 0.0, 1.0, 40211.723481211644], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2395800.0000, 
sim time next is 2397600.0000, 
raw observation next is [-1.7, 44.0, 0.0, 0.0, 26.0, 24.94425657321375, 0.2644134595768341, 0.0, 1.0, 48355.53160746774], 
processed observation next is [0.0, 0.782608695652174, 0.4155124653739613, 0.44, 0.0, 0.0, 0.6666666666666666, 0.5786880477678125, 0.5881378198589448, 0.0, 1.0, 0.23026443622603684], 
reward next is 0.7697, 
noisyNet noise sample is [array([-1.4507089], dtype=float32), -0.10869297]. 
=============================================
[2019-04-06 21:06:58,380] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.5277619e-13 4.2225046e-09 3.3089709e-12 6.9109046e-05 5.8647932e-13
 9.9993086e-01 2.4933536e-12], sum to 1.0000
[2019-04-06 21:06:58,380] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0655
[2019-04-06 21:06:58,594] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 26.0, 25.53155896722158, 0.4953461041648859, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1450800.0000, 
sim time next is 1452600.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 26.0, 25.24407662002876, 0.4377978329677077, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6036730516690634, 0.6459326109892359, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2611514], dtype=float32), -0.26513925]. 
=============================================
[2019-04-06 21:07:12,665] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4303262e-12 6.6491299e-11 1.1077143e-12 9.1356478e-06 8.0715377e-13
 9.9999082e-01 4.2044033e-12], sum to 1.0000
[2019-04-06 21:07:12,665] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9490
[2019-04-06 21:07:12,786] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 25.66868748311508, 0.610649281789963, 0.0, 1.0, 53833.740437014254], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3531600.0000, 
sim time next is 3533400.0000, 
raw observation next is [-0.5, 75.0, 0.0, 0.0, 26.0, 25.92029447804442, 0.6035008454080139, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.44875346260387816, 0.75, 0.0, 0.0, 0.6666666666666666, 0.6600245398370349, 0.7011669484693379, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5193346], dtype=float32), 1.2421356]. 
=============================================
[2019-04-06 21:07:17,145] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 21:07:17,146] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:07:17,146] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:07:17,146] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:07:17,146] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:07:17,152] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run68
[2019-04-06 21:07:17,195] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:07:17,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:07:17,198] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run68
[2019-04-06 21:07:17,246] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run68
[2019-04-06 21:09:45,746] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.06138664], dtype=float32), 0.1336027]
[2019-04-06 21:09:45,747] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [12.3, 57.0, 63.5, 188.0, 26.0, 25.79170803371878, 0.6431849902062616, 1.0, 1.0, 0.0]
[2019-04-06 21:09:45,747] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 21:09:45,747] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [6.5077994e-13 2.8931157e-10 3.0595500e-12 5.0320727e-05 2.9654502e-13
 9.9994969e-01 1.7146161e-12], sampled 0.2354716229676943
[2019-04-06 21:09:51,389] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 21:10:10,269] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 21:10:13,667] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 21:10:14,691] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1340000, evaluation results [1340000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 21:10:19,084] A3C_AGENT_WORKER-Thread-11 INFO:Local step 85000, global step 1340695: loss -4.5947
[2019-04-06 21:10:19,084] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 85000, global step 1340695: learning rate 0.0000
[2019-04-06 21:10:26,590] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.5870989e-12 6.9715322e-09 3.7280762e-10 2.9307073e-03 2.7495230e-11
 9.9706930e-01 1.1454533e-10], sum to 1.0000
[2019-04-06 21:10:26,590] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1789
[2019-04-06 21:10:26,668] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.3, 25.5, 48.0, 279.0, 26.0, 24.96188340158954, 0.2661486680409132, 0.0, 1.0, 18697.96934230805], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2478600.0000, 
sim time next is 2480400.0000, 
raw observation next is [3.3, 25.0, 27.0, 161.0, 26.0, 25.04566734410692, 0.2341839022748726, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.554016620498615, 0.25, 0.09, 0.17790055248618786, 0.6666666666666666, 0.5871389453422434, 0.5780613007582909, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6086531], dtype=float32), -0.7000569]. 
=============================================
[2019-04-06 21:10:43,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2613510e-10 2.0883592e-08 2.6614480e-10 4.8122153e-04 7.3370754e-11
 9.9951875e-01 5.7451897e-11], sum to 1.0000
[2019-04-06 21:10:43,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8621
[2019-04-06 21:10:43,227] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 40.0, 0.0, 0.0, 26.0, 25.58696242769682, 0.5146442112313704, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4131000.0000, 
sim time next is 4132800.0000, 
raw observation next is [1.0, 43.0, 0.0, 0.0, 26.0, 25.47821166648921, 0.4801128622134125, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.4903047091412743, 0.43, 0.0, 0.0, 0.6666666666666666, 0.6231843055407674, 0.6600376207378041, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3011272], dtype=float32), -0.54773295]. 
=============================================
[2019-04-06 21:10:54,397] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.1048790e-13 2.0182891e-09 3.9822633e-12 1.9528325e-05 1.7272867e-12
 9.9998045e-01 6.9360099e-12], sum to 1.0000
[2019-04-06 21:10:54,397] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4475
[2019-04-06 21:10:54,501] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 92.0, 140.5, 3.0, 26.0, 26.17012067416086, 0.6218168057309964, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4456800.0000, 
sim time next is 4458600.0000, 
raw observation next is [0.0, 88.5, 85.0, 0.0, 26.0, 26.33581025655494, 0.6245251625602335, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.46260387811634357, 0.885, 0.2833333333333333, 0.0, 0.6666666666666666, 0.6946508547129117, 0.7081750541867445, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.51332885], dtype=float32), 1.3356124]. 
=============================================
[2019-04-06 21:10:55,619] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9754025e-12 1.5301613e-10 2.6702423e-12 8.2661900e-05 1.1262780e-12
 9.9991739e-01 5.0088341e-12], sum to 1.0000
[2019-04-06 21:10:55,619] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7479
[2019-04-06 21:10:55,728] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 45.0, 75.5, 634.0, 26.0, 26.88206741560917, 0.7516072563440529, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3859200.0000, 
sim time next is 3861000.0000, 
raw observation next is [3.0, 43.0, 64.0, 551.0, 26.0, 26.40236943220677, 0.678832453068794, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.43, 0.21333333333333335, 0.6088397790055249, 0.6666666666666666, 0.7001974526838973, 0.7262774843562646, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5029126], dtype=float32), 0.5780343]. 
=============================================
[2019-04-06 21:10:55,732] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[86.40537]
 [86.72869]
 [86.89126]
 [86.95378]
 [87.00149]], R is [[86.16187286]
 [86.30025482]
 [86.43725586]
 [86.57288361]
 [86.70715332]].
[2019-04-06 21:11:07,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:11:07,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:11:07,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run31
[2019-04-06 21:11:19,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:11:19,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:11:19,114] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run31
[2019-04-06 21:11:19,346] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5838669e-12 2.9868916e-10 2.5458720e-11 3.7366431e-04 8.4278152e-13
 9.9962628e-01 2.8396745e-12], sum to 1.0000
[2019-04-06 21:11:19,347] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8925
[2019-04-06 21:11:19,413] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.35, 75.5, 0.0, 0.0, 26.0, 25.53230100113539, 0.4047293758724611, 0.0, 1.0, 19795.41478810817], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4321800.0000, 
sim time next is 4323600.0000, 
raw observation next is [4.2, 75.0, 0.0, 0.0, 26.0, 25.5024262956842, 0.4062986074184309, 0.0, 1.0, 36635.698485054716], 
processed observation next is [1.0, 0.043478260869565216, 0.5789473684210527, 0.75, 0.0, 0.0, 0.6666666666666666, 0.6252021913070166, 0.6354328691394769, 0.0, 1.0, 0.17445570707168911], 
reward next is 0.8255, 
noisyNet noise sample is [array([-0.66174865], dtype=float32), 1.3454591]. 
=============================================
[2019-04-06 21:11:21,043] A3C_AGENT_WORKER-Thread-3 INFO:Local step 85000, global step 1350032: loss 0.3770
[2019-04-06 21:11:21,045] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 85000, global step 1350032: learning rate 0.0000
[2019-04-06 21:11:25,536] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5681044e-11 3.4675314e-09 2.0259666e-10 1.9309684e-03 4.0593340e-12
 9.9806899e-01 4.4890439e-11], sum to 1.0000
[2019-04-06 21:11:25,537] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2918
[2019-04-06 21:11:25,654] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.25, 61.0, 139.0, 484.0, 26.0, 25.79626808572278, 0.4617986743886093, 1.0, 1.0, 22347.42547807036], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 135000.0000, 
sim time next is 136800.0000, 
raw observation next is [-6.7, 61.0, 143.5, 295.0, 26.0, 25.93254546051917, 0.4538055083411635, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.2770083102493075, 0.61, 0.47833333333333333, 0.3259668508287293, 0.6666666666666666, 0.6610454550432641, 0.6512685027803878, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5614584], dtype=float32), -0.84724987]. 
=============================================
[2019-04-06 21:11:26,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:11:26,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:11:26,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run31
[2019-04-06 21:11:28,470] A3C_AGENT_WORKER-Thread-11 INFO:Local step 85500, global step 1351198: loss 0.0648
[2019-04-06 21:11:28,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 85500, global step 1351198: learning rate 0.0000
[2019-04-06 21:11:28,781] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:11:28,781] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:11:28,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run31
[2019-04-06 21:11:32,035] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5185720e-11 2.1059188e-08 2.8568856e-10 1.7253769e-03 7.5620989e-11
 9.9827456e-01 2.9404360e-10], sum to 1.0000
[2019-04-06 21:11:32,035] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2886
[2019-04-06 21:11:32,103] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.0, 53.0, 0.0, 0.0, 26.0, 25.14489148113849, 0.3855041463160229, 0.0, 1.0, 47977.95786193846], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3970800.0000, 
sim time next is 3972600.0000, 
raw observation next is [-9.5, 55.5, 0.0, 0.0, 26.0, 24.99906137874251, 0.3508805457001007, 0.0, 1.0, 44138.297808557116], 
processed observation next is [1.0, 1.0, 0.1994459833795014, 0.555, 0.0, 0.0, 0.6666666666666666, 0.5832551148952092, 0.6169601819000335, 0.0, 1.0, 0.21018237051693864], 
reward next is 0.7898, 
noisyNet noise sample is [array([-1.1735574], dtype=float32), -0.88753986]. 
=============================================
[2019-04-06 21:11:32,303] A3C_AGENT_WORKER-Thread-17 INFO:Local step 85000, global step 1351715: loss 0.4574
[2019-04-06 21:11:32,304] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 85000, global step 1351715: learning rate 0.0000
[2019-04-06 21:11:38,214] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.9421782e-12 1.7789772e-10 2.3298091e-12 1.7483108e-05 4.1038323e-13
 9.9998248e-01 3.4233794e-12], sum to 1.0000
[2019-04-06 21:11:38,214] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6254
[2019-04-06 21:11:38,485] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 93.0, 60.0, 0.0, 26.0, 23.78553752603829, -0.002750682232440021, 0.0, 1.0, 57053.460430502375], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 37800.0000, 
sim time next is 39600.0000, 
raw observation next is [7.7, 93.0, 67.5, 0.0, 26.0, 24.05959511522286, 0.05725671615671657, 0.0, 1.0, 56509.123116787], 
processed observation next is [0.0, 0.4782608695652174, 0.6759002770083103, 0.93, 0.225, 0.0, 0.6666666666666666, 0.5049662596019049, 0.5190855720522388, 0.0, 1.0, 0.2690910624608905], 
reward next is 0.7309, 
noisyNet noise sample is [array([-0.5783835], dtype=float32), 0.044247154]. 
=============================================
[2019-04-06 21:11:39,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:11:39,406] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:11:39,434] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run31
[2019-04-06 21:11:39,925] A3C_AGENT_WORKER-Thread-5 INFO:Local step 85000, global step 1352965: loss 0.4443
[2019-04-06 21:11:39,926] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 85000, global step 1352965: learning rate 0.0000
[2019-04-06 21:11:40,502] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1562216e-11 2.4844791e-08 9.7121068e-11 9.4703690e-04 7.9791495e-12
 9.9905294e-01 2.4949889e-11], sum to 1.0000
[2019-04-06 21:11:40,503] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9589
[2019-04-06 21:11:40,570] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 74.0, 0.0, 0.0, 26.0, 25.60541752996528, 0.5238280041465561, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3792600.0000, 
sim time next is 3794400.0000, 
raw observation next is [-3.0, 77.0, 0.0, 0.0, 26.0, 25.45426838758833, 0.5108995395505292, 0.0, 1.0, 63822.65364647162], 
processed observation next is [1.0, 0.9565217391304348, 0.3795013850415513, 0.77, 0.0, 0.0, 0.6666666666666666, 0.6211890322990273, 0.6702998465168432, 0.0, 1.0, 0.30391739831653153], 
reward next is 0.6961, 
noisyNet noise sample is [array([-0.9689296], dtype=float32), 0.52529645]. 
=============================================
[2019-04-06 21:11:41,338] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8172173e-10 2.3658799e-08 5.1702851e-09 3.3689139e-03 3.3709556e-11
 9.9663109e-01 6.3784672e-11], sum to 1.0000
[2019-04-06 21:11:41,338] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3758
[2019-04-06 21:11:41,601] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.0, 76.0, 0.0, 0.0, 26.0, 23.85902360878533, 0.08821534145762344, 0.0, 1.0, 44001.466033445606], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3308400.0000, 
sim time next is 3310200.0000, 
raw observation next is [-11.0, 80.0, 2.0, 94.0, 26.0, 24.15888290098042, 0.2604417523251015, 1.0, 1.0, 149850.00660750677], 
processed observation next is [1.0, 0.30434782608695654, 0.15789473684210528, 0.8, 0.006666666666666667, 0.10386740331491713, 0.6666666666666666, 0.5132402417483682, 0.5868139174417005, 1.0, 1.0, 0.7135714600357466], 
reward next is 0.2864, 
noisyNet noise sample is [array([-1.1973454], dtype=float32), -0.034225635]. 
=============================================
[2019-04-06 21:11:41,947] A3C_AGENT_WORKER-Thread-16 INFO:Local step 85000, global step 1353254: loss 0.4494
[2019-04-06 21:11:41,947] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 85000, global step 1353254: learning rate 0.0000
[2019-04-06 21:11:47,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:11:47,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:11:47,576] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run31
[2019-04-06 21:11:49,397] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0016741e-12 8.3998425e-10 4.3120208e-12 1.8847425e-04 3.0321415e-14
 9.9981159e-01 3.6323464e-12], sum to 1.0000
[2019-04-06 21:11:49,398] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9798
[2019-04-06 21:11:49,439] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.2, 96.0, 0.0, 0.0, 26.0, 25.36638376095126, 0.4476494458815293, 0.0, 1.0, 33299.7782414762], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1483200.0000, 
sim time next is 1485000.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 26.0, 25.35461489412166, 0.4531805915343967, 0.0, 1.0, 42268.7850381394], 
processed observation next is [1.0, 0.17391304347826086, 0.5235457063711911, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6128845745101383, 0.6510601971781322, 0.0, 1.0, 0.20127992875304476], 
reward next is 0.7987, 
noisyNet noise sample is [array([0.54775], dtype=float32), -0.13547456]. 
=============================================
[2019-04-06 21:11:49,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[95.0261  ]
 [94.9163  ]
 [94.72018 ]
 [94.209625]
 [94.15038 ]], R is [[95.0490799 ]
 [94.9400177 ]
 [94.79051208]
 [94.64996338]
 [94.60160828]].
[2019-04-06 21:11:50,275] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1420348e-12 1.5328526e-09 4.8554445e-11 1.1300915e-04 1.5219428e-12
 9.9988699e-01 1.0668330e-12], sum to 1.0000
[2019-04-06 21:11:50,276] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6329
[2019-04-06 21:11:50,351] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.36044450094234, 0.3436418933389401, 0.0, 1.0, 65849.66345082037], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3099600.0000, 
sim time next is 3101400.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.39412988293379, 0.3473448547356217, 0.0, 1.0, 39314.63172189643], 
processed observation next is [0.0, 0.9130434782608695, 0.4349030470914128, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6161774902444824, 0.6157816182452073, 0.0, 1.0, 0.18721253200903062], 
reward next is 0.8128, 
noisyNet noise sample is [array([0.22257419], dtype=float32), 1.0224066]. 
=============================================
[2019-04-06 21:11:51,825] A3C_AGENT_WORKER-Thread-13 INFO:Local step 85000, global step 1354619: loss 0.4072
[2019-04-06 21:11:51,839] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 85000, global step 1354619: learning rate 0.0000
[2019-04-06 21:11:54,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:11:54,390] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:11:54,406] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run31
[2019-04-06 21:11:55,634] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:11:55,634] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:11:55,639] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run31
[2019-04-06 21:12:03,075] A3C_AGENT_WORKER-Thread-6 INFO:Local step 85000, global step 1356077: loss 0.4081
[2019-04-06 21:12:03,075] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 85000, global step 1356077: learning rate 0.0000
[2019-04-06 21:12:15,414] A3C_AGENT_WORKER-Thread-18 INFO:Local step 85000, global step 1357103: loss 0.4987
[2019-04-06 21:12:15,414] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 85000, global step 1357103: learning rate 0.0000
[2019-04-06 21:12:18,479] A3C_AGENT_WORKER-Thread-12 INFO:Local step 85000, global step 1357380: loss 0.4526
[2019-04-06 21:12:18,479] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 85000, global step 1357380: learning rate 0.0000
[2019-04-06 21:12:19,571] A3C_AGENT_WORKER-Thread-11 INFO:Local step 86000, global step 1357462: loss 0.0656
[2019-04-06 21:12:19,571] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 86000, global step 1357462: learning rate 0.0000
[2019-04-06 21:12:26,460] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.09422825e-10 2.40644269e-08 2.00908817e-10 1.15816295e-03
 2.01953732e-11 9.98841822e-01 3.86147225e-11], sum to 1.0000
[2019-04-06 21:12:26,461] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5534
[2019-04-06 21:12:26,573] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.65, 76.0, 0.0, 0.0, 26.0, 24.08735019697966, 0.07843406833210599, 0.0, 1.0, 47079.46700939374], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 340200.0000, 
sim time next is 342000.0000, 
raw observation next is [-13.9, 70.0, 0.0, 0.0, 26.0, 23.91665674636515, 0.03456156769485059, 0.0, 1.0, 47078.34852789681], 
processed observation next is [1.0, 1.0, 0.07756232686980608, 0.7, 0.0, 0.0, 0.6666666666666666, 0.4930547288637624, 0.5115205225649502, 0.0, 1.0, 0.22418261203760384], 
reward next is 0.7758, 
noisyNet noise sample is [array([-1.6675575], dtype=float32), -1.4449016]. 
=============================================
[2019-04-06 21:12:26,577] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[77.105606]
 [77.17073 ]
 [77.188614]
 [77.120056]
 [77.24967 ]], R is [[76.37182617]
 [76.38391876]
 [76.39508057]
 [76.40516663]
 [76.43557739]].
[2019-04-06 21:12:34,613] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5538818e-10 8.1626110e-09 1.8179018e-10 3.9922091e-04 1.0021558e-10
 9.9960083e-01 1.5771988e-10], sum to 1.0000
[2019-04-06 21:12:34,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2708
[2019-04-06 21:12:34,890] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 38.0, 98.0, 574.0, 26.0, 26.07378305793528, 0.4646162130798796, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4093200.0000, 
sim time next is 4095000.0000, 
raw observation next is [-2.5, 36.5, 104.0, 679.0, 26.0, 26.20421056989942, 0.5158958057679439, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.39335180055401664, 0.365, 0.3466666666666667, 0.7502762430939226, 0.6666666666666666, 0.683684214158285, 0.6719652685893146, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.01389949], dtype=float32), -0.56838304]. 
=============================================
[2019-04-06 21:12:34,906] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[80.786415]
 [80.43559 ]
 [79.53036 ]
 [78.652695]
 [77.66083 ]], R is [[81.52658844]
 [81.7113266 ]
 [81.89421082]
 [82.07527161]
 [81.86985779]].
[2019-04-06 21:12:38,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3382163e-11 1.2438749e-09 2.3685302e-11 1.2341587e-05 3.2249151e-12
 9.9998760e-01 1.2317972e-11], sum to 1.0000
[2019-04-06 21:12:38,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2145
[2019-04-06 21:12:38,927] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.65, 71.5, 0.0, 0.0, 26.0, 24.39737060697749, 0.09157955540916567, 0.0, 1.0, 41002.05878128728], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 693000.0000, 
sim time next is 694800.0000, 
raw observation next is [-3.4, 72.0, 0.0, 0.0, 26.0, 24.39125904611616, 0.09192803370943133, 0.0, 1.0, 40947.23179782094], 
processed observation next is [1.0, 0.043478260869565216, 0.368421052631579, 0.72, 0.0, 0.0, 0.6666666666666666, 0.5326049205096801, 0.5306426779031438, 0.0, 1.0, 0.19498681808486162], 
reward next is 0.8050, 
noisyNet noise sample is [array([-1.0448637], dtype=float32), -0.14677092]. 
=============================================
[2019-04-06 21:12:39,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:12:39,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:12:39,944] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run31
[2019-04-06 21:12:44,018] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2365276e-11 3.1853775e-09 6.0453698e-10 9.8756696e-05 6.7767133e-12
 9.9990118e-01 1.0076192e-10], sum to 1.0000
[2019-04-06 21:12:44,018] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9227
[2019-04-06 21:12:44,143] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.3, 46.0, 85.0, 31.0, 26.0, 25.36796762050358, 0.3583276580501213, 1.0, 1.0, 39746.54786105068], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 747000.0000, 
sim time next is 748800.0000, 
raw observation next is [-0.6, 45.0, 76.5, 17.0, 26.0, 25.67064876171223, 0.2942906349571549, 1.0, 1.0, 25848.915287381697], 
processed observation next is [1.0, 0.6956521739130435, 0.44598337950138506, 0.45, 0.255, 0.01878453038674033, 0.6666666666666666, 0.6392207301426858, 0.5980968783190517, 1.0, 1.0, 0.1230900727970557], 
reward next is 0.8769, 
noisyNet noise sample is [array([-0.36857042], dtype=float32), 1.1121931]. 
=============================================
[2019-04-06 21:12:49,428] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 21:12:49,428] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:12:49,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:12:49,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run69
[2019-04-06 21:12:49,482] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:12:49,482] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:12:49,520] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:12:49,520] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:12:49,524] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run69
[2019-04-06 21:12:49,607] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run69
[2019-04-06 21:15:23,904] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 21:15:43,702] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 21:15:47,210] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 21:15:48,233] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 1360000, evaluation results [1360000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 21:15:50,468] A3C_AGENT_WORKER-Thread-3 INFO:Local step 85500, global step 1360290: loss 0.0734
[2019-04-06 21:15:50,481] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 85500, global step 1360290: learning rate 0.0000
[2019-04-06 21:15:54,509] A3C_AGENT_WORKER-Thread-19 INFO:Local step 85000, global step 1360877: loss 0.4900
[2019-04-06 21:15:54,510] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 85000, global step 1360877: learning rate 0.0000
[2019-04-06 21:16:00,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:16:00,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:16:00,292] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run31
[2019-04-06 21:16:00,819] A3C_AGENT_WORKER-Thread-17 INFO:Local step 85500, global step 1361747: loss 0.0705
[2019-04-06 21:16:00,825] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 85500, global step 1361747: learning rate 0.0000
[2019-04-06 21:16:11,633] A3C_AGENT_WORKER-Thread-16 INFO:Local step 85500, global step 1363289: loss 0.1244
[2019-04-06 21:16:11,647] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 85500, global step 1363289: learning rate 0.0000
[2019-04-06 21:16:12,013] A3C_AGENT_WORKER-Thread-5 INFO:Local step 85500, global step 1363341: loss 0.0496
[2019-04-06 21:16:12,014] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 85500, global step 1363341: learning rate 0.0000
[2019-04-06 21:16:14,053] A3C_AGENT_WORKER-Thread-15 INFO:Local step 85000, global step 1363635: loss 0.4382
[2019-04-06 21:16:14,053] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 85000, global step 1363635: learning rate 0.0000
[2019-04-06 21:16:14,246] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.2501409e-11 5.6312260e-08 9.9548592e-10 1.8800496e-03 7.0010830e-11
 9.9811989e-01 2.5164643e-10], sum to 1.0000
[2019-04-06 21:16:14,264] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1223
[2019-04-06 21:16:14,340] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 42.0, 0.0, 0.0, 26.0, 25.15863166515101, 0.2810747670945781, 0.0, 1.0, 43456.73851941975], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2406600.0000, 
sim time next is 2408400.0000, 
raw observation next is [-3.4, 42.0, 0.0, 0.0, 26.0, 25.1059921860388, 0.2782895807737737, 0.0, 1.0, 43142.20748466193], 
processed observation next is [0.0, 0.9130434782608695, 0.368421052631579, 0.42, 0.0, 0.0, 0.6666666666666666, 0.5921660155032334, 0.592763193591258, 0.0, 1.0, 0.2054390832602949], 
reward next is 0.7946, 
noisyNet noise sample is [array([-0.9098059], dtype=float32), 0.3561569]. 
=============================================
[2019-04-06 21:16:22,858] A3C_AGENT_WORKER-Thread-13 INFO:Local step 85500, global step 1365148: loss 0.0647
[2019-04-06 21:16:22,869] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 85500, global step 1365148: learning rate 0.0000
[2019-04-06 21:16:24,932] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6769219e-11 4.6695523e-09 9.3158294e-11 2.2634047e-04 1.4151392e-11
 9.9977368e-01 9.9270625e-10], sum to 1.0000
[2019-04-06 21:16:24,933] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0829
[2019-04-06 21:16:25,210] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 54.5, 0.0, 0.0, 26.0, 25.37174462645817, 0.3351225614836732, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 757800.0000, 
sim time next is 759600.0000, 
raw observation next is [-3.9, 53.0, 0.0, 0.0, 26.0, 24.96187631023951, 0.2984217328726219, 1.0, 1.0, 69017.02880839426], 
processed observation next is [1.0, 0.8260869565217391, 0.3545706371191136, 0.53, 0.0, 0.0, 0.6666666666666666, 0.5801563591866259, 0.5994739109575407, 1.0, 1.0, 0.32865251813521074], 
reward next is 0.6713, 
noisyNet noise sample is [array([0.5573578], dtype=float32), -1.8251406]. 
=============================================
[2019-04-06 21:16:25,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:16:25,602] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:16:25,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run31
[2019-04-06 21:16:30,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:16:30,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:16:30,792] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run31
[2019-04-06 21:16:32,581] A3C_AGENT_WORKER-Thread-6 INFO:Local step 85500, global step 1366546: loss 0.0640
[2019-04-06 21:16:32,582] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 85500, global step 1366546: learning rate 0.0000
[2019-04-06 21:16:35,555] A3C_AGENT_WORKER-Thread-3 INFO:Local step 86000, global step 1366956: loss 0.0687
[2019-04-06 21:16:35,555] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 86000, global step 1366956: learning rate 0.0000
[2019-04-06 21:16:35,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6029643e-14 1.5618057e-11 1.8088379e-13 9.8176151e-06 9.0548344e-14
 9.9999022e-01 6.0825412e-13], sum to 1.0000
[2019-04-06 21:16:35,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4597
[2019-04-06 21:16:36,092] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.35, 54.0, 87.0, 28.0, 26.0, 27.2486383819159, 0.7000800741059338, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1528200.0000, 
sim time next is 1530000.0000, 
raw observation next is [10.5, 58.0, 44.5, 17.0, 26.0, 26.4717626969951, 0.7117291413847541, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.7534626038781165, 0.58, 0.14833333333333334, 0.01878453038674033, 0.6666666666666666, 0.7059802247495917, 0.7372430471282514, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1749232], dtype=float32), -0.3468746]. 
=============================================
[2019-04-06 21:16:36,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[94.336555]
 [94.428474]
 [94.9276  ]
 [95.31869 ]
 [95.63934 ]], R is [[94.3343277 ]
 [94.39098358]
 [94.44707489]
 [94.50260162]
 [94.55757904]].
[2019-04-06 21:16:37,392] A3C_AGENT_WORKER-Thread-11 INFO:Local step 86500, global step 1367206: loss 0.0379
[2019-04-06 21:16:37,393] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 86500, global step 1367206: learning rate 0.0000
[2019-04-06 21:16:39,845] A3C_AGENT_WORKER-Thread-20 INFO:Local step 85000, global step 1367625: loss 0.4106
[2019-04-06 21:16:39,846] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 85000, global step 1367625: learning rate 0.0000
[2019-04-06 21:16:39,979] A3C_AGENT_WORKER-Thread-12 INFO:Local step 85500, global step 1367651: loss 0.0739
[2019-04-06 21:16:39,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 85500, global step 1367651: learning rate 0.0000
[2019-04-06 21:16:40,374] A3C_AGENT_WORKER-Thread-18 INFO:Local step 85500, global step 1367721: loss 0.0430
[2019-04-06 21:16:40,374] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 85500, global step 1367721: learning rate 0.0000
[2019-04-06 21:16:43,366] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:16:43,366] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:16:43,370] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run31
[2019-04-06 21:16:45,115] A3C_AGENT_WORKER-Thread-10 INFO:Local step 85000, global step 1368477: loss 0.4328
[2019-04-06 21:16:45,115] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 85000, global step 1368477: learning rate 0.0000
[2019-04-06 21:16:45,766] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.6423715e-13 1.9094774e-10 6.6185625e-12 8.2405422e-06 2.2073324e-13
 9.9999177e-01 2.7202277e-13], sum to 1.0000
[2019-04-06 21:16:45,767] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2144
[2019-04-06 21:16:45,829] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.9, 68.5, 0.0, 0.0, 26.0, 25.73737980849132, 0.6660460143941404, 0.0, 1.0, 6241.487523695344], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1121400.0000, 
sim time next is 1123200.0000, 
raw observation next is [11.6, 71.0, 0.0, 0.0, 26.0, 25.76227933544137, 0.6512561282196073, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.0, 0.7839335180055402, 0.71, 0.0, 0.0, 0.6666666666666666, 0.6468566112867808, 0.7170853760732024, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0441061], dtype=float32), 0.1720877]. 
=============================================
[2019-04-06 21:16:46,908] A3C_AGENT_WORKER-Thread-17 INFO:Local step 86000, global step 1368724: loss 0.0696
[2019-04-06 21:16:46,908] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 86000, global step 1368724: learning rate 0.0000
[2019-04-06 21:16:49,204] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1699382e-11 8.5971861e-09 2.4999672e-10 3.5283901e-04 2.3150336e-11
 9.9964714e-01 8.4893551e-11], sum to 1.0000
[2019-04-06 21:16:49,205] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7148
[2019-04-06 21:16:49,243] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 78.0, 0.0, 0.0, 26.0, 24.11044945611614, -0.009860912041450015, 0.0, 1.0, 44794.92853648504], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1911600.0000, 
sim time next is 1913400.0000, 
raw observation next is [-8.4, 78.0, 0.0, 0.0, 26.0, 23.91090387441164, -0.03593517307320076, 0.0, 1.0, 44739.286440338336], 
processed observation next is [1.0, 0.13043478260869565, 0.2299168975069252, 0.78, 0.0, 0.0, 0.6666666666666666, 0.4925753228676368, 0.48802160897559976, 0.0, 1.0, 0.21304422114446828], 
reward next is 0.7870, 
noisyNet noise sample is [array([0.3154618], dtype=float32), -0.5892474]. 
=============================================
[2019-04-06 21:16:50,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:16:50,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:16:50,006] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run31
[2019-04-06 21:16:51,900] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:16:51,900] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:16:51,911] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run31
[2019-04-06 21:16:55,631] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8026197e-11 4.5216342e-10 6.1023695e-12 1.5076996e-04 5.5510354e-13
 9.9984920e-01 2.9675637e-12], sum to 1.0000
[2019-04-06 21:16:55,631] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4936
[2019-04-06 21:16:55,714] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 26.0, 25.24129424529551, 0.4589079373845548, 0.0, 1.0, 58608.207463909865], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1396800.0000, 
sim time next is 1398600.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 26.0, 25.28999250876263, 0.4598468392895613, 0.0, 1.0, 39860.07733846758], 
processed observation next is [1.0, 0.17391304347826086, 0.44598337950138506, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6074993757302192, 0.6532822797631871, 0.0, 1.0, 0.18980989208794086], 
reward next is 0.8102, 
noisyNet noise sample is [array([0.29718348], dtype=float32), 0.38925964]. 
=============================================
[2019-04-06 21:16:56,361] A3C_AGENT_WORKER-Thread-16 INFO:Local step 86000, global step 1369939: loss 0.0667
[2019-04-06 21:16:56,362] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 86000, global step 1369939: learning rate 0.0000
[2019-04-06 21:16:56,624] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.1589552e-11 3.7434398e-09 3.3001274e-10 5.3191063e-05 2.5476503e-11
 9.9994683e-01 1.0976887e-11], sum to 1.0000
[2019-04-06 21:16:56,624] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3474
[2019-04-06 21:16:56,969] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.3, 67.0, 0.0, 0.0, 26.0, 22.52887548795389, -0.2781907294638269, 0.0, 1.0, 47921.45676928842], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 284400.0000, 
sim time next is 286200.0000, 
raw observation next is [-12.55, 68.5, 0.0, 0.0, 26.0, 22.70189519545707, -0.1458819668010206, 1.0, 1.0, 151243.45110296155], 
processed observation next is [1.0, 0.30434782608695654, 0.11495844875346259, 0.685, 0.0, 0.0, 0.6666666666666666, 0.39182459962142246, 0.4513726777329931, 1.0, 1.0, 0.7202069100141026], 
reward next is 0.2798, 
noisyNet noise sample is [array([-1.3508104], dtype=float32), -0.47772804]. 
=============================================
[2019-04-06 21:16:57,125] A3C_AGENT_WORKER-Thread-2 INFO:Local step 85000, global step 1369994: loss 0.3990
[2019-04-06 21:16:57,126] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 85000, global step 1369994: learning rate 0.0000
[2019-04-06 21:16:58,216] A3C_AGENT_WORKER-Thread-5 INFO:Local step 86000, global step 1370119: loss 0.0663
[2019-04-06 21:16:58,217] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 86000, global step 1370119: learning rate 0.0000
[2019-04-06 21:17:04,293] A3C_AGENT_WORKER-Thread-4 INFO:Local step 85000, global step 1370881: loss 0.4212
[2019-04-06 21:17:04,294] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 85000, global step 1370881: learning rate 0.0000
[2019-04-06 21:17:05,579] A3C_AGENT_WORKER-Thread-13 INFO:Local step 86000, global step 1371062: loss 0.0683
[2019-04-06 21:17:05,580] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 86000, global step 1371062: learning rate 0.0000
[2019-04-06 21:17:06,297] A3C_AGENT_WORKER-Thread-14 INFO:Local step 85000, global step 1371159: loss 0.3450
[2019-04-06 21:17:06,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 85000, global step 1371159: learning rate 0.0000
[2019-04-06 21:17:06,420] A3C_AGENT_WORKER-Thread-19 INFO:Local step 85500, global step 1371176: loss 0.1213
[2019-04-06 21:17:06,421] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 85500, global step 1371176: learning rate 0.0000
[2019-04-06 21:17:07,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.5138324e-12 4.0101839e-10 1.1141269e-11 6.6181776e-05 1.6670335e-12
 9.9993384e-01 8.8309186e-12], sum to 1.0000
[2019-04-06 21:17:07,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3698
[2019-04-06 21:17:08,007] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 45.0, 76.5, 17.0, 26.0, 25.67063217322353, 0.2942881602218132, 1.0, 1.0, 25849.157466937486], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 748800.0000, 
sim time next is 750600.0000, 
raw observation next is [-1.7, 49.5, 68.0, 3.0, 26.0, 25.22742281717996, 0.3958715926577653, 1.0, 1.0, 75964.2958276262], 
processed observation next is [1.0, 0.6956521739130435, 0.4155124653739613, 0.495, 0.22666666666666666, 0.0033149171270718232, 0.6666666666666666, 0.6022852347649966, 0.6319571975525884, 1.0, 1.0, 0.3617347420363153], 
reward next is 0.6383, 
noisyNet noise sample is [array([-1.4006759], dtype=float32), -0.39441118]. 
=============================================
[2019-04-06 21:17:14,527] A3C_AGENT_WORKER-Thread-6 INFO:Local step 86000, global step 1372250: loss 0.0665
[2019-04-06 21:17:14,527] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 86000, global step 1372250: learning rate 0.0000
[2019-04-06 21:17:17,457] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.2561676e-11 2.1889519e-09 3.2447123e-10 1.1897819e-04 5.8236623e-12
 9.9988103e-01 3.4389623e-11], sum to 1.0000
[2019-04-06 21:17:17,457] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5620
[2019-04-06 21:17:17,758] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 91.0, 0.0, 0.0, 26.0, 23.11923672893798, -0.1933502383145946, 0.0, 1.0, 44541.96793129926], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1926000.0000, 
sim time next is 1927800.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 26.0, 23.62482582125511, 0.009840905635030853, 1.0, 1.0, 150047.43741813317], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.6666666666666666, 0.4687354851045926, 0.5032803018783436, 1.0, 1.0, 0.7145116067530151], 
reward next is 0.2855, 
noisyNet noise sample is [array([-0.08013404], dtype=float32), -1.044913]. 
=============================================
[2019-04-06 21:17:23,452] A3C_AGENT_WORKER-Thread-12 INFO:Local step 86000, global step 1373315: loss 0.0681
[2019-04-06 21:17:23,465] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 86000, global step 1373315: learning rate 0.0000
[2019-04-06 21:17:23,739] A3C_AGENT_WORKER-Thread-18 INFO:Local step 86000, global step 1373349: loss 0.0665
[2019-04-06 21:17:23,739] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 86000, global step 1373349: learning rate 0.0000
[2019-04-06 21:17:24,103] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.1259279e-11 1.4592352e-09 3.7218248e-10 3.5981945e-04 5.8095364e-12
 9.9964023e-01 2.1982411e-11], sum to 1.0000
[2019-04-06 21:17:24,103] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9064
[2019-04-06 21:17:24,141] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.24099296882595, 0.07411455812404721, 0.0, 1.0, 41078.13091384374], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2007000.0000, 
sim time next is 2008800.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.13805997751053, 0.05771806164269403, 0.0, 1.0, 41108.05848512557], 
processed observation next is [1.0, 0.2608695652173913, 0.2908587257617729, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5115049981258775, 0.519239353880898, 0.0, 1.0, 0.1957526594529789], 
reward next is 0.8042, 
noisyNet noise sample is [array([-1.1409973], dtype=float32), -1.7870786]. 
=============================================
[2019-04-06 21:17:24,237] A3C_AGENT_WORKER-Thread-15 INFO:Local step 85500, global step 1373417: loss 0.0653
[2019-04-06 21:17:24,238] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 85500, global step 1373417: learning rate 0.0000
[2019-04-06 21:17:26,064] A3C_AGENT_WORKER-Thread-11 INFO:Local step 87000, global step 1373626: loss 0.3635
[2019-04-06 21:17:26,065] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 87000, global step 1373626: learning rate 0.0000
[2019-04-06 21:17:47,754] A3C_AGENT_WORKER-Thread-3 INFO:Local step 86500, global step 1375670: loss 0.0226
[2019-04-06 21:17:47,755] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 86500, global step 1375670: learning rate 0.0000
[2019-04-06 21:17:59,970] A3C_AGENT_WORKER-Thread-19 INFO:Local step 86000, global step 1376666: loss 0.0648
[2019-04-06 21:17:59,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 86000, global step 1376666: learning rate 0.0000
[2019-04-06 21:18:03,980] A3C_AGENT_WORKER-Thread-20 INFO:Local step 85500, global step 1376988: loss 0.1168
[2019-04-06 21:18:03,980] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 85500, global step 1376988: learning rate 0.0000
[2019-04-06 21:18:04,467] A3C_AGENT_WORKER-Thread-17 INFO:Local step 86500, global step 1377043: loss 0.0223
[2019-04-06 21:18:04,468] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 86500, global step 1377043: learning rate 0.0000
[2019-04-06 21:18:08,212] A3C_AGENT_WORKER-Thread-10 INFO:Local step 85500, global step 1377413: loss 0.0861
[2019-04-06 21:18:08,213] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 85500, global step 1377413: learning rate 0.0000
[2019-04-06 21:18:21,513] A3C_AGENT_WORKER-Thread-16 INFO:Local step 86500, global step 1378724: loss 0.0217
[2019-04-06 21:18:21,513] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 86500, global step 1378724: learning rate 0.0000
[2019-04-06 21:18:22,299] A3C_AGENT_WORKER-Thread-5 INFO:Local step 86500, global step 1378794: loss 0.0266
[2019-04-06 21:18:22,300] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 86500, global step 1378794: learning rate 0.0000
[2019-04-06 21:18:23,975] A3C_AGENT_WORKER-Thread-15 INFO:Local step 86000, global step 1378926: loss 0.0657
[2019-04-06 21:18:23,975] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 86000, global step 1378926: learning rate 0.0000
[2019-04-06 21:18:28,520] A3C_AGENT_WORKER-Thread-11 INFO:Local step 87500, global step 1379328: loss 0.4620
[2019-04-06 21:18:28,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 87500, global step 1379328: learning rate 0.0000
[2019-04-06 21:18:29,262] A3C_AGENT_WORKER-Thread-2 INFO:Local step 85500, global step 1379393: loss 0.0874
[2019-04-06 21:18:29,263] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 85500, global step 1379393: learning rate 0.0000
[2019-04-06 21:18:34,552] A3C_AGENT_WORKER-Thread-13 INFO:Local step 86500, global step 1379853: loss 0.0215
[2019-04-06 21:18:34,553] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 86500, global step 1379853: learning rate 0.0000
[2019-04-06 21:18:36,241] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-06 21:18:36,241] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:18:36,241] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:18:36,245] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:18:36,248] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run70
[2019-04-06 21:18:36,242] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:18:36,345] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:18:36,328] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:18:36,371] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run70
[2019-04-06 21:18:36,368] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run70
[2019-04-06 21:21:13,467] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3748 79991956.7854 535.1864
[2019-04-06 21:21:31,301] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 21:21:34,980] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 21:21:36,018] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1380000, evaluation results [1380000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.374809603911, 79991956.78540477, 535.1864255395496, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 21:21:43,486] A3C_AGENT_WORKER-Thread-4 INFO:Local step 85500, global step 1381179: loss 0.0846
[2019-04-06 21:21:43,486] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 85500, global step 1381179: learning rate 0.0000
[2019-04-06 21:21:43,651] A3C_AGENT_WORKER-Thread-14 INFO:Local step 85500, global step 1381208: loss 0.0960
[2019-04-06 21:21:43,664] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 85500, global step 1381208: learning rate 0.0000
[2019-04-06 21:21:45,779] A3C_AGENT_WORKER-Thread-6 INFO:Local step 86500, global step 1381543: loss 0.0270
[2019-04-06 21:21:45,780] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 86500, global step 1381543: learning rate 0.0000
[2019-04-06 21:21:51,444] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8776924e-12 2.5363128e-10 5.5687221e-12 7.1563409e-05 7.7768944e-13
 9.9992847e-01 2.9213361e-12], sum to 1.0000
[2019-04-06 21:21:51,444] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3230
[2019-04-06 21:21:51,481] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 82.5, 0.0, 0.0, 26.0, 25.0554063496386, 0.3133474154057166, 0.0, 1.0, 42486.3203142573], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2154600.0000, 
sim time next is 2156400.0000, 
raw observation next is [-7.3, 82.0, 0.0, 0.0, 26.0, 24.80076006596724, 0.2686743964070832, 0.0, 1.0, 42154.2756044177], 
processed observation next is [1.0, 1.0, 0.26038781163434904, 0.82, 0.0, 0.0, 0.6666666666666666, 0.5667300054972699, 0.5895581321356944, 0.0, 1.0, 0.20073464573532238], 
reward next is 0.7993, 
noisyNet noise sample is [array([-2.1838799], dtype=float32), 0.75613534]. 
=============================================
[2019-04-06 21:21:52,034] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.2630530e-11 5.3428910e-09 1.2211852e-10 7.0753194e-05 5.1094289e-12
 9.9992919e-01 2.8896189e-11], sum to 1.0000
[2019-04-06 21:21:52,035] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6621
[2019-04-06 21:21:52,080] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 26.0, 23.45096544400141, 0.1378830058280725, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1236600.0000, 
sim time next is 1238400.0000, 
raw observation next is [15.0, 96.0, 14.0, 0.0, 26.0, 23.43851470198008, 0.1348069649412411, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.8781163434903049, 0.96, 0.04666666666666667, 0.0, 0.6666666666666666, 0.45320955849833994, 0.5449356549804137, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4706618], dtype=float32), 0.7018425]. 
=============================================
[2019-04-06 21:21:54,552] A3C_AGENT_WORKER-Thread-12 INFO:Local step 86500, global step 1382942: loss 0.0212
[2019-04-06 21:21:54,553] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 86500, global step 1382942: learning rate 0.0000
[2019-04-06 21:21:55,041] A3C_AGENT_WORKER-Thread-18 INFO:Local step 86500, global step 1383022: loss 0.0228
[2019-04-06 21:21:55,042] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 86500, global step 1383022: learning rate 0.0000
[2019-04-06 21:21:55,734] A3C_AGENT_WORKER-Thread-3 INFO:Local step 87000, global step 1383147: loss 0.3581
[2019-04-06 21:21:55,735] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 87000, global step 1383147: learning rate 0.0000
[2019-04-06 21:21:57,269] A3C_AGENT_WORKER-Thread-20 INFO:Local step 86000, global step 1383392: loss 0.0660
[2019-04-06 21:21:57,271] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 86000, global step 1383392: learning rate 0.0000
[2019-04-06 21:21:57,493] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:21:57,493] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:21:57,496] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run32
[2019-04-06 21:22:01,432] A3C_AGENT_WORKER-Thread-10 INFO:Local step 86000, global step 1383960: loss 0.0675
[2019-04-06 21:22:01,433] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 86000, global step 1383960: learning rate 0.0000
[2019-04-06 21:22:06,044] A3C_AGENT_WORKER-Thread-17 INFO:Local step 87000, global step 1384592: loss 0.3993
[2019-04-06 21:22:06,044] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 87000, global step 1384592: learning rate 0.0000
[2019-04-06 21:22:09,233] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8252498e-11 5.0639439e-09 8.1058993e-11 7.2651543e-05 2.7880830e-11
 9.9992728e-01 2.0015588e-10], sum to 1.0000
[2019-04-06 21:22:09,233] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5933
[2019-04-06 21:22:09,325] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 34.0, 77.0, 630.0, 26.0, 27.03684445193544, 0.7973685899329993, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3945600.0000, 
sim time next is 3947400.0000, 
raw observation next is [-4.5, 36.0, 66.0, 536.0, 26.0, 27.05341432342756, 0.7517978244821943, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.3379501385041552, 0.36, 0.22, 0.5922651933701657, 0.6666666666666666, 0.7544511936189634, 0.7505992748273981, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.64922893], dtype=float32), -2.0851743]. 
=============================================
[2019-04-06 21:22:15,213] A3C_AGENT_WORKER-Thread-2 INFO:Local step 86000, global step 1385930: loss 0.0659
[2019-04-06 21:22:15,214] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 86000, global step 1385930: learning rate 0.0000
[2019-04-06 21:22:17,815] A3C_AGENT_WORKER-Thread-16 INFO:Local step 87000, global step 1386320: loss 0.3434
[2019-04-06 21:22:17,816] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 87000, global step 1386320: learning rate 0.0000
[2019-04-06 21:22:18,652] A3C_AGENT_WORKER-Thread-5 INFO:Local step 87000, global step 1386470: loss 0.4312
[2019-04-06 21:22:18,652] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 87000, global step 1386470: learning rate 0.0000
[2019-04-06 21:22:20,370] A3C_AGENT_WORKER-Thread-19 INFO:Local step 86500, global step 1386729: loss 0.0232
[2019-04-06 21:22:20,385] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 86500, global step 1386732: learning rate 0.0000
[2019-04-06 21:22:23,105] A3C_AGENT_WORKER-Thread-13 INFO:Local step 87000, global step 1387128: loss 0.3971
[2019-04-06 21:22:23,129] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 87000, global step 1387128: learning rate 0.0000
[2019-04-06 21:22:24,180] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.6302092e-11 5.6962246e-10 5.1221472e-10 1.2807826e-04 4.7216130e-11
 9.9987185e-01 1.9354116e-11], sum to 1.0000
[2019-04-06 21:22:24,180] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3264
[2019-04-06 21:22:24,398] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 78.0, 14.0, 0.0, 26.0, 23.21336146354057, -0.108682403510682, 0.0, 1.0, 47143.01916669929], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1843200.0000, 
sim time next is 1845000.0000, 
raw observation next is [-6.7, 78.0, 27.0, 0.0, 26.0, 23.50548875717431, 0.05706513801021209, 0.0, 1.0, 150940.95958043696], 
processed observation next is [0.0, 0.34782608695652173, 0.2770083102493075, 0.78, 0.09, 0.0, 0.6666666666666666, 0.45879072976452573, 0.5190217126700707, 0.0, 1.0, 0.7187664741925569], 
reward next is 0.2812, 
noisyNet noise sample is [array([0.19076106], dtype=float32), -0.23815621]. 
=============================================
[2019-04-06 21:22:24,401] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[74.978294]
 [75.25807 ]
 [75.64577 ]
 [76.09852 ]
 [76.49441 ]], R is [[75.23583221]
 [75.25898743]
 [75.28170013]
 [75.30454254]
 [75.32736969]].
[2019-04-06 21:22:27,879] A3C_AGENT_WORKER-Thread-4 INFO:Local step 86000, global step 1387833: loss 0.0692
[2019-04-06 21:22:27,880] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 86000, global step 1387833: learning rate 0.0000
[2019-04-06 21:22:28,948] A3C_AGENT_WORKER-Thread-14 INFO:Local step 86000, global step 1387994: loss 0.0680
[2019-04-06 21:22:28,950] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 86000, global step 1387994: learning rate 0.0000
[2019-04-06 21:22:34,279] A3C_AGENT_WORKER-Thread-6 INFO:Local step 87000, global step 1388781: loss 0.4341
[2019-04-06 21:22:34,279] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 87000, global step 1388781: learning rate 0.0000
[2019-04-06 21:22:35,047] A3C_AGENT_WORKER-Thread-15 INFO:Local step 86500, global step 1388896: loss 0.0250
[2019-04-06 21:22:35,052] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 86500, global step 1388896: learning rate 0.0000
[2019-04-06 21:22:35,071] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5912644e-11 1.8423202e-09 6.3121431e-12 1.6803508e-04 1.2990835e-12
 9.9983191e-01 7.7142936e-12], sum to 1.0000
[2019-04-06 21:22:35,071] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1248
[2019-04-06 21:22:35,193] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.5, 61.0, 0.0, 0.0, 26.0, 24.94724582975445, 0.3546128154550861, 0.0, 1.0, 143151.50183434458], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3699000.0000, 
sim time next is 3700800.0000, 
raw observation next is [3.0, 63.0, 0.0, 0.0, 26.0, 25.41548259371854, 0.4591830747408079, 0.0, 1.0, 81168.43720875744], 
processed observation next is [0.0, 0.8695652173913043, 0.5457063711911359, 0.63, 0.0, 0.0, 0.6666666666666666, 0.6179568828098784, 0.6530610249136026, 0.0, 1.0, 0.38651636766074976], 
reward next is 0.6135, 
noisyNet noise sample is [array([-0.58807683], dtype=float32), 0.6574064]. 
=============================================
[2019-04-06 21:22:39,264] A3C_AGENT_WORKER-Thread-3 INFO:Local step 87500, global step 1389558: loss 0.3495
[2019-04-06 21:22:39,266] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 87500, global step 1389558: learning rate 0.0000
[2019-04-06 21:22:44,005] A3C_AGENT_WORKER-Thread-18 INFO:Local step 87000, global step 1390299: loss 0.3601
[2019-04-06 21:22:44,005] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 87000, global step 1390299: learning rate 0.0000
[2019-04-06 21:22:44,893] A3C_AGENT_WORKER-Thread-12 INFO:Local step 87000, global step 1390461: loss 0.3659
[2019-04-06 21:22:44,896] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 87000, global step 1390462: learning rate 0.0000
[2019-04-06 21:22:48,594] A3C_AGENT_WORKER-Thread-17 INFO:Local step 87500, global step 1391070: loss 0.5115
[2019-04-06 21:22:48,595] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 87500, global step 1391070: learning rate 0.0000
[2019-04-06 21:23:00,529] A3C_AGENT_WORKER-Thread-5 INFO:Local step 87500, global step 1393078: loss 0.3093
[2019-04-06 21:23:00,537] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 87500, global step 1393078: learning rate 0.0000
[2019-04-06 21:23:01,380] A3C_AGENT_WORKER-Thread-20 INFO:Local step 86500, global step 1393236: loss 0.0276
[2019-04-06 21:23:01,381] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 86500, global step 1393236: learning rate 0.0000
[2019-04-06 21:23:01,488] A3C_AGENT_WORKER-Thread-16 INFO:Local step 87500, global step 1393260: loss 0.3183
[2019-04-06 21:23:01,490] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 87500, global step 1393260: learning rate 0.0000
[2019-04-06 21:23:03,661] A3C_AGENT_WORKER-Thread-13 INFO:Local step 87500, global step 1393622: loss 0.3095
[2019-04-06 21:23:03,661] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 87500, global step 1393622: learning rate 0.0000
[2019-04-06 21:23:05,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:23:05,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:23:05,420] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run32
[2019-04-06 21:23:05,653] A3C_AGENT_WORKER-Thread-10 INFO:Local step 86500, global step 1393963: loss 0.0333
[2019-04-06 21:23:05,662] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 86500, global step 1393963: learning rate 0.0000
[2019-04-06 21:23:07,828] A3C_AGENT_WORKER-Thread-19 INFO:Local step 87000, global step 1394331: loss 0.3940
[2019-04-06 21:23:07,842] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 87000, global step 1394331: learning rate 0.0000
[2019-04-06 21:23:13,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:23:13,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:23:13,540] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run32
[2019-04-06 21:23:13,774] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8379353e-11 1.5945950e-09 2.7865236e-11 8.4720341e-05 2.3648052e-12
 9.9991524e-01 7.5175708e-12], sum to 1.0000
[2019-04-06 21:23:13,774] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7464
[2019-04-06 21:23:13,859] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 38.0, 0.0, 0.0, 26.0, 25.0792768291658, 0.219909291458258, 0.0, 1.0, 39554.74734502441], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2505600.0000, 
sim time next is 2507400.0000, 
raw observation next is [-1.7, 39.0, 0.0, 0.0, 26.0, 25.18994028938755, 0.2442843117367943, 0.0, 1.0, 39457.51704817259], 
processed observation next is [1.0, 0.0, 0.4155124653739613, 0.39, 0.0, 0.0, 0.6666666666666666, 0.5991616907822959, 0.5814281039122647, 0.0, 1.0, 0.18789293832463136], 
reward next is 0.8121, 
noisyNet noise sample is [array([-0.13218372], dtype=float32), 0.18078154]. 
=============================================
[2019-04-06 21:23:15,706] A3C_AGENT_WORKER-Thread-6 INFO:Local step 87500, global step 1395707: loss 0.2555
[2019-04-06 21:23:15,707] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 87500, global step 1395707: learning rate 0.0000
[2019-04-06 21:23:18,205] A3C_AGENT_WORKER-Thread-2 INFO:Local step 86500, global step 1395989: loss 0.0367
[2019-04-06 21:23:18,206] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 86500, global step 1395989: learning rate 0.0000
[2019-04-06 21:23:23,696] A3C_AGENT_WORKER-Thread-15 INFO:Local step 87000, global step 1396559: loss 0.4263
[2019-04-06 21:23:23,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 87000, global step 1396559: learning rate 0.0000
[2019-04-06 21:23:25,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1119636e-11 2.5966427e-09 9.8741973e-11 7.6023265e-05 2.5961136e-12
 9.9992394e-01 6.6974960e-11], sum to 1.0000
[2019-04-06 21:23:25,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4774
[2019-04-06 21:23:25,165] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 26.0, 21.19154630656796, -0.5838038839159895, 0.0, 1.0, 40385.629733236674], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 21600.0000, 
sim time next is 23400.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 26.0, 21.2560216395749, -0.5648554714690567, 0.0, 1.0, 40309.10375636767], 
processed observation next is [0.0, 0.2608695652173913, 0.6759002770083103, 0.93, 0.0, 0.0, 0.6666666666666666, 0.2713351366312417, 0.31171484284364775, 0.0, 1.0, 0.19194811312556034], 
reward next is 0.8081, 
noisyNet noise sample is [array([-0.55739915], dtype=float32), -1.1137718]. 
=============================================
[2019-04-06 21:23:28,113] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:23:28,113] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:23:28,136] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run32
[2019-04-06 21:23:29,483] A3C_AGENT_WORKER-Thread-18 INFO:Local step 87500, global step 1397194: loss 0.3402
[2019-04-06 21:23:29,484] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 87500, global step 1397194: learning rate 0.0000
[2019-04-06 21:23:30,575] A3C_AGENT_WORKER-Thread-12 INFO:Local step 87500, global step 1397318: loss 0.2571
[2019-04-06 21:23:30,575] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 87500, global step 1397318: learning rate 0.0000
[2019-04-06 21:23:32,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:23:32,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:23:32,552] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run32
[2019-04-06 21:23:34,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:23:34,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:23:34,900] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run32
[2019-04-06 21:23:37,441] A3C_AGENT_WORKER-Thread-4 INFO:Local step 86500, global step 1397921: loss 0.0364
[2019-04-06 21:23:37,442] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 86500, global step 1397921: learning rate 0.0000
[2019-04-06 21:23:40,414] A3C_AGENT_WORKER-Thread-14 INFO:Local step 86500, global step 1398137: loss 0.0380
[2019-04-06 21:23:40,414] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 86500, global step 1398137: learning rate 0.0000
[2019-04-06 21:23:43,448] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.72818781e-11 9.16025122e-09 4.16910013e-11 9.14104457e-05
 1.14332474e-10 9.99908566e-01 3.67210221e-11], sum to 1.0000
[2019-04-06 21:23:43,449] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9132
[2019-04-06 21:23:43,556] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 37.5, 0.0, 0.0, 26.0, 25.46122862772531, 0.3625058834467534, 0.0, 1.0, 34020.095577246815], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4919400.0000, 
sim time next is 4921200.0000, 
raw observation next is [0.0, 39.0, 0.0, 0.0, 26.0, 25.40511363103611, 0.3507681245216811, 0.0, 1.0, 46361.10131274901], 
processed observation next is [0.0, 1.0, 0.46260387811634357, 0.39, 0.0, 0.0, 0.6666666666666666, 0.6170928025863424, 0.6169227081738937, 0.0, 1.0, 0.22076714910832862], 
reward next is 0.7792, 
noisyNet noise sample is [array([2.3799486], dtype=float32), -1.6042421]. 
=============================================
[2019-04-06 21:23:55,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:23:55,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:23:55,548] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run32
[2019-04-06 21:24:01,730] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-06 21:24:01,730] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:24:01,730] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:24:01,731] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:24:01,731] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:24:01,731] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:24:01,731] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:24:01,736] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run71
[2019-04-06 21:24:01,740] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run71
[2019-04-06 21:24:01,748] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run71
[2019-04-06 21:26:36,077] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 21:26:38,379] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.06216766], dtype=float32), 0.13523208]
[2019-04-06 21:26:38,379] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-0.921560224, 69.43985215, 102.10305017, 697.2155485000001, 26.0, 25.72457544176946, 0.4847755910750259, 1.0, 1.0, 0.0]
[2019-04-06 21:26:38,379] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 21:26:38,380] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [3.6881284e-12 9.3199959e-10 1.3161173e-11 6.1937280e-05 1.8074821e-12
 9.9993801e-01 8.1380805e-12], sampled 0.39124172890896747
[2019-04-06 21:26:57,011] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 21:26:59,249] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 21:27:00,271] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1400000, evaluation results [1400000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 21:27:01,254] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2149669e-11 2.1280924e-09 2.9343878e-11 4.0362161e-04 1.0447646e-11
 9.9959642e-01 1.9161043e-11], sum to 1.0000
[2019-04-06 21:27:01,254] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7847
[2019-04-06 21:27:01,371] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 55.0, 116.0, 819.5, 26.0, 25.17921352260345, 0.4453130470618434, 0.0, 1.0, 27600.771129635632], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3585600.0000, 
sim time next is 3587400.0000, 
raw observation next is [-2.5, 52.5, 118.0, 823.0, 26.0, 25.18006123977021, 0.4491911113445922, 0.0, 1.0, 18711.22159289924], 
processed observation next is [0.0, 0.5217391304347826, 0.39335180055401664, 0.525, 0.3933333333333333, 0.9093922651933701, 0.6666666666666666, 0.5983384366475176, 0.6497303704481974, 0.0, 1.0, 0.0891010552042821], 
reward next is 0.9109, 
noisyNet noise sample is [array([-0.4615285], dtype=float32), -1.1376156]. 
=============================================
[2019-04-06 21:27:04,775] A3C_AGENT_WORKER-Thread-20 INFO:Local step 87000, global step 1400629: loss 0.3953
[2019-04-06 21:27:04,776] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 87000, global step 1400629: learning rate 0.0000
[2019-04-06 21:27:05,051] A3C_AGENT_WORKER-Thread-19 INFO:Local step 87500, global step 1400672: loss 0.3196
[2019-04-06 21:27:05,051] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 87500, global step 1400672: learning rate 0.0000
[2019-04-06 21:27:06,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:27:06,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:27:06,188] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run32
[2019-04-06 21:27:07,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:27:07,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:27:07,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run32
[2019-04-06 21:27:08,716] A3C_AGENT_WORKER-Thread-10 INFO:Local step 87000, global step 1401141: loss 0.3590
[2019-04-06 21:27:08,717] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 87000, global step 1401141: learning rate 0.0000
[2019-04-06 21:27:19,131] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.9516636e-12 2.0004845e-10 9.3997185e-11 3.0251162e-04 4.8909453e-12
 9.9969757e-01 2.2371431e-11], sum to 1.0000
[2019-04-06 21:27:19,131] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6373
[2019-04-06 21:27:19,150] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.5, 54.0, 118.0, 811.0, 26.0, 26.24678252315418, 0.5773457359469171, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3328200.0000, 
sim time next is 3330000.0000, 
raw observation next is [-5.0, 54.0, 116.0, 805.5, 26.0, 25.94001885601104, 0.5578672511731724, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.32409972299168976, 0.54, 0.38666666666666666, 0.8900552486187845, 0.6666666666666666, 0.66166823800092, 0.6859557503910575, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.29472965], dtype=float32), 1.6058743]. 
=============================================
[2019-04-06 21:27:19,203] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[82.966125]
 [83.1234  ]
 [83.31963 ]
 [83.508316]
 [83.49745 ]], R is [[82.91929626]
 [83.09010315]
 [83.25920105]
 [83.42661285]
 [83.59234619]].
[2019-04-06 21:27:19,634] A3C_AGENT_WORKER-Thread-15 INFO:Local step 87500, global step 1402501: loss 0.3117
[2019-04-06 21:27:19,635] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 87500, global step 1402501: learning rate 0.0000
[2019-04-06 21:27:23,021] A3C_AGENT_WORKER-Thread-2 INFO:Local step 87000, global step 1402934: loss 0.3984
[2019-04-06 21:27:23,022] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 87000, global step 1402934: learning rate 0.0000
[2019-04-06 21:27:28,130] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.5612693e-11 1.1854811e-08 3.0667124e-10 3.1078204e-03 1.2781418e-11
 9.9689215e-01 5.9169593e-11], sum to 1.0000
[2019-04-06 21:27:28,130] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1054
[2019-04-06 21:27:28,321] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 40.0, 0.0, 0.0, 26.0, 25.24604018260659, 0.2857273978263907, 1.0, 1.0, 46892.70173600206], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 414000.0000, 
sim time next is 415800.0000, 
raw observation next is [-9.75, 41.0, 0.0, 0.0, 26.0, 25.08810795553453, 0.2949925818132944, 1.0, 1.0, 96994.0594348293], 
processed observation next is [1.0, 0.8260869565217391, 0.19252077562326872, 0.41, 0.0, 0.0, 0.6666666666666666, 0.5906756629612108, 0.5983308606044314, 1.0, 1.0, 0.4618764734991871], 
reward next is 0.5381, 
noisyNet noise sample is [array([-0.764227], dtype=float32), -1.0423701]. 
=============================================
[2019-04-06 21:27:33,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:27:33,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:27:33,796] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run32
[2019-04-06 21:27:36,824] A3C_AGENT_WORKER-Thread-4 INFO:Local step 87000, global step 1404685: loss 0.3576
[2019-04-06 21:27:36,824] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 87000, global step 1404685: learning rate 0.0000
[2019-04-06 21:27:38,962] A3C_AGENT_WORKER-Thread-14 INFO:Local step 87000, global step 1405003: loss 0.3260
[2019-04-06 21:27:38,963] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 87000, global step 1405003: learning rate 0.0000
[2019-04-06 21:27:47,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:27:47,358] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:27:47,363] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run32
[2019-04-06 21:27:47,507] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.4532673e-11 5.6164645e-10 1.3221943e-11 3.2887790e-05 3.0718990e-13
 9.9996710e-01 1.9947087e-11], sum to 1.0000
[2019-04-06 21:27:47,507] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1688
[2019-04-06 21:27:47,586] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 68.0, 0.0, 0.0, 26.0, 25.15215612320444, 0.3251548556823612, 0.0, 1.0, 41120.33933478856], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3907800.0000, 
sim time next is 3909600.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.92304421986042, 0.2943063824581099, 0.0, 1.0, 41583.37536304803], 
processed observation next is [1.0, 0.2608695652173913, 0.296398891966759, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5769203516550349, 0.5981021274860366, 0.0, 1.0, 0.19801607315737155], 
reward next is 0.8020, 
noisyNet noise sample is [array([-0.7075937], dtype=float32), 2.149665]. 
=============================================
[2019-04-06 21:27:51,155] A3C_AGENT_WORKER-Thread-20 INFO:Local step 87500, global step 1406623: loss 0.3815
[2019-04-06 21:27:51,155] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 87500, global step 1406623: learning rate 0.0000
[2019-04-06 21:27:54,909] A3C_AGENT_WORKER-Thread-10 INFO:Local step 87500, global step 1407149: loss 0.3376
[2019-04-06 21:27:54,909] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 87500, global step 1407149: learning rate 0.0000
[2019-04-06 21:27:55,380] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1390376e-11 2.1071997e-09 3.6505281e-11 8.2636681e-05 4.5522609e-12
 9.9991739e-01 1.4498823e-11], sum to 1.0000
[2019-04-06 21:27:55,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7432
[2019-04-06 21:27:55,485] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.45, 75.5, 0.0, 0.0, 26.0, 25.56261208545037, 0.4022590905078445, 0.0, 1.0, 23971.63102114669], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4318200.0000, 
sim time next is 4320000.0000, 
raw observation next is [4.5, 76.0, 0.0, 0.0, 26.0, 25.45326070069806, 0.4091276563107401, 0.0, 1.0, 61400.83569935564], 
processed observation next is [1.0, 0.0, 0.5872576177285319, 0.76, 0.0, 0.0, 0.6666666666666666, 0.621105058391505, 0.6363758854369134, 0.0, 1.0, 0.2923849319016935], 
reward next is 0.7076, 
noisyNet noise sample is [array([1.7220472], dtype=float32), -1.4160292]. 
=============================================
[2019-04-06 21:27:55,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[89.821266]
 [90.10176 ]
 [90.38654 ]
 [90.43812 ]
 [90.14186 ]], R is [[91.67640686]
 [91.64549255]
 [91.62506104]
 [91.53170013]
 [91.30339813]].
[2019-04-06 21:28:03,704] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8678011e-11 3.1132455e-08 3.1000154e-11 2.1527901e-03 1.1950570e-12
 9.9784720e-01 1.3470676e-11], sum to 1.0000
[2019-04-06 21:28:03,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9299
[2019-04-06 21:28:03,863] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.5, 59.0, 0.0, 26.0, 26.29748061408941, 0.455268224329584, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 829800.0000, 
sim time next is 831600.0000, 
raw observation next is [-3.9, 86.0, 54.0, 0.0, 26.0, 26.22924777072891, 0.3353189858304184, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.3545706371191136, 0.86, 0.18, 0.0, 0.6666666666666666, 0.6857706475607426, 0.6117729952768062, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9570655], dtype=float32), -1.3090662]. 
=============================================
[2019-04-06 21:28:06,941] A3C_AGENT_WORKER-Thread-2 INFO:Local step 87500, global step 1408933: loss 0.3013
[2019-04-06 21:28:06,941] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 87500, global step 1408933: learning rate 0.0000
[2019-04-06 21:28:17,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:28:17,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:28:17,380] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run32
[2019-04-06 21:28:18,636] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6265838e-12 8.1898125e-12 1.6849908e-12 8.0839009e-06 5.7407161e-13
 9.9999189e-01 3.7138586e-13], sum to 1.0000
[2019-04-06 21:28:18,636] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5925
[2019-04-06 21:28:18,674] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.15, 72.0, 0.0, 0.0, 26.0, 25.39512773656721, 0.4832212035809144, 0.0, 1.0, 75196.28866384855], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4487400.0000, 
sim time next is 4489200.0000, 
raw observation next is [-0.3, 72.0, 0.0, 0.0, 26.0, 25.34374323051502, 0.4842050718761599, 0.0, 1.0, 57366.05997338356], 
processed observation next is [1.0, 1.0, 0.4542936288088643, 0.72, 0.0, 0.0, 0.6666666666666666, 0.6119786025429184, 0.6614016906253867, 0.0, 1.0, 0.27317171415896935], 
reward next is 0.7268, 
noisyNet noise sample is [array([-0.35531288], dtype=float32), -1.9314221]. 
=============================================
[2019-04-06 21:28:19,660] A3C_AGENT_WORKER-Thread-4 INFO:Local step 87500, global step 1411269: loss 0.4348
[2019-04-06 21:28:19,660] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 87500, global step 1411269: learning rate 0.0000
[2019-04-06 21:28:20,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:28:20,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:28:20,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run32
[2019-04-06 21:28:21,951] A3C_AGENT_WORKER-Thread-14 INFO:Local step 87500, global step 1411592: loss 0.4235
[2019-04-06 21:28:21,952] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 87500, global step 1411592: learning rate 0.0000
[2019-04-06 21:28:23,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9232059e-12 6.2826905e-10 1.7841031e-10 3.6564228e-04 1.9044185e-12
 9.9963439e-01 6.0149425e-12], sum to 1.0000
[2019-04-06 21:28:23,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0635
[2019-04-06 21:28:23,511] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 43.0, 0.0, 0.0, 26.0, 25.66165313459273, 0.3599862377829031, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4928400.0000, 
sim time next is 4930200.0000, 
raw observation next is [-0.5, 46.5, 0.0, 0.0, 26.0, 25.42825800872156, 0.3137669073105281, 0.0, 1.0, 35179.426989460844], 
processed observation next is [1.0, 0.043478260869565216, 0.44875346260387816, 0.465, 0.0, 0.0, 0.6666666666666666, 0.6190215007267966, 0.6045889691035093, 0.0, 1.0, 0.1675210809021945], 
reward next is 0.8325, 
noisyNet noise sample is [array([-1.6872212], dtype=float32), 0.8969124]. 
=============================================
[2019-04-06 21:28:26,955] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8579492e-13 7.2860655e-11 2.2613526e-12 9.7276325e-06 3.7413459e-13
 9.9999022e-01 2.4887156e-13], sum to 1.0000
[2019-04-06 21:28:26,955] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5490
[2019-04-06 21:28:27,001] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.3, 97.5, 0.0, 0.0, 26.0, 25.48076951863624, 0.4664960025111042, 0.0, 1.0, 17093.875326910875], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1395000.0000, 
sim time next is 1396800.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 26.0, 25.24129424529551, 0.4589079373845548, 0.0, 1.0, 58608.207463909865], 
processed observation next is [1.0, 0.17391304347826086, 0.44598337950138506, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6034411871079591, 0.6529693124615182, 0.0, 1.0, 0.2790867022090946], 
reward next is 0.7209, 
noisyNet noise sample is [array([-0.67690104], dtype=float32), -2.3626626]. 
=============================================
[2019-04-06 21:28:31,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:28:31,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:28:31,769] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run32
[2019-04-06 21:28:40,552] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.8676523e-12 2.8406175e-10 9.7718795e-13 2.5618816e-05 1.7894383e-13
 9.9997437e-01 6.4154893e-13], sum to 1.0000
[2019-04-06 21:28:40,553] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0278
[2019-04-06 21:28:40,617] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 82.0, 0.0, 0.0, 26.0, 25.47615539713037, 0.553287204291861, 0.0, 1.0, 51026.90599851062], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1555200.0000, 
sim time next is 1557000.0000, 
raw observation next is [5.0, 82.0, 0.0, 0.0, 26.0, 25.48759701868731, 0.5661307196371765, 0.0, 1.0, 39247.911815950414], 
processed observation next is [1.0, 0.0, 0.6011080332409973, 0.82, 0.0, 0.0, 0.6666666666666666, 0.6239664182239425, 0.6887102398790589, 0.0, 1.0, 0.18689481817119244], 
reward next is 0.8131, 
noisyNet noise sample is [array([0.12689792], dtype=float32), 2.0235133]. 
=============================================
[2019-04-06 21:28:40,623] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[92.93484 ]
 [92.80924 ]
 [92.931114]
 [92.73611 ]
 [92.87333 ]], R is [[92.96764374]
 [92.79498291]
 [92.72600555]
 [92.44768524]
 [92.52320862]].
[2019-04-06 21:28:40,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.5048925e-12 1.3242265e-09 9.5663777e-10 2.7754469e-04 2.3549170e-11
 9.9972242e-01 1.1316836e-10], sum to 1.0000
[2019-04-06 21:28:40,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4503
[2019-04-06 21:28:41,005] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 71.0, 0.0, 0.0, 26.0, 23.95617247812843, 0.05982449196822043, 0.0, 1.0, 44810.475893032715], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 171000.0000, 
sim time next is 172800.0000, 
raw observation next is [-8.4, 71.0, 0.0, 0.0, 26.0, 23.83105400442642, 0.03034964524917983, 0.0, 1.0, 44645.01041405436], 
processed observation next is [1.0, 0.0, 0.2299168975069252, 0.71, 0.0, 0.0, 0.6666666666666666, 0.485921167035535, 0.5101165484163933, 0.0, 1.0, 0.21259528768597316], 
reward next is 0.7874, 
noisyNet noise sample is [array([1.3658209], dtype=float32), 1.7167872]. 
=============================================
[2019-04-06 21:28:45,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:28:45,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:28:45,528] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run32
[2019-04-06 21:28:47,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:28:47,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:28:47,301] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run32
[2019-04-06 21:29:22,969] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3702941e-11 1.3163910e-09 2.7989850e-11 2.5373726e-04 4.6322486e-12
 9.9974626e-01 4.4288930e-11], sum to 1.0000
[2019-04-06 21:29:22,969] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4289
[2019-04-06 21:29:23,003] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5531808e-12 1.0289838e-09 1.0141860e-11 6.4510830e-05 5.5095971e-12
 9.9993551e-01 6.0291039e-12], sum to 1.0000
[2019-04-06 21:29:23,004] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7803
[2019-04-06 21:29:23,286] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 32.0, 0.0, 26.0, 25.81851380572238, 0.4026359148166687, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2046600.0000, 
sim time next is 2048400.0000, 
raw observation next is [-3.9, 82.0, 17.0, 0.0, 26.0, 25.36543490312292, 0.3421748303614889, 1.0, 1.0, 21251.25273471625], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.82, 0.056666666666666664, 0.0, 0.6666666666666666, 0.6137862419269101, 0.614058276787163, 1.0, 1.0, 0.10119644159388691], 
reward next is 0.8988, 
noisyNet noise sample is [array([0.4121918], dtype=float32), 0.46631393]. 
=============================================
[2019-04-06 21:29:23,298] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.8, 90.0, 0.0, 0.0, 26.0, 24.85712539551301, 0.2325249847199502, 1.0, 1.0, 99588.52541190966], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 498600.0000, 
sim time next is 500400.0000, 
raw observation next is [1.1, 96.0, 0.0, 0.0, 26.0, 25.0278173091757, 0.214892075851168, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.96, 0.0, 0.0, 0.6666666666666666, 0.5856514424313083, 0.5716306919503894, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7314724], dtype=float32), -1.7583935]. 
=============================================
[2019-04-06 21:29:26,911] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2993550e-11 3.3404506e-09 8.7745568e-11 4.3646749e-05 4.3045346e-12
 9.9995637e-01 2.8587839e-11], sum to 1.0000
[2019-04-06 21:29:26,911] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8317
[2019-04-06 21:29:27,276] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 71.0, 178.0, 62.0, 26.0, 25.03093854101908, 0.2816435080738328, 0.0, 1.0, 35968.1111489838], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1864800.0000, 
sim time next is 1866600.0000, 
raw observation next is [-4.5, 77.0, 186.0, 84.0, 26.0, 25.02389187628254, 0.284839502996971, 0.0, 1.0, 40255.0997425729], 
processed observation next is [0.0, 0.6086956521739131, 0.3379501385041552, 0.77, 0.62, 0.09281767955801105, 0.6666666666666666, 0.5853243230235451, 0.5949465009989904, 0.0, 1.0, 0.19169095115510904], 
reward next is 0.8083, 
noisyNet noise sample is [array([0.6278713], dtype=float32), 0.37935334]. 
=============================================
[2019-04-06 21:29:36,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2827361e-14 1.3524740e-10 2.8600063e-13 1.5601207e-05 6.0329590e-14
 9.9998438e-01 2.3305235e-13], sum to 1.0000
[2019-04-06 21:29:36,921] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9743
[2019-04-06 21:29:36,984] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.8, 93.0, 0.0, 0.0, 26.0, 25.53299989987421, 0.5868746638452531, 0.0, 1.0, 12498.302193014437], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1299600.0000, 
sim time next is 1301400.0000, 
raw observation next is [3.55, 92.5, 0.0, 0.0, 26.0, 25.49840342098388, 0.5544002975734662, 0.0, 1.0, 27904.354911938164], 
processed observation next is [1.0, 0.043478260869565216, 0.5609418282548477, 0.925, 0.0, 0.0, 0.6666666666666666, 0.6248669517486567, 0.6848000991911554, 0.0, 1.0, 0.13287788053303887], 
reward next is 0.8671, 
noisyNet noise sample is [array([-1.3894764], dtype=float32), 1.8545371]. 
=============================================
[2019-04-06 21:29:43,264] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2680612e-11 7.6494748e-09 4.0269610e-10 1.7662763e-03 1.6384396e-11
 9.9823368e-01 5.2187049e-10], sum to 1.0000
[2019-04-06 21:29:43,264] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4625
[2019-04-06 21:29:43,345] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.9, 80.5, 0.0, 0.0, 26.0, 25.17328501466623, 0.3625959104477088, 0.0, 1.0, 43716.61583728477], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1978200.0000, 
sim time next is 1980000.0000, 
raw observation next is [-6.2, 83.0, 0.0, 0.0, 26.0, 25.08156396832157, 0.3479049735231395, 0.0, 1.0, 42998.49563446829], 
processed observation next is [1.0, 0.9565217391304348, 0.2908587257617729, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5901303306934643, 0.6159683245077131, 0.0, 1.0, 0.20475474111651565], 
reward next is 0.7952, 
noisyNet noise sample is [array([0.0600546], dtype=float32), -0.128873]. 
=============================================
[2019-04-06 21:29:43,348] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[81.127106]
 [81.13624 ]
 [81.107155]
 [81.05694 ]
 [80.864914]], R is [[81.14014435]
 [81.12056732]
 [81.0842514 ]
 [81.03813934]
 [80.61078644]].
[2019-04-06 21:29:47,766] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 21:29:47,767] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:29:47,767] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:29:47,771] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run72
[2019-04-06 21:29:47,841] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:29:47,841] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:29:47,857] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:29:47,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:29:47,861] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run72
[2019-04-06 21:29:47,932] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run72
[2019-04-06 21:32:25,308] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 21:32:43,162] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 21:32:46,129] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 21:32:47,153] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1420000, evaluation results [1420000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 21:33:06,291] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3885548e-11 1.0312451e-08 3.5685233e-11 1.1040127e-03 8.0471879e-12
 9.9889600e-01 1.5920637e-10], sum to 1.0000
[2019-04-06 21:33:06,291] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2848
[2019-04-06 21:33:06,465] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 62.0, 93.0, 0.0, 26.0, 25.7090927140359, 0.3162621520966807, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1954800.0000, 
sim time next is 1956600.0000, 
raw observation next is [-2.8, 62.0, 74.0, 0.0, 26.0, 25.63432904141165, 0.3237720360911077, 1.0, 1.0, 55841.93988942296], 
processed observation next is [1.0, 0.6521739130434783, 0.38504155124653744, 0.62, 0.24666666666666667, 0.0, 0.6666666666666666, 0.6361940867843042, 0.6079240120303693, 1.0, 1.0, 0.2659139994734427], 
reward next is 0.7341, 
noisyNet noise sample is [array([-0.49758443], dtype=float32), -0.04065826]. 
=============================================
[2019-04-06 21:33:19,545] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7986762e-12 1.4582420e-09 5.7453514e-11 4.5101420e-05 2.9444218e-12
 9.9995494e-01 4.9831502e-12], sum to 1.0000
[2019-04-06 21:33:19,546] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7339
[2019-04-06 21:33:19,663] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.8, 94.5, 18.0, 0.0, 26.0, 25.69498489815761, 0.4854196809879373, 1.0, 1.0, 17432.152614956867], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1355400.0000, 
sim time next is 1357200.0000, 
raw observation next is [0.5, 96.0, 9.0, 0.0, 26.0, 25.05375484092359, 0.4296938118634375, 1.0, 1.0, 64067.944897116955], 
processed observation next is [1.0, 0.7391304347826086, 0.4764542936288089, 0.96, 0.03, 0.0, 0.6666666666666666, 0.5878129034102993, 0.6432312706211458, 1.0, 1.0, 0.30508545189103314], 
reward next is 0.6949, 
noisyNet noise sample is [array([0.28506485], dtype=float32), 0.2528157]. 
=============================================
[2019-04-06 21:33:21,067] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2488477e-11 1.7638458e-08 1.4417507e-10 3.4002346e-04 1.8586452e-11
 9.9966002e-01 2.7014722e-11], sum to 1.0000
[2019-04-06 21:33:21,067] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6873
[2019-04-06 21:33:21,130] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.65, 71.5, 0.0, 0.0, 26.0, 24.3977697436107, 0.09165802518161437, 0.0, 1.0, 41001.89878937471], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 693000.0000, 
sim time next is 694800.0000, 
raw observation next is [-3.4, 72.0, 0.0, 0.0, 26.0, 24.39164791518039, 0.09200533665186507, 0.0, 1.0, 40947.06756785908], 
processed observation next is [1.0, 0.043478260869565216, 0.368421052631579, 0.72, 0.0, 0.0, 0.6666666666666666, 0.5326373262650325, 0.5306684455506218, 0.0, 1.0, 0.19498603603742418], 
reward next is 0.8050, 
noisyNet noise sample is [array([-0.98007876], dtype=float32), -0.27183998]. 
=============================================
[2019-04-06 21:33:40,909] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9017020e-13 4.7630250e-11 3.0887940e-12 2.4532526e-05 2.1180921e-14
 9.9997544e-01 2.5866486e-12], sum to 1.0000
[2019-04-06 21:33:40,909] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8191
[2019-04-06 21:33:41,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:33:41,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:33:41,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run33
[2019-04-06 21:33:41,090] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 25.03506243903738, 0.456141600769205, 0.0, 1.0, 84694.4364445948], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3528000.0000, 
sim time next is 3529800.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 25.09769324136807, 0.5143160189653799, 0.0, 1.0, 146310.56848251066], 
processed observation next is [1.0, 0.8695652173913043, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.5914744367806725, 0.6714386729884599, 0.0, 1.0, 0.6967169927738602], 
reward next is 0.3033, 
noisyNet noise sample is [array([-0.5666365], dtype=float32), 0.10332533]. 
=============================================
[2019-04-06 21:34:07,696] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5788362e-11 1.1444098e-08 5.5173886e-11 1.0620853e-03 6.6367592e-11
 9.9893790e-01 1.2620711e-10], sum to 1.0000
[2019-04-06 21:34:07,697] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9306
[2019-04-06 21:34:07,790] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 29.0, 0.0, 0.0, 26.0, 25.6804760927208, 0.5256703533002691, 0.0, 1.0, 17243.483794304164], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4050000.0000, 
sim time next is 4051800.0000, 
raw observation next is [-4.5, 30.0, 0.0, 0.0, 26.0, 25.59108912855307, 0.4868081263296586, 0.0, 1.0, 13695.808168977206], 
processed observation next is [1.0, 0.9130434782608695, 0.3379501385041552, 0.3, 0.0, 0.0, 0.6666666666666666, 0.6325907607127558, 0.6622693754432195, 0.0, 1.0, 0.0652181341379867], 
reward next is 0.9348, 
noisyNet noise sample is [array([-0.7412589], dtype=float32), 0.24257913]. 
=============================================
[2019-04-06 21:34:18,255] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4397653e-12 3.3251835e-10 2.5104530e-11 9.3469629e-04 1.4505767e-11
 9.9906534e-01 3.6163489e-11], sum to 1.0000
[2019-04-06 21:34:18,256] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7686
[2019-04-06 21:34:18,331] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.35882300479779, 0.3341321401568108, 0.0, 1.0, 36673.611234303666], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3729600.0000, 
sim time next is 3731400.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.4030222379708, 0.3295290586898421, 0.0, 1.0, 38629.928037825855], 
processed observation next is [1.0, 0.17391304347826086, 0.3795013850415513, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6169185198308998, 0.6098430195632807, 0.0, 1.0, 0.18395203827536122], 
reward next is 0.8160, 
noisyNet noise sample is [array([0.15262015], dtype=float32), -0.4924137]. 
=============================================
[2019-04-06 21:34:24,376] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7669251e-11 8.3691037e-10 5.2193087e-11 1.7697223e-06 4.1582662e-12
 9.9999821e-01 8.2466083e-12], sum to 1.0000
[2019-04-06 21:34:24,387] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7842
[2019-04-06 21:34:24,441] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.10928345625657, 0.08090820453338986, 0.0, 1.0, 41320.654356438194], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2358000.0000, 
sim time next is 2359800.0000, 
raw observation next is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.00585925441625, 0.05950042640214775, 0.0, 1.0, 41522.5893517386], 
processed observation next is [0.0, 0.30434782608695654, 0.368421052631579, 0.69, 0.0, 0.0, 0.6666666666666666, 0.5004882712013542, 0.5198334754673826, 0.0, 1.0, 0.19772661596066], 
reward next is 0.8023, 
noisyNet noise sample is [array([0.38697392], dtype=float32), 0.74399906]. 
=============================================
[2019-04-06 21:34:27,273] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3670263e-12 5.4478827e-10 1.0166347e-12 8.1059668e-04 2.0120329e-12
 9.9918944e-01 1.3358475e-11], sum to 1.0000
[2019-04-06 21:34:27,273] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6718
[2019-04-06 21:34:27,321] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 26.0, 24.50037241068129, 0.1581035272567075, 0.0, 1.0, 42528.854988277504], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2169000.0000, 
sim time next is 2170800.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 26.0, 24.49888018357656, 0.1600654390824777, 0.0, 1.0, 42433.22692268149], 
processed observation next is [1.0, 0.13043478260869565, 0.2770083102493075, 0.78, 0.0, 0.0, 0.6666666666666666, 0.54157334863138, 0.5533551463608258, 0.0, 1.0, 0.20206298534610234], 
reward next is 0.7979, 
noisyNet noise sample is [array([1.2563349], dtype=float32), -0.011478584]. 
=============================================
[2019-04-06 21:34:27,498] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0460167e-12 2.1797722e-10 9.6783597e-12 1.0388398e-05 8.8784443e-13
 9.9998963e-01 7.6792617e-12], sum to 1.0000
[2019-04-06 21:34:27,498] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0039
[2019-04-06 21:34:27,610] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.449999999999999, 77.0, 171.0, 236.0, 26.0, 25.83542683196043, 0.33378889923934, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1938600.0000, 
sim time next is 1940400.0000, 
raw observation next is [-5.6, 75.0, 201.5, 123.0, 26.0, 25.71021257753003, 0.3177922624206114, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.30747922437673136, 0.75, 0.6716666666666666, 0.13591160220994475, 0.6666666666666666, 0.6425177147941691, 0.6059307541402038, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0186368], dtype=float32), -0.6600003]. 
=============================================
[2019-04-06 21:34:28,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.9417219e-12 2.6513753e-09 1.0890222e-11 1.8253240e-04 2.7054702e-12
 9.9981755e-01 9.8459914e-11], sum to 1.0000
[2019-04-06 21:34:28,173] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3620
[2019-04-06 21:34:28,298] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 65.0, 182.0, 2.0, 26.0, 25.57563556278687, 0.3137902792921876, 1.0, 1.0, 26449.097835840104], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1947600.0000, 
sim time next is 1949400.0000, 
raw observation next is [-3.65, 63.5, 137.0, 0.0, 26.0, 25.54632805424376, 0.3306372361621983, 1.0, 1.0, 22865.41185118951], 
processed observation next is [1.0, 0.5652173913043478, 0.3614958448753463, 0.635, 0.45666666666666667, 0.0, 0.6666666666666666, 0.6288606711869799, 0.6102124120540661, 1.0, 1.0, 0.10888291357709291], 
reward next is 0.8911, 
noisyNet noise sample is [array([-0.41030765], dtype=float32), -0.41801366]. 
=============================================
[2019-04-06 21:34:29,886] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7832949e-12 1.2073580e-09 1.1403934e-11 4.0173222e-04 1.0153025e-12
 9.9959832e-01 3.6477397e-12], sum to 1.0000
[2019-04-06 21:34:29,888] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4646
[2019-04-06 21:34:29,957] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.4, 63.0, 0.0, 0.0, 26.0, 25.43121017027804, 0.4453644860505006, 0.0, 1.0, 32492.557904639532], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4582800.0000, 
sim time next is 4584600.0000, 
raw observation next is [0.1, 64.0, 0.0, 0.0, 26.0, 25.43833897192, 0.4415889131197385, 0.0, 1.0, 37126.978089326134], 
processed observation next is [1.0, 0.043478260869565216, 0.4653739612188367, 0.64, 0.0, 0.0, 0.6666666666666666, 0.6198615809933333, 0.6471963043732462, 0.0, 1.0, 0.17679513375869588], 
reward next is 0.8232, 
noisyNet noise sample is [array([0.19761601], dtype=float32), 0.27651268]. 
=============================================
[2019-04-06 21:34:48,259] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3207883e-14 8.6196640e-11 1.0219156e-13 1.0867178e-06 5.5667480e-15
 9.9999893e-01 7.2390621e-14], sum to 1.0000
[2019-04-06 21:34:48,259] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7507
[2019-04-06 21:34:48,357] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 100.0, 0.0, 0.0, 26.0, 25.43509848397836, 0.5418414529770351, 0.0, 1.0, 74700.94498066661], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3204000.0000, 
sim time next is 3205800.0000, 
raw observation next is [-0.5, 100.0, 0.0, 0.0, 26.0, 25.4725548184096, 0.5807206194626013, 0.0, 1.0, 53235.364628530486], 
processed observation next is [1.0, 0.08695652173913043, 0.44875346260387816, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6227129015341332, 0.6935735398208672, 0.0, 1.0, 0.25350173632633566], 
reward next is 0.7465, 
noisyNet noise sample is [array([0.94353455], dtype=float32), 0.77864677]. 
=============================================
[2019-04-06 21:34:52,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2867817e-11 2.9456049e-09 1.3465572e-10 7.6234370e-04 1.8519727e-11
 9.9923766e-01 4.2514589e-11], sum to 1.0000
[2019-04-06 21:34:52,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0823
[2019-04-06 21:34:52,619] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.25, 50.0, 0.0, 0.0, 26.0, 25.02255241911284, 0.3822758262256021, 0.0, 1.0, 103801.97707494973], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2579400.0000, 
sim time next is 2581200.0000, 
raw observation next is [-2.8, 56.0, 0.0, 0.0, 26.0, 25.3933005062374, 0.4214490979279441, 0.0, 1.0, 47764.39690949111], 
processed observation next is [1.0, 0.9130434782608695, 0.38504155124653744, 0.56, 0.0, 0.0, 0.6666666666666666, 0.6161083755197833, 0.640483032642648, 0.0, 1.0, 0.2274495090928148], 
reward next is 0.7726, 
noisyNet noise sample is [array([1.5969644], dtype=float32), -1.4600178]. 
=============================================
[2019-04-06 21:35:07,294] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4411801e-12 8.6331969e-11 1.2525812e-11 3.0613868e-05 3.7471901e-12
 9.9996936e-01 1.7289494e-11], sum to 1.0000
[2019-04-06 21:35:07,294] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9899
[2019-04-06 21:35:07,403] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 44.0, 0.0, 0.0, 26.0, 24.92560882941622, 0.1766751921566819, 0.0, 1.0, 38642.046205487524], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2516400.0000, 
sim time next is 2518200.0000, 
raw observation next is [-1.7, 46.5, 0.0, 0.0, 26.0, 25.01493642069213, 0.1894419233600829, 0.0, 1.0, 38514.97022766445], 
processed observation next is [1.0, 0.13043478260869565, 0.4155124653739613, 0.465, 0.0, 0.0, 0.6666666666666666, 0.5845780350576776, 0.5631473077866943, 0.0, 1.0, 0.1834046201317355], 
reward next is 0.8166, 
noisyNet noise sample is [array([-1.1593884], dtype=float32), 2.313006]. 
=============================================
[2019-04-06 21:35:09,260] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:35:09,260] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:35:09,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run33
[2019-04-06 21:35:19,188] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-06 21:35:19,190] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:35:19,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:35:19,201] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:35:19,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:35:19,209] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:35:19,209] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:35:19,216] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run73
[2019-04-06 21:35:19,307] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run73
[2019-04-06 21:35:19,403] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run73
[2019-04-06 21:37:50,022] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 21:38:10,407] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 21:38:12,842] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 21:38:13,865] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1440000, evaluation results [1440000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 21:38:18,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:38:18,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:38:18,654] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run33
[2019-04-06 21:38:21,764] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.5757506e-13 1.1828087e-10 9.3844268e-13 1.2323877e-04 2.9101877e-14
 9.9987674e-01 2.6903571e-12], sum to 1.0000
[2019-04-06 21:38:21,764] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8152
[2019-04-06 21:38:21,808] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.85, 49.5, 203.0, 599.0, 26.0, 26.62712656256016, 0.7941416542527157, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4631400.0000, 
sim time next is 4633200.0000, 
raw observation next is [5.0, 50.0, 199.0, 364.0, 26.0, 27.33526657649114, 0.8744631594101889, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.6011080332409973, 0.5, 0.6633333333333333, 0.4022099447513812, 0.6666666666666666, 0.7779388813742617, 0.7914877198033964, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7706962], dtype=float32), -0.6316706]. 
=============================================
[2019-04-06 21:38:27,291] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.61386352e-12 3.24162319e-09 7.07706463e-12 2.61216977e-04
 1.34051355e-11 9.99738753e-01 2.18455948e-11], sum to 1.0000
[2019-04-06 21:38:27,292] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6166
[2019-04-06 21:38:27,330] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 49.5, 0.0, 0.0, 26.0, 25.23978746383132, 0.5051711521384296, 1.0, 1.0, 86305.26165178094], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3868200.0000, 
sim time next is 3870000.0000, 
raw observation next is [1.0, 51.0, 0.0, 0.0, 26.0, 25.51401788045739, 0.5324925561961621, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.4903047091412743, 0.51, 0.0, 0.0, 0.6666666666666666, 0.6261681567047827, 0.677497518732054, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3948655], dtype=float32), 0.31984124]. 
=============================================
[2019-04-06 21:38:27,337] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[86.35582 ]
 [85.82087 ]
 [86.589325]
 [87.2618  ]
 [88.01173 ]], R is [[86.24432373]
 [85.97090149]
 [86.1111908 ]
 [86.25007629]
 [86.38757324]].
[2019-04-06 21:38:33,673] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:38:33,673] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:38:33,676] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run33
[2019-04-06 21:38:36,071] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9955517e-12 8.0027873e-10 3.6128177e-11 1.3622129e-04 1.5943158e-12
 9.9986374e-01 5.2677368e-12], sum to 1.0000
[2019-04-06 21:38:36,071] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1440
[2019-04-06 21:38:36,113] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 67.0, 0.0, 0.0, 26.0, 24.14697953739614, 0.07460676864728757, 0.0, 1.0, 44698.53475975473], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 262800.0000, 
sim time next is 264600.0000, 
raw observation next is [-7.0, 69.0, 0.0, 0.0, 26.0, 24.01987610252099, 0.04883353517894815, 0.0, 1.0, 45179.74456979325], 
processed observation next is [1.0, 0.043478260869565216, 0.2686980609418283, 0.69, 0.0, 0.0, 0.6666666666666666, 0.5016563418767491, 0.5162778450596494, 0.0, 1.0, 0.2151416408085393], 
reward next is 0.7849, 
noisyNet noise sample is [array([1.13658], dtype=float32), -1.3221791]. 
=============================================
[2019-04-06 21:38:36,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:38:36,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:38:36,534] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run33
[2019-04-06 21:38:36,818] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:38:36,819] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:38:36,868] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run33
[2019-04-06 21:38:42,070] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9267088e-12 4.5164641e-10 3.7517832e-12 2.4516668e-05 1.6438822e-12
 9.9997544e-01 2.4023548e-12], sum to 1.0000
[2019-04-06 21:38:42,070] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4641
[2019-04-06 21:38:42,333] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 26.0, 24.51935932291228, 0.1795225155747696, 0.0, 1.0, 42793.074469794636], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3394800.0000, 
sim time next is 3396600.0000, 
raw observation next is [-2.5, 62.5, 2.0, 107.0, 26.0, 24.92115233006141, 0.3300567186641471, 1.0, 1.0, 81695.80546307703], 
processed observation next is [1.0, 0.30434782608695654, 0.39335180055401664, 0.625, 0.006666666666666667, 0.11823204419889503, 0.6666666666666666, 0.5767626941717842, 0.6100189062213824, 1.0, 1.0, 0.3890276450622716], 
reward next is 0.6110, 
noisyNet noise sample is [array([0.07127965], dtype=float32), -1.1101124]. 
=============================================
[2019-04-06 21:38:44,819] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6728759e-11 1.8391830e-09 2.7470246e-10 4.5203298e-05 4.1626584e-11
 9.9995482e-01 5.9901591e-11], sum to 1.0000
[2019-04-06 21:38:44,820] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9614
[2019-04-06 21:38:44,839] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 45.0, 163.0, 422.0, 26.0, 25.09910532910938, 0.3767747942468467, 0.0, 1.0, 6228.630414011656], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4894200.0000, 
sim time next is 4896000.0000, 
raw observation next is [3.0, 45.0, 132.5, 369.5, 26.0, 25.12849770923782, 0.3746091875699166, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.45, 0.44166666666666665, 0.40828729281767956, 0.6666666666666666, 0.5940414757698184, 0.6248697291899722, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.30201286], dtype=float32), -0.11619672]. 
=============================================
[2019-04-06 21:38:44,850] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[78.70426 ]
 [78.53184 ]
 [78.44718 ]
 [78.340355]
 [78.42378 ]], R is [[78.76272583]
 [78.94543457]
 [79.15598297]
 [79.30509186]
 [79.51203918]].
[2019-04-06 21:38:46,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:38:46,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:38:46,028] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run33
[2019-04-06 21:38:48,083] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.5532308e-13 1.4697742e-10 2.6665566e-12 2.1816702e-05 3.8678083e-13
 9.9997818e-01 3.2382107e-12], sum to 1.0000
[2019-04-06 21:38:48,084] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5737
[2019-04-06 21:38:48,234] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 60.0, 44.5, 264.5, 26.0, 25.68057900825761, 0.3822752058633924, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3398400.0000, 
sim time next is 3400200.0000, 
raw observation next is [-1.5, 60.0, 87.0, 422.0, 26.0, 25.73141218046219, 0.4458879237422879, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4210526315789474, 0.6, 0.29, 0.4662983425414365, 0.6666666666666666, 0.6442843483718491, 0.648629307914096, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5709732], dtype=float32), -0.15751442]. 
=============================================
[2019-04-06 21:38:55,326] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:38:55,326] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:38:55,341] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run33
[2019-04-06 21:38:55,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:38:55,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:38:55,797] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run33
[2019-04-06 21:39:07,847] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6715279e-12 3.8229625e-10 3.8648754e-11 1.0851782e-05 1.8187994e-13
 9.9998915e-01 5.5654071e-12], sum to 1.0000
[2019-04-06 21:39:07,847] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8151
[2019-04-06 21:39:07,897] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.1, 62.0, 112.0, 0.0, 26.0, 25.76909154269032, 0.3420709976176297, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1953000.0000, 
sim time next is 1954800.0000, 
raw observation next is [-2.8, 62.0, 93.0, 0.0, 26.0, 25.7090927140359, 0.3162621520966807, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.38504155124653744, 0.62, 0.31, 0.0, 0.6666666666666666, 0.642424392836325, 0.6054207173655602, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.77340806], dtype=float32), 0.14522497]. 
=============================================
[2019-04-06 21:39:08,700] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.3573171e-13 1.4083502e-10 1.6122200e-13 9.8807541e-06 1.1773160e-13
 9.9999011e-01 2.5972399e-13], sum to 1.0000
[2019-04-06 21:39:08,701] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2252
[2019-04-06 21:39:08,750] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 77.0, 34.0, 307.5, 26.0, 26.52242206879365, 0.7174982546911223, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3258000.0000, 
sim time next is 3259800.0000, 
raw observation next is [-4.0, 71.0, 9.0, 104.0, 26.0, 26.12885382479114, 0.6050779709533128, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3518005540166205, 0.71, 0.03, 0.11491712707182321, 0.6666666666666666, 0.6774044853992617, 0.7016926569844376, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6033476], dtype=float32), 0.6693963]. 
=============================================
[2019-04-06 21:39:18,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:39:18,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:39:18,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run33
[2019-04-06 21:39:28,454] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:39:28,454] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:39:28,474] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run33
[2019-04-06 21:39:42,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8356548e-13 1.0669561e-10 2.6828108e-12 1.5886213e-05 2.9861374e-14
 9.9998415e-01 6.6483050e-13], sum to 1.0000
[2019-04-06 21:39:42,614] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2120
[2019-04-06 21:39:42,668] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.1, 96.0, 0.0, 0.0, 26.0, 25.08153702607306, 0.5646419600068259, 0.0, 1.0, 64781.7609865498], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1281600.0000, 
sim time next is 1283400.0000, 
raw observation next is [5.8, 98.0, 0.0, 0.0, 26.0, 25.40368155782577, 0.6048596937741478, 0.0, 1.0, 35206.287353587046], 
processed observation next is [0.0, 0.8695652173913043, 0.6232686980609419, 0.98, 0.0, 0.0, 0.6666666666666666, 0.6169734631521475, 0.7016198979247159, 0.0, 1.0, 0.16764898739803355], 
reward next is 0.8324, 
noisyNet noise sample is [array([1.0773365], dtype=float32), 1.0180317]. 
=============================================
[2019-04-06 21:39:52,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6398200e-12 5.7933713e-10 4.5914683e-12 3.2530166e-05 1.6332828e-13
 9.9996746e-01 1.2734445e-12], sum to 1.0000
[2019-04-06 21:39:52,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1715
[2019-04-06 21:39:52,405] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 88.5, 85.0, 0.0, 26.0, 26.33581025655494, 0.6245251625602335, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4458600.0000, 
sim time next is 4460400.0000, 
raw observation next is [0.0, 85.0, 78.0, 0.0, 26.0, 24.89114395645289, 0.4994526198808125, 1.0, 1.0, 81807.15375166362], 
processed observation next is [1.0, 0.6521739130434783, 0.46260387811634357, 0.85, 0.26, 0.0, 0.6666666666666666, 0.5742619963710741, 0.6664842066269375, 1.0, 1.0, 0.389557875007922], 
reward next is 0.6104, 
noisyNet noise sample is [array([-0.9042987], dtype=float32), -2.0739195]. 
=============================================
[2019-04-06 21:39:54,600] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.2896677e-12 2.7494079e-10 2.8425314e-11 1.0304276e-04 1.2157466e-11
 9.9989700e-01 3.7584497e-12], sum to 1.0000
[2019-04-06 21:39:54,600] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7929
[2019-04-06 21:39:54,669] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 47.0, 82.5, 372.5, 26.0, 25.94479421960897, 0.4267617651475511, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 745200.0000, 
sim time next is 747000.0000, 
raw observation next is [-0.3, 46.0, 85.0, 31.0, 26.0, 25.36794852157735, 0.3583244765325751, 1.0, 1.0, 39747.17103982676], 
processed observation next is [1.0, 0.6521739130434783, 0.4542936288088643, 0.46, 0.2833333333333333, 0.03425414364640884, 0.6666666666666666, 0.6139957101314458, 0.619441492177525, 1.0, 1.0, 0.1892722430467941], 
reward next is 0.8107, 
noisyNet noise sample is [array([-0.2582681], dtype=float32), 0.00967686]. 
=============================================
[2019-04-06 21:39:54,730] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[84.91606 ]
 [86.18578 ]
 [86.07387 ]
 [86.907845]
 [87.62783 ]], R is [[83.53914642]
 [83.70375824]
 [83.86672211]
 [83.99840546]
 [84.06946564]].
[2019-04-06 21:40:11,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:40:11,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:40:11,436] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run33
[2019-04-06 21:40:18,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:40:18,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:40:18,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run33
[2019-04-06 21:40:42,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:40:42,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:40:42,680] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run33
[2019-04-06 21:40:46,843] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7820603e-13 6.3014954e-11 3.2913990e-13 4.6899808e-05 3.0219826e-13
 9.9995315e-01 3.5252405e-13], sum to 1.0000
[2019-04-06 21:40:46,844] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0629
[2019-04-06 21:40:46,901] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.35, 57.5, 0.0, 0.0, 26.0, 26.8092742177253, 0.7372736782181959, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1618200.0000, 
sim time next is 1620000.0000, 
raw observation next is [10.5, 61.0, 0.0, 0.0, 26.0, 26.5607703335678, 0.7472992262800741, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.7534626038781165, 0.61, 0.0, 0.0, 0.6666666666666666, 0.7133975277973166, 0.7490997420933581, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0095614], dtype=float32), -2.0142622]. 
=============================================
[2019-04-06 21:40:46,926] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[94.48599]
 [95.03793]
 [95.09897]
 [94.86332]
 [94.87441]], R is [[94.25917816]
 [94.31658936]
 [94.37342072]
 [94.4296875 ]
 [94.48538971]].
[2019-04-06 21:40:54,267] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.04604150e-12 4.65397443e-10 1.15872156e-11 1.38046860e-04
 2.13206384e-12 9.99861956e-01 4.68418620e-12], sum to 1.0000
[2019-04-06 21:40:54,268] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4318
[2019-04-06 21:40:54,707] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 21:40:54,713] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:40:54,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:40:54,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run74
[2019-04-06 21:40:54,864] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:40:54,865] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:40:54,869] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run74
[2019-04-06 21:40:54,890] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.7, 61.0, 100.5, 69.0, 26.0, 24.87410653857007, 0.2233091435405483, 0.0, 1.0, 42239.70420311011], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 648000.0000, 
sim time next is 649800.0000, 
raw observation next is [-2.5, 60.0, 112.0, 100.0, 26.0, 24.88906802384508, 0.2267234747259585, 0.0, 1.0, 35546.91937538381], 
processed observation next is [0.0, 0.5217391304347826, 0.39335180055401664, 0.6, 0.37333333333333335, 0.11049723756906077, 0.6666666666666666, 0.57408900198709, 0.5755744915753195, 0.0, 1.0, 0.16927104464468481], 
reward next is 0.8307, 
noisyNet noise sample is [array([-1.7710586], dtype=float32), 1.6806521]. 
=============================================
[2019-04-06 21:40:55,013] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:40:55,029] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:40:55,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run74
[2019-04-06 21:42:51,966] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.06426041], dtype=float32), 0.13597234]
[2019-04-06 21:42:51,967] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [2.1, 69.0, 0.0, 0.0, 26.0, 25.30538619593748, 0.5033305912710677, 0.0, 1.0, 66426.81548350827]
[2019-04-06 21:42:51,967] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 21:42:51,967] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [2.9342761e-12 6.8059619e-10 1.0956420e-11 8.2563100e-05 1.4108703e-12
 9.9991739e-01 7.1388815e-12], sampled 0.8957363609391797
[2019-04-06 21:43:27,109] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 21:43:47,800] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 21:43:49,470] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2891 91944900.5891 409.3749
[2019-04-06 21:43:50,493] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1460000, evaluation results [1460000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.2891096038065, 91944900.58913434, 409.3749352301794]
[2019-04-06 21:43:55,369] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:43:55,369] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:43:55,372] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run33
[2019-04-06 21:43:59,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:43:59,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:43:59,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run33
[2019-04-06 21:44:06,886] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2704507e-12 3.0134013e-09 1.0599411e-11 6.6706052e-06 2.2702276e-12
 9.9999332e-01 2.7035329e-11], sum to 1.0000
[2019-04-06 21:44:06,886] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0107
[2019-04-06 21:44:06,978] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 78.0, 0.0, 0.0, 26.0, 24.11044853521532, -0.009861216624652919, 0.0, 1.0, 44794.929233610914], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1911600.0000, 
sim time next is 1913400.0000, 
raw observation next is [-8.4, 78.0, 0.0, 0.0, 26.0, 23.91090293483037, -0.03593548115421654, 0.0, 1.0, 44739.28715350001], 
processed observation next is [1.0, 0.13043478260869565, 0.2299168975069252, 0.78, 0.0, 0.0, 0.6666666666666666, 0.4925752445691976, 0.4880215062819278, 0.0, 1.0, 0.21304422454047622], 
reward next is 0.7870, 
noisyNet noise sample is [array([0.25897893], dtype=float32), -0.42214945]. 
=============================================
[2019-04-06 21:44:21,555] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.5692755e-12 2.3294173e-09 8.7472607e-12 3.4542689e-05 6.6844850e-12
 9.9996543e-01 2.1330543e-11], sum to 1.0000
[2019-04-06 21:44:21,555] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8393
[2019-04-06 21:44:21,576] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.25, 94.5, 0.0, 0.0, 26.0, 23.74083414730985, 0.1965150701208138, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1225800.0000, 
sim time next is 1227600.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 26.0, 23.66923652001038, 0.1823068762081715, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.8781163434903049, 0.96, 0.0, 0.0, 0.6666666666666666, 0.47243637666753163, 0.5607689587360571, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.28806746], dtype=float32), -0.87280935]. 
=============================================
[2019-04-06 21:44:43,852] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8564711e-12 1.5935301e-09 2.2341448e-11 8.3263702e-05 1.7443723e-12
 9.9991667e-01 2.0885777e-11], sum to 1.0000
[2019-04-06 21:44:43,853] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6727
[2019-04-06 21:44:43,946] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 75.0, 0.0, 0.0, 26.0, 23.89187628988783, 0.02015885790603151, 0.0, 1.0, 41257.748531332414], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 792000.0000, 
sim time next is 793800.0000, 
raw observation next is [-7.3, 73.0, 0.0, 0.0, 26.0, 23.80261139196135, 0.0005210455607558793, 0.0, 1.0, 41418.54176287735], 
processed observation next is [1.0, 0.17391304347826086, 0.26038781163434904, 0.73, 0.0, 0.0, 0.6666666666666666, 0.48355094933011245, 0.5001736818535852, 0.0, 1.0, 0.1972311512517969], 
reward next is 0.8028, 
noisyNet noise sample is [array([2.0427468], dtype=float32), -0.72452426]. 
=============================================
[2019-04-06 21:44:52,127] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1157655e-12 1.0316007e-09 2.7787037e-10 8.4097666e-04 3.5353792e-12
 9.9915898e-01 3.2225028e-11], sum to 1.0000
[2019-04-06 21:44:52,129] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2405
[2019-04-06 21:44:52,341] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.1, 87.0, 66.0, 0.0, 26.0, 25.01621342591279, 0.3453880417691044, 0.0, 1.0, 35252.87759093199], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1783800.0000, 
sim time next is 1785600.0000, 
raw observation next is [-3.4, 87.0, 47.0, 0.0, 26.0, 24.9977679313131, 0.3288521450947206, 0.0, 1.0, 44095.39825530234], 
processed observation next is [0.0, 0.6956521739130435, 0.368421052631579, 0.87, 0.15666666666666668, 0.0, 0.6666666666666666, 0.5831473276094249, 0.6096173816982402, 0.0, 1.0, 0.20997808693001113], 
reward next is 0.7900, 
noisyNet noise sample is [array([-0.03597042], dtype=float32), 0.61988723]. 
=============================================
[2019-04-06 21:44:52,474] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9518316e-14 2.3119664e-11 6.5181633e-13 7.4611991e-05 1.8444084e-13
 9.9992537e-01 2.4306440e-12], sum to 1.0000
[2019-04-06 21:44:52,475] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2588
[2019-04-06 21:44:52,571] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 96.5, 71.0, 54.0, 26.0, 25.15613702378743, 0.4209336089274429, 1.0, 1.0, 65664.76484625133], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2910600.0000, 
sim time next is 2912400.0000, 
raw observation next is [2.0, 93.0, 38.5, 47.5, 26.0, 25.87509786721977, 0.4709980208330315, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.93, 0.12833333333333333, 0.052486187845303865, 0.6666666666666666, 0.6562581556016474, 0.6569993402776771, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4018447], dtype=float32), 0.91757303]. 
=============================================
[2019-04-06 21:44:54,193] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.7066521e-12 8.9391428e-10 7.5243770e-12 1.5427644e-05 7.0724855e-13
 9.9998462e-01 7.0132489e-12], sum to 1.0000
[2019-04-06 21:44:54,193] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1274
[2019-04-06 21:44:54,273] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 83.0, 0.0, 0.0, 26.0, 25.08156396832157, 0.3479049735231395, 0.0, 1.0, 42998.49563446829], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1980000.0000, 
sim time next is 1981800.0000, 
raw observation next is [-5.9, 83.0, 0.0, 0.0, 26.0, 24.92183346597277, 0.2669506350329666, 0.0, 1.0, 43297.89172017094], 
processed observation next is [1.0, 0.9565217391304348, 0.2991689750692521, 0.83, 0.0, 0.0, 0.6666666666666666, 0.576819455497731, 0.5889835450109889, 0.0, 1.0, 0.20618043676271877], 
reward next is 0.7938, 
noisyNet noise sample is [array([-0.2980262], dtype=float32), -0.48032108]. 
=============================================
[2019-04-06 21:44:57,512] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.3139107e-16 6.5412552e-13 1.2111176e-15 2.5983029e-08 2.4334833e-16
 1.0000000e+00 8.7297111e-16], sum to 1.0000
[2019-04-06 21:44:57,512] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6760
[2019-04-06 21:44:57,607] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.2, 86.0, 124.0, 0.0, 26.0, 26.69547821926884, 0.6989155232896372, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 993600.0000, 
sim time next is 995400.0000, 
raw observation next is [12.45, 86.0, 128.0, 0.0, 26.0, 25.73372131643142, 0.5533700844303221, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.8074792243767314, 0.86, 0.4266666666666667, 0.0, 0.6666666666666666, 0.644476776369285, 0.6844566948101073, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.84224933], dtype=float32), -1.3815254]. 
=============================================
[2019-04-06 21:45:16,583] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5783058e-12 1.9095967e-09 1.4530035e-11 3.9788451e-05 3.1002669e-13
 9.9996018e-01 9.7810128e-12], sum to 1.0000
[2019-04-06 21:45:16,583] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9665
[2019-04-06 21:45:16,608] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 45.0, 67.5, 252.0, 26.0, 25.14214810492108, 0.339012537510585, 0.0, 1.0, 6226.803890076847], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4899600.0000, 
sim time next is 4901400.0000, 
raw observation next is [2.5, 44.5, 33.0, 187.0, 26.0, 25.02982166320326, 0.3204341676432377, 0.0, 1.0, 40499.63141744026], 
processed observation next is [0.0, 0.7391304347826086, 0.5318559556786704, 0.445, 0.11, 0.20662983425414364, 0.6666666666666666, 0.5858184719336051, 0.6068113892144126, 0.0, 1.0, 0.19285538770209645], 
reward next is 0.8071, 
noisyNet noise sample is [array([0.43723777], dtype=float32), 0.2405045]. 
=============================================
[2019-04-06 21:45:26,004] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:45:26,004] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:45:26,008] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run34
[2019-04-06 21:45:26,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.46728808e-12 4.34174252e-09 1.51171072e-11 8.43525850e-05
 5.70262067e-12 9.99915600e-01 1.11724545e-11], sum to 1.0000
[2019-04-06 21:45:26,622] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9402
[2019-04-06 21:45:26,790] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 50.0, 110.0, 776.0, 26.0, 25.73191515685676, 0.5234503092038599, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3333600.0000, 
sim time next is 3335400.0000, 
raw observation next is [-3.5, 50.0, 106.0, 752.0, 26.0, 26.09413109133474, 0.6513439148545158, 1.0, 1.0, 88872.41026945184], 
processed observation next is [1.0, 0.6086956521739131, 0.36565096952908593, 0.5, 0.35333333333333333, 0.830939226519337, 0.6666666666666666, 0.6745109242778952, 0.7171146382848387, 1.0, 1.0, 0.4232019536640564], 
reward next is 0.5768, 
noisyNet noise sample is [array([-1.8419892], dtype=float32), -0.14406624]. 
=============================================
[2019-04-06 21:45:33,257] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2631141e-06 2.3715593e-05 2.3250939e-06 3.3977211e-03 2.7233995e-07
 9.9657083e-01 3.0182323e-06], sum to 1.0000
[2019-04-06 21:45:33,259] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0305
[2019-04-06 21:45:33,319] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.2, 96.0, 0.0, 0.0, 22.0, 20.05475781599167, -0.8306253765656183, 0.0, 1.0, 45157.934975250006], 
current ob forecast is [], 
actual action is [23.0], 
sim time this is 5400.0000, 
sim time next is 7200.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 23.0, 20.30782857125094, -0.7885634995344163, 0.0, 1.0, 43894.09716376298], 
processed observation next is [0.0, 0.08695652173913043, 0.662049861495845, 0.96, 0.0, 0.0, 0.4166666666666667, 0.19231904760424504, 0.23714550015519456, 0.0, 1.0, 0.20901951030363322], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8296348], dtype=float32), 1.3431271]. 
=============================================
[2019-04-06 21:45:59,763] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.3589489e-12 4.0459611e-10 2.2115406e-12 2.7077846e-04 7.6961565e-13
 9.9972922e-01 1.1354658e-11], sum to 1.0000
[2019-04-06 21:45:59,763] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3436
[2019-04-06 21:45:59,892] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 48.0, 106.0, 782.0, 26.0, 26.79643322113229, 0.7360210715187326, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3853800.0000, 
sim time next is 3855600.0000, 
raw observation next is [2.0, 48.0, 96.5, 749.5, 26.0, 26.33246451008962, 0.676673421763102, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.518005540166205, 0.48, 0.32166666666666666, 0.8281767955801105, 0.6666666666666666, 0.6943720425074682, 0.7255578072543672, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7929713], dtype=float32), 0.5126363]. 
=============================================
[2019-04-06 21:46:07,410] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8908716e-12 4.6256804e-10 5.8827665e-11 4.8672558e-05 1.2871041e-11
 9.9995136e-01 3.3560110e-12], sum to 1.0000
[2019-04-06 21:46:07,410] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8296
[2019-04-06 21:46:07,528] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 82.0, 0.0, 0.0, 26.0, 24.17710118793788, 0.05934080952268406, 0.0, 1.0, 44982.26308792673], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1900800.0000, 
sim time next is 1902600.0000, 
raw observation next is [-7.3, 78.5, 0.0, 0.0, 26.0, 24.13183527723151, 0.05253248866487997, 0.0, 1.0, 45072.51582671764], 
processed observation next is [1.0, 0.0, 0.26038781163434904, 0.785, 0.0, 0.0, 0.6666666666666666, 0.5109862731026258, 0.51751082955496, 0.0, 1.0, 0.21463102774627446], 
reward next is 0.7854, 
noisyNet noise sample is [array([1.5667583], dtype=float32), 0.3097147]. 
=============================================
[2019-04-06 21:46:35,559] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.2740526e-13 9.6066000e-10 2.3303176e-12 7.0088725e-05 8.7570619e-13
 9.9992990e-01 9.8753579e-13], sum to 1.0000
[2019-04-06 21:46:35,559] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7834
[2019-04-06 21:46:35,664] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 49.0, 75.0, 606.0, 26.0, 26.71713034161822, 0.7399338550254454, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3513600.0000, 
sim time next is 3515400.0000, 
raw observation next is [3.0, 49.0, 62.0, 525.0, 26.0, 26.89027819779753, 0.7398298563500666, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.49, 0.20666666666666667, 0.580110497237569, 0.6666666666666666, 0.7408565164831277, 0.7466099521166889, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7177939], dtype=float32), -0.29600176]. 
=============================================
[2019-04-06 21:46:38,443] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 21:46:38,445] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:46:38,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:46:38,449] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:46:38,449] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:46:38,453] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run75
[2019-04-06 21:46:38,511] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run75
[2019-04-06 21:46:38,578] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:46:38,579] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:46:38,583] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run75
[2019-04-06 21:49:07,209] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.06390225], dtype=float32), 0.13600904]
[2019-04-06 21:49:07,209] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-3.496592362, 38.88620915, 0.0, 0.0, 26.0, 25.09066055251429, 0.3479091149954876, 0.0, 1.0, 50735.19322757242]
[2019-04-06 21:49:07,209] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 21:49:07,210] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.3915337e-11 4.7775672e-09 1.0879320e-10 1.2222657e-04 1.5388217e-11
 9.9987781e-01 6.5230578e-11], sampled 0.3034861496235286
[2019-04-06 21:49:07,851] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 21:49:21,936] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.06390225], dtype=float32), 0.13600904]
[2019-04-06 21:49:21,936] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.0, 77.0, 0.0, 0.0, 26.0, 25.57391221904671, 0.4455285577842235, 0.0, 1.0, 24192.236226078094]
[2019-04-06 21:49:21,936] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 21:49:21,937] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.2941696e-12 3.5756589e-10 5.7851059e-12 2.4949475e-05 5.3826702e-13
 9.9997509e-01 3.3945891e-12], sampled 0.6800063827451475
[2019-04-06 21:49:28,886] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 21:49:31,256] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 21:49:32,279] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 1480000, evaluation results [1480000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 21:49:39,894] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.47478533e-14 3.76621789e-11 4.07448597e-13 1.49529205e-05
 3.86004095e-15 9.99985099e-01 2.56732451e-14], sum to 1.0000
[2019-04-06 21:49:39,894] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6751
[2019-04-06 21:49:39,973] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 92.0, 161.5, 3.0, 26.0, 26.44168955088109, 0.5779535498566761, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4701600.0000, 
sim time next is 4703400.0000, 
raw observation next is [0.0, 92.0, 208.0, 6.0, 26.0, 26.44882807218339, 0.5934658210484952, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.46260387811634357, 0.92, 0.6933333333333334, 0.0066298342541436465, 0.6666666666666666, 0.7040690060152824, 0.6978219403494984, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.938632], dtype=float32), 0.18036097]. 
=============================================
[2019-04-06 21:49:40,643] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.2762560e-12 1.8622691e-10 8.3169582e-12 1.0135393e-05 4.5991596e-13
 9.9998987e-01 5.3022326e-12], sum to 1.0000
[2019-04-06 21:49:40,644] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6666
[2019-04-06 21:49:40,837] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 71.0, 132.0, 0.0, 26.0, 25.54531509636557, 0.4550608018652007, 1.0, 1.0, 110099.66685680098], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2210400.0000, 
sim time next is 2212200.0000, 
raw observation next is [-3.9, 69.5, 120.0, 0.0, 26.0, 26.36564049824187, 0.5083436515563778, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3545706371191136, 0.695, 0.4, 0.0, 0.6666666666666666, 0.6971367081868225, 0.669447883852126, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3654479], dtype=float32), 0.5284161]. 
=============================================
[2019-04-06 21:49:52,796] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0009071e-13 3.2293817e-11 3.2436339e-12 2.5006811e-05 2.7259526e-13
 9.9997497e-01 1.6958194e-14], sum to 1.0000
[2019-04-06 21:49:52,797] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2200
[2019-04-06 21:49:52,864] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 67.0, 0.0, 0.0, 26.0, 25.76483862792483, 0.5697619405525236, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4417200.0000, 
sim time next is 4419000.0000, 
raw observation next is [4.75, 67.0, 0.0, 0.0, 26.0, 25.61884752016483, 0.5637210744817588, 0.0, 1.0, 50702.00620112566], 
processed observation next is [1.0, 0.13043478260869565, 0.5941828254847646, 0.67, 0.0, 0.0, 0.6666666666666666, 0.634903960013736, 0.6879070248272529, 0.0, 1.0, 0.24143812476726503], 
reward next is 0.7586, 
noisyNet noise sample is [array([0.31623262], dtype=float32), -1.9269549]. 
=============================================
[2019-04-06 21:49:52,881] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[94.95022]
 [95.34156]
 [94.96585]
 [95.35062]
 [95.8494 ]], R is [[94.72583771]
 [94.77857971]
 [94.35305023]
 [94.40952301]
 [94.46543121]].
[2019-04-06 21:49:54,211] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2142427e-11 1.0969108e-09 3.7405529e-10 1.9176168e-05 3.1314740e-12
 9.9998081e-01 2.1180301e-11], sum to 1.0000
[2019-04-06 21:49:54,211] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2932
[2019-04-06 21:49:54,377] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 79.0, 42.0, 4.0, 26.0, 25.35074890440337, 0.2980758577835568, 1.0, 1.0, 29366.362036469334], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2620800.0000, 
sim time next is 2622600.0000, 
raw observation next is [-7.0, 77.0, 77.0, 0.0, 26.0, 25.4985246217401, 0.3346379919225965, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.2686980609418283, 0.77, 0.25666666666666665, 0.0, 0.6666666666666666, 0.624877051811675, 0.6115459973075322, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.35739896], dtype=float32), -0.67811644]. 
=============================================
[2019-04-06 21:49:59,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:49:59,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:49:59,788] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run34
[2019-04-06 21:50:11,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:50:11,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:50:11,020] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run34
[2019-04-06 21:50:17,784] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3330944e-11 1.1383405e-09 5.2652448e-11 3.7712077e-04 1.3490631e-11
 9.9962282e-01 2.3693283e-11], sum to 1.0000
[2019-04-06 21:50:17,785] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1162
[2019-04-06 21:50:17,849] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8, 73.0, 0.0, 0.0, 26.0, 25.34282034210368, 0.4345295781087136, 0.0, 1.0, 43572.160314045475], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4501800.0000, 
sim time next is 4503600.0000, 
raw observation next is [-1.0, 73.0, 0.0, 0.0, 26.0, 25.40540176578923, 0.4516224430327641, 0.0, 1.0, 36461.45597410513], 
processed observation next is [1.0, 0.13043478260869565, 0.4349030470914128, 0.73, 0.0, 0.0, 0.6666666666666666, 0.6171168138157691, 0.6505408143442547, 0.0, 1.0, 0.17362598082907205], 
reward next is 0.8264, 
noisyNet noise sample is [array([-0.98226845], dtype=float32), 0.83628535]. 
=============================================
[2019-04-06 21:50:19,500] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.8189391e-12 8.9261126e-10 3.7951530e-12 1.0078471e-04 2.4052615e-12
 9.9989915e-01 2.2564075e-12], sum to 1.0000
[2019-04-06 21:50:19,500] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9917
[2019-04-06 21:50:19,569] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 26.0, 21.19154630656796, -0.5838038839159895, 0.0, 1.0, 40385.629733236674], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 21600.0000, 
sim time next is 23400.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 26.0, 21.2560216395749, -0.5648554714690567, 0.0, 1.0, 40309.10375636767], 
processed observation next is [0.0, 0.2608695652173913, 0.6759002770083103, 0.93, 0.0, 0.0, 0.6666666666666666, 0.2713351366312417, 0.31171484284364775, 0.0, 1.0, 0.19194811312556034], 
reward next is 0.8081, 
noisyNet noise sample is [array([-0.07937462], dtype=float32), 0.2633707]. 
=============================================
[2019-04-06 21:50:26,427] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.4641126e-13 1.6580226e-10 5.3017421e-12 1.8693005e-05 6.0357513e-13
 9.9998128e-01 1.5210707e-12], sum to 1.0000
[2019-04-06 21:50:26,428] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4400
[2019-04-06 21:50:26,459] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 36.0, 88.0, 724.0, 26.0, 25.77456237295675, 0.6292773823743659, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3943800.0000, 
sim time next is 3945600.0000, 
raw observation next is [-4.0, 34.0, 77.0, 630.0, 26.0, 26.56774891981971, 0.7287877914386304, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.3518005540166205, 0.34, 0.25666666666666665, 0.6961325966850829, 0.6666666666666666, 0.7139790766516425, 0.7429292638128767, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.4347856], dtype=float32), 0.043170005]. 
=============================================
[2019-04-06 21:50:26,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:50:26,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:50:26,844] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run34
[2019-04-06 21:50:27,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:50:27,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:50:27,408] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run34
[2019-04-06 21:50:27,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:50:27,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:50:27,438] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run34
[2019-04-06 21:50:28,184] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3807299e-13 1.0975019e-10 4.3261670e-13 2.6247708e-06 1.4174942e-13
 9.9999738e-01 2.2305471e-12], sum to 1.0000
[2019-04-06 21:50:28,184] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1841
[2019-04-06 21:50:28,328] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.1, 73.5, 184.0, 13.0, 26.0, 25.40651119557062, 0.3215370130039465, 1.0, 1.0, 45312.73496230261], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 127800.0000, 
sim time next is 129600.0000, 
raw observation next is [-8.4, 61.0, 157.0, 308.0, 26.0, 25.56785283841909, 0.3903668561274127, 1.0, 1.0, 47231.11811844541], 
processed observation next is [1.0, 0.5217391304347826, 0.2299168975069252, 0.61, 0.5233333333333333, 0.34033149171270716, 0.6666666666666666, 0.6306544032015907, 0.6301222853758043, 1.0, 1.0, 0.22491008627831147], 
reward next is 0.7751, 
noisyNet noise sample is [array([0.14191562], dtype=float32), -1.4927442]. 
=============================================
[2019-04-06 21:50:33,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:50:33,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:50:33,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run34
[2019-04-06 21:50:42,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:50:42,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:50:42,596] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run34
[2019-04-06 21:50:47,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:50:47,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:50:47,872] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run34
[2019-04-06 21:50:59,104] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9434190e-13 3.0396959e-11 1.2051329e-12 3.0473735e-05 1.6526450e-14
 9.9996948e-01 7.2340219e-13], sum to 1.0000
[2019-04-06 21:50:59,104] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5505
[2019-04-06 21:50:59,138] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 93.0, 0.0, 0.0, 26.0, 25.54785934847195, 0.5944918580184151, 0.0, 1.0, 19215.474752077364], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3196800.0000, 
sim time next is 3198600.0000, 
raw observation next is [1.5, 96.5, 0.0, 0.0, 26.0, 25.45468231894926, 0.5992649334300142, 0.0, 1.0, 58347.3309579111], 
processed observation next is [1.0, 0.0, 0.5041551246537397, 0.965, 0.0, 0.0, 0.6666666666666666, 0.621223526579105, 0.6997549778100046, 0.0, 1.0, 0.27784443313291], 
reward next is 0.7222, 
noisyNet noise sample is [array([-0.38414317], dtype=float32), -0.19720367]. 
=============================================
[2019-04-06 21:51:04,328] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7757773e-12 2.0189184e-10 1.2812371e-12 5.0687140e-05 7.8450376e-13
 9.9994934e-01 4.5397644e-12], sum to 1.0000
[2019-04-06 21:51:04,328] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6636
[2019-04-06 21:51:04,442] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 66.0, 0.0, 0.0, 26.0, 25.221606514845, 0.4759455774062478, 0.0, 1.0, 94121.34309012548], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3538800.0000, 
sim time next is 3540600.0000, 
raw observation next is [-1.5, 63.0, 0.0, 0.0, 26.0, 25.37034572430062, 0.479889004063579, 0.0, 1.0, 45160.55619928205], 
processed observation next is [1.0, 1.0, 0.4210526315789474, 0.63, 0.0, 0.0, 0.6666666666666666, 0.6141954770250516, 0.6599630013545263, 0.0, 1.0, 0.21505026761562882], 
reward next is 0.7849, 
noisyNet noise sample is [array([0.34819287], dtype=float32), 1.6438189]. 
=============================================
[2019-04-06 21:51:08,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:51:08,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:51:08,440] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run34
[2019-04-06 21:51:27,846] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:51:27,846] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:51:27,850] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run34
[2019-04-06 21:51:37,391] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5381129e-12 3.4752731e-10 2.0873017e-12 3.5806770e-06 5.4084953e-12
 9.9999642e-01 1.6513750e-11], sum to 1.0000
[2019-04-06 21:51:37,391] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8468
[2019-04-06 21:51:37,422] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.0, 100.0, 51.0, 0.0, 26.0, 23.34116609234635, 0.1239459618798282, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1242000.0000, 
sim time next is 1243800.0000, 
raw observation next is [15.0, 100.0, 74.0, 0.0, 26.0, 23.31882763492509, 0.1235864860374796, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.8781163434903049, 1.0, 0.24666666666666667, 0.0, 0.6666666666666666, 0.44323563624375745, 0.5411954953458266, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5013852], dtype=float32), -0.80776393]. 
=============================================
[2019-04-06 21:52:10,984] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-06 21:52:11,003] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:52:11,003] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:52:11,007] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run76
[2019-04-06 21:52:11,111] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:52:11,111] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:52:11,165] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run76
[2019-04-06 21:52:11,249] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:52:11,251] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:52:11,255] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run76
[2019-04-06 21:54:34,900] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.0646076], dtype=float32), 0.13676544]
[2019-04-06 21:54:34,900] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.0, 79.0, 0.0, 0.0, 26.0, 25.29219264707039, 0.4613757179535203, 1.0, 1.0, 36950.94601355676]
[2019-04-06 21:54:34,900] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 21:54:34,901] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.0252752e-12 3.9246301e-10 3.8218768e-12 3.4302066e-05 7.8469165e-13
 9.9996567e-01 3.4273725e-12], sampled 0.4479394669190506
[2019-04-06 21:54:42,620] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 21:55:01,691] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 21:55:05,123] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 21:55:06,146] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1500000, evaluation results [1500000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 21:55:09,711] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8052428e-14 1.1818638e-11 7.8381109e-14 1.5934371e-05 3.7588737e-14
 9.9998403e-01 6.8878323e-13], sum to 1.0000
[2019-04-06 21:55:09,711] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5444
[2019-04-06 21:55:09,725] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 26.0, 25.77511016562056, 0.5307559688764998, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1017000.0000, 
sim time next is 1018800.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 26.0, 25.58534340089899, 0.517725399667309, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.8614958448753465, 0.81, 0.0, 0.0, 0.6666666666666666, 0.6321119500749157, 0.6725751332224363, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7546269], dtype=float32), 0.6329973]. 
=============================================
[2019-04-06 21:55:17,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:55:17,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:55:17,179] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run34
[2019-04-06 21:55:17,386] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:55:17,386] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:55:17,401] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run34
[2019-04-06 21:55:18,718] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6410960e-13 8.4983735e-11 3.4413555e-12 3.5054862e-05 1.8457133e-13
 9.9996495e-01 3.7270921e-13], sum to 1.0000
[2019-04-06 21:55:18,721] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2303
[2019-04-06 21:55:18,828] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 66.5, 123.0, 0.0, 26.0, 26.17326920002619, 0.5178762509144318, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4527000.0000, 
sim time next is 4528800.0000, 
raw observation next is [1.0, 61.0, 172.0, 9.0, 26.0, 26.17010211475501, 0.5343850763934475, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4903047091412743, 0.61, 0.5733333333333334, 0.009944751381215469, 0.6666666666666666, 0.6808418428962509, 0.6781283587978159, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0288285], dtype=float32), -0.45922437]. 
=============================================
[2019-04-06 21:55:36,040] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:55:36,040] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:55:36,044] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run34
[2019-04-06 21:55:41,236] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:55:41,236] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:55:41,240] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run34
[2019-04-06 21:55:47,932] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:55:47,933] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:55:47,952] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run34
[2019-04-06 21:56:08,791] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1253932e-13 4.6612053e-10 1.0281746e-12 2.7514821e-05 4.7453261e-12
 9.9997246e-01 6.0559040e-12], sum to 1.0000
[2019-04-06 21:56:08,791] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3606
[2019-04-06 21:56:08,821] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.0, 25.0, 0.0, 0.0, 26.0, 25.50096898393072, 0.3653003893070663, 0.0, 1.0, 33542.410198824946], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3650400.0000, 
sim time next is 3652200.0000, 
raw observation next is [9.5, 26.0, 0.0, 0.0, 26.0, 25.53565063936897, 0.3563556104312817, 0.0, 1.0, 19293.637590725204], 
processed observation next is [0.0, 0.2608695652173913, 0.7257617728531857, 0.26, 0.0, 0.0, 0.6666666666666666, 0.6279708866140808, 0.6187852034770939, 0.0, 1.0, 0.09187446471773907], 
reward next is 0.9081, 
noisyNet noise sample is [array([1.331491], dtype=float32), -0.94747674]. 
=============================================
[2019-04-06 21:56:41,510] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.3019806e-13 7.3773834e-11 2.8387011e-11 1.2959573e-04 8.9241402e-13
 9.9987042e-01 3.7129206e-12], sum to 1.0000
[2019-04-06 21:56:41,510] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4323
[2019-04-06 21:56:41,588] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.55, 75.5, 0.0, 0.0, 26.0, 24.29817265365511, 0.04525494709548333, 0.0, 1.0, 41596.09189636632], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 707400.0000, 
sim time next is 709200.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 26.0, 24.26798432594072, 0.03811557802216782, 0.0, 1.0, 41564.64585720482], 
processed observation next is [1.0, 0.21739130434782608, 0.3988919667590028, 0.76, 0.0, 0.0, 0.6666666666666666, 0.5223320271617267, 0.5127051926740559, 0.0, 1.0, 0.19792688503430866], 
reward next is 0.8021, 
noisyNet noise sample is [array([-0.35951987], dtype=float32), 1.1593108]. 
=============================================
[2019-04-06 21:56:54,820] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.32552311e-11 1.31864963e-10 1.87064253e-11 1.04788305e-04
 2.24953172e-12 9.99895215e-01 7.32782307e-11], sum to 1.0000
[2019-04-06 21:56:54,821] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7032
[2019-04-06 21:56:54,910] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.95, 87.0, 0.0, 0.0, 26.0, 23.69552951627524, 0.02579448696248194, 0.0, 1.0, 44521.73758479202], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2691000.0000, 
sim time next is 2692800.0000, 
raw observation next is [-15.0, 91.0, 0.0, 0.0, 26.0, 23.51180627460512, -0.01140833228865865, 0.0, 1.0, 44516.210506272175], 
processed observation next is [1.0, 0.17391304347826086, 0.04709141274238226, 0.91, 0.0, 0.0, 0.6666666666666666, 0.4593171895504267, 0.4961972225704471, 0.0, 1.0, 0.21198195479177226], 
reward next is 0.7880, 
noisyNet noise sample is [array([0.28029904], dtype=float32), 0.14025596]. 
=============================================
[2019-04-06 21:57:29,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:57:29,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:57:29,424] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run35
[2019-04-06 21:57:30,435] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7255536e-11 3.1290228e-09 8.5732976e-11 1.7909344e-05 1.5873379e-11
 9.9998212e-01 1.5659182e-11], sum to 1.0000
[2019-04-06 21:57:30,435] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9587
[2019-04-06 21:57:30,536] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 42.0, 0.0, 0.0, 26.0, 25.10599215965886, 0.2782895728653361, 0.0, 1.0, 43142.207474303556], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2408400.0000, 
sim time next is 2410200.0000, 
raw observation next is [-3.95, 43.0, 0.0, 0.0, 26.0, 25.08302442326526, 0.2547449836129242, 0.0, 1.0, 43039.23730896957], 
processed observation next is [0.0, 0.9130434782608695, 0.3531855955678671, 0.43, 0.0, 0.0, 0.6666666666666666, 0.5902520352721051, 0.5849149945376414, 0.0, 1.0, 0.20494874909033128], 
reward next is 0.7951, 
noisyNet noise sample is [array([0.5488674], dtype=float32), 1.1186334]. 
=============================================
[2019-04-06 21:57:42,550] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.6023052e-13 1.2429888e-10 1.8377455e-12 5.4273769e-06 1.5776182e-14
 9.9999452e-01 1.3928442e-13], sum to 1.0000
[2019-04-06 21:57:42,550] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2349
[2019-04-06 21:57:42,889] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.0, 100.0, 42.0, 237.0, 26.0, 25.37600581538433, 0.3723072969966096, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3139200.0000, 
sim time next is 3141000.0000, 
raw observation next is [6.5, 100.0, 83.0, 392.0, 26.0, 25.77333774796746, 0.4478601126609875, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.6426592797783934, 1.0, 0.27666666666666667, 0.4331491712707182, 0.6666666666666666, 0.647778145663955, 0.6492867042203292, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8736842], dtype=float32), -0.3696288]. 
=============================================
[2019-04-06 21:57:42,893] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[96.78721 ]
 [95.951385]
 [94.91926 ]
 [94.5683  ]
 [94.147514]], R is [[97.44160461]
 [97.46718597]
 [97.46273804]
 [97.2684021 ]
 [97.00899506]].
[2019-04-06 21:57:45,819] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-06 21:57:45,825] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:57:45,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:57:45,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run77
[2019-04-06 21:57:45,953] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:57:45,953] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:57:45,964] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run77
[2019-04-06 21:57:46,090] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:57:46,090] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:57:46,111] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run77
[2019-04-06 21:58:06,070] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.06497949], dtype=float32), 0.1364491]
[2019-04-06 21:58:06,070] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [7.2, 91.5, 134.0, 15.0, 26.0, 25.20442088411195, 0.4068892530027115, 1.0, 1.0, 11590.690436021368]
[2019-04-06 21:58:06,070] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 21:58:06,071] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.44407937e-13 5.15835014e-11 5.13935194e-13 1.02290005e-05
 8.55278711e-14 9.99989748e-01 4.04444734e-13], sampled 0.4864334000271736
[2019-04-06 21:58:58,093] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.06497949], dtype=float32), 0.1364491]
[2019-04-06 21:58:58,093] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [5.5, 89.0, 0.0, 0.0, 26.0, 25.30799646871146, 0.425069209294445, 0.0, 1.0, 38035.04296869299]
[2019-04-06 21:58:58,093] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 21:58:58,094] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.4680089e-13 4.5371512e-11 6.3717673e-13 1.0859007e-05 6.0361757e-14
 9.9998915e-01 2.7788554e-13], sampled 0.8634753482753634
[2019-04-06 21:58:59,802] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.06497949], dtype=float32), 0.1364491]
[2019-04-06 21:58:59,802] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [15.5, 78.0, 12.5, 0.0, 26.0, 26.79162215033247, 0.719683682149263, 1.0, 1.0, 0.0]
[2019-04-06 21:58:59,802] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 21:58:59,803] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.0812287e-14 1.5039581e-11 9.3460836e-14 5.6155482e-06 1.4440082e-14
 9.9999440e-01 7.7134351e-14], sampled 0.8563641213812735
[2019-04-06 22:00:23,294] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3885 79967197.3248 535.2671
[2019-04-06 22:00:43,141] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 22:00:43,494] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.06497949], dtype=float32), 0.1364491]
[2019-04-06 22:00:43,494] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [0.6801866025000001, 41.529750595, 0.0, 0.0, 26.0, 25.27453775683799, 0.3195320764098962, 0.0, 1.0, 38030.07047356278]
[2019-04-06 22:00:43,494] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 22:00:43,495] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [9.9947229e-12 1.3363262e-09 3.7406883e-11 4.5468449e-05 3.9862792e-12
 9.9995458e-01 1.8855051e-11], sampled 0.5208228232719962
[2019-04-06 22:00:45,761] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 22:00:46,784] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1520000, evaluation results [1520000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.388471443006, 79967197.3248232, 535.2671102210136, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 22:00:55,833] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0982116e-13 2.5126788e-11 7.3094256e-12 6.8694990e-06 9.1040825e-13
 9.9999309e-01 1.4674079e-12], sum to 1.0000
[2019-04-06 22:00:55,834] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8400
[2019-04-06 22:00:55,883] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.83980017497565, 0.2829908416082521, 0.0, 1.0, 41105.75955119613], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3380400.0000, 
sim time next is 3382200.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.82780688839461, 0.2769813545067847, 0.0, 1.0, 41117.316258929466], 
processed observation next is [1.0, 0.13043478260869565, 0.296398891966759, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5689839073662174, 0.5923271181689282, 0.0, 1.0, 0.1957967440901403], 
reward next is 0.8042, 
noisyNet noise sample is [array([-0.8670401], dtype=float32), -0.21642585]. 
=============================================
[2019-04-06 22:01:13,766] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.1180462e-12 2.0471466e-10 6.5398511e-12 2.0610405e-05 1.7884893e-12
 9.9997938e-01 2.2245036e-12], sum to 1.0000
[2019-04-06 22:01:13,766] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4940
[2019-04-06 22:01:13,825] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.0, 25.0, 0.0, 0.0, 26.0, 25.50072199853667, 0.3652458460007495, 0.0, 1.0, 33559.577025847546], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3650400.0000, 
sim time next is 3652200.0000, 
raw observation next is [9.5, 26.0, 0.0, 0.0, 26.0, 25.53543705495913, 0.3563058318525052, 0.0, 1.0, 19293.450229001653], 
processed observation next is [0.0, 0.2608695652173913, 0.7257617728531857, 0.26, 0.0, 0.0, 0.6666666666666666, 0.6279530879132608, 0.6187686106175018, 0.0, 1.0, 0.0918735725190555], 
reward next is 0.9081, 
noisyNet noise sample is [array([-0.417095], dtype=float32), 0.2619763]. 
=============================================
[2019-04-06 22:01:29,305] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7316841e-10 2.4092206e-08 3.7171988e-10 4.3415115e-04 1.7432897e-10
 9.9956578e-01 8.8993579e-10], sum to 1.0000
[2019-04-06 22:01:29,306] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3840
[2019-04-06 22:01:29,382] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 53.0, 0.0, 0.0, 26.0, 24.13099443282784, 0.04506271701049594, 0.0, 1.0, 43524.008831276326], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2426400.0000, 
sim time next is 2428200.0000, 
raw observation next is [-7.55, 54.0, 0.0, 0.0, 26.0, 23.99200686395871, 0.01791843073349337, 0.0, 1.0, 43608.52043148115], 
processed observation next is [0.0, 0.08695652173913043, 0.25346260387811637, 0.54, 0.0, 0.0, 0.6666666666666666, 0.4993339053298926, 0.5059728102444978, 0.0, 1.0, 0.2076596211022912], 
reward next is 0.7923, 
noisyNet noise sample is [array([-0.40461564], dtype=float32), 1.69348]. 
=============================================
[2019-04-06 22:01:42,444] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3738485e-13 5.2157184e-10 4.0870879e-12 9.1542955e-05 2.8339806e-13
 9.9990845e-01 2.4422532e-12], sum to 1.0000
[2019-04-06 22:01:42,444] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0021
[2019-04-06 22:01:42,664] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 75.0, 71.5, 356.5, 26.0, 25.96182469659184, 0.4075528619308668, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2192400.0000, 
sim time next is 2194200.0000, 
raw observation next is [-5.3, 73.0, 102.0, 451.0, 26.0, 25.98027473593717, 0.4309751181240196, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.31578947368421056, 0.73, 0.34, 0.4983425414364641, 0.6666666666666666, 0.6650228946614307, 0.6436583727080065, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5851221], dtype=float32), -0.5725698]. 
=============================================
[2019-04-06 22:01:44,956] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:01:44,956] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:01:44,960] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run35
[2019-04-06 22:02:02,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:02:02,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:02:02,624] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run35
[2019-04-06 22:02:10,670] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6740234e-11 1.5352783e-09 1.6741830e-11 1.7510238e-05 1.5872681e-12
 9.9998248e-01 7.9079680e-11], sum to 1.0000
[2019-04-06 22:02:10,670] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9509
[2019-04-06 22:02:10,837] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 48.0, 0.0, 0.0, 26.0, 25.15199767005338, 0.2658006222564356, 1.0, 1.0, 16391.110731137156], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4951800.0000, 
sim time next is 4953600.0000, 
raw observation next is [-2.0, 46.0, 46.5, 280.0, 26.0, 25.23332052511947, 0.2762042409162856, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.40720221606648205, 0.46, 0.155, 0.30939226519337015, 0.6666666666666666, 0.6027767104266225, 0.5920680803054285, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24449958], dtype=float32), 0.36127514]. 
=============================================
[2019-04-06 22:02:13,530] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4279973e-12 3.5611458e-10 3.9180059e-11 1.1128573e-04 8.0983417e-14
 9.9988866e-01 8.4583616e-12], sum to 1.0000
[2019-04-06 22:02:13,531] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8502
[2019-04-06 22:02:13,573] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.58969351040121, 0.5529030067622883, 0.0, 1.0, 36675.024935110596], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3790800.0000, 
sim time next is 3792600.0000, 
raw observation next is [-3.0, 74.0, 0.0, 0.0, 26.0, 25.60529104457443, 0.5238181528440676, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.3795013850415513, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6337742537145358, 0.6746060509480225, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3196828], dtype=float32), -1.0885322]. 
=============================================
[2019-04-06 22:02:15,341] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:02:15,341] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:02:15,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run35
[2019-04-06 22:02:17,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:02:17,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:02:17,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run35
[2019-04-06 22:02:21,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:02:21,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:02:21,577] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run35
[2019-04-06 22:02:24,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:02:24,630] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:02:24,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run35
[2019-04-06 22:02:35,660] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:02:35,660] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:02:35,664] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run35
[2019-04-06 22:02:39,859] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:02:39,859] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:02:39,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run35
[2019-04-06 22:02:47,496] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.6634509e-11 7.1704759e-10 1.3455737e-11 1.6712811e-04 2.4920539e-12
 9.9983287e-01 4.7466212e-11], sum to 1.0000
[2019-04-06 22:02:47,496] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2747
[2019-04-06 22:02:47,849] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 64.0, 44.0, 24.0, 26.0, 25.84766552667926, 0.4427423820368651, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 144000.0000, 
sim time next is 145800.0000, 
raw observation next is [-7.0, 67.5, 27.0, 3.0, 26.0, 25.96839817240937, 0.2765346663098698, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.2686980609418283, 0.675, 0.09, 0.0033149171270718232, 0.6666666666666666, 0.6640331810341141, 0.59217822210329, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.795354], dtype=float32), -2.5198562]. 
=============================================
[2019-04-06 22:03:08,268] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:03:08,268] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:03:08,272] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run35
[2019-04-06 22:03:15,302] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 22:03:15,305] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:03:15,306] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:03:15,311] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:03:15,311] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:03:15,327] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run78
[2019-04-06 22:03:15,409] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:03:15,410] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:03:15,414] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run78
[2019-04-06 22:03:15,636] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run78
[2019-04-06 22:05:54,842] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 22:06:13,783] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.9138 87799002.1168 515.3043
[2019-04-06 22:06:16,946] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 22:06:17,969] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 1540000, evaluation results [1540000.0, 2415.913755201966, 87799002.11678837, 515.3042642146117, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 22:06:32,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:06:32,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:06:32,113] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run35
[2019-04-06 22:07:05,539] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:07:05,539] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:07:05,543] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run35
[2019-04-06 22:07:06,923] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:07:06,923] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:07:06,948] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run35
[2019-04-06 22:07:07,342] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.8786733e-13 2.0191114e-10 9.8211851e-14 3.1396161e-05 2.9189609e-14
 9.9996865e-01 7.2435975e-13], sum to 1.0000
[2019-04-06 22:07:07,342] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3282
[2019-04-06 22:07:07,360] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.5, 76.5, 25.0, 0.0, 26.0, 25.94885173989908, 0.6332677426625071, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1009800.0000, 
sim time next is 1011600.0000, 
raw observation next is [15.5, 78.0, 12.5, 0.0, 26.0, 26.79162215033247, 0.719683682149263, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.8919667590027703, 0.78, 0.041666666666666664, 0.0, 0.6666666666666666, 0.7326351791943724, 0.739894560716421, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.96608096], dtype=float32), 0.9247745]. 
=============================================
[2019-04-06 22:07:16,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:07:16,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:07:16,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run35
[2019-04-06 22:07:30,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:07:30,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:07:30,260] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run35
[2019-04-06 22:07:37,009] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:07:37,009] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:07:37,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run35
[2019-04-06 22:07:45,874] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1788270e-12 8.8139052e-10 2.3051141e-11 4.4671433e-06 1.5895794e-12
 9.9999559e-01 1.0011560e-11], sum to 1.0000
[2019-04-06 22:07:45,875] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0536
[2019-04-06 22:07:45,931] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 46.0, 73.5, 587.5, 26.0, 26.04204494118304, 0.6483160012345127, 1.0, 1.0, 20792.676881680447], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3340800.0000, 
sim time next is 3342600.0000, 
raw observation next is [-2.0, 48.0, 60.0, 501.0, 26.0, 26.65521768856553, 0.6754748042776946, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.40720221606648205, 0.48, 0.2, 0.5535911602209945, 0.6666666666666666, 0.7212681407137941, 0.7251582680925649, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.272648], dtype=float32), -2.106896]. 
=============================================
[2019-04-06 22:07:48,649] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.6976132e-13 1.3536597e-10 1.7980948e-11 1.4431694e-06 7.5495632e-13
 9.9999857e-01 1.2678903e-12], sum to 1.0000
[2019-04-06 22:07:48,649] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8231
[2019-04-06 22:07:48,734] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 83.0, 0.0, 0.0, 26.0, 23.85987545821026, 0.04062691469476109, 0.0, 1.0, 46881.314486982556], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1828800.0000, 
sim time next is 1830600.0000, 
raw observation next is [-6.2, 81.0, 0.0, 0.0, 26.0, 23.78586040340056, 0.01795251803094739, 0.0, 1.0, 46930.94638641528], 
processed observation next is [0.0, 0.17391304347826086, 0.2908587257617729, 0.81, 0.0, 0.0, 0.6666666666666666, 0.48215503361671325, 0.5059841726769825, 0.0, 1.0, 0.223480697078168], 
reward next is 0.7765, 
noisyNet noise sample is [array([-0.18949048], dtype=float32), -1.9223386]. 
=============================================
[2019-04-06 22:08:58,148] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0940466e-14 3.7850011e-11 4.5718146e-14 5.6442092e-05 2.9256321e-14
 9.9994361e-01 9.8659985e-14], sum to 1.0000
[2019-04-06 22:08:58,148] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7099
[2019-04-06 22:08:58,200] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 57.5, 0.0, 26.0, 25.73547809042233, 0.5133929548395977, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1350000.0000, 
sim time next is 1351800.0000, 
raw observation next is [1.1, 92.5, 44.0, 0.0, 26.0, 25.7046166911852, 0.506131038167113, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.925, 0.14666666666666667, 0.0, 0.6666666666666666, 0.6420513909321001, 0.6687103460557043, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0448663], dtype=float32), 2.213623]. 
=============================================
[2019-04-06 22:09:00,225] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 22:09:00,227] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:09:00,227] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:09:00,230] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:09:00,230] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:09:00,234] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run79
[2019-04-06 22:09:00,269] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:09:00,270] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:09:00,275] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run79
[2019-04-06 22:09:00,393] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run79
[2019-04-06 22:11:40,975] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3885 79967197.3248 535.2671
[2019-04-06 22:12:01,555] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 22:12:03,677] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 22:12:04,698] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1560000, evaluation results [1560000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.388471443006, 79967197.3248232, 535.2671102210136, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 22:12:11,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0481151e-11 1.1815954e-09 7.4367054e-11 4.0024090e-05 2.3781053e-12
 9.9995995e-01 4.2242421e-11], sum to 1.0000
[2019-04-06 22:12:11,959] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8336
[2019-04-06 22:12:12,244] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-15.0, 83.0, 0.0, 0.0, 26.0, 22.78028221356607, -0.1963134636358817, 0.0, 1.0, 43200.90113344778], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2703600.0000, 
sim time next is 2705400.0000, 
raw observation next is [-15.0, 83.0, 0.0, 0.0, 26.0, 23.15334610897002, -0.00885021965184333, 1.0, 1.0, 149594.68436893122], 
processed observation next is [1.0, 0.30434782608695654, 0.04709141274238226, 0.83, 0.0, 0.0, 0.6666666666666666, 0.42944550908083495, 0.49704992678271886, 1.0, 1.0, 0.7123556398520534], 
reward next is 0.2876, 
noisyNet noise sample is [array([-0.7436929], dtype=float32), -0.17887926]. 
=============================================
[2019-04-06 22:12:14,502] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2364196e-12 5.3240207e-10 1.4219398e-12 7.9873229e-05 2.2567046e-12
 9.9992013e-01 4.9303161e-13], sum to 1.0000
[2019-04-06 22:12:14,503] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2363
[2019-04-06 22:12:14,597] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 44.0, 0.0, 0.0, 26.0, 24.9250519470886, 0.1766119551921795, 0.0, 1.0, 38642.274002689905], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2516400.0000, 
sim time next is 2518200.0000, 
raw observation next is [-1.7, 46.5, 0.0, 0.0, 26.0, 25.01437014004222, 0.1893786713032001, 0.0, 1.0, 38515.2076210402], 
processed observation next is [1.0, 0.13043478260869565, 0.4155124653739613, 0.465, 0.0, 0.0, 0.6666666666666666, 0.5845308450035184, 0.5631262237677334, 0.0, 1.0, 0.18340575057638192], 
reward next is 0.8166, 
noisyNet noise sample is [array([0.6423223], dtype=float32), -0.28991732]. 
=============================================
[2019-04-06 22:12:31,421] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2197513e-12 1.4005493e-09 6.0805792e-12 8.8835266e-05 2.2318911e-12
 9.9991119e-01 2.9978550e-12], sum to 1.0000
[2019-04-06 22:12:31,422] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3681
[2019-04-06 22:12:31,494] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 26.0, 23.98693362464066, 0.06872632644386133, 0.0, 1.0, 46683.06163697561], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1825200.0000, 
sim time next is 1827000.0000, 
raw observation next is [-6.2, 85.0, 0.0, 0.0, 26.0, 23.95955959692031, 0.0611680790502343, 0.0, 1.0, 46815.83239350975], 
processed observation next is [0.0, 0.13043478260869565, 0.2908587257617729, 0.85, 0.0, 0.0, 0.6666666666666666, 0.49662996641002594, 0.5203893596834114, 0.0, 1.0, 0.22293253520718928], 
reward next is 0.7771, 
noisyNet noise sample is [array([-0.85704356], dtype=float32), 2.2179036]. 
=============================================
[2019-04-06 22:12:31,499] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[77.831985]
 [77.85726 ]
 [78.09567 ]
 [78.03208 ]
 [78.37724 ]], R is [[77.56031799]
 [77.56241608]
 [77.56536102]
 [77.5692215 ]
 [77.57407379]].
[2019-04-06 22:12:34,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:12:34,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:12:34,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run36
[2019-04-06 22:12:49,863] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.5594956e-11 7.1236608e-09 2.2885119e-11 1.6428316e-04 5.0209264e-12
 9.9983573e-01 1.1794368e-11], sum to 1.0000
[2019-04-06 22:12:49,893] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9832
[2019-04-06 22:12:50,165] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 68.0, 0.0, 0.0, 26.0, 23.16550114236745, -0.1146732947981285, 0.0, 1.0, 45766.381593475984], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 111600.0000, 
sim time next is 113400.0000, 
raw observation next is [-7.3, 68.0, 0.0, 0.0, 26.0, 23.38884594130199, 0.05037957051855502, 1.0, 1.0, 150571.1384740972], 
processed observation next is [1.0, 0.30434782608695654, 0.26038781163434904, 0.68, 0.0, 0.0, 0.6666666666666666, 0.4490704951084992, 0.5167931901728516, 1.0, 1.0, 0.7170054213052248], 
reward next is 0.2830, 
noisyNet noise sample is [array([0.00605442], dtype=float32), 0.016800534]. 
=============================================
[2019-04-06 22:12:57,873] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.7391897e-13 2.0237596e-11 1.0015963e-12 1.1019023e-06 8.3656138e-14
 9.9999893e-01 4.7704167e-12], sum to 1.0000
[2019-04-06 22:12:57,874] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9590
[2019-04-06 22:12:57,928] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.5, 74.0, 0.0, 0.0, 26.0, 24.83594522795639, 0.2562206972489047, 0.0, 1.0, 41677.714951834256], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3385800.0000, 
sim time next is 3387600.0000, 
raw observation next is [-5.0, 71.0, 0.0, 0.0, 26.0, 24.74658514334127, 0.2482205678714617, 0.0, 1.0, 42141.4634327332], 
processed observation next is [1.0, 0.21739130434782608, 0.32409972299168976, 0.71, 0.0, 0.0, 0.6666666666666666, 0.5622154286117725, 0.5827401892904872, 0.0, 1.0, 0.20067363539396763], 
reward next is 0.7993, 
noisyNet noise sample is [array([0.88810694], dtype=float32), -2.0623813]. 
=============================================
[2019-04-06 22:13:14,665] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7349078e-12 5.2714161e-10 4.9350220e-12 4.9301521e-05 3.1100229e-12
 9.9995065e-01 5.4521006e-12], sum to 1.0000
[2019-04-06 22:13:14,666] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4232
[2019-04-06 22:13:14,722] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 26.0, 25.46506228785516, 0.4952735431293915, 1.0, 1.0, 47195.40487090317], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3524400.0000, 
sim time next is 3526200.0000, 
raw observation next is [1.0, 62.0, 0.0, 0.0, 26.0, 25.28214388322609, 0.4604348466601598, 0.0, 1.0, 31398.998155362333], 
processed observation next is [1.0, 0.8260869565217391, 0.4903047091412743, 0.62, 0.0, 0.0, 0.6666666666666666, 0.6068453236021742, 0.6534782822200532, 0.0, 1.0, 0.14951903883505874], 
reward next is 0.8505, 
noisyNet noise sample is [array([0.48881587], dtype=float32), 1.4402547]. 
=============================================
[2019-04-06 22:13:27,584] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.3012288e-14 1.4053361e-11 1.7962098e-13 4.0285434e-07 3.3613137e-14
 9.9999964e-01 3.1953026e-15], sum to 1.0000
[2019-04-06 22:13:27,585] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3248
[2019-04-06 22:13:27,632] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.3, 88.0, 0.0, 0.0, 26.0, 24.92723199662465, 0.2436926872773316, 0.0, 1.0, 39594.48297314043], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 525600.0000, 
sim time next is 527400.0000, 
raw observation next is [4.05, 87.0, 0.0, 0.0, 26.0, 24.84643455622105, 0.2332904375082095, 0.0, 1.0, 39681.60149323769], 
processed observation next is [0.0, 0.08695652173913043, 0.5747922437673131, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5705362130184207, 0.5777634791694032, 0.0, 1.0, 0.1889600071106557], 
reward next is 0.8110, 
noisyNet noise sample is [array([-0.7543835], dtype=float32), -0.25417855]. 
=============================================
[2019-04-06 22:13:35,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:13:35,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:13:35,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run36
[2019-04-06 22:13:38,235] A3C_AGENT_WORKER-Thread-11 INFO:Local step 99500, global step 1574105: loss 0.0662
[2019-04-06 22:13:38,240] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 99500, global step 1574106: learning rate 0.0000
[2019-04-06 22:13:42,964] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5685389e-14 1.7219587e-11 2.2628397e-13 3.5501830e-07 8.6968396e-15
 9.9999964e-01 1.5272339e-14], sum to 1.0000
[2019-04-06 22:13:42,964] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4095
[2019-04-06 22:13:43,048] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.3, 57.0, 99.5, 584.0, 26.0, 26.37378845354358, 0.5779263155712183, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4352400.0000, 
sim time next is 4354200.0000, 
raw observation next is [8.15, 49.5, 107.0, 677.0, 26.0, 26.68445465848415, 0.6675386106891549, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6883656509695293, 0.495, 0.3566666666666667, 0.7480662983425415, 0.6666666666666666, 0.7237045548736791, 0.7225128702297182, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.04381658], dtype=float32), -0.93062204]. 
=============================================
[2019-04-06 22:13:46,690] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2836626e-12 7.9869906e-09 5.0445283e-11 9.4692965e-05 8.0263938e-12
 9.9990535e-01 3.0393268e-11], sum to 1.0000
[2019-04-06 22:13:46,690] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4438
[2019-04-06 22:13:46,734] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 42.0, 187.0, 89.0, 26.0, 25.08873192462073, 0.3567609370093026, 0.0, 1.0, 11867.118711905874], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4199400.0000, 
sim time next is 4201200.0000, 
raw observation next is [2.0, 44.0, 173.5, 313.5, 26.0, 25.00505682946983, 0.394909384448402, 0.0, 1.0, 46251.06374482167], 
processed observation next is [0.0, 0.6521739130434783, 0.518005540166205, 0.44, 0.5783333333333334, 0.34640883977900555, 0.6666666666666666, 0.5837547357891525, 0.6316364614828006, 0.0, 1.0, 0.22024316068962702], 
reward next is 0.7798, 
noisyNet noise sample is [array([-0.9976673], dtype=float32), 0.10681324]. 
=============================================
[2019-04-06 22:13:49,411] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.8196612e-13 3.0032997e-11 7.1284932e-13 2.5701182e-05 1.8635057e-13
 9.9997425e-01 5.2362585e-13], sum to 1.0000
[2019-04-06 22:13:49,412] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0826
[2019-04-06 22:13:49,485] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 50.0, 109.0, 68.0, 26.0, 25.14846947723121, 0.4467502132386579, 1.0, 1.0, 27179.407548514282], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4552200.0000, 
sim time next is 4554000.0000, 
raw observation next is [2.0, 52.0, 68.5, 48.0, 26.0, 25.91366781911533, 0.5252840828921194, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.52, 0.22833333333333333, 0.05303867403314917, 0.6666666666666666, 0.6594723182596107, 0.6750946942973731, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3288863], dtype=float32), -0.86462116]. 
=============================================
[2019-04-06 22:13:49,519] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[85.71677 ]
 [85.73646 ]
 [85.82242 ]
 [86.61191 ]
 [87.651794]], R is [[85.46535492]
 [85.48127747]
 [85.62646484]
 [85.77020264]
 [85.91249847]].
[2019-04-06 22:13:52,851] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.3554565e-12 1.5652613e-09 2.3763701e-11 1.7664696e-06 1.9821100e-12
 9.9999821e-01 4.1065162e-11], sum to 1.0000
[2019-04-06 22:13:52,851] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7030
[2019-04-06 22:13:52,890] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.3, 27.0, 70.0, 732.0, 26.0, 24.96452824738054, 0.2826571534007261, 0.0, 1.0, 12468.008916283246], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2473200.0000, 
sim time next is 2475000.0000, 
raw observation next is [3.3, 26.5, 62.0, 680.0, 26.0, 24.97513901394997, 0.2804122218231922, 0.0, 1.0, 12465.06959386132], 
processed observation next is [0.0, 0.6521739130434783, 0.554016620498615, 0.265, 0.20666666666666667, 0.7513812154696132, 0.6666666666666666, 0.5812615844958309, 0.5934707406077308, 0.0, 1.0, 0.05935747425648248], 
reward next is 0.9406, 
noisyNet noise sample is [array([-0.36491656], dtype=float32), -1.3636583]. 
=============================================
[2019-04-06 22:13:52,894] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[78.20838 ]
 [78.020515]
 [77.90314 ]
 [77.62158 ]
 [77.22186 ]], R is [[78.49732971]
 [78.65298462]
 [78.8367691 ]
 [78.95931244]
 [79.14002228]].
[2019-04-06 22:13:54,727] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:13:54,727] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:13:54,731] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run36
[2019-04-06 22:13:57,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1370881e-13 7.6567801e-11 1.8950512e-12 1.7003485e-06 8.5560912e-14
 9.9999833e-01 1.4494653e-12], sum to 1.0000
[2019-04-06 22:13:57,416] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9424
[2019-04-06 22:13:57,591] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 68.0, 0.0, 0.0, 26.0, 25.37682830552636, 0.3879252589611705, 0.0, 1.0, 44442.35765382737], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3713400.0000, 
sim time next is 3715200.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.3683308743645, 0.3858237095324888, 0.0, 1.0, 43708.21863715849], 
processed observation next is [1.0, 0.0, 0.3795013850415513, 0.71, 0.0, 0.0, 0.6666666666666666, 0.6140275728637082, 0.6286079031774963, 0.0, 1.0, 0.20813437446265948], 
reward next is 0.7919, 
noisyNet noise sample is [array([0.09724373], dtype=float32), 1.3335544]. 
=============================================
[2019-04-06 22:14:05,188] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.5238419e-15 4.4812977e-12 3.4644342e-14 1.1158930e-06 6.1489374e-15
 9.9999893e-01 1.6087717e-14], sum to 1.0000
[2019-04-06 22:14:05,188] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7034
[2019-04-06 22:14:05,486] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 89.0, 102.0, 0.0, 26.0, 26.32395026361691, 0.483434489917515, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4451400.0000, 
sim time next is 4453200.0000, 
raw observation next is [0.0, 92.0, 149.0, 3.0, 26.0, 25.11843319524032, 0.5019339673561586, 1.0, 1.0, 105201.68363660522], 
processed observation next is [1.0, 0.5652173913043478, 0.46260387811634357, 0.92, 0.49666666666666665, 0.0033149171270718232, 0.6666666666666666, 0.5932027662700268, 0.6673113224520528, 1.0, 1.0, 0.5009603982695486], 
reward next is 0.4990, 
noisyNet noise sample is [array([-0.2850876], dtype=float32), 1.0204365]. 
=============================================
[2019-04-06 22:14:06,830] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8709744e-13 1.3000730e-10 5.6376757e-12 5.9980175e-05 1.4780425e-13
 9.9994004e-01 8.3099075e-14], sum to 1.0000
[2019-04-06 22:14:06,830] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7180
[2019-04-06 22:14:07,202] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 92.5, 0.0, 0.0, 26.0, 25.00831032712875, 0.3672727387030481, 1.0, 1.0, 28387.388371932477], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2917800.0000, 
sim time next is 2919600.0000, 
raw observation next is [-1.0, 92.0, 0.0, 0.0, 26.0, 25.08925519754031, 0.4129236597917427, 1.0, 1.0, 52694.57662299419], 
processed observation next is [1.0, 0.8260869565217391, 0.4349030470914128, 0.92, 0.0, 0.0, 0.6666666666666666, 0.5907712664616925, 0.6376412199305809, 1.0, 1.0, 0.2509265553475914], 
reward next is 0.7491, 
noisyNet noise sample is [array([-0.06102547], dtype=float32), -0.6990373]. 
=============================================
[2019-04-06 22:14:24,854] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.0185457e-12 1.5821031e-10 5.9716056e-13 1.0211009e-04 6.9388869e-13
 9.9989784e-01 4.0144800e-13], sum to 1.0000
[2019-04-06 22:14:24,855] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2523
[2019-04-06 22:14:24,967] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 26.0, 24.86367884426795, 0.3370372271014519, 0.0, 1.0, 43353.07875248029], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2939400.0000, 
sim time next is 2941200.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 26.0, 24.88031317309304, 0.3310345491023737, 0.0, 1.0, 43319.31090182161], 
processed observation next is [0.0, 0.043478260869565216, 0.40720221606648205, 0.85, 0.0, 0.0, 0.6666666666666666, 0.5733594310910867, 0.6103448497007912, 0.0, 1.0, 0.2062824328658172], 
reward next is 0.7937, 
noisyNet noise sample is [array([0.68422896], dtype=float32), -0.77963114]. 
=============================================
[2019-04-06 22:14:25,764] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-06 22:14:25,765] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:14:25,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:14:25,789] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:14:25,789] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:14:25,797] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:14:25,797] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:14:25,801] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run80
[2019-04-06 22:14:25,869] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run80
[2019-04-06 22:14:25,903] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run80
[2019-04-06 22:15:56,463] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.06587431], dtype=float32), 0.13786769]
[2019-04-06 22:15:56,463] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [8.3, 93.0, 24.5, 47.0, 26.0, 25.54333532282302, 0.5722790381043469, 0.0, 1.0, 21076.898532765113]
[2019-04-06 22:15:56,463] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:15:56,465] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [9.4993898e-15 5.6001345e-12 4.3028349e-14 6.9268901e-07 3.6320252e-15
 9.9999928e-01 1.9284768e-14], sampled 0.78628483832377
[2019-04-06 22:17:02,255] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3748 79991956.7854 535.1864
[2019-04-06 22:17:21,838] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.8302 87803285.7563 514.7094
[2019-04-06 22:17:23,804] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 22:17:24,827] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1580000, evaluation results [1580000.0, 2415.830221886695, 87803285.7563282, 514.7094491225716, 2453.374809603911, 79991956.78540477, 535.1864255395496, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 22:17:26,809] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:17:26,809] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:17:26,818] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run36
[2019-04-06 22:17:27,557] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:17:27,557] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:17:27,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run36
[2019-04-06 22:17:29,225] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:17:29,225] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:17:29,228] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run36
[2019-04-06 22:17:30,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:17:30,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:17:30,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run36
[2019-04-06 22:17:31,710] A3C_AGENT_WORKER-Thread-11 INFO:Local step 100000, global step 1580953: loss 0.1308
[2019-04-06 22:17:31,710] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 100000, global step 1580953: learning rate 0.0000
[2019-04-06 22:17:41,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:17:41,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:17:41,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run36
[2019-04-06 22:17:45,101] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:17:45,101] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:17:45,104] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run36
[2019-04-06 22:17:54,060] A3C_AGENT_WORKER-Thread-3 INFO:Local step 99500, global step 1583827: loss 0.0842
[2019-04-06 22:17:54,064] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 99500, global step 1583827: learning rate 0.0000
[2019-04-06 22:17:57,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:17:57,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:17:57,766] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run36
[2019-04-06 22:17:58,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7565853e-13 1.2929792e-10 6.0165453e-12 9.7344506e-05 2.2553557e-13
 9.9990261e-01 3.9587274e-12], sum to 1.0000
[2019-04-06 22:17:58,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4262
[2019-04-06 22:17:59,068] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 80.5, 0.0, 0.0, 26.0, 25.24754887624329, 0.3825027389098225, 0.0, 1.0, 49405.90744989334], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1974600.0000, 
sim time next is 1976400.0000, 
raw observation next is [-5.6, 78.0, 0.0, 0.0, 26.0, 25.22183804657253, 0.3792861524186223, 0.0, 1.0, 47273.45600852559], 
processed observation next is [1.0, 0.9130434782608695, 0.30747922437673136, 0.78, 0.0, 0.0, 0.6666666666666666, 0.6018198372143774, 0.6264287174728741, 0.0, 1.0, 0.22511169527869326], 
reward next is 0.7749, 
noisyNet noise sample is [array([0.08082824], dtype=float32), 0.23286064]. 
=============================================
[2019-04-06 22:18:15,930] A3C_AGENT_WORKER-Thread-17 INFO:Local step 99500, global step 1586575: loss 0.0704
[2019-04-06 22:18:15,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 99500, global step 1586575: learning rate 0.0000
[2019-04-06 22:18:16,725] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:18:16,725] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:18:16,728] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run36
[2019-04-06 22:18:34,436] A3C_AGENT_WORKER-Thread-16 INFO:Local step 99500, global step 1588999: loss 0.0687
[2019-04-06 22:18:34,437] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 99500, global step 1588999: learning rate 0.0000
[2019-04-06 22:18:35,660] A3C_AGENT_WORKER-Thread-5 INFO:Local step 99500, global step 1589183: loss 0.0633
[2019-04-06 22:18:35,661] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 99500, global step 1589183: learning rate 0.0000
[2019-04-06 22:18:38,451] A3C_AGENT_WORKER-Thread-6 INFO:Local step 99500, global step 1589600: loss 0.0571
[2019-04-06 22:18:38,452] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 99500, global step 1589600: learning rate 0.0000
[2019-04-06 22:18:38,593] A3C_AGENT_WORKER-Thread-13 INFO:Local step 99500, global step 1589632: loss 0.0836
[2019-04-06 22:18:38,593] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 99500, global step 1589632: learning rate 0.0000
[2019-04-06 22:18:39,614] A3C_AGENT_WORKER-Thread-11 INFO:Local step 100500, global step 1589818: loss 0.3496
[2019-04-06 22:18:39,617] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 100500, global step 1589818: learning rate 0.0000
[2019-04-06 22:18:40,328] A3C_AGENT_WORKER-Thread-3 INFO:Local step 100000, global step 1589937: loss 0.1399
[2019-04-06 22:18:40,329] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 100000, global step 1589937: learning rate 0.0000
[2019-04-06 22:18:43,454] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.08052981e-13 2.69134215e-10 8.24062444e-13 2.41337602e-06
 1.03761306e-13 9.99997616e-01 4.37922593e-13], sum to 1.0000
[2019-04-06 22:18:43,454] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1100
[2019-04-06 22:18:43,549] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.5, 93.0, 0.0, 0.0, 26.0, 23.92201212604246, 0.2302778929254492, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1220400.0000, 
sim time next is 1222200.0000, 
raw observation next is [15.5, 93.0, 0.0, 0.0, 26.0, 23.86640464653166, 0.219573336315824, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.8919667590027703, 0.93, 0.0, 0.0, 0.6666666666666666, 0.4888670538776383, 0.5731911121052747, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0115254], dtype=float32), -0.10015125]. 
=============================================
[2019-04-06 22:18:47,565] A3C_AGENT_WORKER-Thread-12 INFO:Local step 99500, global step 1591097: loss 0.0438
[2019-04-06 22:18:47,565] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 99500, global step 1591097: learning rate 0.0000
[2019-04-06 22:18:50,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:18:50,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:18:50,946] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run36
[2019-04-06 22:18:51,501] A3C_AGENT_WORKER-Thread-18 INFO:Local step 99500, global step 1591675: loss 0.0661
[2019-04-06 22:18:51,502] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 99500, global step 1591675: learning rate 0.0000
[2019-04-06 22:18:53,341] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:18:53,341] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:18:53,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run36
[2019-04-06 22:18:55,793] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.1655253e-13 5.5457059e-11 2.0005975e-13 9.8622832e-06 2.4276435e-14
 9.9999011e-01 1.8054046e-13], sum to 1.0000
[2019-04-06 22:18:55,793] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8903
[2019-04-06 22:18:55,866] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 72.0, 123.5, 5.5, 26.0, 26.16253476210784, 0.5471346414061583, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4723200.0000, 
sim time next is 4725000.0000, 
raw observation next is [1.0, 72.0, 100.0, 11.0, 26.0, 26.1426437499189, 0.4326071757089311, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4903047091412743, 0.72, 0.3333333333333333, 0.012154696132596685, 0.6666666666666666, 0.678553645826575, 0.644202391902977, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3421467], dtype=float32), 0.34855524]. 
=============================================
[2019-04-06 22:18:55,870] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[89.18483 ]
 [90.11905 ]
 [90.688286]
 [91.34759 ]
 [91.429016]], R is [[88.52718353]
 [88.64191437]
 [88.7357254 ]
 [88.81526947]
 [88.92711639]].
[2019-04-06 22:19:00,009] A3C_AGENT_WORKER-Thread-17 INFO:Local step 100000, global step 1593034: loss 0.1234
[2019-04-06 22:19:00,010] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 100000, global step 1593034: learning rate 0.0000
[2019-04-06 22:19:03,360] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:19:03,360] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:19:03,368] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run36
[2019-04-06 22:19:03,950] A3C_AGENT_WORKER-Thread-19 INFO:Local step 99500, global step 1593743: loss 0.0703
[2019-04-06 22:19:03,950] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 99500, global step 1593743: learning rate 0.0000
[2019-04-06 22:19:05,445] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9219528e-13 4.3725842e-11 4.8070841e-14 1.0420767e-06 7.7490084e-14
 9.9999893e-01 3.2825405e-13], sum to 1.0000
[2019-04-06 22:19:05,445] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0277
[2019-04-06 22:19:05,645] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.5, 86.0, 0.0, 0.0, 26.0, 24.54659692194853, 0.1947913318725229, 0.0, 1.0, 37151.99185405776], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 61200.0000, 
sim time next is 63000.0000, 
raw observation next is [4.95, 87.5, 0.0, 0.0, 26.0, 24.56896975712736, 0.189475279799225, 0.0, 1.0, 35186.734164281814], 
processed observation next is [0.0, 0.7391304347826086, 0.5997229916897507, 0.875, 0.0, 0.0, 0.6666666666666666, 0.5474141464272799, 0.5631584265997417, 0.0, 1.0, 0.16755587697277055], 
reward next is 0.8324, 
noisyNet noise sample is [array([-0.02535276], dtype=float32), 0.2351687]. 
=============================================
[2019-04-06 22:19:05,669] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[88.57724 ]
 [88.81411 ]
 [88.964355]
 [89.420815]
 [89.64355 ]], R is [[88.39823151]
 [88.33733368]
 [88.23453522]
 [88.25314331]
 [88.14396667]].
[2019-04-06 22:19:14,309] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:19:14,309] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:19:14,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run36
[2019-04-06 22:19:15,521] A3C_AGENT_WORKER-Thread-16 INFO:Local step 100000, global step 1595532: loss 0.1208
[2019-04-06 22:19:15,537] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 100000, global step 1595532: learning rate 0.0000
[2019-04-06 22:19:17,319] A3C_AGENT_WORKER-Thread-5 INFO:Local step 100000, global step 1595843: loss 0.1258
[2019-04-06 22:19:17,324] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 100000, global step 1595843: learning rate 0.0000
[2019-04-06 22:19:19,527] A3C_AGENT_WORKER-Thread-15 INFO:Local step 99500, global step 1596224: loss 0.0574
[2019-04-06 22:19:19,527] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 99500, global step 1596224: learning rate 0.0000
[2019-04-06 22:19:19,565] A3C_AGENT_WORKER-Thread-6 INFO:Local step 100000, global step 1596230: loss 0.1239
[2019-04-06 22:19:19,566] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 100000, global step 1596231: learning rate 0.0000
[2019-04-06 22:19:21,153] A3C_AGENT_WORKER-Thread-13 INFO:Local step 100000, global step 1596423: loss 0.1187
[2019-04-06 22:19:21,154] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 100000, global step 1596423: learning rate 0.0000
[2019-04-06 22:19:26,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:19:26,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:19:26,640] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run36
[2019-04-06 22:19:33,788] A3C_AGENT_WORKER-Thread-12 INFO:Local step 100000, global step 1597489: loss 0.1356
[2019-04-06 22:19:33,788] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 100000, global step 1597489: learning rate 0.0000
[2019-04-06 22:19:39,080] A3C_AGENT_WORKER-Thread-11 INFO:Local step 101000, global step 1597887: loss 0.0613
[2019-04-06 22:19:39,080] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 101000, global step 1597887: learning rate 0.0000
[2019-04-06 22:19:41,364] A3C_AGENT_WORKER-Thread-18 INFO:Local step 100000, global step 1598038: loss 0.1210
[2019-04-06 22:19:41,365] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 100000, global step 1598038: learning rate 0.0000
[2019-04-06 22:19:53,584] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0252782e-10 2.6765552e-09 4.6828363e-10 1.1251206e-04 6.3421969e-11
 9.9988747e-01 1.4968471e-10], sum to 1.0000
[2019-04-06 22:19:53,584] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3305
[2019-04-06 22:19:53,663] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.9, 66.0, 0.0, 0.0, 26.0, 23.59463218448258, -0.04219981718181617, 0.0, 1.0, 47260.06380432818], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 345600.0000, 
sim time next is 347400.0000, 
raw observation next is [-14.2, 67.5, 0.0, 0.0, 26.0, 23.39060071949031, -0.08731810078282258, 0.0, 1.0, 47448.51245814791], 
processed observation next is [1.0, 0.0, 0.06925207756232687, 0.675, 0.0, 0.0, 0.6666666666666666, 0.4492167266241924, 0.47089396640572584, 0.0, 1.0, 0.22594529741975194], 
reward next is 0.7741, 
noisyNet noise sample is [array([1.3469876], dtype=float32), 0.7833024]. 
=============================================
[2019-04-06 22:19:54,445] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0982738e-10 9.2485610e-09 2.5798719e-10 3.2940038e-04 1.9241660e-10
 9.9967062e-01 2.5456462e-10], sum to 1.0000
[2019-04-06 22:19:54,446] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6551
[2019-04-06 22:19:54,540] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-15.6, 73.0, 0.0, 0.0, 26.0, 22.40462319033593, -0.3273765097570185, 0.0, 1.0, 49358.10268720962], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 360000.0000, 
sim time next is 361800.0000, 
raw observation next is [-15.6, 73.0, 0.0, 0.0, 26.0, 22.15084249015, -0.3633017509551706, 0.0, 1.0, 49383.48800302926], 
processed observation next is [1.0, 0.17391304347826086, 0.030470914127423816, 0.73, 0.0, 0.0, 0.6666666666666666, 0.34590354084583347, 0.37889941634827645, 0.0, 1.0, 0.23515946668109172], 
reward next is 0.7648, 
noisyNet noise sample is [array([0.9482999], dtype=float32), 0.06877534]. 
=============================================
[2019-04-06 22:19:58,299] A3C_AGENT_WORKER-Thread-19 INFO:Local step 100000, global step 1599375: loss 0.1438
[2019-04-06 22:19:58,299] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 100000, global step 1599375: learning rate 0.0000
[2019-04-06 22:19:59,794] A3C_AGENT_WORKER-Thread-3 INFO:Local step 100500, global step 1599503: loss 0.2303
[2019-04-06 22:19:59,794] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 100500, global step 1599503: learning rate 0.0000
[2019-04-06 22:20:06,047] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 22:20:06,057] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:20:06,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:20:06,068] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:20:06,068] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:20:06,077] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:20:06,077] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:20:06,083] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run81
[2019-04-06 22:20:06,170] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run81
[2019-04-06 22:20:06,265] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run81
[2019-04-06 22:20:47,112] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.06737232], dtype=float32), 0.13749424]
[2019-04-06 22:20:47,112] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-8.1, 41.5, 0.0, 0.0, 26.0, 22.87396089058539, -0.1718418274959656, 1.0, 1.0, 150612.3448040705]
[2019-04-06 22:20:47,112] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:20:47,114] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.3958376e-10 9.5854036e-09 4.7615545e-10 4.9721508e-05 6.1714446e-11
 9.9995029e-01 2.5479910e-10], sampled 0.339281137779056
[2019-04-06 22:20:54,415] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.06737232], dtype=float32), 0.13749424]
[2019-04-06 22:20:54,415] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-1.441160318, 70.84942946, 0.0, 0.0, 26.0, 23.73470865046786, -0.0115784417178571, 0.0, 1.0, 43843.22540258831]
[2019-04-06 22:20:54,415] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 22:20:54,417] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.7985637e-12 4.6489590e-10 1.0903835e-11 7.0638607e-06 1.1944103e-12
 9.9999297e-01 5.5200115e-12], sampled 0.3006357296800334
[2019-04-06 22:22:44,593] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 22:23:05,887] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 22:23:06,438] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 22:23:07,461] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1600000, evaluation results [1600000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 22:23:15,159] A3C_AGENT_WORKER-Thread-20 INFO:Local step 99500, global step 1600854: loss 0.0545
[2019-04-06 22:23:15,160] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 99500, global step 1600854: learning rate 0.0000
[2019-04-06 22:23:19,875] A3C_AGENT_WORKER-Thread-10 INFO:Local step 99500, global step 1601391: loss 0.0445
[2019-04-06 22:23:19,876] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 99500, global step 1601391: learning rate 0.0000
[2019-04-06 22:23:21,458] A3C_AGENT_WORKER-Thread-15 INFO:Local step 100000, global step 1601575: loss 0.1417
[2019-04-06 22:23:21,458] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 100000, global step 1601575: learning rate 0.0000
[2019-04-06 22:23:27,163] A3C_AGENT_WORKER-Thread-17 INFO:Local step 100500, global step 1602230: loss 0.1864
[2019-04-06 22:23:27,163] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 100500, global step 1602230: learning rate 0.0000
[2019-04-06 22:23:29,796] A3C_AGENT_WORKER-Thread-2 INFO:Local step 99500, global step 1602529: loss 0.0472
[2019-04-06 22:23:29,796] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 99500, global step 1602529: learning rate 0.0000
[2019-04-06 22:23:36,042] A3C_AGENT_WORKER-Thread-11 INFO:Local step 101500, global step 1603285: loss 2.0397
[2019-04-06 22:23:36,044] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 101500, global step 1603285: learning rate 0.0000
[2019-04-06 22:23:36,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.4460917e-12 3.6490821e-10 7.4308129e-12 1.5896714e-05 8.5227474e-13
 9.9998415e-01 7.4216024e-13], sum to 1.0000
[2019-04-06 22:23:36,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2997
[2019-04-06 22:23:37,123] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.2, 69.5, 35.0, 0.0, 26.0, 25.99983571723964, 0.4168014045188291, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2219400.0000, 
sim time next is 2221200.0000, 
raw observation next is [-4.5, 71.0, 19.0, 0.0, 26.0, 25.64419946390641, 0.4002118813357577, 1.0, 1.0, 64732.95444401935], 
processed observation next is [1.0, 0.7391304347826086, 0.3379501385041552, 0.71, 0.06333333333333334, 0.0, 0.6666666666666666, 0.6370166219922009, 0.6334039604452526, 1.0, 1.0, 0.30825216401913974], 
reward next is 0.6917, 
noisyNet noise sample is [array([0.16717492], dtype=float32), -0.0094606625]. 
=============================================
[2019-04-06 22:23:38,965] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1224825e-12 9.2370994e-10 8.0837982e-11 1.4515987e-05 2.0351505e-12
 9.9998546e-01 5.1760089e-11], sum to 1.0000
[2019-04-06 22:23:38,965] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9248
[2019-04-06 22:23:39,254] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 61.5, 0.0, 0.0, 26.0, 25.11127177081986, 0.3532388723852326, 0.0, 1.0, 8559.27971504667], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2662200.0000, 
sim time next is 2664000.0000, 
raw observation next is [-1.2, 63.0, 0.0, 0.0, 26.0, 24.95541146598098, 0.372744739425137, 0.0, 1.0, 77567.5788343562], 
processed observation next is [1.0, 0.8695652173913043, 0.42936288088642666, 0.63, 0.0, 0.0, 0.6666666666666666, 0.5796176221650816, 0.6242482464750457, 0.0, 1.0, 0.3693694230207438], 
reward next is 0.6306, 
noisyNet noise sample is [array([0.27068573], dtype=float32), 2.1470613]. 
=============================================
[2019-04-06 22:23:39,258] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[81.81866]
 [82.58581]
 [82.00604]
 [81.75613]
 [81.82833]], R is [[82.13085175]
 [82.2687912 ]
 [82.06882477]
 [82.14273834]
 [82.12950134]].
[2019-04-06 22:23:41,656] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3197810e-15 2.9955018e-13 5.5401278e-14 5.0189460e-08 1.2132123e-15
 1.0000000e+00 1.1712165e-15], sum to 1.0000
[2019-04-06 22:23:41,656] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9762
[2019-04-06 22:23:41,686] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.7, 86.0, 123.5, 0.0, 26.0, 25.95070354710873, 0.5811338451229963, 1.0, 1.0, 1868.041167023054], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 997200.0000, 
sim time next is 999000.0000, 
raw observation next is [13.55, 83.5, 119.0, 0.0, 26.0, 26.28732943942103, 0.6472030167620462, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.8379501385041552, 0.835, 0.39666666666666667, 0.0, 0.6666666666666666, 0.6906107866184191, 0.7157343389206821, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.08745633], dtype=float32), 0.6954364]. 
=============================================
[2019-04-06 22:23:41,706] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[99.54002 ]
 [99.76727 ]
 [99.70943 ]
 [99.42619 ]
 [98.991455]], R is [[99.40603638]
 [99.4030838 ]
 [99.40905762]
 [99.4149704 ]
 [99.42082214]].
[2019-04-06 22:23:43,506] A3C_AGENT_WORKER-Thread-4 INFO:Local step 99500, global step 1604268: loss 0.0464
[2019-04-06 22:23:43,507] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 99500, global step 1604268: learning rate 0.0000
[2019-04-06 22:23:44,087] A3C_AGENT_WORKER-Thread-5 INFO:Local step 100500, global step 1604356: loss 0.1918
[2019-04-06 22:23:44,087] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 100500, global step 1604356: learning rate 0.0000
[2019-04-06 22:23:44,116] A3C_AGENT_WORKER-Thread-16 INFO:Local step 100500, global step 1604360: loss 0.1998
[2019-04-06 22:23:44,116] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 100500, global step 1604360: learning rate 0.0000
[2019-04-06 22:23:45,649] A3C_AGENT_WORKER-Thread-6 INFO:Local step 100500, global step 1604570: loss 0.2133
[2019-04-06 22:23:45,649] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 100500, global step 1604570: learning rate 0.0000
[2019-04-06 22:23:48,744] A3C_AGENT_WORKER-Thread-13 INFO:Local step 100500, global step 1605056: loss 0.2100
[2019-04-06 22:23:48,745] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 100500, global step 1605056: learning rate 0.0000
[2019-04-06 22:23:54,894] A3C_AGENT_WORKER-Thread-14 INFO:Local step 99500, global step 1605928: loss 0.0787
[2019-04-06 22:23:54,895] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 99500, global step 1605928: learning rate 0.0000
[2019-04-06 22:23:58,071] A3C_AGENT_WORKER-Thread-12 INFO:Local step 100500, global step 1606387: loss 0.2728
[2019-04-06 22:23:58,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 100500, global step 1606387: learning rate 0.0000
[2019-04-06 22:23:59,846] A3C_AGENT_WORKER-Thread-18 INFO:Local step 100500, global step 1606616: loss 0.1901
[2019-04-06 22:23:59,846] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 100500, global step 1606616: learning rate 0.0000
[2019-04-06 22:24:01,675] A3C_AGENT_WORKER-Thread-3 INFO:Local step 101000, global step 1606885: loss 0.0554
[2019-04-06 22:24:01,681] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 101000, global step 1606885: learning rate 0.0000
[2019-04-06 22:24:01,798] A3C_AGENT_WORKER-Thread-20 INFO:Local step 100000, global step 1606908: loss 0.1342
[2019-04-06 22:24:01,811] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 100000, global step 1606908: learning rate 0.0000
[2019-04-06 22:24:05,985] A3C_AGENT_WORKER-Thread-10 INFO:Local step 100000, global step 1607547: loss 0.1343
[2019-04-06 22:24:05,986] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 100000, global step 1607547: learning rate 0.0000
[2019-04-06 22:24:07,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5979219e-15 1.3413361e-12 7.7208917e-15 2.6247906e-07 1.3980728e-14
 9.9999976e-01 2.9165808e-14], sum to 1.0000
[2019-04-06 22:24:07,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7851
[2019-04-06 22:24:07,202] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 49.0, 111.5, 0.0, 26.0, 26.11157826484739, 0.7123247739705945, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1609200.0000, 
sim time next is 1611000.0000, 
raw observation next is [13.55, 50.0, 78.0, 0.0, 26.0, 27.04341204495685, 0.8135617703856455, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.8379501385041552, 0.5, 0.26, 0.0, 0.6666666666666666, 0.7536176704130707, 0.7711872567952152, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.816438], dtype=float32), 0.92003745]. 
=============================================
[2019-04-06 22:24:07,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[94.43577 ]
 [94.385414]
 [93.99518 ]
 [93.66659 ]
 [93.80958 ]], R is [[94.24974823]
 [94.30725098]
 [94.36418152]
 [94.42053986]
 [94.47633362]].
[2019-04-06 22:24:11,468] A3C_AGENT_WORKER-Thread-19 INFO:Local step 100500, global step 1608427: loss 0.2580
[2019-04-06 22:24:11,469] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 100500, global step 1608427: learning rate 0.0000
[2019-04-06 22:24:14,852] A3C_AGENT_WORKER-Thread-2 INFO:Local step 100000, global step 1608947: loss 0.1513
[2019-04-06 22:24:14,853] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 100000, global step 1608947: learning rate 0.0000
[2019-04-06 22:24:15,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:24:15,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:24:15,632] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run37
[2019-04-06 22:24:18,762] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.25219456e-14 1.69807712e-12 1.62343300e-14 2.09385439e-06
 4.28773584e-15 9.99997854e-01 7.10922749e-14], sum to 1.0000
[2019-04-06 22:24:18,762] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3705
[2019-04-06 22:24:18,821] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.2, 83.0, 11.5, 38.0, 26.0, 25.92345422276947, 0.623993847899504, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1065600.0000, 
sim time next is 1067400.0000, 
raw observation next is [12.2, 83.0, 22.0, 69.0, 26.0, 26.06846811708475, 0.6821835545850465, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.8005540166204987, 0.83, 0.07333333333333333, 0.07624309392265194, 0.6666666666666666, 0.6723723430903957, 0.7273945181950155, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.79937994], dtype=float32), 0.564968]. 
=============================================
[2019-04-06 22:24:23,841] A3C_AGENT_WORKER-Thread-17 INFO:Local step 101000, global step 1610223: loss 0.0615
[2019-04-06 22:24:23,841] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 101000, global step 1610223: learning rate 0.0000
[2019-04-06 22:24:28,392] A3C_AGENT_WORKER-Thread-15 INFO:Local step 100500, global step 1610903: loss 0.2272
[2019-04-06 22:24:28,393] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 100500, global step 1610903: learning rate 0.0000
[2019-04-06 22:24:28,990] A3C_AGENT_WORKER-Thread-4 INFO:Local step 100000, global step 1611013: loss 0.1572
[2019-04-06 22:24:28,990] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 100000, global step 1611013: learning rate 0.0000
[2019-04-06 22:24:38,186] A3C_AGENT_WORKER-Thread-16 INFO:Local step 101000, global step 1612403: loss 0.0633
[2019-04-06 22:24:38,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 101000, global step 1612403: learning rate 0.0000
[2019-04-06 22:24:39,126] A3C_AGENT_WORKER-Thread-5 INFO:Local step 101000, global step 1612545: loss 0.0443
[2019-04-06 22:24:39,137] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 101000, global step 1612545: learning rate 0.0000
[2019-04-06 22:24:39,939] A3C_AGENT_WORKER-Thread-6 INFO:Local step 101000, global step 1612692: loss 0.0648
[2019-04-06 22:24:39,942] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 101000, global step 1612692: learning rate 0.0000
[2019-04-06 22:24:40,544] A3C_AGENT_WORKER-Thread-14 INFO:Local step 100000, global step 1612784: loss 0.1355
[2019-04-06 22:24:40,564] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 100000, global step 1612784: learning rate 0.0000
[2019-04-06 22:24:41,595] A3C_AGENT_WORKER-Thread-13 INFO:Local step 101000, global step 1612946: loss 0.0661
[2019-04-06 22:24:41,596] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 101000, global step 1612946: learning rate 0.0000
[2019-04-06 22:24:46,304] A3C_AGENT_WORKER-Thread-3 INFO:Local step 101500, global step 1613719: loss 2.2442
[2019-04-06 22:24:46,305] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 101500, global step 1613719: learning rate 0.0000
[2019-04-06 22:24:50,404] A3C_AGENT_WORKER-Thread-12 INFO:Local step 101000, global step 1614335: loss 0.0605
[2019-04-06 22:24:50,405] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 101000, global step 1614335: learning rate 0.0000
[2019-04-06 22:24:51,644] A3C_AGENT_WORKER-Thread-18 INFO:Local step 101000, global step 1614540: loss 0.0774
[2019-04-06 22:24:51,644] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 101000, global step 1614540: learning rate 0.0000
[2019-04-06 22:24:57,595] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.9992044e-13 7.6181839e-11 6.4330366e-13 7.5550076e-07 7.0087179e-14
 9.9999928e-01 1.5821716e-12], sum to 1.0000
[2019-04-06 22:24:57,595] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8289
[2019-04-06 22:24:57,650] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.2975940e-13 1.7472246e-09 1.4592218e-11 1.5189275e-05 1.0960394e-12
 9.9998486e-01 4.7655456e-13], sum to 1.0000
[2019-04-06 22:24:57,651] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2189
[2019-04-06 22:24:57,673] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 74.0, 0.0, 0.0, 26.0, 25.40347150709046, 0.4508907825958369, 0.0, 1.0, 56638.99407682793], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3796200.0000, 
sim time next is 3798000.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.2898319143034, 0.440268994791732, 0.0, 1.0, 58131.00839973598], 
processed observation next is [1.0, 1.0, 0.3795013850415513, 0.71, 0.0, 0.0, 0.6666666666666666, 0.6074859928586166, 0.646756331597244, 0.0, 1.0, 0.2768143257130285], 
reward next is 0.7232, 
noisyNet noise sample is [array([-0.8411307], dtype=float32), 0.5986535]. 
=============================================
[2019-04-06 22:24:57,726] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[83.60283 ]
 [83.54066 ]
 [83.231255]
 [83.386566]
 [83.57191 ]], R is [[83.16326904]
 [83.0619278 ]
 [82.92731476]
 [83.09804535]
 [83.09242249]].
[2019-04-06 22:24:57,807] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 86.0, 49.0, 0.0, 26.0, 25.69378518040049, 0.3009874606780501, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2019600.0000, 
sim time next is 2021400.0000, 
raw observation next is [-5.8, 84.5, 69.0, 0.0, 26.0, 25.50788034628935, 0.2841911672042438, 1.0, 1.0, 6241.487952887416], 
processed observation next is [1.0, 0.391304347826087, 0.30193905817174516, 0.845, 0.23, 0.0, 0.6666666666666666, 0.6256566955241126, 0.5947303890680813, 1.0, 1.0, 0.029721371204225792], 
reward next is 0.9703, 
noisyNet noise sample is [array([2.5941908], dtype=float32), -1.1195782]. 
=============================================
[2019-04-06 22:25:02,759] A3C_AGENT_WORKER-Thread-19 INFO:Local step 101000, global step 1616406: loss 0.0679
[2019-04-06 22:25:02,760] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 101000, global step 1616406: learning rate 0.0000
[2019-04-06 22:25:03,710] A3C_AGENT_WORKER-Thread-20 INFO:Local step 100500, global step 1616493: loss 0.2220
[2019-04-06 22:25:03,710] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 100500, global step 1616493: learning rate 0.0000
[2019-04-06 22:25:08,953] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.0744029e-11 2.3954101e-09 3.9234922e-12 6.6866814e-06 4.1224012e-12
 9.9999332e-01 1.7246335e-11], sum to 1.0000
[2019-04-06 22:25:08,954] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8935
[2019-04-06 22:25:09,112] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 45.0, 0.0, 0.0, 26.0, 25.52367922381159, 0.5166667179165784, 0.0, 1.0, 43191.01763625356], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3963600.0000, 
sim time next is 3965400.0000, 
raw observation next is [-7.5, 47.0, 0.0, 0.0, 26.0, 25.47680666212933, 0.5045266735127245, 0.0, 1.0, 48963.921703412016], 
processed observation next is [1.0, 0.9130434782608695, 0.2548476454293629, 0.47, 0.0, 0.0, 0.6666666666666666, 0.6230672218441109, 0.6681755578375749, 0.0, 1.0, 0.2331615319210096], 
reward next is 0.7668, 
noisyNet noise sample is [array([-0.20903014], dtype=float32), 0.42188886]. 
=============================================
[2019-04-06 22:25:11,146] A3C_AGENT_WORKER-Thread-17 INFO:Local step 101500, global step 1617180: loss 2.1384
[2019-04-06 22:25:11,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 101500, global step 1617180: learning rate 0.0000
[2019-04-06 22:25:13,590] A3C_AGENT_WORKER-Thread-10 INFO:Local step 100500, global step 1617400: loss 0.2444
[2019-04-06 22:25:13,591] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 100500, global step 1617400: learning rate 0.0000
[2019-04-06 22:25:27,929] A3C_AGENT_WORKER-Thread-2 INFO:Local step 100500, global step 1618763: loss 0.2630
[2019-04-06 22:25:27,934] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 100500, global step 1618763: learning rate 0.0000
[2019-04-06 22:25:32,407] A3C_AGENT_WORKER-Thread-15 INFO:Local step 101000, global step 1619202: loss 0.1191
[2019-04-06 22:25:32,408] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 101000, global step 1619202: learning rate 0.0000
[2019-04-06 22:25:34,779] A3C_AGENT_WORKER-Thread-16 INFO:Local step 101500, global step 1619420: loss 2.1793
[2019-04-06 22:25:34,789] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 101500, global step 1619420: learning rate 0.0000
[2019-04-06 22:25:34,875] A3C_AGENT_WORKER-Thread-5 INFO:Local step 101500, global step 1619432: loss 2.0521
[2019-04-06 22:25:34,875] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 101500, global step 1619432: learning rate 0.0000
[2019-04-06 22:25:37,145] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:25:37,145] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:25:37,148] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run37
[2019-04-06 22:25:37,566] A3C_AGENT_WORKER-Thread-6 INFO:Local step 101500, global step 1619690: loss 2.0707
[2019-04-06 22:25:37,567] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 101500, global step 1619690: learning rate 0.0000
[2019-04-06 22:25:37,693] A3C_AGENT_WORKER-Thread-13 INFO:Local step 101500, global step 1619703: loss 2.0657
[2019-04-06 22:25:37,694] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 101500, global step 1619703: learning rate 0.0000
[2019-04-06 22:25:40,578] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 22:25:40,579] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:25:40,579] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:25:40,585] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:25:40,585] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:25:40,590] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run82
[2019-04-06 22:25:40,725] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:25:40,725] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:25:40,754] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run82
[2019-04-06 22:25:40,876] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run82
[2019-04-06 22:28:16,492] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 22:28:35,275] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 22:28:39,188] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 22:28:40,211] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1620000, evaluation results [1620000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 22:28:41,051] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2865091e-12 7.1335444e-11 2.2335046e-12 3.2015093e-06 1.1748480e-12
 9.9999678e-01 4.1683449e-12], sum to 1.0000
[2019-04-06 22:28:41,052] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2421
[2019-04-06 22:28:41,314] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 37.0, 0.0, 0.0, 26.0, 24.55325106825936, 0.3453595654161898, 1.0, 1.0, 161834.66334123877], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2833200.0000, 
sim time next is 2835000.0000, 
raw observation next is [2.5, 40.5, 0.0, 0.0, 26.0, 25.41454799667424, 0.3943384816616369, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.5318559556786704, 0.405, 0.0, 0.0, 0.6666666666666666, 0.6178789997228534, 0.6314461605538789, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4776918], dtype=float32), -0.7614618]. 
=============================================
[2019-04-06 22:28:41,347] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[83.63307]
 [82.76352]
 [82.07629]
 [82.70285]
 [82.97775]], R is [[83.50628662]
 [82.90058899]
 [82.44805908]
 [82.62358093]
 [82.79734802]].
[2019-04-06 22:28:42,230] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3985667e-14 5.9419900e-11 1.0453700e-12 3.1711193e-06 6.3562030e-14
 9.9999678e-01 6.2551052e-14], sum to 1.0000
[2019-04-06 22:28:42,230] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2669
[2019-04-06 22:28:42,307] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 68.0, 0.0, 0.0, 26.0, 25.15241524623183, 0.325212433620619, 0.0, 1.0, 41121.48865414], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3907800.0000, 
sim time next is 3909600.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.92334859511042, 0.2943688333331356, 0.0, 1.0, 41583.73043979561], 
processed observation next is [1.0, 0.2608695652173913, 0.296398891966759, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5769457162592015, 0.5981229444443785, 0.0, 1.0, 0.1980177639990267], 
reward next is 0.8020, 
noisyNet noise sample is [array([-0.13677147], dtype=float32), -1.0278267]. 
=============================================
[2019-04-06 22:28:49,159] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.23604994e-14 4.72796143e-11 1.90560905e-13 1.43818193e-06
 1.06767775e-14 9.99998569e-01 6.06151075e-14], sum to 1.0000
[2019-04-06 22:28:49,159] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3000
[2019-04-06 22:28:49,224] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.1, 67.0, 0.0, 0.0, 26.0, 25.33682378377229, 0.4206465845842804, 0.0, 1.0, 54357.79916091772], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4590000.0000, 
sim time next is 4591800.0000, 
raw observation next is [-1.3, 68.0, 0.0, 0.0, 26.0, 25.47147141795237, 0.4330141496297703, 0.0, 1.0, 25472.813883864572], 
processed observation next is [1.0, 0.13043478260869565, 0.42659279778393355, 0.68, 0.0, 0.0, 0.6666666666666666, 0.6226226181626974, 0.6443380498765902, 0.0, 1.0, 0.12129911373268844], 
reward next is 0.8787, 
noisyNet noise sample is [array([-0.2626166], dtype=float32), -0.24853349]. 
=============================================
[2019-04-06 22:28:49,520] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0590442e-14 2.7253085e-12 2.3967805e-14 5.9212351e-07 1.1940660e-14
 9.9999940e-01 7.8939540e-14], sum to 1.0000
[2019-04-06 22:28:49,523] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3738
[2019-04-06 22:28:49,590] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 89.5, 0.0, 0.0, 26.0, 25.14131986254537, 0.2856191298078692, 0.0, 1.0, 52151.97864500693], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2863800.0000, 
sim time next is 2865600.0000, 
raw observation next is [1.0, 93.0, 0.0, 0.0, 26.0, 24.92106868093198, 0.2595991851994986, 0.0, 1.0, 54972.14334263949], 
processed observation next is [1.0, 0.17391304347826086, 0.4903047091412743, 0.93, 0.0, 0.0, 0.6666666666666666, 0.5767557234109985, 0.5865330617331662, 0.0, 1.0, 0.26177211115542615], 
reward next is 0.7382, 
noisyNet noise sample is [array([1.5073532], dtype=float32), 0.5069147]. 
=============================================
[2019-04-06 22:28:49,783] A3C_AGENT_WORKER-Thread-12 INFO:Local step 101500, global step 1621482: loss 2.0791
[2019-04-06 22:28:49,784] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 101500, global step 1621482: learning rate 0.0000
[2019-04-06 22:28:49,885] A3C_AGENT_WORKER-Thread-4 INFO:Local step 100500, global step 1621495: loss 0.3285
[2019-04-06 22:28:49,885] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 100500, global step 1621495: learning rate 0.0000
[2019-04-06 22:28:50,185] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.3458104e-15 5.6170546e-12 5.0734606e-13 1.3185964e-06 3.0987040e-15
 9.9999869e-01 2.9438867e-13], sum to 1.0000
[2019-04-06 22:28:50,185] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9226
[2019-04-06 22:28:50,381] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 100.0, 0.0, 0.0, 26.0, 24.63065127276424, 0.287322960705285, 1.0, 1.0, 59736.668562683575], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 936000.0000, 
sim time next is 937800.0000, 
raw observation next is [5.0, 100.0, 0.0, 0.0, 26.0, 24.70086450921662, 0.336654431689496, 0.0, 1.0, 106418.44096917701], 
processed observation next is [1.0, 0.8695652173913043, 0.6011080332409973, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5584053757680515, 0.6122181438964986, 0.0, 1.0, 0.5067544808056048], 
reward next is 0.4932, 
noisyNet noise sample is [array([-0.07665162], dtype=float32), 0.10703036]. 
=============================================
[2019-04-06 22:28:50,555] A3C_AGENT_WORKER-Thread-18 INFO:Local step 101500, global step 1621598: loss 1.8810
[2019-04-06 22:28:50,556] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 101500, global step 1621598: learning rate 0.0000
[2019-04-06 22:29:00,711] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:29:00,711] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:29:00,714] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run37
[2019-04-06 22:29:02,278] A3C_AGENT_WORKER-Thread-19 INFO:Local step 101500, global step 1623613: loss 2.1501
[2019-04-06 22:29:02,279] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 101500, global step 1623613: learning rate 0.0000
[2019-04-06 22:29:02,499] A3C_AGENT_WORKER-Thread-14 INFO:Local step 100500, global step 1623653: loss 0.3185
[2019-04-06 22:29:02,499] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 100500, global step 1623653: learning rate 0.0000
[2019-04-06 22:29:13,145] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4091238e-15 8.7564738e-12 4.1577364e-14 3.6012307e-07 1.8961536e-15
 9.9999964e-01 2.6744450e-14], sum to 1.0000
[2019-04-06 22:29:13,146] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2028
[2019-04-06 22:29:13,191] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.8, 100.0, 0.0, 0.0, 26.0, 25.24630562746479, 0.2965724311340123, 0.0, 1.0, 53985.26025138548], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3126600.0000, 
sim time next is 3128400.0000, 
raw observation next is [3.0, 100.0, 0.0, 0.0, 26.0, 25.28959355688119, 0.3264403287357778, 0.0, 1.0, 53918.30324765042], 
processed observation next is [1.0, 0.21739130434782608, 0.5457063711911359, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6074661297400992, 0.608813442911926, 0.0, 1.0, 0.25675382498881155], 
reward next is 0.7432, 
noisyNet noise sample is [array([-0.4341787], dtype=float32), -0.1069448]. 
=============================================
[2019-04-06 22:29:13,493] A3C_AGENT_WORKER-Thread-20 INFO:Local step 101000, global step 1625288: loss 0.1088
[2019-04-06 22:29:13,500] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 101000, global step 1625288: learning rate 0.0000
[2019-04-06 22:29:15,439] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:29:15,440] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:29:15,443] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run37
[2019-04-06 22:29:16,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:29:16,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:29:16,141] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run37
[2019-04-06 22:29:17,694] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:29:17,694] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:29:17,698] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run37
[2019-04-06 22:29:19,700] A3C_AGENT_WORKER-Thread-10 INFO:Local step 101000, global step 1626219: loss 0.1076
[2019-04-06 22:29:19,705] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 101000, global step 1626219: learning rate 0.0000
[2019-04-06 22:29:20,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:29:20,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:29:20,174] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run37
[2019-04-06 22:29:20,563] A3C_AGENT_WORKER-Thread-15 INFO:Local step 101500, global step 1626317: loss 2.0247
[2019-04-06 22:29:20,577] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 101500, global step 1626317: learning rate 0.0000
[2019-04-06 22:29:26,648] A3C_AGENT_WORKER-Thread-2 INFO:Local step 101000, global step 1627034: loss 0.0924
[2019-04-06 22:29:26,661] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 101000, global step 1627034: learning rate 0.0000
[2019-04-06 22:29:27,467] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.9733194e-14 3.1630941e-12 2.9055913e-13 1.0522921e-06 2.1394136e-14
 9.9999893e-01 8.7725739e-14], sum to 1.0000
[2019-04-06 22:29:27,467] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4236
[2019-04-06 22:29:27,529] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 92.0, 196.0, 6.0, 26.0, 25.93074202448354, 0.6042725059028456, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4455000.0000, 
sim time next is 4456800.0000, 
raw observation next is [0.0, 92.0, 140.5, 3.0, 26.0, 26.17012067416086, 0.6218168057309964, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.46260387811634357, 0.92, 0.4683333333333333, 0.0033149171270718232, 0.6666666666666666, 0.680843389513405, 0.7072722685769989, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.37623712], dtype=float32), -0.46358493]. 
=============================================
[2019-04-06 22:29:29,987] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:29:29,988] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:29:29,991] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run37
[2019-04-06 22:29:30,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:29:30,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:29:30,056] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run37
[2019-04-06 22:29:36,365] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.9555341e-13 6.0866354e-11 5.7104720e-12 1.1329576e-05 1.1871124e-12
 9.9998868e-01 5.1572077e-13], sum to 1.0000
[2019-04-06 22:29:36,366] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7455
[2019-04-06 22:29:36,408] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 75.0, 0.0, 0.0, 26.0, 23.31655173008694, -0.06945395021849109, 0.0, 1.0, 44891.3283310394], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 108000.0000, 
sim time next is 109800.0000, 
raw observation next is [-7.0, 71.5, 0.0, 0.0, 26.0, 23.23874929656838, -0.08962474816215937, 0.0, 1.0, 45437.14863550841], 
processed observation next is [1.0, 0.2608695652173913, 0.2686980609418283, 0.715, 0.0, 0.0, 0.6666666666666666, 0.4365624413806983, 0.4701250839459468, 0.0, 1.0, 0.21636737445480198], 
reward next is 0.7836, 
noisyNet noise sample is [array([1.7275789], dtype=float32), -0.06561269]. 
=============================================
[2019-04-06 22:29:41,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:29:41,174] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:29:41,182] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run37
[2019-04-06 22:29:45,336] A3C_AGENT_WORKER-Thread-4 INFO:Local step 101000, global step 1629365: loss 0.0978
[2019-04-06 22:29:45,337] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 101000, global step 1629365: learning rate 0.0000
[2019-04-06 22:29:47,251] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3497091e-11 1.9932633e-09 2.6477888e-11 1.4856591e-05 1.7445391e-11
 9.9998510e-01 4.3680495e-10], sum to 1.0000
[2019-04-06 22:29:47,252] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6111
[2019-04-06 22:29:47,301] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.2, 55.0, 0.0, 0.0, 26.0, 23.60675253345813, -0.0625677641537301, 0.0, 1.0, 45386.74083830506], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 435600.0000, 
sim time next is 437400.0000, 
raw observation next is [-11.2, 55.0, 0.0, 0.0, 26.0, 23.55342212076916, -0.09114813129938894, 0.0, 1.0, 45493.136780384775], 
processed observation next is [1.0, 0.043478260869565216, 0.15235457063711913, 0.55, 0.0, 0.0, 0.6666666666666666, 0.4627851767307633, 0.4696172895668704, 0.0, 1.0, 0.21663398466849892], 
reward next is 0.7834, 
noisyNet noise sample is [array([-0.90682924], dtype=float32), -0.9660267]. 
=============================================
[2019-04-06 22:29:52,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1928348e-11 3.1787930e-09 6.5278054e-11 3.3681739e-05 1.2002796e-12
 9.9996626e-01 3.0511114e-11], sum to 1.0000
[2019-04-06 22:29:52,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1942
[2019-04-06 22:29:52,917] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.6, 60.0, 96.5, 585.0, 26.0, 25.77392521042561, 0.3553999979941998, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 298800.0000, 
sim time next is 300600.0000, 
raw observation next is [-10.6, 54.5, 106.0, 658.0, 26.0, 25.60696828729495, 0.3511097430751344, 1.0, 1.0, 66290.45245113304], 
processed observation next is [1.0, 0.4782608695652174, 0.1689750692520776, 0.545, 0.35333333333333333, 0.7270718232044199, 0.6666666666666666, 0.6339140239412459, 0.6170365810250448, 1.0, 1.0, 0.3156688211958716], 
reward next is 0.6843, 
noisyNet noise sample is [array([1.2373378], dtype=float32), 0.5919485]. 
=============================================
[2019-04-06 22:29:57,628] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.4013869e-11 2.8245133e-09 2.3205356e-11 8.2448171e-04 4.0332325e-12
 9.9917549e-01 3.4255609e-11], sum to 1.0000
[2019-04-06 22:29:57,628] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9015
[2019-04-06 22:29:57,792] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-14.5, 66.0, 55.0, 733.5, 26.0, 25.67645539870376, 0.3260090935012018, 1.0, 1.0, 54803.709824213096], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 381600.0000, 
sim time next is 383400.0000, 
raw observation next is [-13.95, 63.0, 71.0, 729.0, 26.0, 25.92727534350503, 0.3623003975700971, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.07617728531855956, 0.63, 0.23666666666666666, 0.8055248618784531, 0.6666666666666666, 0.6606062786254192, 0.6207667991900324, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.36645734], dtype=float32), 0.15292637]. 
=============================================
[2019-04-06 22:29:59,031] A3C_AGENT_WORKER-Thread-14 INFO:Local step 101000, global step 1631159: loss 0.0720
[2019-04-06 22:29:59,031] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 101000, global step 1631159: learning rate 0.0000
[2019-04-06 22:29:59,072] A3C_AGENT_WORKER-Thread-20 INFO:Local step 101500, global step 1631165: loss 2.0436
[2019-04-06 22:29:59,073] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 101500, global step 1631165: learning rate 0.0000
[2019-04-06 22:29:59,309] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:29:59,309] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:29:59,312] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run37
[2019-04-06 22:30:05,213] A3C_AGENT_WORKER-Thread-10 INFO:Local step 101500, global step 1632045: loss 2.0242
[2019-04-06 22:30:05,215] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 101500, global step 1632045: learning rate 0.0000
[2019-04-06 22:30:12,606] A3C_AGENT_WORKER-Thread-2 INFO:Local step 101500, global step 1633077: loss 1.9619
[2019-04-06 22:30:12,606] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 101500, global step 1633077: learning rate 0.0000
[2019-04-06 22:30:29,445] A3C_AGENT_WORKER-Thread-4 INFO:Local step 101500, global step 1635618: loss 1.8992
[2019-04-06 22:30:29,451] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 101500, global step 1635618: learning rate 0.0000
[2019-04-06 22:30:35,302] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4610530e-13 4.3166182e-11 3.5639945e-13 6.7824834e-07 9.3309941e-13
 9.9999928e-01 1.9483316e-13], sum to 1.0000
[2019-04-06 22:30:35,302] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6998
[2019-04-06 22:30:35,395] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 80.0, 0.0, 0.0, 26.0, 24.65257446765129, 0.2233866981183018, 0.0, 1.0, 39911.69475178362], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 865800.0000, 
sim time next is 867600.0000, 
raw observation next is [-2.3, 80.0, 0.0, 0.0, 26.0, 24.7707525715668, 0.2270035616234316, 0.0, 1.0, 39567.908849321764], 
processed observation next is [1.0, 0.043478260869565216, 0.3988919667590028, 0.8, 0.0, 0.0, 0.6666666666666666, 0.5642293809639, 0.5756678538744772, 0.0, 1.0, 0.1884186135681989], 
reward next is 0.8116, 
noisyNet noise sample is [array([-0.06240001], dtype=float32), 0.49041316]. 
=============================================
[2019-04-06 22:30:36,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:30:36,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:30:36,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run37
[2019-04-06 22:30:47,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:30:47,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:30:47,604] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run37
[2019-04-06 22:30:49,672] A3C_AGENT_WORKER-Thread-14 INFO:Local step 101500, global step 1637511: loss 1.8889
[2019-04-06 22:30:49,674] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 101500, global step 1637511: learning rate 0.0000
[2019-04-06 22:30:58,923] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9983139e-13 1.9774999e-11 1.3869876e-13 3.0544263e-05 1.5049406e-13
 9.9996948e-01 6.9964888e-14], sum to 1.0000
[2019-04-06 22:30:58,924] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4842
[2019-04-06 22:30:59,333] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 26.0, 25.13535902365071, 0.2843974993990245, 1.0, 1.0, 44847.20204643944], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 842400.0000, 
sim time next is 844200.0000, 
raw observation next is [-3.9, 84.0, 0.0, 0.0, 26.0, 24.92608742367739, 0.269878009129065, 1.0, 1.0, 88593.04162227332], 
processed observation next is [1.0, 0.782608695652174, 0.3545706371191136, 0.84, 0.0, 0.0, 0.6666666666666666, 0.5771739519731159, 0.589959336376355, 1.0, 1.0, 0.4218716267727301], 
reward next is 0.5781, 
noisyNet noise sample is [array([-1.298794], dtype=float32), 0.797834]. 
=============================================
[2019-04-06 22:31:00,070] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:31:00,070] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:31:00,074] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run37
[2019-04-06 22:31:15,549] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-06 22:31:15,550] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:31:15,550] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:31:15,563] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:31:15,566] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:31:15,571] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run83
[2019-04-06 22:31:15,627] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run83
[2019-04-06 22:31:15,655] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:31:15,655] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:31:15,661] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run83
[2019-04-06 22:33:51,540] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3885 79967197.3248 535.2671
[2019-04-06 22:34:10,398] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 22:34:12,972] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 22:34:13,996] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1640000, evaluation results [1640000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.388471443006, 79967197.3248232, 535.2671102210136, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 22:34:20,842] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0000494e-14 5.4075435e-11 8.8996159e-14 8.2645562e-07 2.7845391e-13
 9.9999917e-01 3.6403373e-13], sum to 1.0000
[2019-04-06 22:34:20,842] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3165
[2019-04-06 22:34:20,919] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 92.0, 0.0, 0.0, 26.0, 25.04753078131193, 0.3208828846334599, 0.0, 1.0, 119840.40823568609], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3094200.0000, 
sim time next is 3096000.0000, 
raw observation next is [-1.0, 92.0, 0.0, 0.0, 26.0, 25.47446964913158, 0.3717866900861554, 0.0, 1.0, 39764.74517463327], 
processed observation next is [0.0, 0.8695652173913043, 0.4349030470914128, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6228724707609651, 0.6239288966953852, 0.0, 1.0, 0.1893559294030156], 
reward next is 0.8106, 
noisyNet noise sample is [array([-1.4367406], dtype=float32), -0.28843036]. 
=============================================
[2019-04-06 22:34:20,925] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[84.304596]
 [82.668625]
 [81.60741 ]
 [80.46533 ]
 [79.45513 ]], R is [[85.19132996]
 [84.76874542]
 [84.75635529]
 [84.73814392]
 [84.64981079]].
[2019-04-06 22:34:22,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:34:22,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:34:22,872] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run37
[2019-04-06 22:34:24,406] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.8226418e-12 3.1519451e-09 2.9497522e-11 8.7775215e-06 2.0866976e-12
 9.9999118e-01 1.0595002e-11], sum to 1.0000
[2019-04-06 22:34:24,406] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3946
[2019-04-06 22:34:24,644] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.55, 68.5, 0.0, 0.0, 26.0, 22.70203702887871, -0.1458374444346605, 1.0, 1.0, 151243.40859986702], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 286200.0000, 
sim time next is 288000.0000, 
raw observation next is [-12.8, 70.0, 15.0, 205.5, 26.0, 24.41710840335185, 0.1191061538683925, 1.0, 1.0, 123983.71667498826], 
processed observation next is [1.0, 0.34782608695652173, 0.1080332409972299, 0.7, 0.05, 0.22707182320441988, 0.6666666666666666, 0.5347590336126542, 0.5397020512894641, 1.0, 1.0, 0.5903986508332775], 
reward next is 0.4096, 
noisyNet noise sample is [array([1.7100308], dtype=float32), 0.8161866]. 
=============================================
[2019-04-06 22:34:24,648] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.84521]
 [72.82906]
 [73.63186]
 [74.38621]
 [75.17298]], R is [[75.11832428]
 [74.64693451]
 [74.67227173]
 [74.69777679]
 [74.72306824]].
[2019-04-06 22:34:26,178] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2937377e-12 6.2977856e-10 5.9796668e-12 5.8261918e-05 1.0809140e-12
 9.9994171e-01 9.3016176e-13], sum to 1.0000
[2019-04-06 22:34:26,178] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5674
[2019-04-06 22:34:26,219] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 71.0, 0.0, 0.0, 26.0, 23.80262745018853, -0.01094306316952564, 0.0, 1.0, 41635.64837381444], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 795600.0000, 
sim time next is 797400.0000, 
raw observation next is [-7.3, 71.0, 0.0, 0.0, 26.0, 23.63440609081136, -0.03996473787269585, 0.0, 1.0, 41911.420693352586], 
processed observation next is [1.0, 0.21739130434782608, 0.26038781163434904, 0.71, 0.0, 0.0, 0.6666666666666666, 0.4695338409009467, 0.48667842070910133, 0.0, 1.0, 0.19957819377786945], 
reward next is 0.8004, 
noisyNet noise sample is [array([0.16134161], dtype=float32), 0.47340593]. 
=============================================
[2019-04-06 22:34:37,496] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:34:37,496] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:34:37,500] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run37
[2019-04-06 22:35:10,719] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.7985661e-12 1.0211600e-10 9.0361372e-13 2.1985738e-06 4.3511939e-13
 9.9999785e-01 1.8812966e-12], sum to 1.0000
[2019-04-06 22:35:10,728] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9528
[2019-04-06 22:35:11,021] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 75.0, 0.0, 0.0, 26.0, 23.92722970640725, 0.1457399139942662, 1.0, 1.0, 149022.33611456558], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2187000.0000, 
sim time next is 2188800.0000, 
raw observation next is [-5.6, 75.0, 21.5, 131.0, 26.0, 25.49604865484374, 0.3471602717850472, 1.0, 1.0, 42801.183560628], 
processed observation next is [1.0, 0.34782608695652173, 0.30747922437673136, 0.75, 0.07166666666666667, 0.14475138121546963, 0.6666666666666666, 0.6246707212369783, 0.6157200905950158, 1.0, 1.0, 0.20381515981251427], 
reward next is 0.7962, 
noisyNet noise sample is [array([-2.008065], dtype=float32), -1.032903]. 
=============================================
[2019-04-06 22:35:29,623] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.3697702e-12 5.5315041e-10 3.1166753e-11 1.1040848e-05 3.6457336e-13
 9.9998891e-01 1.8182459e-11], sum to 1.0000
[2019-04-06 22:35:29,623] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4357
[2019-04-06 22:35:29,770] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 60.0, 131.5, 74.5, 26.0, 24.91552611872758, 0.235048749220713, 0.0, 1.0, 27635.64620754932], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 655200.0000, 
sim time next is 657000.0000, 
raw observation next is [-0.8999999999999999, 57.0, 81.0, 56.0, 26.0, 24.88794578405737, 0.2247426428662101, 0.0, 1.0, 40726.81442874246], 
processed observation next is [0.0, 0.6086956521739131, 0.43767313019390586, 0.57, 0.27, 0.061878453038674036, 0.6666666666666666, 0.5739954820047807, 0.5749142142887367, 0.0, 1.0, 0.19393721156544028], 
reward next is 0.8061, 
noisyNet noise sample is [array([0.26571378], dtype=float32), 0.9221912]. 
=============================================
[2019-04-06 22:35:29,773] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[77.51193]
 [77.83062]
 [77.53121]
 [77.33263]
 [77.4377 ]], R is [[77.30787659]
 [77.40319824]
 [77.49107361]
 [77.5283432 ]
 [77.58378601]].
[2019-04-06 22:35:48,516] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7940475e-12 4.5666249e-11 2.5207310e-12 5.4974626e-06 2.7803018e-13
 9.9999452e-01 4.7835984e-12], sum to 1.0000
[2019-04-06 22:35:48,516] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6954
[2019-04-06 22:35:48,571] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 47.0, 125.0, 763.0, 26.0, 26.02819598106496, 0.4536780886750782, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2806200.0000, 
sim time next is 2808000.0000, 
raw observation next is [2.0, 44.0, 151.5, 724.0, 26.0, 25.91312331825317, 0.4422248700662929, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.518005540166205, 0.44, 0.505, 0.8, 0.6666666666666666, 0.6594269431877642, 0.6474082900220977, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.08396944], dtype=float32), -1.9733939]. 
=============================================
[2019-04-06 22:35:48,577] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[82.20002]
 [81.8205 ]
 [81.50898]
 [80.97462]
 [80.80436]], R is [[82.76266479]
 [82.93503571]
 [83.10568237]
 [83.27462769]
 [83.44187927]].
[2019-04-06 22:35:56,160] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.7853275e-12 1.7050221e-10 1.3953207e-12 7.1530449e-06 3.2935599e-12
 9.9999285e-01 8.1863847e-12], sum to 1.0000
[2019-04-06 22:35:56,161] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3593
[2019-04-06 22:35:56,347] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 59.0, 0.0, 0.0, 26.0, 25.11392675087005, 0.4170734548615414, 0.0, 1.0, 67984.29490584935], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2750400.0000, 
sim time next is 2752200.0000, 
raw observation next is [-5.5, 61.5, 0.0, 0.0, 26.0, 25.20103272005189, 0.4414903568379375, 0.0, 1.0, 103863.54905639107], 
processed observation next is [1.0, 0.8695652173913043, 0.3102493074792244, 0.615, 0.0, 0.0, 0.6666666666666666, 0.6000860600043243, 0.6471634522793125, 0.0, 1.0, 0.49458832883995746], 
reward next is 0.5054, 
noisyNet noise sample is [array([0.40911868], dtype=float32), -1.2996365]. 
=============================================
[2019-04-06 22:35:57,235] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8637995e-13 1.3683644e-10 5.4017715e-12 1.5476537e-05 9.0112969e-14
 9.9998450e-01 5.3555825e-13], sum to 1.0000
[2019-04-06 22:35:57,236] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4121
[2019-04-06 22:35:57,282] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.27949027176869, 0.4192801446368056, 0.0, 1.0, 43701.25022525503], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3801600.0000, 
sim time next is 3803400.0000, 
raw observation next is [-3.5, 74.0, 0.0, 0.0, 26.0, 25.22037803129468, 0.4140022456962431, 0.0, 1.0, 43790.57582568831], 
processed observation next is [1.0, 0.0, 0.36565096952908593, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6016981692745565, 0.6380007485654143, 0.0, 1.0, 0.20852655155089672], 
reward next is 0.7915, 
noisyNet noise sample is [array([-0.21844964], dtype=float32), 1.0065032]. 
=============================================
[2019-04-06 22:35:59,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:35:59,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:35:59,280] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run38
[2019-04-06 22:36:00,970] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4638212e-13 8.1047502e-11 2.1082643e-13 7.8391844e-07 3.5389037e-13
 9.9999917e-01 1.9515448e-13], sum to 1.0000
[2019-04-06 22:36:00,972] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5960
[2019-04-06 22:36:01,134] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 37.0, 0.0, 0.0, 26.0, 24.55325106825936, 0.3453595654161898, 1.0, 1.0, 161834.66334123877], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2833200.0000, 
sim time next is 2835000.0000, 
raw observation next is [2.5, 40.5, 0.0, 0.0, 26.0, 25.41454799667424, 0.3943384816616369, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.5318559556786704, 0.405, 0.0, 0.0, 0.6666666666666666, 0.6178789997228534, 0.6314461605538789, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.411678], dtype=float32), 1.4774412]. 
=============================================
[2019-04-06 22:36:01,138] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[81.85689 ]
 [81.011765]
 [80.33333 ]
 [80.97694 ]
 [81.24071 ]], R is [[81.74355316]
 [81.15547943]
 [80.72039795]
 [80.91319275]
 [81.10406494]].
[2019-04-06 22:36:04,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2505296e-11 1.4541782e-09 6.8159568e-11 8.9367468e-06 6.7914012e-12
 9.9999106e-01 6.1450560e-11], sum to 1.0000
[2019-04-06 22:36:04,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8764
[2019-04-06 22:36:04,653] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 61.0, 0.0, 0.0, 26.0, 23.46585376881198, -0.09378784244687231, 0.0, 1.0, 44397.08943725665], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2435400.0000, 
sim time next is 2437200.0000, 
raw observation next is [-8.4, 61.0, 0.0, 0.0, 26.0, 23.35788628780906, -0.1141751997603622, 0.0, 1.0, 44402.31144511298], 
processed observation next is [0.0, 0.21739130434782608, 0.2299168975069252, 0.61, 0.0, 0.0, 0.6666666666666666, 0.44649052398408823, 0.4619416000798793, 0.0, 1.0, 0.2114395783100618], 
reward next is 0.7886, 
noisyNet noise sample is [array([-1.2793525], dtype=float32), 0.23542184]. 
=============================================
[2019-04-06 22:36:21,995] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.1813627e-12 6.4358803e-11 1.1049159e-11 6.2123681e-06 5.6248476e-14
 9.9999380e-01 8.5245206e-13], sum to 1.0000
[2019-04-06 22:36:21,995] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0030
[2019-04-06 22:36:22,127] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.0, 76.0, 0.0, 0.0, 26.0, 24.48140527495197, 0.2209205188449593, 0.0, 1.0, 43747.47639264729], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3301200.0000, 
sim time next is 3303000.0000, 
raw observation next is [-10.5, 76.0, 0.0, 0.0, 26.0, 24.39886148542573, 0.1883777948123616, 0.0, 1.0, 43630.78174125867], 
processed observation next is [1.0, 0.21739130434782608, 0.17174515235457063, 0.76, 0.0, 0.0, 0.6666666666666666, 0.5332384571188108, 0.5627925982707872, 0.0, 1.0, 0.207765627339327], 
reward next is 0.7922, 
noisyNet noise sample is [array([-0.01945621], dtype=float32), 0.066524334]. 
=============================================
[2019-04-06 22:36:22,139] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[79.683495]
 [80.18954 ]
 [80.60113 ]
 [81.08959 ]
 [81.55713 ]], R is [[79.11167145]
 [79.11223602]
 [79.11237335]
 [79.11174011]
 [79.11140442]].
[2019-04-06 22:36:24,363] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7777899e-13 1.0900457e-10 3.1169777e-13 7.8406049e-07 1.6384517e-13
 9.9999917e-01 2.5819074e-13], sum to 1.0000
[2019-04-06 22:36:24,364] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6209
[2019-04-06 22:36:24,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2343624e-13 4.1931875e-11 2.1609301e-12 1.0583448e-06 1.0125483e-13
 9.9999893e-01 1.7503476e-13], sum to 1.0000
[2019-04-06 22:36:24,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7022
[2019-04-06 22:36:24,529] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 42.0, 115.0, 823.5, 26.0, 25.29318034090307, 0.4526143685489974, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3675600.0000, 
sim time next is 3677400.0000, 
raw observation next is [5.5, 42.5, 113.0, 818.0, 26.0, 25.29794716278786, 0.4564897372560201, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.6149584487534627, 0.425, 0.37666666666666665, 0.9038674033149171, 0.6666666666666666, 0.6081622635656551, 0.6521632457520067, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1069741], dtype=float32), 2.152924]. 
=============================================
[2019-04-06 22:36:24,802] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8999999999999999, 57.0, 0.0, 0.0, 26.0, 25.16842581036736, 0.3464219514111084, 1.0, 1.0, 22133.94453713264], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2658600.0000, 
sim time next is 2660400.0000, 
raw observation next is [-1.2, 60.0, 0.0, 0.0, 26.0, 25.06487058647085, 0.393459150681809, 1.0, 1.0, 79228.54477009775], 
processed observation next is [1.0, 0.8260869565217391, 0.42936288088642666, 0.6, 0.0, 0.0, 0.6666666666666666, 0.5887392155392375, 0.6311530502272696, 1.0, 1.0, 0.3772787846195131], 
reward next is 0.6227, 
noisyNet noise sample is [array([-0.33266392], dtype=float32), -0.75025886]. 
=============================================
[2019-04-06 22:36:39,373] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1465853e-13 2.1902779e-12 1.4322383e-13 2.9312977e-07 1.9474101e-14
 9.9999976e-01 2.0247467e-14], sum to 1.0000
[2019-04-06 22:36:39,374] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0253
[2019-04-06 22:36:39,597] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 92.0, 93.0, 511.5, 26.0, 26.00461446457811, 0.6064739036144732, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3229200.0000, 
sim time next is 3231000.0000, 
raw observation next is [-3.0, 92.0, 101.0, 653.0, 26.0, 26.17347763641865, 0.6515194117614732, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.92, 0.33666666666666667, 0.7215469613259669, 0.6666666666666666, 0.6811231363682207, 0.7171731372538245, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5806174], dtype=float32), 0.30115667]. 
=============================================
[2019-04-06 22:36:39,604] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[90.21545 ]
 [90.075806]
 [89.937805]
 [89.66363 ]
 [89.46751 ]], R is [[90.46485901]
 [90.56021118]
 [90.65460968]
 [90.74806213]
 [90.77531433]].
[2019-04-06 22:36:52,517] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 22:36:52,560] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:36:52,560] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:36:52,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run84
[2019-04-06 22:36:52,626] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:36:52,627] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:36:52,631] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run84
[2019-04-06 22:36:52,669] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:36:52,669] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:36:52,683] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run84
[2019-04-06 22:39:31,074] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 22:39:52,589] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 22:39:54,303] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 22:39:55,325] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1660000, evaluation results [1660000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 22:39:56,416] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8051355e-13 7.5734731e-11 5.2290437e-13 7.7715441e-07 3.6793233e-13
 9.9999917e-01 3.2776050e-13], sum to 1.0000
[2019-04-06 22:39:56,418] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6947
[2019-04-06 22:39:56,653] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 87.0, 108.0, 0.0, 26.0, 24.89826071986597, 0.3356726442632931, 0.0, 1.0, 51509.525172222035], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1767600.0000, 
sim time next is 1769400.0000, 
raw observation next is [-2.3, 85.0, 119.0, 0.0, 26.0, 24.92737229551742, 0.3481253028801684, 0.0, 1.0, 43448.9252586561], 
processed observation next is [0.0, 0.4782608695652174, 0.3988919667590028, 0.85, 0.39666666666666667, 0.0, 0.6666666666666666, 0.5772810246264516, 0.6160417676267228, 0.0, 1.0, 0.20689964408883857], 
reward next is 0.7931, 
noisyNet noise sample is [array([1.1667142], dtype=float32), 0.37970638]. 
=============================================
[2019-04-06 22:40:20,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:40:20,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:40:20,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run38
[2019-04-06 22:40:21,635] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9260327e-12 1.5589086e-10 1.0659945e-11 3.4224686e-06 7.0107245e-12
 9.9999654e-01 8.9993221e-12], sum to 1.0000
[2019-04-06 22:40:21,635] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4391
[2019-04-06 22:40:21,670] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 28.0, 171.0, 482.0, 26.0, 25.41834293453547, 0.3428142724455684, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2554200.0000, 
sim time next is 2556000.0000, 
raw observation next is [3.8, 26.0, 165.0, 378.5, 26.0, 25.72783229577758, 0.3669711005998975, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5678670360110805, 0.26, 0.55, 0.41823204419889504, 0.6666666666666666, 0.6439860246481318, 0.6223237001999659, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06760264], dtype=float32), 0.7930488]. 
=============================================
[2019-04-06 22:40:21,686] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[81.16511 ]
 [80.849754]
 [80.63068 ]
 [80.91473 ]
 [81.00316 ]], R is [[80.81757355]
 [81.00939941]
 [81.19930267]
 [81.38731384]
 [81.57344055]].
[2019-04-06 22:40:47,840] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:40:47,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:40:47,844] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run38
[2019-04-06 22:40:56,182] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.8766286e-13 7.6463252e-11 2.8536487e-12 4.2821848e-06 2.2207828e-13
 9.9999571e-01 9.8009881e-12], sum to 1.0000
[2019-04-06 22:40:56,183] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8510
[2019-04-06 22:40:56,272] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 49.0, 134.5, 39.0, 26.0, 25.8239492257968, 0.3076850075449724, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2541600.0000, 
sim time next is 2543400.0000, 
raw observation next is [-0.8999999999999999, 48.0, 133.0, 45.0, 26.0, 25.79521464578109, 0.3001929568921549, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.43767313019390586, 0.48, 0.44333333333333336, 0.049723756906077346, 0.6666666666666666, 0.6496012204817575, 0.6000643189640517, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3146738], dtype=float32), -1.4771814]. 
=============================================
[2019-04-06 22:40:56,898] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5036990e-13 7.5703777e-11 8.6103184e-13 1.4583245e-06 2.1371300e-13
 9.9999857e-01 4.8915288e-13], sum to 1.0000
[2019-04-06 22:40:56,898] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1689
[2019-04-06 22:40:57,025] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 82.0, 0.0, 0.0, 26.0, 24.99176819956359, 0.2838153664125689, 0.0, 1.0, 50599.054560289915], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3088800.0000, 
sim time next is 3090600.0000, 
raw observation next is [-0.8, 87.0, 0.0, 0.0, 26.0, 25.00175268903764, 0.2827527888802362, 0.0, 1.0, 35835.64141317395], 
processed observation next is [0.0, 0.782608695652174, 0.4404432132963989, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5834793907531367, 0.5942509296267454, 0.0, 1.0, 0.17064591149130454], 
reward next is 0.8294, 
noisyNet noise sample is [array([-1.5694897], dtype=float32), -0.76204073]. 
=============================================
[2019-04-06 22:41:02,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1835370e-12 2.5196217e-10 1.2643617e-11 2.3247037e-05 2.9763464e-14
 9.9997675e-01 1.5859700e-12], sum to 1.0000
[2019-04-06 22:41:02,494] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4673
[2019-04-06 22:41:02,533] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 29.0, 0.0, 0.0, 26.0, 25.6307144646802, 0.5378453309942116, 0.0, 1.0, 130956.6245131941], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5000400.0000, 
sim time next is 5002200.0000, 
raw observation next is [3.5, 33.0, 0.0, 0.0, 26.0, 25.69370977139023, 0.5792816883454509, 0.0, 1.0, 59512.07749713241], 
processed observation next is [1.0, 0.9130434782608695, 0.5595567867036012, 0.33, 0.0, 0.0, 0.6666666666666666, 0.6411424809491857, 0.6930938961151503, 0.0, 1.0, 0.2833908452244401], 
reward next is 0.7166, 
noisyNet noise sample is [array([0.6037853], dtype=float32), 0.4694367]. 
=============================================
[2019-04-06 22:41:03,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:41:03,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:41:03,860] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run38
[2019-04-06 22:41:06,633] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2044227e-13 6.0870857e-11 2.8373781e-12 2.8225631e-07 1.9605785e-13
 9.9999976e-01 3.9059164e-13], sum to 1.0000
[2019-04-06 22:41:06,633] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8156
[2019-04-06 22:41:06,713] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.0, 77.0, 0.0, 0.0, 26.0, 24.83977598718884, 0.3093039836941421, 0.0, 1.0, 43870.27957709655], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3294000.0000, 
sim time next is 3295800.0000, 
raw observation next is [-8.45, 77.0, 0.0, 0.0, 26.0, 24.71849180547426, 0.2914614400944307, 0.0, 1.0, 43936.932321852575], 
processed observation next is [1.0, 0.13043478260869565, 0.2285318559556787, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5598743171228552, 0.5971538133648102, 0.0, 1.0, 0.20922348724691703], 
reward next is 0.7908, 
noisyNet noise sample is [array([-0.63312954], dtype=float32), -1.8305126]. 
=============================================
[2019-04-06 22:41:06,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:41:06,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:41:06,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run38
[2019-04-06 22:41:07,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:41:07,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:41:07,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run38
[2019-04-06 22:41:07,493] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:41:07,493] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:41:07,496] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run38
[2019-04-06 22:41:15,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:41:15,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:41:15,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run38
[2019-04-06 22:41:22,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:41:22,231] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:41:22,240] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run38
[2019-04-06 22:41:24,487] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.04514874e-13 7.67593888e-12 7.64166399e-13 6.73049840e-07
 1.94313966e-13 9.99999285e-01 6.09303257e-14], sum to 1.0000
[2019-04-06 22:41:24,488] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0927
[2019-04-06 22:41:24,611] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 72.0, 101.0, 49.0, 26.0, 25.91606820323542, 0.3368556411670618, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 725400.0000, 
sim time next is 727200.0000, 
raw observation next is [-1.7, 68.0, 120.0, 58.5, 26.0, 25.94306982005574, 0.3372939402450883, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4155124653739613, 0.68, 0.4, 0.06464088397790055, 0.6666666666666666, 0.661922485004645, 0.6124313134150294, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4034231], dtype=float32), 0.016758768]. 
=============================================
[2019-04-06 22:41:31,063] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:41:31,063] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:41:31,067] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run38
[2019-04-06 22:41:44,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:41:44,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:41:44,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run38
[2019-04-06 22:41:55,847] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.5571914e-12 4.8826205e-09 1.5058028e-10 1.9969788e-05 1.9611738e-11
 9.9997997e-01 9.5126608e-11], sum to 1.0000
[2019-04-06 22:41:55,847] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8147
[2019-04-06 22:41:55,936] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.9, 50.5, 0.0, 0.0, 26.0, 23.11715966782695, -0.1991127916065451, 0.0, 1.0, 46027.787609024585], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 444600.0000, 
sim time next is 446400.0000, 
raw observation next is [-11.2, 52.0, 0.0, 0.0, 26.0, 22.89292956578316, -0.2409242260355984, 0.0, 1.0, 46298.89603337892], 
processed observation next is [1.0, 0.17391304347826086, 0.15235457063711913, 0.52, 0.0, 0.0, 0.6666666666666666, 0.40774413048193, 0.41969192465480054, 0.0, 1.0, 0.22047093349228059], 
reward next is 0.7795, 
noisyNet noise sample is [array([1.257059], dtype=float32), 0.87616843]. 
=============================================
[2019-04-06 22:41:56,893] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4180930e-13 6.6538899e-11 2.1223012e-12 2.9873900e-06 8.6054455e-13
 9.9999702e-01 2.2124904e-13], sum to 1.0000
[2019-04-06 22:41:56,893] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0381
[2019-04-06 22:41:57,004] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 71.0, 0.0, 0.0, 26.0, 23.95617247812843, 0.05982449196822043, 0.0, 1.0, 44810.475893032715], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 171000.0000, 
sim time next is 172800.0000, 
raw observation next is [-8.4, 71.0, 0.0, 0.0, 26.0, 23.83105400442642, 0.03034964524917983, 0.0, 1.0, 44645.01041405436], 
processed observation next is [1.0, 0.0, 0.2299168975069252, 0.71, 0.0, 0.0, 0.6666666666666666, 0.485921167035535, 0.5101165484163933, 0.0, 1.0, 0.21259528768597316], 
reward next is 0.7874, 
noisyNet noise sample is [array([0.7610143], dtype=float32), -0.40697694]. 
=============================================
[2019-04-06 22:42:07,405] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2058201e-14 5.2559807e-11 3.1975683e-13 1.2173918e-07 7.7677758e-15
 9.9999988e-01 3.0992471e-14], sum to 1.0000
[2019-04-06 22:42:07,433] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9169
[2019-04-06 22:42:07,508] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.3, 84.0, 142.5, 131.5, 26.0, 26.17496112394989, 0.5985749268683356, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4438800.0000, 
sim time next is 4440600.0000, 
raw observation next is [1.15, 85.0, 165.0, 31.0, 26.0, 26.23065266190838, 0.6153096442993028, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49445983379501385, 0.85, 0.55, 0.03425414364640884, 0.6666666666666666, 0.6858877218256983, 0.7051032147664342, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3970985], dtype=float32), 2.2884204]. 
=============================================
[2019-04-06 22:42:07,995] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5775764e-14 7.0422032e-12 3.4003486e-13 5.6326403e-08 1.6158217e-14
 1.0000000e+00 1.7431397e-13], sum to 1.0000
[2019-04-06 22:42:07,995] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6009
[2019-04-06 22:42:08,139] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 52.0, 187.0, 24.0, 26.0, 25.41242610805704, 0.473907574850384, 1.0, 1.0, 14862.104831587807], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4539600.0000, 
sim time next is 4541400.0000, 
raw observation next is [2.5, 50.5, 247.0, 48.0, 26.0, 25.9766021673662, 0.553821937082625, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5318559556786704, 0.505, 0.8233333333333334, 0.05303867403314917, 0.6666666666666666, 0.6647168472805166, 0.684607312360875, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6756316], dtype=float32), -0.916595]. 
=============================================
[2019-04-06 22:42:28,091] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 22:42:28,091] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:42:28,091] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:42:28,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run85
[2019-04-06 22:42:28,126] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:42:28,126] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:42:28,170] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run85
[2019-04-06 22:42:28,237] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:42:28,238] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:42:28,291] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run85
[2019-04-06 22:44:46,634] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.06842625], dtype=float32), 0.13913906]
[2019-04-06 22:44:46,634] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.0, 93.0, 0.0, 0.0, 26.0, 24.92106868093198, 0.2595991851994986, 0.0, 1.0, 54972.14334263949]
[2019-04-06 22:44:46,634] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:44:46,635] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [3.39504392e-14 1.17495944e-11 1.50848043e-13 4.37848797e-07
 1.25101735e-14 9.99999523e-01 7.28680354e-14], sampled 0.6009808893581278
[2019-04-06 22:45:07,875] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 22:45:26,642] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 22:45:27,380] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 22:45:28,404] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 1680000, evaluation results [1680000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 22:45:31,825] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3385837e-13 4.2104868e-11 3.2021662e-12 2.3964235e-08 3.2379400e-13
 1.0000000e+00 3.1118955e-13], sum to 1.0000
[2019-04-06 22:45:31,827] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8867
[2019-04-06 22:45:31,935] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 26.0, 24.31275900916256, 0.188153224704694, 0.0, 1.0, 41312.62362166322], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4771800.0000, 
sim time next is 4773600.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 26.0, 24.18012388540699, 0.1583877221927385, 0.0, 1.0, 41455.32815490031], 
processed observation next is [0.0, 0.2608695652173913, 0.296398891966759, 0.92, 0.0, 0.0, 0.6666666666666666, 0.5150103237839158, 0.5527959073975796, 0.0, 1.0, 0.19740632454714432], 
reward next is 0.8026, 
noisyNet noise sample is [array([-1.1846799], dtype=float32), -0.15894979]. 
=============================================
[2019-04-06 22:45:35,286] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.3354175e-13 1.7343563e-10 7.8782432e-12 1.3996809e-05 6.7554610e-13
 9.9998605e-01 1.1806811e-11], sum to 1.0000
[2019-04-06 22:45:35,287] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6929
[2019-04-06 22:45:35,327] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.45, 65.5, 0.0, 0.0, 26.0, 24.65519749063233, 0.2280741530499846, 0.0, 1.0, 43190.619106980565], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 772200.0000, 
sim time next is 774000.0000, 
raw observation next is [-6.7, 67.0, 0.0, 0.0, 26.0, 24.55979689713424, 0.2067274320862237, 0.0, 1.0, 42779.91635492639], 
processed observation next is [1.0, 1.0, 0.2770083102493075, 0.67, 0.0, 0.0, 0.6666666666666666, 0.5466497414278534, 0.5689091440287413, 0.0, 1.0, 0.20371388740441138], 
reward next is 0.7963, 
noisyNet noise sample is [array([-0.31954116], dtype=float32), -0.725989]. 
=============================================
[2019-04-06 22:45:35,353] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[78.73562]
 [78.78709]
 [79.08009]
 [79.25909]
 [79.72433]], R is [[78.8007431 ]
 [78.80706024]
 [78.81195068]
 [78.8135376 ]
 [78.80528259]].
[2019-04-06 22:45:43,124] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.9265045e-12 1.3415015e-09 2.5558676e-12 1.0090229e-05 1.1058324e-12
 9.9998987e-01 6.8199769e-12], sum to 1.0000
[2019-04-06 22:45:43,124] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8135
[2019-04-06 22:45:43,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:45:43,150] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:45:43,182] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.85, 40.5, 24.0, 163.0, 26.0, 25.18321481555864, 0.337642489267477, 0.0, 1.0, 6226.803890076847], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4210200.0000, 
sim time next is 4212000.0000, 
raw observation next is [1.7, 41.0, 0.0, 0.0, 26.0, 25.02834591687204, 0.3188826164234378, 0.0, 1.0, 57688.13935449056], 
processed observation next is [0.0, 0.782608695652174, 0.5096952908587258, 0.41, 0.0, 0.0, 0.6666666666666666, 0.5856954930726701, 0.6062942054744792, 0.0, 1.0, 0.2747054254975741], 
reward next is 0.7253, 
noisyNet noise sample is [array([-0.75225604], dtype=float32), 0.07722981]. 
=============================================
[2019-04-06 22:45:43,194] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run38
[2019-04-06 22:45:43,268] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[78.01033]
 [79.32176]
 [79.99245]
 [79.74001]
 [79.99451]], R is [[77.82689667]
 [78.01898193]
 [78.23879242]
 [78.45640564]
 [78.67184448]].
[2019-04-06 22:45:46,236] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0492615e-13 3.2759084e-10 2.0051338e-13 3.1655022e-06 2.8797039e-13
 9.9999678e-01 1.4691497e-12], sum to 1.0000
[2019-04-06 22:45:46,236] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5203
[2019-04-06 22:45:46,445] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 63.0, 0.0, 0.0, 26.0, 24.95541146598098, 0.372744739425137, 0.0, 1.0, 77567.5788343562], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2664000.0000, 
sim time next is 2665800.0000, 
raw observation next is [-1.2, 64.0, 0.0, 0.0, 26.0, 25.03958214514933, 0.4102993794276926, 0.0, 1.0, 110494.41495887977], 
processed observation next is [1.0, 0.8695652173913043, 0.42936288088642666, 0.64, 0.0, 0.0, 0.6666666666666666, 0.5866318454291107, 0.6367664598092309, 0.0, 1.0, 0.5261638807565704], 
reward next is 0.4738, 
noisyNet noise sample is [array([1.5098901], dtype=float32), -0.20545061]. 
=============================================
[2019-04-06 22:45:49,369] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:45:49,369] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:45:49,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run38
[2019-04-06 22:45:57,436] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:45:57,436] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:45:57,440] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run38
[2019-04-06 22:45:58,336] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.8655632e-12 1.6174423e-10 1.7964836e-12 1.0076527e-06 7.8777896e-12
 9.9999905e-01 1.5717910e-12], sum to 1.0000
[2019-04-06 22:45:58,336] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4765
[2019-04-06 22:45:58,402] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [18.55, 64.0, 29.0, 0.0, 26.0, 24.9978157556196, 0.470888665076038, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1182600.0000, 
sim time next is 1184400.0000, 
raw observation next is [18.3, 65.0, 14.5, 0.0, 26.0, 24.93528120249126, 0.4565269821222449, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.9695290858725764, 0.65, 0.04833333333333333, 0.0, 0.6666666666666666, 0.5779401002076051, 0.652175660707415, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4390269], dtype=float32), -0.41215616]. 
=============================================
[2019-04-06 22:46:00,725] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4968645e-12 2.9323471e-11 1.5205731e-12 7.6737842e-07 8.4406257e-14
 9.9999928e-01 1.0723615e-12], sum to 1.0000
[2019-04-06 22:46:00,725] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0683
[2019-04-06 22:46:00,887] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 86.0, 187.0, 24.5, 26.0, 25.3227968859729, 0.3035307021730238, 1.0, 1.0, 41953.25909556442], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 126000.0000, 
sim time next is 127800.0000, 
raw observation next is [-8.1, 73.5, 184.0, 13.0, 26.0, 25.40633058176198, 0.3214871724457347, 1.0, 1.0, 45312.92656502107], 
processed observation next is [1.0, 0.4782608695652174, 0.23822714681440446, 0.735, 0.6133333333333333, 0.014364640883977901, 0.6666666666666666, 0.6171942151468318, 0.6071623908152449, 1.0, 1.0, 0.21577584078581463], 
reward next is 0.7842, 
noisyNet noise sample is [array([-1.7299246], dtype=float32), 0.55357665]. 
=============================================
[2019-04-06 22:46:12,136] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.13621048e-12 1.25365107e-10 1.01325615e-11 8.92540174e-06
 1.00214589e-13 9.99991059e-01 1.08719728e-12], sum to 1.0000
[2019-04-06 22:46:12,137] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6252
[2019-04-06 22:46:12,209] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 91.0, 0.0, 0.0, 26.0, 24.24658010880745, 0.1239493097257282, 0.0, 1.0, 41804.91914883405], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 93600.0000, 
sim time next is 95400.0000, 
raw observation next is [-2.25, 89.0, 0.0, 0.0, 26.0, 24.23082506461778, 0.1113484315665553, 0.0, 1.0, 42278.588449115836], 
processed observation next is [1.0, 0.08695652173913043, 0.40027700831024937, 0.89, 0.0, 0.0, 0.6666666666666666, 0.5192354220514815, 0.5371161438555184, 0.0, 1.0, 0.20132661166245636], 
reward next is 0.7987, 
noisyNet noise sample is [array([0.095241], dtype=float32), 0.9087968]. 
=============================================
[2019-04-06 22:46:12,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:46:12,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:46:12,710] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run38
[2019-04-06 22:46:16,117] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5721647e-15 1.0817049e-12 1.7679907e-14 1.7183932e-07 5.2986180e-15
 9.9999988e-01 5.5723228e-14], sum to 1.0000
[2019-04-06 22:46:16,117] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7225
[2019-04-06 22:46:16,136] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.25, 59.0, 0.0, 0.0, 26.0, 26.69498067541669, 0.67790894166669, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1531800.0000, 
sim time next is 1533600.0000, 
raw observation next is [10.0, 60.0, 0.0, 0.0, 26.0, 26.37819820007794, 0.7009120979463281, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.739612188365651, 0.6, 0.0, 0.0, 0.6666666666666666, 0.6981831833398283, 0.7336373659821094, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1898278], dtype=float32), -0.6300368]. 
=============================================
[2019-04-06 22:46:26,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:46:26,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:46:26,177] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run38
[2019-04-06 22:46:26,406] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2442436e-14 4.3833526e-12 4.1911007e-14 1.4646132e-06 1.4473149e-14
 9.9999857e-01 4.0542900e-14], sum to 1.0000
[2019-04-06 22:46:26,406] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3276
[2019-04-06 22:46:26,474] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.2, 50.0, 82.0, 253.0, 26.0, 26.98153580880275, 0.7942011728113694, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1526400.0000, 
sim time next is 1528200.0000, 
raw observation next is [11.35, 54.0, 87.0, 28.0, 26.0, 27.2486383819159, 0.7000800741059338, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.7770083102493075, 0.54, 0.29, 0.030939226519337018, 0.6666666666666666, 0.7707198651596583, 0.7333600247019779, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2695442], dtype=float32), -1.6574701]. 
=============================================
[2019-04-06 22:46:36,161] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2992682e-14 3.5947904e-11 1.2015103e-13 3.8804346e-06 8.9056968e-15
 9.9999607e-01 1.2002831e-12], sum to 1.0000
[2019-04-06 22:46:36,162] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1187
[2019-04-06 22:46:36,237] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.55, 96.5, 0.0, 0.0, 26.0, 24.83403627630005, 0.2344562725054647, 0.0, 1.0, 40125.55414761909], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 516600.0000, 
sim time next is 518400.0000, 
raw observation next is [3.8, 97.0, 0.0, 0.0, 26.0, 24.88323869225347, 0.2391244638858679, 0.0, 1.0, 39854.03528388854], 
processed observation next is [0.0, 0.0, 0.5678670360110805, 0.97, 0.0, 0.0, 0.6666666666666666, 0.5736032243544559, 0.5797081546286226, 0.0, 1.0, 0.18978112039946923], 
reward next is 0.8102, 
noisyNet noise sample is [array([-1.4306494], dtype=float32), 0.17464022]. 
=============================================
[2019-04-06 22:46:37,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1462314e-16 2.6124041e-13 4.7720047e-16 9.6332426e-09 6.8592469e-16
 1.0000000e+00 3.3005967e-15], sum to 1.0000
[2019-04-06 22:46:37,171] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3250
[2019-04-06 22:46:37,249] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.25, 98.0, 0.0, 0.0, 26.0, 24.59008743476455, 0.4330187011210192, 0.0, 1.0, 44198.159433158995], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1272600.0000, 
sim time next is 1274400.0000, 
raw observation next is [8.3, 96.0, 0.0, 0.0, 26.0, 24.70889361890081, 0.4493269865620247, 0.0, 1.0, 26372.058893692945], 
processed observation next is [0.0, 0.782608695652174, 0.6925207756232689, 0.96, 0.0, 0.0, 0.6666666666666666, 0.5590744682417341, 0.6497756621873415, 0.0, 1.0, 0.12558123282710926], 
reward next is 0.8744, 
noisyNet noise sample is [array([-0.15878579], dtype=float32), 0.11500589]. 
=============================================
[2019-04-06 22:46:56,843] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0839734e-12 4.7738771e-11 2.3345041e-12 3.2083710e-06 1.5344607e-12
 9.9999678e-01 6.9497067e-13], sum to 1.0000
[2019-04-06 22:46:56,843] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6670
[2019-04-06 22:46:56,991] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 83.0, 100.0, 73.0, 26.0, 24.96331982358114, 0.3250365299198316, 0.0, 1.0, 45003.11799193448], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 574200.0000, 
sim time next is 576000.0000, 
raw observation next is [-1.2, 83.0, 70.5, 59.0, 26.0, 24.9766722805026, 0.3140953258248645, 0.0, 1.0, 29596.87907966757], 
processed observation next is [0.0, 0.6956521739130435, 0.42936288088642666, 0.83, 0.235, 0.06519337016574586, 0.6666666666666666, 0.5813893567085501, 0.6046984419416215, 0.0, 1.0, 0.14093751942698843], 
reward next is 0.8591, 
noisyNet noise sample is [array([0.00049953], dtype=float32), 0.03444011]. 
=============================================
[2019-04-06 22:46:56,997] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[82.18299 ]
 [82.94535 ]
 [83.86524 ]
 [84.2648  ]
 [84.848915]], R is [[82.16075897]
 [82.12484741]
 [82.19735718]
 [82.22850037]
 [82.31704712]].
[2019-04-06 22:47:06,518] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8576882e-14 3.7611591e-11 2.4524738e-12 1.4350021e-05 1.2787342e-13
 9.9998569e-01 1.4231944e-12], sum to 1.0000
[2019-04-06 22:47:06,519] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5665
[2019-04-06 22:47:06,564] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 56.0, 0.0, 0.0, 26.0, 25.41433630299266, 0.4157892446457611, 0.0, 1.0, 30031.810000247988], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2583000.0000, 
sim time next is 2584800.0000, 
raw observation next is [-2.8, 56.0, 0.0, 0.0, 26.0, 25.37325981555664, 0.4120475456572439, 0.0, 1.0, 50559.01289254826], 
processed observation next is [1.0, 0.9565217391304348, 0.38504155124653744, 0.56, 0.0, 0.0, 0.6666666666666666, 0.6144383179630534, 0.637349181885748, 0.0, 1.0, 0.24075720425022978], 
reward next is 0.7592, 
noisyNet noise sample is [array([-0.1751611], dtype=float32), 0.7853357]. 
=============================================
[2019-04-06 22:47:14,859] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4349841e-12 6.1087357e-10 4.5882131e-12 1.3190694e-05 3.7253683e-13
 9.9998677e-01 4.9693539e-13], sum to 1.0000
[2019-04-06 22:47:14,859] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7053
[2019-04-06 22:47:15,061] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.449999999999999, 77.0, 171.0, 236.0, 26.0, 25.8354234578566, 0.3337896242697374, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1938600.0000, 
sim time next is 1940400.0000, 
raw observation next is [-5.6, 75.0, 201.5, 123.0, 26.0, 25.71021300561715, 0.3177933869733382, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.30747922437673136, 0.75, 0.6716666666666666, 0.13591160220994475, 0.6666666666666666, 0.6425177504680958, 0.6059311289911128, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.606985], dtype=float32), -0.47574773]. 
=============================================
[2019-04-06 22:47:17,515] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.71713077e-11 7.08307968e-10 5.27872641e-11 1.15404982e-05
 1.33872739e-11 9.99988437e-01 1.36470965e-11], sum to 1.0000
[2019-04-06 22:47:17,516] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8054
[2019-04-06 22:47:17,563] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.75, 42.5, 0.0, 0.0, 26.0, 24.89207616204424, 0.2125057676489288, 0.0, 1.0, 42981.97798606175], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2413800.0000, 
sim time next is 2415600.0000, 
raw observation next is [-5.0, 41.0, 0.0, 0.0, 26.0, 24.74325238312336, 0.1845365346205831, 0.0, 1.0, 43039.48524082793], 
processed observation next is [0.0, 1.0, 0.32409972299168976, 0.41, 0.0, 0.0, 0.6666666666666666, 0.5619376985936132, 0.5615121782068611, 0.0, 1.0, 0.20494992971822826], 
reward next is 0.7951, 
noisyNet noise sample is [array([-1.017679], dtype=float32), 0.5536822]. 
=============================================
[2019-04-06 22:47:47,266] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8934916e-14 1.0871635e-11 3.9823654e-14 5.2876032e-07 4.1416269e-15
 9.9999952e-01 3.8373716e-14], sum to 1.0000
[2019-04-06 22:47:47,266] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4338
[2019-04-06 22:47:47,447] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.45, 87.0, 0.0, 0.0, 26.0, 24.83080956465037, 0.3274670605777127, 0.0, 1.0, 43913.773015644554], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1751400.0000, 
sim time next is 1753200.0000, 
raw observation next is [-1.7, 87.0, 0.0, 0.0, 26.0, 24.75683393952364, 0.3139666293592623, 0.0, 1.0, 44006.05621085019], 
processed observation next is [0.0, 0.30434782608695654, 0.4155124653739613, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5630694949603035, 0.6046555431197541, 0.0, 1.0, 0.20955264862309614], 
reward next is 0.7904, 
noisyNet noise sample is [array([-0.6631517], dtype=float32), -0.78814775]. 
=============================================
[2019-04-06 22:48:01,286] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5774212e-15 5.2156625e-12 3.2065998e-14 8.6238458e-08 2.2217378e-16
 9.9999988e-01 3.2475558e-14], sum to 1.0000
[2019-04-06 22:48:01,287] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9190
[2019-04-06 22:48:01,349] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.2, 96.0, 0.0, 0.0, 26.0, 25.74672640581577, 0.5833726358747197, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1648800.0000, 
sim time next is 1650600.0000, 
raw observation next is [6.9, 96.5, 0.0, 0.0, 26.0, 25.71790632109349, 0.5715380705692251, 0.0, 1.0, 11490.671550056284], 
processed observation next is [1.0, 0.08695652173913043, 0.6537396121883658, 0.965, 0.0, 0.0, 0.6666666666666666, 0.6431588600911242, 0.6905126901897417, 0.0, 1.0, 0.05471748357169659], 
reward next is 0.9453, 
noisyNet noise sample is [array([0.33820602], dtype=float32), 1.01573]. 
=============================================
[2019-04-06 22:48:02,752] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 22:48:02,752] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:48:02,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:48:02,764] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run86
[2019-04-06 22:48:02,863] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:48:02,863] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:48:02,869] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:48:02,869] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:48:02,873] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run86
[2019-04-06 22:48:02,996] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run86
[2019-04-06 22:50:28,552] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.06843988], dtype=float32), 0.13910697]
[2019-04-06 22:50:28,552] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-5.5, 74.0, 0.0, 0.0, 26.0, 24.36361217295942, 0.1326868515724793, 0.0, 1.0, 38746.56471275404]
[2019-04-06 22:50:28,552] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:50:28,553] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.0942739e-12 2.1368302e-10 4.3148649e-12 2.1802186e-06 5.3389682e-13
 9.9999785e-01 2.4561176e-12], sampled 0.04489731813013753
[2019-04-06 22:50:39,771] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.06843988], dtype=float32), 0.13910697]
[2019-04-06 22:50:39,771] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [14.3, 46.0, 0.0, 0.0, 26.0, 27.3049723076965, 0.9794084229909651, 0.0, 1.0, 0.0]
[2019-04-06 22:50:39,771] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:50:39,772] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [2.18032159e-14 1.27858245e-11 9.59327764e-14 5.01887939e-07
 1.27982968e-14 9.99999523e-01 4.67971710e-14], sampled 0.8953905491655086
[2019-04-06 22:50:45,393] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 22:51:03,371] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 22:51:07,378] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 22:51:08,400] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1700000, evaluation results [1700000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 22:51:12,039] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:51:12,040] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:51:12,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run39
[2019-04-06 22:51:34,320] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2703014e-12 5.0512025e-11 6.2027293e-13 8.4558502e-07 2.4140962e-13
 9.9999917e-01 2.7512273e-13], sum to 1.0000
[2019-04-06 22:51:34,320] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6948
[2019-04-06 22:51:34,512] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 92.0, 0.0, 0.0, 26.0, 24.99748039798364, 0.27530477630989, 0.0, 1.0, 34588.026742982496], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3092400.0000, 
sim time next is 3094200.0000, 
raw observation next is [-1.0, 92.0, 0.0, 0.0, 26.0, 25.04753078131193, 0.3208828846334599, 0.0, 1.0, 119840.40823568609], 
processed observation next is [0.0, 0.8260869565217391, 0.4349030470914128, 0.92, 0.0, 0.0, 0.6666666666666666, 0.5872942317759943, 0.6069609615444866, 0.0, 1.0, 0.5706686106461243], 
reward next is 0.4293, 
noisyNet noise sample is [array([1.7624621], dtype=float32), 0.9761771]. 
=============================================
[2019-04-06 22:51:52,710] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.9062513e-14 7.5817156e-12 1.9298631e-13 3.5963335e-06 1.9871957e-14
 9.9999642e-01 1.5962550e-13], sum to 1.0000
[2019-04-06 22:51:52,711] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8897
[2019-04-06 22:51:52,805] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.28968135283294, 0.3319272295585285, 0.0, 1.0, 41051.98150418807], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3726000.0000, 
sim time next is 3727800.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.36296147503767, 0.3459447152278023, 0.0, 1.0, 41238.60414544496], 
processed observation next is [1.0, 0.13043478260869565, 0.3795013850415513, 0.65, 0.0, 0.0, 0.6666666666666666, 0.613580122919806, 0.6153149050759341, 0.0, 1.0, 0.1963743054544998], 
reward next is 0.8036, 
noisyNet noise sample is [array([1.5488551], dtype=float32), -0.6148172]. 
=============================================
[2019-04-06 22:52:01,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:52:01,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:52:01,572] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run39
[2019-04-06 22:52:29,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3920421e-12 1.3483582e-09 1.0066763e-11 4.5562269e-06 8.3824874e-13
 9.9999547e-01 2.9463109e-12], sum to 1.0000
[2019-04-06 22:52:29,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5719
[2019-04-06 22:52:29,601] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.1, 67.0, 0.0, 0.0, 26.0, 24.19452350110534, 0.1134680641518058, 0.0, 1.0, 41029.0699018718], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2352600.0000, 
sim time next is 2354400.0000, 
raw observation next is [-2.8, 65.0, 0.0, 0.0, 26.0, 24.12885982520534, 0.1025527686571428, 0.0, 1.0, 41169.0382807645], 
processed observation next is [0.0, 0.2608695652173913, 0.38504155124653744, 0.65, 0.0, 0.0, 0.6666666666666666, 0.5107383187671116, 0.5341842562190476, 0.0, 1.0, 0.1960430394322119], 
reward next is 0.8040, 
noisyNet noise sample is [array([0.10089847], dtype=float32), -0.46473187]. 
=============================================
[2019-04-06 22:52:36,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0004102e-12 6.9092487e-10 9.2229184e-12 2.9719854e-06 2.6953088e-12
 9.9999702e-01 4.2462483e-12], sum to 1.0000
[2019-04-06 22:52:36,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7787
[2019-04-06 22:52:36,934] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.95, 39.5, 76.0, 777.0, 26.0, 25.00895035065825, 0.228437956698007, 0.0, 1.0, 6248.231740718984], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2457000.0000, 
sim time next is 2458800.0000, 
raw observation next is [-2.3, 36.0, 81.0, 803.0, 26.0, 24.95856482079549, 0.2495736944596842, 0.0, 1.0, 33416.7976019558], 
processed observation next is [0.0, 0.4782608695652174, 0.3988919667590028, 0.36, 0.27, 0.887292817679558, 0.6666666666666666, 0.5798804017329576, 0.5831912314865614, 0.0, 1.0, 0.15912760762836095], 
reward next is 0.8409, 
noisyNet noise sample is [array([-0.9318714], dtype=float32), 0.839409]. 
=============================================
[2019-04-06 22:52:37,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:52:37,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:52:37,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run39
[2019-04-06 22:52:46,785] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5843760e-14 4.4930715e-11 1.0157915e-12 3.0699232e-07 2.3237900e-13
 9.9999964e-01 2.5680686e-13], sum to 1.0000
[2019-04-06 22:52:46,792] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6636
[2019-04-06 22:52:46,848] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 37.0, 0.0, 0.0, 26.0, 25.32309475377136, 0.5137804906689443, 1.0, 1.0, 69766.6258631818], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4129200.0000, 
sim time next is 4131000.0000, 
raw observation next is [2.0, 40.0, 0.0, 0.0, 26.0, 25.58696242769682, 0.5146442112313704, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.518005540166205, 0.4, 0.0, 0.0, 0.6666666666666666, 0.6322468689747351, 0.6715480704104567, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.24946292], dtype=float32), 0.13029487]. 
=============================================
[2019-04-06 22:52:46,852] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[83.88869 ]
 [83.615524]
 [83.997765]
 [84.46632 ]
 [85.29113 ]], R is [[83.77301788]
 [83.60306549]
 [83.76703644]
 [83.92936707]
 [84.09007263]].
[2019-04-06 22:52:52,143] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:52:52,143] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:52:52,147] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run39
[2019-04-06 22:52:54,242] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.18748891e-14 9.23527747e-12 5.42594832e-13 9.20854802e-07
 1.11837155e-13 9.99999046e-01 1.75335508e-13], sum to 1.0000
[2019-04-06 22:52:54,243] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6093
[2019-04-06 22:52:54,400] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 42.5, 93.0, 560.0, 26.0, 25.23826389180049, 0.329059180771462, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4955400.0000, 
sim time next is 4957200.0000, 
raw observation next is [-1.0, 39.0, 100.5, 638.5, 26.0, 25.70443401686995, 0.4102789829749721, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4349030470914128, 0.39, 0.335, 0.7055248618784531, 0.6666666666666666, 0.6420361680724959, 0.6367596609916574, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8615487], dtype=float32), -0.8445081]. 
=============================================
[2019-04-06 22:53:00,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:53:00,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:53:00,384] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run39
[2019-04-06 22:53:00,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:53:00,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:53:00,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run39
[2019-04-06 22:53:01,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:53:01,018] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:53:01,023] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run39
[2019-04-06 22:53:01,212] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:53:01,212] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:53:01,216] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run39
[2019-04-06 22:53:10,224] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:53:10,225] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:53:10,228] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run39
[2019-04-06 22:53:21,458] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.7792882e-14 1.3136606e-11 4.0537406e-13 1.9897195e-06 1.6230905e-13
 9.9999797e-01 1.3509408e-13], sum to 1.0000
[2019-04-06 22:53:21,459] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2946
[2019-04-06 22:53:21,581] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.25, 89.0, 0.0, 0.0, 26.0, 24.22543183061112, 0.1101228503854664, 0.0, 1.0, 42283.0136401532], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 95400.0000, 
sim time next is 97200.0000, 
raw observation next is [-2.8, 87.0, 0.0, 0.0, 26.0, 24.11887201715673, 0.0852124411266979, 0.0, 1.0, 42773.888877800084], 
processed observation next is [1.0, 0.13043478260869565, 0.38504155124653744, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5099060014297274, 0.5284041470422326, 0.0, 1.0, 0.20368518513238135], 
reward next is 0.7963, 
noisyNet noise sample is [array([1.0750306], dtype=float32), -0.43312952]. 
=============================================
[2019-04-06 22:53:24,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:53:24,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:53:24,675] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run39
[2019-04-06 22:53:25,703] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 22:53:25,704] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:53:25,704] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:53:25,708] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run87
[2019-04-06 22:53:25,816] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:53:25,818] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:53:25,822] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run87
[2019-04-06 22:53:25,977] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:53:25,977] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:53:26,000] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run87
[2019-04-06 22:55:12,854] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.06880639], dtype=float32), 0.13973655]
[2019-04-06 22:55:12,854] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-3.2643253565, 71.2841662, 256.0562095, 255.5340933, 26.0, 25.41261567191016, 0.2802867420328688, 1.0, 1.0, 12470.71182568551]
[2019-04-06 22:55:12,854] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 22:55:12,855] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [5.1706426e-13 9.6375526e-11 1.4511220e-12 1.8063815e-06 3.2747337e-13
 9.9999821e-01 1.1456309e-12], sampled 0.8284095911395436
[2019-04-06 22:56:10,480] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 22:56:30,099] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 22:56:31,088] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 22:56:32,112] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 1720000, evaluation results [1720000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 22:56:34,486] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7774534e-11 1.7209136e-09 8.9342977e-11 6.8814821e-05 1.5257634e-11
 9.9993122e-01 7.7544388e-11], sum to 1.0000
[2019-04-06 22:56:34,486] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3837
[2019-04-06 22:56:34,735] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.55, 68.5, 0.0, 0.0, 26.0, 22.70203702887871, -0.1458374444346605, 1.0, 1.0, 151243.40859986702], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 286200.0000, 
sim time next is 288000.0000, 
raw observation next is [-12.8, 70.0, 15.0, 205.5, 26.0, 24.41710840335185, 0.1191061538683925, 1.0, 1.0, 123983.71667498826], 
processed observation next is [1.0, 0.34782608695652173, 0.1080332409972299, 0.7, 0.05, 0.22707182320441988, 0.6666666666666666, 0.5347590336126542, 0.5397020512894641, 1.0, 1.0, 0.5903986508332775], 
reward next is 0.4096, 
noisyNet noise sample is [array([0.41598722], dtype=float32), 0.015568469]. 
=============================================
[2019-04-06 22:56:34,743] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[73.07977]
 [72.07522]
 [72.87394]
 [73.62507]
 [74.40845]], R is [[74.35806274]
 [73.89427185]
 [73.92713165]
 [73.96008301]
 [73.99275208]].
[2019-04-06 22:56:43,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:56:43,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:56:43,484] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run39
[2019-04-06 22:56:46,640] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7328204e-13 9.9854292e-11 3.1719436e-12 7.2666448e-06 9.1409139e-13
 9.9999273e-01 2.2747472e-12], sum to 1.0000
[2019-04-06 22:56:46,640] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7997
[2019-04-06 22:56:46,674] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 23.0, 67.0, 548.0, 26.0, 25.86548676110579, 0.6312424503687711, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4033800.0000, 
sim time next is 4035600.0000, 
raw observation next is [-2.0, 24.0, 43.5, 370.5, 26.0, 26.81783523666768, 0.7139459221545943, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.40720221606648205, 0.24, 0.145, 0.4093922651933702, 0.6666666666666666, 0.73481960305564, 0.7379819740515314, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.4345183], dtype=float32), -1.560097]. 
=============================================
[2019-04-06 22:56:56,281] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3580698e-12 9.1870143e-11 2.2535045e-12 3.5734040e-06 2.2236538e-13
 9.9999642e-01 9.7319600e-12], sum to 1.0000
[2019-04-06 22:56:56,281] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8954
[2019-04-06 22:56:56,346] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 55.0, 0.0, 0.0, 26.0, 25.36773645822509, 0.3777332361764192, 0.0, 1.0, 43996.13023851032], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3623400.0000, 
sim time next is 3625200.0000, 
raw observation next is [-3.0, 60.0, 0.0, 0.0, 26.0, 25.33859928050897, 0.3671694500338121, 0.0, 1.0, 41100.21493182946], 
processed observation next is [0.0, 1.0, 0.3795013850415513, 0.6, 0.0, 0.0, 0.6666666666666666, 0.6115499400424141, 0.6223898166779374, 0.0, 1.0, 0.19571530919918792], 
reward next is 0.8043, 
noisyNet noise sample is [array([0.9675076], dtype=float32), -0.81900674]. 
=============================================
[2019-04-06 22:57:22,633] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3897618e-13 8.0345237e-11 4.6379589e-12 2.1922194e-06 2.1093477e-13
 9.9999785e-01 3.3449387e-12], sum to 1.0000
[2019-04-06 22:57:22,634] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7029
[2019-04-06 22:57:22,672] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 45.0, 163.0, 422.0, 26.0, 25.10344058485146, 0.3766864098369182, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4894200.0000, 
sim time next is 4896000.0000, 
raw observation next is [3.0, 45.0, 132.5, 369.5, 26.0, 25.12931294876455, 0.3742987370613855, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.45, 0.44166666666666665, 0.40828729281767956, 0.6666666666666666, 0.5941094123970458, 0.6247662456871285, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.12002491], dtype=float32), -0.008532697]. 
=============================================
[2019-04-06 22:57:22,676] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[79.74011 ]
 [79.58039 ]
 [79.404816]
 [79.28584 ]
 [79.31966 ]], R is [[79.76535034]
 [79.96769714]
 [80.13835907]
 [80.2776413 ]
 [80.47486877]].
[2019-04-06 22:57:25,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:57:25,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:57:25,347] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run39
[2019-04-06 22:57:32,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:57:32,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:57:32,984] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run39
[2019-04-06 22:57:39,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:57:39,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:57:39,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run39
[2019-04-06 22:57:51,122] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:57:51,122] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:57:51,125] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run39
[2019-04-06 22:58:12,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:58:12,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:58:12,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run39
[2019-04-06 22:58:19,962] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4714103e-11 1.8571250e-09 4.2341092e-11 3.9716160e-05 4.5277445e-11
 9.9996030e-01 3.6019696e-12], sum to 1.0000
[2019-04-06 22:58:19,963] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3100
[2019-04-06 22:58:20,150] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 40.0, 0.0, 0.0, 26.0, 25.52947609459156, 0.3412758905877049, 1.0, 1.0, 40505.07258233043], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 412200.0000, 
sim time next is 414000.0000, 
raw observation next is [-9.5, 40.0, 0.0, 0.0, 26.0, 25.24604018260659, 0.2857273978263907, 1.0, 1.0, 46892.70173600206], 
processed observation next is [1.0, 0.8260869565217391, 0.1994459833795014, 0.4, 0.0, 0.0, 0.6666666666666666, 0.6038366818838824, 0.5952424659421303, 1.0, 1.0, 0.2232985796952479], 
reward next is 0.7767, 
noisyNet noise sample is [array([-0.33351192], dtype=float32), -0.8953364]. 
=============================================
[2019-04-06 22:58:20,154] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.65685 ]
 [71.67832 ]
 [70.924446]
 [71.6515  ]
 [72.473076]], R is [[71.76888275]
 [71.85831451]
 [71.67778778]
 [71.66759491]
 [71.9509201 ]].
[2019-04-06 22:58:34,865] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4504325e-11 7.8184181e-10 2.6900827e-11 2.3572009e-05 5.4765667e-12
 9.9997640e-01 4.4929928e-11], sum to 1.0000
[2019-04-06 22:58:34,866] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2166
[2019-04-06 22:58:34,935] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 26.0, 22.87906889299419, -0.213399903010743, 0.0, 1.0, 44801.12009600096], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 192600.0000, 
sim time next is 194400.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 26.0, 22.74138015727413, -0.2438855594443943, 0.0, 1.0, 44934.639403149085], 
processed observation next is [1.0, 0.2608695652173913, 0.21606648199445982, 0.78, 0.0, 0.0, 0.6666666666666666, 0.3951150131061774, 0.4187048135185352, 0.0, 1.0, 0.21397447334832898], 
reward next is 0.7860, 
noisyNet noise sample is [array([-0.17582764], dtype=float32), -1.6338593]. 
=============================================
[2019-04-06 22:59:12,471] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-06 22:59:12,477] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:59:12,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:59:12,482] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run88
[2019-04-06 22:59:12,589] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:59:12,589] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:59:12,614] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run88
[2019-04-06 22:59:12,648] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:59:12,648] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:59:12,668] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run88
[2019-04-06 23:01:37,167] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.06967201], dtype=float32), 0.13948365]
[2019-04-06 23:01:37,167] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [2.0, 44.0, 0.0, 0.0, 26.0, 25.4921789834992, 0.4279612051169308, 0.0, 1.0, 20653.610804030865]
[2019-04-06 23:01:37,167] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 23:01:37,167] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.50752391e-13 1.04835966e-10 1.93884774e-12 1.82991573e-06
 2.30105025e-13 9.99998212e-01 1.31122706e-12], sampled 0.6356073432589152
[2019-04-06 23:01:55,923] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 23:02:17,396] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 23:02:18,469] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 23:02:19,492] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1740000, evaluation results [1740000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 23:02:47,835] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2412920e-13 7.9091478e-10 5.4365589e-13 2.3284276e-06 9.5512485e-14
 9.9999762e-01 2.8986576e-13], sum to 1.0000
[2019-04-06 23:02:47,835] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3096
[2019-04-06 23:02:48,045] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 32.0, 0.0, 0.0, 26.0, 25.66008080435066, 0.174769518270306, 1.0, 1.0, 3113.4019450384226], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2568600.0000, 
sim time next is 2570400.0000, 
raw observation next is [0.5, 35.0, 0.0, 0.0, 26.0, 25.01429494280535, 0.3387048299137259, 1.0, 1.0, 93968.9520008543], 
processed observation next is [1.0, 0.782608695652174, 0.4764542936288089, 0.35, 0.0, 0.0, 0.6666666666666666, 0.5845245785671125, 0.612901609971242, 1.0, 1.0, 0.4474712000040681], 
reward next is 0.5525, 
noisyNet noise sample is [array([-0.52420396], dtype=float32), -0.23207903]. 
=============================================
[2019-04-06 23:03:02,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:03:02,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:03:02,164] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run40
[2019-04-06 23:03:28,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7613875e-12 2.0065040e-10 3.5439384e-12 8.3472014e-06 5.5082116e-13
 9.9999166e-01 1.1089541e-12], sum to 1.0000
[2019-04-06 23:03:28,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1253
[2019-04-06 23:03:28,250] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.45, 76.5, 0.0, 0.0, 26.0, 24.63947874124722, 0.2440148373524255, 0.0, 1.0, 43834.78431832045], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3299400.0000, 
sim time next is 3301200.0000, 
raw observation next is [-10.0, 76.0, 0.0, 0.0, 26.0, 24.48140527495197, 0.2209205188449593, 0.0, 1.0, 43747.47639264729], 
processed observation next is [1.0, 0.21739130434782608, 0.18559556786703602, 0.76, 0.0, 0.0, 0.6666666666666666, 0.5401171062459976, 0.5736401729483197, 0.0, 1.0, 0.2083213161554633], 
reward next is 0.7917, 
noisyNet noise sample is [array([0.2901218], dtype=float32), 0.8870505]. 
=============================================
[2019-04-06 23:03:44,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:03:44,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:03:44,724] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run40
[2019-04-06 23:03:50,023] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.2535973e-13 6.3825265e-11 2.0038847e-12 1.3142665e-06 8.1167739e-13
 9.9999869e-01 2.4655772e-12], sum to 1.0000
[2019-04-06 23:03:50,023] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7079
[2019-04-06 23:03:50,232] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 28.0, 124.0, 0.0, 26.0, 24.98716506295168, 0.156985370298349, 1.0, 1.0, 71555.68105276478], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 478800.0000, 
sim time next is 480600.0000, 
raw observation next is [-0.8999999999999999, 31.5, 119.0, 0.0, 26.0, 24.95089509436038, 0.2028666009498425, 1.0, 1.0, 45987.59217530743], 
processed observation next is [1.0, 0.5652173913043478, 0.43767313019390586, 0.315, 0.39666666666666667, 0.0, 0.6666666666666666, 0.579241257863365, 0.5676222003166141, 1.0, 1.0, 0.2189885341681306], 
reward next is 0.7810, 
noisyNet noise sample is [array([-1.9808182], dtype=float32), 0.5907553]. 
=============================================
[2019-04-06 23:03:53,771] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.2151858e-13 6.0729082e-12 5.7162288e-13 7.1803305e-07 1.2780633e-14
 9.9999928e-01 3.7445353e-13], sum to 1.0000
[2019-04-06 23:03:53,771] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9680
[2019-04-06 23:03:53,994] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 77.0, 5.0, 149.0, 26.0, 24.88200305803023, 0.3390678729396442, 1.0, 1.0, 86021.78637546177], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3828600.0000, 
sim time next is 3830400.0000, 
raw observation next is [-5.0, 77.0, 48.0, 298.0, 26.0, 25.39240555146537, 0.3767141087756001, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.32409972299168976, 0.77, 0.16, 0.3292817679558011, 0.6666666666666666, 0.6160337959554475, 0.6255713695918667, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.32907262], dtype=float32), -0.20894097]. 
=============================================
[2019-04-06 23:04:02,209] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5590874e-12 1.7750422e-10 7.4943784e-13 3.0549492e-07 1.3527969e-13
 9.9999964e-01 1.8369837e-12], sum to 1.0000
[2019-04-06 23:04:02,210] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5850
[2019-04-06 23:04:02,322] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.5, 70.0, 3.0, 121.0, 26.0, 24.28499659213479, 0.190301685303057, 0.0, 1.0, 41448.820539610366], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3569400.0000, 
sim time next is 3571200.0000, 
raw observation next is [-7.0, 70.0, 45.5, 273.0, 26.0, 24.20483961964074, 0.1987446204206891, 0.0, 1.0, 41493.96885949317], 
processed observation next is [0.0, 0.34782608695652173, 0.2686980609418283, 0.7, 0.15166666666666667, 0.30165745856353593, 0.6666666666666666, 0.517069968303395, 0.5662482068068964, 0.0, 1.0, 0.19759032790234843], 
reward next is 0.8024, 
noisyNet noise sample is [array([1.4686625], dtype=float32), 2.1865566]. 
=============================================
[2019-04-06 23:04:02,492] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8415109e-13 2.9474448e-10 3.0187198e-12 3.0065257e-07 1.0202959e-13
 9.9999964e-01 6.6035529e-14], sum to 1.0000
[2019-04-06 23:04:02,492] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0071
[2019-04-06 23:04:02,814] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.0, 58.0, 48.5, 314.5, 26.0, 25.70954889667954, 0.4402178677905227, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3916800.0000, 
sim time next is 3918600.0000, 
raw observation next is [-8.0, 55.5, 91.0, 466.0, 26.0, 25.77258075045681, 0.4679726537523053, 1.0, 1.0, 3123.54834102421], 
processed observation next is [1.0, 0.34782608695652173, 0.24099722991689754, 0.555, 0.30333333333333334, 0.5149171270718232, 0.6666666666666666, 0.6477150625380675, 0.6559908845841017, 1.0, 1.0, 0.014874039719162905], 
reward next is 0.9851, 
noisyNet noise sample is [array([1.0199758], dtype=float32), 0.567007]. 
=============================================
[2019-04-06 23:04:22,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:04:22,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:04:22,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run40
[2019-04-06 23:04:33,510] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 23:04:33,517] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:04:33,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:04:33,582] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:04:33,583] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:04:33,587] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run89
[2019-04-06 23:04:33,741] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:04:33,749] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:04:33,745] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run89
[2019-04-06 23:04:33,815] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run89
[2019-04-06 23:07:17,978] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.3885 79967197.3248 535.2671
[2019-04-06 23:07:33,743] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 23:07:38,737] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 23:07:39,780] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1760000, evaluation results [1760000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.388471443006, 79967197.3248232, 535.2671102210136, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 23:07:40,227] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3853337e-15 3.1839073e-12 8.2361646e-13 7.9381458e-08 1.8427586e-14
 9.9999988e-01 6.7303944e-14], sum to 1.0000
[2019-04-06 23:07:40,227] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7856
[2019-04-06 23:07:40,294] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 26.0, 25.02234619193356, 0.3636279260487965, 0.0, 1.0, 41574.14079367], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3369600.0000, 
sim time next is 3371400.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.96371026169886, 0.3429652785585509, 0.0, 1.0, 41454.915175006376], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5803091884749051, 0.614321759519517, 0.0, 1.0, 0.19740435797622083], 
reward next is 0.8026, 
noisyNet noise sample is [array([0.15256168], dtype=float32), 0.5918035]. 
=============================================
[2019-04-06 23:07:47,703] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:07:47,703] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:07:47,706] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run40
[2019-04-06 23:07:59,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:07:59,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:07:59,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run40
[2019-04-06 23:08:02,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:08:02,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:08:02,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run40
[2019-04-06 23:08:05,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:08:05,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:08:05,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run40
[2019-04-06 23:08:05,806] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:08:05,806] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:08:05,819] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run40
[2019-04-06 23:08:10,293] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:08:10,293] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:08:10,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run40
[2019-04-06 23:08:10,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:08:10,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:08:10,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run40
[2019-04-06 23:08:19,696] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.09245598e-14 1.08068225e-11 4.98304401e-14 4.20485179e-07
 1.06229180e-14 9.99999523e-01 3.88970641e-14], sum to 1.0000
[2019-04-06 23:08:19,696] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5018
[2019-04-06 23:08:19,737] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 26.0, 25.46512751628713, 0.4225176580688575, 0.0, 1.0, 14510.397715974404], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3893400.0000, 
sim time next is 3895200.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 26.0, 25.26267830552031, 0.4025018251259354, 0.0, 1.0, 57230.88163258362], 
processed observation next is [1.0, 0.08695652173913043, 0.40720221606648205, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6052231921266925, 0.6341672750419785, 0.0, 1.0, 0.2725280077742077], 
reward next is 0.7275, 
noisyNet noise sample is [array([0.4645459], dtype=float32), -0.79196364]. 
=============================================
[2019-04-06 23:08:30,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:08:30,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:08:30,376] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run40
[2019-04-06 23:08:31,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3861666e-12 6.2335095e-11 4.9337717e-12 3.3604842e-06 9.8782397e-13
 9.9999666e-01 4.1913209e-12], sum to 1.0000
[2019-04-06 23:08:31,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6954
[2019-04-06 23:08:32,143] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.75, 73.5, 124.0, 0.0, 26.0, 25.30217550367282, 0.2101370943510326, 1.0, 1.0, 23852.75550451149], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 210600.0000, 
sim time next is 212400.0000, 
raw observation next is [-6.2, 72.0, 138.5, 0.0, 26.0, 25.28166104267619, 0.2222361961752551, 1.0, 1.0, 27812.32864988838], 
processed observation next is [1.0, 0.4782608695652174, 0.2908587257617729, 0.72, 0.46166666666666667, 0.0, 0.6666666666666666, 0.6068050868896826, 0.5740787320584183, 1.0, 1.0, 0.1324396602375637], 
reward next is 0.8676, 
noisyNet noise sample is [array([1.8819549], dtype=float32), 0.46442968]. 
=============================================
[2019-04-06 23:08:37,283] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3962011e-13 1.1756514e-10 1.4292333e-11 1.5800940e-06 9.1336292e-13
 9.9999845e-01 2.0342842e-12], sum to 1.0000
[2019-04-06 23:08:37,284] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6974
[2019-04-06 23:08:37,359] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.95486878349629, 0.2056499695810395, 0.0, 1.0, 42443.546578984824], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 680400.0000, 
sim time next is 682200.0000, 
raw observation next is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.85303713939475, 0.184685454245594, 0.0, 1.0, 42266.27803130492], 
processed observation next is [0.0, 0.9130434782608695, 0.368421052631579, 0.69, 0.0, 0.0, 0.6666666666666666, 0.5710864282828959, 0.5615618180818647, 0.0, 1.0, 0.20126799062526154], 
reward next is 0.7987, 
noisyNet noise sample is [array([1.4136555], dtype=float32), -0.00221599]. 
=============================================
[2019-04-06 23:09:02,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.4082100e-16 9.4861272e-13 2.8979900e-15 8.8383098e-07 1.1221996e-15
 9.9999917e-01 1.8480158e-14], sum to 1.0000
[2019-04-06 23:09:02,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8552
[2019-04-06 23:09:02,446] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.7, 80.0, 0.0, 0.0, 26.0, 25.666165853522, 0.6142114277117167, 0.0, 1.0, 18727.03825273127], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1148400.0000, 
sim time next is 1150200.0000, 
raw observation next is [12.7, 82.0, 0.0, 0.0, 26.0, 25.67807029932417, 0.6162648320547074, 0.0, 1.0, 18725.026904540016], 
processed observation next is [0.0, 0.30434782608695654, 0.8144044321329641, 0.82, 0.0, 0.0, 0.6666666666666666, 0.6398391916103474, 0.7054216106849025, 0.0, 1.0, 0.08916679478352389], 
reward next is 0.9108, 
noisyNet noise sample is [array([0.6138205], dtype=float32), -0.8269433]. 
=============================================
[2019-04-06 23:09:07,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:09:07,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:09:07,756] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run40
[2019-04-06 23:09:14,754] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:09:14,754] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:09:14,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run40
[2019-04-06 23:09:20,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:09:20,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:09:20,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run40
[2019-04-06 23:09:32,638] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6775625e-13 3.8330606e-11 6.0657740e-13 6.7687847e-07 8.1835255e-14
 9.9999928e-01 5.3727481e-13], sum to 1.0000
[2019-04-06 23:09:32,643] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6982
[2019-04-06 23:09:32,822] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 83.0, 0.0, 0.0, 26.0, 25.0814771004057, 0.3103114309494024, 0.0, 1.0, 52155.59258657863], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 851400.0000, 
sim time next is 853200.0000, 
raw observation next is [-3.4, 83.0, 0.0, 0.0, 26.0, 24.98527765827593, 0.2906756241076814, 0.0, 1.0, 46474.62687792059], 
processed observation next is [1.0, 0.9130434782608695, 0.368421052631579, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5821064715229941, 0.5968918747025604, 0.0, 1.0, 0.2213077470377171], 
reward next is 0.7787, 
noisyNet noise sample is [array([0.19717817], dtype=float32), -2.9905636]. 
=============================================
[2019-04-06 23:09:33,928] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:09:33,929] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:09:33,932] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run40
[2019-04-06 23:09:46,571] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4025432e-15 6.3729057e-13 3.3380361e-16 1.7049182e-07 2.9010656e-16
 9.9999988e-01 6.4001852e-15], sum to 1.0000
[2019-04-06 23:09:46,572] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5297
[2019-04-06 23:09:46,669] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.25, 80.5, 0.0, 0.0, 26.0, 25.54559118834849, 0.4849176258494902, 0.0, 1.0, 31024.159164120065], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1578600.0000, 
sim time next is 1580400.0000, 
raw observation next is [5.5, 79.0, 0.0, 0.0, 26.0, 25.45265509301618, 0.4923488882121279, 0.0, 1.0, 64180.127288984484], 
processed observation next is [1.0, 0.30434782608695654, 0.6149584487534627, 0.79, 0.0, 0.0, 0.6666666666666666, 0.6210545910846816, 0.6641162960707093, 0.0, 1.0, 0.30561965375706895], 
reward next is 0.6944, 
noisyNet noise sample is [array([-1.2681051], dtype=float32), 0.4997931]. 
=============================================
[2019-04-06 23:10:02,772] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:10:02,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:10:02,776] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run40
[2019-04-06 23:10:11,849] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-06 23:10:11,851] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:10:11,851] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:10:11,855] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run90
[2019-04-06 23:10:12,005] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:10:12,006] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:10:12,016] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run90
[2019-04-06 23:10:12,125] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:10:12,128] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:10:12,157] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run90
[2019-04-06 23:11:44,533] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.07063231], dtype=float32), 0.14019199]
[2019-04-06 23:11:44,534] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-0.3, 89.0, 0.0, 0.0, 26.0, 25.17291966113001, 0.4097999240423305, 0.0, 1.0, 43076.11672670411]
[2019-04-06 23:11:44,534] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 23:11:44,535] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.0644096e-14 3.5575735e-12 4.6565958e-14 9.5062987e-08 4.5236675e-15
 9.9999988e-01 2.2518600e-14], sampled 0.26792473027192387
[2019-04-06 23:12:55,113] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 23:13:15,656] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 23:13:16,755] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 23:13:17,778] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1780000, evaluation results [1780000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 23:13:38,337] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.0473084e-13 8.8948078e-11 4.9881594e-13 1.0744947e-06 1.8567245e-14
 9.9999893e-01 1.1670042e-13], sum to 1.0000
[2019-04-06 23:13:38,338] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1612
[2019-04-06 23:13:38,440] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.38120711482748, 0.1178963331155424, 0.0, 1.0, 41354.057980619014], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1999800.0000, 
sim time next is 2001600.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.25808535745524, 0.08749486572508425, 0.0, 1.0, 41260.30465506927], 
processed observation next is [1.0, 0.17391304347826086, 0.30747922437673136, 0.83, 0.0, 0.0, 0.6666666666666666, 0.52150711312127, 0.5291649552416947, 0.0, 1.0, 0.19647764121461556], 
reward next is 0.8035, 
noisyNet noise sample is [array([-0.97989494], dtype=float32), 0.011249765]. 
=============================================
[2019-04-06 23:13:47,138] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3721502e-16 5.1773402e-14 1.8344116e-15 1.8792996e-08 3.8231653e-17
 1.0000000e+00 6.9639389e-17], sum to 1.0000
[2019-04-06 23:13:47,138] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7985
[2019-04-06 23:13:47,225] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.0, 100.0, 99.0, 647.0, 26.0, 26.42574894519258, 0.573362403467943, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3144600.0000, 
sim time next is 3146400.0000, 
raw observation next is [7.0, 100.0, 103.5, 696.5, 26.0, 26.64464233686327, 0.6339443979195666, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.6565096952908588, 1.0, 0.345, 0.7696132596685082, 0.6666666666666666, 0.7203868614052725, 0.7113147993065222, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1714636], dtype=float32), -1.2473366]. 
=============================================
[2019-04-06 23:14:25,508] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8723395e-13 4.0120771e-11 5.6292753e-13 5.7091493e-06 3.0406957e-13
 9.9999428e-01 4.5173869e-13], sum to 1.0000
[2019-04-06 23:14:25,508] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3029
[2019-04-06 23:14:25,654] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.3, 29.0, 92.0, 256.5, 26.0, 25.92260043141344, 0.3076265022715465, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2563200.0000, 
sim time next is 2565000.0000, 
raw observation next is [3.0, 29.0, 70.0, 162.0, 26.0, 25.27933620936296, 0.3507715674062472, 1.0, 1.0, 74700.16838848441], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.29, 0.23333333333333334, 0.17900552486187846, 0.6666666666666666, 0.6066113507802466, 0.6169238558020824, 1.0, 1.0, 0.3557150875642115], 
reward next is 0.6443, 
noisyNet noise sample is [array([-1.0102737], dtype=float32), -0.87230897]. 
=============================================
[2019-04-06 23:14:25,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[79.99915]
 [80.52842]
 [80.77024]
 [80.52441]
 [80.71083]], R is [[80.21878815]
 [80.41660309]
 [80.61243439]
 [80.80631256]
 [80.99825287]].
[2019-04-06 23:14:38,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:14:38,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:14:38,540] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run41
[2019-04-06 23:14:58,859] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0455006e-12 5.1434287e-11 8.7800508e-13 2.1346397e-05 2.9682805e-13
 9.9997866e-01 4.5809884e-12], sum to 1.0000
[2019-04-06 23:14:58,859] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4387
[2019-04-06 23:14:58,931] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.0, 76.0, 0.0, 0.0, 26.0, 24.48140527495197, 0.2209205188449593, 0.0, 1.0, 43747.47639264729], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3301200.0000, 
sim time next is 3303000.0000, 
raw observation next is [-10.5, 76.0, 0.0, 0.0, 26.0, 24.39886148542573, 0.1883777948123616, 0.0, 1.0, 43630.78174125867], 
processed observation next is [1.0, 0.21739130434782608, 0.17174515235457063, 0.76, 0.0, 0.0, 0.6666666666666666, 0.5332384571188108, 0.5627925982707872, 0.0, 1.0, 0.207765627339327], 
reward next is 0.7922, 
noisyNet noise sample is [array([1.8296865], dtype=float32), -3.950917]. 
=============================================
[2019-04-06 23:14:58,935] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[78.86773]
 [79.38191]
 [79.80557]
 [80.29637]
 [80.75514]], R is [[78.30075073]
 [78.30942535]
 [78.31758881]
 [78.3249054 ]
 [78.33243561]].
[2019-04-06 23:15:18,025] A3C_AGENT_WORKER-Thread-11 INFO:Local step 113500, global step 1796713: loss 0.0726
[2019-04-06 23:15:18,025] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 113500, global step 1796713: learning rate 0.0000
[2019-04-06 23:15:19,556] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3956203e-11 2.0892124e-09 5.9813196e-11 3.6452798e-06 5.8446767e-12
 9.9999630e-01 6.3791160e-11], sum to 1.0000
[2019-04-06 23:15:19,556] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8865
[2019-04-06 23:15:19,877] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 54.0, 40.0, 416.0, 26.0, 23.30715263994946, -0.005743958792985865, 0.0, 1.0, 149924.4273040051], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2449800.0000, 
sim time next is 2451600.0000, 
raw observation next is [-7.3, 50.0, 50.5, 540.5, 26.0, 24.92156052500962, 0.2356530634984777, 0.0, 1.0, 86671.5443003351], 
processed observation next is [0.0, 0.391304347826087, 0.26038781163434904, 0.5, 0.16833333333333333, 0.5972375690607735, 0.6666666666666666, 0.5767967104174684, 0.5785510211661592, 0.0, 1.0, 0.4127216395254052], 
reward next is 0.5873, 
noisyNet noise sample is [array([-1.7045883], dtype=float32), -1.4420538]. 
=============================================
[2019-04-06 23:15:22,703] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7938299e-14 3.3087263e-12 1.1521005e-14 1.1384775e-08 5.6212545e-15
 1.0000000e+00 1.4551836e-14], sum to 1.0000
[2019-04-06 23:15:22,703] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4591
[2019-04-06 23:15:22,808] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 69.5, 0.0, 0.0, 26.0, 25.44518112023595, 0.4398324453751692, 0.0, 1.0, 24949.63512419465], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3468600.0000, 
sim time next is 3470400.0000, 
raw observation next is [1.0, 67.0, 0.0, 0.0, 26.0, 25.43968695027788, 0.4030628161108434, 0.0, 1.0, 25978.8163271345], 
processed observation next is [1.0, 0.17391304347826086, 0.4903047091412743, 0.67, 0.0, 0.0, 0.6666666666666666, 0.6199739125231568, 0.6343542720369478, 0.0, 1.0, 0.12370864917683096], 
reward next is 0.8763, 
noisyNet noise sample is [array([1.1911188], dtype=float32), -0.01769869]. 
=============================================
[2019-04-06 23:15:22,928] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:15:22,928] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:15:22,933] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run41
[2019-04-06 23:15:48,405] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-06 23:15:48,409] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:15:48,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:15:48,413] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:15:48,413] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:15:48,417] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:15:48,418] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:15:48,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run91
[2019-04-06 23:15:48,426] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run91
[2019-04-06 23:15:48,427] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run91
[2019-04-06 23:18:01,664] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.07005349], dtype=float32), 0.14063373]
[2019-04-06 23:18:01,664] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-2.25, 38.0, 0.0, 0.0, 26.0, 25.00968722176088, 0.2679812362001242, 0.0, 1.0, 44035.50482404793]
[2019-04-06 23:18:01,664] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 23:18:01,665] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.1628604e-12 2.5993921e-10 5.2894308e-12 1.4139473e-06 8.7605032e-13
 9.9999857e-01 3.0494572e-12], sampled 0.5669925282423766
[2019-04-06 23:18:29,834] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 23:18:52,452] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 23:18:52,927] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 23:18:53,950] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1800000, evaluation results [1800000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 23:19:17,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:19:17,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:19:17,056] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run41
[2019-04-06 23:19:17,169] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.5000836e-17 9.7106568e-15 2.8498963e-16 7.3315065e-09 5.3463059e-17
 1.0000000e+00 2.3150234e-16], sum to 1.0000
[2019-04-06 23:19:17,170] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6254
[2019-04-06 23:19:17,193] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.05, 89.5, 96.0, 0.0, 26.0, 26.60601044113599, 0.6549575679572421, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 988200.0000, 
sim time next is 990000.0000, 
raw observation next is [11.6, 86.0, 108.0, 0.0, 26.0, 26.67253445430246, 0.6693162272095708, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.7839335180055402, 0.86, 0.36, 0.0, 0.6666666666666666, 0.7227112045252051, 0.723105409069857, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.22327252], dtype=float32), 0.40494362]. 
=============================================
[2019-04-06 23:19:17,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[98.968346]
 [99.11984 ]
 [98.833115]
 [98.577286]
 [98.36715 ]], R is [[99.28833771]
 [99.29545593]
 [99.30250549]
 [99.30947876]
 [99.31638336]].
[2019-04-06 23:19:22,832] A3C_AGENT_WORKER-Thread-3 INFO:Local step 113500, global step 1804534: loss 0.0614
[2019-04-06 23:19:22,833] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 113500, global step 1804534: learning rate 0.0000
[2019-04-06 23:19:24,836] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.5226943e-14 1.4631808e-12 2.8765764e-14 1.8858442e-07 7.3885185e-15
 9.9999976e-01 2.7795938e-14], sum to 1.0000
[2019-04-06 23:19:24,836] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2211
[2019-04-06 23:19:24,976] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 74.0, 0.0, 0.0, 26.0, 25.09691386204256, 0.3641323225708768, 1.0, 1.0, 12093.232786801853], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4606200.0000, 
sim time next is 4608000.0000, 
raw observation next is [-2.0, 71.0, 61.5, 85.5, 26.0, 25.46517348092254, 0.4038579169924736, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.40720221606648205, 0.71, 0.205, 0.09447513812154697, 0.6666666666666666, 0.6220977900768784, 0.6346193056641579, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5998741], dtype=float32), 1.5834448]. 
=============================================
[2019-04-06 23:19:24,987] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[86.70031 ]
 [86.45638 ]
 [86.63933 ]
 [86.805275]
 [87.001656]], R is [[87.28405762]
 [87.35363007]
 [87.30754089]
 [87.26210785]
 [87.21717834]].
[2019-04-06 23:19:27,882] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2601649e-13 1.0212088e-10 1.0997792e-12 1.5264011e-07 1.0984076e-13
 9.9999988e-01 5.5895918e-13], sum to 1.0000
[2019-04-06 23:19:27,884] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6853
[2019-04-06 23:19:27,897] A3C_AGENT_WORKER-Thread-11 INFO:Local step 114000, global step 1805369: loss 1.9513
[2019-04-06 23:19:27,898] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 114000, global step 1805369: learning rate 0.0000
[2019-04-06 23:19:28,177] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 36.5, 23.0, 0.0, 26.0, 25.1516387895333, 0.1718001631319643, 1.0, 1.0, 22072.195803245635], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 462600.0000, 
sim time next is 464400.0000, 
raw observation next is [-6.2, 33.0, 42.5, 0.0, 26.0, 25.48329997913473, 0.2023595037835793, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.2908587257617729, 0.33, 0.14166666666666666, 0.0, 0.6666666666666666, 0.623608331594561, 0.5674531679278597, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6063312], dtype=float32), -2.7345567]. 
=============================================
[2019-04-06 23:19:29,789] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.1088262e-15 1.9307608e-13 1.6784910e-14 1.0712179e-07 7.2156264e-16
 9.9999988e-01 1.0100599e-15], sum to 1.0000
[2019-04-06 23:19:29,789] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9588
[2019-04-06 23:19:29,846] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 92.0, 161.5, 3.0, 26.0, 26.44168955088109, 0.5779535498566761, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4701600.0000, 
sim time next is 4703400.0000, 
raw observation next is [0.0, 92.0, 208.0, 6.0, 26.0, 26.44882807218339, 0.5934658210484952, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.46260387811634357, 0.92, 0.6933333333333334, 0.0066298342541436465, 0.6666666666666666, 0.7040690060152824, 0.6978219403494984, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.26480523], dtype=float32), 0.21219549]. 
=============================================
[2019-04-06 23:19:42,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:19:42,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:19:42,392] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run41
[2019-04-06 23:19:42,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:19:42,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:19:42,693] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run41
[2019-04-06 23:19:51,503] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:19:51,503] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:19:51,507] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run41
[2019-04-06 23:19:52,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:19:52,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:19:52,112] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run41
[2019-04-06 23:19:53,565] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9526779e-14 1.4090932e-11 1.9599605e-13 7.0266856e-07 4.7711872e-14
 9.9999928e-01 1.5146209e-13], sum to 1.0000
[2019-04-06 23:19:53,565] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5515
[2019-04-06 23:19:53,817] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 54.5, 114.0, 816.0, 26.0, 25.18603449454581, 0.4333373872147885, 0.0, 1.0, 17570.780964790243], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3583800.0000, 
sim time next is 3585600.0000, 
raw observation next is [-3.0, 55.0, 116.0, 819.5, 26.0, 25.17921808236447, 0.445315906348072, 0.0, 1.0, 27603.257874367144], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.55, 0.38666666666666666, 0.905524861878453, 0.6666666666666666, 0.5982681735303726, 0.6484386354493573, 0.0, 1.0, 0.13144408511603403], 
reward next is 0.8686, 
noisyNet noise sample is [array([0.5364162], dtype=float32), -0.05192005]. 
=============================================
[2019-04-06 23:19:55,182] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:19:55,182] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:19:55,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run41
[2019-04-06 23:19:56,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:19:56,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:19:56,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run41
[2019-04-06 23:19:58,164] A3C_AGENT_WORKER-Thread-17 INFO:Local step 113500, global step 1809892: loss 0.0663
[2019-04-06 23:19:58,164] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 113500, global step 1809892: learning rate 0.0000
[2019-04-06 23:19:58,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:19:58,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:19:58,485] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run41
[2019-04-06 23:20:16,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:20:16,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:20:16,436] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run41
[2019-04-06 23:20:16,509] A3C_AGENT_WORKER-Thread-3 INFO:Local step 114000, global step 1812180: loss 1.9356
[2019-04-06 23:20:16,510] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 114000, global step 1812180: learning rate 0.0000
[2019-04-06 23:20:25,183] A3C_AGENT_WORKER-Thread-12 INFO:Local step 113500, global step 1813290: loss 0.0748
[2019-04-06 23:20:25,184] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 113500, global step 1813290: learning rate 0.0000
[2019-04-06 23:20:25,255] A3C_AGENT_WORKER-Thread-16 INFO:Local step 113500, global step 1813302: loss 0.0750
[2019-04-06 23:20:25,255] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 113500, global step 1813302: learning rate 0.0000
[2019-04-06 23:20:27,501] A3C_AGENT_WORKER-Thread-11 INFO:Local step 114500, global step 1813601: loss 2.4665
[2019-04-06 23:20:27,502] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 114500, global step 1813601: learning rate 0.0000
[2019-04-06 23:20:34,451] A3C_AGENT_WORKER-Thread-13 INFO:Local step 113500, global step 1814606: loss 0.0692
[2019-04-06 23:20:34,464] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 113500, global step 1814606: learning rate 0.0000
[2019-04-06 23:20:35,473] A3C_AGENT_WORKER-Thread-6 INFO:Local step 113500, global step 1814737: loss 0.0805
[2019-04-06 23:20:35,473] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 113500, global step 1814737: learning rate 0.0000
[2019-04-06 23:20:36,738] A3C_AGENT_WORKER-Thread-5 INFO:Local step 113500, global step 1814910: loss 0.0698
[2019-04-06 23:20:36,739] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 113500, global step 1814910: learning rate 0.0000
[2019-04-06 23:20:38,251] A3C_AGENT_WORKER-Thread-18 INFO:Local step 113500, global step 1815139: loss 0.0726
[2019-04-06 23:20:38,252] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 113500, global step 1815139: learning rate 0.0000
[2019-04-06 23:20:41,099] A3C_AGENT_WORKER-Thread-19 INFO:Local step 113500, global step 1815508: loss 0.0718
[2019-04-06 23:20:41,100] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 113500, global step 1815508: learning rate 0.0000
[2019-04-06 23:20:49,266] A3C_AGENT_WORKER-Thread-17 INFO:Local step 114000, global step 1816756: loss 1.9568
[2019-04-06 23:20:49,268] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 114000, global step 1816756: learning rate 0.0000
[2019-04-06 23:20:54,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:20:54,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:20:54,535] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run41
[2019-04-06 23:20:56,241] A3C_AGENT_WORKER-Thread-15 INFO:Local step 113500, global step 1817765: loss 0.0708
[2019-04-06 23:20:56,242] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 113500, global step 1817765: learning rate 0.0000
[2019-04-06 23:21:02,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:21:02,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:21:02,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run41
[2019-04-06 23:21:07,245] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3672883e-14 1.0361806e-11 2.0953479e-14 2.4107277e-07 1.8397520e-14
 9.9999976e-01 1.0807803e-13], sum to 1.0000
[2019-04-06 23:21:07,246] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1159
[2019-04-06 23:21:07,306] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 50.0, 110.0, 611.0, 26.0, 25.58458720462538, 0.3591352820367154, 1.0, 1.0, 24820.695385224884], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 738000.0000, 
sim time next is 739800.0000, 
raw observation next is [0.5, 47.5, 89.0, 773.0, 26.0, 25.35882971036455, 0.382069213817876, 1.0, 1.0, 18680.597996368397], 
processed observation next is [1.0, 0.5652173913043478, 0.4764542936288089, 0.475, 0.2966666666666667, 0.8541436464088398, 0.6666666666666666, 0.6132358091970458, 0.6273564046059587, 1.0, 1.0, 0.08895522855413522], 
reward next is 0.9110, 
noisyNet noise sample is [array([-0.4037863], dtype=float32), 1.1152419]. 
=============================================
[2019-04-06 23:21:11,046] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:21:11,046] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:21:11,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run41
[2019-04-06 23:21:21,974] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 23:21:21,979] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:21:21,979] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:21:21,983] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run92
[2019-04-06 23:21:22,057] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:21:22,057] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:21:22,061] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run92
[2019-04-06 23:21:22,170] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:21:22,171] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:21:22,216] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run92
[2019-04-06 23:24:05,992] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 23:24:08,854] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.07105553], dtype=float32), 0.14116266]
[2019-04-06 23:24:08,854] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-10.0, 58.0, 0.0, 0.0, 26.0, 24.85356004560278, 0.3175795989767824, 0.0, 1.0, 44107.971394532324]
[2019-04-06 23:24:08,854] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 23:24:08,855] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.6318458e-12 2.1533034e-10 6.2335176e-12 1.5094153e-06 9.2980831e-13
 9.9999845e-01 3.7596918e-12], sampled 0.23957322097453115
[2019-04-06 23:24:26,946] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 23:24:28,192] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 23:24:29,216] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1820000, evaluation results [1820000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 23:24:31,092] A3C_AGENT_WORKER-Thread-16 INFO:Local step 114000, global step 1820269: loss 1.9661
[2019-04-06 23:24:31,099] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 114000, global step 1820269: learning rate 0.0000
[2019-04-06 23:24:31,760] A3C_AGENT_WORKER-Thread-12 INFO:Local step 114000, global step 1820355: loss 1.9611
[2019-04-06 23:24:31,761] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 114000, global step 1820355: learning rate 0.0000
[2019-04-06 23:24:33,012] A3C_AGENT_WORKER-Thread-3 INFO:Local step 114500, global step 1820511: loss 2.2761
[2019-04-06 23:24:33,012] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 114500, global step 1820511: learning rate 0.0000
[2019-04-06 23:24:39,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:24:39,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:24:39,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run41
[2019-04-06 23:24:43,019] A3C_AGENT_WORKER-Thread-11 INFO:Local step 115000, global step 1822055: loss 13.7745
[2019-04-06 23:24:43,022] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 115000, global step 1822055: learning rate 0.0000
[2019-04-06 23:24:44,832] A3C_AGENT_WORKER-Thread-13 INFO:Local step 114000, global step 1822414: loss 1.9239
[2019-04-06 23:24:44,833] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 114000, global step 1822414: learning rate 0.0000
[2019-04-06 23:24:46,974] A3C_AGENT_WORKER-Thread-6 INFO:Local step 114000, global step 1822730: loss 2.0048
[2019-04-06 23:24:47,003] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 114000, global step 1822730: learning rate 0.0000
[2019-04-06 23:24:47,769] A3C_AGENT_WORKER-Thread-5 INFO:Local step 114000, global step 1822858: loss 1.9640
[2019-04-06 23:24:47,770] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 114000, global step 1822858: learning rate 0.0000
[2019-04-06 23:24:48,904] A3C_AGENT_WORKER-Thread-18 INFO:Local step 114000, global step 1823049: loss 1.9973
[2019-04-06 23:24:48,905] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 114000, global step 1823049: learning rate 0.0000
[2019-04-06 23:24:51,086] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.21404495e-14 3.93326214e-12 2.67608743e-13 1.04365711e-06
 7.79181136e-14 9.99998927e-01 3.39924080e-14], sum to 1.0000
[2019-04-06 23:24:51,087] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4673
[2019-04-06 23:24:51,112] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.0, 23.0, 0.0, 0.0, 26.0, 26.04829821618703, 0.586995851297922, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4996800.0000, 
sim time next is 4998600.0000, 
raw observation next is [5.0, 26.0, 0.0, 0.0, 26.0, 25.84309378147385, 0.5395040304005315, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.6011080332409973, 0.26, 0.0, 0.0, 0.6666666666666666, 0.6535911484561542, 0.6798346768001772, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.08302717], dtype=float32), -1.5954152]. 
=============================================
[2019-04-06 23:24:51,599] A3C_AGENT_WORKER-Thread-19 INFO:Local step 114000, global step 1823460: loss 2.0116
[2019-04-06 23:24:51,600] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 114000, global step 1823460: learning rate 0.0000
[2019-04-06 23:24:55,168] A3C_AGENT_WORKER-Thread-20 INFO:Local step 113500, global step 1823913: loss 0.0815
[2019-04-06 23:24:55,168] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 113500, global step 1823913: learning rate 0.0000
[2019-04-06 23:24:56,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:24:56,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:24:56,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run41
[2019-04-06 23:25:02,230] A3C_AGENT_WORKER-Thread-17 INFO:Local step 114500, global step 1824856: loss 2.2138
[2019-04-06 23:25:02,230] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 114500, global step 1824856: learning rate 0.0000
[2019-04-06 23:25:02,561] A3C_AGENT_WORKER-Thread-10 INFO:Local step 113500, global step 1824912: loss 0.0744
[2019-04-06 23:25:02,562] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 113500, global step 1824912: learning rate 0.0000
[2019-04-06 23:25:02,679] A3C_AGENT_WORKER-Thread-2 INFO:Local step 113500, global step 1824928: loss 0.0859
[2019-04-06 23:25:02,679] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 113500, global step 1824928: learning rate 0.0000
[2019-04-06 23:25:09,792] A3C_AGENT_WORKER-Thread-15 INFO:Local step 114000, global step 1825915: loss 2.0304
[2019-04-06 23:25:09,792] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 114000, global step 1825915: learning rate 0.0000
[2019-04-06 23:25:20,808] A3C_AGENT_WORKER-Thread-4 INFO:Local step 113500, global step 1827184: loss 0.0833
[2019-04-06 23:25:20,808] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 113500, global step 1827184: learning rate 0.0000
[2019-04-06 23:25:29,130] A3C_AGENT_WORKER-Thread-11 INFO:Local step 115500, global step 1828163: loss 1.3745
[2019-04-06 23:25:29,130] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 115500, global step 1828163: learning rate 0.0000
[2019-04-06 23:25:32,988] A3C_AGENT_WORKER-Thread-12 INFO:Local step 114500, global step 1828604: loss 2.2390
[2019-04-06 23:25:32,989] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 114500, global step 1828604: learning rate 0.0000
[2019-04-06 23:25:33,541] A3C_AGENT_WORKER-Thread-16 INFO:Local step 114500, global step 1828681: loss 2.2493
[2019-04-06 23:25:33,542] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 114500, global step 1828681: learning rate 0.0000
[2019-04-06 23:25:38,568] A3C_AGENT_WORKER-Thread-3 INFO:Local step 115000, global step 1829220: loss 13.4166
[2019-04-06 23:25:38,568] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 115000, global step 1829220: learning rate 0.0000
[2019-04-06 23:25:39,076] A3C_AGENT_WORKER-Thread-14 INFO:Local step 113500, global step 1829277: loss 0.0890
[2019-04-06 23:25:39,076] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 113500, global step 1829277: learning rate 0.0000
[2019-04-06 23:25:41,328] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.6712433e-14 1.5127455e-11 1.8156156e-12 1.1198418e-06 3.2675970e-14
 9.9999893e-01 1.5631707e-13], sum to 1.0000
[2019-04-06 23:25:41,328] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8121
[2019-04-06 23:25:41,539] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 68.0, 135.0, 51.0, 26.0, 25.18753304071021, 0.2427406720562342, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 639000.0000, 
sim time next is 640800.0000, 
raw observation next is [-3.9, 65.0, 117.5, 25.5, 26.0, 24.99688492800137, 0.1926373777704105, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3545706371191136, 0.65, 0.39166666666666666, 0.0281767955801105, 0.6666666666666666, 0.5830737440001142, 0.5642124592568035, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.35047436], dtype=float32), 0.3636242]. 
=============================================
[2019-04-06 23:25:41,978] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0359193e-16 9.7701812e-15 2.8799395e-16 1.4936973e-08 1.0914434e-16
 1.0000000e+00 5.7377840e-17], sum to 1.0000
[2019-04-06 23:25:41,978] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3663
[2019-04-06 23:25:42,011] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 26.0, 25.58534340089899, 0.517725399667309, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1018800.0000, 
sim time next is 1020600.0000, 
raw observation next is [14.4, 79.0, 0.0, 0.0, 26.0, 25.33872862070843, 0.4565958604569877, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.8614958448753465, 0.79, 0.0, 0.0, 0.6666666666666666, 0.6115607183923691, 0.6521986201523292, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.00316983], dtype=float32), -0.21276209]. 
=============================================
[2019-04-06 23:25:43,765] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.4984192e-17 4.7775741e-14 7.1356380e-18 7.5906819e-09 5.5276642e-17
 1.0000000e+00 1.9733267e-17], sum to 1.0000
[2019-04-06 23:25:43,765] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2576
[2019-04-06 23:25:43,847] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.5, 70.0, 184.0, 107.5, 26.0, 27.26126824233825, 0.9081180699825321, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1076400.0000, 
sim time next is 1078200.0000, 
raw observation next is [16.05, 67.5, 254.0, 215.0, 26.0, 27.48533988829138, 0.6458381962412766, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.9072022160664821, 0.675, 0.8466666666666667, 0.23756906077348067, 0.6666666666666666, 0.7904449906909484, 0.7152793987470921, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.90479225], dtype=float32), -0.62457705]. 
=============================================
[2019-04-06 23:25:47,260] A3C_AGENT_WORKER-Thread-13 INFO:Local step 114500, global step 1830400: loss 2.2211
[2019-04-06 23:25:47,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 114500, global step 1830400: learning rate 0.0000
[2019-04-06 23:25:47,503] A3C_AGENT_WORKER-Thread-6 INFO:Local step 114500, global step 1830443: loss 2.2710
[2019-04-06 23:25:47,504] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 114500, global step 1830443: learning rate 0.0000
[2019-04-06 23:25:49,955] A3C_AGENT_WORKER-Thread-5 INFO:Local step 114500, global step 1830805: loss 2.3203
[2019-04-06 23:25:49,956] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 114500, global step 1830805: learning rate 0.0000
[2019-04-06 23:25:50,304] A3C_AGENT_WORKER-Thread-20 INFO:Local step 114000, global step 1830862: loss 2.0702
[2019-04-06 23:25:50,305] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 114000, global step 1830862: learning rate 0.0000
[2019-04-06 23:25:50,812] A3C_AGENT_WORKER-Thread-18 INFO:Local step 114500, global step 1830950: loss 2.2732
[2019-04-06 23:25:50,812] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 114500, global step 1830950: learning rate 0.0000
[2019-04-06 23:25:54,680] A3C_AGENT_WORKER-Thread-19 INFO:Local step 114500, global step 1831577: loss 2.2661
[2019-04-06 23:25:54,681] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 114500, global step 1831577: learning rate 0.0000
[2019-04-06 23:25:57,050] A3C_AGENT_WORKER-Thread-10 INFO:Local step 114000, global step 1831937: loss 2.0285
[2019-04-06 23:25:57,065] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 114000, global step 1831937: learning rate 0.0000
[2019-04-06 23:25:58,639] A3C_AGENT_WORKER-Thread-2 INFO:Local step 114000, global step 1832175: loss 2.0697
[2019-04-06 23:25:58,639] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 114000, global step 1832175: learning rate 0.0000
[2019-04-06 23:26:04,041] A3C_AGENT_WORKER-Thread-17 INFO:Local step 115000, global step 1832987: loss 13.6274
[2019-04-06 23:26:04,055] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 115000, global step 1832987: learning rate 0.0000
[2019-04-06 23:26:09,217] A3C_AGENT_WORKER-Thread-15 INFO:Local step 114500, global step 1833852: loss 2.3281
[2019-04-06 23:26:09,217] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 114500, global step 1833852: learning rate 0.0000
[2019-04-06 23:26:12,292] A3C_AGENT_WORKER-Thread-11 INFO:Local step 116000, global step 1834384: loss 0.8544
[2019-04-06 23:26:12,293] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 116000, global step 1834384: learning rate 0.0000
[2019-04-06 23:26:13,439] A3C_AGENT_WORKER-Thread-4 INFO:Local step 114000, global step 1834566: loss 2.1050
[2019-04-06 23:26:13,460] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 114000, global step 1834566: learning rate 0.0000
[2019-04-06 23:26:21,364] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.05382676e-13 1.40493962e-11 4.75561918e-13 1.92448496e-07
 3.11720999e-14 9.99999762e-01 2.07951481e-13], sum to 1.0000
[2019-04-06 23:26:21,365] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3308
[2019-04-06 23:26:21,402] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 26.0, 24.99813204504273, 0.3655692366369291, 0.0, 1.0, 43522.01973677244], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2935800.0000, 
sim time next is 2937600.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 26.0, 24.9860413662608, 0.3559384781744819, 0.0, 1.0, 43380.843845764226], 
processed observation next is [0.0, 0.0, 0.40720221606648205, 0.85, 0.0, 0.0, 0.6666666666666666, 0.5821701138550667, 0.6186461593914939, 0.0, 1.0, 0.20657544688459156], 
reward next is 0.7934, 
noisyNet noise sample is [array([1.0668756], dtype=float32), -1.1629428]. 
=============================================
[2019-04-06 23:26:21,487] A3C_AGENT_WORKER-Thread-3 INFO:Local step 115500, global step 1835821: loss 1.3852
[2019-04-06 23:26:21,506] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 115500, global step 1835821: learning rate 0.0000
[2019-04-06 23:26:22,382] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:26:22,383] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:26:22,386] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run42
[2019-04-06 23:26:30,078] A3C_AGENT_WORKER-Thread-14 INFO:Local step 114000, global step 1837101: loss 2.1610
[2019-04-06 23:26:30,079] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 114000, global step 1837101: learning rate 0.0000
[2019-04-06 23:26:31,653] A3C_AGENT_WORKER-Thread-12 INFO:Local step 115000, global step 1837358: loss 13.5751
[2019-04-06 23:26:31,653] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 115000, global step 1837358: learning rate 0.0000
[2019-04-06 23:26:33,800] A3C_AGENT_WORKER-Thread-16 INFO:Local step 115000, global step 1837567: loss 13.5103
[2019-04-06 23:26:33,800] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 115000, global step 1837567: learning rate 0.0000
[2019-04-06 23:26:51,668] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6817320e-12 2.6977720e-10 3.2024461e-12 3.5781059e-07 8.3735854e-14
 9.9999964e-01 4.8416886e-13], sum to 1.0000
[2019-04-06 23:26:51,668] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0279
[2019-04-06 23:26:51,844] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 55.0, 69.5, 570.5, 26.0, 25.14849951573077, 0.407805903577534, 0.0, 1.0, 12471.908781945493], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2995200.0000, 
sim time next is 2997000.0000, 
raw observation next is [-1.0, 55.0, 56.0, 474.0, 26.0, 25.10925670332085, 0.3801365180209062, 0.0, 1.0, 20013.960448147347], 
processed observation next is [0.0, 0.6956521739130435, 0.4349030470914128, 0.55, 0.18666666666666668, 0.523756906077348, 0.6666666666666666, 0.5924380586100707, 0.6267121726736354, 0.0, 1.0, 0.09530457356260641], 
reward next is 0.9047, 
noisyNet noise sample is [array([-1.914823], dtype=float32), -1.4670761]. 
=============================================
[2019-04-06 23:26:51,857] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[79.65416 ]
 [79.9818  ]
 [79.921906]
 [79.74782 ]
 [80.07141 ]], R is [[79.55370331]
 [79.69877625]
 [79.77973175]
 [79.84777832]
 [79.98989868]].
[2019-04-06 23:26:54,186] A3C_AGENT_WORKER-Thread-17 INFO:Local step 115500, global step 1839330: loss 1.4280
[2019-04-06 23:26:54,187] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 115500, global step 1839330: learning rate 0.0000
[2019-04-06 23:26:54,306] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.7821281e-13 1.7895717e-10 1.7461318e-12 2.2375762e-07 2.8829714e-13
 9.9999976e-01 1.2186983e-13], sum to 1.0000
[2019-04-06 23:26:54,306] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8337
[2019-04-06 23:26:54,414] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 73.5, 0.0, 0.0, 26.0, 23.70667593914112, -0.0200800353785007, 0.0, 1.0, 40260.71763934295], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3047400.0000, 
sim time next is 3049200.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 26.0, 23.73107201408202, -0.02568021301216675, 0.0, 1.0, 40422.4307655973], 
processed observation next is [0.0, 0.30434782608695654, 0.296398891966759, 0.77, 0.0, 0.0, 0.6666666666666666, 0.477589334506835, 0.4914399289959444, 0.0, 1.0, 0.19248776555046335], 
reward next is 0.8075, 
noisyNet noise sample is [array([0.2465806], dtype=float32), -0.18314028]. 
=============================================
[2019-04-06 23:26:54,571] A3C_AGENT_WORKER-Thread-13 INFO:Local step 115000, global step 1839369: loss 13.4061
[2019-04-06 23:26:54,572] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 115000, global step 1839369: learning rate 0.0000
[2019-04-06 23:26:55,023] A3C_AGENT_WORKER-Thread-6 INFO:Local step 115000, global step 1839409: loss 13.5082
[2019-04-06 23:26:55,024] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 115000, global step 1839409: learning rate 0.0000
[2019-04-06 23:26:57,237] A3C_AGENT_WORKER-Thread-20 INFO:Local step 114500, global step 1839628: loss 2.3881
[2019-04-06 23:26:57,238] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 114500, global step 1839628: learning rate 0.0000
[2019-04-06 23:26:58,291] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.0532437e-14 2.1410922e-11 1.9208428e-13 3.3403882e-07 1.1604548e-13
 9.9999964e-01 7.4218267e-14], sum to 1.0000
[2019-04-06 23:26:58,291] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7237
[2019-04-06 23:26:58,408] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.5, 40.5, 99.0, 775.0, 26.0, 25.11441300719846, 0.3633598400463478, 0.0, 1.0, 12470.133792156426], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3076200.0000, 
sim time next is 3078000.0000, 
raw observation next is [0.0, 39.0, 91.5, 724.0, 26.0, 25.1194115537939, 0.3653356299190771, 0.0, 1.0, 12468.915084310598], 
processed observation next is [0.0, 0.6521739130434783, 0.46260387811634357, 0.39, 0.305, 0.8, 0.6666666666666666, 0.5932842961494916, 0.6217785433063591, 0.0, 1.0, 0.05937578611576475], 
reward next is 0.9406, 
noisyNet noise sample is [array([-2.2457032], dtype=float32), 2.098568]. 
=============================================
[2019-04-06 23:26:58,413] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[77.83142]
 [77.94652]
 [78.03348]
 [78.03424]
 [78.07073]], R is [[77.82266235]
 [77.98505402]
 [78.11611176]
 [78.24583435]
 [78.43367004]].
[2019-04-06 23:27:00,560] A3C_AGENT_WORKER-Thread-5 INFO:Local step 115000, global step 1839929: loss 13.5889
[2019-04-06 23:27:00,561] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 115000, global step 1839929: learning rate 0.0000
[2019-04-06 23:27:01,332] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 23:27:01,333] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:27:01,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:27:01,361] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:27:01,362] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:27:01,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run93
[2019-04-06 23:27:01,479] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:27:01,484] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:27:01,488] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run93
[2019-04-06 23:27:01,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run93
[2019-04-06 23:29:44,550] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 23:30:04,959] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 23:30:06,685] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 23:30:07,708] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 1840000, evaluation results [1840000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 23:30:08,683] A3C_AGENT_WORKER-Thread-18 INFO:Local step 115000, global step 1840147: loss 13.4511
[2019-04-06 23:30:08,684] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 115000, global step 1840147: learning rate 0.0000
[2019-04-06 23:30:12,191] A3C_AGENT_WORKER-Thread-19 INFO:Local step 115000, global step 1840676: loss 13.4226
[2019-04-06 23:30:12,193] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 115000, global step 1840676: learning rate 0.0000
[2019-04-06 23:30:13,066] A3C_AGENT_WORKER-Thread-10 INFO:Local step 114500, global step 1840803: loss 2.4516
[2019-04-06 23:30:13,068] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 114500, global step 1840803: learning rate 0.0000
[2019-04-06 23:30:14,225] A3C_AGENT_WORKER-Thread-2 INFO:Local step 114500, global step 1840948: loss 2.3837
[2019-04-06 23:30:14,226] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 114500, global step 1840948: learning rate 0.0000
[2019-04-06 23:30:17,900] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3428338e-13 1.0824155e-11 1.0562241e-12 6.1340536e-08 2.9198540e-14
 9.9999988e-01 1.4002407e-13], sum to 1.0000
[2019-04-06 23:30:17,901] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1638
[2019-04-06 23:30:17,932] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.5, 26.0, 0.0, 0.0, 26.0, 25.50674497954367, 0.3558895845662004, 0.0, 1.0, 22331.713968687272], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3648600.0000, 
sim time next is 3650400.0000, 
raw observation next is [10.0, 25.0, 0.0, 0.0, 26.0, 25.50096898393072, 0.3653003893070663, 0.0, 1.0, 33542.410198824946], 
processed observation next is [0.0, 0.2608695652173913, 0.739612188365651, 0.25, 0.0, 0.0, 0.6666666666666666, 0.6250807486608932, 0.6217667964356888, 0.0, 1.0, 0.15972576285154735], 
reward next is 0.8403, 
noisyNet noise sample is [array([0.13611898], dtype=float32), 0.06590492]. 
=============================================
[2019-04-06 23:30:21,721] A3C_AGENT_WORKER-Thread-3 INFO:Local step 116000, global step 1842052: loss 0.8502
[2019-04-06 23:30:21,722] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 116000, global step 1842052: learning rate 0.0000
[2019-04-06 23:30:27,540] A3C_AGENT_WORKER-Thread-15 INFO:Local step 115000, global step 1842935: loss 13.3622
[2019-04-06 23:30:27,540] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 115000, global step 1842935: learning rate 0.0000
[2019-04-06 23:30:29,277] A3C_AGENT_WORKER-Thread-4 INFO:Local step 114500, global step 1843207: loss 2.4358
[2019-04-06 23:30:29,277] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 114500, global step 1843207: learning rate 0.0000
[2019-04-06 23:30:32,378] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:30:32,378] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:30:32,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run42
[2019-04-06 23:30:32,604] A3C_AGENT_WORKER-Thread-12 INFO:Local step 115500, global step 1843746: loss 1.3765
[2019-04-06 23:30:32,605] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 115500, global step 1843746: learning rate 0.0000
[2019-04-06 23:30:33,957] A3C_AGENT_WORKER-Thread-16 INFO:Local step 115500, global step 1843932: loss 1.4489
[2019-04-06 23:30:33,968] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 115500, global step 1843932: learning rate 0.0000
[2019-04-06 23:30:45,307] A3C_AGENT_WORKER-Thread-14 INFO:Local step 114500, global step 1845607: loss 2.3999
[2019-04-06 23:30:45,308] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 114500, global step 1845607: learning rate 0.0000
[2019-04-06 23:30:47,010] A3C_AGENT_WORKER-Thread-6 INFO:Local step 115500, global step 1845899: loss 1.4822
[2019-04-06 23:30:47,011] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 115500, global step 1845899: learning rate 0.0000
[2019-04-06 23:30:47,617] A3C_AGENT_WORKER-Thread-13 INFO:Local step 115500, global step 1845991: loss 1.5286
[2019-04-06 23:30:47,627] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 115500, global step 1845991: learning rate 0.0000
[2019-04-06 23:30:48,533] A3C_AGENT_WORKER-Thread-17 INFO:Local step 116000, global step 1846114: loss 0.8178
[2019-04-06 23:30:48,533] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 116000, global step 1846114: learning rate 0.0000
[2019-04-06 23:30:50,874] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.5766183e-16 3.1284876e-13 1.3362128e-14 8.4843954e-09 2.3922111e-17
 1.0000000e+00 1.2083902e-15], sum to 1.0000
[2019-04-06 23:30:50,874] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2671
[2019-04-06 23:30:50,942] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.3, 71.0, 0.0, 0.0, 26.0, 25.5100092900678, 0.3890605214720601, 0.0, 1.0, 26651.337203722087], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4341600.0000, 
sim time next is 4343400.0000, 
raw observation next is [3.1, 73.0, 0.0, 0.0, 26.0, 25.50169170808444, 0.3564580509204561, 0.0, 1.0, 20181.806752835415], 
processed observation next is [1.0, 0.2608695652173913, 0.5484764542936289, 0.73, 0.0, 0.0, 0.6666666666666666, 0.6251409756737033, 0.6188193503068188, 0.0, 1.0, 0.09610384168016864], 
reward next is 0.9039, 
noisyNet noise sample is [array([0.69595677], dtype=float32), 0.4405149]. 
=============================================
[2019-04-06 23:30:53,257] A3C_AGENT_WORKER-Thread-5 INFO:Local step 115500, global step 1846790: loss 1.6072
[2019-04-06 23:30:53,257] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 115500, global step 1846790: learning rate 0.0000
[2019-04-06 23:30:53,328] A3C_AGENT_WORKER-Thread-18 INFO:Local step 115500, global step 1846804: loss 1.5842
[2019-04-06 23:30:53,329] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 115500, global step 1846804: learning rate 0.0000
[2019-04-06 23:30:57,342] A3C_AGENT_WORKER-Thread-19 INFO:Local step 115500, global step 1847468: loss 1.5802
[2019-04-06 23:30:57,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 115500, global step 1847468: learning rate 0.0000
[2019-04-06 23:30:58,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:30:58,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:30:58,686] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run42
[2019-04-06 23:31:00,180] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.92444937e-13 1.60352599e-11 7.05653323e-14 7.02047555e-06
 3.19152494e-14 9.99992967e-01 1.09778424e-13], sum to 1.0000
[2019-04-06 23:31:00,180] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9813
[2019-04-06 23:31:00,207] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 60.0, 87.0, 711.0, 26.0, 26.82445252085725, 0.6960767746584393, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3771000.0000, 
sim time next is 3772800.0000, 
raw observation next is [0.0, 60.0, 75.5, 625.0, 26.0, 26.87360174252905, 0.7122180522555975, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.46260387811634357, 0.6, 0.25166666666666665, 0.6906077348066298, 0.6666666666666666, 0.7394668118774209, 0.7374060174185325, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6457433], dtype=float32), 0.3494963]. 
=============================================
[2019-04-06 23:31:07,892] A3C_AGENT_WORKER-Thread-20 INFO:Local step 115000, global step 1849016: loss 13.4742
[2019-04-06 23:31:07,899] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 115000, global step 1849018: learning rate 0.0000
[2019-04-06 23:31:11,394] A3C_AGENT_WORKER-Thread-15 INFO:Local step 115500, global step 1849634: loss 1.5854
[2019-04-06 23:31:11,395] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 115500, global step 1849634: learning rate 0.0000
[2019-04-06 23:31:14,248] A3C_AGENT_WORKER-Thread-10 INFO:Local step 115000, global step 1850126: loss 13.5553
[2019-04-06 23:31:14,248] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 115000, global step 1850126: learning rate 0.0000
[2019-04-06 23:31:15,859] A3C_AGENT_WORKER-Thread-2 INFO:Local step 115000, global step 1850436: loss 13.5134
[2019-04-06 23:31:15,863] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 115000, global step 1850436: learning rate 0.0000
[2019-04-06 23:31:17,447] A3C_AGENT_WORKER-Thread-12 INFO:Local step 116000, global step 1850704: loss 0.8041
[2019-04-06 23:31:17,448] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 116000, global step 1850704: learning rate 0.0000
[2019-04-06 23:31:19,032] A3C_AGENT_WORKER-Thread-16 INFO:Local step 116000, global step 1850986: loss 0.7805
[2019-04-06 23:31:19,060] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 116000, global step 1850986: learning rate 0.0000
[2019-04-06 23:31:28,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:31:28,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:31:28,336] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run42
[2019-04-06 23:31:29,116] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:31:29,116] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:31:29,120] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run42
[2019-04-06 23:31:29,419] A3C_AGENT_WORKER-Thread-4 INFO:Local step 115000, global step 1852681: loss 13.4985
[2019-04-06 23:31:29,420] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 115000, global step 1852681: learning rate 0.0000
[2019-04-06 23:31:30,647] A3C_AGENT_WORKER-Thread-6 INFO:Local step 116000, global step 1852876: loss 0.7993
[2019-04-06 23:31:30,647] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 116000, global step 1852876: learning rate 0.0000
[2019-04-06 23:31:32,685] A3C_AGENT_WORKER-Thread-13 INFO:Local step 116000, global step 1853173: loss 0.7773
[2019-04-06 23:31:32,686] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 116000, global step 1853173: learning rate 0.0000
[2019-04-06 23:31:37,730] A3C_AGENT_WORKER-Thread-18 INFO:Local step 116000, global step 1853987: loss 0.7771
[2019-04-06 23:31:37,742] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 116000, global step 1853987: learning rate 0.0000
[2019-04-06 23:31:38,151] A3C_AGENT_WORKER-Thread-5 INFO:Local step 116000, global step 1854063: loss 0.7756
[2019-04-06 23:31:38,157] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 116000, global step 1854063: learning rate 0.0000
[2019-04-06 23:31:39,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:31:39,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:31:39,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run42
[2019-04-06 23:31:40,952] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.32332576e-14 3.02344608e-12 1.29549954e-14 5.48867050e-08
 8.97034319e-15 1.00000000e+00 7.29011510e-14], sum to 1.0000
[2019-04-06 23:31:40,953] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2357
[2019-04-06 23:31:41,044] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 39.0, 100.5, 638.5, 26.0, 25.70443401686995, 0.4102789829749721, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4957200.0000, 
sim time next is 4959000.0000, 
raw observation next is [0.0, 34.5, 108.0, 717.0, 26.0, 26.08216394692588, 0.4704168524656509, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.46260387811634357, 0.345, 0.36, 0.7922651933701658, 0.6666666666666666, 0.6735136622438235, 0.6568056174885503, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.90834284], dtype=float32), -2.8870404]. 
=============================================
[2019-04-06 23:31:41,052] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[84.51344]
 [84.57984]
 [83.49733]
 [82.40247]
 [82.1561 ]], R is [[85.01441956]
 [85.16427612]
 [85.31263733]
 [85.4595108 ]
 [85.53017426]].
[2019-04-06 23:31:41,318] A3C_AGENT_WORKER-Thread-19 INFO:Local step 116000, global step 1854539: loss 0.7678
[2019-04-06 23:31:41,332] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 116000, global step 1854539: learning rate 0.0000
[2019-04-06 23:31:42,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:31:42,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:31:42,166] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run42
[2019-04-06 23:31:44,965] A3C_AGENT_WORKER-Thread-14 INFO:Local step 115000, global step 1855092: loss 13.4030
[2019-04-06 23:31:44,966] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 115000, global step 1855092: learning rate 0.0000
[2019-04-06 23:31:47,388] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:31:47,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:31:47,392] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run42
[2019-04-06 23:31:47,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:31:47,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:31:47,734] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run42
[2019-04-06 23:31:50,332] A3C_AGENT_WORKER-Thread-20 INFO:Local step 115500, global step 1855796: loss 1.5746
[2019-04-06 23:31:50,334] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 115500, global step 1855796: learning rate 0.0000
[2019-04-06 23:31:50,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:31:50,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:31:50,366] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run42
[2019-04-06 23:31:52,736] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7111998e-14 2.9576487e-11 2.0036570e-13 1.7364743e-08 2.7203786e-14
 1.0000000e+00 3.2443013e-13], sum to 1.0000
[2019-04-06 23:31:52,737] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2498
[2019-04-06 23:31:52,808] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 60.0, 0.0, 0.0, 26.0, 25.10254561305516, 0.30168953352435, 0.0, 1.0, 39142.17210287981], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4847400.0000, 
sim time next is 4849200.0000, 
raw observation next is [-3.0, 60.0, 0.0, 0.0, 26.0, 25.016246074017, 0.2819933795647833, 0.0, 1.0, 39160.253412475424], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.6, 0.0, 0.0, 0.6666666666666666, 0.5846871728347501, 0.5939977931882611, 0.0, 1.0, 0.18647739720226392], 
reward next is 0.8135, 
noisyNet noise sample is [array([1.3508048], dtype=float32), 0.24047248]. 
=============================================
[2019-04-06 23:31:55,090] A3C_AGENT_WORKER-Thread-15 INFO:Local step 116000, global step 1856305: loss 0.7554
[2019-04-06 23:31:55,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 116000, global step 1856305: learning rate 0.0000
[2019-04-06 23:31:58,027] A3C_AGENT_WORKER-Thread-10 INFO:Local step 115500, global step 1856741: loss 1.5710
[2019-04-06 23:31:58,037] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 115500, global step 1856741: learning rate 0.0000
[2019-04-06 23:31:58,251] A3C_AGENT_WORKER-Thread-2 INFO:Local step 115500, global step 1856781: loss 1.5224
[2019-04-06 23:31:58,252] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 115500, global step 1856781: learning rate 0.0000
[2019-04-06 23:32:03,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.8388572e-14 1.6782813e-12 2.2930351e-14 9.2885656e-08 4.0731434e-15
 9.9999988e-01 5.1943523e-14], sum to 1.0000
[2019-04-06 23:32:03,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9219
[2019-04-06 23:32:03,536] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 75.0, 151.5, 0.0, 26.0, 25.69511802084746, 0.3523479874246633, 1.0, 1.0, 22892.377149720098], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2030400.0000, 
sim time next is 2032200.0000, 
raw observation next is [-4.5, 77.0, 156.0, 0.0, 26.0, 25.53486147436868, 0.3023591702177633, 1.0, 1.0, 17523.8948549152], 
processed observation next is [1.0, 0.5217391304347826, 0.3379501385041552, 0.77, 0.52, 0.0, 0.6666666666666666, 0.6279051228640565, 0.6007863900725877, 1.0, 1.0, 0.08344711835673906], 
reward next is 0.9166, 
noisyNet noise sample is [array([1.5292612], dtype=float32), 0.02030127]. 
=============================================
[2019-04-06 23:32:04,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:32:04,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:32:04,980] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run42
[2019-04-06 23:32:14,276] A3C_AGENT_WORKER-Thread-4 INFO:Local step 115500, global step 1858662: loss 1.4999
[2019-04-06 23:32:14,277] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 115500, global step 1858662: learning rate 0.0000
[2019-04-06 23:32:26,917] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.7916051e-14 3.5788799e-11 1.1176808e-12 1.3495649e-06 3.5088515e-13
 9.9999869e-01 2.0225184e-13], sum to 1.0000
[2019-04-06 23:32:26,918] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1287
[2019-04-06 23:32:27,168] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 35.5, 0.0, 0.0, 26.0, 25.8399790302912, 0.5129828560165571, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4127400.0000, 
sim time next is 4129200.0000, 
raw observation next is [3.0, 37.0, 0.0, 0.0, 26.0, 25.32309475377136, 0.5137804906689443, 1.0, 1.0, 69766.6258631818], 
processed observation next is [1.0, 0.8260869565217391, 0.5457063711911359, 0.37, 0.0, 0.0, 0.6666666666666666, 0.6102578961476134, 0.6712601635563148, 1.0, 1.0, 0.33222202791991334], 
reward next is 0.6678, 
noisyNet noise sample is [array([0.3720092], dtype=float32), 0.89694333]. 
=============================================
[2019-04-06 23:32:27,879] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.6253248e-13 1.5899169e-11 3.2166091e-13 5.4801131e-07 1.7934023e-13
 9.9999940e-01 3.4461556e-13], sum to 1.0000
[2019-04-06 23:32:27,879] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8477
[2019-04-06 23:32:28,348] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.95, 63.0, 71.0, 729.0, 26.0, 25.92727534350503, 0.3623003975700971, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 383400.0000, 
sim time next is 385200.0000, 
raw observation next is [-13.4, 60.0, 64.5, 746.5, 26.0, 25.87398962055461, 0.3450403505080835, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.09141274238227146, 0.6, 0.215, 0.8248618784530387, 0.6666666666666666, 0.6561658017128842, 0.6150134501693612, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2565321], dtype=float32), 0.325243]. 
=============================================
[2019-04-06 23:32:29,721] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-06 23:32:29,721] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:32:29,722] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:32:29,738] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run94
[2019-04-06 23:32:29,814] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:32:29,816] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:32:29,820] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run94
[2019-04-06 23:32:29,997] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:32:29,997] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:32:30,011] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run94
[2019-04-06 23:35:14,648] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 23:35:18,029] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.0721412], dtype=float32), 0.1415335]
[2019-04-06 23:35:18,029] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-5.477898168, 48.39070185, 0.0, 0.0, 26.0, 24.50605481024464, 0.2357999612695278, 0.0, 1.0, 44475.89386738205]
[2019-04-06 23:35:18,029] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 23:35:18,030] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.9804865e-12 1.6956955e-10 7.0191049e-12 1.0129731e-06 9.4288173e-13
 9.9999905e-01 3.6404495e-12], sampled 0.9251150772568064
[2019-04-06 23:35:33,778] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 23:35:36,243] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 23:35:37,266] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1860000, evaluation results [1860000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 23:35:43,845] A3C_AGENT_WORKER-Thread-14 INFO:Local step 115500, global step 1860866: loss 1.4584
[2019-04-06 23:35:43,846] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 115500, global step 1860866: learning rate 0.0000
[2019-04-06 23:35:47,332] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.1598844e-15 8.0237200e-13 5.3864106e-16 1.3661462e-07 4.7412330e-15
 9.9999988e-01 7.3841808e-15], sum to 1.0000
[2019-04-06 23:35:47,332] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6934
[2019-04-06 23:35:47,394] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.4, 61.0, 0.0, 0.0, 26.0, 26.52149042070161, 0.7772192749213985, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4399200.0000, 
sim time next is 4401000.0000, 
raw observation next is [8.95, 61.5, 0.0, 0.0, 26.0, 26.19686179526865, 0.6603426127017838, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.7105263157894738, 0.615, 0.0, 0.0, 0.6666666666666666, 0.6830718162723874, 0.720114204233928, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.42296386], dtype=float32), 1.0148437]. 
=============================================
[2019-04-06 23:35:47,413] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[93.68177 ]
 [94.03426 ]
 [94.07466 ]
 [93.957466]
 [94.27351 ]], R is [[93.40414429]
 [93.4701004 ]
 [93.53540039]
 [93.60004425]
 [93.66404724]].
[2019-04-06 23:35:47,772] A3C_AGENT_WORKER-Thread-20 INFO:Local step 116000, global step 1861409: loss 0.7727
[2019-04-06 23:35:47,774] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 116000, global step 1861409: learning rate 0.0000
[2019-04-06 23:35:54,515] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2351990e-11 8.1473284e-10 1.3172044e-11 3.0581373e-06 2.8083120e-12
 9.9999690e-01 5.6914135e-12], sum to 1.0000
[2019-04-06 23:35:54,515] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5391
[2019-04-06 23:35:54,807] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 40.0, 11.5, 0.0, 26.0, 24.43741622463588, 0.06120304136073321, 1.0, 1.0, 120344.01926154485], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 460800.0000, 
sim time next is 462600.0000, 
raw observation next is [-7.0, 36.5, 23.0, 0.0, 26.0, 25.1516387895333, 0.1718001631319643, 1.0, 1.0, 22072.195803245635], 
processed observation next is [1.0, 0.34782608695652173, 0.2686980609418283, 0.365, 0.07666666666666666, 0.0, 0.6666666666666666, 0.5959698991277751, 0.5572667210439881, 1.0, 1.0, 0.10510569430116969], 
reward next is 0.8949, 
noisyNet noise sample is [array([1.4120895], dtype=float32), 0.48230702]. 
=============================================
[2019-04-06 23:35:55,092] A3C_AGENT_WORKER-Thread-10 INFO:Local step 116000, global step 1862379: loss 0.7789
[2019-04-06 23:35:55,092] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 116000, global step 1862379: learning rate 0.0000
[2019-04-06 23:35:57,911] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:35:57,911] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:35:57,915] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run42
[2019-04-06 23:35:58,126] A3C_AGENT_WORKER-Thread-2 INFO:Local step 116000, global step 1862761: loss 0.7146
[2019-04-06 23:35:58,127] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 116000, global step 1862761: learning rate 0.0000
[2019-04-06 23:36:05,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:36:05,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:36:05,092] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run42
[2019-04-06 23:36:08,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:36:08,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:36:08,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run42
[2019-04-06 23:36:11,667] A3C_AGENT_WORKER-Thread-4 INFO:Local step 116000, global step 1864445: loss 0.7908
[2019-04-06 23:36:11,668] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 116000, global step 1864445: learning rate 0.0000
[2019-04-06 23:36:13,256] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.1130130e-14 3.5465619e-12 1.1674926e-12 7.1385176e-07 1.4424353e-14
 9.9999928e-01 2.5716359e-13], sum to 1.0000
[2019-04-06 23:36:13,257] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8657
[2019-04-06 23:36:13,316] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 75.0, 0.0, 0.0, 26.0, 24.27173470705799, 0.05338054274654772, 0.0, 1.0, 41349.36007166847], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 702000.0000, 
sim time next is 703800.0000, 
raw observation next is [-3.1, 75.0, 0.0, 0.0, 26.0, 24.36373022598906, 0.05828493686467379, 0.0, 1.0, 41543.413453540124], 
processed observation next is [1.0, 0.13043478260869565, 0.37673130193905824, 0.75, 0.0, 0.0, 0.6666666666666666, 0.5303108521657549, 0.5194283122882246, 0.0, 1.0, 0.19782577835019108], 
reward next is 0.8022, 
noisyNet noise sample is [array([0.27448213], dtype=float32), -0.2685371]. 
=============================================
[2019-04-06 23:36:17,998] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6501506e-14 4.4853919e-11 2.8326454e-13 1.5545945e-07 1.3490038e-14
 9.9999988e-01 1.4130598e-13], sum to 1.0000
[2019-04-06 23:36:17,998] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9809
[2019-04-06 23:36:18,006] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [16.1, 83.0, 0.0, 0.0, 26.0, 23.98415991919266, 0.2472898991815484, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1216800.0000, 
sim time next is 1218600.0000, 
raw observation next is [15.8, 88.0, 0.0, 0.0, 26.0, 24.00487721772116, 0.24561751889424, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.9002770083102495, 0.88, 0.0, 0.0, 0.6666666666666666, 0.5004064348100966, 0.58187250629808, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0051706], dtype=float32), -2.2758417]. 
=============================================
[2019-04-06 23:36:21,598] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:36:21,598] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:36:21,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run42
[2019-04-06 23:36:30,105] A3C_AGENT_WORKER-Thread-14 INFO:Local step 116000, global step 1866880: loss 0.8291
[2019-04-06 23:36:30,121] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 116000, global step 1866883: learning rate 0.0000
[2019-04-06 23:36:34,695] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.81655080e-16 2.29754150e-13 1.16099486e-14 6.05086159e-09
 2.25858556e-16 1.00000000e+00 7.29887338e-16], sum to 1.0000
[2019-04-06 23:36:34,695] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8919
[2019-04-06 23:36:34,922] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 26.0, 25.41176259642193, 0.516568451603789, 0.0, 1.0, 32174.261867605597], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1321200.0000, 
sim time next is 1323000.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 26.0, 25.62146489532133, 0.583940729916822, 1.0, 1.0, 18828.50110941478], 
processed observation next is [1.0, 0.30434782608695654, 0.49307479224376743, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6351220746101109, 0.6946469099722741, 1.0, 1.0, 0.08965952909245134], 
reward next is 0.9103, 
noisyNet noise sample is [array([-2.369241], dtype=float32), -0.7108495]. 
=============================================
[2019-04-06 23:36:34,927] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[93.68811]
 [93.96213]
 [93.87061]
 [94.0217 ]
 [94.60046]], R is [[94.08303833]
 [93.98899841]
 [93.70663452]
 [93.56109619]
 [93.59573364]].
[2019-04-06 23:36:40,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:36:40,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:36:40,040] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run42
[2019-04-06 23:37:04,530] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2258148e-14 3.2126714e-11 1.0695018e-13 6.0859577e-08 1.2594266e-13
 9.9999988e-01 1.4011330e-13], sum to 1.0000
[2019-04-06 23:37:04,530] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1238
[2019-04-06 23:37:04,625] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.28262016653897, 0.1261326481978182, 0.0, 1.0, 41731.963838765994], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1994400.0000, 
sim time next is 1996200.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.33137021355545, 0.1340124439971207, 0.0, 1.0, 41691.316889112124], 
processed observation next is [1.0, 0.08695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.6666666666666666, 0.527614184462954, 0.5446708146657069, 0.0, 1.0, 0.19853008042434345], 
reward next is 0.8015, 
noisyNet noise sample is [array([1.423152], dtype=float32), 0.9869001]. 
=============================================
[2019-04-06 23:37:07,840] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7824210e-15 1.5050678e-12 4.5944668e-15 2.6318445e-09 7.4592059e-15
 1.0000000e+00 2.2857213e-14], sum to 1.0000
[2019-04-06 23:37:07,840] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8982
[2019-04-06 23:37:07,926] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 91.0, 0.0, 0.0, 26.0, 25.23739481876392, 0.4242200163001235, 0.0, 1.0, 42982.03777863687], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1738800.0000, 
sim time next is 1740600.0000, 
raw observation next is [-0.3, 89.0, 0.0, 0.0, 26.0, 25.17291966113001, 0.4097999240423305, 0.0, 1.0, 43076.11672670411], 
processed observation next is [0.0, 0.13043478260869565, 0.4542936288088643, 0.89, 0.0, 0.0, 0.6666666666666666, 0.5977433050941675, 0.6365999746807768, 0.0, 1.0, 0.20512436536525766], 
reward next is 0.7949, 
noisyNet noise sample is [array([0.6529227], dtype=float32), 0.32388422]. 
=============================================
[2019-04-06 23:37:09,906] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.1734303e-12 8.1785323e-10 5.8406149e-12 8.2264575e-07 4.4937613e-12
 9.9999917e-01 2.7157031e-12], sum to 1.0000
[2019-04-06 23:37:09,906] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3682
[2019-04-06 23:37:10,103] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 26.5, 122.0, 0.0, 26.0, 25.12827208604327, 0.1385448183632547, 1.0, 1.0, 21270.081901965426], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 473400.0000, 
sim time next is 475200.0000, 
raw observation next is [-1.7, 25.0, 125.5, 0.0, 26.0, 25.14699155037999, 0.1672624198964032, 1.0, 1.0, 36264.96055910076], 
processed observation next is [1.0, 0.5217391304347826, 0.4155124653739613, 0.25, 0.41833333333333333, 0.0, 0.6666666666666666, 0.5955826291983325, 0.5557541399654677, 1.0, 1.0, 0.17269028837667028], 
reward next is 0.8273, 
noisyNet noise sample is [array([-0.01334729], dtype=float32), 2.6913803]. 
=============================================
[2019-04-06 23:37:16,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8767276e-13 9.8998466e-12 6.6163362e-13 8.2724733e-07 8.0506294e-14
 9.9999917e-01 9.6251707e-13], sum to 1.0000
[2019-04-06 23:37:16,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7852
[2019-04-06 23:37:16,351] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 79.0, 0.0, 0.0, 26.0, 23.66656613529634, -0.00612103330763232, 0.0, 1.0, 47096.84939094251], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1834200.0000, 
sim time next is 1836000.0000, 
raw observation next is [-6.2, 79.0, 0.0, 0.0, 26.0, 23.60206128633327, -0.02961260475398345, 0.0, 1.0, 47077.171583056625], 
processed observation next is [0.0, 0.2608695652173913, 0.2908587257617729, 0.79, 0.0, 0.0, 0.6666666666666666, 0.46683844052777257, 0.4901291317486722, 0.0, 1.0, 0.2241770075383649], 
reward next is 0.7758, 
noisyNet noise sample is [array([0.10528382], dtype=float32), 0.033369645]. 
=============================================
[2019-04-06 23:37:16,355] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.536964]
 [74.848274]
 [75.212494]
 [75.52305 ]
 [75.850914]], R is [[74.29106903]
 [74.32388306]
 [74.35671997]
 [74.38967133]
 [74.42253113]].
[2019-04-06 23:37:46,420] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.8433826e-16 2.3884044e-13 3.8328781e-16 3.2093250e-09 2.3095447e-17
 1.0000000e+00 8.8829266e-16], sum to 1.0000
[2019-04-06 23:37:46,420] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6226
[2019-04-06 23:37:46,514] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 26.0, 25.55343473028335, 0.5325912291564134, 0.0, 1.0, 6248.06674945621], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1315800.0000, 
sim time next is 1317600.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 26.0, 25.48871233591588, 0.5215442137621845, 0.0, 1.0, 43779.44544469487], 
processed observation next is [1.0, 0.2608695652173913, 0.5069252077562327, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6240593613263234, 0.6738480712540614, 0.0, 1.0, 0.20847354973664226], 
reward next is 0.7915, 
noisyNet noise sample is [array([-0.8618624], dtype=float32), -0.3218939]. 
=============================================
[2019-04-06 23:38:10,053] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.9092349e-16 3.0895634e-13 5.0760169e-15 6.4889306e-08 2.8620436e-16
 9.9999988e-01 6.2731391e-15], sum to 1.0000
[2019-04-06 23:38:10,053] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6469
[2019-04-06 23:38:10,194] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 72.0, 0.0, 26.0, 25.53236003774968, 0.4925055935508838, 1.0, 1.0, 6351.804008089747], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1434600.0000, 
sim time next is 1436400.0000, 
raw observation next is [1.1, 92.0, 59.0, 0.0, 26.0, 26.01352269239699, 0.539302010494577, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.92, 0.19666666666666666, 0.0, 0.6666666666666666, 0.6677935576997491, 0.6797673368315257, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.67827445], dtype=float32), -1.1136842]. 
=============================================
[2019-04-06 23:38:11,637] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-06 23:38:11,645] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:38:11,646] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:38:11,650] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run95
[2019-04-06 23:38:11,749] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:38:11,750] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:38:11,759] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:38:11,760] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:38:11,763] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run95
[2019-04-06 23:38:11,884] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run95
[2019-04-06 23:39:40,449] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.07229103], dtype=float32), 0.14137504]
[2019-04-06 23:39:40,450] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [5.0, 92.0, 0.0, 0.0, 26.0, 25.58664347650115, 0.5376818275066634, 0.0, 1.0, 21843.84586523999]
[2019-04-06 23:39:40,450] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 23:39:40,451] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.5235276e-16 2.2586147e-13 2.1581449e-15 9.6781978e-09 2.0477683e-16
 1.0000000e+00 1.0867037e-15], sampled 0.6030726815068491
[2019-04-06 23:39:51,912] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.07229103], dtype=float32), 0.14137504]
[2019-04-06 23:39:51,912] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [4.6, 71.0, 0.0, 0.0, 26.0, 25.42289677531615, 0.5163494060597432, 0.0, 1.0, 47467.42553264572]
[2019-04-06 23:39:51,912] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 23:39:51,914] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [9.0945853e-16 4.0028777e-13 4.2461736e-15 1.3960336e-08 3.8713040e-16
 1.0000000e+00 2.3141506e-15], sampled 0.4520787146169284
[2019-04-06 23:40:56,064] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 23:41:04,024] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.07229103], dtype=float32), 0.14137504]
[2019-04-06 23:41:04,024] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [4.8, 76.0, 0.0, 0.0, 26.0, 25.50574536854075, 0.4144086941815637, 0.0, 1.0, 65727.14733790683]
[2019-04-06 23:41:04,024] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 23:41:04,025] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.3141599e-15 1.6608215e-12 1.9004458e-14 4.4595431e-08 2.7074157e-15
 1.0000000e+00 1.1022646e-14], sampled 0.313265787709455
[2019-04-06 23:41:15,975] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 23:41:19,600] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.2290 91932853.8921 409.3020
[2019-04-06 23:41:20,639] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1880000, evaluation results [1880000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.229026592473, 91932853.89214352, 409.3019501072503]
[2019-04-06 23:41:28,655] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5071624e-15 4.5112494e-12 1.5943618e-13 1.3075577e-07 2.2515497e-15
 9.9999988e-01 8.0759807e-14], sum to 1.0000
[2019-04-06 23:41:28,656] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6814
[2019-04-06 23:41:28,715] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.3, 29.0, 114.0, 351.0, 26.0, 25.79347494034079, 0.3964607524437012, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2561400.0000, 
sim time next is 2563200.0000, 
raw observation next is [3.3, 29.0, 92.0, 256.5, 26.0, 25.92260043141344, 0.3076265022715465, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.554016620498615, 0.29, 0.30666666666666664, 0.28342541436464086, 0.6666666666666666, 0.6602167026177866, 0.6025421674238488, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7598934], dtype=float32), 0.67463595]. 
=============================================
[2019-04-06 23:41:31,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:41:31,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:41:31,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run43
[2019-04-06 23:42:18,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:42:18,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:42:18,237] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run43
[2019-04-06 23:42:21,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4489096e-15 2.9749883e-12 5.1468080e-14 2.9988765e-08 9.2386900e-15
 1.0000000e+00 4.8282767e-15], sum to 1.0000
[2019-04-06 23:42:21,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7017
[2019-04-06 23:42:21,369] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 41.0, 41.0, 365.0, 26.0, 26.57038942502309, 0.6918135016742409, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3862800.0000, 
sim time next is 3864600.0000, 
raw observation next is [2.5, 44.5, 18.0, 179.0, 26.0, 26.75058066333533, 0.6358550435011839, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5318559556786704, 0.445, 0.06, 0.19779005524861878, 0.6666666666666666, 0.7292150552779443, 0.7119516811670613, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4523112], dtype=float32), -0.13352817]. 
=============================================
[2019-04-06 23:42:23,069] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1457064e-15 3.7042613e-12 4.5248598e-14 2.1630116e-07 1.5952126e-14
 9.9999976e-01 3.4872116e-13], sum to 1.0000
[2019-04-06 23:42:23,071] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3053
[2019-04-06 23:42:23,215] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.5, 67.5, 100.0, 676.0, 26.0, 25.89933642343454, 0.526986532207871, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3576600.0000, 
sim time next is 3578400.0000, 
raw observation next is [-5.0, 65.0, 105.5, 717.0, 26.0, 25.76153513195192, 0.507373816237126, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.32409972299168976, 0.65, 0.3516666666666667, 0.7922651933701658, 0.6666666666666666, 0.6467945943293266, 0.6691246054123754, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0201781], dtype=float32), -0.2983504]. 
=============================================
[2019-04-06 23:42:28,442] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0175602e-12 3.9262666e-11 1.8141623e-13 1.8941337e-07 6.7033232e-14
 9.9999976e-01 4.1803756e-14], sum to 1.0000
[2019-04-06 23:42:28,443] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8113
[2019-04-06 23:42:28,500] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.2, 27.0, 82.5, 808.0, 26.0, 24.96132179427164, 0.2786897981795579, 0.0, 1.0, 18708.307637613918], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2469600.0000, 
sim time next is 2471400.0000, 
raw observation next is [2.75, 27.0, 78.0, 784.0, 26.0, 24.96725673351907, 0.2783740947115361, 0.0, 1.0, 6234.177231419701], 
processed observation next is [0.0, 0.6086956521739131, 0.5387811634349031, 0.27, 0.26, 0.8662983425414365, 0.6666666666666666, 0.5806047277932557, 0.5927913649038453, 0.0, 1.0, 0.029686558244855717], 
reward next is 0.9703, 
noisyNet noise sample is [array([-0.9748298], dtype=float32), -0.9982792]. 
=============================================
[2019-04-06 23:42:48,386] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:42:48,386] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:42:48,394] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run43
[2019-04-06 23:42:48,754] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5064320e-16 1.6180408e-12 4.1213316e-14 5.0957958e-08 1.4822509e-16
 1.0000000e+00 2.9879665e-15], sum to 1.0000
[2019-04-06 23:42:48,755] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2107
[2019-04-06 23:42:48,775] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.0, 58.0, 0.0, 0.0, 26.0, 27.26676729963554, 0.9159651972308627, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4392000.0000, 
sim time next is 4393800.0000, 
raw observation next is [10.6, 58.5, 0.0, 0.0, 26.0, 27.02016634304054, 0.876022059706817, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.7562326869806094, 0.585, 0.0, 0.0, 0.6666666666666666, 0.7516805285867116, 0.7920073532356057, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8084225], dtype=float32), 1.1246572]. 
=============================================
[2019-04-06 23:43:18,860] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4152691e-16 5.0719384e-13 2.4538621e-15 1.9504684e-08 4.7197570e-16
 1.0000000e+00 7.4832320e-15], sum to 1.0000
[2019-04-06 23:43:18,860] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2902
[2019-04-06 23:43:18,922] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.2, 73.0, 0.0, 0.0, 26.0, 25.51259355436496, 0.5503059161059055, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1540800.0000, 
sim time next is 1542600.0000, 
raw observation next is [7.45, 73.5, 0.0, 0.0, 26.0, 25.2964552057658, 0.5534028149206998, 0.0, 1.0, 130960.65966034708], 
processed observation next is [1.0, 0.8695652173913043, 0.6689750692520776, 0.735, 0.0, 0.0, 0.6666666666666666, 0.6080379338138165, 0.6844676049735666, 0.0, 1.0, 0.6236221888587956], 
reward next is 0.3764, 
noisyNet noise sample is [array([1.1388104], dtype=float32), -0.96779597]. 
=============================================
[2019-04-06 23:43:19,040] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:43:19,040] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:43:19,044] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run43
[2019-04-06 23:43:20,983] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:43:20,983] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:43:20,988] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run43
[2019-04-06 23:43:32,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:43:32,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:43:32,724] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run43
[2019-04-06 23:43:35,332] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 23:43:35,333] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:43:35,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:43:35,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run96
[2019-04-06 23:43:35,391] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:43:35,393] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:43:35,394] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:43:35,417] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run96
[2019-04-06 23:43:35,465] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:43:35,538] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run96
[2019-04-06 23:46:16,675] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 23:46:37,024] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 23:46:41,830] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 23:46:42,855] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1900000, evaluation results [1900000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 23:46:45,851] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:46:45,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:46:45,855] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run43
[2019-04-06 23:46:54,438] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:46:54,438] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:46:54,442] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run43
[2019-04-06 23:46:54,810] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:46:54,811] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:46:54,815] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run43
[2019-04-06 23:46:56,493] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:46:56,493] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:46:56,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run43
[2019-04-06 23:47:05,438] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:47:05,439] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:47:05,450] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run43
[2019-04-06 23:47:18,156] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0553929e-15 1.2041809e-13 1.6440173e-15 9.9885789e-09 8.7242848e-16
 1.0000000e+00 1.9390470e-16], sum to 1.0000
[2019-04-06 23:47:18,157] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6309
[2019-04-06 23:47:18,322] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.2, 54.0, 25.5, 18.5, 26.0, 26.08245426556875, 0.7129832239349164, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1616400.0000, 
sim time next is 1618200.0000, 
raw observation next is [11.35, 57.5, 0.0, 0.0, 26.0, 26.8092742177253, 0.7372736782181959, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.7770083102493075, 0.575, 0.0, 0.0, 0.6666666666666666, 0.7341061848104417, 0.7457578927393986, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.90828806], dtype=float32), -0.17784162]. 
=============================================
[2019-04-06 23:47:18,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.9176019e-13 1.5771502e-11 2.7190524e-12 3.1077786e-07 8.2033447e-14
 9.9999964e-01 2.8408040e-13], sum to 1.0000
[2019-04-06 23:47:18,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2758
[2019-04-06 23:47:19,016] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 26.0, 22.64423461643237, -0.2686205423049726, 0.0, 1.0, 44957.974396430254], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 196200.0000, 
sim time next is 198000.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 26.0, 22.60008549849249, -0.2845155169865929, 0.0, 1.0, 44979.39549923005], 
processed observation next is [1.0, 0.30434782608695654, 0.21606648199445982, 0.78, 0.0, 0.0, 0.6666666666666666, 0.3833404582077075, 0.40516149433780235, 0.0, 1.0, 0.2141875976153812], 
reward next is 0.7858, 
noisyNet noise sample is [array([0.58569324], dtype=float32), -0.92612773]. 
=============================================
[2019-04-06 23:47:19,020] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.0368  ]
 [76.310715]
 [76.54669 ]
 [76.74422 ]
 [76.992325]], R is [[75.78288269]
 [75.81096649]
 [75.83888245]
 [75.86715698]
 [75.89622498]].
[2019-04-06 23:47:38,358] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.82567584e-14 2.06097747e-12 1.06639305e-14 2.34419879e-08
 1.09405393e-14 1.00000000e+00 2.20080071e-13], sum to 1.0000
[2019-04-06 23:47:38,358] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7695
[2019-04-06 23:47:38,433] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 48.0, 131.0, 40.0, 26.0, 26.47423399040414, 0.6046649151141085, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4550400.0000, 
sim time next is 4552200.0000, 
raw observation next is [2.0, 50.0, 109.0, 68.0, 26.0, 25.14846947723121, 0.4467502132386579, 1.0, 1.0, 27179.407548514282], 
processed observation next is [1.0, 0.6956521739130435, 0.518005540166205, 0.5, 0.36333333333333334, 0.07513812154696133, 0.6666666666666666, 0.5957057897692675, 0.6489167377462193, 1.0, 1.0, 0.1294257502310204], 
reward next is 0.8706, 
noisyNet noise sample is [array([1.7864718], dtype=float32), -2.023838]. 
=============================================
[2019-04-06 23:47:39,162] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7523283e-13 1.0035165e-11 1.4798030e-12 1.2278499e-06 7.5849951e-14
 9.9999881e-01 2.0115016e-12], sum to 1.0000
[2019-04-06 23:47:39,162] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1960
[2019-04-06 23:47:39,372] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 35.0, 106.5, 0.0, 26.0, 25.5754128531393, 0.2513228844463852, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 482400.0000, 
sim time next is 484200.0000, 
raw observation next is [-0.3, 36.0, 94.0, 0.0, 26.0, 24.44096525628457, 0.1806223074810993, 1.0, 1.0, 66131.976932777], 
processed observation next is [1.0, 0.6086956521739131, 0.4542936288088643, 0.36, 0.31333333333333335, 0.0, 0.6666666666666666, 0.5367471046903809, 0.5602074358270331, 1.0, 1.0, 0.3149141758703667], 
reward next is 0.6851, 
noisyNet noise sample is [array([0.08172634], dtype=float32), 1.0544298]. 
=============================================
[2019-04-06 23:47:41,473] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:47:41,473] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:47:41,476] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run43
[2019-04-06 23:47:45,781] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:47:45,781] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:47:45,806] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run43
[2019-04-06 23:47:46,992] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0885826e-16 6.7576783e-14 5.3382182e-16 2.3228073e-09 3.9599942e-17
 1.0000000e+00 3.3214732e-16], sum to 1.0000
[2019-04-06 23:47:46,992] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6297
[2019-04-06 23:47:47,031] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.4, 44.0, 0.0, 0.0, 26.0, 27.72252575428364, 1.01161323777679, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4384800.0000, 
sim time next is 4386600.0000, 
raw observation next is [12.2, 47.0, 0.0, 0.0, 26.0, 27.94701596778084, 1.026292969253263, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.8005540166204987, 0.47, 0.0, 0.0, 0.6666666666666666, 0.8289179973150699, 0.8420976564177544, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1891746], dtype=float32), 0.6543756]. 
=============================================
[2019-04-06 23:47:58,662] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6769710e-14 4.8328446e-12 2.8978683e-13 8.1374960e-09 1.7174271e-14
 1.0000000e+00 4.0307709e-14], sum to 1.0000
[2019-04-06 23:47:58,662] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1278
[2019-04-06 23:47:58,703] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.2, 75.0, 0.0, 0.0, 26.0, 24.18031419951986, 0.0777531429696246, 0.0, 1.0, 43152.003779948165], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 617400.0000, 
sim time next is 619200.0000, 
raw observation next is [-4.5, 75.0, 0.0, 0.0, 26.0, 24.03307346456412, 0.04851413633639745, 0.0, 1.0, 43747.94024768141], 
processed observation next is [0.0, 0.17391304347826086, 0.3379501385041552, 0.75, 0.0, 0.0, 0.6666666666666666, 0.5027561220470099, 0.5161713787787992, 0.0, 1.0, 0.2083235249889591], 
reward next is 0.7917, 
noisyNet noise sample is [array([0.4736433], dtype=float32), 1.8900557]. 
=============================================
[2019-04-06 23:47:59,640] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:47:59,640] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:47:59,643] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run43
[2019-04-06 23:48:06,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:48:06,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:48:06,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run43
[2019-04-06 23:48:22,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:48:22,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:48:22,144] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run43
[2019-04-06 23:48:37,115] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.8161353e-15 3.4163681e-12 2.6310459e-13 1.1971242e-07 2.1900418e-14
 9.9999988e-01 1.1797096e-14], sum to 1.0000
[2019-04-06 23:48:37,116] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0524
[2019-04-06 23:48:37,168] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 67.0, 12.0, 121.0, 26.0, 25.96467930460844, 0.4852164044574683, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3432600.0000, 
sim time next is 3434400.0000, 
raw observation next is [2.0, 67.0, 0.0, 0.0, 26.0, 25.73247613922467, 0.4904372516254664, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.518005540166205, 0.67, 0.0, 0.0, 0.6666666666666666, 0.6443730116020557, 0.6634790838751555, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5720332], dtype=float32), 1.0256479]. 
=============================================
[2019-04-06 23:49:24,246] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-06 23:49:24,253] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:49:24,253] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:49:24,257] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:49:24,253] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:49:24,261] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:49:24,261] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run97
[2019-04-06 23:49:24,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:49:24,360] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run97
[2019-04-06 23:49:24,412] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run97
[2019-04-06 23:52:06,608] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 23:52:25,579] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 23:52:28,014] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 23:52:29,076] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1920000, evaluation results [1920000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 23:52:34,207] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4896249e-13 2.0927954e-11 4.2417339e-13 4.9798789e-08 5.4506689e-14
 1.0000000e+00 5.2322307e-13], sum to 1.0000
[2019-04-06 23:52:34,207] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7813
[2019-04-06 23:52:34,276] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 47.0, 0.0, 0.0, 26.0, 25.425181894845, 0.3692935434976026, 0.0, 1.0, 42240.21790884563], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4228200.0000, 
sim time next is 4230000.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 26.0, 25.41162345860911, 0.3640483394297764, 0.0, 1.0, 42489.47341456783], 
processed observation next is [0.0, 1.0, 0.4903047091412743, 0.47, 0.0, 0.0, 0.6666666666666666, 0.6176352882174259, 0.6213494464765922, 0.0, 1.0, 0.20233082578365633], 
reward next is 0.7977, 
noisyNet noise sample is [array([1.2057239], dtype=float32), 1.8148115]. 
=============================================
[2019-04-06 23:52:34,317] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[78.6616  ]
 [78.63254 ]
 [78.5947  ]
 [78.43916 ]
 [78.739395]], R is [[78.61090088]
 [78.6236496 ]
 [78.7064743 ]
 [78.6352005 ]
 [78.74211121]].
[2019-04-06 23:52:40,358] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.5453554e-13 3.9798650e-12 1.2021062e-13 2.4918037e-07 6.7973852e-15
 9.9999976e-01 2.0075508e-13], sum to 1.0000
[2019-04-06 23:52:40,358] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0513
[2019-04-06 23:52:40,651] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 71.0, 98.5, 0.0, 26.0, 25.59600278783704, 0.2991288959471972, 1.0, 1.0, 20158.071616300575], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 817200.0000, 
sim time next is 819000.0000, 
raw observation next is [-4.5, 71.0, 110.0, 0.0, 26.0, 25.63207010912495, 0.3124027626679091, 1.0, 1.0, 22825.90334421964], 
processed observation next is [1.0, 0.4782608695652174, 0.3379501385041552, 0.71, 0.36666666666666664, 0.0, 0.6666666666666666, 0.6360058424270791, 0.6041342542226363, 1.0, 1.0, 0.10869477782961734], 
reward next is 0.8913, 
noisyNet noise sample is [array([1.1999714], dtype=float32), -1.6599448]. 
=============================================
[2019-04-06 23:52:40,655] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[80.89311 ]
 [80.598175]
 [80.35547 ]
 [80.36711 ]
 [80.34769 ]], R is [[81.22860718]
 [81.32032776]
 [81.38262939]
 [81.56880188]
 [81.75311279]].
[2019-04-06 23:52:47,405] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.9470158e-15 2.1210325e-12 3.4741895e-15 1.7068085e-07 1.3586813e-15
 9.9999988e-01 1.9308114e-14], sum to 1.0000
[2019-04-06 23:52:47,405] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8573
[2019-04-06 23:52:47,440] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 84.0, 87.0, 0.0, 26.0, 25.44417228833298, 0.2831390469846868, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 903600.0000, 
sim time next is 905400.0000, 
raw observation next is [1.9, 90.5, 97.0, 0.0, 26.0, 25.35464579227338, 0.2806896550437646, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.515235457063712, 0.905, 0.3233333333333333, 0.0, 0.6666666666666666, 0.6128871493561151, 0.5935632183479215, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1217678], dtype=float32), -0.48235595]. 
=============================================
[2019-04-06 23:52:48,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0247071e-13 8.5891867e-12 5.8389871e-13 5.5476414e-07 2.5441880e-13
 9.9999940e-01 2.2838602e-13], sum to 1.0000
[2019-04-06 23:52:48,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9909
[2019-04-06 23:52:48,348] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.9, 73.0, 0.0, 0.0, 26.0, 25.03924028569166, 0.3090821555550189, 0.0, 1.0, 44771.57771763761], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2241000.0000, 
sim time next is 2242800.0000, 
raw observation next is [-6.2, 75.0, 0.0, 0.0, 26.0, 24.78970726491308, 0.2670124122433631, 0.0, 1.0, 44235.43734849055], 
processed observation next is [1.0, 1.0, 0.2908587257617729, 0.75, 0.0, 0.0, 0.6666666666666666, 0.5658089387427566, 0.5890041374144543, 0.0, 1.0, 0.2106449397547169], 
reward next is 0.7894, 
noisyNet noise sample is [array([-0.2113097], dtype=float32), 0.4010734]. 
=============================================
[2019-04-06 23:53:18,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:53:18,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:53:18,548] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run44
[2019-04-06 23:53:32,911] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8604875e-14 9.0581440e-12 9.6766209e-14 1.3967026e-07 1.2249042e-13
 9.9999988e-01 7.4282154e-14], sum to 1.0000
[2019-04-06 23:53:32,912] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9749
[2019-04-06 23:53:33,110] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 75.0, 0.0, 0.0, 26.0, 23.92722970640725, 0.1457399139942662, 1.0, 1.0, 149022.33611456558], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2187000.0000, 
sim time next is 2188800.0000, 
raw observation next is [-5.6, 75.0, 21.5, 131.0, 26.0, 25.49604865484374, 0.3471602717850472, 1.0, 1.0, 42801.183560628], 
processed observation next is [1.0, 0.34782608695652173, 0.30747922437673136, 0.75, 0.07166666666666667, 0.14475138121546963, 0.6666666666666666, 0.6246707212369783, 0.6157200905950158, 1.0, 1.0, 0.20381515981251427], 
reward next is 0.7962, 
noisyNet noise sample is [array([-0.19895522], dtype=float32), -1.287453]. 
=============================================
[2019-04-06 23:53:42,699] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8471681e-13 1.4325510e-11 5.6942927e-13 3.2773698e-07 1.8311922e-14
 9.9999964e-01 7.0475451e-13], sum to 1.0000
[2019-04-06 23:53:42,699] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5456
[2019-04-06 23:53:42,900] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 43.0, 129.5, 51.0, 26.0, 26.29687411452721, 0.4987392315047161, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2300400.0000, 
sim time next is 2302200.0000, 
raw observation next is [0.55, 43.5, 138.0, 42.0, 26.0, 25.19644174210071, 0.3747504375851305, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.4778393351800555, 0.435, 0.46, 0.04640883977900553, 0.6666666666666666, 0.5997034785083925, 0.6249168125283768, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8618143], dtype=float32), -1.1319095]. 
=============================================
[2019-04-06 23:53:45,422] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5377448e-15 2.1599776e-11 3.8116815e-14 4.5981391e-08 2.3670507e-15
 1.0000000e+00 1.8858901e-14], sum to 1.0000
[2019-04-06 23:53:45,422] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0312
[2019-04-06 23:53:45,501] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 92.0, 0.0, 0.0, 26.0, 25.47446964913158, 0.3717866900861554, 0.0, 1.0, 39764.74517463327], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3096000.0000, 
sim time next is 3097800.0000, 
raw observation next is [-1.0, 96.0, 0.0, 0.0, 26.0, 25.46820264813337, 0.3459174071467632, 0.0, 1.0, 20166.66147291092], 
processed observation next is [0.0, 0.8695652173913043, 0.4349030470914128, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6223502206777809, 0.6153058023822544, 0.0, 1.0, 0.09603172129957581], 
reward next is 0.9040, 
noisyNet noise sample is [array([-2.2439883], dtype=float32), 0.78683114]. 
=============================================
[2019-04-06 23:53:48,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1853473e-16 2.7235419e-13 3.3509478e-16 1.7228549e-09 1.0945830e-16
 1.0000000e+00 5.1997796e-16], sum to 1.0000
[2019-04-06 23:53:48,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4247
[2019-04-06 23:53:48,129] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 100.0, 87.5, 0.0, 26.0, 25.66150895762087, 0.4382999572098387, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2905200.0000, 
sim time next is 2907000.0000, 
raw observation next is [2.0, 100.0, 85.0, 0.0, 26.0, 25.87533844883768, 0.4543928189975122, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.518005540166205, 1.0, 0.2833333333333333, 0.0, 0.6666666666666666, 0.6562782040698067, 0.6514642729991708, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6971692], dtype=float32), 0.96541214]. 
=============================================
[2019-04-06 23:53:48,135] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[90.95295 ]
 [91.18365 ]
 [90.534615]
 [90.84522 ]
 [90.86781 ]], R is [[90.91764069]
 [91.00846863]
 [90.45915222]
 [90.49525452]
 [90.59030151]].
[2019-04-06 23:53:55,279] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.19188666e-14 3.24836425e-12 3.43526172e-14 9.46394678e-08
 9.66851772e-15 9.99999881e-01 4.05375400e-14], sum to 1.0000
[2019-04-06 23:53:55,279] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0824
[2019-04-06 23:53:55,368] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.39412988293379, 0.3473448547356217, 0.0, 1.0, 39314.63172189643], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3101400.0000, 
sim time next is 3103200.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.39565809586656, 0.3440184787360971, 0.0, 1.0, 40511.41228525361], 
processed observation next is [0.0, 0.9565217391304348, 0.4349030470914128, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6163048413222132, 0.6146728262453657, 0.0, 1.0, 0.19291148707263622], 
reward next is 0.8071, 
noisyNet noise sample is [array([-0.32044804], dtype=float32), 1.5069679]. 
=============================================
[2019-04-06 23:53:59,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:53:59,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:53:59,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run44
[2019-04-06 23:54:01,539] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4801986e-15 2.6007621e-12 3.2509772e-14 4.8507216e-09 1.7567024e-15
 1.0000000e+00 1.0020243e-14], sum to 1.0000
[2019-04-06 23:54:01,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9815
[2019-04-06 23:54:01,587] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.0, 34.5, 116.0, 816.0, 26.0, 25.6867894692689, 0.4954896167419909, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3670200.0000, 
sim time next is 3672000.0000, 
raw observation next is [4.0, 45.0, 116.5, 822.5, 26.0, 25.52372932112246, 0.4643987175481723, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.5734072022160666, 0.45, 0.3883333333333333, 0.9088397790055248, 0.6666666666666666, 0.6269774434268717, 0.6547995725160575, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.30260554], dtype=float32), -0.9221817]. 
=============================================
[2019-04-06 23:54:01,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[86.66029]
 [86.70226]
 [86.74255]
 [86.54266]
 [86.37293]], R is [[86.45124817]
 [86.58673859]
 [86.72087097]
 [86.85366058]
 [86.98512268]].
[2019-04-06 23:54:16,480] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0497467e-15 4.3108740e-13 3.3977731e-14 3.3315814e-08 9.8709925e-15
 1.0000000e+00 2.9716904e-14], sum to 1.0000
[2019-04-06 23:54:16,480] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2004
[2019-04-06 23:54:16,517] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 79.0, 0.0, 0.0, 26.0, 25.29219433239937, 0.46137473375451, 1.0, 1.0, 36949.95937846048], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3438000.0000, 
sim time next is 3439800.0000, 
raw observation next is [1.0, 79.0, 0.0, 0.0, 26.0, 25.05325187706555, 0.4154175641174782, 1.0, 1.0, 41954.780325401014], 
processed observation next is [1.0, 0.8260869565217391, 0.4903047091412743, 0.79, 0.0, 0.0, 0.6666666666666666, 0.5877709897554624, 0.6384725213724928, 1.0, 1.0, 0.1997846682161953], 
reward next is 0.8002, 
noisyNet noise sample is [array([0.863436], dtype=float32), 1.8062215]. 
=============================================
[2019-04-06 23:54:30,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:54:30,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:54:30,716] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run44
[2019-04-06 23:54:52,201] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-06 23:54:52,202] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:54:52,202] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:54:52,206] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run98
[2019-04-06 23:54:52,285] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:54:52,286] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:54:52,289] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run98
[2019-04-06 23:54:52,362] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:54:52,367] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:54:52,371] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run98
[2019-04-06 23:56:52,543] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.07329218], dtype=float32), 0.14264448]
[2019-04-06 23:56:52,543] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-7.844213829, 74.08534417, 0.0, 0.0, 26.0, 24.88736337332995, 0.2482209349060212, 0.0, 1.0, 41973.743512257584]
[2019-04-06 23:56:52,544] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 23:56:52,545] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [4.42878461e-14 8.79272696e-12 1.81309354e-13 1.10900828e-07
 2.60127494e-14 9.99999881e-01 1.05411034e-13], sampled 0.40735314514213206
[2019-04-06 23:57:31,430] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-06 23:57:51,594] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-06 23:57:54,555] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-06 23:57:55,579] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1940000, evaluation results [1940000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-06 23:57:59,659] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2831592e-14 7.1822071e-12 3.8649480e-14 8.4924288e-08 5.5091861e-15
 9.9999988e-01 9.8641781e-15], sum to 1.0000
[2019-04-06 23:57:59,659] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1302
[2019-04-06 23:57:59,668] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [18.3, 65.0, 165.0, 0.0, 26.0, 25.07908776583792, 0.5006153161919765, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1170000.0000, 
sim time next is 1171800.0000, 
raw observation next is [18.3, 65.0, 159.0, 0.0, 26.0, 25.04944458239039, 0.4972804705747234, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.9695290858725764, 0.65, 0.53, 0.0, 0.6666666666666666, 0.5874537151991991, 0.6657601568582411, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.37729424], dtype=float32), -1.2062376]. 
=============================================
[2019-04-06 23:58:03,382] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5164718e-14 1.8542826e-12 8.7703450e-13 7.0423916e-08 1.6658927e-14
 9.9999988e-01 1.6754084e-13], sum to 1.0000
[2019-04-06 23:58:03,383] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6993
[2019-04-06 23:58:03,777] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 92.0, 62.0, 209.5, 26.0, 23.79552636062179, 0.1128513234896407, 0.0, 1.0, 41768.311433539144], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4780800.0000, 
sim time next is 4782600.0000, 
raw observation next is [-5.5, 84.5, 124.0, 419.0, 26.0, 24.31781378082753, 0.3489413017274095, 0.0, 1.0, 148650.40706205062], 
processed observation next is [0.0, 0.34782608695652173, 0.3102493074792244, 0.845, 0.41333333333333333, 0.46298342541436466, 0.6666666666666666, 0.5264844817356277, 0.6163137672424698, 0.0, 1.0, 0.7078590812478601], 
reward next is 0.2921, 
noisyNet noise sample is [array([0.69400156], dtype=float32), 1.936805]. 
=============================================
[2019-04-06 23:58:07,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7031393e-15 1.9257968e-12 4.0309478e-14 1.8183002e-08 7.8953926e-17
 1.0000000e+00 3.4664474e-14], sum to 1.0000
[2019-04-06 23:58:07,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5870
[2019-04-06 23:58:07,475] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.5, 46.5, 0.0, 0.0, 26.0, 25.42825800872156, 0.3137669073105281, 0.0, 1.0, 35179.426989460844], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4930200.0000, 
sim time next is 4932000.0000, 
raw observation next is [-1.0, 50.0, 0.0, 0.0, 26.0, 25.35105733881791, 0.3477685240163191, 0.0, 1.0, 63653.332458806166], 
processed observation next is [1.0, 0.08695652173913043, 0.4349030470914128, 0.5, 0.0, 0.0, 0.6666666666666666, 0.6125881115681592, 0.6159228413387731, 0.0, 1.0, 0.303111106946696], 
reward next is 0.6969, 
noisyNet noise sample is [array([0.34008124], dtype=float32), -0.055168264]. 
=============================================
[2019-04-06 23:58:07,483] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[83.9441  ]
 [83.561775]
 [82.95974 ]
 [81.49644 ]
 [79.2614  ]], R is [[84.1353302 ]
 [84.12645721]
 [84.2851944 ]
 [84.23545074]
 [84.23674774]].
[2019-04-06 23:58:08,128] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.1402504e-17 5.6968563e-14 6.7381339e-16 3.6810412e-08 1.9432076e-17
 1.0000000e+00 6.6599368e-16], sum to 1.0000
[2019-04-06 23:58:08,128] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7984
[2019-04-06 23:58:08,174] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.15, 85.0, 165.0, 31.0, 26.0, 26.23065266190838, 0.6153096442993028, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4440600.0000, 
sim time next is 4442400.0000, 
raw observation next is [1.0, 86.0, 208.0, 88.5, 26.0, 26.35089192899696, 0.6343544034694705, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4903047091412743, 0.86, 0.6933333333333334, 0.09779005524861878, 0.6666666666666666, 0.6959076607497465, 0.7114514678231568, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.81263936], dtype=float32), 1.6408046]. 
=============================================
[2019-04-06 23:58:15,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:58:15,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:58:15,816] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run44
[2019-04-06 23:58:18,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7017166e-14 1.0383669e-11 2.5364224e-13 9.3788422e-08 4.1041992e-14
 9.9999988e-01 9.1620952e-14], sum to 1.0000
[2019-04-06 23:58:18,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8955
[2019-04-06 23:58:18,750] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.5, 53.0, 0.0, 0.0, 26.0, 25.40866433839633, 0.4061593716624812, 0.0, 1.0, 56907.064487428164], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4829400.0000, 
sim time next is 4831200.0000, 
raw observation next is [-1.0, 55.0, 0.0, 0.0, 26.0, 25.38949725837604, 0.4004439696458449, 0.0, 1.0, 43622.36116079755], 
processed observation next is [0.0, 0.9565217391304348, 0.4349030470914128, 0.55, 0.0, 0.0, 0.6666666666666666, 0.6157914381980033, 0.6334813232152816, 0.0, 1.0, 0.20772552933713118], 
reward next is 0.7923, 
noisyNet noise sample is [array([-0.26507258], dtype=float32), -1.512702]. 
=============================================
[2019-04-06 23:58:19,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:58:19,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:58:19,824] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run44
[2019-04-06 23:58:20,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:58:20,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:58:20,586] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run44
[2019-04-06 23:58:32,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:58:32,614] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:58:32,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run44
[2019-04-06 23:58:42,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:58:42,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:58:42,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run44
[2019-04-06 23:58:44,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:58:44,670] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:58:44,674] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run44
[2019-04-06 23:58:44,908] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:58:44,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:58:44,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run44
[2019-04-06 23:58:49,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:58:49,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:58:49,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run44
[2019-04-06 23:59:06,518] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.7051520e-13 7.8263229e-12 4.3367615e-13 3.7649798e-08 8.4608402e-15
 1.0000000e+00 5.2949669e-13], sum to 1.0000
[2019-04-06 23:59:06,519] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1348
[2019-04-06 23:59:06,808] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 78.0, 17.0, 157.0, 26.0, 24.40427705977291, 0.1259352286072122, 1.0, 1.0, 119136.09693019319], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 201600.0000, 
sim time next is 203400.0000, 
raw observation next is [-8.65, 78.0, 34.0, 296.0, 26.0, 25.09608672172866, 0.2228932223347867, 1.0, 1.0, 20101.212535011688], 
processed observation next is [1.0, 0.34782608695652173, 0.22299168975069253, 0.78, 0.11333333333333333, 0.3270718232044199, 0.6666666666666666, 0.591340560144055, 0.5742977407782622, 1.0, 1.0, 0.09572005969053185], 
reward next is 0.9043, 
noisyNet noise sample is [array([1.8277704], dtype=float32), -1.0406646]. 
=============================================
[2019-04-06 23:59:12,765] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.9652880e-15 3.9058596e-12 2.2948654e-13 3.1699834e-08 1.9343492e-15
 1.0000000e+00 9.5731765e-14], sum to 1.0000
[2019-04-06 23:59:12,765] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6878
[2019-04-06 23:59:12,849] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 49.0, 0.0, 0.0, 26.0, 25.3240356238631, 0.3154149071168832, 0.0, 1.0, 39170.87204907097], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4260600.0000, 
sim time next is 4262400.0000, 
raw observation next is [3.0, 49.0, 55.0, 26.5, 26.0, 25.32209189538507, 0.3258617240862324, 0.0, 1.0, 39069.184006476215], 
processed observation next is [0.0, 0.34782608695652173, 0.5457063711911359, 0.49, 0.18333333333333332, 0.029281767955801105, 0.6666666666666666, 0.6101743246154226, 0.6086205746954109, 0.0, 1.0, 0.18604373336417246], 
reward next is 0.8140, 
noisyNet noise sample is [array([-0.23687813], dtype=float32), -1.2615504]. 
=============================================
[2019-04-06 23:59:22,376] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3067717e-15 1.8218339e-12 4.6515166e-15 8.9871541e-09 3.2875892e-16
 1.0000000e+00 2.0192850e-15], sum to 1.0000
[2019-04-06 23:59:22,376] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4196
[2019-04-06 23:59:22,421] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 66.0, 111.5, 423.5, 26.0, 25.87277009738929, 0.3543256163136259, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 730800.0000, 
sim time next is 732600.0000, 
raw observation next is [-0.6, 61.5, 84.0, 779.0, 26.0, 25.83433398554451, 0.3894601439889407, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.44598337950138506, 0.615, 0.28, 0.8607734806629834, 0.6666666666666666, 0.6528611654620425, 0.6298200479963135, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16426325], dtype=float32), -0.4324239]. 
=============================================
[2019-04-06 23:59:23,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:59:23,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:59:23,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run44
[2019-04-06 23:59:25,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:59:25,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:59:25,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run44
[2019-04-06 23:59:34,911] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.5824577e-14 1.8901313e-11 2.5315169e-13 6.7475746e-08 4.4230275e-14
 9.9999988e-01 2.9471599e-13], sum to 1.0000
[2019-04-06 23:59:34,911] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1184
[2019-04-06 23:59:35,139] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 58.0, 0.0, 0.0, 26.0, 24.92430657300488, 0.3093445848210389, 1.0, 1.0, 84551.03645927824], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 763200.0000, 
sim time next is 765000.0000, 
raw observation next is [-5.3, 59.5, 0.0, 0.0, 26.0, 25.02807883068366, 0.32064183200649, 0.0, 1.0, 66144.2038558391], 
processed observation next is [1.0, 0.8695652173913043, 0.31578947368421056, 0.595, 0.0, 0.0, 0.6666666666666666, 0.5856732358903051, 0.60688061066883, 0.0, 1.0, 0.31497239931351956], 
reward next is 0.6850, 
noisyNet noise sample is [array([-0.27020028], dtype=float32), -0.7624322]. 
=============================================
[2019-04-06 23:59:35,143] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[79.311554]
 [79.26582 ]
 [79.535515]
 [79.78377 ]
 [80.493996]], R is [[78.71585846]
 [78.52607727]
 [78.58255768]
 [78.46807861]
 [78.68339539]].
[2019-04-06 23:59:36,568] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.6765229e-15 1.8195274e-12 2.1099379e-14 3.4301399e-07 2.0168517e-15
 9.9999964e-01 2.2573982e-14], sum to 1.0000
[2019-04-06 23:59:36,569] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0710
[2019-04-06 23:59:36,608] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.3, 88.5, 0.0, 0.0, 26.0, 24.45761373424872, 0.1578820276250919, 0.0, 1.0, 43298.79999592138], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2086200.0000, 
sim time next is 2088000.0000, 
raw observation next is [-5.6, 91.0, 0.0, 0.0, 26.0, 24.41168842643322, 0.1649025212811111, 0.0, 1.0, 43619.836512659494], 
processed observation next is [1.0, 0.17391304347826086, 0.30747922437673136, 0.91, 0.0, 0.0, 0.6666666666666666, 0.534307368869435, 0.5549675070937037, 0.0, 1.0, 0.20771350720314044], 
reward next is 0.7923, 
noisyNet noise sample is [array([1.1876516], dtype=float32), 0.633652]. 
=============================================
[2019-04-06 23:59:36,612] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[85.4541  ]
 [85.678375]
 [85.67116 ]
 [85.75833 ]
 [85.73413 ]], R is [[85.17539215]
 [85.11745453]
 [85.06149292]
 [85.00726318]
 [84.95372772]].
[2019-04-06 23:59:36,739] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.37624896e-17 6.61646438e-14 1.05347374e-16 2.77496648e-09
 4.85679361e-17 1.00000000e+00 3.04944381e-16], sum to 1.0000
[2019-04-06 23:59:36,739] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5859
[2019-04-06 23:59:36,790] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 74.0, 0.0, 0.0, 26.0, 25.57808109625306, 0.5760091901266039, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1627200.0000, 
sim time next is 1629000.0000, 
raw observation next is [7.45, 75.0, 0.0, 0.0, 26.0, 25.32673613788881, 0.576251819410613, 0.0, 1.0, 130811.93961286407], 
processed observation next is [1.0, 0.8695652173913043, 0.6689750692520776, 0.75, 0.0, 0.0, 0.6666666666666666, 0.6105613448240673, 0.6920839398035378, 0.0, 1.0, 0.6229139981564955], 
reward next is 0.3771, 
noisyNet noise sample is [array([1.067839], dtype=float32), 0.86897874]. 
=============================================
[2019-04-06 23:59:36,805] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[93.10613]
 [93.15026]
 [94.16374]
 [94.22627]
 [94.13645]], R is [[93.06513977]
 [93.13449097]
 [93.20314789]
 [93.27111816]
 [93.33840942]].
[2019-04-06 23:59:42,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:59:42,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:59:42,836] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run44
[2019-04-06 23:59:43,251] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.85600665e-15 4.42569701e-13 1.15775741e-14 1.03928794e-08
 1.74117755e-15 1.00000000e+00 1.80996931e-14], sum to 1.0000
[2019-04-06 23:59:43,251] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5255
[2019-04-06 23:59:43,389] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 64.0, 130.0, 220.0, 26.0, 25.94020855822558, 0.382390931466859, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2797200.0000, 
sim time next is 2799000.0000, 
raw observation next is [-4.5, 59.5, 152.0, 233.0, 26.0, 25.87468273285439, 0.3960684279679203, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3379501385041552, 0.595, 0.5066666666666667, 0.2574585635359116, 0.6666666666666666, 0.6562235610711991, 0.6320228093226401, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.13563171], dtype=float32), 1.3764341]. 
=============================================
[2019-04-06 23:59:43,393] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[82.02109 ]
 [81.92098 ]
 [80.892586]
 [79.48133 ]
 [78.058235]], R is [[82.11903381]
 [82.29784393]
 [82.47486877]
 [82.34477234]
 [81.77796936]].
[2019-04-06 23:59:45,312] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.9637767e-15 5.2364737e-13 1.0741877e-13 2.5217261e-08 6.3382061e-15
 1.0000000e+00 5.0581596e-14], sum to 1.0000
[2019-04-06 23:59:45,312] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7655
[2019-04-06 23:59:45,409] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 39.0, 100.5, 638.5, 26.0, 25.70443401686995, 0.4102789829749721, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4957200.0000, 
sim time next is 4959000.0000, 
raw observation next is [0.0, 34.5, 108.0, 717.0, 26.0, 26.08216394692588, 0.4704168524656509, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.46260387811634357, 0.345, 0.36, 0.7922651933701658, 0.6666666666666666, 0.6735136622438235, 0.6568056174885503, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8881711], dtype=float32), 0.31754392]. 
=============================================
[2019-04-06 23:59:45,414] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[83.669304]
 [83.764305]
 [82.63709 ]
 [81.50121 ]
 [81.24991 ]], R is [[84.14713287]
 [84.30566406]
 [84.46260834]
 [84.61798096]
 [84.69705963]].
[2019-04-06 23:59:46,079] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8026010e-15 2.0339997e-12 8.2662027e-14 2.0198168e-07 6.2712481e-15
 9.9999976e-01 6.8294060e-15], sum to 1.0000
[2019-04-06 23:59:46,093] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7468
[2019-04-06 23:59:46,168] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 44.0, 0.0, 0.0, 26.0, 24.86941428174969, 0.3461467890452223, 0.0, 1.0, 128485.37640228278], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2838600.0000, 
sim time next is 2840400.0000, 
raw observation next is [2.0, 44.0, 0.0, 0.0, 26.0, 25.22788796881627, 0.4133522363374943, 0.0, 1.0, 80238.5798685838], 
processed observation next is [1.0, 0.9130434782608695, 0.518005540166205, 0.44, 0.0, 0.0, 0.6666666666666666, 0.6023239974013558, 0.6377840787791648, 0.0, 1.0, 0.3820884755646847], 
reward next is 0.6179, 
noisyNet noise sample is [array([2.0473294], dtype=float32), 0.39021057]. 
=============================================
[2019-04-06 23:59:51,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:59:51,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:59:51,955] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run44
[2019-04-07 00:00:02,493] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6376152e-16 2.0091754e-13 3.1444436e-16 6.5633765e-09 3.7001448e-16
 1.0000000e+00 9.4846865e-17], sum to 1.0000
[2019-04-07 00:00:02,494] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4392
[2019-04-07 00:00:02,768] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.35, 100.0, 18.0, 0.0, 26.0, 25.56787340515372, 0.4768331339276884, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1499400.0000, 
sim time next is 1501200.0000, 
raw observation next is [1.6, 100.0, 32.5, 0.0, 26.0, 25.82561488811113, 0.4933226096205901, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.5069252077562327, 1.0, 0.10833333333333334, 0.0, 0.6666666666666666, 0.6521345740092608, 0.66444086987353, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8298395], dtype=float32), 0.6219482]. 
=============================================
[2019-04-07 00:00:08,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7673544e-17 1.8970560e-14 1.3810090e-16 3.0111464e-09 1.5214239e-16
 1.0000000e+00 8.9069458e-17], sum to 1.0000
[2019-04-07 00:00:08,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6183
[2019-04-07 00:00:08,291] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.7, 82.0, 0.0, 0.0, 26.0, 25.67807029932417, 0.6162648320547074, 0.0, 1.0, 18725.026904540016], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1150200.0000, 
sim time next is 1152000.0000, 
raw observation next is [12.7, 84.0, 16.0, 0.5, 26.0, 25.69415594059318, 0.6066588417361984, 0.0, 1.0, 7412.569542502581], 
processed observation next is [0.0, 0.34782608695652173, 0.8144044321329641, 0.84, 0.05333333333333334, 0.0005524861878453039, 0.6666666666666666, 0.6411796617160984, 0.7022196139120661, 0.0, 1.0, 0.03529795020239324], 
reward next is 0.9647, 
noisyNet noise sample is [array([-1.6044692], dtype=float32), 0.43874294]. 
=============================================
[2019-04-07 00:00:08,347] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[97.61669]
 [97.33166]
 [97.10479]
 [96.83666]
 [96.5214 ]], R is [[97.89781189]
 [97.82967377]
 [97.7621994 ]
 [97.63347626]
 [97.51726532]].
[2019-04-07 00:00:09,266] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:00:09,266] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:00:09,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run44
[2019-04-07 00:00:28,409] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-07 00:00:28,436] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 00:00:28,452] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 00:00:28,453] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:00:28,452] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:00:28,459] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run99
[2019-04-07 00:00:28,574] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 00:00:28,575] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:00:28,579] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run99
[2019-04-07 00:00:28,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run99
[2019-04-07 00:01:55,875] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.07425008], dtype=float32), 0.14295731]
[2019-04-07 00:01:55,875] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [8.3, 67.0, 0.0, 0.0, 26.0, 25.7690074348451, 0.5963331840428968, 0.0, 1.0, 0.0]
[2019-04-07 00:01:55,875] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 00:01:55,877] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.8361452e-16 2.6779184e-13 1.6608665e-15 8.7111802e-09 3.1212831e-16
 1.0000000e+00 1.5704146e-15], sampled 0.343771605472302
[2019-04-07 00:03:09,454] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-07 00:03:29,987] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-07 00:03:30,011] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-07 00:03:31,035] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1960000, evaluation results [1960000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-07 00:03:34,112] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1550000e-17 5.7872747e-14 2.3852231e-16 1.7401934e-09 3.7916771e-17
 1.0000000e+00 4.2976991e-16], sum to 1.0000
[2019-04-07 00:03:34,113] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7649
[2019-04-07 00:03:34,150] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.55, 79.0, 0.0, 0.0, 26.0, 25.68678727327605, 0.6097492840629134, 0.0, 1.0, 68095.44132961065], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1056600.0000, 
sim time next is 1058400.0000, 
raw observation next is [13.3, 80.0, 0.0, 0.0, 26.0, 25.82268626879889, 0.5983144068625639, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.8310249307479226, 0.8, 0.0, 0.0, 0.6666666666666666, 0.6518905223999075, 0.6994381356208547, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.4474952], dtype=float32), 0.93312067]. 
=============================================
[2019-04-07 00:03:34,182] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.06445150e-15 8.40192607e-13 4.93748278e-14 4.43791226e-09
 3.91555041e-15 1.00000000e+00 1.08498525e-14], sum to 1.0000
[2019-04-07 00:03:34,182] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6649
[2019-04-07 00:03:34,241] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.8, 90.0, 0.0, 0.0, 26.0, 24.58104647909239, 0.183748940522816, 0.0, 1.0, 40924.63175975507], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 541800.0000, 
sim time next is 543600.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 26.0, 24.58862794337909, 0.1688898611986422, 0.0, 1.0, 40777.84903642185], 
processed observation next is [0.0, 0.30434782608695654, 0.4764542936288089, 0.92, 0.0, 0.0, 0.6666666666666666, 0.5490523286149243, 0.5562966203995474, 0.0, 1.0, 0.19418023350677072], 
reward next is 0.8058, 
noisyNet noise sample is [array([0.48560178], dtype=float32), 1.6380706]. 
=============================================
[2019-04-07 00:03:38,184] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9128904e-14 4.1598600e-12 3.2399167e-13 4.5335824e-08 2.8979332e-14
 1.0000000e+00 6.4984734e-14], sum to 1.0000
[2019-04-07 00:03:38,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3837
[2019-04-07 00:03:38,425] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 87.0, 20.5, 22.5, 26.0, 24.98320799786399, 0.3050336883395189, 0.0, 1.0, 41699.81403941093], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 579600.0000, 
sim time next is 581400.0000, 
raw observation next is [-2.0, 87.0, 0.0, 0.0, 26.0, 24.94341702800877, 0.289773327911177, 0.0, 1.0, 45664.5030274184], 
processed observation next is [0.0, 0.7391304347826086, 0.40720221606648205, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5786180856673976, 0.5965911093037256, 0.0, 1.0, 0.21745001441627812], 
reward next is 0.7825, 
noisyNet noise sample is [array([-1.3741053], dtype=float32), -1.7775673]. 
=============================================
[2019-04-07 00:04:00,278] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0271100e-15 9.4999681e-13 4.0187089e-15 4.2412026e-08 5.7856135e-16
 1.0000000e+00 1.7210834e-14], sum to 1.0000
[2019-04-07 00:04:00,278] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4286
[2019-04-07 00:04:00,352] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 85.0, 0.0, 0.0, 26.0, 25.03365842763477, 0.3800378384906222, 0.0, 1.0, 43325.5691726585], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1744200.0000, 
sim time next is 1746000.0000, 
raw observation next is [-0.6, 83.0, 0.0, 0.0, 26.0, 24.97746160085111, 0.3668817408537586, 0.0, 1.0, 43467.67138616302], 
processed observation next is [0.0, 0.21739130434782608, 0.44598337950138506, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5814551334042593, 0.6222939136179195, 0.0, 1.0, 0.20698891136268105], 
reward next is 0.7930, 
noisyNet noise sample is [array([-0.08473844], dtype=float32), 0.29040042]. 
=============================================
[2019-04-07 00:04:00,358] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[84.30633]
 [84.77001]
 [85.19504]
 [85.503  ]
 [85.15584]], R is [[83.77787018]
 [83.73377991]
 [83.69076538]
 [83.64873505]
 [83.60757446]].
[2019-04-07 00:04:01,074] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5386541e-15 5.3008301e-12 8.5875941e-14 8.6031582e-09 3.4478768e-15
 1.0000000e+00 5.7819790e-14], sum to 1.0000
[2019-04-07 00:04:01,074] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9207
[2019-04-07 00:04:01,147] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 79.0, 0.0, 0.0, 26.0, 24.60871197606228, 0.1834453964536318, 0.0, 1.0, 39361.35700184799], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 874800.0000, 
sim time next is 876600.0000, 
raw observation next is [-1.45, 77.5, 0.0, 0.0, 26.0, 24.61344081981355, 0.1847178269616885, 0.0, 1.0, 39263.00857562954], 
processed observation next is [1.0, 0.13043478260869565, 0.422437673130194, 0.775, 0.0, 0.0, 0.6666666666666666, 0.5511200683177959, 0.5615726089872295, 0.0, 1.0, 0.1869667075029978], 
reward next is 0.8130, 
noisyNet noise sample is [array([-0.2708375], dtype=float32), -0.784105]. 
=============================================
[2019-04-07 00:04:08,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2331472e-18 2.2660354e-14 4.5964782e-17 2.6707725e-09 7.2463252e-17
 1.0000000e+00 4.0777590e-16], sum to 1.0000
[2019-04-07 00:04:08,341] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7990
[2019-04-07 00:04:08,464] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.25, 92.5, 60.0, 0.0, 26.0, 26.35255201882364, 0.6070792772209891, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 984600.0000, 
sim time next is 986400.0000, 
raw observation next is [10.5, 93.0, 78.0, 0.0, 26.0, 26.47276495812752, 0.6299986621124463, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.7534626038781165, 0.93, 0.26, 0.0, 0.6666666666666666, 0.7060637465106266, 0.709999554037482, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4556885], dtype=float32), 0.08750052]. 
=============================================
[2019-04-07 00:04:33,105] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.2492005e-17 2.4525531e-14 1.6471182e-15 6.4354194e-10 2.2668706e-17
 1.0000000e+00 5.8268101e-16], sum to 1.0000
[2019-04-07 00:04:33,105] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9058
[2019-04-07 00:04:33,190] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 96.0, 98.0, 0.0, 26.0, 25.06633997677871, 0.4849008704880035, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1252800.0000, 
sim time next is 1254600.0000, 
raw observation next is [14.1, 98.0, 101.0, 0.0, 26.0, 25.0130561161769, 0.477789598885596, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.8531855955678671, 0.98, 0.33666666666666667, 0.0, 0.6666666666666666, 0.5844213430147418, 0.659263199628532, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.63912356], dtype=float32), 0.033905517]. 
=============================================
[2019-04-07 00:04:34,663] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7945355e-13 8.4284781e-11 1.5338065e-12 5.3078173e-07 6.0847795e-13
 9.9999952e-01 1.7598567e-12], sum to 1.0000
[2019-04-07 00:04:34,664] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1020
[2019-04-07 00:04:34,716] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.18252824625887, 0.09052494890158751, 0.0, 1.0, 39619.40986018515], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3036600.0000, 
sim time next is 3038400.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.08025170683843, 0.06840716411479587, 0.0, 1.0, 39956.38591966075], 
processed observation next is [0.0, 0.17391304347826086, 0.296398891966759, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5066876422365357, 0.5228023880382653, 0.0, 1.0, 0.1902685043793369], 
reward next is 0.8097, 
noisyNet noise sample is [array([0.6827759], dtype=float32), 0.5921614]. 
=============================================
[2019-04-07 00:04:44,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7938069e-14 2.3856193e-12 2.6154252e-13 1.2163090e-07 1.5022832e-15
 9.9999988e-01 2.2538623e-14], sum to 1.0000
[2019-04-07 00:04:44,989] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9367
[2019-04-07 00:04:45,091] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.46090830261587, 0.1527962030780163, 0.0, 1.0, 40759.02230208027], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2779200.0000, 
sim time next is 2781000.0000, 
raw observation next is [-6.5, 61.5, 0.0, 0.0, 26.0, 24.47663804810006, 0.1493318662793169, 0.0, 1.0, 40777.319741405605], 
processed observation next is [1.0, 0.17391304347826086, 0.28254847645429365, 0.615, 0.0, 0.0, 0.6666666666666666, 0.5397198373416717, 0.5497772887597723, 0.0, 1.0, 0.19417771305431242], 
reward next is 0.8058, 
noisyNet noise sample is [array([1.0140003], dtype=float32), 0.76570445]. 
=============================================
[2019-04-07 00:04:45,103] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[78.28396]
 [78.44805]
 [78.6014 ]
 [78.52773]
 [78.54817]], R is [[78.19676971]
 [78.22071075]
 [78.24378967]
 [78.26535797]
 [78.28508759]].
[2019-04-07 00:04:57,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:04:57,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:04:57,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run45
[2019-04-07 00:05:05,097] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3523788e-14 1.7739038e-12 3.8407415e-14 2.7589384e-09 5.7827292e-14
 1.0000000e+00 9.0855099e-14], sum to 1.0000
[2019-04-07 00:05:05,097] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0926
[2019-04-07 00:05:05,209] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.3, 77.0, 7.0, 88.0, 26.0, 25.05694536594121, 0.2955681006274938, 0.0, 1.0, 29082.502345654226], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3087000.0000, 
sim time next is 3088800.0000, 
raw observation next is [-0.6, 82.0, 0.0, 0.0, 26.0, 24.99176819956359, 0.2838153664125689, 0.0, 1.0, 50599.054560289915], 
processed observation next is [0.0, 0.782608695652174, 0.44598337950138506, 0.82, 0.0, 0.0, 0.6666666666666666, 0.5826473499636325, 0.5946051221375229, 0.0, 1.0, 0.2409478788585234], 
reward next is 0.7591, 
noisyNet noise sample is [array([0.15441017], dtype=float32), 1.9646472]. 
=============================================
[2019-04-07 00:05:23,339] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.1079415e-13 9.2912213e-11 1.2894994e-12 8.0642974e-07 2.3321843e-14
 9.9999917e-01 9.2619062e-14], sum to 1.0000
[2019-04-07 00:05:23,339] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8291
[2019-04-07 00:05:23,737] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 91.0, 0.0, 0.0, 26.0, 23.11923672893798, -0.1933502383145946, 0.0, 1.0, 44541.96793129926], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1926000.0000, 
sim time next is 1927800.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 26.0, 23.62482582125511, 0.009840905635030853, 1.0, 1.0, 150047.43741813317], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.6666666666666666, 0.4687354851045926, 0.5032803018783436, 1.0, 1.0, 0.7145116067530151], 
reward next is 0.2855, 
noisyNet noise sample is [array([-1.6399322], dtype=float32), -0.29464185]. 
=============================================
[2019-04-07 00:05:28,260] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9881100e-14 1.1544410e-10 6.6971933e-13 9.1491835e-08 5.4184343e-13
 9.9999988e-01 1.1151354e-12], sum to 1.0000
[2019-04-07 00:05:28,264] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4712
[2019-04-07 00:05:28,348] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 70.0, 0.0, 0.0, 26.0, 24.66291834348707, 0.2650136085125981, 0.0, 1.0, 40860.20493695769], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3564000.0000, 
sim time next is 3565800.0000, 
raw observation next is [-6.0, 70.0, 0.0, 0.0, 26.0, 24.53775429480983, 0.2356392945129711, 0.0, 1.0, 40909.60659302059], 
processed observation next is [0.0, 0.2608695652173913, 0.296398891966759, 0.7, 0.0, 0.0, 0.6666666666666666, 0.5448128579008191, 0.5785464315043237, 0.0, 1.0, 0.19480765044295517], 
reward next is 0.8052, 
noisyNet noise sample is [array([1.5799236], dtype=float32), 0.5494689]. 
=============================================
[2019-04-07 00:05:38,243] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6532313e-14 1.2518593e-12 1.4101036e-13 6.8267745e-08 1.8467698e-14
 9.9999988e-01 1.9517686e-14], sum to 1.0000
[2019-04-07 00:05:38,243] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9435
[2019-04-07 00:05:38,309] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.8, 58.0, 70.0, 556.0, 26.0, 25.5653198648061, 0.466443122255165, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4293000.0000, 
sim time next is 4294800.0000, 
raw observation next is [6.6, 60.0, 47.0, 392.0, 26.0, 25.60076865731673, 0.4475036317223982, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.6454293628808865, 0.6, 0.15666666666666668, 0.4331491712707182, 0.6666666666666666, 0.6333973881097276, 0.6491678772407994, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24857111], dtype=float32), -2.2438638]. 
=============================================
[2019-04-07 00:05:44,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:05:44,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:05:44,184] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run45
[2019-04-07 00:06:03,009] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-07 00:06:03,029] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 00:06:03,030] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:06:03,048] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 00:06:03,048] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:06:03,053] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 00:06:03,053] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:06:03,068] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run100
[2019-04-07 00:06:03,206] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run100
[2019-04-07 00:06:03,257] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run100
[2019-04-07 00:08:02,028] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.0740769], dtype=float32), 0.14297037]
[2019-04-07 00:08:02,029] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-4.5, 68.0, 14.0, 0.0, 26.0, 26.09740607255883, 0.4572353093997617, 1.0, 1.0, 0.0]
[2019-04-07 00:08:02,029] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 00:08:02,030] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [6.3791535e-14 1.0808496e-11 2.2003514e-13 1.0147196e-07 4.7156218e-14
 9.9999988e-01 2.0405348e-13], sampled 0.5998147889917101
[2019-04-07 00:08:47,093] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-07 00:09:05,496] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-07 00:09:09,785] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-07 00:09:10,809] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1980000, evaluation results [1980000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
[2019-04-07 00:09:21,169] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.66145175e-15 1.24235925e-11 7.27805013e-15 3.27850444e-07
 1.96618118e-16 9.99999642e-01 1.63036529e-14], sum to 1.0000
[2019-04-07 00:09:21,169] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8813
[2019-04-07 00:09:21,276] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.5, 65.5, 99.0, 670.0, 26.0, 25.72918537935858, 0.4989944164272253, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3490200.0000, 
sim time next is 3492000.0000, 
raw observation next is [0.0, 60.0, 104.0, 720.0, 26.0, 26.13614660064907, 0.5618829339627793, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.46260387811634357, 0.6, 0.3466666666666667, 0.7955801104972375, 0.6666666666666666, 0.6780122167207558, 0.6872943113209264, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7716904], dtype=float32), -0.47403586]. 
=============================================
[2019-04-07 00:09:21,280] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[88.55941 ]
 [88.71289 ]
 [88.6942  ]
 [88.297775]
 [87.85715 ]], R is [[88.06245422]
 [88.18183136]
 [88.30001068]
 [88.41701508]
 [88.53284454]].
[2019-04-07 00:09:32,852] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.8421631e-14 1.4817515e-11 5.4489955e-14 2.7053296e-08 1.6392400e-14
 1.0000000e+00 7.7637813e-14], sum to 1.0000
[2019-04-07 00:09:32,853] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4874
[2019-04-07 00:09:32,955] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 26.0, 24.97989800314202, 0.252424487895651, 0.0, 1.0, 41638.98499265084], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2599200.0000, 
sim time next is 2601000.0000, 
raw observation next is [-5.0, 74.0, 0.0, 0.0, 26.0, 24.88257074650033, 0.2227773525614618, 0.0, 1.0, 41633.55783031555], 
processed observation next is [1.0, 0.08695652173913043, 0.32409972299168976, 0.74, 0.0, 0.0, 0.6666666666666666, 0.5735475622083609, 0.5742591175204873, 0.0, 1.0, 0.1982550372872169], 
reward next is 0.8017, 
noisyNet noise sample is [array([-1.7208731], dtype=float32), -1.4896114]. 
=============================================
[2019-04-07 00:09:32,961] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[81.56805 ]
 [81.1957  ]
 [80.89448 ]
 [80.80422 ]
 [80.730965]], R is [[81.77507019]
 [81.75904083]
 [81.74274445]
 [81.72608185]
 [81.70925903]].
[2019-04-07 00:09:34,029] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:09:34,029] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:09:34,036] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run45
[2019-04-07 00:09:41,774] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0650029e-15 1.0196217e-12 3.7936488e-15 3.4115569e-08 2.6837933e-17
 1.0000000e+00 9.7479146e-16], sum to 1.0000
[2019-04-07 00:09:41,775] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6714
[2019-04-07 00:09:41,842] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 100.0, 0.0, 0.0, 26.0, 25.29828799884694, 0.5073141212938538, 0.0, 1.0, 41578.68263904098], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3214800.0000, 
sim time next is 3216600.0000, 
raw observation next is [-2.5, 100.0, 0.0, 0.0, 26.0, 25.3199666838722, 0.4942803288789746, 0.0, 1.0, 40611.79554836434], 
processed observation next is [1.0, 0.21739130434782608, 0.39335180055401664, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6099972236560166, 0.6647601096263248, 0.0, 1.0, 0.19338950261125876], 
reward next is 0.8066, 
noisyNet noise sample is [array([1.9194001], dtype=float32), -1.9143243]. 
=============================================
[2019-04-07 00:10:02,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:10:02,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:10:02,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run45
[2019-04-07 00:10:08,521] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:10:08,521] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:10:08,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run45
[2019-04-07 00:10:09,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:10:09,466] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:10:09,475] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run45
[2019-04-07 00:10:21,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:10:21,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:10:21,108] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run45
[2019-04-07 00:10:30,725] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:10:30,725] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:10:30,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run45
[2019-04-07 00:10:31,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:10:31,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:10:31,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run45
[2019-04-07 00:10:36,312] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3505730e-16 2.1486018e-13 5.5954958e-15 7.9217468e-09 1.9369252e-16
 1.0000000e+00 6.7146043e-16], sum to 1.0000
[2019-04-07 00:10:36,312] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0193
[2019-04-07 00:10:36,689] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 26.0, 25.38595093569916, 0.4573818600885849, 0.0, 1.0, 47888.045754558894], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3456000.0000, 
sim time next is 3457800.0000, 
raw observation next is [1.0, 82.5, 0.0, 0.0, 26.0, 25.47850329687068, 0.4648493947388846, 0.0, 1.0, 28670.304205129865], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.825, 0.0, 0.0, 0.6666666666666666, 0.6232086080725567, 0.6549497982462948, 0.0, 1.0, 0.13652525811966604], 
reward next is 0.8635, 
noisyNet noise sample is [array([0.8232744], dtype=float32), -0.9045283]. 
=============================================
[2019-04-07 00:10:39,740] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:10:39,740] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:10:39,744] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run45
[2019-04-07 00:10:41,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:10:41,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:10:41,024] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run45
[2019-04-07 00:10:45,328] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2927221e-13 1.9736176e-11 4.6124687e-13 5.7936757e-07 2.3511591e-13
 9.9999940e-01 1.0415712e-12], sum to 1.0000
[2019-04-07 00:10:45,328] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0864
[2019-04-07 00:10:45,404] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.4, 82.0, 0.0, 0.0, 26.0, 24.2312268837282, 0.1106167122271548, 0.0, 1.0, 47248.97560585756], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 338400.0000, 
sim time next is 340200.0000, 
raw observation next is [-13.65, 76.0, 0.0, 0.0, 26.0, 24.08735019697966, 0.07843406833210599, 0.0, 1.0, 47079.46700939374], 
processed observation next is [1.0, 0.9565217391304348, 0.08448753462603877, 0.76, 0.0, 0.0, 0.6666666666666666, 0.5072791830816383, 0.5261446894440354, 0.0, 1.0, 0.22418793813997018], 
reward next is 0.7758, 
noisyNet noise sample is [array([-0.03491171], dtype=float32), 2.054467]. 
=============================================
[2019-04-07 00:10:49,625] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.06234960e-16 2.59529973e-13 1.79937009e-15 5.84202411e-08
 1.49042202e-15 1.00000000e+00 1.15108135e-14], sum to 1.0000
[2019-04-07 00:10:49,625] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6476
[2019-04-07 00:10:49,700] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 60.0, 146.5, 638.0, 26.0, 26.44661745943677, 0.6264626186598731, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4615200.0000, 
sim time next is 4617000.0000, 
raw observation next is [1.0, 56.0, 129.0, 767.0, 26.0, 26.64746032834829, 0.6701905047337519, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4903047091412743, 0.56, 0.43, 0.8475138121546961, 0.6666666666666666, 0.7206216940290243, 0.7233968349112506, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5075629], dtype=float32), -0.3149446]. 
=============================================
[2019-04-07 00:10:49,722] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[87.84339]
 [87.85705]
 [87.30007]
 [86.64967]
 [86.15522]], R is [[88.04708099]
 [88.16661072]
 [88.28494263]
 [88.40209198]
 [88.51807404]].
[2019-04-07 00:10:50,219] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6132896e-15 6.7782455e-13 1.9181396e-15 2.8364159e-08 3.0568861e-16
 1.0000000e+00 4.4046560e-15], sum to 1.0000
[2019-04-07 00:10:50,220] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8373
[2019-04-07 00:10:50,265] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 71.0, 0.0, 0.0, 26.0, 25.29245961075805, 0.3967128134745927, 0.0, 1.0, 36858.895986017305], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4597200.0000, 
sim time next is 4599000.0000, 
raw observation next is [-2.3, 72.5, 0.0, 0.0, 26.0, 25.18660931636487, 0.3679650803421738, 0.0, 1.0, 36210.27373029218], 
processed observation next is [1.0, 0.21739130434782608, 0.3988919667590028, 0.725, 0.0, 0.0, 0.6666666666666666, 0.5988841096970724, 0.6226550267807246, 0.0, 1.0, 0.17242987490615325], 
reward next is 0.8276, 
noisyNet noise sample is [array([0.6090315], dtype=float32), 0.10688452]. 
=============================================
[2019-04-07 00:10:50,269] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[86.20104 ]
 [86.40435 ]
 [86.47039 ]
 [86.693504]
 [86.93409 ]], R is [[85.98822021]
 [85.95281982]
 [85.84235382]
 [85.83914185]
 [85.85945129]].
[2019-04-07 00:11:13,084] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:11:13,084] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:11:13,087] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run45
[2019-04-07 00:11:16,476] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:11:16,476] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:11:16,480] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run45
[2019-04-07 00:11:39,844] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-07 00:11:39,873] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 00:11:39,874] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:11:39,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run101
[2019-04-07 00:11:40,038] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 00:11:40,038] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:11:40,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run101
[2019-04-07 00:11:40,165] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 00:11:40,166] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:11:40,234] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/44/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run101
[2019-04-07 00:13:58,070] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.07517242], dtype=float32), 0.14340948]
[2019-04-07 00:13:58,070] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [4.5, 72.0, 161.5, 377.0, 26.0, 26.63913806406345, 0.8306224577559943, 1.0, 1.0, 0.0]
[2019-04-07 00:13:58,070] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 00:13:58,071] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [3.7995267e-16 1.6062049e-13 1.4592325e-15 5.3051270e-09 3.4104241e-16
 1.0000000e+00 1.3275520e-15], sampled 0.8376168341107115
[2019-04-07 00:14:02,563] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([-0.07517242], dtype=float32), 0.14340948]
[2019-04-07 00:14:02,563] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-5.25, 55.5, 224.0, 378.0, 26.0, 25.38744993602837, 0.4637551470433971, 1.0, 1.0, 18720.955222651693]
[2019-04-07 00:14:02,563] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 00:14:02,564] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [6.1583829e-14 9.7985803e-12 2.0500143e-13 8.5471271e-08 5.2052221e-14
 9.9999988e-01 1.7669531e-13], sampled 0.18328958377280558
[2019-04-07 00:14:21,682] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2453.2897 79959984.5800 535.1579
[2019-04-07 00:14:41,364] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2415.5784 87830352.8773 516.5543
[2019-04-07 00:14:44,906] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.0870 91944900.5891 409.3749
[2019-04-07 00:14:45,931] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2000000, evaluation results [2000000.0, 2415.5783941548752, 87830352.877312, 516.5542744756061, 2453.289682627508, 79959984.58002774, 535.1579115189242, 2396.0870440443086, 91944900.58913434, 409.3749352301794]
Traceback (most recent call last):
  File "../../../a3c_eplus_rlParametric_v0.1.py", line 48, in <module>
    main()
  File "../../../a3c_eplus_rlParametric_v0.1.py", line 44, in main
    eval_action_limits, raw_state_process_func, raw_stateLimit_process_func);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/main_args.py", line 195, in effective_main
    args.debug_log_prob, args.is_greedy_policy, args.action_repeat_n, args.eval_env_res_max_keep);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 850, in fit
    coordinator.join(threads);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py", line 397, in join
    " ".join(stragglers))
RuntimeError: Coordinator stopped with threads still running: Thread-6 Thread-13 Thread-19 Thread-3 Thread-10 Thread-12 Thread-17 Thread-20 Thread-16 Thread-5 Thread-15 Thread-18
