Using TensorFlow backend.
[2019-04-06 14:50:23,229] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part4_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part4-Light-Pit-Train-Repeat-v1', eval_act_func='part4_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=20000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=5e-06, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2000000, metric_func='part4_v1', model_dir='None', model_param=[64, 2], model_type='nn', num_threads=16, output='./Part4-Light-Pit-Train-Repeat-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part4_heuri_v4', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=5.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=10, test_env=['Part4-Light-Pit-Test-Repeat-v1', 'Part4-Light-Pit-Test-Repeat-v2'], test_mode='Multiple', train_act_func='part4_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=10.0, weight_initer='glorot_uniform', window_len=7)
[2019-04-06 14:50:23,229] A3C_AGENT_MAIN INFO:Start compiling...
2019-04-06 14:50:23.268074: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-04-06 14:50:44,671] A3C_AGENT_MAIN INFO:Start the learning...
[2019-04-06 14:50:44,672] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part4-Light-Pit-Train-Repeat-v1', 'Part4-Light-Pit-Test-Repeat-v1', 'Part4-Light-Pit-Test-Repeat-v2'] ...
[2019-04-06 14:50:44,695] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation worker starts!
[2019-04-06 14:50:44,719] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation worker starts!
[2019-04-06 14:50:44,760] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation worker starts!
[2019-04-06 14:50:44,760] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:44,761] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-04-06 14:50:44,871] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:44,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run1
[2019-04-06 14:50:45,762] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:45,763] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-04-06 14:50:45,888] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:45,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run1
[2019-04-06 14:50:46,764] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:46,765] A3C_AGENT_WORKER-Thread-4 INFO:Local worker starts!
[2019-04-06 14:50:46,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:46,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run1
[2019-04-06 14:50:47,766] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:47,767] A3C_AGENT_WORKER-Thread-5 INFO:Local worker starts!
[2019-04-06 14:50:47,847] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:47,848] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run1
[2019-04-06 14:50:48,768] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:48,769] A3C_AGENT_WORKER-Thread-6 INFO:Local worker starts!
[2019-04-06 14:50:48,898] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:48,900] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run1
[2019-04-06 14:50:49,770] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:49,771] A3C_AGENT_WORKER-Thread-7 INFO:Local worker starts!
[2019-04-06 14:50:49,899] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:49,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run1
[2019-04-06 14:50:50,772] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:50,773] A3C_AGENT_WORKER-Thread-8 INFO:Local worker starts!
[2019-04-06 14:50:50,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:50,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run1
[2019-04-06 14:50:51,575] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 14:50:51,576] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 14:50:51,576] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 14:50:51,576] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:51,576] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 14:50:51,576] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:51,577] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:51,580] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run1
[2019-04-06 14:50:51,580] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run1
[2019-04-06 14:50:51,581] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run1
[2019-04-06 14:50:51,773] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:51,774] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-04-06 14:50:51,904] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:51,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run1
[2019-04-06 14:50:52,775] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:52,775] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-04-06 14:50:53,064] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:53,066] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run1
[2019-04-06 14:50:53,776] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:53,777] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-04-06 14:50:53,895] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:53,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run1
[2019-04-06 14:50:54,778] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:54,779] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-04-06 14:50:54,960] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:54,970] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run1
[2019-04-06 14:50:55,779] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:55,782] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-04-06 14:50:55,908] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:55,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run1
[2019-04-06 14:50:56,783] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:56,784] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-04-06 14:50:56,978] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:56,979] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run1
[2019-04-06 14:50:57,785] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:57,801] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-04-06 14:50:58,051] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:58,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run1
[2019-04-06 14:50:58,802] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:58,803] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-04-06 14:50:58,935] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:58,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run1
[2019-04-06 14:50:59,804] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-06 14:50:59,805] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-04-06 14:50:59,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:50:59,979] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run1
[2019-04-06 14:52:30,005] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2661.6233 61798025.2939 117.0062
[2019-04-06 14:52:42,152] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2567.2314 71214374.8903 -56.3580
[2019-04-06 14:52:43,199] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2558.8473 74150699.7243 -142.5459
[2019-04-06 14:52:44,220] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 0, evaluation results [0.0, 2567.2314472859916, 71214374.89026433, -56.35799903323117, 2661.623329910687, 61798025.29393492, 117.00622530949632, 2558.8473429015144, 74150699.72434156, -142.54589414237813]
[2019-04-06 14:52:56,463] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.14667359 0.16602296 0.15364379 0.1116021  0.18445848 0.10331663
 0.13428245], sum to 1.0000
[2019-04-06 14:52:56,463] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6925
[2019-04-06 14:52:56,877] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.3, 93.0, 0.0, 0.0, 19.0, 20.11615219721947, -0.7872942808534723, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [19.5], 
sim time this is 88200.0000, 
sim time next is 90000.0000, 
raw observation next is [-0.6, 91.0, 0.0, 0.0, 19.5, 19.95128751041764, -0.842144221770205, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.44598337950138506, 0.91, 0.0, 0.0, 0.125, 0.1626072925348033, 0.21928525940993168, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9341836], dtype=float32), -0.49511695]. 
=============================================
[2019-04-06 14:52:56,880] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-0.15940897]
 [-0.01432936]
 [-0.16676018]
 [-0.14672628]
 [-0.16273186]], R is [[1.032794  ]
 [2.02246618]
 [3.00224161]
 [3.97221923]
 [4.93249702]].
[2019-04-06 14:53:00,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.11315917 0.15614644 0.15246077 0.15442042 0.17597462 0.11525284
 0.13258575], sum to 1.0000
[2019-04-06 14:53:00,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2622
[2019-04-06 14:53:01,244] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-4.2, 76.5, 0.0, 0.0, 26.0, 22.88758653418469, -0.1908537220310131, 0.0, 1.0, 45481.34938128386], 
current ob forecast is [], 
actual action is [25.0], 
sim time this is 102600.0000, 
sim time next is 104400.0000, 
raw observation next is [-5.0, 74.0, 0.0, 0.0, 25.0, 22.77449456057172, -0.2200081711326559, 0.0, 1.0, 44917.58896922265], 
processed observation next is [1.0, 0.21739130434782608, 0.32409972299168976, 0.74, 0.0, 0.0, 0.5833333333333334, 0.3978745467143101, 0.4266639429557814, 0.0, 1.0, 0.21389328080582212], 
reward next is 0.9290, 
noisyNet noise sample is [array([0.56805867], dtype=float32), -0.33948755]. 
=============================================
[2019-04-06 14:53:22,600] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.12673812 0.13631608 0.15169603 0.16894889 0.17128502 0.12077796
 0.12423791], sum to 1.0000
[2019-04-06 14:53:22,600] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6476
[2019-04-06 14:53:23,473] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 26.0, 24.72608335153981, 0.1524581723667685, 0.0, 1.0, 35326.614554010186], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 246600.0000, 
sim time next is 248400.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 26.0, 24.42502603260903, 0.1052839938634539, 0.0, 1.0, 43631.645937717134], 
processed observation next is [1.0, 0.9130434782608695, 0.368421052631579, 0.65, 0.0, 0.0, 0.6666666666666666, 0.5354188360507525, 0.5350946646211513, 0.0, 1.0, 0.20776974256055777], 
reward next is 0.7922, 
noisyNet noise sample is [array([-1.2635698], dtype=float32), -0.88180727]. 
=============================================
[2019-04-06 14:54:27,675] A3C_AGENT_WORKER-Thread-4 INFO:Local step 500, global step 7427: loss 40.1582
[2019-04-06 14:54:27,838] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 500, global step 7427: learning rate 0.0000
[2019-04-06 14:54:28,295] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7470: loss 42.6468
[2019-04-06 14:54:28,295] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7470: learning rate 0.0000
[2019-04-06 14:54:29,419] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7579: loss 26.2004
[2019-04-06 14:54:29,420] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7579: learning rate 0.0000
[2019-04-06 14:54:30,594] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7665: loss 44.7881
[2019-04-06 14:54:30,595] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7665: learning rate 0.0000
[2019-04-06 14:54:31,369] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7734: loss 26.3302
[2019-04-06 14:54:31,370] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7734: learning rate 0.0000
[2019-04-06 14:54:32,679] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7842: loss 39.0770
[2019-04-06 14:54:32,679] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7842: learning rate 0.0000
[2019-04-06 14:54:32,886] A3C_AGENT_WORKER-Thread-7 INFO:Local step 500, global step 7858: loss 40.9183
[2019-04-06 14:54:32,892] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 500, global step 7858: learning rate 0.0000
[2019-04-06 14:54:33,252] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7890: loss 17.4686
[2019-04-06 14:54:33,252] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7890: learning rate 0.0000
[2019-04-06 14:54:33,410] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 7901: loss 43.7042
[2019-04-06 14:54:33,411] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 7901: learning rate 0.0000
[2019-04-06 14:54:35,929] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8098: loss 33.3746
[2019-04-06 14:54:35,930] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8098: learning rate 0.0000
[2019-04-06 14:54:36,170] A3C_AGENT_WORKER-Thread-8 INFO:Local step 500, global step 8127: loss 39.1626
[2019-04-06 14:54:36,170] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 500, global step 8127: learning rate 0.0000
[2019-04-06 14:54:36,285] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8142: loss 38.5067
[2019-04-06 14:54:36,287] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8142: learning rate 0.0000
[2019-04-06 14:54:38,619] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 8468: loss 39.9593
[2019-04-06 14:54:38,620] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 8468: learning rate 0.0000
[2019-04-06 14:54:39,305] A3C_AGENT_WORKER-Thread-5 INFO:Local step 500, global step 8580: loss 37.8909
[2019-04-06 14:54:39,306] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 500, global step 8580: learning rate 0.0000
[2019-04-06 14:54:40,729] A3C_AGENT_WORKER-Thread-6 INFO:Local step 500, global step 8808: loss 44.9347
[2019-04-06 14:54:40,729] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 500, global step 8808: learning rate 0.0000
[2019-04-06 14:54:40,992] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 8847: loss 45.0616
[2019-04-06 14:54:40,992] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 8847: learning rate 0.0000
[2019-04-06 14:54:51,299] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.14271642 0.10948519 0.13295645 0.10826647 0.25215223 0.12145206
 0.13297118], sum to 1.0000
[2019-04-06 14:54:51,299] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0344
[2019-04-06 14:54:51,887] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.7, 67.0, 0.0, 0.0, 22.5, 23.27215419791155, 0.05596269470618159, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [20.5], 
sim time this is 1195200.0000, 
sim time next is 1197000.0000, 
raw observation next is [17.7, 67.0, 0.0, 0.0, 20.5, 23.27012362464331, 0.05162736675383855, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.9529085872576178, 0.67, 0.0, 0.0, 0.20833333333333334, 0.43917696872027595, 0.5172091222512795, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.3745356], dtype=float32), 0.42655528]. 
=============================================
[2019-04-06 14:54:51,974] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[0.64232606]
 [0.6431222 ]
 [0.6277333 ]
 [0.6405829 ]
 [0.6632114 ]], R is [[1.61882627]
 [2.60263801]
 [3.57661176]
 [4.54084587]
 [5.49543762]].
[2019-04-06 14:54:52,178] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.13378341 0.12665635 0.1255977  0.12300156 0.2695256  0.10633232
 0.11510304], sum to 1.0000
[2019-04-06 14:54:52,178] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0875
[2019-04-06 14:54:52,764] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.0, 79.0, 0.0, 0.0, 25.0, 25.46801062798214, 0.5660025751116923, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [23.0], 
sim time this is 1130400.0000, 
sim time next is 1132200.0000, 
raw observation next is [10.55, 78.0, 0.0, 0.0, 23.0, 25.2980352468813, 0.5283120694192497, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.754847645429363, 0.78, 0.0, 0.0, 0.4166666666666667, 0.6081696039067751, 0.6761040231397498, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2964798], dtype=float32), 0.6738775]. 
=============================================
[2019-04-06 14:55:25,114] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.10246209 0.10700122 0.1371712  0.11509489 0.33451355 0.09187075
 0.11188634], sum to 1.0000
[2019-04-06 14:55:25,114] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5328
[2019-04-06 14:55:25,672] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15403: loss 23.2872
[2019-04-06 14:55:25,689] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15403: learning rate 0.0000
[2019-04-06 14:55:25,791] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 23.0, 22.69933841142822, -0.1684800194382074, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [23.5], 
sim time this is 1731600.0000, 
sim time next is 1733400.0000, 
raw observation next is [0.35, 91.5, 0.0, 0.0, 23.5, 22.65788334904492, -0.1502679797881393, 0.0, 1.0, 81654.50002664056], 
processed observation next is [0.0, 0.043478260869565216, 0.47229916897506935, 0.915, 0.0, 0.0, 0.4583333333333333, 0.38815694575374327, 0.4499106734039536, 0.0, 1.0, 0.3888309525078122], 
reward next is 0.9683, 
noisyNet noise sample is [array([-0.78814185], dtype=float32), -0.55000854]. 
=============================================
[2019-04-06 14:55:26,739] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15492: loss 39.1011
[2019-04-06 14:55:26,739] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15492: learning rate 0.0000
[2019-04-06 14:55:28,389] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15650: loss 36.0728
[2019-04-06 14:55:28,390] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15650: learning rate 0.0000
[2019-04-06 14:55:29,012] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1000, global step 15719: loss 29.0814
[2019-04-06 14:55:29,012] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 1000, global step 15719: learning rate 0.0000
[2019-04-06 14:55:29,842] A3C_AGENT_WORKER-Thread-7 INFO:Local step 1000, global step 15779: loss 20.6200
[2019-04-06 14:55:29,843] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 1000, global step 15779: learning rate 0.0000
[2019-04-06 14:55:30,890] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15856: loss 31.9307
[2019-04-06 14:55:30,897] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15856: learning rate 0.0000
[2019-04-06 14:55:32,365] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15980: loss 33.1344
[2019-04-06 14:55:32,365] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15980: learning rate 0.0000
[2019-04-06 14:55:33,033] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16037: loss 39.7213
[2019-04-06 14:55:33,033] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16037: learning rate 0.0000
[2019-04-06 14:55:33,937] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16100: loss 31.6929
[2019-04-06 14:55:33,937] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16100: learning rate 0.0000
[2019-04-06 14:55:34,306] A3C_AGENT_WORKER-Thread-8 INFO:Local step 1000, global step 16126: loss 30.7847
[2019-04-06 14:55:34,307] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 1000, global step 16126: learning rate 0.0000
[2019-04-06 14:55:36,802] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16306: loss 24.6219
[2019-04-06 14:55:36,803] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16306: learning rate 0.0000
[2019-04-06 14:55:36,971] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1000, global step 16317: loss 37.9735
[2019-04-06 14:55:36,972] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 1000, global step 16317: learning rate 0.0000
[2019-04-06 14:55:37,253] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16340: loss 34.4926
[2019-04-06 14:55:37,261] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16340: learning rate 0.0000
[2019-04-06 14:55:37,373] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16353: loss 40.6187
[2019-04-06 14:55:37,374] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16353: learning rate 0.0000
[2019-04-06 14:55:38,418] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1000, global step 16449: loss 33.3473
[2019-04-06 14:55:38,419] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 1000, global step 16449: learning rate 0.0000
[2019-04-06 14:55:44,303] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16833: loss 24.8459
[2019-04-06 14:55:44,304] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16833: learning rate 0.0000
[2019-04-06 14:56:06,453] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.09227352 0.09290241 0.17666838 0.15892985 0.30004904 0.06858417
 0.1105926 ], sum to 1.0000
[2019-04-06 14:56:06,454] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2430
[2019-04-06 14:56:06,713] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.05, 79.0, 147.0, 0.0, 26.0, 25.28704099488247, 0.2275522798424577, 1.0, 1.0, 18720.16634255232], 
current ob forecast is [], 
actual action is [25.5], 
sim time this is 2028600.0000, 
sim time next is 2030400.0000, 
raw observation next is [-4.5, 75.0, 151.5, 0.0, 25.5, 25.32004648760809, 0.2268996829967463, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.3379501385041552, 0.75, 0.505, 0.0, 0.625, 0.6100038739673407, 0.5756332276655821, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.33573735], dtype=float32), 0.14331883]. 
=============================================
[2019-04-06 14:56:23,595] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 14:56:23,595] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 14:56:23,595] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:56:23,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run2
[2019-04-06 14:56:23,628] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 14:56:23,628] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:56:23,630] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run2
[2019-04-06 14:56:23,651] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 14:56:23,651] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 14:56:23,654] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run2
[2019-04-06 14:56:48,892] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00488051], dtype=float32), 0.015795633]
[2019-04-06 14:56:48,893] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-6.2, 75.0, 61.0, 0.0, 23.0, 24.32997432322122, -0.09651105128944502, 1.0, 1.0, 0.0]
[2019-04-06 14:56:48,893] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 14:56:48,894] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [0.11670125 0.12260676 0.19768006 0.1208434  0.25223964 0.07300625
 0.11692255], sampled 0.17178619328281142
[2019-04-06 14:57:56,518] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2593.3529 68004411.8905 208.0742
[2019-04-06 14:58:08,456] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2581.6293 73843543.7790 38.9371
[2019-04-06 14:58:10,213] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2550.8900 78039128.1410 -67.2676
[2019-04-06 14:58:11,234] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 20000, evaluation results [20000.0, 2581.629250309045, 73843543.7790012, 38.937070443972615, 2593.3528667869073, 68004411.89050218, 208.07419328517366, 2550.889968166153, 78039128.14102402, -67.26760131152587]
[2019-04-06 14:58:13,252] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.08072502 0.08143083 0.15552416 0.10057452 0.42754707 0.06574395
 0.08845446], sum to 1.0000
[2019-04-06 14:58:13,252] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9742
[2019-04-06 14:58:13,785] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [-5.0, 69.5, 0.0, 0.0, 24.5, 24.14027360597241, 0.1328367421814438, 0.0, 1.0, 33082.99265513247], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2233800.0000, 
sim time next is 2235600.0000, 
raw observation next is [-5.0, 68.0, 0.0, 0.0, 26.0, 24.05654996599347, 0.1889863736789676, 0.0, 1.0, 136185.7071164919], 
processed observation next is [1.0, 0.9130434782608695, 0.32409972299168976, 0.68, 0.0, 0.0, 0.6666666666666666, 0.5047124971661224, 0.5629954578929892, 0.0, 1.0, 0.6485033672213899], 
reward next is 0.3515, 
noisyNet noise sample is [array([1.2135935], dtype=float32), -1.0800498]. 
=============================================
[2019-04-06 14:58:22,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.09908552 0.10420711 0.12325103 0.10242271 0.3947968  0.07534433
 0.10089253], sum to 1.0000
[2019-04-06 14:58:22,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9965
[2019-04-06 14:58:22,306] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [-8.1, 86.5, 0.0, 0.0, 26.0, 23.5264122751122, -0.08357548055738534, 0.0, 1.0, 44359.16754640864], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2259000.0000, 
sim time next is 2260800.0000, 
raw observation next is [-8.4, 87.0, 0.0, 0.0, 26.0, 23.41987135946728, -0.1039141246167628, 0.0, 1.0, 44263.64657079792], 
processed observation next is [1.0, 0.17391304347826086, 0.2299168975069252, 0.87, 0.0, 0.0, 0.6666666666666666, 0.4516559466222733, 0.4653619584610791, 0.0, 1.0, 0.210779269384752], 
reward next is 0.7892, 
noisyNet noise sample is [array([-1.1597446], dtype=float32), -0.3390428]. 
=============================================
[2019-04-06 14:58:44,652] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 22898: loss 35.6490
[2019-04-06 14:58:44,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 22898: learning rate 0.0000
[2019-04-06 14:58:47,728] A3C_AGENT_WORKER-Thread-7 INFO:Local step 1500, global step 23138: loss 32.4520
[2019-04-06 14:58:47,736] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 1500, global step 23138: learning rate 0.0000
[2019-04-06 14:58:49,216] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0910131  0.09100962 0.12738416 0.08993582 0.40464514 0.08014025
 0.11587184], sum to 1.0000
[2019-04-06 14:58:49,217] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4542
[2019-04-06 14:58:49,295] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1500, global step 23300: loss 31.5433
[2019-04-06 14:58:49,296] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 1500, global step 23300: learning rate 0.0000
[2019-04-06 14:58:49,334] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.0, 70.5, 0.0, 0.0, 23.5, 23.32688133945017, -0.1014498608796874, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2680200.0000, 
sim time next is 2682000.0000, 
raw observation next is [-9.0, 69.0, 0.0, 0.0, 24.0, 23.08753148691391, -0.06803518361145386, 0.0, 1.0, 157829.2505007833], 
processed observation next is [1.0, 0.043478260869565216, 0.21329639889196678, 0.69, 0.0, 0.0, 0.5, 0.42396095724282584, 0.4773216054628487, 0.0, 1.0, 0.7515678595275395], 
reward next is 0.5341, 
noisyNet noise sample is [array([1.3191173], dtype=float32), 0.48388684]. 
=============================================
[2019-04-06 14:58:49,337] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[2.6921892]
 [2.8697836]
 [2.8469007]
 [2.8601887]
 [2.930906 ]], R is [[3.21651173]
 [4.18434668]
 [5.14250326]
 [6.09107828]
 [7.03016758]].
[2019-04-06 14:58:50,524] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23416: loss 26.2404
[2019-04-06 14:58:50,525] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23416: learning rate 0.0000
[2019-04-06 14:58:53,262] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.09206443 0.09693466 0.16964579 0.10739819 0.36599332 0.06568817
 0.10227539], sum to 1.0000
[2019-04-06 14:58:53,262] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1707
[2019-04-06 14:58:53,530] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-4.0, 54.0, 94.0, 673.5, 23.5, 23.95857619681575, -0.0188785408593978, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [22.5], 
sim time this is 2732400.0000, 
sim time next is 2734200.0000, 
raw observation next is [-3.5, 52.0, 86.0, 614.0, 22.5, 24.07661101738335, -0.08784054404280406, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.36565096952908593, 0.52, 0.2866666666666667, 0.6784530386740332, 0.375, 0.5063842514486124, 0.47071981865239865, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.20470537], dtype=float32), 1.4545047]. 
=============================================
[2019-04-06 14:58:53,600] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23668: loss 33.3337
[2019-04-06 14:58:53,601] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23668: learning rate 0.0000
[2019-04-06 14:58:53,727] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23682: loss 25.2348
[2019-04-06 14:58:53,727] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23682: learning rate 0.0000
[2019-04-06 14:58:54,739] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23801: loss 39.3000
[2019-04-06 14:58:54,771] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23801: learning rate 0.0000
[2019-04-06 14:58:55,197] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23855: loss 27.3221
[2019-04-06 14:58:55,198] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23855: learning rate 0.0000
[2019-04-06 14:58:55,410] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23876: loss 41.3784
[2019-04-06 14:58:55,410] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23876: learning rate 0.0000
[2019-04-06 14:58:56,480] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23988: loss 17.7987
[2019-04-06 14:58:56,481] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23988: learning rate 0.0000
[2019-04-06 14:58:58,788] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1500, global step 24178: loss 38.8176
[2019-04-06 14:58:58,788] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 1500, global step 24178: learning rate 0.0000
[2019-04-06 14:58:59,061] A3C_AGENT_WORKER-Thread-8 INFO:Local step 1500, global step 24204: loss 28.6807
[2019-04-06 14:58:59,061] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 1500, global step 24204: learning rate 0.0000
[2019-04-06 14:58:59,798] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24262: loss 26.8612
[2019-04-06 14:58:59,798] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24262: learning rate 0.0000
[2019-04-06 14:59:00,258] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24294: loss 36.9325
[2019-04-06 14:59:00,259] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 24294: learning rate 0.0000
[2019-04-06 14:59:05,815] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1500, global step 24766: loss 37.1741
[2019-04-06 14:59:05,815] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 1500, global step 24766: learning rate 0.0000
[2019-04-06 14:59:08,187] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24955: loss 23.7687
[2019-04-06 14:59:08,187] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24955: learning rate 0.0000
[2019-04-06 14:59:22,738] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.07913546 0.09497064 0.17350389 0.10303142 0.3915117  0.06041773
 0.09742919], sum to 1.0000
[2019-04-06 14:59:22,738] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5934
[2019-04-06 14:59:23,224] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 25.5, 24.92276338433056, 0.2084160113799908, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3002400.0000, 
sim time next is 3004200.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 26.0, 24.79312795122712, 0.2916247724663339, 0.0, 1.0, 158811.22597515333], 
processed observation next is [0.0, 0.782608695652174, 0.40720221606648205, 0.6, 0.0, 0.0, 0.6666666666666666, 0.5660939959355934, 0.5972082574887779, 0.0, 1.0, 0.7562439332150158], 
reward next is 0.2438, 
noisyNet noise sample is [array([1.0329818], dtype=float32), 0.7723383]. 
=============================================
[2019-04-06 14:59:24,695] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.10099564 0.08078621 0.15365498 0.09683245 0.43613926 0.05633054
 0.07526097], sum to 1.0000
[2019-04-06 14:59:24,696] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1859
[2019-04-06 14:59:25,197] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.0, 65.0, 256.0, 284.0, 24.0, 23.20500005319812, -0.03638432057114026, 0.0, 1.0, 8772.245994578812], 
current ob forecast is [], 
actual action is [23.5], 
sim time this is 2979000.0000, 
sim time next is 2980800.0000, 
raw observation next is [-3.0, 65.0, 218.5, 487.5, 23.5, 23.1552912595998, -0.04481793336035866, 0.0, 1.0, 12468.886833689983], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.65, 0.7283333333333334, 0.5386740331491713, 0.4583333333333333, 0.42960760496664996, 0.48506068887988046, 0.0, 1.0, 0.05937565158899992], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6616468], dtype=float32), -1.3416206]. 
=============================================
[2019-04-06 14:59:26,175] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.07831781 0.05627388 0.16661252 0.11112364 0.45668325 0.06617316
 0.0648158 ], sum to 1.0000
[2019-04-06 14:59:26,175] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9916
[2019-04-06 14:59:26,273] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 26.0, 24.00607847315099, 0.1076754146887662, 0.0, 1.0, 44182.17952543958], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2937600.0000, 
sim time next is 2939400.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 26.0, 23.90143360521744, 0.09284600447811353, 0.0, 1.0, 44121.69383167612], 
processed observation next is [0.0, 0.0, 0.40720221606648205, 0.85, 0.0, 0.0, 0.6666666666666666, 0.49178613376812014, 0.5309486681593713, 0.0, 1.0, 0.21010330396036248], 
reward next is 0.7899, 
noisyNet noise sample is [array([1.2256457], dtype=float32), -0.032288875]. 
=============================================
[2019-04-06 14:59:33,988] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.11114402 0.09729466 0.14707962 0.11431792 0.36203742 0.0687867
 0.09933968], sum to 1.0000
[2019-04-06 14:59:33,988] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6079
[2019-04-06 14:59:34,053] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 22.5, 22.61755875423533, -0.3110228029123856, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [23.0], 
sim time this is 3049200.0000, 
sim time next is 3051000.0000, 
raw observation next is [-6.0, 70.5, 0.0, 0.0, 23.0, 22.32443709981203, -0.32952981722526, 0.0, 1.0, 90906.0975219374], 
processed observation next is [0.0, 0.30434782608695654, 0.296398891966759, 0.705, 0.0, 0.0, 0.4166666666666667, 0.3603697583176692, 0.39015672759158004, 0.0, 1.0, 0.43288617867589235], 
reward next is 0.9957, 
noisyNet noise sample is [array([0.62440455], dtype=float32), -0.10072915]. 
=============================================
[2019-04-06 14:59:34,117] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[2.5917883]
 [2.6247656]
 [2.6570485]
 [2.6933095]
 [2.6807468]], R is [[3.58435059]
 [4.54850721]
 [5.50302219]
 [6.44799185]
 [7.18838787]].
[2019-04-06 14:59:38,293] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.08820907 0.08541759 0.15035173 0.0827096  0.42971265 0.05850659
 0.10509279], sum to 1.0000
[2019-04-06 14:59:38,293] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3025
[2019-04-06 14:59:38,351] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 23.5, 22.8289539358937, -0.1447922245140998, 0.0, 1.0, 122303.58068714027], 
current ob forecast is [], 
actual action is [23.0], 
sim time this is 3029400.0000, 
sim time next is 3031200.0000, 
raw observation next is [-5.0, 71.0, 0.0, 0.0, 23.0, 23.05571846020228, -0.1483954260335229, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.32409972299168976, 0.71, 0.0, 0.0, 0.4166666666666667, 0.42130987168352324, 0.4505348579888257, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.36526418], dtype=float32), 0.19351713]. 
=============================================
[2019-04-06 14:59:49,819] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.04042644 0.06069804 0.18151143 0.07908911 0.52776325 0.02700091
 0.08351083], sum to 1.0000
[2019-04-06 14:59:49,819] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7726
[2019-04-06 14:59:50,080] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.5, 54.0, 118.0, 811.0, 25.5, 26.0342267316583, 0.5180832955951015, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3328200.0000, 
sim time next is 3330000.0000, 
raw observation next is [-5.0, 54.0, 116.0, 805.5, 26.0, 24.42558352727269, 0.4585985748092947, 1.0, 1.0, 125405.9093999963], 
processed observation next is [1.0, 0.5652173913043478, 0.32409972299168976, 0.54, 0.38666666666666666, 0.8900552486187845, 0.6666666666666666, 0.5354652939393908, 0.6528661916030982, 1.0, 1.0, 0.5971709971428395], 
reward next is 0.4028, 
noisyNet noise sample is [array([0.2806721], dtype=float32), 0.97010916]. 
=============================================
[2019-04-06 14:59:50,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[4.332619 ]
 [4.3131375]
 [4.29806  ]
 [4.276859 ]
 [4.253375 ]], R is [[4.75004053]
 [5.7025404 ]
 [6.64551497]
 [7.57906008]
 [8.5032692 ]].
[2019-04-06 14:59:50,091] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.06974335 0.04881316 0.13046503 0.06525314 0.57365566 0.05269243
 0.05937729], sum to 1.0000
[2019-04-06 14:59:50,091] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1015
[2019-04-06 14:59:50,161] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [2.0, 96.5, 0.0, 0.0, 26.0, 25.45811431791669, 0.552672317378402, 0.0, 1.0, 85703.0872779949], 
current ob forecast is [], 
actual action is [25.0], 
sim time this is 3191400.0000, 
sim time next is 3193200.0000, 
raw observation next is [2.0, 93.0, 0.0, 0.0, 25.0, 25.33955486807807, 0.5232227066267098, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.518005540166205, 0.93, 0.0, 0.0, 0.5833333333333334, 0.6116295723398393, 0.6744075688755699, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.49731278], dtype=float32), -0.17491452]. 
=============================================
[2019-04-06 15:00:07,449] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31046: loss 42.6893
[2019-04-06 15:00:07,451] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31046: learning rate 0.0000
[2019-04-06 15:00:07,670] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31076: loss 35.4421
[2019-04-06 15:00:07,671] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31076: learning rate 0.0000
[2019-04-06 15:00:08,058] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31122: loss 24.2355
[2019-04-06 15:00:08,059] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31122: learning rate 0.0000
[2019-04-06 15:00:08,916] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2000, global step 31215: loss 32.3513
[2019-04-06 15:00:08,916] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 2000, global step 31215: learning rate 0.0000
[2019-04-06 15:00:10,413] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2000, global step 31381: loss 28.9213
[2019-04-06 15:00:10,413] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 2000, global step 31381: learning rate 0.0000
[2019-04-06 15:00:11,197] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31465: loss 29.4558
[2019-04-06 15:00:11,197] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31465: learning rate 0.0000
[2019-04-06 15:00:13,041] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31690: loss 34.9680
[2019-04-06 15:00:13,043] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31690: learning rate 0.0000
[2019-04-06 15:00:13,372] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31734: loss 30.7650
[2019-04-06 15:00:13,396] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31734: learning rate 0.0000
[2019-04-06 15:00:15,909] A3C_AGENT_WORKER-Thread-8 INFO:Local step 2000, global step 32046: loss 36.7814
[2019-04-06 15:00:15,910] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 2000, global step 32046: learning rate 0.0000
[2019-04-06 15:00:18,140] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32312: loss 46.9324
[2019-04-06 15:00:18,188] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32312: learning rate 0.0000
[2019-04-06 15:00:19,989] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2000, global step 32534: loss 37.1594
[2019-04-06 15:00:20,011] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 2000, global step 32534: learning rate 0.0000
[2019-04-06 15:00:21,369] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 32756: loss 34.3025
[2019-04-06 15:00:21,369] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 32756: learning rate 0.0000
[2019-04-06 15:00:21,547] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32788: loss 31.0663
[2019-04-06 15:00:21,576] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32792: loss 22.9625
[2019-04-06 15:00:21,576] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32792: learning rate 0.0000
[2019-04-06 15:00:21,601] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32788: learning rate 0.0000
[2019-04-06 15:00:26,076] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.05876311 0.03657312 0.11761797 0.05407275 0.634175   0.03414696
 0.06465104], sum to 1.0000
[2019-04-06 15:00:26,076] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9232
[2019-04-06 15:00:26,112] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 59.0, 15.0, 165.0, 21.5, 25.22894631743305, 0.3598216373839938, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [22.5], 
sim time this is 3691800.0000, 
sim time next is 3693600.0000, 
raw observation next is [4.0, 59.0, 0.0, 0.0, 22.5, 25.07171044362354, 0.3091741051961149, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.5734072022160666, 0.59, 0.0, 0.0, 0.375, 0.589309203635295, 0.6030580350653717, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.961051], dtype=float32), 1.1707934]. 
=============================================
[2019-04-06 15:00:26,307] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 33494: loss 32.5351
[2019-04-06 15:00:26,375] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 33498: learning rate 0.0000
[2019-04-06 15:00:27,973] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2000, global step 33727: loss 33.0835
[2019-04-06 15:00:27,977] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 2000, global step 33727: learning rate 0.0000
[2019-04-06 15:00:43,576] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [0.04879346 0.07291902 0.13156506 0.07104848 0.5480395  0.04856065
 0.0790738 ], sum to 1.0000
[2019-04-06 15:00:43,576] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2133
[2019-04-06 15:00:44,051] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-13.0, 69.0, 0.0, 0.0, 25.0, 23.37597500051379, -0.05874236446371058, 0.0, 1.0, 44503.17855734323], 
current ob forecast is [], 
actual action is [24.5], 
sim time this is 3992400.0000, 
sim time next is 3994200.0000, 
raw observation next is [-13.0, 66.0, 0.0, 0.0, 24.5, 23.26066507368741, -0.0901647065308384, 0.0, 1.0, 44410.84990519031], 
processed observation next is [1.0, 0.21739130434782608, 0.10249307479224376, 0.66, 0.0, 0.0, 0.5416666666666666, 0.43838875614061745, 0.4699450978230539, 0.0, 1.0, 0.2114802376437634], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.13856703], dtype=float32), 0.55695826]. 
=============================================
[2019-04-06 15:01:07,051] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.05401315 0.05829149 0.11327479 0.05262725 0.65823317 0.02198805
 0.04157209], sum to 1.0000
[2019-04-06 15:01:07,051] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1231
[2019-04-06 15:01:07,079] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.2, 42.5, 0.0, 0.0, 24.0, 24.41972165367897, 0.1472807077266684, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [23.5], 
sim time this is 4217400.0000, 
sim time next is 4219200.0000, 
raw observation next is [1.0, 43.0, 0.0, 0.0, 23.5, 24.21778637432823, 0.0996215363764511, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.4903047091412743, 0.43, 0.0, 0.0, 0.4583333333333333, 0.5181488645273525, 0.5332071787921504, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0998043], dtype=float32), 0.67254734]. 
=============================================
[2019-04-06 15:01:07,471] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 38421: loss 24.7696
[2019-04-06 15:01:07,472] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 38421: learning rate 0.0000
[2019-04-06 15:01:08,790] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 38650: loss 24.7762
[2019-04-06 15:01:08,794] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 38650: learning rate 0.0000
[2019-04-06 15:01:11,349] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [0.05020558 0.04816531 0.13351394 0.07130019 0.5917517  0.03296425
 0.07209904], sum to 1.0000
[2019-04-06 15:01:11,349] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5723
[2019-04-06 15:01:11,910] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39043: loss 18.1179
[2019-04-06 15:01:11,911] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39043: learning rate 0.0000
[2019-04-06 15:01:12,168] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 35.0, 111.0, 717.0, 26.0, 25.48322149445418, 0.4175544323672493, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4183200.0000, 
sim time next is 4185000.0000, 
raw observation next is [-1.5, 35.0, 114.0, 774.0, 26.0, 25.38847238440488, 0.4139380912510131, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.4210526315789474, 0.35, 0.38, 0.8552486187845304, 0.6666666666666666, 0.6157060320337401, 0.6379793637503377, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.44580752], dtype=float32), 0.37819722]. 
=============================================
[2019-04-06 15:01:12,265] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[4.7562046]
 [4.6372113]
 [4.457725 ]
 [4.4110436]
 [4.3779407]], R is [[5.86715794]
 [6.80848646]
 [7.74040174]
 [8.6629982 ]
 [9.09875107]].
[2019-04-06 15:01:13,339] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2500, global step 39199: loss 7.0389
[2019-04-06 15:01:13,398] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 2500, global step 39199: learning rate 0.0000
[2019-04-06 15:01:13,951] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39284: loss 24.9399
[2019-04-06 15:01:13,954] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39284: learning rate 0.0000
[2019-04-06 15:01:14,997] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39429: loss 12.7920
[2019-04-06 15:01:14,997] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39429: learning rate 0.0000
[2019-04-06 15:01:15,390] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2500, global step 39485: loss 11.8885
[2019-04-06 15:01:15,391] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 2500, global step 39485: learning rate 0.0000
[2019-04-06 15:01:17,031] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39723: loss 15.7304
[2019-04-06 15:01:17,091] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39726: learning rate 0.0000
[2019-04-06 15:01:18,780] A3C_AGENT_WORKER-Thread-8 INFO:Evaluating...
[2019-04-06 15:01:18,781] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:01:18,782] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:01:18,783] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run3
[2019-04-06 15:01:18,874] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:01:18,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:01:18,887] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run3
[2019-04-06 15:01:18,909] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:01:18,909] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:01:18,911] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run3
[2019-04-06 15:01:44,996] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.0050724], dtype=float32), 0.03516708]
[2019-04-06 15:01:44,996] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-4.5, 68.0, 0.0, 0.0, 23.0, 22.7115751153001, -0.2333286739809353, 0.0, 1.0, 0.0]
[2019-04-06 15:01:44,996] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:01:44,997] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [0.05215966 0.06017414 0.12934282 0.06321392 0.59532166 0.03309073
 0.06669702], sampled 0.8544791247702515
[2019-04-06 15:03:00,841] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2520.5161 76771529.9211 475.1722
[2019-04-06 15:03:21,977] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2478.0777 85573433.9622 451.2788
[2019-04-06 15:03:26,357] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2480.7064 88427906.5572 314.0390
[2019-04-06 15:03:27,395] A3C_AGENT_WORKER-Thread-8 INFO:Global step: 40000, evaluation results [40000.0, 2478.0776505017047, 85573433.96218188, 451.27883934258165, 2520.5161377512245, 76771529.92108417, 475.17221415355414, 2480.7064083410455, 88427906.55715165, 314.03902506682624]
[2019-04-06 15:03:27,929] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40084: loss 33.8667
[2019-04-06 15:03:27,944] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40084: learning rate 0.0000
[2019-04-06 15:03:28,586] A3C_AGENT_WORKER-Thread-8 INFO:Local step 2500, global step 40154: loss 17.3214
[2019-04-06 15:03:28,588] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 2500, global step 40154: learning rate 0.0000
[2019-04-06 15:03:30,657] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40407: loss 7.2271
[2019-04-06 15:03:30,657] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40407: learning rate 0.0000
[2019-04-06 15:03:31,745] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40538: loss 9.3546
[2019-04-06 15:03:31,749] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40538: learning rate 0.0000
[2019-04-06 15:03:32,549] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.01558811 0.02192191 0.10579704 0.03054051 0.7689196  0.01195668
 0.04527615], sum to 1.0000
[2019-04-06 15:03:32,549] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2804
[2019-04-06 15:03:32,643] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40659: loss 16.6137
[2019-04-06 15:03:32,644] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40659: learning rate 0.0000
[2019-04-06 15:03:32,662] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.01828895 0.03004625 0.10276616 0.03088202 0.7585758  0.01932951
 0.04011127], sum to 1.0000
[2019-04-06 15:03:32,663] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6536
[2019-04-06 15:03:32,737] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 71.0, 0.0, 0.0, 25.0, 24.73009720014733, 0.2627921170157715, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.5], 
sim time this is 4516200.0000, 
sim time next is 4518000.0000, 
raw observation next is [-1.0, 71.0, 0.0, 0.0, 25.5, 24.66298992767717, 0.2881799321932879, 0.0, 1.0, 112192.58720418043], 
processed observation next is [1.0, 0.30434782608695654, 0.4349030470914128, 0.71, 0.0, 0.0, 0.625, 0.5552491606397641, 0.5960599773977626, 0.0, 1.0, 0.534250415258002], 
reward next is 0.5372, 
noisyNet noise sample is [array([0.9714009], dtype=float32), 1.0937523]. 
=============================================
[2019-04-06 15:03:32,741] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[6.6417346]
 [6.686089 ]
 [6.7053514]
 [6.7427807]
 [6.7381096]], R is [[ 7.18591499]
 [ 8.11405563]
 [ 9.02262115]
 [ 9.93239498]
 [10.63515568]].
[2019-04-06 15:03:32,769] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 25.28110039135848, 0.4668310108994125, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4478400.0000, 
sim time next is 4480200.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 25.12027182122321, 0.4747635743958279, 0.0, 1.0, 128358.25403667787], 
processed observation next is [1.0, 0.8695652173913043, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.5933559851019341, 0.6582545247986092, 0.0, 1.0, 0.6112297811270375], 
reward next is 0.3888, 
noisyNet noise sample is [array([-0.7752752], dtype=float32), 1.5318437]. 
=============================================
[2019-04-06 15:03:34,082] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2500, global step 40837: loss 14.7874
[2019-04-06 15:03:34,083] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 2500, global step 40837: learning rate 0.0000
[2019-04-06 15:03:41,468] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2500, global step 41654: loss 7.3799
[2019-04-06 15:03:41,468] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 2500, global step 41654: learning rate 0.0000
[2019-04-06 15:03:41,634] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 41675: loss 17.4950
[2019-04-06 15:03:41,668] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 41675: learning rate 0.0000
[2019-04-06 15:03:59,666] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.02071491 0.02336795 0.11259492 0.02326144 0.7725913  0.01265792
 0.03481153], sum to 1.0000
[2019-04-06 15:03:59,666] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8695
[2019-04-06 15:04:00,209] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 46.0, 0.0, 0.0, 24.5, 24.95182970994263, 0.1916963202137308, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.0], 
sim time this is 4942800.0000, 
sim time next is 4944600.0000, 
raw observation next is [-2.5, 48.0, 0.0, 0.0, 25.0, 24.67459339618774, 0.1151137122712432, 0.0, 1.0, 3120.9490919740115], 
processed observation next is [1.0, 0.21739130434782608, 0.39335180055401664, 0.48, 0.0, 0.0, 0.5833333333333334, 0.5562161163489782, 0.5383712374237477, 0.0, 1.0, 0.014861662342733388], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.35194838], dtype=float32), -0.5745835]. 
=============================================
[2019-04-06 15:04:00,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:00,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:00,682] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run2
[2019-04-06 15:04:03,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:03,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:03,251] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run2
[2019-04-06 15:04:06,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:06,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:06,050] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run2
[2019-04-06 15:04:09,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:09,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:09,195] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run2
[2019-04-06 15:04:09,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:09,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:09,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run2
[2019-04-06 15:04:11,322] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:11,322] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:11,324] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run2
[2019-04-06 15:04:11,998] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:11,998] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:12,000] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run2
[2019-04-06 15:04:13,326] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:13,326] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:13,328] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run2
[2019-04-06 15:04:15,502] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:15,502] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:15,504] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run2
[2019-04-06 15:04:16,879] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:16,879] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:16,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run2
[2019-04-06 15:04:18,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:18,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:18,451] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run2
[2019-04-06 15:04:19,743] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:19,743] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:19,745] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run2
[2019-04-06 15:04:20,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:20,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:20,310] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run2
[2019-04-06 15:04:20,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:20,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:20,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run2
[2019-04-06 15:04:29,046] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:29,046] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:29,048] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run2
[2019-04-06 15:04:29,744] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:04:29,745] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:04:29,746] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run2
[2019-04-06 15:05:16,434] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.00834264 0.01443899 0.07771972 0.02575907 0.82919234 0.00382701
 0.04072034], sum to 1.0000
[2019-04-06 15:05:16,434] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0924
[2019-04-06 15:05:16,746] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-10.05, 45.5, 24.0, 240.0, 26.0, 25.87553361466328, 0.2724310501898655, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.5], 
sim time this is 318600.0000, 
sim time next is 320400.0000, 
raw observation next is [-10.6, 49.0, 12.0, 123.0, 25.5, 25.28253800761423, 0.2969744893281809, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.1689750692520776, 0.49, 0.04, 0.13591160220994475, 0.625, 0.6068781673011859, 0.598991496442727, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.58975035], dtype=float32), -0.16349915]. 
=============================================
[2019-04-06 15:06:30,008] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.9054158e-04 1.4431288e-03 1.3559539e-02 3.1223439e-03 9.7927082e-01
 3.1079812e-04 1.5028900e-03], sum to 1.0000
[2019-04-06 15:06:30,008] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6010
[2019-04-06 15:06:30,325] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.95, 79.5, 0.0, 0.0, 25.0, 25.27075198649581, 0.4686971206661036, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.5], 
sim time this is 1013400.0000, 
sim time next is 1015200.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 25.5, 25.43966517530209, 0.4989934966443748, 1.0, 1.0, 65416.225924754835], 
processed observation next is [1.0, 0.782608695652174, 0.8614958448753465, 0.81, 0.0, 0.0, 0.625, 0.6199720979418407, 0.6663311655481249, 1.0, 1.0, 0.3115058377369278], 
reward next is 0.7599, 
noisyNet noise sample is [array([2.3468769], dtype=float32), 0.9388321]. 
=============================================
[2019-04-06 15:06:37,005] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7843530e-04 9.2961610e-04 6.7496924e-03 1.8853445e-03 9.8772043e-01
 2.3387557e-04 2.1026151e-03], sum to 1.0000
[2019-04-06 15:06:37,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5715
[2019-04-06 15:06:37,176] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.4, 93.0, 36.0, 0.0, 26.0, 25.83382158898032, 0.3020504238283264, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 921600.0000, 
sim time next is 923400.0000, 
raw observation next is [4.7, 92.5, 18.0, 0.0, 26.0, 25.04860847241265, 0.3638515974726895, 1.0, 1.0, 65661.2059460283], 
processed observation next is [1.0, 0.6956521739130435, 0.592797783933518, 0.925, 0.06, 0.0, 0.6666666666666666, 0.5873840393677208, 0.6212838658242298, 1.0, 1.0, 0.31267240926680145], 
reward next is 0.6873, 
noisyNet noise sample is [array([-1.6071166], dtype=float32), -1.1244912]. 
=============================================
[2019-04-06 15:06:56,369] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.0049801  0.00583366 0.03070493 0.00530337 0.9455519  0.00161475
 0.00601138], sum to 1.0000
[2019-04-06 15:06:56,370] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1265
[2019-04-06 15:06:56,389] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.3, 65.0, 128.0, 0.0, 26.0, 25.45408036179061, 0.573310953991344, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1175400.0000, 
sim time next is 1177200.0000, 
raw observation next is [18.3, 65.0, 104.0, 0.0, 26.0, 25.44296978203885, 0.5739870238586026, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.9695290858725764, 0.65, 0.3466666666666667, 0.0, 0.6666666666666666, 0.620247481836571, 0.6913290079528674, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06014907], dtype=float32), 1.4977539]. 
=============================================
[2019-04-06 15:06:58,236] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.00620307 0.00931932 0.03509899 0.0064091  0.93212885 0.00302029
 0.00782034], sum to 1.0000
[2019-04-06 15:06:58,237] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2242
[2019-04-06 15:06:58,440] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 26.0, 23.60440371897334, 0.1757791290017398, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1229400.0000, 
sim time next is 1231200.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 26.0, 23.57883332660898, 0.1631902436498633, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.8781163434903049, 0.96, 0.0, 0.0, 0.6666666666666666, 0.46490277721741496, 0.5543967478832877, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03240802], dtype=float32), 0.3565964]. 
=============================================
[2019-04-06 15:06:59,290] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9666734e-03 1.1684197e-03 2.9873010e-02 1.6755454e-03 9.6391606e-01
 1.2190479e-04 1.2782977e-03], sum to 1.0000
[2019-04-06 15:06:59,290] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8292
[2019-04-06 15:06:59,331] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [9.7, 60.5, 0.0, 0.0, 26.0, 26.30735304418275, 0.669204450961813, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1535400.0000, 
sim time next is 1537200.0000, 
raw observation next is [9.4, 61.0, 0.0, 0.0, 26.0, 26.06942360957869, 0.6387180465244002, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.7229916897506927, 0.61, 0.0, 0.0, 0.6666666666666666, 0.6724519674648907, 0.7129060155081334, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.04352223], dtype=float32), 0.1517611]. 
=============================================
[2019-04-06 15:07:02,294] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.8478539e-04 1.3947533e-03 1.4827595e-02 2.7560915e-03 9.7873849e-01
 3.2849493e-04 1.4699141e-03], sum to 1.0000
[2019-04-06 15:07:02,295] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0237
[2019-04-06 15:07:02,540] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 26.0, 25.29930918089856, 0.4820049857373364, 0.0, 1.0, 57036.87301038522], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1387800.0000, 
sim time next is 1389600.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 26.0, 25.23631387521545, 0.4681133222674985, 0.0, 1.0, 40513.49485023846], 
processed observation next is [1.0, 0.08695652173913043, 0.46260387811634357, 0.95, 0.0, 0.0, 0.6666666666666666, 0.6030261562679543, 0.6560377740891662, 0.0, 1.0, 0.19292140404875457], 
reward next is 0.8071, 
noisyNet noise sample is [array([-1.0696713], dtype=float32), -1.4082164]. 
=============================================
[2019-04-06 15:07:10,358] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6901067e-04 9.4826746e-04 4.5632166e-03 7.4679859e-04 9.9218726e-01
 2.8380359e-04 9.0160384e-04], sum to 1.0000
[2019-04-06 15:07:10,358] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9385
[2019-04-06 15:07:10,389] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.5, 97.0, 0.0, 0.0, 26.0, 25.47869807181286, 0.5500050657016139, 0.0, 1.0, 63986.62061460706], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1663200.0000, 
sim time next is 1665000.0000, 
raw observation next is [5.25, 94.5, 0.0, 0.0, 26.0, 25.65407537738076, 0.5461839934464697, 0.0, 1.0, 6249.01991404017], 
processed observation next is [1.0, 0.2608695652173913, 0.60803324099723, 0.945, 0.0, 0.0, 0.6666666666666666, 0.63783961478173, 0.6820613311488232, 0.0, 1.0, 0.02975723768590557], 
reward next is 0.9702, 
noisyNet noise sample is [array([0.4107833], dtype=float32), 0.576253]. 
=============================================
[2019-04-06 15:07:10,393] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[15.2735405]
 [15.184347 ]
 [15.130463 ]
 [15.089829 ]
 [15.069812 ]], R is [[16.12450981]
 [16.65856552]
 [17.38840103]
 [17.96563911]
 [18.78598213]].
[2019-04-06 15:07:11,272] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.5251124e-04 6.9853396e-04 1.5460895e-02 3.6704884e-04 9.8223156e-01
 6.3116437e-05 8.2634483e-04], sum to 1.0000
[2019-04-06 15:07:11,272] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0518
[2019-04-06 15:07:11,421] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 81.0, 0.0, 26.0, 26.04687851944086, 0.5684857180893254, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1432800.0000, 
sim time next is 1434600.0000, 
raw observation next is [1.1, 92.0, 72.0, 0.0, 26.0, 26.29761793733328, 0.5924220044653855, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.92, 0.24, 0.0, 0.6666666666666666, 0.6914681614444399, 0.6974740014884618, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1310409], dtype=float32), -0.43543404]. 
=============================================
[2019-04-06 15:07:14,908] A3C_AGENT_WORKER-Thread-8 INFO:Evaluating...
[2019-04-06 15:07:14,909] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:07:14,913] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:07:14,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:07:14,914] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:07:14,914] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:07:14,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:07:14,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run4
[2019-04-06 15:07:14,936] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run4
[2019-04-06 15:07:14,959] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run4
[2019-04-06 15:08:12,976] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00546413], dtype=float32), 0.054480612]
[2019-04-06 15:08:12,976] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [0.0, 47.0, 227.5, 238.0, 26.0, 25.00811694496778, 0.32237770881608, 0.0, 1.0, 18718.70164616955]
[2019-04-06 15:08:12,976] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:08:12,977] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.5403336e-03 1.7163134e-03 1.9380266e-02 2.3967514e-03 9.7195590e-01
 5.1479263e-04 2.4956488e-03], sampled 0.18774125155942623
[2019-04-06 15:08:53,320] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2460.3162 79738583.7544 533.9182
[2019-04-06 15:09:03,631] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00546413], dtype=float32), 0.054480612]
[2019-04-06 15:09:03,631] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [5.25, 73.0, 0.0, 0.0, 26.0, 25.78543516160309, 0.4724455521146744, 0.0, 1.0, 0.0]
[2019-04-06 15:09:03,631] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:09:03,632] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.1705272e-03 1.6284370e-03 1.6167400e-02 1.7107661e-03 9.7695506e-01
 4.0138530e-04 1.9665058e-03], sampled 0.6971816726922891
[2019-04-06 15:09:29,313] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2420.0359 87769407.2278 514.7844
[2019-04-06 15:09:32,758] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2400.9521 91848038.6862 408.1416
[2019-04-06 15:09:33,822] A3C_AGENT_WORKER-Thread-8 INFO:Global step: 60000, evaluation results [60000.0, 2420.035902496903, 87769407.22784896, 514.7844205058144, 2460.316152378416, 79738583.75435211, 533.9181598229266, 2400.952138891939, 91848038.68621106, 408.1416275446877]
[2019-04-06 15:10:20,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0598778e-04 2.7119188e-04 4.8143915e-03 3.1839623e-04 9.9410915e-01
 2.6228714e-05 3.5463242e-04], sum to 1.0000
[2019-04-06 15:10:20,939] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7839
[2019-04-06 15:10:21,232] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 68.0, 14.0, 0.0, 26.0, 26.09606586840845, 0.4568534671915663, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2134800.0000, 
sim time next is 2136600.0000, 
raw observation next is [-4.75, 69.5, 0.0, 0.0, 26.0, 25.59012325190668, 0.2932127301749206, 1.0, 1.0, 30301.38801116092], 
processed observation next is [1.0, 0.7391304347826086, 0.3310249307479225, 0.695, 0.0, 0.0, 0.6666666666666666, 0.6325102709922232, 0.5977375767249735, 1.0, 1.0, 0.14429232386267105], 
reward next is 0.8557, 
noisyNet noise sample is [array([0.5820554], dtype=float32), -0.061804358]. 
=============================================
[2019-04-06 15:10:52,718] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.8561397e-05 8.1040460e-05 3.4987817e-03 1.2844794e-04 9.9616098e-01
 8.4960093e-06 1.0366093e-04], sum to 1.0000
[2019-04-06 15:10:52,718] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8776
[2019-04-06 15:10:53,229] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 71.0, 19.0, 0.0, 26.0, 25.64406458835827, 0.4001419317918095, 1.0, 1.0, 64700.59119868684], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2221200.0000, 
sim time next is 2223000.0000, 
raw observation next is [-4.5, 69.5, 0.0, 0.0, 26.0, 24.62788729825551, 0.2786123061381821, 1.0, 1.0, 89500.98159164569], 
processed observation next is [1.0, 0.7391304347826086, 0.3379501385041552, 0.695, 0.0, 0.0, 0.6666666666666666, 0.5523239415212924, 0.5928707687127274, 1.0, 1.0, 0.42619515043640804], 
reward next is 0.5738, 
noisyNet noise sample is [array([-1.5999926], dtype=float32), -0.5858094]. 
=============================================
[2019-04-06 15:10:53,237] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[22.07337 ]
 [21.781898]
 [21.590075]
 [21.567095]
 [21.567232]], R is [[22.21825027]
 [22.68796921]
 [23.46109009]
 [24.22647858]
 [24.78738976]].
[2019-04-06 15:11:23,350] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5751521e-04 2.2122059e-03 1.5595802e-02 7.4305054e-04 9.7941303e-01
 1.4209878e-04 1.4363682e-03], sum to 1.0000
[2019-04-06 15:11:23,350] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2635
[2019-04-06 15:11:23,446] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 41.0, 0.0, 0.0, 26.0, 24.74732044219674, 0.1856139780616018, 0.0, 1.0, 43037.60512996808], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2415600.0000, 
sim time next is 2417400.0000, 
raw observation next is [-5.3, 42.0, 0.0, 0.0, 26.0, 24.65467453023565, 0.171864377969372, 0.0, 1.0, 43098.98707798133], 
processed observation next is [0.0, 1.0, 0.31578947368421056, 0.42, 0.0, 0.0, 0.6666666666666666, 0.5545562108529708, 0.5572881259897907, 0.0, 1.0, 0.20523327179991108], 
reward next is 0.7948, 
noisyNet noise sample is [array([-0.01841944], dtype=float32), 1.3792822]. 
=============================================
[2019-04-06 15:11:24,195] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2308040e-04 3.2997888e-04 3.7718336e-03 2.1923175e-04 9.9533170e-01
 4.3647924e-05 1.8048788e-04], sum to 1.0000
[2019-04-06 15:11:24,196] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9360
[2019-04-06 15:11:24,311] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 57.0, 0.0, 0.0, 26.0, 24.78315805842762, 0.1292276801570876, 0.0, 1.0, 38473.57800540527], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2527200.0000, 
sim time next is 2529000.0000, 
raw observation next is [-2.55, 55.5, 0.0, 0.0, 26.0, 24.69739252528922, 0.1121003319097215, 0.0, 1.0, 38693.49676876612], 
processed observation next is [1.0, 0.2608695652173913, 0.3919667590027701, 0.555, 0.0, 0.0, 0.6666666666666666, 0.5581160437741017, 0.5373667773032406, 0.0, 1.0, 0.1842547465179339], 
reward next is 0.8157, 
noisyNet noise sample is [array([-0.6600766], dtype=float32), 0.23624504]. 
=============================================
[2019-04-06 15:11:24,319] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[17.338322]
 [17.23063 ]
 [17.097452]
 [17.005775]
 [16.911997]], R is [[18.06256294]
 [18.69873047]
 [19.32903862]
 [19.95301056]
 [20.57061195]].
[2019-04-06 15:11:26,486] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3997220e-04 1.5164277e-04 3.4794749e-03 1.5098433e-04 9.9582362e-01
 1.4141679e-05 2.4010781e-04], sum to 1.0000
[2019-04-06 15:11:26,486] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1868
[2019-04-06 15:11:26,610] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.0, 72.0, 0.0, 0.0, 26.0, 24.70026946803574, 0.2623028169999413, 0.0, 1.0, 44407.67933951399], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2678400.0000, 
sim time next is 2680200.0000, 
raw observation next is [-8.0, 70.5, 0.0, 0.0, 26.0, 24.61911877325013, 0.2400951575869431, 0.0, 1.0, 44424.92141862234], 
processed observation next is [1.0, 0.0, 0.24099722991689754, 0.705, 0.0, 0.0, 0.6666666666666666, 0.5515932311041775, 0.5800317191956478, 0.0, 1.0, 0.21154724485058257], 
reward next is 0.7885, 
noisyNet noise sample is [array([-1.3127737], dtype=float32), 1.233526]. 
=============================================
[2019-04-06 15:11:38,603] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.2956555e-05 8.0561986e-05 2.9682582e-03 7.4774522e-05 9.9675936e-01
 7.3564888e-06 6.6742257e-05], sum to 1.0000
[2019-04-06 15:11:38,604] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3344
[2019-04-06 15:11:38,879] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.2, 61.5, 0.0, 0.0, 26.0, 25.11458575996471, 0.3536858677651259, 0.0, 1.0, 7790.4936058065505], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2662200.0000, 
sim time next is 2664000.0000, 
raw observation next is [-1.2, 63.0, 0.0, 0.0, 26.0, 24.95518200455302, 0.3724077982800139, 0.0, 1.0, 77624.82562583368], 
processed observation next is [1.0, 0.8695652173913043, 0.42936288088642666, 0.63, 0.0, 0.0, 0.6666666666666666, 0.5795985003794183, 0.6241359327600047, 0.0, 1.0, 0.36964202678968416], 
reward next is 0.6304, 
noisyNet noise sample is [array([-0.6316066], dtype=float32), -2.8504992]. 
=============================================
[2019-04-06 15:11:38,887] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[23.15633 ]
 [23.715403]
 [23.744167]
 [23.951637]
 [24.10886 ]], R is [[23.15198135]
 [23.88336372]
 [24.2620945 ]
 [24.92481613]
 [25.48476791]].
[2019-04-06 15:12:02,682] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.2103161e-05 8.1489481e-05 5.8909566e-03 1.5816624e-04 9.9378383e-01
 3.2779992e-06 6.0083996e-05], sum to 1.0000
[2019-04-06 15:12:02,682] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7570
[2019-04-06 15:12:02,831] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 44.0, 0.0, 0.0, 26.0, 24.87010529503776, 0.346132996545443, 0.0, 1.0, 128482.61475980187], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2838600.0000, 
sim time next is 2840400.0000, 
raw observation next is [2.0, 44.0, 0.0, 0.0, 26.0, 25.2284308848953, 0.413268808345097, 0.0, 1.0, 80233.00946526267], 
processed observation next is [1.0, 0.9130434782608695, 0.518005540166205, 0.44, 0.0, 0.0, 0.6666666666666666, 0.6023692404079416, 0.6377562694483657, 0.0, 1.0, 0.38206194983458414], 
reward next is 0.6179, 
noisyNet noise sample is [array([0.66550463], dtype=float32), 0.49461186]. 
=============================================
[2019-04-06 15:12:35,339] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7309259e-05 1.5715632e-04 1.8068454e-03 3.9641927e-05 9.9791056e-01
 5.1721440e-06 5.3243515e-05], sum to 1.0000
[2019-04-06 15:12:35,339] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6906
[2019-04-06 15:12:35,378] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-10.5, 76.0, 0.0, 0.0, 26.0, 24.4001795940449, 0.1887130232958611, 0.0, 1.0, 43629.97727232115], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3303000.0000, 
sim time next is 3304800.0000, 
raw observation next is [-11.0, 76.0, 0.0, 0.0, 26.0, 24.18722750070074, 0.1452245199203833, 0.0, 1.0, 43697.50624567966], 
processed observation next is [1.0, 0.2608695652173913, 0.15789473684210528, 0.76, 0.0, 0.0, 0.6666666666666666, 0.5156022917250617, 0.5484081733067944, 0.0, 1.0, 0.20808336307466505], 
reward next is 0.7919, 
noisyNet noise sample is [array([-0.16148831], dtype=float32), 1.4954607]. 
=============================================
[2019-04-06 15:12:40,112] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1947926e-05 2.1954384e-04 6.8325745e-03 4.4831449e-05 9.9281353e-01
 8.1265289e-06 5.9379559e-05], sum to 1.0000
[2019-04-06 15:12:40,136] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2739
[2019-04-06 15:12:40,186] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 65.5, 0.0, 0.0, 26.0, 24.65537142925062, 0.2428825699158442, 0.0, 1.0, 42762.624656887674], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3389400.0000, 
sim time next is 3391200.0000, 
raw observation next is [-3.0, 60.0, 0.0, 0.0, 26.0, 24.76573456262092, 0.2239848004655181, 0.0, 1.0, 42715.867036446165], 
processed observation next is [1.0, 0.2608695652173913, 0.3795013850415513, 0.6, 0.0, 0.0, 0.6666666666666666, 0.5638112135517434, 0.5746616001551726, 0.0, 1.0, 0.20340889064974366], 
reward next is 0.7966, 
noisyNet noise sample is [array([1.0332148], dtype=float32), 1.1613545]. 
=============================================
[2019-04-06 15:12:59,800] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.5301066e-06 7.0887550e-06 1.4893007e-03 1.8265993e-05 9.9845576e-01
 4.2162756e-07 1.9549212e-05], sum to 1.0000
[2019-04-06 15:12:59,800] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3219
[2019-04-06 15:12:59,830] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.0, 34.5, 116.0, 816.0, 26.0, 25.686785374673, 0.4954886909875355, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3670200.0000, 
sim time next is 3672000.0000, 
raw observation next is [4.0, 45.0, 116.5, 822.5, 26.0, 25.52372538480475, 0.4643978467979319, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.5734072022160666, 0.45, 0.3883333333333333, 0.9088397790055248, 0.6666666666666666, 0.6269771154003957, 0.6547992822659773, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.39992014], dtype=float32), -2.2161112]. 
=============================================
[2019-04-06 15:12:59,838] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[26.204815]
 [25.934624]
 [25.451279]
 [24.875978]
 [24.247875]], R is [[27.09684753]
 [27.82588005]
 [28.54762077]
 [29.26214409]
 [29.96952248]].
[2019-04-06 15:13:07,576] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 15:13:07,576] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:13:07,576] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:13:07,578] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run5
[2019-04-06 15:13:07,595] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:13:07,597] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:13:07,599] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run5
[2019-04-06 15:13:07,621] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:13:07,622] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:13:07,624] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run5
[2019-04-06 15:13:43,780] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00546413], dtype=float32), 0.07235388]
[2019-04-06 15:13:43,781] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [0.2, 69.5, 0.0, 0.0, 26.0, 25.08332555380508, 0.3097710262096173, 0.0, 1.0, 38006.06825672066]
[2019-04-06 15:13:43,781] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:13:43,782] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.6659085e-05 2.1702237e-05 1.0746226e-03 3.5875826e-05 9.9883157e-01
 1.3033157e-06 1.8165247e-05], sampled 0.2144245722419964
[2019-04-06 15:14:45,235] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2455.4672 79888451.3066 535.3313
[2019-04-06 15:15:22,397] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2417.2505 87757332.2214 514.7148
[2019-04-06 15:15:24,408] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.9602 91892641.8397 408.5047
[2019-04-06 15:15:25,446] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 80000, evaluation results [80000.0, 2417.250545822255, 87757332.22135767, 514.7147971248587, 2455.467236429802, 79888451.30661818, 535.3312556835558, 2397.9602364855405, 91892641.83965988, 408.5046641342766]
[2019-04-06 15:15:42,642] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.2139259e-07 2.7786777e-07 5.5539125e-04 4.1669358e-07 9.9944359e-01
 3.4901151e-09 2.1235245e-07], sum to 1.0000
[2019-04-06 15:15:42,642] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6358
[2019-04-06 15:15:42,702] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 32.0, 117.5, 792.5, 26.0, 26.67184754648371, 0.6277514659479196, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4100400.0000, 
sim time next is 4102200.0000, 
raw observation next is [0.0, 30.0, 121.0, 816.0, 26.0, 26.76046773380483, 0.4069565492607288, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.46260387811634357, 0.3, 0.4033333333333333, 0.901657458563536, 0.6666666666666666, 0.7300389778170692, 0.6356521830869096, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0228114], dtype=float32), 0.45597878]. 
=============================================
[2019-04-06 15:15:49,412] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7573402e-06 2.3281547e-05 3.0025789e-03 2.6827120e-05 9.9693966e-01
 2.6547721e-07 3.6467052e-06], sum to 1.0000
[2019-04-06 15:15:49,412] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0190
[2019-04-06 15:15:49,557] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.4, 42.0, 0.0, 0.0, 26.0, 25.01393750061263, 0.3060670456463007, 0.0, 1.0, 30907.169165928848], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4215600.0000, 
sim time next is 4217400.0000, 
raw observation next is [1.2, 42.5, 0.0, 0.0, 26.0, 25.02288320638451, 0.3456814358909559, 0.0, 1.0, 137535.47785684888], 
processed observation next is [0.0, 0.8260869565217391, 0.4958448753462604, 0.425, 0.0, 0.0, 0.6666666666666666, 0.5852402671987091, 0.6152271452969853, 0.0, 1.0, 0.6549308469373757], 
reward next is 0.3451, 
noisyNet noise sample is [array([0.279976], dtype=float32), -0.102225974]. 
=============================================
[2019-04-06 15:16:46,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:16:46,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:16:46,390] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run3
[2019-04-06 15:16:46,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:16:46,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:16:46,611] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run3
[2019-04-06 15:17:00,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:00,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:00,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run3
[2019-04-06 15:17:01,926] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:01,926] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:01,928] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run3
[2019-04-06 15:17:03,325] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:03,325] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:03,327] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run3
[2019-04-06 15:17:04,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:04,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:04,715] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run3
[2019-04-06 15:17:06,488] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:06,488] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:06,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run3
[2019-04-06 15:17:08,510] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:08,510] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:08,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run3
[2019-04-06 15:17:09,318] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:09,318] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:09,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run3
[2019-04-06 15:17:09,571] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9291799e-08 1.6575196e-07 1.2040585e-04 4.7802547e-07 9.9987841e-01
 9.0139389e-09 4.6443390e-07], sum to 1.0000
[2019-04-06 15:17:09,571] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4685
[2019-04-06 15:17:09,946] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 65.0, 78.0, 317.0, 26.0, 25.58477626112661, 0.4291923577623673, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5040000.0000, 
sim time next is 5041800.0000, 
raw observation next is [-0.5, 56.0, 97.0, 533.0, 26.0, 25.84082064626592, 0.5218783384194741, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.44875346260387816, 0.56, 0.3233333333333333, 0.5889502762430939, 0.6666666666666666, 0.6534017205221602, 0.6739594461398246, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.044962], dtype=float32), -1.57543]. 
=============================================
[2019-04-06 15:17:11,358] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:11,358] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:11,360] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run3
[2019-04-06 15:17:12,397] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:12,397] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:12,399] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run3
[2019-04-06 15:17:13,142] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:13,142] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:13,144] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run3
[2019-04-06 15:17:13,198] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:13,199] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:13,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run3
[2019-04-06 15:17:13,878] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:13,878] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:13,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run3
[2019-04-06 15:17:16,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:16,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:16,459] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run3
[2019-04-06 15:17:17,819] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:17:17,819] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:17:17,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run3
[2019-04-06 15:17:36,261] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.6154677e-07 1.2958397e-07 4.4393029e-05 4.3806389e-07 9.9995470e-01
 1.1580265e-08 1.2361251e-07], sum to 1.0000
[2019-04-06 15:17:36,262] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1620
[2019-04-06 15:17:36,661] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.0, 89.5, 96.0, 0.0, 26.0, 24.32663628616576, 0.1101244292716096, 0.0, 1.0, 33945.474260966716], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 45000.0000, 
sim time next is 46800.0000, 
raw observation next is [8.3, 86.0, 91.5, 0.0, 26.0, 24.37645235073251, 0.1229359465092171, 0.0, 1.0, 22844.65018980937], 
processed observation next is [0.0, 0.5652173913043478, 0.6925207756232689, 0.86, 0.305, 0.0, 0.6666666666666666, 0.5313710292277092, 0.5409786488364057, 0.0, 1.0, 0.10878404852290176], 
reward next is 0.8912, 
noisyNet noise sample is [array([1.4431493], dtype=float32), -2.1927228]. 
=============================================
[2019-04-06 15:18:10,558] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8070091e-07 2.5283444e-07 9.0945745e-05 2.0872942e-07 9.9990833e-01
 7.3037585e-09 6.6808035e-08], sum to 1.0000
[2019-04-06 15:18:10,558] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4961
[2019-04-06 15:18:10,654] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.1, 69.0, 0.0, 0.0, 26.0, 23.85912710399759, 0.01041644316467307, 0.0, 1.0, 45595.23899776747], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 268200.0000, 
sim time next is 270000.0000, 
raw observation next is [-8.9, 67.0, 0.0, 0.0, 26.0, 23.75641621029373, -0.02554241889118035, 0.0, 1.0, 45727.19309725542], 
processed observation next is [1.0, 0.13043478260869565, 0.21606648199445982, 0.67, 0.0, 0.0, 0.6666666666666666, 0.47970135085781074, 0.49148586036960656, 0.0, 1.0, 0.21774853855835913], 
reward next is 0.7823, 
noisyNet noise sample is [array([1.7998327], dtype=float32), 1.1771833]. 
=============================================
[2019-04-06 15:18:10,657] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[35.608128]
 [36.83628 ]
 [37.79483 ]
 [38.745216]
 [39.430996]], R is [[35.15497971]
 [35.58630753]
 [36.01396179]
 [36.43867493]
 [36.86143112]].
[2019-04-06 15:18:11,950] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.7222958e-07 7.3723703e-07 9.9977871e-05 5.6177299e-07 9.9989712e-01
 3.5395711e-08 6.9091618e-07], sum to 1.0000
[2019-04-06 15:18:11,950] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2148
[2019-04-06 15:18:12,507] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-12.55, 68.5, 0.0, 0.0, 26.0, 22.70203702887871, -0.1458374444346605, 1.0, 1.0, 151243.40859986702], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 286200.0000, 
sim time next is 288000.0000, 
raw observation next is [-12.8, 70.0, 15.0, 205.5, 26.0, 24.41710840335185, 0.1191061538683925, 1.0, 1.0, 123983.71667498826], 
processed observation next is [1.0, 0.34782608695652173, 0.1080332409972299, 0.7, 0.05, 0.22707182320441988, 0.6666666666666666, 0.5347590336126542, 0.5397020512894641, 1.0, 1.0, 0.5903986508332775], 
reward next is 0.4096, 
noisyNet noise sample is [array([0.09357022], dtype=float32), 1.5206354]. 
=============================================
[2019-04-06 15:18:12,514] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[34.750286]
 [33.521408]
 [33.65375 ]
 [33.762783]
 [33.916912]], R is [[36.3883934 ]
 [36.30430222]
 [36.7130661 ]
 [37.11816406]
 [37.51925278]].
[2019-04-06 15:18:13,635] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7194263e-06 3.3815611e-06 2.9973721e-04 1.3514956e-06 9.9968982e-01
 2.6365253e-08 4.0886935e-06], sum to 1.0000
[2019-04-06 15:18:13,636] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8252
[2019-04-06 15:18:13,723] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-15.3, 71.0, 0.0, 0.0, 26.0, 22.63530782197211, -0.2744113921434683, 0.0, 1.0, 49280.97896379147], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 358200.0000, 
sim time next is 360000.0000, 
raw observation next is [-15.6, 73.0, 0.0, 0.0, 26.0, 22.44977216899012, -0.3283254819672531, 0.0, 1.0, 49323.97367308841], 
processed observation next is [1.0, 0.17391304347826086, 0.030470914127423816, 0.73, 0.0, 0.0, 0.6666666666666666, 0.37081434741584324, 0.39055817267758225, 0.0, 1.0, 0.23487606510994483], 
reward next is 0.7651, 
noisyNet noise sample is [array([1.9211416], dtype=float32), 0.99107254]. 
=============================================
[2019-04-06 15:18:13,736] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[31.17161 ]
 [31.191593]
 [31.916338]
 [32.990738]
 [33.91984 ]], R is [[31.62234879]
 [32.07145309]
 [32.51670456]
 [32.95931625]
 [33.40038681]].
[2019-04-06 15:18:21,978] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0052902e-07 6.1538361e-07 4.1285166e-05 8.1646533e-07 9.9995673e-01
 2.4866507e-08 1.4694044e-07], sum to 1.0000
[2019-04-06 15:18:21,978] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7407
[2019-04-06 15:18:22,051] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-14.5, 69.0, 0.0, 0.0, 26.0, 23.26414369170375, -0.1081439439529799, 0.0, 1.0, 47629.8294195], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 349200.0000, 
sim time next is 351000.0000, 
raw observation next is [-14.75, 69.0, 0.0, 0.0, 26.0, 23.29819291892085, -0.1212209936813704, 0.0, 1.0, 47807.50901628662], 
processed observation next is [1.0, 0.043478260869565216, 0.05401662049861495, 0.69, 0.0, 0.0, 0.6666666666666666, 0.4415160765767376, 0.45959300210620985, 0.0, 1.0, 0.22765480483946007], 
reward next is 0.7723, 
noisyNet noise sample is [array([-0.910902], dtype=float32), 0.70088863]. 
=============================================
[2019-04-06 15:18:22,055] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[36.26674 ]
 [37.023483]
 [38.231598]
 [39.04417 ]
 [39.376625]], R is [[35.67226791]
 [36.08873367]
 [36.50190353]
 [36.91183853]
 [37.31820297]].
[2019-04-06 15:18:27,524] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.0044872e-08 5.2554698e-09 1.2531431e-05 2.7962331e-08 9.9998748e-01
 2.0980140e-10 7.1829337e-10], sum to 1.0000
[2019-04-06 15:18:27,524] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7446
[2019-04-06 15:18:27,824] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.2, 38.0, 0.0, 0.0, 26.0, 25.54301459618593, 0.2922169201918907, 1.0, 1.0, 61617.5352455984], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 408600.0000, 
sim time next is 410400.0000, 
raw observation next is [-9.5, 40.0, 0.0, 0.0, 26.0, 25.41780598867718, 0.3659984492812889, 1.0, 1.0, 96999.77950172768], 
processed observation next is [1.0, 0.782608695652174, 0.1994459833795014, 0.4, 0.0, 0.0, 0.6666666666666666, 0.6181504990564317, 0.621999483093763, 1.0, 1.0, 0.46190371191298896], 
reward next is 0.5381, 
noisyNet noise sample is [array([1.4410138], dtype=float32), 0.5449242]. 
=============================================
[2019-04-06 15:19:11,702] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 15:19:11,707] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:19:11,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:19:11,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run6
[2019-04-06 15:19:11,725] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:19:11,727] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:19:11,727] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:19:11,728] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:19:11,730] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run6
[2019-04-06 15:19:11,745] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run6
[2019-04-06 15:20:49,894] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.6619 79982128.5367 535.1793
[2019-04-06 15:21:26,728] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2417.0247 87811776.4026 516.5518
[2019-04-06 15:21:32,614] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.6884 91944900.5891 409.3749
[2019-04-06 15:21:33,690] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 100000, evaluation results [100000.0, 2417.02473732734, 87811776.40262125, 516.5517721996582, 2454.6619278591807, 79982128.53666079, 535.1792512599005, 2396.6884059424474, 91944900.58913434, 409.3749352301794]
[2019-04-06 15:21:36,990] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6095080e-10 4.5578420e-11 3.5975577e-07 7.9851353e-10 9.9999964e-01
 1.2500337e-12 2.2122580e-11], sum to 1.0000
[2019-04-06 15:21:37,060] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5740
[2019-04-06 15:21:37,143] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.45, 86.0, 128.0, 0.0, 26.0, 25.73341407957678, 0.5535164570588927, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 995400.0000, 
sim time next is 997200.0000, 
raw observation next is [12.7, 86.0, 123.5, 0.0, 26.0, 25.95845895749698, 0.5820811373352607, 1.0, 1.0, 1868.041167023054], 
processed observation next is [1.0, 0.5652173913043478, 0.8144044321329641, 0.86, 0.4116666666666667, 0.0, 0.6666666666666666, 0.6632049131247483, 0.6940270457784202, 1.0, 1.0, 0.008895434128681209], 
reward next is 0.9911, 
noisyNet noise sample is [array([-1.2729695], dtype=float32), 0.06681024]. 
=============================================
[2019-04-06 15:21:41,644] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4727995e-07 2.9756626e-07 7.2302988e-05 4.1093446e-07 9.9992657e-01
 1.4549508e-08 9.7773274e-08], sum to 1.0000
[2019-04-06 15:21:41,652] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1442
[2019-04-06 15:21:41,814] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.3, 65.0, 165.0, 0.0, 26.0, 25.07919210778955, 0.500648228249502, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1170000.0000, 
sim time next is 1171800.0000, 
raw observation next is [18.3, 65.0, 159.0, 0.0, 26.0, 25.04955144649838, 0.4973137223254189, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.9695290858725764, 0.65, 0.53, 0.0, 0.6666666666666666, 0.5874626205415318, 0.6657712407751396, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7493538], dtype=float32), -0.72016627]. 
=============================================
[2019-04-06 15:22:15,861] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.14135916e-10 3.48826003e-11 9.25261787e-08 4.66990280e-10
 9.99999881e-01 4.16857819e-13 3.31187820e-11], sum to 1.0000
[2019-04-06 15:22:15,861] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1008
[2019-04-06 15:22:15,940] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 59.0, 0.0, 26.0, 26.01350219284852, 0.5392803260373388, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1436400.0000, 
sim time next is 1438200.0000, 
raw observation next is [1.1, 92.0, 46.0, 0.0, 26.0, 25.90888144797664, 0.5152736045265598, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.92, 0.15333333333333332, 0.0, 0.6666666666666666, 0.6590734539980533, 0.67175786817552, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.38732693], dtype=float32), 0.73688424]. 
=============================================
[2019-04-06 15:23:10,843] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8195515e-10 5.4558261e-11 5.5244012e-08 2.7114691e-10 1.0000000e+00
 5.0322761e-13 1.2500872e-11], sum to 1.0000
[2019-04-06 15:23:10,843] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9556
[2019-04-06 15:23:11,151] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.3, 70.0, 232.0, 10.0, 26.0, 25.71276730624527, 0.3022076261306725, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1942200.0000, 
sim time next is 1944000.0000, 
raw observation next is [-5.0, 65.0, 229.5, 7.0, 26.0, 25.688952474565, 0.3449441939584026, 1.0, 1.0, 63157.782782553695], 
processed observation next is [1.0, 0.5217391304347826, 0.32409972299168976, 0.65, 0.765, 0.0077348066298342545, 0.6666666666666666, 0.6407460395470833, 0.6149813979861342, 1.0, 1.0, 0.30075134658358904], 
reward next is 0.6992, 
noisyNet noise sample is [array([0.2836112], dtype=float32), 0.05860565]. 
=============================================
[2019-04-06 15:23:11,154] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[57.141438]
 [56.636   ]
 [55.901905]
 [53.67716 ]
 [51.650177]], R is [[57.99861526]
 [58.41862869]
 [58.83444214]
 [59.24609756]
 [59.55265427]].
[2019-04-06 15:23:40,990] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.36617996e-08 1.03011155e-08 1.29674652e-06 8.75816966e-08
 9.99998569e-01 3.82171517e-10 5.49754420e-09], sum to 1.0000
[2019-04-06 15:23:40,990] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2257
[2019-04-06 15:23:41,173] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 42.0, 0.0, 0.0, 26.0, 25.10942119723776, 0.2850847971227823, 0.0, 1.0, 50275.78169341783], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2404800.0000, 
sim time next is 2406600.0000, 
raw observation next is [-3.4, 42.0, 0.0, 0.0, 26.0, 25.15880532489357, 0.281110185714414, 0.0, 1.0, 43456.83847835689], 
processed observation next is [0.0, 0.8695652173913043, 0.368421052631579, 0.42, 0.0, 0.0, 0.6666666666666666, 0.5965671104077975, 0.593703395238138, 0.0, 1.0, 0.20693732608741378], 
reward next is 0.7931, 
noisyNet noise sample is [array([-0.33431578], dtype=float32), -0.10477413]. 
=============================================
[2019-04-06 15:24:02,347] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.7044630e-07 1.0828276e-07 2.5686713e-06 5.6846787e-08 9.9999714e-01
 1.7481193e-09 1.5703080e-08], sum to 1.0000
[2019-04-06 15:24:02,347] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2443
[2019-04-06 15:24:02,438] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.8, 65.0, 0.0, 0.0, 26.0, 24.42502009261146, 0.1717038578644921, 0.0, 1.0, 40099.34249059624], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2347200.0000, 
sim time next is 2349000.0000, 
raw observation next is [-3.1, 67.0, 0.0, 0.0, 26.0, 24.38264722611332, 0.1506446311989698, 0.0, 1.0, 40430.818037752724], 
processed observation next is [0.0, 0.17391304347826086, 0.37673130193905824, 0.67, 0.0, 0.0, 0.6666666666666666, 0.5318872688427767, 0.5502148770663232, 0.0, 1.0, 0.19252770494167964], 
reward next is 0.8075, 
noisyNet noise sample is [array([-0.736606], dtype=float32), -0.014959598]. 
=============================================
[2019-04-06 15:24:02,467] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[39.563976]
 [39.511276]
 [39.491253]
 [41.139004]
 [43.79072 ]], R is [[40.06239319]
 [40.47082138]
 [40.87679291]
 [41.28030014]
 [41.68138123]].
[2019-04-06 15:24:05,427] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.0685933e-09 6.8248220e-09 1.3976714e-06 3.3527343e-08 9.9999857e-01
 1.8318342e-09 1.9941533e-09], sum to 1.0000
[2019-04-06 15:24:05,427] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8373
[2019-04-06 15:24:05,713] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.15, 44.5, 0.0, 0.0, 26.0, 24.95558032831415, 0.2656975933057876, 0.0, 1.0, 40230.88764757856], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2395800.0000, 
sim time next is 2397600.0000, 
raw observation next is [-1.7, 44.0, 0.0, 0.0, 26.0, 24.94431898176909, 0.2646221115046585, 0.0, 1.0, 48338.39633253386], 
processed observation next is [0.0, 0.782608695652174, 0.4155124653739613, 0.44, 0.0, 0.0, 0.6666666666666666, 0.5786932484807575, 0.5882073705015528, 0.0, 1.0, 0.23018283967873268], 
reward next is 0.7698, 
noisyNet noise sample is [array([0.70159423], dtype=float32), 0.733172]. 
=============================================
[2019-04-06 15:24:20,155] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4301084e-09 1.2847214e-09 2.7254071e-06 2.7811318e-09 9.9999726e-01
 3.1976550e-11 1.2548484e-09], sum to 1.0000
[2019-04-06 15:24:20,155] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8219
[2019-04-06 15:24:20,206] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.2, 83.0, 0.0, 0.0, 26.0, 24.30502291660034, 0.09987116482381819, 0.0, 1.0, 42891.13825242845], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2610000.0000, 
sim time next is 2611800.0000, 
raw observation next is [-6.45, 80.5, 0.0, 0.0, 26.0, 24.06125077468531, 0.05793485594257933, 0.0, 1.0, 43273.1352560551], 
processed observation next is [1.0, 0.21739130434782608, 0.28393351800554023, 0.805, 0.0, 0.0, 0.6666666666666666, 0.5051042312237758, 0.5193116186475265, 0.0, 1.0, 0.20606254883835762], 
reward next is 0.7939, 
noisyNet noise sample is [array([-0.23439462], dtype=float32), 0.82515365]. 
=============================================
[2019-04-06 15:24:34,419] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3158267e-13 1.9216213e-12 1.3052801e-09 1.0039690e-12 1.0000000e+00
 5.9097256e-16 2.8857174e-13], sum to 1.0000
[2019-04-06 15:24:34,420] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6925
[2019-04-06 15:24:34,519] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 96.5, 71.0, 54.0, 26.0, 25.15746072682899, 0.4213022339086245, 1.0, 1.0, 65664.829228798], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2910600.0000, 
sim time next is 2912400.0000, 
raw observation next is [2.0, 93.0, 38.5, 47.5, 26.0, 25.87595714261318, 0.4713234920721221, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.93, 0.12833333333333333, 0.052486187845303865, 0.6666666666666666, 0.6563297618844318, 0.6571078306907073, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2132685], dtype=float32), 1.009423]. 
=============================================
[2019-04-06 15:24:58,663] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 15:24:58,664] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:24:58,664] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:24:58,664] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:24:58,666] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run7
[2019-04-06 15:24:58,677] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:24:58,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:24:58,682] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:24:58,686] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run7
[2019-04-06 15:24:58,708] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run7
[2019-04-06 15:26:43,668] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.4131 79987260.4995 535.2506
[2019-04-06 15:27:21,956] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 15:27:24,014] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 15:27:25,057] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 120000, evaluation results [120000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.413070268317, 79987260.49946941, 535.2506232687274, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 15:27:39,090] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5197054e-13 1.8011653e-12 7.1539002e-10 5.6814640e-12 1.0000000e+00
 2.0803354e-14 1.7830763e-12], sum to 1.0000
[2019-04-06 15:27:39,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0121
[2019-04-06 15:27:39,248] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 52.0, 115.5, 814.5, 26.0, 26.19204201521449, 0.6377494552799642, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3502800.0000, 
sim time next is 3504600.0000, 
raw observation next is [2.5, 50.5, 115.0, 806.0, 26.0, 26.01866118494943, 0.6258801397178403, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5318559556786704, 0.505, 0.38333333333333336, 0.8906077348066298, 0.6666666666666666, 0.6682217654124525, 0.7086267132392802, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.06527053], dtype=float32), -0.73381585]. 
=============================================
[2019-04-06 15:28:14,346] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.4496624e-12 5.0121144e-12 1.0211500e-07 4.8736992e-10 9.9999988e-01
 8.4915283e-14 1.1420924e-11], sum to 1.0000
[2019-04-06 15:28:14,347] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5516
[2019-04-06 15:28:14,416] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.5, 74.0, 0.0, 0.0, 26.0, 25.22037803129468, 0.4140022456962431, 0.0, 1.0, 43790.57582568831], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3803400.0000, 
sim time next is 3805200.0000, 
raw observation next is [-4.0, 77.0, 0.0, 0.0, 26.0, 25.24115768370186, 0.396162727143249, 0.0, 1.0, 43971.104254166596], 
processed observation next is [1.0, 0.043478260869565216, 0.3518005540166205, 0.77, 0.0, 0.0, 0.6666666666666666, 0.603429806975155, 0.632054242381083, 0.0, 1.0, 0.20938621073412664], 
reward next is 0.7906, 
noisyNet noise sample is [array([-0.26581195], dtype=float32), -0.53492004]. 
=============================================
[2019-04-06 15:28:44,761] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.70307561e-12 1.31042182e-12 1.40137724e-08 2.18206078e-11
 1.00000000e+00 3.28199754e-14 1.31188055e-11], sum to 1.0000
[2019-04-06 15:28:44,761] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4655
[2019-04-06 15:28:44,798] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 36.0, 0.0, 0.0, 26.0, 25.56490562186303, 0.5833357028434145, 0.0, 1.0, 99246.38870723984], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4136400.0000, 
sim time next is 4138200.0000, 
raw observation next is [1.0, 38.0, 0.0, 0.0, 26.0, 25.87397445593103, 0.5869009516160205, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4903047091412743, 0.38, 0.0, 0.0, 0.6666666666666666, 0.6561645379942526, 0.6956336505386735, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.28909028], dtype=float32), 0.07741355]. 
=============================================
[2019-04-06 15:28:54,657] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7239703e-15 3.9260202e-15 2.4566254e-11 8.2992586e-13 1.0000000e+00
 1.1968506e-18 1.5680860e-15], sum to 1.0000
[2019-04-06 15:28:54,666] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6249
[2019-04-06 15:28:54,748] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.2, 31.5, 195.0, 629.0, 26.0, 28.23640236239546, 1.11684248102409, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4372200.0000, 
sim time next is 4374000.0000, 
raw observation next is [13.9, 32.0, 149.0, 314.5, 26.0, 28.39007023152054, 1.118812046758093, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.847645429362881, 0.32, 0.49666666666666665, 0.3475138121546961, 0.6666666666666666, 0.8658391859600449, 0.8729373489193644, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0592638], dtype=float32), 0.76450276]. 
=============================================
[2019-04-06 15:28:54,755] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.35394 ]
 [72.875145]
 [72.40116 ]
 [72.01473 ]
 [71.65408 ]], R is [[73.65099335]
 [73.91448212]
 [74.17533875]
 [74.43358612]
 [74.68925476]].
[2019-04-06 15:28:55,087] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1690949e-09 2.6418359e-10 2.5137865e-07 4.1218522e-09 9.9999976e-01
 2.3111185e-12 2.3319902e-10], sum to 1.0000
[2019-04-06 15:28:55,087] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0653
[2019-04-06 15:28:55,387] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.0, 54.0, 193.0, 367.5, 26.0, 25.62099219170046, 0.4113638645023447, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4269600.0000, 
sim time next is 4271400.0000, 
raw observation next is [4.5, 54.5, 204.0, 604.0, 26.0, 25.41667378974289, 0.4072302590001038, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.5872576177285319, 0.545, 0.68, 0.6674033149171271, 0.6666666666666666, 0.6180561491452409, 0.6357434196667012, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.00103606], dtype=float32), -0.55354136]. 
=============================================
[2019-04-06 15:29:02,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8612542e-10 1.7114592e-10 2.7665632e-07 4.8104569e-09 9.9999976e-01
 8.6070284e-13 1.9940891e-11], sum to 1.0000
[2019-04-06 15:29:02,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5587
[2019-04-06 15:29:03,082] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.2, 56.0, 300.0, 164.0, 26.0, 25.13765877263354, 0.3281870967797022, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4876200.0000, 
sim time next is 4878000.0000, 
raw observation next is [-0.4, 52.0, 291.5, 236.0, 26.0, 24.98930266048516, 0.3274879351810359, 0.0, 1.0, 30809.48338977095], 
processed observation next is [0.0, 0.4782608695652174, 0.45152354570637127, 0.52, 0.9716666666666667, 0.26077348066298345, 0.6666666666666666, 0.5824418883737632, 0.6091626450603452, 0.0, 1.0, 0.14671182566557595], 
reward next is 0.8533, 
noisyNet noise sample is [array([0.42388123], dtype=float32), 0.30599988]. 
=============================================
[2019-04-06 15:29:03,100] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[53.319046]
 [51.994476]
 [50.70466 ]
 [49.365208]
 [48.474964]], R is [[54.86281967]
 [55.31419373]
 [55.76105118]
 [56.20344162]
 [56.64140701]].
[2019-04-06 15:29:22,599] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0299634e-10 1.2603368e-10 1.8659722e-07 4.6159801e-10 9.9999976e-01
 8.3392272e-13 4.1905843e-11], sum to 1.0000
[2019-04-06 15:29:22,599] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8665
[2019-04-06 15:29:22,685] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 72.5, 0.0, 0.0, 26.0, 25.18779549240707, 0.3696096780377092, 0.0, 1.0, 36216.988806867776], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4599000.0000, 
sim time next is 4600800.0000, 
raw observation next is [-2.6, 74.0, 0.0, 0.0, 26.0, 25.20454130588909, 0.3780698138279324, 0.0, 1.0, 36189.85124169649], 
processed observation next is [1.0, 0.2608695652173913, 0.3905817174515236, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6003784421574242, 0.6260232712759775, 0.0, 1.0, 0.17233262496045945], 
reward next is 0.8277, 
noisyNet noise sample is [array([1.1213694], dtype=float32), -2.0512705]. 
=============================================
[2019-04-06 15:29:22,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:22,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:22,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run4
[2019-04-06 15:29:23,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:23,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:23,222] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run4
[2019-04-06 15:29:34,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:34,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:34,575] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run4
[2019-04-06 15:29:38,549] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1531479e-11 2.2546482e-11 1.5054863e-07 3.9994470e-11 9.9999988e-01
 1.1758201e-12 4.5547580e-11], sum to 1.0000
[2019-04-06 15:29:38,550] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4607
[2019-04-06 15:29:38,629] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.1, 83.0, 0.0, 0.0, 26.0, 24.06341296119863, 0.06909757563308432, 0.0, 1.0, 43208.97476201256], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 99000.0000, 
sim time next is 100800.0000, 
raw observation next is [-3.4, 79.0, 0.0, 0.0, 26.0, 23.91595697544757, 0.04986446072843837, 0.0, 1.0, 43535.963794111995], 
processed observation next is [1.0, 0.17391304347826086, 0.368421052631579, 0.79, 0.0, 0.0, 0.6666666666666666, 0.49299641462063093, 0.5166214869094795, 0.0, 1.0, 0.2073141133052952], 
reward next is 0.7927, 
noisyNet noise sample is [array([-0.736056], dtype=float32), 0.67029107]. 
=============================================
[2019-04-06 15:29:39,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:39,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:39,663] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run4
[2019-04-06 15:29:41,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:41,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:41,307] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run4
[2019-04-06 15:29:43,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:43,022] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:43,023] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run4
[2019-04-06 15:29:43,236] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0786570e-13 6.7996138e-12 1.2796053e-07 3.6662908e-12 9.9999988e-01
 1.2404864e-15 1.2234145e-13], sum to 1.0000
[2019-04-06 15:29:43,236] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4932
[2019-04-06 15:29:43,250] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [10.0, 19.0, 0.0, 0.0, 26.0, 27.48737167262892, 0.9290699805948206, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5083200.0000, 
sim time next is 5085000.0000, 
raw observation next is [9.5, 19.0, 0.0, 0.0, 26.0, 27.26934501093287, 0.8873757216239908, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.7257617728531857, 0.19, 0.0, 0.0, 0.6666666666666666, 0.7724454175777392, 0.795791907207997, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1961428], dtype=float32), 1.2567029]. 
=============================================
[2019-04-06 15:29:43,298] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.23848 ]
 [69.38669 ]
 [70.43961 ]
 [71.363846]
 [72.31465 ]], R is [[65.48349762]
 [65.82866669]
 [66.17037964]
 [66.50867462]
 [66.84358978]].
[2019-04-06 15:29:44,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:44,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:44,823] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run4
[2019-04-06 15:29:44,842] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:44,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:44,847] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run4
[2019-04-06 15:29:47,604] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:47,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:47,606] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run4
[2019-04-06 15:29:47,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:47,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:47,763] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run4
[2019-04-06 15:29:47,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:47,842] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:47,844] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run4
[2019-04-06 15:29:48,794] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:48,794] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:48,796] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run4
[2019-04-06 15:29:48,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:48,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:48,887] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run4
[2019-04-06 15:29:49,123] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:49,123] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:49,125] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run4
[2019-04-06 15:29:49,174] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:49,174] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:49,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run4
[2019-04-06 15:29:49,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:29:49,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:29:49,479] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run4
[2019-04-06 15:30:23,537] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.7195733e-12 1.5785253e-12 2.5867406e-09 5.9871171e-11 1.0000000e+00
 8.0967066e-15 1.3289315e-13], sum to 1.0000
[2019-04-06 15:30:23,537] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0386
[2019-04-06 15:30:23,583] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.2, 80.5, 0.0, 0.0, 26.0, 24.27482301117454, 0.1153851507703953, 0.0, 1.0, 44296.69642395598], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 257400.0000, 
sim time next is 259200.0000, 
raw observation next is [-4.5, 79.0, 0.0, 0.0, 26.0, 24.15701475100779, 0.09159761515267202, 0.0, 1.0, 44356.85506684594], 
processed observation next is [1.0, 0.0, 0.3379501385041552, 0.79, 0.0, 0.0, 0.6666666666666666, 0.5130845625839825, 0.530532538384224, 0.0, 1.0, 0.21122311936593305], 
reward next is 0.7888, 
noisyNet noise sample is [array([2.0844932], dtype=float32), 0.008230493]. 
=============================================
[2019-04-06 15:30:34,546] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 15:30:34,546] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:30:34,546] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:30:34,548] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run8
[2019-04-06 15:30:34,564] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:30:34,565] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:30:34,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run8
[2019-04-06 15:30:34,606] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:30:34,606] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:30:34,608] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run8
[2019-04-06 15:32:23,404] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 15:32:59,308] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 15:33:06,271] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 15:33:07,308] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 140000, evaluation results [140000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 15:33:55,531] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0488394e-14 1.3173114e-15 1.9247073e-11 6.7614425e-14 1.0000000e+00
 1.1192069e-17 3.6199507e-16], sum to 1.0000
[2019-04-06 15:33:55,531] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6791
[2019-04-06 15:33:55,586] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.4, 81.0, 106.5, 0.0, 26.0, 26.6155998700304, 0.6912713588261169, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1000800.0000, 
sim time next is 1002600.0000, 
raw observation next is [14.4, 81.0, 94.0, 0.0, 26.0, 26.78405912319095, 0.7159902067917693, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.8614958448753465, 0.81, 0.31333333333333335, 0.0, 0.6666666666666666, 0.7320049269325791, 0.738663402263923, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03678758], dtype=float32), 0.57878125]. 
=============================================
[2019-04-06 15:34:06,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5115456e-13 3.9601232e-13 7.2751111e-11 1.2731889e-13 1.0000000e+00
 6.4750302e-17 4.2234706e-14], sum to 1.0000
[2019-04-06 15:34:06,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2154
[2019-04-06 15:34:06,652] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.9, 100.0, 47.0, 0.0, 26.0, 25.95040128318081, 0.5192398103328301, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1503000.0000, 
sim time next is 1504800.0000, 
raw observation next is [2.2, 100.0, 60.0, 0.0, 26.0, 26.13003519275808, 0.5233894815502627, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.5235457063711911, 1.0, 0.2, 0.0, 0.6666666666666666, 0.67750293272984, 0.6744631605167543, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.40575], dtype=float32), -0.88103414]. 
=============================================
[2019-04-06 15:34:43,899] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.3857658e-10 9.2842689e-10 2.5967555e-07 3.1142169e-09 9.9999976e-01
 8.2973775e-12 8.9578442e-11], sum to 1.0000
[2019-04-06 15:34:43,899] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8035
[2019-04-06 15:34:44,017] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.6, 75.0, 0.0, 0.0, 26.0, 24.47439203961638, 0.3474046063255301, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1202400.0000, 
sim time next is 1204200.0000, 
raw observation next is [16.6, 75.0, 0.0, 0.0, 26.0, 24.38793751347774, 0.3296307196160886, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.922437673130194, 0.75, 0.0, 0.0, 0.6666666666666666, 0.5323281261231451, 0.6098769065386962, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.3141398], dtype=float32), -0.66441834]. 
=============================================
[2019-04-06 15:34:45,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.7899008e-14 4.1965599e-15 9.2755098e-10 5.5737052e-14 1.0000000e+00
 4.9843508e-17 2.1621001e-15], sum to 1.0000
[2019-04-06 15:34:45,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3026
[2019-04-06 15:34:45,629] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [11.35, 54.0, 87.0, 28.0, 26.0, 27.24837126005239, 0.7000306230471485, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1528200.0000, 
sim time next is 1530000.0000, 
raw observation next is [10.5, 58.0, 44.5, 17.0, 26.0, 26.47149336196462, 0.7116778758053354, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.7534626038781165, 0.58, 0.14833333333333334, 0.01878453038674033, 0.6666666666666666, 0.7059577801637182, 0.7372259586017784, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5574853], dtype=float32), 1.8393056]. 
=============================================
[2019-04-06 15:34:45,675] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[80.11903 ]
 [80.335915]
 [80.60926 ]
 [80.952614]
 [81.207825]], R is [[79.66429901]
 [79.86766052]
 [80.06898499]
 [80.26829529]
 [80.46561432]].
[2019-04-06 15:35:40,391] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5319460e-10 1.4222605e-10 2.9506583e-07 2.9932223e-09 9.9999964e-01
 6.8156705e-13 2.6171539e-11], sum to 1.0000
[2019-04-06 15:35:40,391] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5194
[2019-04-06 15:35:40,432] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.9, 85.0, 0.0, 0.0, 26.0, 24.20774011571, 0.08948773933547123, 0.0, 1.0, 41403.68828616713], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2003400.0000, 
sim time next is 2005200.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.2157486504781, 0.08298882568040045, 0.0, 1.0, 41116.95395974255], 
processed observation next is [1.0, 0.21739130434782608, 0.2908587257617729, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5179790542065085, 0.5276629418934667, 0.0, 1.0, 0.19579501885591688], 
reward next is 0.8042, 
noisyNet noise sample is [array([-0.11824631], dtype=float32), -0.3078806]. 
=============================================
[2019-04-06 15:35:54,433] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3236187e-14 2.7512174e-14 4.5779897e-10 2.5758215e-12 1.0000000e+00
 9.0787448e-16 2.3861823e-13], sum to 1.0000
[2019-04-06 15:35:54,434] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6231
[2019-04-06 15:35:54,557] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 91.0, 0.0, 0.0, 26.0, 24.71259540887069, 0.2535760168783924, 0.0, 1.0, 42664.47810186247], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2073600.0000, 
sim time next is 2075400.0000, 
raw observation next is [-4.5, 91.0, 0.0, 0.0, 26.0, 24.73115776813425, 0.2555381708435472, 0.0, 1.0, 42845.52001632943], 
processed observation next is [1.0, 0.0, 0.3379501385041552, 0.91, 0.0, 0.0, 0.6666666666666666, 0.5609298140111875, 0.5851793902811824, 0.0, 1.0, 0.2040262857920449], 
reward next is 0.7960, 
noisyNet noise sample is [array([0.5913928], dtype=float32), -1.4025463]. 
=============================================
[2019-04-06 15:36:29,537] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 15:36:29,538] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:36:29,538] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:36:29,539] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run9
[2019-04-06 15:36:29,570] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:36:29,571] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:36:29,573] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run9
[2019-04-06 15:36:29,594] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:36:29,596] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:36:29,597] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run9
[2019-04-06 15:37:00,600] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00621093], dtype=float32), 0.1028292]
[2019-04-06 15:37:00,600] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-7.0, 69.0, 0.0, 0.0, 26.0, 23.48518615593897, -0.0656440033655744, 0.0, 1.0, 42115.09882223317]
[2019-04-06 15:37:00,601] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:37:00,601] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [7.5135415e-10 4.2001649e-10 1.7933725e-07 2.1362405e-09 9.9999976e-01
 5.7973995e-12 1.4484988e-10], sampled 0.11211298672406123
[2019-04-06 15:37:16,206] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00621093], dtype=float32), 0.1028292]
[2019-04-06 15:37:16,206] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [11.05, 81.5, 0.0, 0.0, 26.0, 25.66515696484248, 0.5901907246910606, 0.0, 1.0, 18748.286387135653]
[2019-04-06 15:37:16,206] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:37:16,206] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [2.0526733e-11 9.3494622e-12 1.1804764e-08 5.6100301e-11 1.0000000e+00
 6.6783120e-14 2.6777768e-12], sampled 0.9817346468104278
[2019-04-06 15:38:23,729] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 15:38:45,546] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00621093], dtype=float32), 0.1028292]
[2019-04-06 15:38:45,547] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-2.7347391365, 64.40265848, 0.0, 0.0, 26.0, 25.19911902726334, 0.3979162696543883, 0.0, 1.0, 42505.22968848586]
[2019-04-06 15:38:45,547] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 15:38:45,548] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.4376297e-10 7.6616283e-11 4.4212786e-08 4.3416429e-10 1.0000000e+00
 7.4891937e-13 2.3105826e-11], sampled 0.506354610621595
[2019-04-06 15:39:00,512] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 15:39:03,719] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2396.6170 91944900.5891 409.3749
[2019-04-06 15:39:04,757] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 160000, evaluation results [160000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2396.616977371019, 91944900.58913434, 409.3749352301794]
[2019-04-06 15:39:17,370] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.7578781e-10 1.7667178e-09 1.8571839e-06 2.5343918e-09 9.9999809e-01
 3.9360824e-11 6.2680694e-11], sum to 1.0000
[2019-04-06 15:39:17,370] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7683
[2019-04-06 15:39:17,440] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 26.0, 24.55336482993545, 0.2482640537537246, 0.0, 1.0, 42681.09081004522], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2950200.0000, 
sim time next is 2952000.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 26.0, 24.44530112656864, 0.223961777454935, 0.0, 1.0, 42744.76838346376], 
processed observation next is [0.0, 0.17391304347826086, 0.3795013850415513, 0.84, 0.0, 0.0, 0.6666666666666666, 0.5371084272140534, 0.5746539258183117, 0.0, 1.0, 0.2035465161117322], 
reward next is 0.7965, 
noisyNet noise sample is [array([-1.0431663], dtype=float32), -0.6495281]. 
=============================================
[2019-04-06 15:39:17,444] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[55.70033 ]
 [55.745766]
 [57.705414]
 [60.817715]
 [63.228024]], R is [[55.89938354]
 [56.137146  ]
 [56.3717804 ]
 [56.60308456]
 [56.83139038]].
[2019-04-06 15:39:26,097] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2240902e-12 1.7740213e-13 9.7258859e-09 1.3575419e-11 1.0000000e+00
 1.7000461e-14 5.6638976e-14], sum to 1.0000
[2019-04-06 15:39:26,097] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3992
[2019-04-06 15:39:26,399] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 59.5, 152.0, 233.0, 26.0, 25.87483780274313, 0.396102177266124, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2799000.0000, 
sim time next is 2800800.0000, 
raw observation next is [-3.0, 55.0, 163.0, 370.5, 26.0, 25.93305850488661, 0.4203809306154403, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.55, 0.5433333333333333, 0.4093922651933702, 0.6666666666666666, 0.6610882087405509, 0.6401269768718134, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5469712], dtype=float32), -1.5501187]. 
=============================================
[2019-04-06 15:40:01,842] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.5298223e-12 1.9362790e-12 7.9485512e-09 3.0151607e-11 1.0000000e+00
 1.7165068e-14 3.9331667e-13], sum to 1.0000
[2019-04-06 15:40:01,842] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3984
[2019-04-06 15:40:02,046] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.5, 46.0, 109.0, 806.0, 26.0, 25.10636932627735, 0.3595159247983106, 0.0, 1.0, 18714.647459243788], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3072600.0000, 
sim time next is 3074400.0000, 
raw observation next is [-1.0, 42.0, 104.0, 790.5, 26.0, 25.11704518099134, 0.3628961849128992, 0.0, 1.0, 18710.311858577592], 
processed observation next is [0.0, 0.6086956521739131, 0.4349030470914128, 0.42, 0.3466666666666667, 0.8734806629834254, 0.6666666666666666, 0.593087098415945, 0.6209653949709665, 0.0, 1.0, 0.08909672313608377], 
reward next is 0.9109, 
noisyNet noise sample is [array([0.00841177], dtype=float32), -1.3834423]. 
=============================================
[2019-04-06 15:40:16,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.4235447e-15 9.0787797e-16 1.4097294e-10 3.4332183e-14 1.0000000e+00
 1.7749020e-16 1.4942647e-15], sum to 1.0000
[2019-04-06 15:40:16,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7280
[2019-04-06 15:40:16,682] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 43.0, 0.0, 0.0, 26.0, 25.42856941819328, 0.4695442059147032, 0.0, 1.0, 28512.958363433358], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4132800.0000, 
sim time next is 4134600.0000, 
raw observation next is [1.0, 39.5, 0.0, 0.0, 26.0, 25.22414563609068, 0.4795759685809856, 0.0, 1.0, 137678.16482424174], 
processed observation next is [1.0, 0.8695652173913043, 0.4903047091412743, 0.395, 0.0, 0.0, 0.6666666666666666, 0.6020121363408899, 0.6598586561936619, 0.0, 1.0, 0.6556103086868654], 
reward next is 0.3444, 
noisyNet noise sample is [array([-1.7453111], dtype=float32), 0.654719]. 
=============================================
[2019-04-06 15:40:52,121] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5166339e-11 8.3453756e-12 4.6658455e-09 4.9241732e-11 1.0000000e+00
 4.9881843e-13 1.6496337e-11], sum to 1.0000
[2019-04-06 15:40:52,121] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5291
[2019-04-06 15:40:52,201] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.17259593144914, 0.3194508424517589, 0.0, 1.0, 39188.33036092477], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4845600.0000, 
sim time next is 4847400.0000, 
raw observation next is [-2.5, 60.0, 0.0, 0.0, 26.0, 25.10281974256972, 0.3017579320098026, 0.0, 1.0, 39142.82372770074], 
processed observation next is [0.0, 0.08695652173913043, 0.39335180055401664, 0.6, 0.0, 0.0, 0.6666666666666666, 0.5919016452141435, 0.6005859773366008, 0.0, 1.0, 0.18639439870333688], 
reward next is 0.8136, 
noisyNet noise sample is [array([-1.7549679], dtype=float32), -0.92418295]. 
=============================================
[2019-04-06 15:40:53,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9503455e-12 1.5872983e-13 4.2707951e-10 6.7485877e-13 1.0000000e+00
 7.7471174e-16 7.7504355e-14], sum to 1.0000
[2019-04-06 15:40:53,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0243
[2019-04-06 15:40:54,014] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.75, 67.0, 0.0, 0.0, 26.0, 25.62184332973351, 0.5621550430039501, 0.0, 1.0, 51380.450927432954], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4419000.0000, 
sim time next is 4420800.0000, 
raw observation next is [4.5, 67.0, 0.0, 0.0, 26.0, 25.81397409243784, 0.5534039110081436, 0.0, 1.0, 6242.02127833994], 
processed observation next is [1.0, 0.17391304347826086, 0.5872576177285319, 0.67, 0.0, 0.0, 0.6666666666666666, 0.6511645077031533, 0.6844679703360478, 0.0, 1.0, 0.02972391084923781], 
reward next is 0.9703, 
noisyNet noise sample is [array([0.7611752], dtype=float32), -1.0452585]. 
=============================================
[2019-04-06 15:41:05,590] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:41:05,590] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:41:05,592] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run5
[2019-04-06 15:41:05,899] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:41:05,900] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:41:05,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run5
[2019-04-06 15:41:19,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:41:19,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:41:19,151] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run5
[2019-04-06 15:41:20,509] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.2635041e-14 4.5592453e-14 5.5016693e-11 2.3816764e-13 1.0000000e+00
 2.5721748e-15 1.6357045e-14], sum to 1.0000
[2019-04-06 15:41:20,509] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8935
[2019-04-06 15:41:20,582] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.1, 64.0, 0.0, 0.0, 26.0, 25.43958701881697, 0.4439187334048577, 0.0, 1.0, 36940.385108835624], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4584600.0000, 
sim time next is 4586400.0000, 
raw observation next is [-0.2, 65.0, 0.0, 0.0, 26.0, 25.44858818363469, 0.4465410524845231, 0.0, 1.0, 29566.708070759258], 
processed observation next is [1.0, 0.08695652173913043, 0.4570637119113574, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6207156819695575, 0.648847017494841, 0.0, 1.0, 0.14079384795599648], 
reward next is 0.8592, 
noisyNet noise sample is [array([0.12501207], dtype=float32), 0.4600319]. 
=============================================
[2019-04-06 15:41:27,578] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:41:27,579] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:41:27,580] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run5
[2019-04-06 15:41:28,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:41:28,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:41:28,315] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run5
[2019-04-06 15:41:31,978] A3C_AGENT_WORKER-Thread-8 INFO:Evaluating...
[2019-04-06 15:41:31,979] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:41:31,980] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:41:31,980] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:41:31,983] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:41:31,984] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run10
[2019-04-06 15:41:31,981] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:41:31,983] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run10
[2019-04-06 15:41:32,020] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:41:32,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run10
[2019-04-06 15:42:16,175] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00629318], dtype=float32), 0.10658765]
[2019-04-06 15:42:16,176] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [4.4, 93.0, 94.0, 704.0, 26.0, 26.07877424620583, 0.6293275422409025, 1.0, 1.0, 0.0]
[2019-04-06 15:42:16,176] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:42:16,176] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.0041528e-14 7.1660910e-15 8.5905894e-11 1.1891580e-13 1.0000000e+00
 1.5579484e-17 1.8404256e-15], sampled 0.01171679010786264
[2019-04-06 15:42:20,128] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00629318], dtype=float32), 0.10658765]
[2019-04-06 15:42:20,128] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [16.6, 58.0, 53.0, 116.0, 26.0, 25.9628615043888, 0.7005020820263551, 0.0, 0.0, 0.0]
[2019-04-06 15:42:20,128] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:42:20,129] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [4.6174141e-11 1.7843496e-11 2.1025931e-08 1.2942623e-10 1.0000000e+00
 1.9043220e-13 6.8915468e-12], sampled 0.7268759027264436
[2019-04-06 15:43:29,986] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 15:44:11,039] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.6373 87830352.8773 516.5543
[2019-04-06 15:44:14,891] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 15:44:15,929] A3C_AGENT_WORKER-Thread-8 INFO:Global step: 180000, evaluation results [180000.0, 2416.637309002334, 87830352.877312, 516.5542744756061, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 15:44:20,247] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:44:20,247] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:44:20,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run5
[2019-04-06 15:44:23,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:44:23,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:44:23,155] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run5
[2019-04-06 15:44:31,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:44:31,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:44:31,283] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run5
[2019-04-06 15:44:31,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:44:31,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:44:31,635] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run5
[2019-04-06 15:44:32,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:44:32,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:44:32,035] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run5
[2019-04-06 15:44:36,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:44:36,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:44:36,091] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run5
[2019-04-06 15:44:36,756] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:44:36,756] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:44:36,758] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run5
[2019-04-06 15:44:39,864] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:44:39,864] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:44:39,866] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run5
[2019-04-06 15:44:41,379] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:44:41,379] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:44:41,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run5
[2019-04-06 15:44:42,227] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:44:42,227] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:44:42,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run5
[2019-04-06 15:44:42,586] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:44:42,586] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:44:42,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run5
[2019-04-06 15:45:57,015] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.01322555e-13 1.59228862e-14 2.55034438e-10 1.89957330e-13
 1.00000000e+00 3.00960666e-17 7.50997029e-15], sum to 1.0000
[2019-04-06 15:45:57,015] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1495
[2019-04-06 15:45:57,438] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 38.5, 20.0, 0.0, 26.0, 24.34800900691103, 0.1718641840029153, 1.0, 1.0, 77402.20591672313], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 491400.0000, 
sim time next is 493200.0000, 
raw observation next is [1.1, 43.0, 10.0, 0.0, 26.0, 25.55330865812043, 0.2946453861647172, 1.0, 1.0, 20145.365663731613], 
processed observation next is [1.0, 0.7391304347826086, 0.49307479224376743, 0.43, 0.03333333333333333, 0.0, 0.6666666666666666, 0.6294423881767024, 0.5982151287215723, 1.0, 1.0, 0.09593031268443625], 
reward next is 0.9041, 
noisyNet noise sample is [array([1.6846056], dtype=float32), -0.92844117]. 
=============================================
[2019-04-06 15:46:28,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0063251e-17 4.8170150e-16 3.9027820e-13 5.5939165e-15 1.0000000e+00
 2.0190950e-20 7.9047266e-19], sum to 1.0000
[2019-04-06 15:46:28,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0733
[2019-04-06 15:46:28,134] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [10.5, 61.0, 0.0, 0.0, 26.0, 26.56044654913152, 0.7472308319638601, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1620000.0000, 
sim time next is 1621800.0000, 
raw observation next is [9.95, 63.5, 0.0, 0.0, 26.0, 26.46336820403207, 0.7182328840125044, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.7382271468144045, 0.635, 0.0, 0.0, 0.6666666666666666, 0.705280683669339, 0.7394109613375015, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.10295068], dtype=float32), 1.5253758]. 
=============================================
[2019-04-06 15:46:44,688] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.10767981e-11 1.01877855e-11 1.19255672e-08 4.43914572e-10
 1.00000000e+00 1.17441647e-13 5.79180844e-12], sum to 1.0000
[2019-04-06 15:46:44,688] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7621
[2019-04-06 15:46:44,706] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.3, 65.0, 159.0, 0.0, 26.0, 25.04953914549703, 0.4973106228094454, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1171800.0000, 
sim time next is 1173600.0000, 
raw observation next is [18.3, 65.0, 143.5, 0.0, 26.0, 25.03981930186438, 0.4983420626409774, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.9695290858725764, 0.65, 0.47833333333333333, 0.0, 0.6666666666666666, 0.5866516084886984, 0.6661140208803258, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2868173], dtype=float32), -0.36177775]. 
=============================================
[2019-04-06 15:47:01,513] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.34499017e-15 1.07761305e-16 5.12843977e-12 6.26397805e-16
 1.00000000e+00 1.32631419e-19 1.96197117e-16], sum to 1.0000
[2019-04-06 15:47:01,514] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0200
[2019-04-06 15:47:01,529] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 120.0, 0.0, 26.0, 26.04701963314058, 0.5752737876218507, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1339200.0000, 
sim time next is 1341000.0000, 
raw observation next is [1.1, 92.0, 113.0, 0.0, 26.0, 25.91350655296308, 0.5404489826098064, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.49307479224376743, 0.92, 0.37666666666666665, 0.0, 0.6666666666666666, 0.6594588794135902, 0.6801496608699354, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.437303], dtype=float32), -2.1533024]. 
=============================================
[2019-04-06 15:47:01,531] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[87.231575]
 [86.563705]
 [85.73488 ]
 [85.095055]
 [83.996   ]], R is [[87.80472565]
 [87.92668152]
 [88.04741669]
 [88.16694641]
 [88.28527832]].
[2019-04-06 15:47:02,126] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.9410843e-15 8.4224230e-15 9.8836724e-11 3.5230445e-14 1.0000000e+00
 3.8150778e-18 3.9042446e-15], sum to 1.0000
[2019-04-06 15:47:02,126] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5008
[2019-04-06 15:47:02,232] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.8, 92.0, 18.0, 0.0, 26.0, 25.72110965571684, 0.5770163061903605, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1326600.0000, 
sim time next is 1328400.0000, 
raw observation next is [0.5, 92.0, 31.5, 0.0, 26.0, 26.07976479968931, 0.5890885810995627, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4764542936288089, 0.92, 0.105, 0.0, 0.6666666666666666, 0.6733137333074426, 0.6963628603665208, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.263382], dtype=float32), 0.35599765]. 
=============================================
[2019-04-06 15:47:06,040] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [9.7330557e-15 8.5331539e-15 2.3278211e-11 1.0289931e-13 1.0000000e+00
 4.7513084e-19 6.5965740e-16], sum to 1.0000
[2019-04-06 15:47:06,040] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4805
[2019-04-06 15:47:06,126] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.6, 97.0, 0.0, 0.0, 26.0, 25.60323242607517, 0.535884471481905, 0.0, 1.0, 35527.242042115235], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1652400.0000, 
sim time next is 1654200.0000, 
raw observation next is [6.6, 97.0, 0.0, 0.0, 26.0, 25.54808144612096, 0.5774281361176471, 0.0, 1.0, 84803.46480861666], 
processed observation next is [1.0, 0.13043478260869565, 0.6454293628808865, 0.97, 0.0, 0.0, 0.6666666666666666, 0.6290067871767467, 0.692476045372549, 0.0, 1.0, 0.40382602289817454], 
reward next is 0.5962, 
noisyNet noise sample is [array([0.05483954], dtype=float32), -0.5542179]. 
=============================================
[2019-04-06 15:47:12,598] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.3068781e-11 6.5853360e-12 9.8072910e-09 5.5029075e-11 1.0000000e+00
 1.2000807e-14 1.3572790e-13], sum to 1.0000
[2019-04-06 15:47:12,598] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6624
[2019-04-06 15:47:12,866] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 85.0, 65.0, 0.0, 26.0, 24.9708291060775, 0.3100311611815654, 0.0, 1.0, 16715.830475414343], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1762200.0000, 
sim time next is 1764000.0000, 
raw observation next is [-2.3, 87.0, 81.0, 0.0, 26.0, 24.88785594935428, 0.333376170268038, 0.0, 1.0, 76589.51963773431], 
processed observation next is [0.0, 0.43478260869565216, 0.3988919667590028, 0.87, 0.27, 0.0, 0.6666666666666666, 0.5739879957795232, 0.611125390089346, 0.0, 1.0, 0.3647119982749253], 
reward next is 0.6353, 
noisyNet noise sample is [array([0.35001785], dtype=float32), -1.0310326]. 
=============================================
[2019-04-06 15:47:12,875] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[68.45005]
 [68.28373]
 [68.31599]
 [68.02244]
 [67.92968]], R is [[69.2013855 ]
 [69.42977142]
 [69.73547363]
 [69.80844116]
 [69.90045929]].
[2019-04-06 15:47:14,911] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.6704036e-13 6.6323759e-13 5.0497091e-09 1.2593752e-11 1.0000000e+00
 2.5779113e-15 1.5321866e-13], sum to 1.0000
[2019-04-06 15:47:14,911] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5404
[2019-04-06 15:47:15,066] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.1, 87.0, 66.0, 0.0, 26.0, 25.01625335013421, 0.3453564124939981, 0.0, 1.0, 35259.96207103026], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1783800.0000, 
sim time next is 1785600.0000, 
raw observation next is [-3.4, 87.0, 47.0, 0.0, 26.0, 24.99773790339846, 0.3288490125141655, 0.0, 1.0, 44116.52107658869], 
processed observation next is [0.0, 0.6956521739130435, 0.368421052631579, 0.87, 0.15666666666666668, 0.0, 0.6666666666666666, 0.5831448252832049, 0.6096163375047218, 0.0, 1.0, 0.21007867179327946], 
reward next is 0.7899, 
noisyNet noise sample is [array([-1.3312302], dtype=float32), 1.5298411]. 
=============================================
[2019-04-06 15:47:39,705] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-06 15:47:39,721] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:47:39,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:47:39,723] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run11
[2019-04-06 15:47:39,741] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:47:39,741] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:47:39,743] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run11
[2019-04-06 15:47:39,756] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:47:39,757] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:47:39,759] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run11
[2019-04-06 15:48:35,542] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00657663], dtype=float32), 0.109493196]
[2019-04-06 15:48:35,542] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-5.676708911, 87.01220332, 0.0, 0.0, 26.0, 24.09222754012953, 0.07304233523105182, 0.0, 1.0, 41070.148830668106]
[2019-04-06 15:48:35,542] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 15:48:35,543] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.7981387e-11 7.3424808e-12 9.6549853e-09 6.0419524e-11 1.0000000e+00
 5.0206157e-14 1.9053038e-12], sampled 0.1845023683905076
[2019-04-06 15:49:12,480] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00657663], dtype=float32), 0.109493196]
[2019-04-06 15:49:12,480] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [6.75, 57.0, 0.0, 0.0, 26.0, 25.53976917869501, 0.4743083607088683, 0.0, 1.0, 33537.291582696744]
[2019-04-06 15:49:12,480] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 15:49:12,481] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.02930425e-11 4.12864534e-12 6.01929839e-09 3.27043601e-11
 1.00000000e+00 2.56484710e-14 9.88586817e-13], sampled 0.49923073143150454
[2019-04-06 15:49:29,753] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.0584 79959984.5800 535.1579
[2019-04-06 15:50:12,792] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 15:50:15,994] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 15:50:17,038] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 200000, evaluation results [200000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.0583810834455, 79959984.58002774, 535.1579115189242, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 15:50:25,075] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5909418e-13 1.2943869e-12 1.4648553e-10 2.5239489e-12 1.0000000e+00
 1.2823465e-15 5.0838101e-14], sum to 1.0000
[2019-04-06 15:50:25,075] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4547
[2019-04-06 15:50:25,346] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 47.0, 86.0, 341.0, 26.0, 24.98095460546822, 0.3184827947604267, 0.0, 1.0, 22439.957366114773], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2388600.0000, 
sim time next is 2390400.0000, 
raw observation next is [0.0, 47.0, 82.5, 199.5, 26.0, 25.00900758759506, 0.2986205659900015, 0.0, 1.0, 18924.568415004607], 
processed observation next is [0.0, 0.6956521739130435, 0.46260387811634357, 0.47, 0.275, 0.22044198895027625, 0.6666666666666666, 0.5840839656329218, 0.5995401886633338, 0.0, 1.0, 0.09011699245240289], 
reward next is 0.9099, 
noisyNet noise sample is [array([-1.4394598], dtype=float32), 0.17308041]. 
=============================================
[2019-04-06 15:50:49,463] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.04218344e-13 9.21496715e-15 9.28717103e-11 1.21420438e-13
 1.00000000e+00 2.90078774e-17 2.48324327e-14], sum to 1.0000
[2019-04-06 15:50:49,463] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1933
[2019-04-06 15:50:49,556] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.15, 83.0, 0.0, 0.0, 26.0, 25.26787101905561, 0.4091321879713989, 0.0, 1.0, 43120.99133204461], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2151000.0000, 
sim time next is 2152800.0000, 
raw observation next is [-6.7, 83.0, 0.0, 0.0, 26.0, 25.21737653277829, 0.3976263854053873, 0.0, 1.0, 42328.506155735355], 
processed observation next is [1.0, 0.9565217391304348, 0.2770083102493075, 0.83, 0.0, 0.0, 0.6666666666666666, 0.6014480443981908, 0.6325421284684625, 0.0, 1.0, 0.2015643150273112], 
reward next is 0.7984, 
noisyNet noise sample is [array([-0.91037875], dtype=float32), -1.1018565]. 
=============================================
[2019-04-06 15:51:03,619] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.07551975e-14 8.88140197e-16 1.61954217e-11 1.16047295e-13
 1.00000000e+00 2.14543705e-16 1.61178247e-15], sum to 1.0000
[2019-04-06 15:51:03,619] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8089
[2019-04-06 15:51:03,741] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 26.0, 24.95461900902336, 0.3052876428653947, 0.0, 1.0, 38569.56562587364], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2331000.0000, 
sim time next is 2332800.0000, 
raw observation next is [-2.3, 65.0, 0.0, 0.0, 26.0, 24.90317703618964, 0.300620499776676, 0.0, 1.0, 38523.947862903915], 
processed observation next is [0.0, 0.0, 0.3988919667590028, 0.65, 0.0, 0.0, 0.6666666666666666, 0.5752647530158033, 0.600206833258892, 0.0, 1.0, 0.18344737077573292], 
reward next is 0.8166, 
noisyNet noise sample is [array([0.00526222], dtype=float32), -0.40908656]. 
=============================================
[2019-04-06 15:51:24,049] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8120013e-14 4.8867563e-15 2.0031939e-10 1.0676025e-13 1.0000000e+00
 6.3469548e-18 4.8901854e-16], sum to 1.0000
[2019-04-06 15:51:24,050] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6617
[2019-04-06 15:51:24,253] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 55.0, 0.0, 0.0, 26.0, 25.45342589154916, 0.4767439193507045, 0.0, 1.0, 28164.86674724834], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3353400.0000, 
sim time next is 3355200.0000, 
raw observation next is [-3.0, 55.0, 0.0, 0.0, 26.0, 25.19366087727546, 0.4397307588216823, 1.0, 1.0, 32850.895869648455], 
processed observation next is [1.0, 0.8695652173913043, 0.3795013850415513, 0.55, 0.0, 0.0, 0.6666666666666666, 0.5994717397729549, 0.6465769196072274, 1.0, 1.0, 0.15643283747451645], 
reward next is 0.8436, 
noisyNet noise sample is [array([-0.98024267], dtype=float32), 1.8949485]. 
=============================================
[2019-04-06 15:51:55,706] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6433254e-16 9.0354143e-17 2.3450081e-12 4.6158266e-16 1.0000000e+00
 1.6155649e-19 1.6238460e-17], sum to 1.0000
[2019-04-06 15:51:55,707] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0731
[2019-04-06 15:51:55,896] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.0, 35.0, 213.5, 429.0, 26.0, 25.62116608658287, 0.4552818909148672, 1.0, 1.0, 60420.26463862407], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2811600.0000, 
sim time next is 2813400.0000, 
raw observation next is [5.0, 32.5, 249.0, 173.0, 26.0, 25.97356761534813, 0.4757528304701817, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.6011080332409973, 0.325, 0.83, 0.19116022099447513, 0.6666666666666666, 0.6644639679456775, 0.6585842768233939, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7855924], dtype=float32), -0.25990894]. 
=============================================
[2019-04-06 15:52:10,844] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3532931e-13 1.4854420e-14 6.8309358e-10 1.0271352e-11 1.0000000e+00
 1.1107906e-15 1.7605012e-13], sum to 1.0000
[2019-04-06 15:52:10,844] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7312
[2019-04-06 15:52:10,901] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 30.0, 0.0, 0.0, 26.0, 25.62570838293348, 0.4893461276300466, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4051800.0000, 
sim time next is 4053600.0000, 
raw observation next is [-5.0, 31.0, 0.0, 0.0, 26.0, 25.44561845614177, 0.4721466317562444, 0.0, 1.0, 62753.29477450794], 
processed observation next is [1.0, 0.9565217391304348, 0.32409972299168976, 0.31, 0.0, 0.0, 0.6666666666666666, 0.6204682046784807, 0.6573822105854148, 0.0, 1.0, 0.29882521321194255], 
reward next is 0.7012, 
noisyNet noise sample is [array([1.7887828], dtype=float32), 0.2625025]. 
=============================================
[2019-04-06 15:52:33,548] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.7154788e-15 1.1860031e-16 9.9360298e-11 1.3129875e-14 1.0000000e+00
 9.5026757e-19 4.8924057e-16], sum to 1.0000
[2019-04-06 15:52:33,549] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1826
[2019-04-06 15:52:33,596] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 79.0, 0.0, 0.0, 26.0, 25.43082664348466, 0.5524235683512718, 0.0, 1.0, 61111.83354477424], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3445200.0000, 
sim time next is 3447000.0000, 
raw observation next is [1.0, 82.5, 0.0, 0.0, 26.0, 25.66434923378835, 0.5553153067592183, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4903047091412743, 0.825, 0.0, 0.0, 0.6666666666666666, 0.6386957694823625, 0.6851051022530728, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4804336], dtype=float32), 0.5510075]. 
=============================================
[2019-04-06 15:52:33,614] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[86.16258 ]
 [86.80491 ]
 [87.347855]
 [89.21214 ]
 [89.53345 ]], R is [[86.42776489]
 [86.27248383]
 [85.77331543]
 [85.62631989]
 [85.57032776]].
[2019-04-06 15:52:41,158] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7421390e-13 5.7414055e-14 4.2619008e-10 1.1764343e-13 1.0000000e+00
 2.8196168e-17 3.9287167e-15], sum to 1.0000
[2019-04-06 15:52:41,160] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1672
[2019-04-06 15:52:41,241] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.5, 42.5, 0.0, 0.0, 26.0, 25.44946758150735, 0.4620548272228861, 0.0, 1.0, 27461.354362503916], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4145400.0000, 
sim time next is 4147200.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 26.0, 25.39591492341245, 0.4396448064514489, 0.0, 1.0, 38344.97166192751], 
processed observation next is [0.0, 0.0, 0.4349030470914128, 0.42, 0.0, 0.0, 0.6666666666666666, 0.6163262436177043, 0.6465482688171497, 0.0, 1.0, 0.18259510315203578], 
reward next is 0.8174, 
noisyNet noise sample is [array([0.7155223], dtype=float32), 0.9891816]. 
=============================================
[2019-04-06 15:52:46,001] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6461228e-11 6.2318596e-13 5.3601728e-09 4.2438804e-12 1.0000000e+00
 5.6226487e-15 4.0050618e-13], sum to 1.0000
[2019-04-06 15:52:46,013] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6934
[2019-04-06 15:52:46,049] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [11.0, 27.0, 101.0, 663.0, 26.0, 25.71886221366795, 0.4641210422245332, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3663000.0000, 
sim time next is 3664800.0000, 
raw observation next is [11.0, 28.0, 106.0, 713.0, 26.0, 25.66742551597319, 0.4686443566874829, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.7673130193905818, 0.28, 0.35333333333333333, 0.7878453038674034, 0.6666666666666666, 0.6389521263310991, 0.6562147855624944, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09952148], dtype=float32), -0.43053323]. 
=============================================
[2019-04-06 15:52:59,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:52:59,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:52:59,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run6
[2019-04-06 15:53:00,335] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:53:00,335] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:53:00,338] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run6
[2019-04-06 15:53:06,533] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-06 15:53:06,535] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:53:06,535] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:53:06,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run12
[2019-04-06 15:53:06,580] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:53:06,580] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:53:06,582] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run12
[2019-04-06 15:53:06,600] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:53:06,600] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:53:06,603] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run12
[2019-04-06 15:54:56,265] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 15:55:34,503] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 15:55:40,874] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 15:55:41,926] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 220000, evaluation results [220000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 15:56:05,392] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6021651e-16 8.4551893e-16 2.5860350e-13 2.3284514e-15 1.0000000e+00
 5.8019792e-20 6.5899554e-17], sum to 1.0000
[2019-04-06 15:56:05,392] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9488
[2019-04-06 15:56:05,455] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [9.0, 25.0, 121.0, 862.5, 26.0, 27.58023112877113, 0.903934497434534, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5058000.0000, 
sim time next is 5059800.0000, 
raw observation next is [10.0, 22.5, 118.0, 860.0, 26.0, 27.93781746650254, 0.8539893496698338, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.739612188365651, 0.225, 0.3933333333333333, 0.9502762430939227, 0.6666666666666666, 0.8281514555418784, 0.7846631165566113, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6802891], dtype=float32), -0.42325157]. 
=============================================
[2019-04-06 15:56:08,849] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9455711e-12 1.2159431e-12 4.6936832e-10 1.8789779e-11 1.0000000e+00
 1.3469934e-14 5.0605749e-13], sum to 1.0000
[2019-04-06 15:56:08,849] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6087
[2019-04-06 15:56:08,966] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 26.0, 22.89020569416615, -0.2015100717051018, 0.0, 1.0, 44574.696685409166], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 190800.0000, 
sim time next is 192600.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 26.0, 22.87885687748418, -0.213436804110604, 0.0, 1.0, 44801.28975385191], 
processed observation next is [1.0, 0.21739130434782608, 0.21606648199445982, 0.78, 0.0, 0.0, 0.6666666666666666, 0.4065714064570149, 0.4288543986297986, 0.0, 1.0, 0.21333947501834244], 
reward next is 0.7867, 
noisyNet noise sample is [array([0.42313528], dtype=float32), -0.14182194]. 
=============================================
[2019-04-06 15:56:09,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:56:09,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:56:09,356] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run6
[2019-04-06 15:56:17,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:56:17,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:56:17,656] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run6
[2019-04-06 15:56:20,745] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:56:20,745] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:56:20,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run6
[2019-04-06 15:56:42,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:56:42,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:56:42,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run6
[2019-04-06 15:56:42,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:56:42,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:56:42,714] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run6
[2019-04-06 15:56:53,288] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:56:53,288] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:56:53,292] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run6
[2019-04-06 15:56:57,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:56:57,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:56:57,303] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run6
[2019-04-06 15:56:58,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:56:58,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:56:58,584] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run6
[2019-04-06 15:56:58,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:56:58,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:56:58,716] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run6
[2019-04-06 15:57:00,375] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:57:00,376] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:57:00,379] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run6
[2019-04-06 15:57:02,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:57:02,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:57:02,252] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run6
[2019-04-06 15:57:02,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:57:02,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:57:02,564] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run6
[2019-04-06 15:57:02,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:57:02,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:57:02,856] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run6
[2019-04-06 15:57:07,702] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 15:57:07,702] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:57:07,706] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run6
[2019-04-06 15:57:13,702] A3C_AGENT_WORKER-Thread-14 INFO:Local step 14500, global step 227845: loss 10.2820
[2019-04-06 15:57:13,703] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 14500, global step 227845: learning rate 0.0000
[2019-04-06 15:57:14,418] A3C_AGENT_WORKER-Thread-17 INFO:Local step 14500, global step 227890: loss 9.9789
[2019-04-06 15:57:14,430] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 14500, global step 227890: learning rate 0.0000
[2019-04-06 15:57:30,438] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.0134773e-14 5.7330449e-14 9.5775787e-10 4.2027584e-12 1.0000000e+00
 2.5154648e-17 1.2122408e-15], sum to 1.0000
[2019-04-06 15:57:30,438] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7222
[2019-04-06 15:57:30,677] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 62.0, 37.0, 0.0, 26.0, 25.95157872359066, 0.362110452228482, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 230400.0000, 
sim time next is 232200.0000, 
raw observation next is [-3.4, 63.5, 18.0, 0.0, 26.0, 25.29234166455113, 0.2731900697424952, 1.0, 1.0, 11906.978562770282], 
processed observation next is [1.0, 0.6956521739130435, 0.368421052631579, 0.635, 0.06, 0.0, 0.6666666666666666, 0.6076951387125943, 0.5910633565808318, 1.0, 1.0, 0.056699897917953726], 
reward next is 0.9433, 
noisyNet noise sample is [array([0.6151083], dtype=float32), -0.16390833]. 
=============================================
[2019-04-06 15:57:49,130] A3C_AGENT_WORKER-Thread-19 INFO:Local step 14500, global step 230219: loss 9.5719
[2019-04-06 15:57:49,131] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 14500, global step 230219: learning rate 0.0000
[2019-04-06 15:57:56,075] A3C_AGENT_WORKER-Thread-15 INFO:Local step 14500, global step 230935: loss 9.9030
[2019-04-06 15:57:56,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 14500, global step 230935: learning rate 0.0000
[2019-04-06 15:57:58,605] A3C_AGENT_WORKER-Thread-18 INFO:Local step 14500, global step 231246: loss 9.1732
[2019-04-06 15:57:58,605] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 14500, global step 231246: learning rate 0.0000
[2019-04-06 15:58:08,993] A3C_AGENT_WORKER-Thread-8 INFO:Local step 14500, global step 232391: loss 9.8784
[2019-04-06 15:58:08,994] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 14500, global step 232391: learning rate 0.0000
[2019-04-06 15:58:10,702] A3C_AGENT_WORKER-Thread-7 INFO:Local step 14500, global step 232592: loss 10.0692
[2019-04-06 15:58:10,702] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 14500, global step 232592: learning rate 0.0000
[2019-04-06 15:58:14,227] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15000, global step 232956: loss 33.2264
[2019-04-06 15:58:14,233] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 15000, global step 232956: learning rate 0.0000
[2019-04-06 15:58:15,310] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15000, global step 233062: loss 33.4057
[2019-04-06 15:58:15,310] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 15000, global step 233062: learning rate 0.0000
[2019-04-06 15:58:16,369] A3C_AGENT_WORKER-Thread-13 INFO:Local step 14500, global step 233195: loss 9.2141
[2019-04-06 15:58:16,371] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 14500, global step 233195: learning rate 0.0000
[2019-04-06 15:58:19,736] A3C_AGENT_WORKER-Thread-3 INFO:Local step 14500, global step 233659: loss 10.3258
[2019-04-06 15:58:19,737] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 14500, global step 233659: learning rate 0.0000
[2019-04-06 15:58:20,924] A3C_AGENT_WORKER-Thread-6 INFO:Local step 14500, global step 233827: loss 9.9592
[2019-04-06 15:58:20,925] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 14500, global step 233827: learning rate 0.0000
[2019-04-06 15:58:21,155] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7344362e-13 3.2291928e-14 8.2081175e-11 1.8449753e-13 1.0000000e+00
 1.5206580e-16 3.6750950e-14], sum to 1.0000
[2019-04-06 15:58:21,155] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7731
[2019-04-06 15:58:21,268] A3C_AGENT_WORKER-Thread-16 INFO:Local step 14500, global step 233871: loss 8.7603
[2019-04-06 15:58:21,269] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 14500, global step 233871: learning rate 0.0000
[2019-04-06 15:58:21,293] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.7, 87.0, 20.5, 22.5, 26.0, 24.98334307345578, 0.3050346549286502, 0.0, 1.0, 41613.40506787581], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 579600.0000, 
sim time next is 581400.0000, 
raw observation next is [-2.0, 87.0, 0.0, 0.0, 26.0, 24.9433445698421, 0.2897799750245668, 0.0, 1.0, 45714.98845872764], 
processed observation next is [0.0, 0.7391304347826086, 0.40720221606648205, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5786120474868417, 0.596593325008189, 0.0, 1.0, 0.21769042123203639], 
reward next is 0.7823, 
noisyNet noise sample is [array([0.6393778], dtype=float32), -0.40758026]. 
=============================================
[2019-04-06 15:58:22,335] A3C_AGENT_WORKER-Thread-4 INFO:Local step 14500, global step 234028: loss 10.5138
[2019-04-06 15:58:22,340] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 14500, global step 234028: learning rate 0.0000
[2019-04-06 15:58:23,178] A3C_AGENT_WORKER-Thread-20 INFO:Local step 14500, global step 234153: loss 10.2163
[2019-04-06 15:58:23,179] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 14500, global step 234153: learning rate 0.0000
[2019-04-06 15:58:23,565] A3C_AGENT_WORKER-Thread-2 INFO:Local step 14500, global step 234198: loss 10.0175
[2019-04-06 15:58:23,566] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 14500, global step 234198: learning rate 0.0000
[2019-04-06 15:58:24,435] A3C_AGENT_WORKER-Thread-12 INFO:Local step 14500, global step 234319: loss 9.7999
[2019-04-06 15:58:24,436] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 14500, global step 234319: learning rate 0.0000
[2019-04-06 15:58:27,612] A3C_AGENT_WORKER-Thread-5 INFO:Local step 14500, global step 234724: loss 9.7076
[2019-04-06 15:58:27,612] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 14500, global step 234724: learning rate 0.0000
[2019-04-06 15:58:31,218] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.93817266e-14 1.35247165e-14 8.96505925e-11 2.75225806e-13
 1.00000000e+00 6.45645405e-18 2.01626770e-15], sum to 1.0000
[2019-04-06 15:58:31,221] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3024
[2019-04-06 15:58:31,439] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.2, 75.0, 61.0, 0.0, 26.0, 25.73167544319658, 0.3039832527689805, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 811800.0000, 
sim time next is 813600.0000, 
raw observation next is [-6.2, 75.0, 74.0, 0.0, 26.0, 25.71990036762242, 0.2992921520426874, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.2908587257617729, 0.75, 0.24666666666666667, 0.0, 0.6666666666666666, 0.6433250306352015, 0.5997640506808958, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.46160176], dtype=float32), -0.32282963]. 
=============================================
[2019-04-06 15:58:36,314] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3235112e-16 1.2657095e-17 3.4063076e-13 3.9505813e-16 1.0000000e+00
 2.2667374e-20 1.3563647e-18], sum to 1.0000
[2019-04-06 15:58:36,314] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8370
[2019-04-06 15:58:36,330] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 120.0, 0.0, 26.0, 26.04701963314058, 0.5752737876218507, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1339200.0000, 
sim time next is 1341000.0000, 
raw observation next is [1.1, 92.0, 113.0, 0.0, 26.0, 25.91350655296308, 0.5404489826098064, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.49307479224376743, 0.92, 0.37666666666666665, 0.0, 0.6666666666666666, 0.6594588794135902, 0.6801496608699354, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([3.1664724], dtype=float32), 0.7408001]. 
=============================================
[2019-04-06 15:58:36,336] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[90.72191 ]
 [90.08963 ]
 [89.25744 ]
 [88.62357 ]
 [87.749245]], R is [[91.20966339]
 [91.29756927]
 [91.38459778]
 [91.4707489 ]
 [91.55604553]].
[2019-04-06 15:58:39,789] A3C_AGENT_WORKER-Thread-19 INFO:Local step 15000, global step 236432: loss 32.4252
[2019-04-06 15:58:39,806] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 15000, global step 236432: learning rate 0.0000
[2019-04-06 15:58:47,018] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15000, global step 237546: loss 32.4548
[2019-04-06 15:58:47,019] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 15000, global step 237546: learning rate 0.0000
[2019-04-06 15:58:47,546] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4046430e-14 2.4419257e-17 6.0551206e-13 2.6374634e-16 1.0000000e+00
 1.7917079e-20 6.6781165e-19], sum to 1.0000
[2019-04-06 15:58:47,546] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0392
[2019-04-06 15:58:47,646] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.4, 93.0, 54.0, 0.0, 26.0, 25.78007249973393, 0.4083159110711272, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 919800.0000, 
sim time next is 921600.0000, 
raw observation next is [4.4, 93.0, 36.0, 0.0, 26.0, 25.80437134185435, 0.4057218798895312, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5844875346260389, 0.93, 0.12, 0.0, 0.6666666666666666, 0.6503642784878624, 0.6352406266298437, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.96473694], dtype=float32), -0.44289514]. 
=============================================
[2019-04-06 15:58:49,666] A3C_AGENT_WORKER-Thread-18 INFO:Local step 15000, global step 237998: loss 32.7697
[2019-04-06 15:58:49,667] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 15000, global step 237998: learning rate 0.0000
[2019-04-06 15:58:57,647] A3C_AGENT_WORKER-Thread-8 INFO:Local step 15000, global step 239838: loss 31.8530
[2019-04-06 15:58:57,649] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 15000, global step 239838: learning rate 0.0000
[2019-04-06 15:58:58,562] A3C_AGENT_WORKER-Thread-7 INFO:Local step 15000, global step 239996: loss 32.0604
[2019-04-06 15:58:58,564] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 15000, global step 239996: learning rate 0.0000
[2019-04-06 15:58:58,581] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-06 15:58:58,582] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:58:58,582] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:58:58,584] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run13
[2019-04-06 15:58:58,596] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 15:58:58,597] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:58:58,600] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run13
[2019-04-06 15:58:58,616] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 15:58:58,618] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 15:58:58,621] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run13
[2019-04-06 16:00:44,461] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 16:01:27,426] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 16:01:29,556] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 16:01:30,594] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 240000, evaluation results [240000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 16:01:42,724] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15000, global step 241142: loss 31.8414
[2019-04-06 16:01:42,724] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 15000, global step 241142: learning rate 0.0000
[2019-04-06 16:01:48,253] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15000, global step 241600: loss 31.9523
[2019-04-06 16:01:48,254] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 15000, global step 241600: learning rate 0.0000
[2019-04-06 16:01:49,227] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15000, global step 241671: loss 32.7202
[2019-04-06 16:01:49,228] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 15000, global step 241671: learning rate 0.0000
[2019-04-06 16:01:50,333] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15000, global step 241760: loss 31.2230
[2019-04-06 16:01:50,334] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 15000, global step 241760: learning rate 0.0000
[2019-04-06 16:01:54,244] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15000, global step 242093: loss 31.2945
[2019-04-06 16:01:54,245] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 15000, global step 242093: learning rate 0.0000
[2019-04-06 16:01:55,312] A3C_AGENT_WORKER-Thread-20 INFO:Local step 15000, global step 242179: loss 31.8033
[2019-04-06 16:01:55,313] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 15000, global step 242179: learning rate 0.0000
[2019-04-06 16:01:55,800] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15000, global step 242207: loss 31.4436
[2019-04-06 16:01:55,801] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 15000, global step 242207: learning rate 0.0000
[2019-04-06 16:01:55,833] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15000, global step 242207: loss 31.8299
[2019-04-06 16:01:56,172] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 15000, global step 242207: learning rate 0.0000
[2019-04-06 16:02:00,841] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15000, global step 242667: loss 30.8151
[2019-04-06 16:02:00,843] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 15000, global step 242667: learning rate 0.0000
[2019-04-06 16:02:07,522] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15500, global step 243259: loss 0.0395
[2019-04-06 16:02:07,522] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 15500, global step 243259: learning rate 0.0000
[2019-04-06 16:02:08,721] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15500, global step 243359: loss 0.0412
[2019-04-06 16:02:08,722] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 15500, global step 243359: learning rate 0.0000
[2019-04-06 16:02:18,651] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3950399e-11 1.1174569e-11 1.0076506e-08 4.8448479e-10 1.0000000e+00
 1.5435471e-13 2.4519102e-12], sum to 1.0000
[2019-04-06 16:02:18,651] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3794
[2019-04-06 16:02:18,754] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.45, 78.5, 0.0, 0.0, 26.0, 23.48815022328472, -0.05244560895331166, 0.0, 1.0, 47066.98530788914], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1837800.0000, 
sim time next is 1839600.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 26.0, 23.38475585422339, -0.07424159290649711, 0.0, 1.0, 47112.35215987228], 
processed observation next is [0.0, 0.30434782608695654, 0.2770083102493075, 0.78, 0.0, 0.0, 0.6666666666666666, 0.44872965451861574, 0.475252802364501, 0.0, 1.0, 0.2243445340946299], 
reward next is 0.7757, 
noisyNet noise sample is [array([1.1434811], dtype=float32), -0.80824447]. 
=============================================
[2019-04-06 16:02:25,216] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.3335475e-13 9.3760964e-14 3.3609004e-09 8.3762329e-12 1.0000000e+00
 1.3181458e-15 3.1270424e-14], sum to 1.0000
[2019-04-06 16:02:25,216] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5880
[2019-04-06 16:02:25,290] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 59.0, 0.0, 0.0, 26.0, 25.08148205696396, 0.3091879748215272, 0.0, 1.0, 45325.66328376189], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2588400.0000, 
sim time next is 2590200.0000, 
raw observation next is [-4.2, 60.5, 0.0, 0.0, 26.0, 24.91238663743584, 0.2826220998258754, 0.0, 1.0, 41993.44391045409], 
processed observation next is [1.0, 1.0, 0.34626038781163443, 0.605, 0.0, 0.0, 0.6666666666666666, 0.57603221978632, 0.5942073666086252, 0.0, 1.0, 0.19996878052597183], 
reward next is 0.8000, 
noisyNet noise sample is [array([-1.7055073], dtype=float32), 0.022243775]. 
=============================================
[2019-04-06 16:02:48,662] A3C_AGENT_WORKER-Thread-19 INFO:Local step 15500, global step 246051: loss 0.0657
[2019-04-06 16:02:48,663] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 15500, global step 246051: learning rate 0.0000
[2019-04-06 16:03:01,464] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15500, global step 246911: loss 0.0338
[2019-04-06 16:03:01,465] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 15500, global step 246911: learning rate 0.0000
[2019-04-06 16:03:07,051] A3C_AGENT_WORKER-Thread-18 INFO:Local step 15500, global step 247315: loss 0.0415
[2019-04-06 16:03:07,051] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 15500, global step 247315: learning rate 0.0000
[2019-04-06 16:03:21,806] A3C_AGENT_WORKER-Thread-7 INFO:Local step 15500, global step 248359: loss 0.0467
[2019-04-06 16:03:21,806] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 15500, global step 248359: learning rate 0.0000
[2019-04-06 16:03:22,117] A3C_AGENT_WORKER-Thread-8 INFO:Local step 15500, global step 248384: loss 0.0384
[2019-04-06 16:03:22,117] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 15500, global step 248384: learning rate 0.0000
[2019-04-06 16:03:32,064] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [3.4498819e-12 1.8418109e-13 7.6467116e-10 1.9548779e-12 1.0000000e+00
 2.9626563e-15 8.6196431e-14], sum to 1.0000
[2019-04-06 16:03:32,064] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.0695
[2019-04-06 16:03:32,140] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.7, 46.5, 0.0, 0.0, 26.0, 25.01504894921746, 0.1894671697506063, 0.0, 1.0, 38514.90001285411], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2518200.0000, 
sim time next is 2520000.0000, 
raw observation next is [-1.7, 49.0, 0.0, 0.0, 26.0, 24.97488895627242, 0.1691680635279124, 0.0, 1.0, 38402.75783826267], 
processed observation next is [1.0, 0.17391304347826086, 0.4155124653739613, 0.49, 0.0, 0.0, 0.6666666666666666, 0.581240746356035, 0.5563893545093042, 0.0, 1.0, 0.1828702754202984], 
reward next is 0.8171, 
noisyNet noise sample is [array([2.074939], dtype=float32), -1.7730112]. 
=============================================
[2019-04-06 16:03:32,144] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[68.49203]
 [68.21834]
 [67.25338]
 [65.91698]
 [65.0546 ]], R is [[68.87045288]
 [68.99834442]
 [69.12435913]
 [69.24855042]
 [69.37072754]].
[2019-04-06 16:03:35,518] A3C_AGENT_WORKER-Thread-17 INFO:Local step 16000, global step 249556: loss 20.1324
[2019-04-06 16:03:35,519] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 16000, global step 249556: learning rate 0.0000
[2019-04-06 16:03:35,688] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15500, global step 249564: loss 0.0675
[2019-04-06 16:03:35,689] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 15500, global step 249564: learning rate 0.0000
[2019-04-06 16:03:36,062] A3C_AGENT_WORKER-Thread-14 INFO:Local step 16000, global step 249587: loss 20.0257
[2019-04-06 16:03:36,063] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 16000, global step 249587: learning rate 0.0000
[2019-04-06 16:03:36,488] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.1994481e-12 1.8751066e-12 4.3032427e-09 9.3101343e-12 1.0000000e+00
 2.5721943e-15 3.3706452e-13], sum to 1.0000
[2019-04-06 16:03:36,488] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7206
[2019-04-06 16:03:36,740] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15500, global step 249635: loss 0.0565
[2019-04-06 16:03:36,741] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 15500, global step 249635: learning rate 0.0000
[2019-04-06 16:03:36,839] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.05, 43.5, 0.0, 0.0, 26.0, 24.96942610264377, 0.2607202741245402, 0.0, 1.0, 37445.146916867394], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2399400.0000, 
sim time next is 2401200.0000, 
raw observation next is [-2.4, 43.0, 0.0, 0.0, 26.0, 24.95991379065343, 0.2562777574081865, 0.0, 1.0, 44804.5421967149], 
processed observation next is [0.0, 0.8260869565217391, 0.39612188365650974, 0.43, 0.0, 0.0, 0.6666666666666666, 0.579992815887786, 0.5854259191360621, 0.0, 1.0, 0.21335496284149952], 
reward next is 0.7866, 
noisyNet noise sample is [array([-0.56841964], dtype=float32), -1.2123129]. 
=============================================
[2019-04-06 16:03:37,063] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15500, global step 249666: loss 0.0615
[2019-04-06 16:03:37,064] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 15500, global step 249666: learning rate 0.0000
[2019-04-06 16:03:37,483] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15500, global step 249719: loss 0.0823
[2019-04-06 16:03:37,484] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 15500, global step 249719: learning rate 0.0000
[2019-04-06 16:03:40,722] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15500, global step 250110: loss 0.0523
[2019-04-06 16:03:40,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 15500, global step 250110: learning rate 0.0000
[2019-04-06 16:03:41,287] A3C_AGENT_WORKER-Thread-20 INFO:Local step 15500, global step 250186: loss 0.0539
[2019-04-06 16:03:41,288] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 15500, global step 250186: learning rate 0.0000
[2019-04-06 16:03:41,986] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15500, global step 250281: loss 0.0618
[2019-04-06 16:03:41,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 15500, global step 250281: learning rate 0.0000
[2019-04-06 16:03:42,421] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15500, global step 250340: loss 0.0664
[2019-04-06 16:03:42,421] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 15500, global step 250340: learning rate 0.0000
[2019-04-06 16:03:45,145] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15500, global step 250713: loss 0.0544
[2019-04-06 16:03:45,145] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 15500, global step 250713: learning rate 0.0000
[2019-04-06 16:04:02,289] A3C_AGENT_WORKER-Thread-19 INFO:Local step 16000, global step 253127: loss 20.3713
[2019-04-06 16:04:02,298] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 16000, global step 253129: learning rate 0.0000
[2019-04-06 16:04:10,907] A3C_AGENT_WORKER-Thread-15 INFO:Local step 16000, global step 254372: loss 20.1232
[2019-04-06 16:04:10,907] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 16000, global step 254372: learning rate 0.0000
[2019-04-06 16:04:14,082] A3C_AGENT_WORKER-Thread-18 INFO:Local step 16000, global step 254790: loss 19.6364
[2019-04-06 16:04:14,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 16000, global step 254790: learning rate 0.0000
[2019-04-06 16:04:22,913] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.83448651e-16 3.06121545e-16 2.31338603e-12 4.12804810e-15
 1.00000000e+00 1.06637404e-19 1.26927847e-16], sum to 1.0000
[2019-04-06 16:04:22,913] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6943
[2019-04-06 16:04:22,971] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.6, 100.0, 0.0, 0.0, 26.0, 25.1967326615597, 0.2902785426244437, 0.0, 1.0, 55326.962535604755], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3124800.0000, 
sim time next is 3126600.0000, 
raw observation next is [2.8, 100.0, 0.0, 0.0, 26.0, 25.24600973170363, 0.2964840051169241, 0.0, 1.0, 53985.291676025554], 
processed observation next is [1.0, 0.17391304347826086, 0.5401662049861496, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6038341443086358, 0.5988280017056414, 0.0, 1.0, 0.2570728175048836], 
reward next is 0.7429, 
noisyNet noise sample is [array([-0.34346867], dtype=float32), -0.14488614]. 
=============================================
[2019-04-06 16:04:23,388] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.9894663e-12 7.0426022e-13 7.5960553e-09 1.0628330e-11 1.0000000e+00
 3.6978748e-15 1.9492743e-12], sum to 1.0000
[2019-04-06 16:04:23,389] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9259
[2019-04-06 16:04:23,453] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 26.0, 24.84051971963207, 0.2464806740132044, 0.0, 1.0, 37973.80251132593], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3024000.0000, 
sim time next is 3025800.0000, 
raw observation next is [-4.5, 68.0, 0.0, 0.0, 26.0, 24.74677054819613, 0.2243959531346295, 0.0, 1.0, 37869.62104429973], 
processed observation next is [0.0, 0.0, 0.3379501385041552, 0.68, 0.0, 0.0, 0.6666666666666666, 0.5622308790163443, 0.5747986510448765, 0.0, 1.0, 0.18033152878237968], 
reward next is 0.8197, 
noisyNet noise sample is [array([-0.15580404], dtype=float32), 0.70753753]. 
=============================================
[2019-04-06 16:04:23,491] A3C_AGENT_WORKER-Thread-8 INFO:Local step 16000, global step 256236: loss 20.4787
[2019-04-06 16:04:23,492] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 16000, global step 256236: learning rate 0.0000
[2019-04-06 16:04:23,988] A3C_AGENT_WORKER-Thread-17 INFO:Local step 16500, global step 256319: loss 2.2127
[2019-04-06 16:04:24,000] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 16500, global step 256319: learning rate 0.0000
[2019-04-06 16:04:24,857] A3C_AGENT_WORKER-Thread-14 INFO:Local step 16500, global step 256482: loss 2.5524
[2019-04-06 16:04:24,858] A3C_AGENT_WORKER-Thread-7 INFO:Local step 16000, global step 256482: loss 20.4276
[2019-04-06 16:04:24,858] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 16000, global step 256482: learning rate 0.0000
[2019-04-06 16:04:24,882] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 16500, global step 256482: learning rate 0.0000
[2019-04-06 16:04:30,952] A3C_AGENT_WORKER-Thread-13 INFO:Local step 16000, global step 257609: loss 20.6404
[2019-04-06 16:04:30,953] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 16000, global step 257609: learning rate 0.0000
[2019-04-06 16:04:31,168] A3C_AGENT_WORKER-Thread-6 INFO:Local step 16000, global step 257653: loss 20.6616
[2019-04-06 16:04:31,169] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 16000, global step 257653: learning rate 0.0000
[2019-04-06 16:04:31,574] A3C_AGENT_WORKER-Thread-3 INFO:Local step 16000, global step 257725: loss 20.2519
[2019-04-06 16:04:31,574] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 16000, global step 257725: learning rate 0.0000
[2019-04-06 16:04:31,624] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.0959116e-16 1.7950089e-16 7.4288579e-13 6.9947203e-16 1.0000000e+00
 9.6382982e-20 1.6670592e-18], sum to 1.0000
[2019-04-06 16:04:31,624] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7534
[2019-04-06 16:04:31,635] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.6488332e-16 1.4453493e-15 7.6912841e-13 1.7622195e-15 1.0000000e+00
 9.1053674e-19 1.5723441e-16], sum to 1.0000
[2019-04-06 16:04:31,636] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2752
[2019-04-06 16:04:31,698] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.95, 61.5, 0.0, 0.0, 26.0, 26.13112544850672, 0.6392192289263262, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4401000.0000, 
sim time next is 4402800.0000, 
raw observation next is [8.5, 62.0, 0.0, 0.0, 26.0, 25.79412081048491, 0.5817954496713132, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.698060941828255, 0.62, 0.0, 0.0, 0.6666666666666666, 0.6495100675404091, 0.6939318165571043, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5553612], dtype=float32), -0.6599299]. 
=============================================
[2019-04-06 16:04:31,699] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 100.0, 0.0, 0.0, 26.0, 25.66324976348052, 0.7200348902145498, 0.0, 1.0, 82435.87202347712], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3186000.0000, 
sim time next is 3187800.0000, 
raw observation next is [2.5, 100.0, 0.0, 0.0, 26.0, 25.82810205125442, 0.7196935996180333, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.5318559556786704, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6523418376045349, 0.7398978665393444, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.9081457], dtype=float32), -1.1860892]. 
=============================================
[2019-04-06 16:04:34,437] A3C_AGENT_WORKER-Thread-16 INFO:Local step 16000, global step 258278: loss 20.1183
[2019-04-06 16:04:34,437] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 16000, global step 258278: learning rate 0.0000
[2019-04-06 16:04:36,159] A3C_AGENT_WORKER-Thread-2 INFO:Local step 16000, global step 258547: loss 19.8515
[2019-04-06 16:04:36,160] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 16000, global step 258547: learning rate 0.0000
[2019-04-06 16:04:36,585] A3C_AGENT_WORKER-Thread-20 INFO:Local step 16000, global step 258616: loss 20.1658
[2019-04-06 16:04:36,586] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 16000, global step 258616: learning rate 0.0000
[2019-04-06 16:04:38,085] A3C_AGENT_WORKER-Thread-12 INFO:Local step 16000, global step 258868: loss 20.5582
[2019-04-06 16:04:38,091] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 16000, global step 258869: learning rate 0.0000
[2019-04-06 16:04:38,196] A3C_AGENT_WORKER-Thread-4 INFO:Local step 16000, global step 258886: loss 21.0693
[2019-04-06 16:04:38,199] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 16000, global step 258886: learning rate 0.0000
[2019-04-06 16:04:39,711] A3C_AGENT_WORKER-Thread-5 INFO:Local step 16000, global step 259114: loss 20.8156
[2019-04-06 16:04:39,719] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 16000, global step 259114: learning rate 0.0000
[2019-04-06 16:04:43,921] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1130888e-12 1.3529529e-12 3.3288483e-09 2.5821277e-12 1.0000000e+00
 3.0260679e-14 2.2282004e-13], sum to 1.0000
[2019-04-06 16:04:43,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9585
[2019-04-06 16:04:44,259] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.0, 70.0, 45.5, 273.0, 26.0, 24.20441849000851, 0.1986919864685137, 0.0, 1.0, 41494.04482403348], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3571200.0000, 
sim time next is 3573000.0000, 
raw observation next is [-6.5, 70.0, 88.0, 425.0, 26.0, 24.58152664100404, 0.4087345487875942, 0.0, 1.0, 148618.07759128712], 
processed observation next is [0.0, 0.34782608695652173, 0.28254847645429365, 0.7, 0.29333333333333333, 0.4696132596685083, 0.6666666666666666, 0.5484605534170033, 0.6362448495958647, 0.0, 1.0, 0.7077051313870815], 
reward next is 0.2923, 
noisyNet noise sample is [array([0.00489103], dtype=float32), 0.42955756]. 
=============================================
[2019-04-06 16:04:44,262] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.3001 ]
 [64.95136]
 [65.02781]
 [65.19865]
 [65.32646]], R is [[67.09757996]
 [67.22901154]
 [67.35935211]
 [67.4899292 ]
 [67.620224  ]].
[2019-04-06 16:04:44,599] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-06 16:04:44,600] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:04:44,600] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:04:44,602] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run14
[2019-04-06 16:04:44,624] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:04:44,627] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:04:44,629] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run14
[2019-04-06 16:04:44,652] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:04:44,654] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:04:44,657] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run14
[2019-04-06 16:04:53,637] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00689702], dtype=float32), 0.11277127]
[2019-04-06 16:04:53,637] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [7.5, 83.0, 0.0, 0.0, 26.0, 24.57469760810481, 0.2547354548406153, 0.0, 1.0, 33937.41687344]
[2019-04-06 16:04:53,637] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:04:53,638] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [3.3901149e-14 1.1407737e-14 8.0904554e-11 1.8321057e-13 1.0000000e+00
 2.8852712e-17 2.7698445e-15], sampled 0.6557787618791743
[2019-04-06 16:06:29,680] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00689702], dtype=float32), 0.11277127]
[2019-04-06 16:06:29,680] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-4.0, 71.0, 96.0, 563.5, 26.0, 26.076423935645, 0.5107623702839907, 1.0, 1.0, 0.0]
[2019-04-06 16:06:29,680] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:06:29,681] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.7773235e-13 5.4769621e-14 3.1216021e-10 8.6519154e-13 1.0000000e+00
 2.0165206e-16 1.2861831e-14], sampled 0.03669817571991918
[2019-04-06 16:06:34,936] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 16:07:08,896] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 16:07:14,834] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 16:07:15,886] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 260000, evaluation results [260000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 16:07:23,573] A3C_AGENT_WORKER-Thread-19 INFO:Local step 16500, global step 260839: loss 2.1101
[2019-04-06 16:07:23,574] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 16500, global step 260839: learning rate 0.0000
[2019-04-06 16:07:34,656] A3C_AGENT_WORKER-Thread-15 INFO:Local step 16500, global step 262002: loss 2.3502
[2019-04-06 16:07:34,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 16500, global step 262002: learning rate 0.0000
[2019-04-06 16:07:42,307] A3C_AGENT_WORKER-Thread-18 INFO:Local step 16500, global step 262858: loss 2.0643
[2019-04-06 16:07:42,308] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 16500, global step 262858: learning rate 0.0000
[2019-04-06 16:07:49,565] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.9713502e-12 2.9874681e-13 1.4461451e-09 7.2471590e-12 1.0000000e+00
 3.4892646e-15 1.1543403e-13], sum to 1.0000
[2019-04-06 16:07:49,571] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6877
[2019-04-06 16:07:49,712] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-13.0, 63.0, 0.0, 0.0, 26.0, 23.5036191708675, -0.02363147325265761, 0.0, 1.0, 43708.47646849358], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3996000.0000, 
sim time next is 3997800.0000, 
raw observation next is [-13.5, 66.0, 0.0, 0.0, 26.0, 23.47631075169058, -0.04423884751704491, 0.0, 1.0, 43421.83968189871], 
processed observation next is [1.0, 0.2608695652173913, 0.0886426592797784, 0.66, 0.0, 0.0, 0.6666666666666666, 0.4563592293075483, 0.48525371749431834, 0.0, 1.0, 0.20677066515189862], 
reward next is 0.7932, 
noisyNet noise sample is [array([0.87053347], dtype=float32), -0.66279125]. 
=============================================
[2019-04-06 16:07:53,935] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:53,935] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:53,938] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run7
[2019-04-06 16:07:54,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:07:54,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:07:54,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run7
[2019-04-06 16:07:57,644] A3C_AGENT_WORKER-Thread-8 INFO:Local step 16500, global step 264376: loss 2.6651
[2019-04-06 16:07:57,645] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 16500, global step 264376: learning rate 0.0000
[2019-04-06 16:08:00,368] A3C_AGENT_WORKER-Thread-7 INFO:Local step 16500, global step 264615: loss 2.8960
[2019-04-06 16:08:00,369] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 16500, global step 264615: learning rate 0.0000
[2019-04-06 16:08:08,229] A3C_AGENT_WORKER-Thread-6 INFO:Local step 16500, global step 265326: loss 2.3543
[2019-04-06 16:08:08,267] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 16500, global step 265326: learning rate 0.0000
[2019-04-06 16:08:10,714] A3C_AGENT_WORKER-Thread-13 INFO:Local step 16500, global step 265572: loss 2.5119
[2019-04-06 16:08:10,715] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 16500, global step 265572: learning rate 0.0000
[2019-04-06 16:08:12,176] A3C_AGENT_WORKER-Thread-3 INFO:Local step 16500, global step 265708: loss 2.5105
[2019-04-06 16:08:12,177] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 16500, global step 265708: learning rate 0.0000
[2019-04-06 16:08:15,942] A3C_AGENT_WORKER-Thread-16 INFO:Local step 16500, global step 266111: loss 2.5008
[2019-04-06 16:08:15,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 16500, global step 266111: learning rate 0.0000
[2019-04-06 16:08:20,696] A3C_AGENT_WORKER-Thread-2 INFO:Local step 16500, global step 266569: loss 2.1965
[2019-04-06 16:08:20,714] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 16500, global step 266569: learning rate 0.0000
[2019-04-06 16:08:20,990] A3C_AGENT_WORKER-Thread-20 INFO:Local step 16500, global step 266597: loss 2.3121
[2019-04-06 16:08:21,017] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 16500, global step 266597: learning rate 0.0000
[2019-04-06 16:08:22,524] A3C_AGENT_WORKER-Thread-12 INFO:Local step 16500, global step 266772: loss 2.3666
[2019-04-06 16:08:22,526] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 16500, global step 266772: learning rate 0.0000
[2019-04-06 16:08:24,673] A3C_AGENT_WORKER-Thread-4 INFO:Local step 16500, global step 267030: loss 2.5135
[2019-04-06 16:08:24,693] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 16500, global step 267030: learning rate 0.0000
[2019-04-06 16:08:26,560] A3C_AGENT_WORKER-Thread-5 INFO:Local step 16500, global step 267218: loss 2.8262
[2019-04-06 16:08:26,560] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 16500, global step 267218: learning rate 0.0000
[2019-04-06 16:08:34,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:08:34,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:08:34,068] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run7
[2019-04-06 16:08:45,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:08:45,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:08:45,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run7
[2019-04-06 16:08:51,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:08:51,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:08:51,500] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run7
[2019-04-06 16:08:56,909] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.85855047e-11 5.17482541e-13 8.37453218e-10 1.80109747e-11
 1.00000000e+00 1.37936774e-14 2.12921545e-13], sum to 1.0000
[2019-04-06 16:08:56,909] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2101
[2019-04-06 16:08:56,980] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 36.0, 0.0, 0.0, 26.0, 25.45164849552516, 0.3667291019881756, 0.0, 1.0, 28389.641473562504], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4917600.0000, 
sim time next is 4919400.0000, 
raw observation next is [0.5, 37.5, 0.0, 0.0, 26.0, 25.46127192214771, 0.3625333908663393, 0.0, 1.0, 34021.73070577314], 
processed observation next is [0.0, 0.9565217391304348, 0.4764542936288089, 0.375, 0.0, 0.0, 0.6666666666666666, 0.6217726601789758, 0.6208444636221131, 0.0, 1.0, 0.16200824145606257], 
reward next is 0.8380, 
noisyNet noise sample is [array([1.5548575], dtype=float32), -0.25529462]. 
=============================================
[2019-04-06 16:09:03,802] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.6038300e-13 2.7037855e-13 6.5087362e-09 3.5066318e-11 1.0000000e+00
 8.4753761e-15 1.3755910e-12], sum to 1.0000
[2019-04-06 16:09:03,802] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2305
[2019-04-06 16:09:04,273] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 71.0, 70.5, 156.5, 26.0, 24.36356347446054, 0.1585495546977057, 0.0, 1.0, 39443.69278231362], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4867200.0000, 
sim time next is 4869000.0000, 
raw observation next is [-3.5, 68.0, 141.0, 313.0, 26.0, 24.80491820786046, 0.3384111493474431, 0.0, 1.0, 83304.19978849636], 
processed observation next is [0.0, 0.34782608695652173, 0.36565096952908593, 0.68, 0.47, 0.34585635359116024, 0.6666666666666666, 0.567076517321705, 0.6128037164491477, 0.0, 1.0, 0.3966866656595065], 
reward next is 0.6033, 
noisyNet noise sample is [array([1.1055437], dtype=float32), 0.7202721]. 
=============================================
[2019-04-06 16:09:04,276] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.24139 ]
 [64.458824]
 [64.33031 ]
 [64.34341 ]
 [64.39083 ]], R is [[66.85746002]
 [67.00106049]
 [67.14260101]
 [67.28309631]
 [67.42219543]].
[2019-04-06 16:09:06,256] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:09:06,256] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:06,259] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run7
[2019-04-06 16:09:09,114] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:09:09,114] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:09,118] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run7
[2019-04-06 16:09:17,414] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:09:17,415] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:17,418] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run7
[2019-04-06 16:09:18,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:09:18,914] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:19,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run7
[2019-04-06 16:09:19,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:09:19,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:19,673] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run7
[2019-04-06 16:09:21,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:09:21,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:21,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run7
[2019-04-06 16:09:24,486] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:09:24,486] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:24,491] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run7
[2019-04-06 16:09:24,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:09:24,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:24,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run7
[2019-04-06 16:09:25,960] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:09:25,960] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:25,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run7
[2019-04-06 16:09:27,794] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:09:27,795] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:27,810] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run7
[2019-04-06 16:09:28,256] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:09:28,256] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:09:28,259] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run7
[2019-04-06 16:10:10,511] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.8985054e-12 1.0981988e-12 2.0695179e-08 3.8113912e-10 1.0000000e+00
 8.2241487e-15 6.4452122e-13], sum to 1.0000
[2019-04-06 16:10:10,511] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0304
[2019-04-06 16:10:10,560] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.35, 86.5, 0.0, 0.0, 26.0, 24.48544162873758, 0.1695497236187123, 0.0, 1.0, 40681.46098826132], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 538200.0000, 
sim time next is 540000.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 26.0, 24.49171940847656, 0.1667295904124394, 0.0, 1.0, 40770.179550294946], 
processed observation next is [0.0, 0.2608695652173913, 0.49307479224376743, 0.88, 0.0, 0.0, 0.6666666666666666, 0.5409766173730466, 0.5555765301374799, 0.0, 1.0, 0.19414371214426165], 
reward next is 0.8059, 
noisyNet noise sample is [array([-1.1168461], dtype=float32), 0.19921245]. 
=============================================
[2019-04-06 16:10:10,576] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[70.28464]
 [70.50331]
 [70.80577]
 [71.10354]
 [71.44106]], R is [[70.24094391]
 [70.34481812]
 [70.44868469]
 [70.55257416]
 [70.65617371]].
[2019-04-06 16:10:17,774] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1601051e-15 2.6848904e-16 1.1755831e-11 2.9306113e-14 1.0000000e+00
 4.2835370e-18 1.3088948e-17], sum to 1.0000
[2019-04-06 16:10:17,774] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3564
[2019-04-06 16:10:17,993] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 100.0, 9.0, 0.0, 26.0, 25.41889721934284, 0.4415741307398887, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1411200.0000, 
sim time next is 1413000.0000, 
raw observation next is [-0.6, 100.0, 18.0, 0.0, 26.0, 25.55990667862704, 0.4802999957580961, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.44598337950138506, 1.0, 0.06, 0.0, 0.6666666666666666, 0.62999222321892, 0.660099998586032, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.69657445], dtype=float32), -0.4396031]. 
=============================================
[2019-04-06 16:10:17,997] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[81.81345 ]
 [80.344124]
 [80.57745 ]
 [80.34757 ]
 [80.31896 ]], R is [[83.54186249]
 [83.70644379]
 [83.80805206]
 [83.78609467]
 [83.76482391]].
[2019-04-06 16:10:19,848] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.3571931e-10 1.3467025e-11 8.9937391e-09 7.1112338e-11 1.0000000e+00
 5.7733942e-14 1.0764654e-11], sum to 1.0000
[2019-04-06 16:10:19,848] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9023
[2019-04-06 16:10:19,923] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-10.6, 52.0, 0.0, 0.0, 26.0, 22.70303757914516, -0.2793303282251076, 0.0, 1.0, 46718.924849120434], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 450000.0000, 
sim time next is 451800.0000, 
raw observation next is [-10.05, 48.0, 0.0, 0.0, 26.0, 22.63762791343242, -0.2998773856066807, 0.0, 1.0, 46734.303080752994], 
processed observation next is [1.0, 0.21739130434782608, 0.18421052631578946, 0.48, 0.0, 0.0, 0.6666666666666666, 0.38646899278603514, 0.40004087146443973, 0.0, 1.0, 0.22254430038453807], 
reward next is 0.7775, 
noisyNet noise sample is [array([-0.49267352], dtype=float32), -0.05843026]. 
=============================================
[2019-04-06 16:10:23,575] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [4.0163836e-13 5.7683556e-13 3.9503110e-08 3.3428729e-12 1.0000000e+00
 1.4162695e-15 1.4171781e-14], sum to 1.0000
[2019-04-06 16:10:23,576] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3233
[2019-04-06 16:10:23,641] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.55, 75.5, 0.0, 0.0, 26.0, 24.29818165952525, 0.04525741332377155, 0.0, 1.0, 41596.08409019124], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 707400.0000, 
sim time next is 709200.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 26.0, 24.26799339067684, 0.03811806090217319, 0.0, 1.0, 41564.63796624728], 
processed observation next is [1.0, 0.21739130434782608, 0.3988919667590028, 0.76, 0.0, 0.0, 0.6666666666666666, 0.5223327825564033, 0.5127060203007244, 0.0, 1.0, 0.1979268474583204], 
reward next is 0.8021, 
noisyNet noise sample is [array([-1.0315452], dtype=float32), -0.5358797]. 
=============================================
[2019-04-06 16:10:34,453] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-06 16:10:34,457] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:10:34,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:10:34,459] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run15
[2019-04-06 16:10:34,495] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:10:34,495] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:10:34,497] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run15
[2019-04-06 16:10:34,514] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:10:34,517] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:10:34,522] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run15
[2019-04-06 16:12:21,028] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00717008], dtype=float32), 0.113989726]
[2019-04-06 16:12:21,028] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [8.100000000000001, 66.5, 288.0, 188.0, 26.0, 25.94497812694924, 0.8015452144509724, 0.0, 1.0, 0.0]
[2019-04-06 16:12:21,028] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:12:21,029] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.6143123e-14 2.2587849e-15 2.8274235e-11 5.5074563e-14 1.0000000e+00
 6.8446023e-18 6.0817331e-16], sampled 0.18193315283830525
[2019-04-06 16:12:28,598] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 16:12:40,760] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00717008], dtype=float32), 0.113989726]
[2019-04-06 16:12:40,760] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [7.0, 52.0, 154.0, 782.0, 26.0, 25.33938210926848, 0.4336217723942473, 0.0, 1.0, 0.0]
[2019-04-06 16:12:40,760] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:12:40,761] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.02083354e-13 1.73334518e-14 1.46593140e-10 3.64107616e-13
 1.00000000e+00 7.95425149e-17 6.50189182e-15], sampled 0.9900308849549987
[2019-04-06 16:13:05,547] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2417.0861 87791866.1671 515.2451
[2019-04-06 16:13:09,439] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 16:13:10,477] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 280000, evaluation results [280000.0, 2417.086098461385, 87791866.16713928, 515.2451498045025, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 16:13:14,055] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.2612758e-13 4.3525331e-12 2.0421473e-09 1.0603622e-12 1.0000000e+00
 9.7106094e-17 7.1150761e-14], sum to 1.0000
[2019-04-06 16:13:14,055] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0322
[2019-04-06 16:13:14,198] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 75.0, 0.0, 0.0, 26.0, 24.36276840435844, 0.07188049683259677, 0.0, 1.0, 41101.44063033801], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 698400.0000, 
sim time next is 700200.0000, 
raw observation next is [-3.4, 75.0, 0.0, 0.0, 26.0, 24.29415922577163, 0.06449652971856505, 0.0, 1.0, 41177.76378580235], 
processed observation next is [1.0, 0.08695652173913043, 0.368421052631579, 0.75, 0.0, 0.0, 0.6666666666666666, 0.5245132688143025, 0.5214988432395217, 0.0, 1.0, 0.19608458945620166], 
reward next is 0.8039, 
noisyNet noise sample is [array([0.47699863], dtype=float32), 0.07289979]. 
=============================================
[2019-04-06 16:13:24,192] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.3030729e-14 1.2597330e-15 2.4476675e-12 1.4845640e-14 1.0000000e+00
 6.7085299e-18 6.0309269e-17], sum to 1.0000
[2019-04-06 16:13:24,193] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8772
[2019-04-06 16:13:24,282] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.8, 83.0, 0.0, 0.0, 26.0, 25.51857597341465, 0.4408796669644681, 0.0, 1.0, 12502.285045790739], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 970200.0000, 
sim time next is 972000.0000, 
raw observation next is [8.8, 83.0, 0.0, 0.0, 26.0, 25.57202879286641, 0.4794593456180489, 0.0, 1.0, 31747.757371532585], 
processed observation next is [1.0, 0.2608695652173913, 0.7063711911357342, 0.83, 0.0, 0.0, 0.6666666666666666, 0.631002399405534, 0.659819781872683, 0.0, 1.0, 0.15117979700729803], 
reward next is 0.8488, 
noisyNet noise sample is [array([-1.6863678], dtype=float32), -0.9176286]. 
=============================================
[2019-04-06 16:13:24,294] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[83.557434]
 [83.42687 ]
 [83.23197 ]
 [82.931114]
 [83.06715 ]], R is [[84.01673126]
 [84.11703491]
 [84.13261414]
 [84.02036285]
 [84.1206131 ]].
[2019-04-06 16:13:45,825] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4270866e-18 1.9747037e-18 2.1337780e-12 4.1147120e-17 1.0000000e+00
 1.7348217e-20 4.0674991e-19], sum to 1.0000
[2019-04-06 16:13:45,826] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4555
[2019-04-06 16:13:45,936] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [11.9, 51.0, 77.0, 478.0, 26.0, 26.6460720176742, 0.7563460146234018, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1524600.0000, 
sim time next is 1526400.0000, 
raw observation next is [12.2, 50.0, 82.0, 253.0, 26.0, 26.98153580880275, 0.7942011728113694, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.8005540166204987, 0.5, 0.2733333333333333, 0.2795580110497238, 0.6666666666666666, 0.7484613174002291, 0.7647337242704565, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.49913225], dtype=float32), 0.19288439]. 
=============================================
[2019-04-06 16:13:47,561] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.8150936e-16 5.1090175e-17 3.4531143e-12 7.3925483e-16 1.0000000e+00
 6.3781125e-20 1.4852046e-17], sum to 1.0000
[2019-04-06 16:13:47,561] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1243
[2019-04-06 16:13:47,621] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.7, 97.0, 100.5, 0.0, 26.0, 25.32386911735844, 0.2751377004946254, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 907200.0000, 
sim time next is 909000.0000, 
raw observation next is [3.25, 95.0, 104.0, 0.0, 26.0, 25.23832281121241, 0.2608029848544812, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5526315789473685, 0.95, 0.3466666666666667, 0.0, 0.6666666666666666, 0.6031935676010342, 0.5869343282848271, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2395438], dtype=float32), -2.3076668]. 
=============================================
[2019-04-06 16:13:47,625] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[87.37094 ]
 [86.326584]
 [85.236694]
 [84.701866]
 [83.923325]], R is [[88.33399963]
 [88.45066071]
 [88.56615448]
 [88.68049622]
 [88.79369354]].
[2019-04-06 16:13:49,099] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.87420234e-14 3.81853633e-14 1.07541726e-10 4.99442935e-13
 1.00000000e+00 8.46692893e-18 6.87958148e-16], sum to 1.0000
[2019-04-06 16:13:49,099] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6316
[2019-04-06 16:13:49,196] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.6, 97.0, 0.0, 0.0, 26.0, 25.56543315147978, 0.5512725502366661, 0.0, 1.0, 51019.33751438201], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1659600.0000, 
sim time next is 1661400.0000, 
raw observation next is [6.05, 97.0, 0.0, 0.0, 26.0, 25.5915655261857, 0.5383168946030653, 0.0, 1.0, 22356.367733399635], 
processed observation next is [1.0, 0.21739130434782608, 0.6301939058171746, 0.97, 0.0, 0.0, 0.6666666666666666, 0.632630460515475, 0.6794389648676885, 0.0, 1.0, 0.1064588939685697], 
reward next is 0.8935, 
noisyNet noise sample is [array([0.4367376], dtype=float32), -0.5259876]. 
=============================================
[2019-04-06 16:14:41,860] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6731743e-14 5.4349801e-15 6.8315062e-11 2.4372694e-12 1.0000000e+00
 6.9375830e-17 2.1552734e-15], sum to 1.0000
[2019-04-06 16:14:41,860] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0812
[2019-04-06 16:14:41,941] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 26.0, 25.34692524775736, 0.4667029681762265, 0.0, 1.0, 43137.29225022806], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1729800.0000, 
sim time next is 1731600.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 26.0, 25.37278254154348, 0.4633711240345268, 0.0, 1.0, 42147.52524249943], 
processed observation next is [0.0, 0.043478260869565216, 0.4764542936288089, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6143985451286232, 0.6544570413448423, 0.0, 1.0, 0.2007025011547592], 
reward next is 0.7993, 
noisyNet noise sample is [array([-0.18561578], dtype=float32), -0.37787673]. 
=============================================
[2019-04-06 16:15:34,301] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1703952e-14 1.1327897e-15 2.6292128e-11 2.9961859e-14 1.0000000e+00
 8.4342735e-18 6.4034796e-16], sum to 1.0000
[2019-04-06 16:15:34,301] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2276
[2019-04-06 16:15:34,517] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 68.0, 0.0, 0.0, 26.0, 25.502581746321, 0.4731885404028471, 1.0, 1.0, 63682.8218099923], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2224800.0000, 
sim time next is 2226600.0000, 
raw observation next is [-4.55, 69.0, 0.0, 0.0, 26.0, 25.85487977466985, 0.4684735720037276, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3365650969529086, 0.69, 0.0, 0.0, 0.6666666666666666, 0.6545733145558209, 0.6561578573345759, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0243962], dtype=float32), 1.2871498]. 
=============================================
[2019-04-06 16:15:38,472] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.8543958e-12 1.3798665e-12 1.6591247e-08 1.4024821e-11 1.0000000e+00
 3.0376624e-14 6.0485904e-12], sum to 1.0000
[2019-04-06 16:15:38,472] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3887
[2019-04-06 16:15:38,558] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.7, 39.0, 0.0, 0.0, 26.0, 24.98790245987578, 0.2025436777489541, 0.0, 1.0, 39091.296648727126], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2511000.0000, 
sim time next is 2512800.0000, 
raw observation next is [-1.7, 38.0, 0.0, 0.0, 26.0, 24.9784307077655, 0.1892053921876603, 0.0, 1.0, 38920.879588855714], 
processed observation next is [1.0, 0.08695652173913043, 0.4155124653739613, 0.38, 0.0, 0.0, 0.6666666666666666, 0.5815358923137918, 0.5630684640625535, 0.0, 1.0, 0.1853375218516939], 
reward next is 0.8147, 
noisyNet noise sample is [array([0.08586974], dtype=float32), 0.678898]. 
=============================================
[2019-04-06 16:15:43,421] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.2195951e-11 8.5636897e-12 5.1159814e-09 1.6680232e-10 1.0000000e+00
 8.2214861e-14 1.4062414e-13], sum to 1.0000
[2019-04-06 16:15:43,422] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8636
[2019-04-06 16:15:43,524] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.00597580948944, 0.05950081105374339, 0.0, 1.0, 41522.979996926675], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2359800.0000, 
sim time next is 2361600.0000, 
raw observation next is [-3.4, 69.0, 19.5, 0.0, 26.0, 23.91037037433283, 0.069223161775976, 0.0, 1.0, 41889.36479302842], 
processed observation next is [0.0, 0.34782608695652173, 0.368421052631579, 0.69, 0.065, 0.0, 0.6666666666666666, 0.492530864527736, 0.5230743872586586, 0.0, 1.0, 0.19947316568108772], 
reward next is 0.8005, 
noisyNet noise sample is [array([-0.67008406], dtype=float32), 0.13372847]. 
=============================================
[2019-04-06 16:15:43,666] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5185316e-13 1.3762727e-13 1.3631607e-09 3.5618106e-12 1.0000000e+00
 2.2049456e-15 1.1947188e-13], sum to 1.0000
[2019-04-06 16:15:43,666] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4478
[2019-04-06 16:15:43,907] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.05, 43.5, 0.0, 0.0, 26.0, 24.96942610264377, 0.2607202741245402, 0.0, 1.0, 37445.146916867394], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2399400.0000, 
sim time next is 2401200.0000, 
raw observation next is [-2.4, 43.0, 0.0, 0.0, 26.0, 24.95991379065343, 0.2562777574081865, 0.0, 1.0, 44804.5421967149], 
processed observation next is [0.0, 0.8260869565217391, 0.39612188365650974, 0.43, 0.0, 0.0, 0.6666666666666666, 0.579992815887786, 0.5854259191360621, 0.0, 1.0, 0.21335496284149952], 
reward next is 0.7866, 
noisyNet noise sample is [array([0.43093187], dtype=float32), 1.381414]. 
=============================================
[2019-04-06 16:15:47,557] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9686381e-14 1.7554631e-15 1.3476532e-11 2.5263533e-15 1.0000000e+00
 1.9196162e-17 3.3353635e-16], sum to 1.0000
[2019-04-06 16:15:47,557] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5642
[2019-04-06 16:15:47,712] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 85.0, 0.0, 0.0, 26.0, 25.04196745769413, 0.377775664922633, 1.0, 1.0, 20701.752233295563], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2921400.0000, 
sim time next is 2923200.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 26.0, 24.91720594726637, 0.4025110198617031, 0.0, 1.0, 85612.4058522579], 
processed observation next is [1.0, 0.8695652173913043, 0.4349030470914128, 0.78, 0.0, 0.0, 0.6666666666666666, 0.5764338289388643, 0.634170339953901, 0.0, 1.0, 0.40767812310599], 
reward next is 0.5923, 
noisyNet noise sample is [array([-1.7275035], dtype=float32), -0.8720294]. 
=============================================
[2019-04-06 16:16:11,511] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3266154e-15 2.5259544e-18 1.2910016e-12 3.8713798e-15 1.0000000e+00
 3.5169192e-19 4.6307622e-17], sum to 1.0000
[2019-04-06 16:16:11,511] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3043
[2019-04-06 16:16:11,563] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 77.0, 34.0, 307.5, 26.0, 26.52262267335287, 0.7175463481974713, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3258000.0000, 
sim time next is 3259800.0000, 
raw observation next is [-4.0, 71.0, 9.0, 104.0, 26.0, 26.12906173493033, 0.6051273917388756, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3518005540166205, 0.71, 0.03, 0.11491712707182321, 0.6666666666666666, 0.677421811244194, 0.7017091305796251, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.10376311], dtype=float32), -0.6511842]. 
=============================================
[2019-04-06 16:16:19,099] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 16:16:19,125] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:16:19,127] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:16:19,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run16
[2019-04-06 16:16:19,144] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:16:19,146] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:16:19,147] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:16:19,147] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:16:19,151] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run16
[2019-04-06 16:16:19,165] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run16
[2019-04-06 16:18:13,770] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 16:18:46,211] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 16:18:50,818] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 16:18:51,853] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 300000, evaluation results [300000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 16:18:56,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2724452e-11 1.9846631e-12 1.2679310e-08 2.0164390e-13 1.0000000e+00
 1.4358703e-14 1.3445767e-12], sum to 1.0000
[2019-04-06 16:18:56,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3387
[2019-04-06 16:18:56,626] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.5, 65.0, 0.0, 0.0, 26.0, 25.29920402690804, 0.3557758898668566, 0.0, 1.0, 40260.44556122734], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3013200.0000, 
sim time next is 3015000.0000, 
raw observation next is [-3.75, 65.0, 0.0, 0.0, 26.0, 25.22136578697882, 0.3371006505404331, 0.0, 1.0, 39513.53202634401], 
processed observation next is [0.0, 0.9130434782608695, 0.3587257617728532, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6017804822482349, 0.6123668835134777, 0.0, 1.0, 0.18815967631592384], 
reward next is 0.8118, 
noisyNet noise sample is [array([-0.6543131], dtype=float32), -0.0667969]. 
=============================================
[2019-04-06 16:18:56,630] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.80004 ]
 [66.65344 ]
 [66.24431 ]
 [65.972336]
 [65.61572 ]], R is [[67.15821838]
 [67.29491425]
 [67.42832947]
 [67.51021576]
 [67.33152771]].
[2019-04-06 16:19:13,892] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0570747e-12 1.7630223e-12 2.4371660e-09 9.0681022e-12 1.0000000e+00
 2.4607048e-15 1.7531895e-13], sum to 1.0000
[2019-04-06 16:19:13,893] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5450
[2019-04-06 16:19:13,938] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.0, 50.0, 75.5, 613.5, 26.0, 25.49302178127103, 0.4776331379644129, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3686400.0000, 
sim time next is 3688200.0000, 
raw observation next is [4.5, 54.5, 64.0, 522.0, 26.0, 25.49452009643911, 0.4674463716555209, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5872576177285319, 0.545, 0.21333333333333335, 0.5767955801104973, 0.6666666666666666, 0.6245433413699258, 0.655815457218507, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.65271026], dtype=float32), 0.6678304]. 
=============================================
[2019-04-06 16:19:38,915] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.7396720e-14 9.0065860e-15 1.1430281e-10 1.6993184e-12 1.0000000e+00
 1.9922445e-16 5.3320365e-14], sum to 1.0000
[2019-04-06 16:19:38,915] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5046
[2019-04-06 16:19:38,983] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.10996185246686, 0.2868299143924279, 0.0, 1.0, 41723.4329227602], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3735000.0000, 
sim time next is 3736800.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.11411739129184, 0.2795661757890372, 0.0, 1.0, 41671.87035715559], 
processed observation next is [1.0, 0.2608695652173913, 0.3795013850415513, 0.65, 0.0, 0.0, 0.6666666666666666, 0.5928431159409865, 0.5931887252630124, 0.0, 1.0, 0.1984374778912171], 
reward next is 0.8016, 
noisyNet noise sample is [array([-1.3908257], dtype=float32), 0.92749345]. 
=============================================
[2019-04-06 16:19:41,582] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.4595678e-13 8.7342455e-15 9.8669597e-12 3.3002160e-13 1.0000000e+00
 1.1636540e-16 3.7034815e-14], sum to 1.0000
[2019-04-06 16:19:41,582] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7550
[2019-04-06 16:19:41,712] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.59010801985841, 0.5529688686188413, 0.0, 1.0, 36650.74111701015], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3790800.0000, 
sim time next is 3792600.0000, 
raw observation next is [-3.0, 74.0, 0.0, 0.0, 26.0, 25.60559869627094, 0.523869505287112, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.3795013850415513, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6337998913559115, 0.6746231684290374, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5301347], dtype=float32), -1.3139397]. 
=============================================
[2019-04-06 16:19:58,369] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5452305e-15 3.3844021e-15 1.7547193e-12 2.4696950e-15 1.0000000e+00
 9.2955869e-19 9.4453670e-17], sum to 1.0000
[2019-04-06 16:19:58,369] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2887
[2019-04-06 16:19:58,660] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.0, 35.0, 100.0, 744.5, 26.0, 27.09305948784415, 0.7676522397180808, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4114800.0000, 
sim time next is 4116600.0000, 
raw observation next is [4.0, 35.0, 94.0, 695.0, 26.0, 26.59423332927014, 0.7000253049577978, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5734072022160666, 0.35, 0.31333333333333335, 0.7679558011049724, 0.6666666666666666, 0.7161861107725116, 0.7333417683192659, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1460568], dtype=float32), -0.83329386]. 
=============================================
[2019-04-06 16:20:08,166] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7668019e-13 4.8379519e-13 2.4456410e-09 2.7395692e-12 1.0000000e+00
 4.6689206e-15 8.2991318e-13], sum to 1.0000
[2019-04-06 16:20:08,166] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1964
[2019-04-06 16:20:08,337] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 68.0, 0.0, 0.0, 26.0, 25.37670911660143, 0.3878986696831412, 0.0, 1.0, 44446.502252461585], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3713400.0000, 
sim time next is 3715200.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.36816283585519, 0.3857728093895552, 0.0, 1.0, 43676.839617613434], 
processed observation next is [1.0, 0.0, 0.3795013850415513, 0.71, 0.0, 0.0, 0.6666666666666666, 0.6140135696545993, 0.6285909364631851, 0.0, 1.0, 0.20798495056006397], 
reward next is 0.7920, 
noisyNet noise sample is [array([-0.77119416], dtype=float32), 0.2060884]. 
=============================================
[2019-04-06 16:20:14,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8350211e-15 3.4014999e-15 6.0351160e-13 5.5932550e-15 1.0000000e+00
 1.3799906e-19 6.0169555e-17], sum to 1.0000
[2019-04-06 16:20:14,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4063
[2019-04-06 16:20:14,892] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [9.0, 25.0, 82.0, 707.5, 26.0, 27.65963116736613, 0.911705436368326, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4982400.0000, 
sim time next is 4984200.0000, 
raw observation next is [8.5, 25.5, 72.0, 641.0, 26.0, 28.0150682705377, 0.8218324351388824, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.698060941828255, 0.255, 0.24, 0.7082872928176795, 0.6666666666666666, 0.8345890225448084, 0.7739441450462942, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.86754215], dtype=float32), 0.6223774]. 
=============================================
[2019-04-06 16:20:23,844] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:20:23,844] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:20:23,848] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run8
[2019-04-06 16:20:24,417] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.5457310e-14 2.2755554e-14 5.7527486e-11 4.1182615e-13 1.0000000e+00
 3.7999887e-17 2.7869402e-15], sum to 1.0000
[2019-04-06 16:20:24,418] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6376
[2019-04-06 16:20:24,478] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.0, 54.5, 188.0, 717.0, 26.0, 25.35908893822257, 0.4411965861271539, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4282200.0000, 
sim time next is 4284000.0000, 
raw observation next is [7.0, 57.0, 208.5, 551.0, 26.0, 25.39992907150259, 0.4448910897515538, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.6565096952908588, 0.57, 0.695, 0.6088397790055249, 0.6666666666666666, 0.6166607559585492, 0.6482970299171846, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9479353], dtype=float32), -1.2594831]. 
=============================================
[2019-04-06 16:20:24,497] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[74.22109]
 [73.90975]
 [73.74779]
 [73.21648]
 [72.47286]], R is [[74.73188019]
 [74.98456573]
 [75.23471832]
 [75.48236847]
 [75.72754669]].
[2019-04-06 16:20:27,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:20:27,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:20:27,254] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run8
[2019-04-06 16:20:43,272] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9190770e-15 2.6701618e-16 8.4505753e-13 2.5290352e-14 1.0000000e+00
 4.3901060e-18 1.7001214e-17], sum to 1.0000
[2019-04-06 16:20:43,272] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2519
[2019-04-06 16:20:43,305] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [9.8, 60.0, 0.0, 0.0, 26.0, 26.61500752825162, 0.7882970933324499, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4397400.0000, 
sim time next is 4399200.0000, 
raw observation next is [9.4, 61.0, 0.0, 0.0, 26.0, 26.44622959868195, 0.7547664057211095, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.7229916897506927, 0.61, 0.0, 0.0, 0.6666666666666666, 0.7038524665568291, 0.7515888019070366, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6311485], dtype=float32), -0.23426916]. 
=============================================
[2019-04-06 16:20:49,814] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:20:49,814] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:20:49,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run8
[2019-04-06 16:20:52,763] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:20:52,764] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:20:52,769] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run8
[2019-04-06 16:20:54,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:20:54,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:20:54,056] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run8
[2019-04-06 16:20:54,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3820909e-14 2.0575464e-14 8.5722249e-11 8.0234457e-13 1.0000000e+00
 1.5129790e-17 1.3465097e-15], sum to 1.0000
[2019-04-06 16:20:54,186] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7901
[2019-04-06 16:20:54,231] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 26.0, 25.51566275050096, 0.4717625247270281, 0.0, 1.0, 12506.99758782501], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4579200.0000, 
sim time next is 4581000.0000, 
raw observation next is [0.7, 62.0, 0.0, 0.0, 26.0, 25.44162588076912, 0.4593192707918726, 0.0, 1.0, 37065.63357133704], 
processed observation next is [1.0, 0.0, 0.4819944598337951, 0.62, 0.0, 0.0, 0.6666666666666666, 0.6201354900640933, 0.6531064235972909, 0.0, 1.0, 0.17650301700636686], 
reward next is 0.8235, 
noisyNet noise sample is [array([-2.1065443], dtype=float32), -2.0108087]. 
=============================================
[2019-04-06 16:20:54,239] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[78.448616]
 [79.86469 ]
 [79.49714 ]
 [79.536705]
 [79.689255]], R is [[77.32675934]
 [77.49393463]
 [77.5770874 ]
 [77.43691254]
 [77.40010834]].
[2019-04-06 16:21:03,834] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:21:03,834] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:03,846] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run8
[2019-04-06 16:21:06,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:21:06,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:06,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run8
[2019-04-06 16:21:10,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:21:10,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:10,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run8
[2019-04-06 16:21:14,772] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.1868793e-13 1.4719137e-13 6.1671383e-11 1.0305624e-13 1.0000000e+00
 5.7392918e-18 2.3946970e-15], sum to 1.0000
[2019-04-06 16:21:14,772] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5361
[2019-04-06 16:21:14,831] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 37.0, 0.0, 0.0, 26.0, 25.80004327846036, 0.5672151673275523, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5004000.0000, 
sim time next is 5005800.0000, 
raw observation next is [3.0, 35.5, 0.0, 0.0, 26.0, 25.60700751800418, 0.4701958340217309, 0.0, 1.0, 38664.9401232539], 
processed observation next is [1.0, 0.9565217391304348, 0.5457063711911359, 0.355, 0.0, 0.0, 0.6666666666666666, 0.6339172931670151, 0.6567319446739103, 0.0, 1.0, 0.18411876249168524], 
reward next is 0.8159, 
noisyNet noise sample is [array([0.48133805], dtype=float32), 0.1279877]. 
=============================================
[2019-04-06 16:21:15,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:21:15,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:15,886] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run8
[2019-04-06 16:21:18,625] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.5660656e-15 1.3820829e-14 3.2439270e-11 3.5750060e-13 1.0000000e+00
 7.9402109e-18 7.5491737e-16], sum to 1.0000
[2019-04-06 16:21:18,625] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3444
[2019-04-06 16:21:18,666] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.0, 24.0, 0.0, 0.0, 26.0, 25.98077356888541, 0.6253701845306695, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4991400.0000, 
sim time next is 4993200.0000, 
raw observation next is [6.0, 23.0, 0.0, 0.0, 26.0, 26.32327287867116, 0.6623150067665848, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.6288088642659281, 0.23, 0.0, 0.0, 0.6666666666666666, 0.6936060732225965, 0.720771668922195, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.87545335], dtype=float32), -0.66886795]. 
=============================================
[2019-04-06 16:21:19,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:21:19,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:19,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run8
[2019-04-06 16:21:19,728] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:21:19,728] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:19,732] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run8
[2019-04-06 16:21:19,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:21:19,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:19,900] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run8
[2019-04-06 16:21:20,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:21:20,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:20,392] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run8
[2019-04-06 16:21:23,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:21:23,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:23,248] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run8
[2019-04-06 16:21:23,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:21:23,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:23,984] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run8
[2019-04-06 16:21:24,293] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:21:24,294] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:24,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run8
[2019-04-06 16:21:35,753] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.2839239e-12 9.1777551e-13 2.0330724e-09 5.3625169e-12 1.0000000e+00
 1.3710790e-14 1.6548096e-13], sum to 1.0000
[2019-04-06 16:21:35,753] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6815
[2019-04-06 16:21:36,130] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.7, 93.0, 10.5, 0.0, 26.0, 21.36797546653545, -0.5213393776434008, 0.0, 1.0, 40356.15260218818], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 28800.0000, 
sim time next is 30600.0000, 
raw observation next is [7.7, 93.0, 21.0, 0.0, 26.0, 21.84245632386681, -0.3671762368306415, 0.0, 1.0, 91056.73035213821], 
processed observation next is [0.0, 0.34782608695652173, 0.6759002770083103, 0.93, 0.07, 0.0, 0.6666666666666666, 0.3202046936555674, 0.37760792105645286, 0.0, 1.0, 0.43360347786732484], 
reward next is 0.5664, 
noisyNet noise sample is [array([1.0461415], dtype=float32), -0.49867705]. 
=============================================
[2019-04-06 16:21:42,777] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 16:21:42,789] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:21:42,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:42,791] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run17
[2019-04-06 16:21:42,833] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:21:42,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:42,835] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run17
[2019-04-06 16:21:42,870] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:21:42,870] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:21:42,873] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run17
[2019-04-06 16:23:47,241] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2455.1234 79914340.2400 535.0996
[2019-04-06 16:24:22,766] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 16:24:26,498] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 16:24:27,535] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 320000, evaluation results [320000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2455.1233888037063, 79914340.24000935, 535.0996202443389, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 16:24:57,046] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3337498e-15 1.1597321e-16 1.1843056e-12 2.4066019e-15 1.0000000e+00
 2.9296777e-18 9.5059532e-16], sum to 1.0000
[2019-04-06 16:24:57,046] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7495
[2019-04-06 16:24:57,116] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 50.0, 110.0, 611.0, 26.0, 25.58459613956564, 0.3591375272923165, 1.0, 1.0, 24820.805173622783], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 738000.0000, 
sim time next is 739800.0000, 
raw observation next is [0.5, 47.5, 89.0, 773.0, 26.0, 25.3588383679842, 0.3820715348137063, 1.0, 1.0, 18680.59799159462], 
processed observation next is [1.0, 0.5652173913043478, 0.4764542936288089, 0.475, 0.2966666666666667, 0.8541436464088398, 0.6666666666666666, 0.6132365306653501, 0.6273571782712354, 1.0, 1.0, 0.08895522853140295], 
reward next is 0.9110, 
noisyNet noise sample is [array([0.23874034], dtype=float32), 0.74603844]. 
=============================================
[2019-04-06 16:25:02,291] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0066645e-13 3.8018666e-13 4.7657316e-11 1.8715728e-12 1.0000000e+00
 1.2442163e-15 7.0919887e-14], sum to 1.0000
[2019-04-06 16:25:02,291] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1319
[2019-04-06 16:25:02,388] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.55, 71.0, 0.0, 0.0, 26.0, 24.20674030497852, 0.1122097033845663, 0.0, 1.0, 41573.04441875985], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 783000.0000, 
sim time next is 784800.0000, 
raw observation next is [-7.8, 71.0, 0.0, 0.0, 26.0, 24.08230814163156, 0.08038458759727565, 0.0, 1.0, 41541.700566405445], 
processed observation next is [1.0, 0.08695652173913043, 0.24653739612188366, 0.71, 0.0, 0.0, 0.6666666666666666, 0.50685901180263, 0.5267948625324252, 0.0, 1.0, 0.19781762174478784], 
reward next is 0.8022, 
noisyNet noise sample is [array([-1.035671], dtype=float32), 0.9917199]. 
=============================================
[2019-04-06 16:25:09,888] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.7431200e-12 1.7515451e-13 2.6217226e-10 4.4343324e-13 1.0000000e+00
 3.1119042e-15 1.2063511e-13], sum to 1.0000
[2019-04-06 16:25:09,888] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4017
[2019-04-06 16:25:10,014] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-11.2, 55.0, 0.0, 0.0, 26.0, 23.55335951334252, -0.09116684501305476, 0.0, 1.0, 45493.1880726346], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 437400.0000, 
sim time next is 439200.0000, 
raw observation next is [-11.2, 55.0, 0.0, 0.0, 26.0, 23.34878504340328, -0.1232779695815402, 0.0, 1.0, 45687.43651215464], 
processed observation next is [1.0, 0.08695652173913043, 0.15235457063711913, 0.55, 0.0, 0.0, 0.6666666666666666, 0.4457320869502732, 0.4589073434728199, 0.0, 1.0, 0.21755922148645068], 
reward next is 0.7824, 
noisyNet noise sample is [array([-0.23782268], dtype=float32), -1.9695159]. 
=============================================
[2019-04-06 16:25:17,416] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0743915e-15 6.6993043e-16 4.7544442e-12 2.2119644e-14 1.0000000e+00
 7.0480677e-18 8.3799186e-17], sum to 1.0000
[2019-04-06 16:25:17,427] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7389
[2019-04-06 16:25:17,827] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 86.0, 0.0, 0.0, 26.0, 25.04323000829292, 0.3204382987519378, 1.0, 1.0, 59378.0114727559], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 846000.0000, 
sim time next is 847800.0000, 
raw observation next is [-3.65, 84.5, 0.0, 0.0, 26.0, 25.04767158530581, 0.2681164306044506, 1.0, 1.0, 8229.238248139936], 
processed observation next is [1.0, 0.8260869565217391, 0.3614958448753463, 0.845, 0.0, 0.0, 0.6666666666666666, 0.5873059654421509, 0.5893721435348168, 1.0, 1.0, 0.03918684880066636], 
reward next is 0.9608, 
noisyNet noise sample is [array([-1.2713069], dtype=float32), 0.69854593]. 
=============================================
[2019-04-06 16:25:41,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4692411e-16 1.5604762e-17 1.5114138e-12 1.5914740e-15 1.0000000e+00
 1.9386215e-20 5.0580940e-17], sum to 1.0000
[2019-04-06 16:25:41,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2838
[2019-04-06 16:25:41,207] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 88.5, 0.0, 26.0, 25.77855220910201, 0.5440307429111905, 1.0, 1.0, 8953.600959601898], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1346400.0000, 
sim time next is 1348200.0000, 
raw observation next is [1.1, 92.0, 71.0, 0.0, 26.0, 25.85070378339378, 0.543282204762809, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.92, 0.23666666666666666, 0.0, 0.6666666666666666, 0.6542253152828149, 0.6810940682542697, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.11611489], dtype=float32), 1.8185825]. 
=============================================
[2019-04-06 16:25:41,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.07659117e-13 1.17400447e-13 4.72375854e-11 1.41828281e-12
 1.00000000e+00 1.01980054e-16 1.38650018e-14], sum to 1.0000
[2019-04-06 16:25:41,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3149
[2019-04-06 16:25:41,468] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.1, 83.0, 0.0, 0.0, 26.0, 24.85823409579979, 0.2414517557507315, 0.0, 1.0, 42894.45425789562], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 599400.0000, 
sim time next is 601200.0000, 
raw observation next is [-3.4, 83.0, 0.0, 0.0, 26.0, 24.79732997037337, 0.2271320371680123, 0.0, 1.0, 42699.18951192994], 
processed observation next is [0.0, 1.0, 0.368421052631579, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5664441641977808, 0.5757106790560041, 0.0, 1.0, 0.20332947386633304], 
reward next is 0.7967, 
noisyNet noise sample is [array([0.3350003], dtype=float32), 0.5851203]. 
=============================================
[2019-04-06 16:26:11,306] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.21653053e-15 4.04962151e-17 1.97631980e-11 1.03401236e-16
 1.00000000e+00 1.71605080e-19 4.21074736e-17], sum to 1.0000
[2019-04-06 16:26:11,306] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7585
[2019-04-06 16:26:11,382] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.8, 83.0, 0.0, 0.0, 26.0, 25.57202879286641, 0.4794593456180489, 0.0, 1.0, 31747.757371532585], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 972000.0000, 
sim time next is 973800.0000, 
raw observation next is [9.4, 83.0, 0.0, 0.0, 26.0, 25.6257479224292, 0.4490015600705989, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.7229916897506927, 0.83, 0.0, 0.0, 0.6666666666666666, 0.6354789935357665, 0.6496671866901996, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16969751], dtype=float32), 1.0169963]. 
=============================================
[2019-04-06 16:26:18,341] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2454865e-13 1.5089753e-14 3.7285014e-10 9.8654442e-14 1.0000000e+00
 3.2399304e-16 7.6508536e-14], sum to 1.0000
[2019-04-06 16:26:18,342] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6744
[2019-04-06 16:26:18,505] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 24.56031126187417, 0.1637731270333933, 0.0, 1.0, 38502.56259296218], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 889200.0000, 
sim time next is 891000.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 24.99306223958927, 0.2482362043018288, 1.0, 1.0, 44526.41728565656], 
processed observation next is [1.0, 0.30434782608695654, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.5827551866324393, 0.5827454014339429, 1.0, 1.0, 0.21203055850312647], 
reward next is 0.7880, 
noisyNet noise sample is [array([-0.93848544], dtype=float32), -0.59575176]. 
=============================================
[2019-04-06 16:26:18,509] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[77.22176]
 [77.25858]
 [77.31591]
 [77.38985]
 [77.43579]], R is [[79.10043335]
 [79.126091  ]
 [79.15060425]
 [79.17405701]
 [79.19688416]].
[2019-04-06 16:26:26,275] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0755082e-14 1.8261598e-14 2.3244859e-10 5.4657542e-14 1.0000000e+00
 4.8324176e-17 3.7066170e-15], sum to 1.0000
[2019-04-06 16:26:26,275] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2642
[2019-04-06 16:26:26,315] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.7, 80.0, 0.0, 0.0, 26.0, 25.66619024769813, 0.614232893988135, 0.0, 1.0, 18727.03349702862], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1148400.0000, 
sim time next is 1150200.0000, 
raw observation next is [12.7, 82.0, 0.0, 0.0, 26.0, 25.67809700659674, 0.6162864369939469, 0.0, 1.0, 18725.02271692125], 
processed observation next is [0.0, 0.30434782608695654, 0.8144044321329641, 0.82, 0.0, 0.0, 0.6666666666666666, 0.639841417216395, 0.7054288123313156, 0.0, 1.0, 0.08916677484248213], 
reward next is 0.9108, 
noisyNet noise sample is [array([1.7604016], dtype=float32), -1.0412663]. 
=============================================
[2019-04-06 16:26:26,969] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7032141e-16 4.4430945e-17 9.3697012e-13 3.9515458e-16 1.0000000e+00
 2.0021055e-21 9.1298232e-18], sum to 1.0000
[2019-04-06 16:26:26,970] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3613
[2019-04-06 16:26:27,004] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [13.3, 80.0, 107.0, 117.0, 26.0, 26.95411750139452, 0.8355135325387901, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1072800.0000, 
sim time next is 1074600.0000, 
raw observation next is [14.4, 75.0, 114.0, 0.0, 26.0, 27.17384251275301, 0.8641380623159479, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.8614958448753465, 0.75, 0.38, 0.0, 0.6666666666666666, 0.7644868760627507, 0.7880460207719827, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0765189], dtype=float32), 1.4915011]. 
=============================================
[2019-04-06 16:26:32,467] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6164132e-14 1.4229194e-15 9.8235075e-12 9.2138770e-15 1.0000000e+00
 7.7903811e-17 1.8539395e-16], sum to 1.0000
[2019-04-06 16:26:32,471] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6426
[2019-04-06 16:26:32,514] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [13.8, 100.0, 98.0, 0.0, 26.0, 24.91604263546672, 0.4654685462692649, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1256400.0000, 
sim time next is 1258200.0000, 
raw observation next is [13.8, 100.0, 95.0, 0.0, 26.0, 24.81652266749461, 0.4563009582959885, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.844875346260388, 1.0, 0.31666666666666665, 0.0, 0.6666666666666666, 0.5680435556245508, 0.6521003194319962, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7050474], dtype=float32), -0.112867214]. 
=============================================
[2019-04-06 16:27:30,275] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6112158e-15 3.6892240e-15 2.6593172e-11 1.2387801e-14 1.0000000e+00
 7.5177838e-18 9.8046327e-17], sum to 1.0000
[2019-04-06 16:27:30,275] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2002
[2019-04-06 16:27:30,522] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.3, 73.0, 102.0, 451.0, 26.0, 25.98020086031194, 0.4309613717150306, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2194200.0000, 
sim time next is 2196000.0000, 
raw observation next is [-5.0, 71.0, 109.5, 225.5, 26.0, 26.01545503245368, 0.4176792926713171, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.32409972299168976, 0.71, 0.365, 0.24917127071823206, 0.6666666666666666, 0.6679545860378067, 0.6392264308904391, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2031128], dtype=float32), 0.0962062]. 
=============================================
[2019-04-06 16:27:30,526] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[83.628235]
 [81.428734]
 [80.29488 ]
 [78.37418 ]
 [75.932   ]], R is [[84.7806015 ]
 [84.93279266]
 [85.08346558]
 [85.2326355 ]
 [85.17645264]].
[2019-04-06 16:27:40,596] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 16:27:40,603] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:27:40,603] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:27:40,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run18
[2019-04-06 16:27:40,629] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:27:40,630] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:27:40,632] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run18
[2019-04-06 16:27:40,655] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:27:40,657] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:27:40,660] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run18
[2019-04-06 16:28:55,652] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00739456], dtype=float32), 0.11556865]
[2019-04-06 16:28:55,652] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-15.96714006, 77.11307134, 0.0, 0.0, 26.0, 22.48950917281642, -0.1624056616138355, 0.0, 1.0, 149922.23652508075]
[2019-04-06 16:28:55,652] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 16:28:55,653] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [5.8906317e-11 2.1114031e-11 1.8025780e-08 1.8826343e-10 1.0000000e+00
 1.9181342e-13 6.6553412e-12], sampled 0.6227188681178515
[2019-04-06 16:29:38,546] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 16:30:15,786] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 16:30:20,533] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 16:30:21,571] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 340000, evaluation results [340000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 16:30:21,614] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.0514972e-14 3.4624166e-14 3.2772565e-10 2.3704945e-14 1.0000000e+00
 4.1742056e-16 1.5737130e-15], sum to 1.0000
[2019-04-06 16:30:21,615] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6993
[2019-04-06 16:30:21,741] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.7874459e-16 9.3287482e-15 1.5603686e-10 2.8660743e-13 1.0000000e+00
 4.4643632e-18 1.5574033e-15], sum to 1.0000
[2019-04-06 16:30:21,741] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9700
[2019-04-06 16:30:21,839] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 71.0, 0.0, 0.0, 26.0, 25.22164066694283, 0.3966006775394103, 0.0, 1.0, 44655.66136807681], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2239200.0000, 
sim time next is 2241000.0000, 
raw observation next is [-5.9, 73.0, 0.0, 0.0, 26.0, 25.03946167325106, 0.3091253002022761, 0.0, 1.0, 44771.58927521622], 
processed observation next is [1.0, 0.9565217391304348, 0.2991689750692521, 0.73, 0.0, 0.0, 0.6666666666666666, 0.5866218061042551, 0.603041766734092, 0.0, 1.0, 0.21319804416769628], 
reward next is 0.7868, 
noisyNet noise sample is [array([0.32680348], dtype=float32), 1.877328]. 
=============================================
[2019-04-06 16:30:21,857] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[78.03556 ]
 [77.338684]
 [78.00378 ]
 [80.26531 ]
 [80.8092  ]], R is [[77.1838913 ]
 [77.19940948]
 [77.21064758]
 [77.18595886]
 [77.043396  ]].
[2019-04-06 16:30:21,863] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.6, 32.0, 0.0, 0.0, 26.0, 25.66014298769075, 0.1747826764033261, 1.0, 1.0, 3113.4019450384226], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2568600.0000, 
sim time next is 2570400.0000, 
raw observation next is [0.5, 35.0, 0.0, 0.0, 26.0, 25.01435674268702, 0.3387119357487522, 1.0, 1.0, 93957.65147350235], 
processed observation next is [1.0, 0.782608695652174, 0.4764542936288089, 0.35, 0.0, 0.0, 0.6666666666666666, 0.5845297285572517, 0.6129039785829175, 1.0, 1.0, 0.44741738796905883], 
reward next is 0.5526, 
noisyNet noise sample is [array([2.0648813], dtype=float32), -1.126629]. 
=============================================
[2019-04-06 16:31:14,093] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4455513e-16 2.7427280e-15 4.7997006e-12 1.0496344e-13 1.0000000e+00
 5.6592182e-19 3.8626724e-17], sum to 1.0000
[2019-04-06 16:31:14,094] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9866
[2019-04-06 16:31:14,306] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.4, 57.5, 109.0, 788.0, 26.0, 26.1215985365259, 0.5801603939647668, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2727000.0000, 
sim time next is 2728800.0000, 
raw observation next is [-4.8, 56.0, 105.5, 760.5, 26.0, 26.50752470544867, 0.6300019622574408, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3296398891966759, 0.56, 0.3516666666666667, 0.8403314917127072, 0.6666666666666666, 0.7089603921207225, 0.7100006540858136, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.95126957], dtype=float32), -0.25191507]. 
=============================================
[2019-04-06 16:31:33,342] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.0778342e-13 2.1693404e-12 2.9458511e-09 1.0165134e-11 1.0000000e+00
 1.3207328e-15 1.7900336e-13], sum to 1.0000
[2019-04-06 16:31:33,343] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6967
[2019-04-06 16:31:33,387] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 39.0, 91.5, 724.0, 26.0, 25.11709159150148, 0.3645796427223548, 0.0, 1.0, 18702.64314491442], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3078000.0000, 
sim time next is 3079800.0000, 
raw observation next is [0.5, 39.5, 84.0, 673.0, 26.0, 25.12733424884191, 0.366575038564407, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.4764542936288089, 0.395, 0.28, 0.7436464088397791, 0.6666666666666666, 0.5939445207368257, 0.6221916795214689, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.00112276], dtype=float32), -0.5626348]. 
=============================================
[2019-04-06 16:31:46,112] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.2535277e-14 7.7173299e-15 5.6808031e-12 1.3101663e-13 1.0000000e+00
 1.0110613e-17 1.3041705e-16], sum to 1.0000
[2019-04-06 16:31:46,112] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4540
[2019-04-06 16:31:46,181] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 26.0, 25.66899262590162, 0.5359840725076195, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3448800.0000, 
sim time next is 3450600.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 26.0, 25.35991125220952, 0.4598896527646321, 0.0, 1.0, 85100.86578238773], 
processed observation next is [1.0, 0.9565217391304348, 0.4903047091412743, 0.86, 0.0, 0.0, 0.6666666666666666, 0.6133259376841268, 0.653296550921544, 0.0, 1.0, 0.4052422180113701], 
reward next is 0.5948, 
noisyNet noise sample is [array([1.0740011], dtype=float32), 0.1140239]. 
=============================================
[2019-04-06 16:31:52,007] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2665995e-15 8.8123540e-16 3.3602515e-10 6.1861112e-13 1.0000000e+00
 2.4444875e-18 2.5467992e-15], sum to 1.0000
[2019-04-06 16:31:52,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4994
[2019-04-06 16:31:52,076] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 67.0, 61.0, 513.0, 26.0, 26.13122232784925, 0.615744810550198, 1.0, 1.0, 31983.590345535747], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3429000.0000, 
sim time next is 3430800.0000, 
raw observation next is [2.0, 67.0, 36.5, 317.0, 26.0, 26.45301851660527, 0.4663955582598429, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.67, 0.12166666666666667, 0.35027624309392263, 0.6666666666666666, 0.7044182097171058, 0.6554651860866143, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3754979], dtype=float32), 0.21352606]. 
=============================================
[2019-04-06 16:32:07,894] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8526696e-15 8.9121207e-15 9.5927797e-12 7.7942235e-15 1.0000000e+00
 3.7128238e-18 4.4819261e-16], sum to 1.0000
[2019-04-06 16:32:07,894] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1023
[2019-04-06 16:32:08,040] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [10.0, 22.5, 118.0, 860.0, 26.0, 27.93775759472444, 0.8539724206662528, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5059800.0000, 
sim time next is 5061600.0000, 
raw observation next is [11.0, 20.0, 114.5, 839.5, 26.0, 27.5217315306325, 0.9528403631013239, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.7673130193905818, 0.2, 0.38166666666666665, 0.9276243093922651, 0.6666666666666666, 0.7934776275527083, 0.817613454367108, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1703699], dtype=float32), -0.29442808]. 
=============================================
[2019-04-06 16:32:08,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:32:08,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:32:08,208] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run9
[2019-04-06 16:32:10,428] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:32:10,428] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:32:10,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run9
[2019-04-06 16:32:13,654] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.4206598e-14 2.1813282e-15 2.9936159e-10 2.0865825e-14 1.0000000e+00
 1.1874188e-18 2.7781818e-16], sum to 1.0000
[2019-04-06 16:32:13,655] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4012
[2019-04-06 16:32:13,680] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.5, 52.5, 0.0, 0.0, 26.0, 25.9422075500676, 0.6046332094762285, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4649400.0000, 
sim time next is 4651200.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 26.0, 25.66408344668046, 0.5561971477778315, 0.0, 1.0, 14153.097717012162], 
processed observation next is [1.0, 0.8695652173913043, 0.518005540166205, 0.52, 0.0, 0.0, 0.6666666666666666, 0.6386736205567051, 0.6853990492592771, 0.0, 1.0, 0.06739570341434363], 
reward next is 0.9326, 
noisyNet noise sample is [array([-0.52080137], dtype=float32), 1.1238146]. 
=============================================
[2019-04-06 16:32:19,298] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5924921e-14 6.3757176e-16 3.5697272e-12 8.7703079e-14 1.0000000e+00
 3.2376044e-18 3.4426427e-17], sum to 1.0000
[2019-04-06 16:32:19,299] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3102
[2019-04-06 16:32:19,410] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 92.0, 63.0, 0.0, 26.0, 25.96236840696961, 0.5206852941281491, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4696200.0000, 
sim time next is 4698000.0000, 
raw observation next is [0.0, 92.0, 89.0, 0.0, 26.0, 26.14584309904588, 0.5242931851173194, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.46260387811634357, 0.92, 0.2966666666666667, 0.0, 0.6666666666666666, 0.6788202582538233, 0.6747643950391065, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17262852], dtype=float32), 0.06561845]. 
=============================================
[2019-04-06 16:32:19,417] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[87.56353 ]
 [86.223206]
 [84.58036 ]
 [83.06778 ]
 [82.412605]], R is [[87.5104599 ]
 [87.63535309]
 [87.75900269]
 [87.79624176]
 [87.73332214]].
[2019-04-06 16:32:34,099] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:32:34,099] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:32:34,136] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run9
[2019-04-06 16:32:36,710] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:32:36,710] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:32:36,714] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run9
[2019-04-06 16:32:39,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:32:39,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:32:39,985] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run9
[2019-04-06 16:32:50,172] A3C_AGENT_WORKER-Thread-7 INFO:Evaluating...
[2019-04-06 16:32:50,178] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:32:50,178] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:32:50,179] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:32:50,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run19
[2019-04-06 16:32:50,195] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:32:50,196] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:32:50,198] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:32:50,200] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run19
[2019-04-06 16:32:50,215] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run19
[2019-04-06 16:33:17,731] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00744851], dtype=float32), 0.11672861]
[2019-04-06 16:33:17,731] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-3.4, 69.0, 0.0, 0.0, 26.0, 24.85304246484115, 0.1846873395529443, 0.0, 1.0, 42266.27973786812]
[2019-04-06 16:33:17,731] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:33:17,732] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.3756706e-12 5.3581689e-13 1.1272755e-09 6.8046224e-12 1.0000000e+00
 3.8200932e-15 1.7754533e-13], sampled 0.11118411536248507
[2019-04-06 16:34:49,511] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 16:35:29,466] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 16:35:33,569] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 16:35:34,610] A3C_AGENT_WORKER-Thread-7 INFO:Global step: 360000, evaluation results [360000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 16:35:40,145] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:35:40,145] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:35:40,148] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run9
[2019-04-06 16:35:47,874] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.0252384e-14 2.4467476e-16 7.7271661e-12 3.1280446e-14 1.0000000e+00
 8.2135344e-19 1.3887432e-16], sum to 1.0000
[2019-04-06 16:35:47,874] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6785
[2019-04-06 16:35:48,186] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.25, 61.0, 139.0, 484.0, 26.0, 25.80053124678339, 0.4627841314148037, 1.0, 1.0, 22341.152782608726], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 135000.0000, 
sim time next is 136800.0000, 
raw observation next is [-6.7, 61.0, 143.5, 295.0, 26.0, 25.93664462459436, 0.4547686001417452, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.2770083102493075, 0.61, 0.47833333333333333, 0.3259668508287293, 0.6666666666666666, 0.6613870520495301, 0.6515895333805818, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2074752], dtype=float32), -0.10981271]. 
=============================================
[2019-04-06 16:35:50,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:35:50,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:35:50,136] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run9
[2019-04-06 16:36:00,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:36:00,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:36:00,623] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run9
[2019-04-06 16:36:09,035] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6497222e-15 1.1238366e-16 6.4195038e-11 7.5357445e-14 1.0000000e+00
 4.1422051e-19 1.7022971e-15], sum to 1.0000
[2019-04-06 16:36:09,035] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2025
[2019-04-06 16:36:09,149] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.0, 25.0, 17.0, 152.0, 26.0, 27.21153110534608, 0.6694150549200996, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4989600.0000, 
sim time next is 4991400.0000, 
raw observation next is [6.0, 24.0, 0.0, 0.0, 26.0, 25.98077356888541, 0.6253701845306695, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6288088642659281, 0.24, 0.0, 0.0, 0.6666666666666666, 0.6650644640737843, 0.7084567281768899, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6738298], dtype=float32), 1.3038044]. 
=============================================
[2019-04-06 16:36:11,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:36:11,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:36:11,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run9
[2019-04-06 16:36:16,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:36:16,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:36:16,528] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run9
[2019-04-06 16:36:22,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:36:22,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:36:22,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run9
[2019-04-06 16:36:23,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:36:23,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:36:23,651] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run9
[2019-04-06 16:36:24,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:36:24,171] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:36:24,174] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run9
[2019-04-06 16:36:24,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:36:24,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:36:24,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run9
[2019-04-06 16:36:24,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:36:24,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:36:24,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run9
[2019-04-06 16:36:26,250] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:36:26,250] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:36:26,254] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run9
[2019-04-06 16:36:43,654] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.54755352e-13 1.27630535e-14 2.52849047e-10 3.28120452e-13
 1.00000000e+00 2.68568922e-16 3.51510406e-14], sum to 1.0000
[2019-04-06 16:36:43,654] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7656
[2019-04-06 16:36:43,984] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 96.0, 0.0, 0.0, 26.0, 25.03083892954923, 0.2156821832117034, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 500400.0000, 
sim time next is 502200.0000, 
raw observation next is [1.1, 96.0, 0.0, 0.0, 26.0, 24.72985180219574, 0.1781970361254603, 1.0, 1.0, 47775.03417498234], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.96, 0.0, 0.0, 0.6666666666666666, 0.5608209835163116, 0.5593990120418201, 1.0, 1.0, 0.22750016273801116], 
reward next is 0.7725, 
noisyNet noise sample is [array([-0.44734246], dtype=float32), -0.42330602]. 
=============================================
[2019-04-06 16:37:05,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4365969e-13 1.4159117e-13 1.6470061e-10 3.3780400e-13 1.0000000e+00
 7.1825046e-17 2.2375815e-14], sum to 1.0000
[2019-04-06 16:37:05,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3753
[2019-04-06 16:37:05,687] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 26.0, 22.87885687748418, -0.213436804110604, 0.0, 1.0, 44801.28975385191], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 192600.0000, 
sim time next is 194400.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 26.0, 22.74115723132353, -0.2439252538649891, 0.0, 1.0, 44934.8109452691], 
processed observation next is [1.0, 0.2608695652173913, 0.21606648199445982, 0.78, 0.0, 0.0, 0.6666666666666666, 0.39509643594362753, 0.4186915820450037, 0.0, 1.0, 0.21397529021556713], 
reward next is 0.7860, 
noisyNet noise sample is [array([1.1787691], dtype=float32), -0.52619064]. 
=============================================
[2019-04-06 16:37:32,112] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.0260653e-12 2.3941253e-12 2.2113192e-10 1.2068172e-11 1.0000000e+00
 1.4691578e-15 5.7056641e-14], sum to 1.0000
[2019-04-06 16:37:32,112] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6356
[2019-04-06 16:37:32,374] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 54.0, 55.0, 26.5, 26.0, 24.87719647224227, 0.2227260340197465, 0.0, 1.0, 44767.058319824915], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 662400.0000, 
sim time next is 664200.0000, 
raw observation next is [-0.8999999999999999, 55.5, 27.0, 15.0, 26.0, 24.88801265194335, 0.2118475376732372, 0.0, 1.0, 38897.08549205649], 
processed observation next is [0.0, 0.6956521739130435, 0.43767313019390586, 0.555, 0.09, 0.016574585635359115, 0.6666666666666666, 0.5740010543286124, 0.570615845891079, 0.0, 1.0, 0.18522421662884042], 
reward next is 0.8148, 
noisyNet noise sample is [array([0.1789171], dtype=float32), -0.5366714]. 
=============================================
[2019-04-06 16:37:34,051] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2757933e-11 1.7357032e-11 3.0055649e-08 3.5396193e-11 1.0000000e+00
 1.7092092e-13 4.3101447e-12], sum to 1.0000
[2019-04-06 16:37:34,051] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9909
[2019-04-06 16:37:34,087] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.35, 76.5, 0.0, 0.0, 26.0, 24.27270208793118, 0.3068931701676618, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1207800.0000, 
sim time next is 1209600.0000, 
raw observation next is [16.1, 78.0, 0.0, 0.0, 26.0, 24.19173431891261, 0.2903485918377566, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.0, 0.9085872576177286, 0.78, 0.0, 0.0, 0.6666666666666666, 0.515977859909384, 0.5967828639459188, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.662507], dtype=float32), -2.1319096]. 
=============================================
[2019-04-06 16:37:54,212] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.11644174e-13 4.76484290e-14 2.82543572e-10 4.11634539e-13
 1.00000000e+00 2.73310483e-18 1.12980336e-15], sum to 1.0000
[2019-04-06 16:37:54,212] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8079
[2019-04-06 16:37:54,324] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.7, 80.0, 0.0, 0.0, 26.0, 25.34964609579397, 0.4344817897752116, 0.0, 1.0, 69189.09256272076], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 961200.0000, 
sim time next is 963000.0000, 
raw observation next is [7.7, 81.5, 0.0, 0.0, 26.0, 25.47806803966535, 0.4507693244556925, 0.0, 1.0, 29560.769435517414], 
processed observation next is [1.0, 0.13043478260869565, 0.6759002770083103, 0.815, 0.0, 0.0, 0.6666666666666666, 0.623172336638779, 0.6502564414852309, 0.0, 1.0, 0.14076556874055912], 
reward next is 0.8592, 
noisyNet noise sample is [array([-0.69213593], dtype=float32), 1.5149359]. 
=============================================
[2019-04-06 16:37:54,387] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[85.01037]
 [84.63013]
 [85.13371]
 [85.52873]
 [85.76137]], R is [[84.81575012]
 [84.63811493]
 [84.74586487]
 [84.83063507]
 [84.81634521]].
[2019-04-06 16:38:23,686] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5913829e-15 1.3612754e-15 8.7890225e-12 1.7312669e-14 1.0000000e+00
 2.0410505e-19 1.3868321e-16], sum to 1.0000
[2019-04-06 16:38:23,687] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2503
[2019-04-06 16:38:23,911] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 26.0, 25.05670125619244, 0.4145846761176715, 0.0, 1.0, 38613.74028493546], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1407600.0000, 
sim time next is 1409400.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 26.0, 25.45273527156665, 0.4729315591297977, 0.0, 1.0, 12878.458640199366], 
processed observation next is [1.0, 0.30434782608695654, 0.44598337950138506, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6210612726305541, 0.6576438530432659, 0.0, 1.0, 0.061325993524758884], 
reward next is 0.9387, 
noisyNet noise sample is [array([0.99148434], dtype=float32), 0.8999171]. 
=============================================
[2019-04-06 16:38:24,451] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1502439e-11 1.2277914e-12 2.8252432e-09 1.4666074e-11 1.0000000e+00
 6.2417058e-14 3.2970844e-12], sum to 1.0000
[2019-04-06 16:38:24,451] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5617
[2019-04-06 16:38:24,459] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0532070e-12 2.4437969e-11 1.0114247e-08 3.7397883e-11 1.0000000e+00
 2.8784046e-14 1.5053384e-11], sum to 1.0000
[2019-04-06 16:38:24,480] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4340
[2019-04-06 16:38:24,492] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.35, 76.5, 0.0, 0.0, 26.0, 24.27270208793118, 0.3068931701676618, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1207800.0000, 
sim time next is 1209600.0000, 
raw observation next is [16.1, 78.0, 0.0, 0.0, 26.0, 24.19173431891261, 0.2903485918377566, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.0, 0.9085872576177286, 0.78, 0.0, 0.0, 0.6666666666666666, 0.515977859909384, 0.5967828639459188, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0903441], dtype=float32), 0.18454985]. 
=============================================
[2019-04-06 16:38:24,529] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.7, 67.0, 0.0, 0.0, 26.0, 24.57611144757394, 0.3753378788682614, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1197000.0000, 
sim time next is 1198800.0000, 
raw observation next is [17.7, 67.0, 0.0, 0.0, 26.0, 24.56856419057861, 0.3708286089823489, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.9529085872576178, 0.67, 0.0, 0.0, 0.6666666666666666, 0.5473803492148841, 0.6236095363274496, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8364317], dtype=float32), 0.7889659]. 
=============================================
[2019-04-06 16:38:33,822] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2415729e-17 1.2520371e-18 1.5052736e-13 2.3719371e-18 1.0000000e+00
 4.3432608e-20 2.7491554e-18], sum to 1.0000
[2019-04-06 16:38:33,822] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6033
[2019-04-06 16:38:33,903] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.800000000000001, 83.0, 100.0, 700.0, 26.0, 25.86404210075208, 0.5672829693584897, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1513800.0000, 
sim time next is 1515600.0000, 
raw observation next is [7.2, 73.0, 92.5, 700.5, 26.0, 25.61589453391185, 0.571775305970652, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.662049861495845, 0.73, 0.30833333333333335, 0.7740331491712708, 0.6666666666666666, 0.6346578778259874, 0.690591768656884, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.04345703], dtype=float32), 0.9273149]. 
=============================================
[2019-04-06 16:38:44,782] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 16:38:44,786] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:38:44,786] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:38:44,788] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run20
[2019-04-06 16:38:44,806] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:38:44,809] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:38:44,809] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:38:44,811] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run20
[2019-04-06 16:38:44,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:38:44,835] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run20
[2019-04-06 16:40:46,609] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 16:41:23,062] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.5280 91911252.3034 409.4099
[2019-04-06 16:41:23,442] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 16:41:24,490] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 380000, evaluation results [380000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.527952487471, 91911252.30343552, 409.4098524395626]
[2019-04-06 16:41:27,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9847739e-13 3.4388152e-14 1.3650385e-10 3.2515616e-13 1.0000000e+00
 2.2411714e-16 2.3831746e-14], sum to 1.0000
[2019-04-06 16:41:27,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0323
[2019-04-06 16:41:28,320] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 83.0, 122.5, 0.0, 26.0, 24.94534258944141, 0.345227818404622, 0.0, 1.0, 34803.67593069642], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1771200.0000, 
sim time next is 1773000.0000, 
raw observation next is [-2.55, 83.0, 126.0, 0.0, 26.0, 24.94465363246887, 0.3516515446275985, 0.0, 1.0, 45792.086220531906], 
processed observation next is [0.0, 0.5217391304347826, 0.3919667590027701, 0.83, 0.42, 0.0, 0.6666666666666666, 0.5787211360390726, 0.6172171815425328, 0.0, 1.0, 0.2180575534311043], 
reward next is 0.7819, 
noisyNet noise sample is [array([-0.72626376], dtype=float32), 0.8255428]. 
=============================================
[2019-04-06 16:41:28,339] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[74.6984 ]
 [74.58107]
 [74.18256]
 [73.65352]
 [73.2937 ]], R is [[75.11036682]
 [75.19352722]
 [75.23468781]
 [75.23705292]
 [75.35519409]].
[2019-04-06 16:43:09,695] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.0014654e-11 1.7302684e-12 1.2038625e-08 2.1723519e-11 1.0000000e+00
 3.1879454e-14 3.1488074e-12], sum to 1.0000
[2019-04-06 16:43:09,698] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2853
[2019-04-06 16:43:09,802] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.15, 36.5, 0.0, 0.0, 26.0, 25.11862603583833, 0.2315544882440556, 0.0, 1.0, 39831.53315471834], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2503800.0000, 
sim time next is 2505600.0000, 
raw observation next is [-1.7, 38.0, 0.0, 0.0, 26.0, 25.08015446334093, 0.2200245340283138, 0.0, 1.0, 39554.5910689152], 
processed observation next is [1.0, 0.0, 0.4155124653739613, 0.38, 0.0, 0.0, 0.6666666666666666, 0.5900128719450773, 0.5733415113427712, 0.0, 1.0, 0.18835519556626287], 
reward next is 0.8116, 
noisyNet noise sample is [array([1.1993891], dtype=float32), 2.2071617]. 
=============================================
[2019-04-06 16:43:20,709] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4962127e-11 1.3195061e-12 8.2214247e-10 1.2841921e-11 1.0000000e+00
 1.3805936e-15 3.1390794e-13], sum to 1.0000
[2019-04-06 16:43:20,709] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1102
[2019-04-06 16:43:20,767] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 70.0, 0.0, 0.0, 26.0, 24.5371943694071, 0.2355683203794961, 0.0, 1.0, 40909.68394872886], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3565800.0000, 
sim time next is 3567600.0000, 
raw observation next is [-6.0, 70.0, 0.0, 0.0, 26.0, 24.40447513950372, 0.2082692245265629, 0.0, 1.0, 41124.93687855036], 
processed observation next is [0.0, 0.30434782608695654, 0.296398891966759, 0.7, 0.0, 0.0, 0.6666666666666666, 0.53370626162531, 0.5694230748421877, 0.0, 1.0, 0.19583303275500172], 
reward next is 0.8042, 
noisyNet noise sample is [array([1.9095417], dtype=float32), 1.0064911]. 
=============================================
[2019-04-06 16:43:52,535] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7919442e-13 2.6745582e-14 2.6645991e-10 1.5227625e-12 1.0000000e+00
 3.0260130e-16 4.1917624e-14], sum to 1.0000
[2019-04-06 16:43:52,536] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5827
[2019-04-06 16:43:52,589] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 40.0, 0.0, 0.0, 26.0, 25.51934140185787, 0.4298659642208038, 0.0, 1.0, 38372.27677411594], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5016600.0000, 
sim time next is 5018400.0000, 
raw observation next is [1.0, 40.0, 0.0, 0.0, 26.0, 25.43359535861817, 0.4336815954888413, 0.0, 1.0, 63938.703764913604], 
processed observation next is [1.0, 0.08695652173913043, 0.4903047091412743, 0.4, 0.0, 0.0, 0.6666666666666666, 0.6194662798848475, 0.6445605318296138, 0.0, 1.0, 0.30447001792816003], 
reward next is 0.6955, 
noisyNet noise sample is [array([-0.7835519], dtype=float32), 0.7481054]. 
=============================================
[2019-04-06 16:43:57,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:43:57,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:43:57,615] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run10
[2019-04-06 16:43:58,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4510718e-13 2.9957761e-13 9.1684610e-10 1.2165440e-12 1.0000000e+00
 1.3888710e-15 4.5053272e-15], sum to 1.0000
[2019-04-06 16:43:58,186] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9844
[2019-04-06 16:43:58,496] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-11.0, 76.0, 0.0, 0.0, 26.0, 23.85908252057566, 0.08823105435251764, 0.0, 1.0, 44001.43180182337], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3308400.0000, 
sim time next is 3310200.0000, 
raw observation next is [-11.0, 80.0, 2.0, 94.0, 26.0, 24.15894325823428, 0.2604575173624115, 1.0, 1.0, 149849.98933058753], 
processed observation next is [1.0, 0.30434782608695654, 0.15789473684210528, 0.8, 0.006666666666666667, 0.10386740331491713, 0.6666666666666666, 0.5132452715195234, 0.5868191724541372, 1.0, 1.0, 0.7135713777647025], 
reward next is 0.2864, 
noisyNet noise sample is [array([0.71009034], dtype=float32), -0.76556087]. 
=============================================
[2019-04-06 16:44:01,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:44:01,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:44:01,268] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run10
[2019-04-06 16:44:18,675] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-06 16:44:18,676] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:44:18,676] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:44:18,679] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run21
[2019-04-06 16:44:18,696] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:44:18,702] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:44:18,704] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run21
[2019-04-06 16:44:18,724] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:44:18,735] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:44:18,738] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run21
[2019-04-06 16:44:31,024] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00753937], dtype=float32), 0.11860485]
[2019-04-06 16:44:31,024] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-3.4, 65.0, 0.0, 0.0, 26.0, 24.82614118775562, 0.2481138736619104, 1.0, 1.0, 87198.91861999703]
[2019-04-06 16:44:31,024] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:44:31,024] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.3454361e-13 7.1425694e-14 2.9942610e-10 1.0832081e-12 1.0000000e+00
 2.9211212e-16 2.7017632e-14], sampled 0.7222354141173027
[2019-04-06 16:45:32,263] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00753937], dtype=float32), 0.11860485]
[2019-04-06 16:45:32,264] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [4.1, 54.0, 0.0, 0.0, 26.0, 25.39433019980019, 0.3274718201210204, 0.0, 1.0, 38747.61444391298]
[2019-04-06 16:45:32,264] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:45:32,264] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.0495549e-12 2.3316979e-13 5.9050109e-10 3.1232070e-12 1.0000000e+00
 1.4100109e-15 7.3341310e-14], sampled 0.8536912812428935
[2019-04-06 16:45:33,067] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00753937], dtype=float32), 0.11860485]
[2019-04-06 16:45:33,068] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-0.1986140860000001, 49.76667296, 157.4062936, 149.3006452, 26.0, 24.98357909659766, 0.2957330930045732, 1.0, 1.0, 74652.36807677183]
[2019-04-06 16:45:33,068] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 16:45:33,068] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.13481937e-13 3.22104200e-14 1.81976934e-10 5.36059153e-13
 1.00000000e+00 1.05303976e-16 1.22416107e-14], sampled 0.35256304203463407
[2019-04-06 16:46:13,072] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2455.1234 79914340.2400 535.0996
[2019-04-06 16:46:52,748] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 16:46:56,175] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 16:46:57,225] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 400000, evaluation results [400000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2455.1233888037063, 79914340.24000935, 535.0996202443389, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 16:47:06,582] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2062308e-13 1.8703371e-13 5.0253107e-10 4.4280319e-11 1.0000000e+00
 3.4987812e-15 1.2216846e-13], sum to 1.0000
[2019-04-06 16:47:06,582] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2592
[2019-04-06 16:47:06,669] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.5, 65.5, 0.0, 0.0, 26.0, 24.7476107053427, 0.2093918681364205, 0.0, 1.0, 39489.67508356677], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4858200.0000, 
sim time next is 4860000.0000, 
raw observation next is [-3.0, 60.0, 0.0, 0.0, 26.0, 24.6511606435122, 0.1928369447031478, 0.0, 1.0, 39554.43048772056], 
processed observation next is [0.0, 0.2608695652173913, 0.3795013850415513, 0.6, 0.0, 0.0, 0.6666666666666666, 0.55426338695935, 0.5642789815677159, 0.0, 1.0, 0.1883544308939074], 
reward next is 0.8116, 
noisyNet noise sample is [array([-0.9984946], dtype=float32), -0.1354572]. 
=============================================
[2019-04-06 16:47:06,680] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[66.33764 ]
 [66.338005]
 [66.309654]
 [66.40383 ]
 [66.668304]], R is [[66.34581757]
 [66.49430847]
 [66.64222717]
 [66.78912354]
 [66.93455505]].
[2019-04-06 16:47:15,097] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.5173887e-16 8.5596180e-17 2.7238498e-12 9.3178300e-15 1.0000000e+00
 6.7948322e-19 1.5847902e-17], sum to 1.0000
[2019-04-06 16:47:15,098] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3323
[2019-04-06 16:47:15,214] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.25, 71.5, 0.0, 0.0, 26.0, 25.52782448363568, 0.3725103248469719, 0.0, 1.0, 52255.366398733655], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4329000.0000, 
sim time next is 4330800.0000, 
raw observation next is [4.0, 71.0, 0.0, 0.0, 26.0, 25.42597305867709, 0.3864769071404976, 0.0, 1.0, 73609.13301311833], 
processed observation next is [1.0, 0.13043478260869565, 0.5734072022160666, 0.71, 0.0, 0.0, 0.6666666666666666, 0.6188310882230909, 0.6288256357134993, 0.0, 1.0, 0.3505196810148492], 
reward next is 0.6495, 
noisyNet noise sample is [array([-0.00307654], dtype=float32), 1.7317302]. 
=============================================
[2019-04-06 16:47:21,141] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:47:21,141] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:47:21,144] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run10
[2019-04-06 16:47:25,538] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:47:25,538] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:47:25,542] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run10
[2019-04-06 16:47:27,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:47:27,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:47:27,528] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run10
[2019-04-06 16:47:51,515] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0337143e-16 1.8569558e-15 4.3950732e-11 5.7528686e-15 1.0000000e+00
 5.2614265e-19 5.1431202e-17], sum to 1.0000
[2019-04-06 16:47:51,515] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5197
[2019-04-06 16:47:51,567] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [10.0, 42.0, 111.0, 728.5, 26.0, 27.23071008847299, 0.7617394453957469, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4356000.0000, 
sim time next is 4357800.0000, 
raw observation next is [11.3, 38.0, 115.0, 780.0, 26.0, 27.51439168817436, 0.8255468820674011, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.7756232686980611, 0.38, 0.38333333333333336, 0.861878453038674, 0.6666666666666666, 0.79286597401453, 0.775182294022467, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.70989], dtype=float32), 1.1017329]. 
=============================================
[2019-04-06 16:47:58,369] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:47:58,369] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:47:58,372] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run10
[2019-04-06 16:48:07,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:48:07,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:07,860] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run10
[2019-04-06 16:48:12,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:48:12,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:12,824] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run10
[2019-04-06 16:48:24,781] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:48:24,781] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:24,784] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run10
[2019-04-06 16:48:33,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:48:33,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:33,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run10
[2019-04-06 16:48:36,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:48:36,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:36,174] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run10
[2019-04-06 16:48:38,430] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5813414e-14 1.2798346e-15 3.0090305e-11 3.5648246e-14 1.0000000e+00
 4.4819214e-18 8.4356017e-16], sum to 1.0000
[2019-04-06 16:48:38,430] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9486
[2019-04-06 16:48:38,507] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 29.5, 117.0, 803.0, 26.0, 26.5955034535136, 0.5820852743464375, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4962600.0000, 
sim time next is 4964400.0000, 
raw observation next is [3.0, 29.0, 119.5, 824.0, 26.0, 26.6792891510937, 0.6126690056854327, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.5457063711911359, 0.29, 0.3983333333333333, 0.9104972375690608, 0.6666666666666666, 0.7232740959244749, 0.7042230018951443, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.15837127], dtype=float32), -0.24814019]. 
=============================================
[2019-04-06 16:48:47,144] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:48:47,144] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:47,147] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run10
[2019-04-06 16:48:47,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:48:47,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:47,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run10
[2019-04-06 16:48:47,451] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:48:47,452] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:47,455] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run10
[2019-04-06 16:48:48,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:48:48,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:48,112] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run10
[2019-04-06 16:48:48,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:48:48,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:48:48,929] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run10
[2019-04-06 16:49:21,317] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.1790023e-16 5.1990459e-16 7.6706315e-12 2.8164767e-14 1.0000000e+00
 1.3075161e-19 2.9476956e-16], sum to 1.0000
[2019-04-06 16:49:21,318] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6344
[2019-04-06 16:49:21,357] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.7, 74.0, 0.0, 0.0, 26.0, 25.57778738098521, 0.5759481594487498, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1627200.0000, 
sim time next is 1629000.0000, 
raw observation next is [7.45, 75.0, 0.0, 0.0, 26.0, 25.32644247161238, 0.5761915186258428, 0.0, 1.0, 130811.93961286407], 
processed observation next is [1.0, 0.8695652173913043, 0.6689750692520776, 0.75, 0.0, 0.0, 0.6666666666666666, 0.6105368726343651, 0.6920638395419476, 0.0, 1.0, 0.6229139981564955], 
reward next is 0.3771, 
noisyNet noise sample is [array([-0.32052302], dtype=float32), 1.2607113]. 
=============================================
[2019-04-06 16:49:21,412] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[85.16355 ]
 [85.11641 ]
 [87.084206]
 [87.36105 ]
 [87.367325]], R is [[85.10375214]
 [85.25271606]
 [85.40019226]
 [85.54618835]
 [85.69072723]].
[2019-04-06 16:49:21,734] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3837884e-14 1.1405251e-15 5.0227402e-11 6.6482925e-14 1.0000000e+00
 1.2912150e-17 7.1614148e-16], sum to 1.0000
[2019-04-06 16:49:21,734] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7485
[2019-04-06 16:49:21,815] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.35, 91.5, 0.0, 0.0, 26.0, 25.32574409262612, 0.4565547133547499, 0.0, 1.0, 43216.566553009565], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1733400.0000, 
sim time next is 1735200.0000, 
raw observation next is [0.2, 91.0, 0.0, 0.0, 26.0, 25.30837274779071, 0.4435379954455684, 0.0, 1.0, 42908.56836661287], 
processed observation next is [0.0, 0.08695652173913043, 0.46814404432132967, 0.91, 0.0, 0.0, 0.6666666666666666, 0.6090310623158924, 0.6478459984818561, 0.0, 1.0, 0.20432651603148985], 
reward next is 0.7957, 
noisyNet noise sample is [array([2.2338321], dtype=float32), 2.722693]. 
=============================================
[2019-04-06 16:49:57,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.8098850e-14 3.2399550e-16 1.8139396e-11 1.4687222e-13 1.0000000e+00
 3.3751140e-18 4.3514975e-15], sum to 1.0000
[2019-04-06 16:49:57,027] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8430
[2019-04-06 16:49:57,128] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.3, 82.0, 0.0, 0.0, 26.0, 24.44078286292272, 0.1984091316979481, 0.0, 1.0, 42393.88201031956], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2160000.0000, 
sim time next is 2161800.0000, 
raw observation next is [-7.3, 80.5, 0.0, 0.0, 26.0, 24.39836061196396, 0.2015570996310221, 0.0, 1.0, 42470.95490705763], 
processed observation next is [1.0, 0.0, 0.26038781163434904, 0.805, 0.0, 0.0, 0.6666666666666666, 0.5331967176636633, 0.5671856998770074, 0.0, 1.0, 0.20224264241456016], 
reward next is 0.7978, 
noisyNet noise sample is [array([-0.18048084], dtype=float32), -1.164662]. 
=============================================
[2019-04-06 16:50:14,837] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-06 16:50:14,843] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:50:14,844] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:50:14,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run22
[2019-04-06 16:50:14,861] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:50:14,864] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:50:14,871] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:50:14,871] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:50:14,874] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run22
[2019-04-06 16:50:14,874] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run22
[2019-04-06 16:50:25,971] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.11962055]
[2019-04-06 16:50:25,972] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [3.2, 86.0, 0.0, 0.0, 26.0, 24.91661449400917, 0.3749534181992973, 0.0, 1.0, 54034.14115999606]
[2019-04-06 16:50:25,972] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:50:25,973] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.8951825e-14 3.5984331e-15 2.8730776e-11 5.5224038e-14 1.0000000e+00
 9.2143553e-18 8.1511833e-16], sampled 0.5380488044791207
[2019-04-06 16:52:05,565] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 16:52:47,156] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.1793 87830352.8773 516.5543
[2019-04-06 16:52:52,929] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 16:52:53,968] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 420000, evaluation results [420000.0, 2416.179305661946, 87830352.877312, 516.5542744756061, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 16:53:08,303] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0134671e-13 8.9856474e-16 3.9745499e-11 9.0594836e-14 1.0000000e+00
 4.4692046e-17 7.3809706e-15], sum to 1.0000
[2019-04-06 16:53:08,303] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2238
[2019-04-06 16:53:08,430] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.25821859883076, 0.08752246323093528, 0.0, 1.0, 41260.234058414666], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2001600.0000, 
sim time next is 2003400.0000, 
raw observation next is [-5.9, 85.0, 0.0, 0.0, 26.0, 24.20788219932998, 0.08951743161975349, 0.0, 1.0, 41403.61163652683], 
processed observation next is [1.0, 0.17391304347826086, 0.2991689750692521, 0.85, 0.0, 0.0, 0.6666666666666666, 0.5173235166108316, 0.5298391438732512, 0.0, 1.0, 0.19716005541203252], 
reward next is 0.8028, 
noisyNet noise sample is [array([0.1088153], dtype=float32), -0.96970004]. 
=============================================
[2019-04-06 16:53:28,216] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1608614e-15 3.1266694e-16 4.1469866e-12 2.7965020e-16 1.0000000e+00
 6.8467891e-20 1.1683822e-16], sum to 1.0000
[2019-04-06 16:53:28,216] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3163
[2019-04-06 16:53:28,310] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 26.0, 25.55342863983919, 0.532603365530576, 0.0, 1.0, 6248.066932902356], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1315800.0000, 
sim time next is 1317600.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 26.0, 25.48870702835625, 0.5215565398960883, 0.0, 1.0, 43780.17605871599], 
processed observation next is [1.0, 0.2608695652173913, 0.5069252077562327, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6240589190296874, 0.6738521799653627, 0.0, 1.0, 0.2084770288510285], 
reward next is 0.7915, 
noisyNet noise sample is [array([-1.1041608], dtype=float32), -0.26228473]. 
=============================================
[2019-04-06 16:53:29,360] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.8720170e-14 1.5189203e-14 2.4843286e-10 1.0711474e-13 1.0000000e+00
 1.5452827e-16 3.1868192e-15], sum to 1.0000
[2019-04-06 16:53:29,360] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0201
[2019-04-06 16:53:29,474] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.1, 91.0, 0.0, 0.0, 26.0, 25.2694924068007, 0.437565211521509, 0.0, 1.0, 42934.93132179183], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1737000.0000, 
sim time next is 1738800.0000, 
raw observation next is [0.0, 91.0, 0.0, 0.0, 26.0, 25.23708709566581, 0.4240712719642698, 0.0, 1.0, 42985.14173771869], 
processed observation next is [0.0, 0.13043478260869565, 0.46260387811634357, 0.91, 0.0, 0.0, 0.6666666666666666, 0.6030905913054841, 0.6413570906547567, 0.0, 1.0, 0.20469115113199376], 
reward next is 0.7953, 
noisyNet noise sample is [array([1.1582602], dtype=float32), -2.437773]. 
=============================================
[2019-04-06 16:53:51,793] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.35362559e-14 3.70512066e-14 2.40581756e-11 1.01147226e-13
 1.00000000e+00 5.34033362e-17 3.51768945e-16], sum to 1.0000
[2019-04-06 16:53:51,794] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9959
[2019-04-06 16:53:52,176] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.65, 84.5, 28.0, 0.0, 26.0, 24.98691472173229, 0.3342825152569738, 0.0, 1.0, 55964.1043243423], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1787400.0000, 
sim time next is 1789200.0000, 
raw observation next is [-3.9, 82.0, 14.5, 0.0, 26.0, 25.01069075861322, 0.3284738237380634, 0.0, 1.0, 40860.274677392874], 
processed observation next is [0.0, 0.7391304347826086, 0.3545706371191136, 0.82, 0.04833333333333333, 0.0, 0.6666666666666666, 0.5842242298844349, 0.6094912745793545, 0.0, 1.0, 0.1945727365590137], 
reward next is 0.8054, 
noisyNet noise sample is [array([1.5661005], dtype=float32), 1.6847169]. 
=============================================
[2019-04-06 16:54:09,529] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0581457e-12 1.6307966e-12 5.8304441e-09 2.5516958e-11 1.0000000e+00
 7.0106678e-16 1.6913726e-13], sum to 1.0000
[2019-04-06 16:54:09,529] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4188
[2019-04-06 16:54:10,030] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.449999999999999, 46.5, 61.0, 665.0, 26.0, 25.30115751355213, 0.256387905006532, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2453400.0000, 
sim time next is 2455200.0000, 
raw observation next is [-5.6, 43.0, 68.5, 721.0, 26.0, 25.16878385492924, 0.2417212343000892, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.30747922437673136, 0.43, 0.22833333333333333, 0.7966850828729282, 0.6666666666666666, 0.5973986545774368, 0.5805737447666964, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2672725], dtype=float32), -0.36793536]. 
=============================================
[2019-04-06 16:54:23,191] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1126911e-14 1.5564641e-16 1.1132405e-11 5.0742750e-15 1.0000000e+00
 8.9875242e-18 2.3795705e-16], sum to 1.0000
[2019-04-06 16:54:23,191] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7627
[2019-04-06 16:54:23,459] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.45, 65.0, 227.0, 4.0, 26.0, 25.67436645817008, 0.3257913347229087, 1.0, 1.0, 14280.201337156393], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1945800.0000, 
sim time next is 1947600.0000, 
raw observation next is [-3.9, 65.0, 182.0, 2.0, 26.0, 25.57560804533499, 0.3137835319586158, 1.0, 1.0, 26449.126245794632], 
processed observation next is [1.0, 0.5652173913043478, 0.3545706371191136, 0.65, 0.6066666666666667, 0.0022099447513812156, 0.6666666666666666, 0.6313006704445826, 0.604594510652872, 1.0, 1.0, 0.12594822021806967], 
reward next is 0.8741, 
noisyNet noise sample is [array([-0.8667916], dtype=float32), 0.7040983]. 
=============================================
[2019-04-06 16:54:27,667] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.2411550e-11 6.8006260e-12 2.5813929e-09 1.3040900e-10 1.0000000e+00
 4.8429068e-14 3.7203851e-12], sum to 1.0000
[2019-04-06 16:54:27,667] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3312
[2019-04-06 16:54:27,876] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 30.0, 0.0, 0.0, 26.0, 24.90605345825794, 0.2131942052568334, 0.0, 1.0, 44586.43016480058], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2487600.0000, 
sim time next is 2489400.0000, 
raw observation next is [-0.35, 29.5, 0.0, 0.0, 26.0, 24.94151395378024, 0.2494479272814587, 0.0, 1.0, 105197.34737680068], 
processed observation next is [0.0, 0.8260869565217391, 0.45290858725761773, 0.295, 0.0, 0.0, 0.6666666666666666, 0.5784594961483535, 0.5831493090938196, 0.0, 1.0, 0.5009397494133365], 
reward next is 0.4991, 
noisyNet noise sample is [array([0.36364123], dtype=float32), 1.8114998]. 
=============================================
[2019-04-06 16:54:42,536] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.9134421e-16 9.7615708e-16 8.6385465e-12 2.4030242e-15 1.0000000e+00
 4.8697959e-18 4.2253391e-18], sum to 1.0000
[2019-04-06 16:54:42,537] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8468
[2019-04-06 16:54:42,592] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 47.0, 115.0, 804.0, 26.0, 26.61114080439412, 0.4193792160895333, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3411000.0000, 
sim time next is 3412800.0000, 
raw observation next is [3.0, 45.0, 116.0, 810.5, 26.0, 26.39155767750254, 0.626944445447828, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5457063711911359, 0.45, 0.38666666666666666, 0.8955801104972375, 0.6666666666666666, 0.6992964731252117, 0.7089814818159427, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.41002172], dtype=float32), 1.0432129]. 
=============================================
[2019-04-06 16:55:03,191] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2515067e-11 9.6313127e-13 1.1949515e-09 4.8278790e-12 1.0000000e+00
 4.2073018e-14 5.2600779e-13], sum to 1.0000
[2019-04-06 16:55:03,192] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6004
[2019-04-06 16:55:03,311] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.2, 35.0, 0.0, 0.0, 26.0, 25.27491615925289, 0.2784559142786837, 0.0, 1.0, 40051.25332022449], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2496600.0000, 
sim time next is 2498400.0000, 
raw observation next is [-1.2, 33.0, 0.0, 0.0, 26.0, 25.28051619392079, 0.2639118198149853, 0.0, 1.0, 40147.097672024625], 
processed observation next is [0.0, 0.9565217391304348, 0.42936288088642666, 0.33, 0.0, 0.0, 0.6666666666666666, 0.6067096828267324, 0.5879706066049951, 0.0, 1.0, 0.19117665558106964], 
reward next is 0.8088, 
noisyNet noise sample is [array([-0.23006955], dtype=float32), 0.39042577]. 
=============================================
[2019-04-06 16:55:14,351] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.5275762e-16 1.1386553e-16 2.9174746e-12 3.7974274e-15 1.0000000e+00
 8.6217097e-19 9.3005930e-18], sum to 1.0000
[2019-04-06 16:55:14,365] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7513
[2019-04-06 16:55:14,471] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 100.0, 0.0, 0.0, 26.0, 24.87857664610006, 0.2363081891072068, 0.0, 1.0, 55682.660294035064], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2872800.0000, 
sim time next is 2874600.0000, 
raw observation next is [1.5, 96.5, 0.0, 0.0, 26.0, 24.73123739543104, 0.2261038789385426, 0.0, 1.0, 55416.93459223002], 
processed observation next is [1.0, 0.2608695652173913, 0.5041551246537397, 0.965, 0.0, 0.0, 0.6666666666666666, 0.5609364496192534, 0.5753679596461808, 0.0, 1.0, 0.26389016472490484], 
reward next is 0.7361, 
noisyNet noise sample is [array([0.05042513], dtype=float32), 0.68773216]. 
=============================================
[2019-04-06 16:55:23,315] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5735323e-15 5.7806746e-15 1.7554005e-10 8.9385462e-14 1.0000000e+00
 7.1325352e-18 5.1122978e-15], sum to 1.0000
[2019-04-06 16:55:23,316] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9957
[2019-04-06 16:55:23,344] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 50.0, 149.5, 635.5, 26.0, 26.04332880447289, 0.4737511910118497, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2804400.0000, 
sim time next is 2806200.0000, 
raw observation next is [0.5, 47.0, 125.0, 763.0, 26.0, 26.02832233228444, 0.4537091926109288, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4764542936288089, 0.47, 0.4166666666666667, 0.8430939226519337, 0.6666666666666666, 0.6690268610237032, 0.6512363975369763, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.21860653], dtype=float32), 0.2971191]. 
=============================================
[2019-04-06 16:55:26,645] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.6303833e-15 1.3915060e-16 2.0579803e-12 1.0916152e-14 1.0000000e+00
 2.5568802e-18 1.7631600e-16], sum to 1.0000
[2019-04-06 16:55:26,645] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2453
[2019-04-06 16:55:26,710] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 82.5, 0.0, 0.0, 26.0, 25.66434923378835, 0.5553153067592183, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3447000.0000, 
sim time next is 3448800.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 26.0, 25.66899262590162, 0.5359840725076195, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4903047091412743, 0.86, 0.0, 0.0, 0.6666666666666666, 0.639082718825135, 0.6786613575025399, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9360637], dtype=float32), -0.22627927]. 
=============================================
[2019-04-06 16:55:33,723] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5081418e-13 4.6730299e-14 2.2252350e-10 2.8415638e-13 1.0000000e+00
 1.1020575e-16 1.2735242e-13], sum to 1.0000
[2019-04-06 16:55:33,724] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1050
[2019-04-06 16:55:33,892] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.5, 52.5, 114.0, 817.0, 26.0, 25.08257958770121, 0.3567420548288907, 0.0, 1.0, 15763.362566230391], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3069000.0000, 
sim time next is 3070800.0000, 
raw observation next is [-2.0, 50.0, 111.5, 811.5, 26.0, 25.10686226966615, 0.3572125521747513, 0.0, 1.0, 6239.057448890676], 
processed observation next is [0.0, 0.5652173913043478, 0.40720221606648205, 0.5, 0.37166666666666665, 0.8966850828729281, 0.6666666666666666, 0.592238522472179, 0.6190708507249171, 0.0, 1.0, 0.029709797375669884], 
reward next is 0.9703, 
noisyNet noise sample is [array([-0.7606068], dtype=float32), -0.40971172]. 
=============================================
[2019-04-06 16:55:49,461] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5747929e-15 1.5265589e-14 6.3256227e-11 4.2587903e-13 1.0000000e+00
 1.3134019e-16 1.7307023e-14], sum to 1.0000
[2019-04-06 16:55:49,462] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9679
[2019-04-06 16:55:49,525] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 39.0, 0.0, 0.0, 26.0, 24.964197002941, 0.3225804199081304, 0.0, 1.0, 40586.99821490688], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4062600.0000, 
sim time next is 4064400.0000, 
raw observation next is [-6.0, 41.0, 0.0, 0.0, 26.0, 24.96823670589099, 0.3100698418141297, 0.0, 1.0, 40660.66445768697], 
processed observation next is [1.0, 0.043478260869565216, 0.296398891966759, 0.41, 0.0, 0.0, 0.6666666666666666, 0.5806863921575826, 0.6033566139380432, 0.0, 1.0, 0.1936222117032713], 
reward next is 0.8064, 
noisyNet noise sample is [array([0.29053307], dtype=float32), 0.2175112]. 
=============================================
[2019-04-06 16:55:52,381] A3C_AGENT_WORKER-Thread-7 INFO:Evaluating...
[2019-04-06 16:55:52,381] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:55:52,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:55:52,383] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run23
[2019-04-06 16:55:52,397] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 16:55:52,417] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:55:52,420] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run23
[2019-04-06 16:55:52,437] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 16:55:52,439] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:55:52,441] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run23
[2019-04-06 16:56:26,644] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.12033611]
[2019-04-06 16:56:26,644] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-2.2, 58.0, 0.0, 0.0, 26.0, 24.76015687215248, 0.3048711756943108, 0.0, 1.0, 38808.85389131639]
[2019-04-06 16:56:26,644] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:56:26,645] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.4394008e-12 3.6794878e-13 8.2702117e-10 3.8477333e-12 1.0000000e+00
 1.7942843e-15 9.5528566e-14], sampled 0.7111252258039111
[2019-04-06 16:57:05,653] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.12033611]
[2019-04-06 16:57:05,654] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-5.900675351, 51.88900224, 168.66384845, 325.24808445, 26.0, 25.4766402022149, 0.3261277966545321, 1.0, 1.0, 27595.19983177092]
[2019-04-06 16:57:05,654] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 16:57:05,654] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [6.5893370e-14 1.7568507e-14 1.0973540e-10 3.2281534e-13 1.0000000e+00
 6.2825929e-17 5.8528778e-15], sampled 0.8033611472289847
[2019-04-06 16:57:14,352] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.12033611]
[2019-04-06 16:57:14,353] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-1.5, 57.5, 6.0, 99.0, 26.0, 25.05515923606761, 0.3403489332055329, 0.0, 1.0, 38284.69373341822]
[2019-04-06 16:57:14,353] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 16:57:14,354] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [8.5279884e-13 1.8771025e-13 5.6248833e-10 2.5273451e-12 1.0000000e+00
 1.1129155e-15 8.3117060e-14], sampled 0.1454144560520949
[2019-04-06 16:57:47,037] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.5990 79959984.5800 535.1579
[2019-04-06 16:58:21,506] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 16:58:25,487] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 16:58:26,524] A3C_AGENT_WORKER-Thread-7 INFO:Global step: 440000, evaluation results [440000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.5990071948627, 79959984.58002774, 535.1579115189242, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 16:58:31,566] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [2.3568896e-13 2.9062734e-15 1.4261095e-11 1.2656807e-13 1.0000000e+00
 1.5039217e-17 1.5975140e-15], sum to 1.0000
[2019-04-06 16:58:31,567] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7046
[2019-04-06 16:58:31,685] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 26.0, 25.09924865493867, 0.3343577674419624, 0.0, 1.0, 43925.61565192548], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3814200.0000, 
sim time next is 3816000.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 26.0, 25.00050004307195, 0.3142445472476397, 0.0, 1.0, 43680.064279584374], 
processed observation next is [1.0, 0.17391304347826086, 0.3518005540166205, 0.71, 0.0, 0.0, 0.6666666666666666, 0.583375003589329, 0.6047481824158799, 0.0, 1.0, 0.20800030609325892], 
reward next is 0.7920, 
noisyNet noise sample is [array([0.03667541], dtype=float32), -0.3906458]. 
=============================================
[2019-04-06 16:58:31,696] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[80.21987 ]
 [80.34665 ]
 [80.06103 ]
 [80.06269 ]
 [80.117775]], R is [[80.01654816]
 [80.00721741]
 [79.95442963]
 [79.95002747]
 [79.99672699]].
[2019-04-06 16:58:34,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:58:34,498] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:58:34,503] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run11
[2019-04-06 16:58:36,210] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.3363932e-18 3.4473964e-19 3.4846060e-13 4.7731494e-17 1.0000000e+00
 1.0299432e-21 6.5516990e-19], sum to 1.0000
[2019-04-06 16:58:36,210] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8240
[2019-04-06 16:58:36,382] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.0, 100.0, 101.0, 763.0, 26.0, 27.61609229611195, 0.9385155034750984, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3162600.0000, 
sim time next is 3164400.0000, 
raw observation next is [7.0, 100.0, 92.5, 721.0, 26.0, 27.7195523743597, 0.8403579672040237, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.6565096952908588, 1.0, 0.30833333333333335, 0.7966850828729282, 0.6666666666666666, 0.8099626978633084, 0.7801193224013412, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.02036126], dtype=float32), 2.3320513]. 
=============================================
[2019-04-06 16:58:48,023] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:58:48,032] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:58:48,095] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run11
[2019-04-06 16:58:54,070] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5731787e-17 3.0551476e-17 5.9920038e-12 2.7560059e-15 1.0000000e+00
 2.2801027e-19 1.0891511e-17], sum to 1.0000
[2019-04-06 16:58:54,070] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2842
[2019-04-06 16:58:54,199] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 67.0, 0.0, 0.0, 26.0, 25.43961947452424, 0.4030535436198409, 0.0, 1.0, 25986.63468817099], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3470400.0000, 
sim time next is 3472200.0000, 
raw observation next is [0.5, 69.5, 0.0, 0.0, 26.0, 25.26843695493376, 0.3958677667528233, 0.0, 1.0, 65222.05901046408], 
processed observation next is [1.0, 0.17391304347826086, 0.4764542936288089, 0.695, 0.0, 0.0, 0.6666666666666666, 0.6057030795778134, 0.6319559222509411, 0.0, 1.0, 0.3105812333831623], 
reward next is 0.6894, 
noisyNet noise sample is [array([-0.36577916], dtype=float32), 0.1022698]. 
=============================================
[2019-04-06 16:59:39,722] A3C_AGENT_WORKER-Thread-17 INFO:Local step 28500, global step 447411: loss 2.9756
[2019-04-06 16:59:39,729] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 28500, global step 447411: learning rate 0.0000
[2019-04-06 16:59:41,426] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.9593258e-14 1.9428611e-15 8.7258714e-11 3.1432569e-12 1.0000000e+00
 2.4090324e-18 1.1085730e-14], sum to 1.0000
[2019-04-06 16:59:41,427] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5959
[2019-04-06 16:59:41,551] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.9, 70.0, 0.0, 0.0, 26.0, 25.46671179365979, 0.3951787694962587, 0.0, 1.0, 34011.00761412237], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4334400.0000, 
sim time next is 4336200.0000, 
raw observation next is [3.75, 69.5, 0.0, 0.0, 26.0, 25.58668826468577, 0.379508918621603, 0.0, 1.0, 6245.654183079223], 
processed observation next is [1.0, 0.17391304347826086, 0.5664819944598338, 0.695, 0.0, 0.0, 0.6666666666666666, 0.6322240220571475, 0.6265029728738677, 0.0, 1.0, 0.029741210395615347], 
reward next is 0.9703, 
noisyNet noise sample is [array([-1.0639737], dtype=float32), -0.121761635]. 
=============================================
[2019-04-06 16:59:43,319] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:59:43,319] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:59:43,322] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run11
[2019-04-06 16:59:44,554] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5500022e-16 4.9004371e-16 3.6376371e-11 1.8149360e-15 1.0000000e+00
 5.6756491e-19 7.9667585e-18], sum to 1.0000
[2019-04-06 16:59:44,554] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5713
[2019-04-06 16:59:44,644] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.0, 71.0, 0.0, 0.0, 26.0, 25.42597305867709, 0.3864769071404976, 0.0, 1.0, 73609.13301311833], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4330800.0000, 
sim time next is 4332600.0000, 
raw observation next is [3.95, 70.5, 0.0, 0.0, 26.0, 25.66520258531298, 0.4037992180740356, 0.0, 1.0, 13799.68524048654], 
processed observation next is [1.0, 0.13043478260869565, 0.57202216066482, 0.705, 0.0, 0.0, 0.6666666666666666, 0.6387668821094149, 0.6345997393580118, 0.0, 1.0, 0.06571278685945972], 
reward next is 0.9343, 
noisyNet noise sample is [array([0.36613128], dtype=float32), -0.6991792]. 
=============================================
[2019-04-06 16:59:54,408] A3C_AGENT_WORKER-Thread-14 INFO:Local step 28500, global step 448849: loss 3.4773
[2019-04-06 16:59:54,408] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 28500, global step 448849: learning rate 0.0000
[2019-04-06 16:59:57,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 16:59:57,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 16:59:57,420] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run11
[2019-04-06 17:00:05,447] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.5257054e-15 1.0785842e-15 3.0433141e-12 6.4326880e-16 1.0000000e+00
 5.4539546e-18 2.4481481e-16], sum to 1.0000
[2019-04-06 17:00:05,447] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8745
[2019-04-06 17:00:05,483] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.9, 58.0, 116.0, 655.0, 26.0, 25.47035167382908, 0.4653837922444136, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4289400.0000, 
sim time next is 4291200.0000, 
raw observation next is [7.0, 56.0, 93.0, 605.5, 26.0, 25.52897859513121, 0.4730883122306116, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.6565096952908588, 0.56, 0.31, 0.669060773480663, 0.6666666666666666, 0.6274148829276008, 0.6576961040768705, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.88451236], dtype=float32), -1.0075653]. 
=============================================
[2019-04-06 17:00:06,369] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:00:06,369] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:06,388] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run11
[2019-04-06 17:00:09,871] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3445240e-14 4.0612260e-16 9.1042712e-12 6.2962785e-14 1.0000000e+00
 1.2200613e-17 1.8563528e-16], sum to 1.0000
[2019-04-06 17:00:09,871] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4294
[2019-04-06 17:00:09,962] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 54.5, 0.0, 0.0, 26.0, 25.63901518108057, 0.541362306478821, 0.0, 1.0, 7653.542914120323], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4663800.0000, 
sim time next is 4665600.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 26.0, 25.55770648499163, 0.5066626312669885, 0.0, 1.0, 20638.447236232856], 
processed observation next is [1.0, 0.0, 0.518005540166205, 0.52, 0.0, 0.0, 0.6666666666666666, 0.6298088737493025, 0.6688875437556628, 0.0, 1.0, 0.0982783201725374], 
reward next is 0.9017, 
noisyNet noise sample is [array([-0.1471689], dtype=float32), -0.5179162]. 
=============================================
[2019-04-06 17:00:13,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:00:13,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:13,332] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run11
[2019-04-06 17:00:19,186] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4589264e-15 4.5115186e-15 9.3485647e-13 4.0331548e-14 1.0000000e+00
 1.0175146e-18 1.9619188e-16], sum to 1.0000
[2019-04-06 17:00:19,188] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2179
[2019-04-06 17:00:19,236] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.5, 52.5, 0.0, 0.0, 26.0, 25.9422075500676, 0.6046332094762285, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4649400.0000, 
sim time next is 4651200.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 26.0, 25.66408344668046, 0.5561971477778315, 0.0, 1.0, 14153.097717012162], 
processed observation next is [1.0, 0.8695652173913043, 0.518005540166205, 0.52, 0.0, 0.0, 0.6666666666666666, 0.6386736205567051, 0.6853990492592771, 0.0, 1.0, 0.06739570341434363], 
reward next is 0.9326, 
noisyNet noise sample is [array([-1.4997376], dtype=float32), 0.37496087]. 
=============================================
[2019-04-06 17:00:21,331] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:00:21,332] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:21,335] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run11
[2019-04-06 17:00:27,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:00:27,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:27,208] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run11
[2019-04-06 17:00:27,751] A3C_AGENT_WORKER-Thread-19 INFO:Local step 28500, global step 453280: loss 3.3541
[2019-04-06 17:00:27,752] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 28500, global step 453280: learning rate 0.0000
[2019-04-06 17:00:29,655] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:00:29,655] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:29,659] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run11
[2019-04-06 17:00:30,028] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2700296e-12 1.7661929e-12 8.3702523e-10 3.6516007e-12 1.0000000e+00
 4.2887735e-16 1.6514138e-13], sum to 1.0000
[2019-04-06 17:00:30,037] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7887
[2019-04-06 17:00:30,061] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 45.0, 199.5, 398.0, 26.0, 25.07309085304816, 0.3712572572440674, 0.0, 1.0, 6229.980619355353], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4892400.0000, 
sim time next is 4894200.0000, 
raw observation next is [3.0, 45.0, 163.0, 422.0, 26.0, 25.10478553517851, 0.3770577696846689, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.5457063711911359, 0.45, 0.5433333333333333, 0.4662983425414365, 0.6666666666666666, 0.5920654612648759, 0.6256859232282229, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3534547], dtype=float32), -0.19487852]. 
=============================================
[2019-04-06 17:00:32,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:00:32,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:32,792] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run11
[2019-04-06 17:00:35,674] A3C_AGENT_WORKER-Thread-18 INFO:Local step 28500, global step 454168: loss 2.7683
[2019-04-06 17:00:35,675] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 28500, global step 454168: learning rate 0.0000
[2019-04-06 17:00:41,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:00:41,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:41,092] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run11
[2019-04-06 17:00:41,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:00:41,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:41,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run11
[2019-04-06 17:00:43,476] A3C_AGENT_WORKER-Thread-15 INFO:Local step 28500, global step 455087: loss 3.4379
[2019-04-06 17:00:43,476] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 28500, global step 455087: learning rate 0.0000
[2019-04-06 17:00:44,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:00:44,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:44,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run11
[2019-04-06 17:00:46,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:00:46,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:46,064] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run11
[2019-04-06 17:00:46,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:00:46,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:46,164] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run11
[2019-04-06 17:00:47,893] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:00:47,893] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:00:47,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run11
[2019-04-06 17:00:48,384] A3C_AGENT_WORKER-Thread-17 INFO:Local step 29000, global step 455614: loss 7.0033
[2019-04-06 17:00:48,392] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 29000, global step 455614: learning rate 0.0000
[2019-04-06 17:00:50,699] A3C_AGENT_WORKER-Thread-8 INFO:Local step 28500, global step 455782: loss 3.0850
[2019-04-06 17:00:50,700] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 28500, global step 455783: learning rate 0.0000
[2019-04-06 17:00:54,772] A3C_AGENT_WORKER-Thread-14 INFO:Local step 29000, global step 456181: loss 6.9440
[2019-04-06 17:00:54,774] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 29000, global step 456181: learning rate 0.0000
[2019-04-06 17:01:01,140] A3C_AGENT_WORKER-Thread-7 INFO:Local step 28500, global step 456817: loss 3.4435
[2019-04-06 17:01:01,140] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 28500, global step 456817: learning rate 0.0000
[2019-04-06 17:01:04,165] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3340222e-17 1.0002927e-17 3.1764272e-13 3.6567039e-15 1.0000000e+00
 3.5227315e-20 1.7493714e-17], sum to 1.0000
[2019-04-06 17:01:04,180] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3165
[2019-04-06 17:01:04,225] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [11.6, 52.0, 76.0, 570.5, 26.0, 26.59950283703584, 0.749277622391841, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1522800.0000, 
sim time next is 1524600.0000, 
raw observation next is [11.9, 51.0, 77.0, 478.0, 26.0, 26.64582023098835, 0.7563002044828387, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.7922437673130196, 0.51, 0.25666666666666665, 0.5281767955801105, 0.6666666666666666, 0.7204850192490291, 0.7521000681609462, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.94306016], dtype=float32), 2.1703672]. 
=============================================
[2019-04-06 17:01:04,730] A3C_AGENT_WORKER-Thread-6 INFO:Local step 28500, global step 457244: loss 3.2942
[2019-04-06 17:01:04,730] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 28500, global step 457244: learning rate 0.0000
[2019-04-06 17:01:09,815] A3C_AGENT_WORKER-Thread-3 INFO:Local step 28500, global step 457781: loss 2.6522
[2019-04-06 17:01:09,815] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 28500, global step 457781: learning rate 0.0000
[2019-04-06 17:01:11,183] A3C_AGENT_WORKER-Thread-16 INFO:Local step 28500, global step 457913: loss 3.0286
[2019-04-06 17:01:11,184] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 28500, global step 457913: learning rate 0.0000
[2019-04-06 17:01:19,944] A3C_AGENT_WORKER-Thread-12 INFO:Local step 28500, global step 458837: loss 2.8419
[2019-04-06 17:01:19,945] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 28500, global step 458837: learning rate 0.0000
[2019-04-06 17:01:22,330] A3C_AGENT_WORKER-Thread-13 INFO:Local step 28500, global step 459110: loss 2.8627
[2019-04-06 17:01:22,332] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 28500, global step 459110: learning rate 0.0000
[2019-04-06 17:01:23,354] A3C_AGENT_WORKER-Thread-20 INFO:Local step 28500, global step 459224: loss 2.9970
[2019-04-06 17:01:23,355] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 28500, global step 459224: learning rate 0.0000
[2019-04-06 17:01:25,983] A3C_AGENT_WORKER-Thread-5 INFO:Local step 28500, global step 459522: loss 2.7790
[2019-04-06 17:01:25,983] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 28500, global step 459522: learning rate 0.0000
[2019-04-06 17:01:26,099] A3C_AGENT_WORKER-Thread-2 INFO:Local step 28500, global step 459537: loss 2.9269
[2019-04-06 17:01:26,099] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 28500, global step 459537: learning rate 0.0000
[2019-04-06 17:01:26,581] A3C_AGENT_WORKER-Thread-4 INFO:Local step 28500, global step 459584: loss 2.4799
[2019-04-06 17:01:26,582] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 28500, global step 459584: learning rate 0.0000
[2019-04-06 17:01:28,382] A3C_AGENT_WORKER-Thread-19 INFO:Local step 29000, global step 459810: loss 6.9891
[2019-04-06 17:01:28,382] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 29000, global step 459810: learning rate 0.0000
[2019-04-06 17:01:28,830] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4116340e-11 7.1000627e-12 6.3545182e-09 3.5715797e-12 1.0000000e+00
 2.1162986e-14 1.1858720e-12], sum to 1.0000
[2019-04-06 17:01:28,830] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4054
[2019-04-06 17:01:28,882] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [15.0, 98.0, 28.0, 0.0, 26.0, 23.38180940441711, 0.1275840174394923, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1240200.0000, 
sim time next is 1242000.0000, 
raw observation next is [15.0, 100.0, 51.0, 0.0, 26.0, 23.34202472654966, 0.1241571778686473, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.8781163434903049, 1.0, 0.17, 0.0, 0.6666666666666666, 0.44516872721247164, 0.5413857259562157, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.73595417], dtype=float32), -0.62257326]. 
=============================================
[2019-04-06 17:01:28,885] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[60.955673]
 [60.804977]
 [60.77695 ]
 [60.813385]
 [60.89976 ]], R is [[61.65565491]
 [62.03910065]
 [62.4187088 ]
 [62.79452133]
 [63.16657639]].
[2019-04-06 17:01:29,848] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-06 17:01:29,861] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:01:29,862] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:01:29,864] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run24
[2019-04-06 17:01:29,896] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:01:29,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:01:29,900] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run24
[2019-04-06 17:01:29,922] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:01:29,938] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:01:29,942] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run24
[2019-04-06 17:03:27,961] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 17:04:06,568] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 17:04:06,791] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 17:04:07,829] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 460000, evaluation results [460000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 17:04:14,836] A3C_AGENT_WORKER-Thread-18 INFO:Local step 29000, global step 460541: loss 7.0647
[2019-04-06 17:04:14,871] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 29000, global step 460541: learning rate 0.0000
[2019-04-06 17:04:26,872] A3C_AGENT_WORKER-Thread-15 INFO:Local step 29000, global step 461489: loss 7.0119
[2019-04-06 17:04:26,872] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 29000, global step 461489: learning rate 0.0000
[2019-04-06 17:04:34,599] A3C_AGENT_WORKER-Thread-17 INFO:Local step 29500, global step 462159: loss 7.0857
[2019-04-06 17:04:34,600] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 29500, global step 462159: learning rate 0.0000
[2019-04-06 17:04:38,126] A3C_AGENT_WORKER-Thread-8 INFO:Local step 29000, global step 462462: loss 6.8889
[2019-04-06 17:04:38,127] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 29000, global step 462462: learning rate 0.0000
[2019-04-06 17:04:48,377] A3C_AGENT_WORKER-Thread-14 INFO:Local step 29500, global step 463275: loss 6.8357
[2019-04-06 17:04:48,381] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 29500, global step 463275: learning rate 0.0000
[2019-04-06 17:04:53,509] A3C_AGENT_WORKER-Thread-7 INFO:Local step 29000, global step 463717: loss 7.0888
[2019-04-06 17:04:53,509] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 29000, global step 463717: learning rate 0.0000
[2019-04-06 17:05:01,806] A3C_AGENT_WORKER-Thread-6 INFO:Local step 29000, global step 464526: loss 6.9160
[2019-04-06 17:05:01,807] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 29000, global step 464526: learning rate 0.0000
[2019-04-06 17:05:11,053] A3C_AGENT_WORKER-Thread-3 INFO:Local step 29000, global step 465365: loss 6.8840
[2019-04-06 17:05:11,053] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 29000, global step 465365: learning rate 0.0000
[2019-04-06 17:05:14,947] A3C_AGENT_WORKER-Thread-16 INFO:Local step 29000, global step 465706: loss 6.8856
[2019-04-06 17:05:14,947] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 29000, global step 465706: learning rate 0.0000
[2019-04-06 17:05:30,226] A3C_AGENT_WORKER-Thread-12 INFO:Local step 29000, global step 467141: loss 6.8145
[2019-04-06 17:05:30,230] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 29000, global step 467141: learning rate 0.0000
[2019-04-06 17:05:31,855] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2913951e-13 2.4051853e-14 9.6492314e-11 7.7635186e-13 1.0000000e+00
 7.7380422e-18 2.2922734e-15], sum to 1.0000
[2019-04-06 17:05:31,855] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5207
[2019-04-06 17:05:31,955] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [13.3, 62.0, 0.0, 0.0, 26.0, 25.75154130249868, 0.7034859028735264, 0.0, 1.0, 29527.988192254445], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1112400.0000, 
sim time next is 1114200.0000, 
raw observation next is [13.0, 63.0, 0.0, 0.0, 26.0, 25.85828189561948, 0.6974433051180372, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.8227146814404434, 0.63, 0.0, 0.0, 0.6666666666666666, 0.6548568246349568, 0.7324811017060124, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2341666], dtype=float32), 0.48907456]. 
=============================================
[2019-04-06 17:05:37,551] A3C_AGENT_WORKER-Thread-20 INFO:Local step 29000, global step 467904: loss 6.8053
[2019-04-06 17:05:37,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 29000, global step 467904: learning rate 0.0000
[2019-04-06 17:05:37,893] A3C_AGENT_WORKER-Thread-13 INFO:Local step 29000, global step 467935: loss 7.0455
[2019-04-06 17:05:37,910] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 29000, global step 467935: learning rate 0.0000
[2019-04-06 17:05:38,644] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5799126e-11 1.3898278e-11 3.6066915e-08 2.0439025e-11 1.0000000e+00
 6.2611178e-14 3.3672798e-12], sum to 1.0000
[2019-04-06 17:05:38,645] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9919
[2019-04-06 17:05:38,754] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 26.0, 23.45107082888685, 0.1379108461389043, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1236600.0000, 
sim time next is 1238400.0000, 
raw observation next is [15.0, 96.0, 14.0, 0.0, 26.0, 23.43861972976527, 0.1348346069624709, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.8781163434903049, 0.96, 0.04666666666666667, 0.0, 0.6666666666666666, 0.4532183108137726, 0.5449448689874903, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5579345], dtype=float32), 0.52843744]. 
=============================================
[2019-04-06 17:05:39,022] A3C_AGENT_WORKER-Thread-19 INFO:Local step 29500, global step 468044: loss 6.7782
[2019-04-06 17:05:39,023] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 29500, global step 468044: learning rate 0.0000
[2019-04-06 17:05:43,761] A3C_AGENT_WORKER-Thread-5 INFO:Local step 29000, global step 468527: loss 6.7835
[2019-04-06 17:05:43,770] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 29000, global step 468527: learning rate 0.0000
[2019-04-06 17:05:45,177] A3C_AGENT_WORKER-Thread-2 INFO:Local step 29000, global step 468693: loss 6.8335
[2019-04-06 17:05:45,189] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 29000, global step 468693: learning rate 0.0000
[2019-04-06 17:05:45,684] A3C_AGENT_WORKER-Thread-4 INFO:Local step 29000, global step 468734: loss 6.9691
[2019-04-06 17:05:45,684] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 29000, global step 468734: learning rate 0.0000
[2019-04-06 17:05:48,436] A3C_AGENT_WORKER-Thread-18 INFO:Local step 29500, global step 469002: loss 7.0808
[2019-04-06 17:05:48,436] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 29500, global step 469002: learning rate 0.0000
[2019-04-06 17:05:52,933] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4930582e-13 3.6002574e-16 2.5551051e-11 1.1670426e-14 1.0000000e+00
 9.2718592e-19 6.8940534e-17], sum to 1.0000
[2019-04-06 17:05:52,933] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3009
[2019-04-06 17:05:52,986] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.3, 82.0, 0.0, 0.0, 26.0, 24.80068298505547, 0.2686611442663149, 0.0, 1.0, 42154.22160875007], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2156400.0000, 
sim time next is 2158200.0000, 
raw observation next is [-7.3, 82.0, 0.0, 0.0, 26.0, 24.60089616971013, 0.2308599894039879, 0.0, 1.0, 42283.59833911644], 
processed observation next is [1.0, 1.0, 0.26038781163434904, 0.82, 0.0, 0.0, 0.6666666666666666, 0.5500746808091774, 0.5769533298013293, 0.0, 1.0, 0.20135046828150685], 
reward next is 0.7986, 
noisyNet noise sample is [array([0.75804883], dtype=float32), 0.34942082]. 
=============================================
[2019-04-06 17:05:58,154] A3C_AGENT_WORKER-Thread-15 INFO:Local step 29500, global step 470097: loss 6.7879
[2019-04-06 17:05:58,154] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 29500, global step 470097: learning rate 0.0000
[2019-04-06 17:06:03,076] A3C_AGENT_WORKER-Thread-8 INFO:Local step 29500, global step 470816: loss 6.7439
[2019-04-06 17:06:03,077] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 29500, global step 470816: learning rate 0.0000
[2019-04-06 17:06:04,308] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.4178688e-16 3.8247114e-17 1.0138176e-12 2.0266703e-15 1.0000000e+00
 1.0705839e-20 7.7896938e-18], sum to 1.0000
[2019-04-06 17:06:04,309] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0304
[2019-04-06 17:06:04,529] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.0, 82.0, 19.0, 20.0, 26.0, 25.40747152669786, 0.458351905662983, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1584000.0000, 
sim time next is 1585800.0000, 
raw observation next is [5.8, 79.0, 37.0, 35.0, 26.0, 25.82597413727636, 0.5630200974608539, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.6232686980609419, 0.79, 0.12333333333333334, 0.03867403314917127, 0.6666666666666666, 0.6521645114396968, 0.6876733658202846, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2288704], dtype=float32), -1.1197095]. 
=============================================
[2019-04-06 17:06:13,352] A3C_AGENT_WORKER-Thread-7 INFO:Local step 29500, global step 472100: loss 5.9564
[2019-04-06 17:06:13,353] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 29500, global step 472100: learning rate 0.0000
[2019-04-06 17:06:13,397] A3C_AGENT_WORKER-Thread-17 INFO:Local step 30000, global step 472103: loss 1.4168
[2019-04-06 17:06:13,397] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 30000, global step 472103: learning rate 0.0000
[2019-04-06 17:06:18,373] A3C_AGENT_WORKER-Thread-6 INFO:Local step 29500, global step 472673: loss 5.8737
[2019-04-06 17:06:18,389] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 29500, global step 472673: learning rate 0.0000
[2019-04-06 17:06:19,608] A3C_AGENT_WORKER-Thread-14 INFO:Local step 30000, global step 472801: loss 1.2451
[2019-04-06 17:06:19,609] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 30000, global step 472801: learning rate 0.0000
[2019-04-06 17:06:26,135] A3C_AGENT_WORKER-Thread-3 INFO:Local step 29500, global step 473579: loss 6.8038
[2019-04-06 17:06:26,139] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 29500, global step 473579: learning rate 0.0000
[2019-04-06 17:06:27,421] A3C_AGENT_WORKER-Thread-16 INFO:Local step 29500, global step 473707: loss 6.2706
[2019-04-06 17:06:27,424] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 29500, global step 473707: learning rate 0.0000
[2019-04-06 17:06:30,718] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7723666e-14 2.5381575e-15 1.7440129e-11 2.0897459e-13 1.0000000e+00
 7.3267341e-18 2.6634693e-15], sum to 1.0000
[2019-04-06 17:06:30,718] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5745
[2019-04-06 17:06:30,794] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.25821859883076, 0.08752246323093528, 0.0, 1.0, 41260.234058414666], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2001600.0000, 
sim time next is 2003400.0000, 
raw observation next is [-5.9, 85.0, 0.0, 0.0, 26.0, 24.20788219932998, 0.08951743161975349, 0.0, 1.0, 41403.61163652683], 
processed observation next is [1.0, 0.17391304347826086, 0.2991689750692521, 0.85, 0.0, 0.0, 0.6666666666666666, 0.5173235166108316, 0.5298391438732512, 0.0, 1.0, 0.19716005541203252], 
reward next is 0.8028, 
noisyNet noise sample is [array([2.4939184], dtype=float32), -0.43919304]. 
=============================================
[2019-04-06 17:06:35,896] A3C_AGENT_WORKER-Thread-12 INFO:Local step 29500, global step 474722: loss 6.4579
[2019-04-06 17:06:35,897] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 29500, global step 474722: learning rate 0.0000
[2019-04-06 17:06:38,367] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.50879116e-14 3.22011899e-15 9.54783908e-12 1.18268364e-14
 1.00000000e+00 3.09137280e-17 1.52535242e-16], sum to 1.0000
[2019-04-06 17:06:38,368] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2928
[2019-04-06 17:06:38,469] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.5, 67.0, 0.0, 0.0, 26.0, 25.22425540424171, 0.3497150496911699, 0.0, 1.0, 43272.57731378624], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2849400.0000, 
sim time next is 2851200.0000, 
raw observation next is [1.0, 72.0, 0.0, 0.0, 26.0, 25.14538612015921, 0.3116860846391808, 0.0, 1.0, 47080.602184586045], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.72, 0.0, 0.0, 0.6666666666666666, 0.5954488433466008, 0.6038953615463937, 0.0, 1.0, 0.224193343736124], 
reward next is 0.7758, 
noisyNet noise sample is [array([-0.7192452], dtype=float32), -0.25744528]. 
=============================================
[2019-04-06 17:06:41,808] A3C_AGENT_WORKER-Thread-20 INFO:Local step 29500, global step 475452: loss 6.4069
[2019-04-06 17:06:41,809] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 29500, global step 475452: learning rate 0.0000
[2019-04-06 17:06:42,534] A3C_AGENT_WORKER-Thread-13 INFO:Local step 29500, global step 475533: loss 6.7978
[2019-04-06 17:06:42,534] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 29500, global step 475533: learning rate 0.0000
[2019-04-06 17:06:44,322] A3C_AGENT_WORKER-Thread-5 INFO:Local step 29500, global step 475753: loss 6.2729
[2019-04-06 17:06:44,323] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 29500, global step 475753: learning rate 0.0000
[2019-04-06 17:06:46,126] A3C_AGENT_WORKER-Thread-4 INFO:Local step 29500, global step 475998: loss 6.2889
[2019-04-06 17:06:46,126] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 29500, global step 475998: learning rate 0.0000
[2019-04-06 17:06:46,507] A3C_AGENT_WORKER-Thread-2 INFO:Local step 29500, global step 476042: loss 6.0979
[2019-04-06 17:06:46,509] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 29500, global step 476042: learning rate 0.0000
[2019-04-06 17:06:50,652] A3C_AGENT_WORKER-Thread-19 INFO:Local step 30000, global step 476559: loss 1.0144
[2019-04-06 17:06:50,652] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 30000, global step 476559: learning rate 0.0000
[2019-04-06 17:06:56,035] A3C_AGENT_WORKER-Thread-18 INFO:Local step 30000, global step 477255: loss 1.1593
[2019-04-06 17:06:56,036] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 30000, global step 477255: learning rate 0.0000
[2019-04-06 17:06:59,826] A3C_AGENT_WORKER-Thread-17 INFO:Local step 30500, global step 477805: loss 3.6917
[2019-04-06 17:06:59,827] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 30500, global step 477805: learning rate 0.0000
[2019-04-06 17:07:01,556] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.4744207e-14 2.2993772e-14 9.8420043e-11 1.7316996e-14 1.0000000e+00
 7.0517822e-17 9.2343913e-15], sum to 1.0000
[2019-04-06 17:07:01,590] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2206
[2019-04-06 17:07:01,658] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 26.0, 24.79043117328441, 0.2689245916905573, 0.0, 1.0, 38501.76629110609], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2336400.0000, 
sim time next is 2338200.0000, 
raw observation next is [-2.3, 62.0, 0.0, 0.0, 26.0, 24.78319693598615, 0.2493409324779826, 0.0, 1.0, 38571.23459636968], 
processed observation next is [0.0, 0.043478260869565216, 0.3988919667590028, 0.62, 0.0, 0.0, 0.6666666666666666, 0.5652664113321793, 0.5831136441593275, 0.0, 1.0, 0.18367254569699848], 
reward next is 0.8163, 
noisyNet noise sample is [array([-0.05091279], dtype=float32), 1.4637152]. 
=============================================
[2019-04-06 17:07:03,916] A3C_AGENT_WORKER-Thread-15 INFO:Local step 30000, global step 478349: loss 0.8566
[2019-04-06 17:07:03,929] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 30000, global step 478349: learning rate 0.0000
[2019-04-06 17:07:06,084] A3C_AGENT_WORKER-Thread-14 INFO:Local step 30500, global step 478629: loss 3.5765
[2019-04-06 17:07:06,085] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 30500, global step 478629: learning rate 0.0000
[2019-04-06 17:07:09,385] A3C_AGENT_WORKER-Thread-8 INFO:Local step 30000, global step 479086: loss 0.9464
[2019-04-06 17:07:09,386] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 30000, global step 479086: learning rate 0.0000
[2019-04-06 17:07:15,662] A3C_AGENT_WORKER-Thread-8 INFO:Evaluating...
[2019-04-06 17:07:15,665] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:07:15,666] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:07:15,667] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run25
[2019-04-06 17:07:15,712] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:07:15,713] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:07:15,715] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run25
[2019-04-06 17:07:15,741] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:07:15,742] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:07:15,745] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run25
[2019-04-06 17:08:02,260] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.12204318]
[2019-04-06 17:08:02,260] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [11.55, 70.5, 0.0, 0.0, 26.0, 25.69515429339594, 0.6271681486728952, 0.0, 1.0, 19673.142503930434]
[2019-04-06 17:08:02,261] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 17:08:02,261] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.1995406e-14 1.6782214e-15 1.2518552e-11 2.9091035e-14 1.0000000e+00
 6.7652220e-18 4.7179926e-16], sampled 0.37682409999260724
[2019-04-06 17:09:09,065] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 17:09:47,512] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 17:09:51,713] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 17:09:52,750] A3C_AGENT_WORKER-Thread-8 INFO:Global step: 480000, evaluation results [480000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 17:09:57,252] A3C_AGENT_WORKER-Thread-7 INFO:Local step 30000, global step 480455: loss 1.0995
[2019-04-06 17:09:57,257] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 30000, global step 480455: learning rate 0.0000
[2019-04-06 17:10:06,053] A3C_AGENT_WORKER-Thread-6 INFO:Local step 30000, global step 481303: loss 0.9632
[2019-04-06 17:10:06,054] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 30000, global step 481303: learning rate 0.0000
[2019-04-06 17:10:16,996] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [3.72548468e-15 2.82752409e-16 2.30556286e-12 2.57220545e-14
 1.00000000e+00 4.61713768e-20 1.01811355e-16], sum to 1.0000
[2019-04-06 17:10:16,996] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.0813
[2019-04-06 17:10:17,116] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 47.0, 115.0, 804.0, 26.0, 26.61114080439412, 0.4193792160895333, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3411000.0000, 
sim time next is 3412800.0000, 
raw observation next is [3.0, 45.0, 116.0, 810.5, 26.0, 26.39155767750254, 0.626944445447828, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5457063711911359, 0.45, 0.38666666666666666, 0.8955801104972375, 0.6666666666666666, 0.6992964731252117, 0.7089814818159427, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.435948], dtype=float32), 0.25436795]. 
=============================================
[2019-04-06 17:10:17,567] A3C_AGENT_WORKER-Thread-3 INFO:Local step 30000, global step 482416: loss 1.0379
[2019-04-06 17:10:17,569] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 30000, global step 482416: learning rate 0.0000
[2019-04-06 17:10:18,897] A3C_AGENT_WORKER-Thread-16 INFO:Local step 30000, global step 482564: loss 1.0922
[2019-04-06 17:10:18,914] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 30000, global step 482564: learning rate 0.0000
[2019-04-06 17:10:24,509] A3C_AGENT_WORKER-Thread-19 INFO:Local step 30500, global step 483139: loss 3.0092
[2019-04-06 17:10:24,529] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 30500, global step 483139: learning rate 0.0000
[2019-04-06 17:10:26,476] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4960019e-16 4.8829501e-17 6.0582973e-13 2.0663422e-16 1.0000000e+00
 2.2288046e-20 9.8578872e-17], sum to 1.0000
[2019-04-06 17:10:26,484] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6816
[2019-04-06 17:10:26,546] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 100.0, 0.0, 0.0, 26.0, 25.47615396144981, 0.3179573539675322, 0.0, 1.0, 8221.03808765089], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3115800.0000, 
sim time next is 3117600.0000, 
raw observation next is [1.0, 100.0, 0.0, 0.0, 26.0, 25.25443173141058, 0.3149073818493442, 0.0, 1.0, 65275.649817385034], 
processed observation next is [1.0, 0.08695652173913043, 0.4903047091412743, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6045359776175484, 0.6049691272831147, 0.0, 1.0, 0.3108364277018335], 
reward next is 0.6892, 
noisyNet noise sample is [array([-1.6339842], dtype=float32), -0.05314596]. 
=============================================
[2019-04-06 17:10:31,125] A3C_AGENT_WORKER-Thread-18 INFO:Local step 30500, global step 483833: loss 2.9982
[2019-04-06 17:10:31,128] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 30500, global step 483833: learning rate 0.0000
[2019-04-06 17:10:31,169] A3C_AGENT_WORKER-Thread-12 INFO:Local step 30000, global step 483837: loss 1.1184
[2019-04-06 17:10:31,170] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 30000, global step 483837: learning rate 0.0000
[2019-04-06 17:10:31,544] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [2.7924860e-14 6.5268076e-14 2.4947322e-10 8.9733640e-13 1.0000000e+00
 2.8495485e-16 1.5582747e-14], sum to 1.0000
[2019-04-06 17:10:31,544] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6895
[2019-04-06 17:10:31,697] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.5, 40.5, 14.0, 142.0, 26.0, 25.10677145602385, 0.3783638044239105, 0.0, 1.0, 46873.21871906418], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3605400.0000, 
sim time next is 3607200.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 26.0, 25.09587449216742, 0.3675594387500614, 0.0, 1.0, 36354.76020558336], 
processed observation next is [0.0, 0.782608695652174, 0.4349030470914128, 0.42, 0.0, 0.0, 0.6666666666666666, 0.5913228743472851, 0.6225198129166871, 0.0, 1.0, 0.17311790574087316], 
reward next is 0.8269, 
noisyNet noise sample is [array([-1.460651], dtype=float32), 0.43507034]. 
=============================================
[2019-04-06 17:10:35,624] A3C_AGENT_WORKER-Thread-17 INFO:Local step 31000, global step 484307: loss 3.4378
[2019-04-06 17:10:35,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 31000, global step 484307: learning rate 0.0000
[2019-04-06 17:10:40,519] A3C_AGENT_WORKER-Thread-20 INFO:Local step 30000, global step 484808: loss 1.2736
[2019-04-06 17:10:40,520] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 30000, global step 484808: learning rate 0.0000
[2019-04-06 17:10:41,890] A3C_AGENT_WORKER-Thread-13 INFO:Local step 30000, global step 484952: loss 1.0632
[2019-04-06 17:10:41,890] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 30000, global step 484952: learning rate 0.0000
[2019-04-06 17:10:43,477] A3C_AGENT_WORKER-Thread-14 INFO:Local step 31000, global step 485120: loss 3.4643
[2019-04-06 17:10:43,478] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 31000, global step 485120: learning rate 0.0000
[2019-04-06 17:10:44,986] A3C_AGENT_WORKER-Thread-5 INFO:Local step 30000, global step 485280: loss 1.0585
[2019-04-06 17:10:44,987] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 30000, global step 485280: learning rate 0.0000
[2019-04-06 17:10:46,037] A3C_AGENT_WORKER-Thread-15 INFO:Local step 30500, global step 485376: loss 2.9239
[2019-04-06 17:10:46,037] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 30500, global step 485376: learning rate 0.0000
[2019-04-06 17:10:48,954] A3C_AGENT_WORKER-Thread-4 INFO:Local step 30000, global step 485681: loss 1.0249
[2019-04-06 17:10:48,969] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 30000, global step 485681: learning rate 0.0000
[2019-04-06 17:10:51,648] A3C_AGENT_WORKER-Thread-2 INFO:Local step 30000, global step 485982: loss 1.0444
[2019-04-06 17:10:51,649] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 30000, global step 485982: learning rate 0.0000
[2019-04-06 17:10:54,394] A3C_AGENT_WORKER-Thread-8 INFO:Local step 30500, global step 486294: loss 3.0306
[2019-04-06 17:10:54,394] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 30500, global step 486294: learning rate 0.0000
[2019-04-06 17:10:56,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:10:56,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:10:56,166] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run12
[2019-04-06 17:11:04,401] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:11:04,401] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:11:04,404] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run12
[2019-04-06 17:11:08,769] A3C_AGENT_WORKER-Thread-7 INFO:Local step 30500, global step 487775: loss 2.7160
[2019-04-06 17:11:08,770] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 30500, global step 487775: learning rate 0.0000
[2019-04-06 17:11:15,565] A3C_AGENT_WORKER-Thread-6 INFO:Local step 30500, global step 488545: loss 2.8934
[2019-04-06 17:11:15,566] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 30500, global step 488545: learning rate 0.0000
[2019-04-06 17:11:24,227] A3C_AGENT_WORKER-Thread-3 INFO:Local step 30500, global step 489920: loss 2.5434
[2019-04-06 17:11:24,228] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 30500, global step 489920: learning rate 0.0000
[2019-04-06 17:11:25,570] A3C_AGENT_WORKER-Thread-16 INFO:Local step 30500, global step 490139: loss 2.6164
[2019-04-06 17:11:25,571] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 30500, global step 490139: learning rate 0.0000
[2019-04-06 17:11:26,601] A3C_AGENT_WORKER-Thread-19 INFO:Local step 31000, global step 490309: loss 3.7531
[2019-04-06 17:11:26,602] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 31000, global step 490309: learning rate 0.0000
[2019-04-06 17:11:30,890] A3C_AGENT_WORKER-Thread-18 INFO:Local step 31000, global step 491055: loss 3.7540
[2019-04-06 17:11:30,892] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 31000, global step 491056: learning rate 0.0000
[2019-04-06 17:11:32,483] A3C_AGENT_WORKER-Thread-12 INFO:Local step 30500, global step 491354: loss 2.5505
[2019-04-06 17:11:32,484] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 30500, global step 491354: learning rate 0.0000
[2019-04-06 17:11:39,225] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5530120e-15 4.0754440e-15 1.8126219e-11 4.9861079e-14 1.0000000e+00
 3.2497924e-18 5.1955989e-15], sum to 1.0000
[2019-04-06 17:11:39,225] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1052
[2019-04-06 17:11:39,270] A3C_AGENT_WORKER-Thread-20 INFO:Local step 30500, global step 492547: loss 2.3370
[2019-04-06 17:11:39,270] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 30500, global step 492547: learning rate 0.0000
[2019-04-06 17:11:39,322] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.5, 25.5, 72.0, 641.0, 26.0, 28.0150682705377, 0.8218324351388824, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4984200.0000, 
sim time next is 4986000.0000, 
raw observation next is [8.0, 26.0, 53.0, 472.5, 26.0, 26.99263414235079, 0.827476345871776, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.6842105263157896, 0.26, 0.17666666666666667, 0.5220994475138122, 0.6666666666666666, 0.7493861785292326, 0.7758254486239253, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5679559], dtype=float32), -0.26432344]. 
=============================================
[2019-04-06 17:11:39,348] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[84.106514]
 [83.9581  ]
 [83.99622 ]
 [84.09529 ]
 [83.9168  ]], R is [[83.74777222]
 [83.91029358]
 [84.07118988]
 [84.23047638]
 [84.38817596]].
[2019-04-06 17:11:40,180] A3C_AGENT_WORKER-Thread-13 INFO:Local step 30500, global step 492695: loss 2.2775
[2019-04-06 17:11:40,180] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 30500, global step 492695: learning rate 0.0000
[2019-04-06 17:11:40,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:11:40,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:11:41,000] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run12
[2019-04-06 17:11:41,656] A3C_AGENT_WORKER-Thread-15 INFO:Local step 31000, global step 492925: loss 3.8487
[2019-04-06 17:11:41,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 31000, global step 492925: learning rate 0.0000
[2019-04-06 17:11:42,095] A3C_AGENT_WORKER-Thread-5 INFO:Local step 30500, global step 492990: loss 2.3007
[2019-04-06 17:11:42,098] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 30500, global step 492990: learning rate 0.0000
[2019-04-06 17:11:45,140] A3C_AGENT_WORKER-Thread-4 INFO:Local step 30500, global step 493444: loss 2.2758
[2019-04-06 17:11:45,141] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 30500, global step 493444: learning rate 0.0000
[2019-04-06 17:11:45,289] A3C_AGENT_WORKER-Thread-2 INFO:Local step 30500, global step 493468: loss 2.1571
[2019-04-06 17:11:45,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 30500, global step 493468: learning rate 0.0000
[2019-04-06 17:11:45,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:11:45,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:11:45,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run12
[2019-04-06 17:11:48,125] A3C_AGENT_WORKER-Thread-8 INFO:Local step 31000, global step 493846: loss 3.8398
[2019-04-06 17:11:48,126] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 31000, global step 493846: learning rate 0.0000
[2019-04-06 17:11:51,221] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.0994253e-15 1.2001802e-16 9.4076873e-12 2.8987182e-14 1.0000000e+00
 1.7229398e-17 5.0826195e-17], sum to 1.0000
[2019-04-06 17:11:51,222] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5666
[2019-04-06 17:11:51,338] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 33.0, 118.0, 841.0, 26.0, 26.45677584152586, 0.4343355185828049, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4019400.0000, 
sim time next is 4021200.0000, 
raw observation next is [-4.0, 29.0, 116.0, 835.5, 26.0, 25.96864533647636, 0.5380574778896223, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3518005540166205, 0.29, 0.38666666666666666, 0.9232044198895027, 0.6666666666666666, 0.6640537780396967, 0.6793524926298741, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9662637], dtype=float32), -1.1939288]. 
=============================================
[2019-04-06 17:11:56,113] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:11:56,113] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:11:56,117] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run12
[2019-04-06 17:11:57,077] A3C_AGENT_WORKER-Thread-7 INFO:Local step 31000, global step 495241: loss 3.9072
[2019-04-06 17:11:57,078] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 31000, global step 495241: learning rate 0.0000
[2019-04-06 17:12:00,477] A3C_AGENT_WORKER-Thread-6 INFO:Local step 31000, global step 495715: loss 3.8624
[2019-04-06 17:12:00,479] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 31000, global step 495715: learning rate 0.0000
[2019-04-06 17:12:02,523] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:12:02,523] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:12:02,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run12
[2019-04-06 17:12:07,589] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.78457302e-14 1.39075915e-14 1.45189027e-10 2.47595184e-13
 1.00000000e+00 1.17498386e-16 1.85897304e-14], sum to 1.0000
[2019-04-06 17:12:07,590] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0569
[2019-04-06 17:12:07,651] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 80.5, 0.0, 0.0, 26.0, 24.22129491139195, 0.1033303705828422, 0.0, 1.0, 42341.00652703562], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 613800.0000, 
sim time next is 615600.0000, 
raw observation next is [-3.9, 75.0, 0.0, 0.0, 26.0, 24.15762027846753, 0.08689053066443654, 0.0, 1.0, 42687.229158405455], 
processed observation next is [0.0, 0.13043478260869565, 0.3545706371191136, 0.75, 0.0, 0.0, 0.6666666666666666, 0.5131350232056274, 0.5289635102214788, 0.0, 1.0, 0.20327251980193073], 
reward next is 0.7967, 
noisyNet noise sample is [array([-1.021742], dtype=float32), -0.46775725]. 
=============================================
[2019-04-06 17:12:08,404] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.4251860e-15 1.3090402e-16 4.0270174e-12 6.1150527e-14 1.0000000e+00
 1.3604479e-18 4.3451588e-16], sum to 1.0000
[2019-04-06 17:12:08,404] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1682
[2019-04-06 17:12:08,464] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.0, 25.5, 34.0, 304.0, 26.0, 27.50523803938095, 0.8256053838767308, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4987800.0000, 
sim time next is 4989600.0000, 
raw observation next is [6.0, 25.0, 17.0, 152.0, 26.0, 27.21147079733535, 0.6694008929908072, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6288088642659281, 0.25, 0.056666666666666664, 0.16795580110497238, 0.6666666666666666, 0.7676225664446124, 0.7231336309969357, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7543495], dtype=float32), -1.1443936]. 
=============================================
[2019-04-06 17:12:10,473] A3C_AGENT_WORKER-Thread-3 INFO:Local step 31000, global step 497251: loss 3.8832
[2019-04-06 17:12:10,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 31000, global step 497251: learning rate 0.0000
[2019-04-06 17:12:10,600] A3C_AGENT_WORKER-Thread-16 INFO:Local step 31000, global step 497272: loss 3.9248
[2019-04-06 17:12:10,601] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 31000, global step 497272: learning rate 0.0000
[2019-04-06 17:12:11,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:12:11,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:12:11,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run12
[2019-04-06 17:12:14,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:12:14,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:12:14,112] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run12
[2019-04-06 17:12:17,317] A3C_AGENT_WORKER-Thread-12 INFO:Local step 31000, global step 498145: loss 3.9085
[2019-04-06 17:12:17,318] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 31000, global step 498145: learning rate 0.0000
[2019-04-06 17:12:24,145] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:12:24,145] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:12:24,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run12
[2019-04-06 17:12:24,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:12:24,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:12:24,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run12
[2019-04-06 17:12:24,883] A3C_AGENT_WORKER-Thread-20 INFO:Local step 31000, global step 499147: loss 3.9447
[2019-04-06 17:12:24,883] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 31000, global step 499147: learning rate 0.0000
[2019-04-06 17:12:25,849] A3C_AGENT_WORKER-Thread-13 INFO:Local step 31000, global step 499236: loss 3.9900
[2019-04-06 17:12:25,849] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 31000, global step 499236: learning rate 0.0000
[2019-04-06 17:12:28,071] A3C_AGENT_WORKER-Thread-5 INFO:Local step 31000, global step 499533: loss 3.9927
[2019-04-06 17:12:28,072] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 31000, global step 499533: learning rate 0.0000
[2019-04-06 17:12:30,588] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.60665143e-13 2.37368430e-14 7.68002273e-10 2.07797307e-13
 1.00000000e+00 1.21656232e-16 1.15302385e-14], sum to 1.0000
[2019-04-06 17:12:30,588] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7871
[2019-04-06 17:12:30,727] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.45, 26.5, 129.0, 0.0, 26.0, 25.16614446715232, 0.1541813295975249, 1.0, 1.0, 6598.571179839553], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 477000.0000, 
sim time next is 478800.0000, 
raw observation next is [-1.2, 28.0, 124.0, 0.0, 26.0, 24.98724069567509, 0.1569603197840842, 1.0, 1.0, 71522.9033566122], 
processed observation next is [1.0, 0.5652173913043478, 0.42936288088642666, 0.28, 0.41333333333333333, 0.0, 0.6666666666666666, 0.5822700579729242, 0.5523201065946948, 1.0, 1.0, 0.34058525407910567], 
reward next is 0.6594, 
noisyNet noise sample is [array([0.00660399], dtype=float32), -0.16047671]. 
=============================================
[2019-04-06 17:12:31,015] A3C_AGENT_WORKER-Thread-4 INFO:Local step 31000, global step 499858: loss 4.0857
[2019-04-06 17:12:31,016] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 31000, global step 499858: learning rate 0.0000
[2019-04-06 17:12:31,068] A3C_AGENT_WORKER-Thread-2 INFO:Local step 31000, global step 499865: loss 4.0213
[2019-04-06 17:12:31,068] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 31000, global step 499865: learning rate 0.0000
[2019-04-06 17:12:31,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:12:31,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:12:31,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run12
[2019-04-06 17:12:32,157] A3C_AGENT_WORKER-Thread-8 INFO:Evaluating...
[2019-04-06 17:12:32,173] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:12:32,174] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:12:32,175] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:12:32,176] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:12:32,177] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run26
[2019-04-06 17:12:32,191] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:12:32,193] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:12:32,195] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run26
[2019-04-06 17:12:32,217] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run26
[2019-04-06 17:14:30,322] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 17:15:08,758] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 17:15:14,597] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 17:15:15,635] A3C_AGENT_WORKER-Thread-8 INFO:Global step: 500000, evaluation results [500000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 17:15:23,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:15:23,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:15:23,884] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run12
[2019-04-06 17:15:26,848] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:15:26,850] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:15:26,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run12
[2019-04-06 17:15:28,976] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1577845e-14 2.4993994e-14 1.5549784e-11 5.7340952e-14 1.0000000e+00
 4.4802316e-17 5.2614773e-15], sum to 1.0000
[2019-04-06 17:15:28,976] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9139
[2019-04-06 17:15:29,142] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.8, 87.0, 0.0, 0.0, 26.0, 25.130935806197, 0.3122028309275541, 0.0, 1.0, 49203.40784417887], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 590400.0000, 
sim time next is 592200.0000, 
raw observation next is [-2.8, 85.0, 0.0, 0.0, 26.0, 25.10262043208361, 0.3045786217422224, 0.0, 1.0, 43457.59209768331], 
processed observation next is [0.0, 0.8695652173913043, 0.38504155124653744, 0.85, 0.0, 0.0, 0.6666666666666666, 0.5918850360069676, 0.6015262072474075, 0.0, 1.0, 0.2069409147508729], 
reward next is 0.7931, 
noisyNet noise sample is [array([-1.6631268], dtype=float32), 2.2797067]. 
=============================================
[2019-04-06 17:15:30,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:15:30,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:15:30,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run12
[2019-04-06 17:15:34,378] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:15:34,378] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:15:34,382] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run12
[2019-04-06 17:15:35,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:15:35,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:15:35,836] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run12
[2019-04-06 17:15:53,975] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3354751e-14 6.0325665e-15 6.5834553e-11 2.0551903e-13 1.0000000e+00
 9.9431982e-18 2.6207460e-15], sum to 1.0000
[2019-04-06 17:15:53,975] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5238
[2019-04-06 17:15:54,136] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-10.05, 68.5, 0.0, 0.0, 26.0, 23.20700324905273, -0.1286407402323012, 0.0, 1.0, 46906.07719272264], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 275400.0000, 
sim time next is 277200.0000, 
raw observation next is [-10.6, 67.0, 0.0, 0.0, 26.0, 23.02366588159116, -0.1677103414263937, 0.0, 1.0, 47404.33181831649], 
processed observation next is [1.0, 0.21739130434782608, 0.1689750692520776, 0.67, 0.0, 0.0, 0.6666666666666666, 0.41863882346593, 0.4440965528578688, 0.0, 1.0, 0.2257349134205547], 
reward next is 0.7743, 
noisyNet noise sample is [array([-0.01744421], dtype=float32), 2.072096]. 
=============================================
[2019-04-06 17:16:20,942] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.2776871e-15 6.1472289e-16 3.9067482e-11 3.2919156e-14 1.0000000e+00
 5.0376002e-19 7.1496500e-16], sum to 1.0000
[2019-04-06 17:16:20,942] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3867
[2019-04-06 17:16:21,117] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.3, 96.0, 0.0, 0.0, 26.0, 24.71114540386998, 0.4497393335498525, 0.0, 1.0, 25762.045970028834], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1274400.0000, 
sim time next is 1276200.0000, 
raw observation next is [7.75, 96.0, 0.0, 0.0, 26.0, 24.69607936269874, 0.4428310574420908, 0.0, 1.0, 24383.236539530695], 
processed observation next is [0.0, 0.782608695652174, 0.6772853185595569, 0.96, 0.0, 0.0, 0.6666666666666666, 0.5580066135582283, 0.647610352480697, 0.0, 1.0, 0.1161106501882414], 
reward next is 0.8839, 
noisyNet noise sample is [array([-1.8578279], dtype=float32), 2.0070846]. 
=============================================
[2019-04-06 17:16:51,948] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5760191e-16 1.5469164e-16 1.6279810e-12 1.2297020e-15 1.0000000e+00
 7.9740476e-20 9.4059187e-18], sum to 1.0000
[2019-04-06 17:16:51,948] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7421
[2019-04-06 17:16:51,999] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 106.0, 0.0, 26.0, 25.70816588002176, 0.5290477863860219, 1.0, 1.0, 37733.059708026296], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1344600.0000, 
sim time next is 1346400.0000, 
raw observation next is [1.1, 92.0, 88.5, 0.0, 26.0, 25.77855220910201, 0.5440307429111905, 1.0, 1.0, 8953.600959601898], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.92, 0.295, 0.0, 0.6666666666666666, 0.6482126840918342, 0.6813435809703968, 1.0, 1.0, 0.04263619504572332], 
reward next is 0.9574, 
noisyNet noise sample is [array([-0.08997896], dtype=float32), 0.68515503]. 
=============================================
[2019-04-06 17:16:54,100] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.4879325e-13 3.2963327e-14 2.6940294e-10 7.2372094e-13 1.0000000e+00
 1.3837466e-15 5.1275543e-14], sum to 1.0000
[2019-04-06 17:16:54,100] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9250
[2019-04-06 17:16:54,208] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-11.2, 52.0, 0.0, 0.0, 26.0, 22.89285618559315, -0.2409448050769294, 0.0, 1.0, 46298.95452358046], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 446400.0000, 
sim time next is 448200.0000, 
raw observation next is [-10.9, 52.0, 0.0, 0.0, 26.0, 22.70761050575477, -0.2578626216070197, 0.0, 1.0, 46613.220468560634], 
processed observation next is [1.0, 0.17391304347826086, 0.16066481994459833, 0.52, 0.0, 0.0, 0.6666666666666666, 0.39230087547956405, 0.41404579279766013, 0.0, 1.0, 0.2219677165169554], 
reward next is 0.7780, 
noisyNet noise sample is [array([-1.2382795], dtype=float32), -0.33209518]. 
=============================================
[2019-04-06 17:17:05,090] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.8877627e-15 4.9836449e-18 2.4209641e-13 6.8329254e-15 1.0000000e+00
 1.6237886e-19 1.7309836e-17], sum to 1.0000
[2019-04-06 17:17:05,090] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0732
[2019-04-06 17:17:05,175] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.0, 89.0, 0.0, 0.0, 26.0, 24.84487043586205, 0.2558227028016593, 0.0, 1.0, 39733.31165664175], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 522000.0000, 
sim time next is 523800.0000, 
raw observation next is [4.65, 88.5, 0.0, 0.0, 26.0, 25.02973844973089, 0.2586517493135633, 0.0, 1.0, 39547.2578415889], 
processed observation next is [0.0, 0.043478260869565216, 0.5914127423822716, 0.885, 0.0, 0.0, 0.6666666666666666, 0.5858115374775741, 0.5862172497711877, 0.0, 1.0, 0.1883202754361376], 
reward next is 0.8117, 
noisyNet noise sample is [array([-0.42890373], dtype=float32), -0.19403942]. 
=============================================
[2019-04-06 17:17:11,381] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6752192e-14 1.6183139e-14 1.1928955e-12 1.2520354e-13 1.0000000e+00
 4.5876145e-17 3.0505623e-15], sum to 1.0000
[2019-04-06 17:17:11,381] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6871
[2019-04-06 17:17:11,630] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.3, 73.0, 184.0, 81.0, 26.0, 24.94885415013587, 0.2594453386430056, 0.0, 1.0, 48283.97706839114], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1855800.0000, 
sim time next is 1857600.0000, 
raw observation next is [-5.0, 71.0, 152.0, 40.5, 26.0, 24.98430078594512, 0.2632197226867747, 0.0, 1.0, 39311.0313140884], 
processed observation next is [0.0, 0.5217391304347826, 0.32409972299168976, 0.71, 0.5066666666666667, 0.044751381215469614, 0.6666666666666666, 0.5820250654954267, 0.5877399075622582, 0.0, 1.0, 0.18719538720994477], 
reward next is 0.8128, 
noisyNet noise sample is [array([-0.6414187], dtype=float32), 0.09409634]. 
=============================================
[2019-04-06 17:17:16,296] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7470451e-17 3.2650268e-18 1.2468789e-12 1.1398640e-15 1.0000000e+00
 1.0934784e-21 9.0654026e-20], sum to 1.0000
[2019-04-06 17:17:16,297] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6921
[2019-04-06 17:17:16,491] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.8, 93.0, 93.0, 0.0, 26.0, 25.32515472872909, 0.3852792965187488, 1.0, 1.0, 111089.18096922843], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 914400.0000, 
sim time next is 916200.0000, 
raw observation next is [4.1, 93.0, 90.0, 0.0, 26.0, 25.97488569134688, 0.3419699630765541, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5761772853185596, 0.93, 0.3, 0.0, 0.6666666666666666, 0.66457380761224, 0.6139899876921847, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.21696422], dtype=float32), 1.3841867]. 
=============================================
[2019-04-06 17:17:52,549] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.6359791e-14 1.3363356e-17 9.7897406e-13 6.5261445e-15 1.0000000e+00
 4.1892397e-20 3.3941990e-17], sum to 1.0000
[2019-04-06 17:17:52,550] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6061
[2019-04-06 17:17:52,578] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.0996639e-17 1.6647714e-18 5.3607906e-15 2.5417399e-17 1.0000000e+00
 4.6718256e-22 1.3473856e-19], sum to 1.0000
[2019-04-06 17:17:52,578] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3718
[2019-04-06 17:17:52,623] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 26.0, 25.55342863983919, 0.532603365530576, 0.0, 1.0, 6248.066932902356], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1315800.0000, 
sim time next is 1317600.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 26.0, 25.48870702835625, 0.5215565398960883, 0.0, 1.0, 43780.17605871599], 
processed observation next is [1.0, 0.2608695652173913, 0.5069252077562327, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6240589190296874, 0.6738521799653627, 0.0, 1.0, 0.2084770288510285], 
reward next is 0.7915, 
noisyNet noise sample is [array([0.8508758], dtype=float32), 0.4173784]. 
=============================================
[2019-04-06 17:17:52,637] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 88.5, 0.0, 26.0, 25.77855220910201, 0.5440307429111905, 1.0, 1.0, 8953.600959601898], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1346400.0000, 
sim time next is 1348200.0000, 
raw observation next is [1.1, 92.0, 71.0, 0.0, 26.0, 25.85070378339378, 0.543282204762809, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.92, 0.23666666666666666, 0.0, 0.6666666666666666, 0.6542253152828149, 0.6810940682542697, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.941644], dtype=float32), 0.3144502]. 
=============================================
[2019-04-06 17:18:15,940] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7238103e-14 4.3994336e-15 1.9720148e-12 1.0926073e-13 1.0000000e+00
 2.2879020e-18 8.4351878e-15], sum to 1.0000
[2019-04-06 17:18:15,940] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2576
[2019-04-06 17:18:16,006] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.2, 87.0, 0.0, 0.0, 26.0, 24.91467897073873, 0.3439391735990109, 0.0, 1.0, 43751.73641460026], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1749600.0000, 
sim time next is 1751400.0000, 
raw observation next is [-1.45, 87.0, 0.0, 0.0, 26.0, 24.8304955237997, 0.3273532531583538, 0.0, 1.0, 43914.544026034426], 
processed observation next is [0.0, 0.2608695652173913, 0.422437673130194, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5692079603166418, 0.6091177510527847, 0.0, 1.0, 0.20911687631444964], 
reward next is 0.7909, 
noisyNet noise sample is [array([-0.12394419], dtype=float32), 1.5738595]. 
=============================================
[2019-04-06 17:18:29,846] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-06 17:18:29,847] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:18:29,847] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:18:29,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run27
[2019-04-06 17:18:29,871] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:18:29,872] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:18:29,873] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:18:29,878] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:18:29,879] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run27
[2019-04-06 17:18:29,901] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run27
[2019-04-06 17:18:58,245] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.12436925]
[2019-04-06 17:18:58,245] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-3.65, 70.0, 0.0, 0.0, 26.0, 24.71147647869514, 0.1608814635250343, 0.0, 1.0, 41843.920408450154]
[2019-04-06 17:18:58,245] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 17:18:58,246] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.5089386e-13 2.5272077e-14 8.6267125e-11 4.1042015e-13 1.0000000e+00
 1.6262831e-16 8.4240933e-15], sampled 0.12851852713414458
[2019-04-06 17:20:02,595] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.12436925]
[2019-04-06 17:20:02,596] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [3.685667318, 100.0, 0.0, 0.0, 26.0, 24.80543757442348, 0.2188550939676014, 0.0, 1.0, 54150.220389253045]
[2019-04-06 17:20:02,596] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 17:20:02,597] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.7501407e-15 2.6716391e-16 3.4134898e-12 5.1237192e-15 1.0000000e+00
 5.6197208e-19 5.5054630e-17], sampled 0.8306088123149125
[2019-04-06 17:20:27,902] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 17:21:03,662] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 17:21:07,657] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.12436925]
[2019-04-06 17:21:07,658] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [5.965361853, 31.79937678, 174.207764, 650.1827131, 26.0, 26.96905572571629, 0.7214628772293, 1.0, 1.0, 0.0]
[2019-04-06 17:21:07,658] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 17:21:07,659] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [5.1032207e-14 1.5736658e-14 8.6799734e-11 2.1291587e-13 1.0000000e+00
 6.0593832e-17 5.8850943e-15], sampled 0.3320649023226627
[2019-04-06 17:21:10,176] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 17:21:11,214] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 520000, evaluation results [520000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 17:21:15,681] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3882615e-12 2.9367919e-12 6.4160459e-09 6.3223773e-11 1.0000000e+00
 1.1644329e-13 6.7226753e-13], sum to 1.0000
[2019-04-06 17:21:15,681] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7713
[2019-04-06 17:21:15,976] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.5, 40.5, 14.0, 142.0, 26.0, 25.10677145602385, 0.3783638044239105, 0.0, 1.0, 46873.21871906418], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3605400.0000, 
sim time next is 3607200.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 26.0, 25.09587449216742, 0.3675594387500614, 0.0, 1.0, 36354.76020558336], 
processed observation next is [0.0, 0.782608695652174, 0.4349030470914128, 0.42, 0.0, 0.0, 0.6666666666666666, 0.5913228743472851, 0.6225198129166871, 0.0, 1.0, 0.17311790574087316], 
reward next is 0.8269, 
noisyNet noise sample is [array([0.06862615], dtype=float32), -0.8308916]. 
=============================================
[2019-04-06 17:21:19,366] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.8535497e-16 9.0979163e-16 7.1473910e-11 1.8837449e-13 1.0000000e+00
 1.5831933e-19 2.6263404e-15], sum to 1.0000
[2019-04-06 17:21:19,366] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6108
[2019-04-06 17:21:19,674] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 79.0, 0.0, 0.0, 26.0, 25.37747569202388, 0.3459453311999673, 1.0, 1.0, 25714.993261988184], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1965600.0000, 
sim time next is 1967400.0000, 
raw observation next is [-4.75, 75.0, 0.0, 0.0, 26.0, 25.13649043862814, 0.3018501048663284, 1.0, 1.0, 47580.95198049431], 
processed observation next is [1.0, 0.782608695652174, 0.3310249307479225, 0.75, 0.0, 0.0, 0.6666666666666666, 0.594707536552345, 0.6006167016221095, 1.0, 1.0, 0.22657596181187767], 
reward next is 0.7734, 
noisyNet noise sample is [array([-0.3854367], dtype=float32), -0.77271986]. 
=============================================
[2019-04-06 17:21:23,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.71011320e-16 3.80900314e-16 9.83885933e-13 1.31264124e-15
 1.00000000e+00 6.35390412e-19 1.05672985e-16], sum to 1.0000
[2019-04-06 17:21:23,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9452
[2019-04-06 17:21:23,538] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.03988062190703, 0.02395870708419182, 0.0, 1.0, 41156.766340275746], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2010600.0000, 
sim time next is 2012400.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 26.0, 23.97669252080172, 0.03614394723763355, 0.0, 1.0, 41138.12006259239], 
processed observation next is [1.0, 0.30434782608695654, 0.2908587257617729, 0.87, 0.0, 0.0, 0.6666666666666666, 0.49805771006681, 0.5120479824125445, 0.0, 1.0, 0.19589580982186852], 
reward next is 0.8041, 
noisyNet noise sample is [array([-0.4810488], dtype=float32), -1.2609832]. 
=============================================
[2019-04-06 17:21:55,982] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.2031466e-14 1.9373613e-16 8.3356599e-11 2.6483595e-14 1.0000000e+00
 1.2761963e-17 4.0047980e-15], sum to 1.0000
[2019-04-06 17:21:55,982] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0564
[2019-04-06 17:21:56,320] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.6, 70.0, 0.0, 0.0, 26.0, 25.61073404656082, 0.398345887876014, 0.0, 1.0, 6455.798281200089], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2228400.0000, 
sim time next is 2230200.0000, 
raw observation next is [-4.8, 70.5, 0.0, 0.0, 26.0, 25.09577336604728, 0.345559504325844, 1.0, 1.0, 56828.75138939277], 
processed observation next is [1.0, 0.8260869565217391, 0.3296398891966759, 0.705, 0.0, 0.0, 0.6666666666666666, 0.5913144471706065, 0.615186501441948, 1.0, 1.0, 0.2706131018542513], 
reward next is 0.7294, 
noisyNet noise sample is [array([-1.7701764], dtype=float32), 0.829284]. 
=============================================
[2019-04-06 17:22:09,847] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2072177e-15 1.9761074e-16 6.2648272e-12 1.8215740e-15 1.0000000e+00
 4.5193662e-18 3.0832952e-16], sum to 1.0000
[2019-04-06 17:22:09,847] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3579
[2019-04-06 17:22:09,960] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.1, 69.0, 0.0, 0.0, 26.0, 25.41429053910755, 0.4430116676948388, 0.0, 1.0, 54558.490263664426], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2671200.0000, 
sim time next is 2673000.0000, 
raw observation next is [-4.05, 69.0, 0.0, 0.0, 26.0, 25.22055351898411, 0.3592776023462027, 0.0, 1.0, 54443.64019698595], 
processed observation next is [1.0, 0.9565217391304348, 0.350415512465374, 0.69, 0.0, 0.0, 0.6666666666666666, 0.601712793248676, 0.6197592007820676, 0.0, 1.0, 0.2592554295094569], 
reward next is 0.7407, 
noisyNet noise sample is [array([-0.87296563], dtype=float32), 1.3482815]. 
=============================================
[2019-04-06 17:22:09,969] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[82.67846 ]
 [81.66443 ]
 [81.542694]
 [80.050644]
 [79.48743 ]], R is [[83.29380798]
 [83.20106506]
 [83.28981018]
 [83.18782043]
 [82.83007812]].
[2019-04-06 17:22:17,914] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7264281e-16 1.7270592e-17 4.1701137e-13 2.4142523e-15 1.0000000e+00
 1.2415687e-18 1.3466926e-18], sum to 1.0000
[2019-04-06 17:22:17,915] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0500
[2019-04-06 17:22:18,026] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.8500000000000001, 72.0, 0.0, 0.0, 26.0, 25.22922817742849, 0.41009077010533, 0.0, 1.0, 43320.48035370261], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4509000.0000, 
sim time next is 4510800.0000, 
raw observation next is [-0.8, 71.0, 0.0, 0.0, 26.0, 25.31329197640854, 0.4176870613421313, 0.0, 1.0, 41652.69817569179], 
processed observation next is [1.0, 0.21739130434782608, 0.4404432132963989, 0.71, 0.0, 0.0, 0.6666666666666666, 0.609440998034045, 0.6392290204473771, 0.0, 1.0, 0.1983461817890085], 
reward next is 0.8017, 
noisyNet noise sample is [array([1.0166484], dtype=float32), -0.39384803]. 
=============================================
[2019-04-06 17:22:36,540] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.7720630e-16 1.1334202e-16 8.1018546e-14 1.0155191e-15 1.0000000e+00
 1.9200830e-19 1.1623491e-17], sum to 1.0000
[2019-04-06 17:22:36,541] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2760
[2019-04-06 17:22:36,584] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 26.0, 25.42836515847856, 0.541925388880079, 0.0, 1.0, 77008.1571762154], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3276000.0000, 
sim time next is 3277800.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 26.0, 25.3860730028754, 0.4808073182012942, 0.0, 1.0, 56045.52961964544], 
processed observation next is [1.0, 0.9565217391304348, 0.296398891966759, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6155060835729499, 0.6602691060670981, 0.0, 1.0, 0.26688347437926396], 
reward next is 0.7331, 
noisyNet noise sample is [array([0.976847], dtype=float32), -0.55893]. 
=============================================
[2019-04-06 17:22:54,693] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:22:54,693] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:22:54,696] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run13
[2019-04-06 17:23:00,102] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:23:00,102] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:23:00,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run13
[2019-04-06 17:23:04,580] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0008585e-15 4.2646957e-15 1.6706110e-11 8.4798759e-14 1.0000000e+00
 6.5173523e-18 5.7205163e-14], sum to 1.0000
[2019-04-06 17:23:04,581] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3130
[2019-04-06 17:23:04,716] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 55.0, 0.0, 0.0, 26.0, 25.45668260026633, 0.5415430522568515, 1.0, 1.0, 81545.04153964309], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3348000.0000, 
sim time next is 3349800.0000, 
raw observation next is [-3.0, 55.0, 0.0, 0.0, 26.0, 25.90905288320641, 0.5413429664714825, 1.0, 1.0, 10662.592943808444], 
processed observation next is [1.0, 0.782608695652174, 0.3795013850415513, 0.55, 0.0, 0.0, 0.6666666666666666, 0.6590877402672009, 0.6804476554904942, 1.0, 1.0, 0.050774252113373546], 
reward next is 0.9492, 
noisyNet noise sample is [array([0.14323558], dtype=float32), 0.45049685]. 
=============================================
[2019-04-06 17:23:08,719] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.1999051e-13 1.8353934e-13 2.6539676e-10 1.4982559e-13 1.0000000e+00
 6.6753217e-17 2.3224792e-13], sum to 1.0000
[2019-04-06 17:23:08,719] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2690
[2019-04-06 17:23:08,932] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 54.0, 106.0, 759.0, 26.0, 25.13153105868141, 0.3080045427752775, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3061800.0000, 
sim time next is 3063600.0000, 
raw observation next is [-4.0, 54.0, 108.5, 782.0, 26.0, 25.0453788942946, 0.3334016778894264, 0.0, 1.0, 44288.570062147635], 
processed observation next is [0.0, 0.4782608695652174, 0.3518005540166205, 0.54, 0.3616666666666667, 0.8640883977900552, 0.6666666666666666, 0.5871149078578833, 0.6111338926298088, 0.0, 1.0, 0.2108979526768935], 
reward next is 0.7891, 
noisyNet noise sample is [array([1.3040193], dtype=float32), -0.7542119]. 
=============================================
[2019-04-06 17:23:14,262] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2404569e-17 1.2613804e-18 2.2654921e-13 3.0701837e-17 1.0000000e+00
 1.3600833e-20 3.4107719e-18], sum to 1.0000
[2019-04-06 17:23:14,262] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0332
[2019-04-06 17:23:14,437] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.65, 65.5, 92.0, 491.0, 26.0, 25.8040911917205, 0.5065288349302196, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4350600.0000, 
sim time next is 4352400.0000, 
raw observation next is [6.3, 57.0, 99.5, 584.0, 26.0, 26.37276662652103, 0.5789365461142286, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6371191135734073, 0.57, 0.33166666666666667, 0.6453038674033149, 0.6666666666666666, 0.697730552210086, 0.6929788487047429, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.47005057], dtype=float32), 1.4204929]. 
=============================================
[2019-04-06 17:23:19,320] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9596834e-15 7.5997384e-16 1.6188404e-12 3.1433541e-15 1.0000000e+00
 6.1029220e-18 2.4190804e-17], sum to 1.0000
[2019-04-06 17:23:19,334] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9650
[2019-04-06 17:23:19,403] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.5, 88.0, 0.0, 0.0, 26.0, 25.23985293850163, 0.4466679018115675, 0.0, 1.0, 43537.75998863019], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3281400.0000, 
sim time next is 3283200.0000, 
raw observation next is [-7.0, 84.0, 0.0, 0.0, 26.0, 25.13858997146296, 0.4207283932639959, 0.0, 1.0, 43346.70444306154], 
processed observation next is [1.0, 0.0, 0.2686980609418283, 0.84, 0.0, 0.0, 0.6666666666666666, 0.5948824976219133, 0.6402427977546653, 0.0, 1.0, 0.20641287830029306], 
reward next is 0.7936, 
noisyNet noise sample is [array([-0.25855455], dtype=float32), 0.882355]. 
=============================================
[2019-04-06 17:23:35,213] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:23:35,213] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:23:35,217] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run13
[2019-04-06 17:23:39,363] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:23:39,363] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:23:39,367] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run13
[2019-04-06 17:23:52,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:23:52,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:23:52,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run13
[2019-04-06 17:23:53,492] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 17:23:53,493] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:23:53,493] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:23:53,495] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run28
[2019-04-06 17:23:53,512] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:23:53,512] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:23:53,513] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:23:53,515] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:23:53,519] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run28
[2019-04-06 17:23:53,547] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run28
[2019-04-06 17:25:36,859] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.12542702]
[2019-04-06 17:25:36,859] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [13.0, 50.5, 0.0, 0.0, 26.0, 26.53920065963869, 0.8039376168540125, 0.0, 1.0, 0.0]
[2019-04-06 17:25:36,859] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 17:25:36,860] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [3.3689836e-15 5.2078196e-16 4.3661698e-12 8.3563366e-15 1.0000000e+00
 1.3869788e-18 1.1579197e-16], sampled 0.6197747320922906
[2019-04-06 17:25:48,414] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 17:26:28,223] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 17:26:30,851] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 17:26:31,888] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 540000, evaluation results [540000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 17:26:37,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:26:37,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:26:37,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run13
[2019-04-06 17:26:53,010] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:26:53,010] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:26:53,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run13
[2019-04-06 17:26:55,582] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0650520e-14 3.5006252e-14 2.1947133e-10 3.4828433e-14 1.0000000e+00
 9.6668495e-17 8.7279173e-15], sum to 1.0000
[2019-04-06 17:26:55,583] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8545
[2019-04-06 17:26:55,650] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.2845518e-14 2.7064761e-15 7.7739837e-12 2.8292386e-13 1.0000000e+00
 1.7834459e-17 3.3134751e-16], sum to 1.0000
[2019-04-06 17:26:55,650] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4764
[2019-04-06 17:26:55,696] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 45.0, 0.0, 0.0, 26.0, 25.41010016821079, 0.3447280673878461, 0.0, 1.0, 41203.9470119401], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4242600.0000, 
sim time next is 4244400.0000, 
raw observation next is [3.0, 45.0, 0.0, 0.0, 26.0, 25.38167556744833, 0.3409024804432597, 0.0, 1.0, 43038.81794236383], 
processed observation next is [0.0, 0.13043478260869565, 0.5457063711911359, 0.45, 0.0, 0.0, 0.6666666666666666, 0.6151396306206941, 0.6136341601477532, 0.0, 1.0, 0.20494675210649443], 
reward next is 0.7951, 
noisyNet noise sample is [array([1.0444411], dtype=float32), -0.6823725]. 
=============================================
[2019-04-06 17:26:55,779] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 45.0, 0.0, 0.0, 26.0, 25.41010016821079, 0.3447280673878461, 0.0, 1.0, 41203.9470119401], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4242600.0000, 
sim time next is 4244400.0000, 
raw observation next is [3.0, 45.0, 0.0, 0.0, 26.0, 25.38167556744833, 0.3409024804432597, 0.0, 1.0, 43038.81794236383], 
processed observation next is [0.0, 0.13043478260869565, 0.5457063711911359, 0.45, 0.0, 0.0, 0.6666666666666666, 0.6151396306206941, 0.6136341601477532, 0.0, 1.0, 0.20494675210649443], 
reward next is 0.7951, 
noisyNet noise sample is [array([0.17187533], dtype=float32), -1.9233713]. 
=============================================
[2019-04-06 17:26:58,265] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.4324953e-14 1.5432688e-15 2.6291124e-11 2.4262154e-13 1.0000000e+00
 6.9354363e-18 1.8223384e-15], sum to 1.0000
[2019-04-06 17:26:58,265] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2685
[2019-04-06 17:26:58,368] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 76.0, 0.0, 0.0, 26.0, 23.49427703817699, -0.05580068995292709, 0.0, 1.0, 44185.578868982186], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 181800.0000, 
sim time next is 183600.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 26.0, 23.4047875543361, -0.09214035746166817, 0.0, 1.0, 44236.28275061376], 
processed observation next is [1.0, 0.13043478260869565, 0.21606648199445982, 0.78, 0.0, 0.0, 0.6666666666666666, 0.4503989628613416, 0.46928654751277726, 0.0, 1.0, 0.21064896547911316], 
reward next is 0.7894, 
noisyNet noise sample is [array([1.0565329], dtype=float32), -0.08755149]. 
=============================================
[2019-04-06 17:27:02,108] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.0763387e-17 7.7300802e-17 1.2772911e-11 4.6430780e-15 1.0000000e+00
 1.5514941e-19 1.0739602e-17], sum to 1.0000
[2019-04-06 17:27:02,108] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4669
[2019-04-06 17:27:02,182] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 25.57444897569913, 0.5807733261661219, 0.0, 1.0, 44610.451113334915], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4482000.0000, 
sim time next is 4483800.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 25.66613798932781, 0.5628888285716509, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.6388448324439843, 0.6876296095238836, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.37193027], dtype=float32), 1.207248]. 
=============================================
[2019-04-06 17:27:06,956] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:27:06,956] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:27:06,960] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run13
[2019-04-06 17:27:08,148] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4694849e-15 4.1357064e-16 2.1782298e-12 5.8490224e-13 1.0000000e+00
 1.5096057e-18 2.5754037e-16], sum to 1.0000
[2019-04-06 17:27:08,148] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1298
[2019-04-06 17:27:08,487] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.4, 52.0, 291.5, 236.0, 26.0, 24.98905770357031, 0.3275128490014677, 0.0, 1.0, 30889.372236115723], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4878000.0000, 
sim time next is 4879800.0000, 
raw observation next is [0.3, 49.5, 283.0, 308.0, 26.0, 25.02246061522358, 0.35056546439335, 0.0, 1.0, 16873.942242699675], 
processed observation next is [0.0, 0.4782608695652174, 0.47091412742382277, 0.495, 0.9433333333333334, 0.34033149171270716, 0.6666666666666666, 0.5852050512686316, 0.6168551547977833, 0.0, 1.0, 0.0803521059176175], 
reward next is 0.9196, 
noisyNet noise sample is [array([2.3770375], dtype=float32), -1.858809]. 
=============================================
[2019-04-06 17:27:10,672] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9349061e-15 1.1268758e-16 2.7132823e-12 1.9324244e-15 1.0000000e+00
 3.0451279e-18 2.0897906e-16], sum to 1.0000
[2019-04-06 17:27:10,672] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2075
[2019-04-06 17:27:10,729] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.5, 51.0, 0.0, 0.0, 26.0, 26.40358697547667, 0.7035963686802913, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4645800.0000, 
sim time next is 4647600.0000, 
raw observation next is [3.0, 53.0, 0.0, 0.0, 26.0, 26.25520864533517, 0.6565404490375332, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.5457063711911359, 0.53, 0.0, 0.0, 0.6666666666666666, 0.6879340537779308, 0.7188468163458444, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0606934], dtype=float32), -1.0880637]. 
=============================================
[2019-04-06 17:27:14,608] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.6402565e-18 1.4867748e-17 1.2357129e-13 6.8833841e-17 1.0000000e+00
 1.2121816e-21 4.8520269e-20], sum to 1.0000
[2019-04-06 17:27:14,609] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8233
[2019-04-06 17:27:14,658] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 89.0, 213.0, 6.0, 26.0, 26.36078766603275, 0.5744767056791849, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4707000.0000, 
sim time next is 4708800.0000, 
raw observation next is [1.0, 86.0, 160.5, 3.0, 26.0, 26.30327647843557, 0.5516058308317295, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4903047091412743, 0.86, 0.535, 0.0033149171270718232, 0.6666666666666666, 0.6919397065362975, 0.6838686102772432, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.35573828], dtype=float32), -0.51096505]. 
=============================================
[2019-04-06 17:27:24,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:27:24,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:27:24,412] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run13
[2019-04-06 17:27:26,200] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:27:26,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:27:26,204] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run13
[2019-04-06 17:27:30,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:27:30,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:27:30,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run13
[2019-04-06 17:27:38,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:27:38,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:27:38,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run13
[2019-04-06 17:27:45,293] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:27:45,293] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:27:45,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run13
[2019-04-06 17:27:48,594] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:27:48,595] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:27:48,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run13
[2019-04-06 17:27:57,473] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:27:57,473] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:27:57,476] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run13
[2019-04-06 17:27:57,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:27:57,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:27:57,719] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run13
[2019-04-06 17:28:03,967] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8407804e-15 5.6779530e-16 1.9077340e-11 5.0473850e-14 1.0000000e+00
 1.8680516e-17 9.2698174e-17], sum to 1.0000
[2019-04-06 17:28:03,967] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3359
[2019-04-06 17:28:04,420] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.0, 67.5, 27.0, 3.0, 26.0, 25.96438264491561, 0.2760390948856886, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 145800.0000, 
sim time next is 147600.0000, 
raw observation next is [-7.3, 71.0, 0.0, 0.0, 26.0, 25.5201208365712, 0.3738302380772208, 1.0, 1.0, 66400.96790810097], 
processed observation next is [1.0, 0.7391304347826086, 0.26038781163434904, 0.71, 0.0, 0.0, 0.6666666666666666, 0.6266767363809332, 0.6246100793590736, 1.0, 1.0, 0.3161950852766713], 
reward next is 0.6838, 
noisyNet noise sample is [array([1.1087264], dtype=float32), -0.045177788]. 
=============================================
[2019-04-06 17:29:00,317] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [2.5308855e-16 7.8778490e-18 6.5174190e-13 6.5440124e-17 1.0000000e+00
 4.2296246e-20 2.0567536e-18], sum to 1.0000
[2019-04-06 17:29:00,317] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4413
[2019-04-06 17:29:00,336] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [15.5, 75.0, 57.0, 0.0, 26.0, 25.72571110148605, 0.6132438911187217, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1155600.0000, 
sim time next is 1157400.0000, 
raw observation next is [16.35, 71.0, 83.0, 0.0, 26.0, 25.72491467048116, 0.5971338830259585, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.9155124653739612, 0.71, 0.27666666666666667, 0.0, 0.6666666666666666, 0.6437428892067633, 0.6990446276753195, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.07860811], dtype=float32), 0.8406153]. 
=============================================
[2019-04-06 17:29:18,342] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2107130e-12 7.6835531e-14 6.8416545e-10 8.6233191e-12 1.0000000e+00
 4.7973409e-15 4.5724064e-13], sum to 1.0000
[2019-04-06 17:29:18,342] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1773
[2019-04-06 17:29:18,378] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.3, 26.5, 62.0, 680.0, 26.0, 24.97675489642404, 0.2806367226241161, 0.0, 1.0, 12465.06367406008], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2475000.0000, 
sim time next is 2476800.0000, 
raw observation next is [3.3, 26.0, 55.0, 479.5, 26.0, 24.97688440896917, 0.2700967825389951, 0.0, 1.0, 18697.9107660561], 
processed observation next is [0.0, 0.6956521739130435, 0.554016620498615, 0.26, 0.18333333333333332, 0.5298342541436464, 0.6666666666666666, 0.5814070340807641, 0.5900322608463316, 0.0, 1.0, 0.08903767031455286], 
reward next is 0.9110, 
noisyNet noise sample is [array([1.9740514], dtype=float32), 0.72742134]. 
=============================================
[2019-04-06 17:29:35,627] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.5913785e-17 2.8839728e-17 1.7092410e-14 2.7515399e-16 1.0000000e+00
 2.2914008e-21 1.1695270e-18], sum to 1.0000
[2019-04-06 17:29:35,627] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0659
[2019-04-06 17:29:35,692] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.8, 83.0, 0.0, 0.0, 26.0, 25.51857597341465, 0.4408796669644681, 0.0, 1.0, 12502.285045790739], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 970200.0000, 
sim time next is 972000.0000, 
raw observation next is [8.8, 83.0, 0.0, 0.0, 26.0, 25.57202879286641, 0.4794593456180489, 0.0, 1.0, 31747.757371532585], 
processed observation next is [1.0, 0.2608695652173913, 0.7063711911357342, 0.83, 0.0, 0.0, 0.6666666666666666, 0.631002399405534, 0.659819781872683, 0.0, 1.0, 0.15117979700729803], 
reward next is 0.8488, 
noisyNet noise sample is [array([-0.29819474], dtype=float32), -0.10732341]. 
=============================================
[2019-04-06 17:29:35,696] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[94.467514]
 [94.4798  ]
 [94.354805]
 [94.01258 ]
 [94.269035]], R is [[94.6155014 ]
 [94.6098175 ]
 [94.52046967]
 [94.30433655]
 [94.30175018]].
[2019-04-06 17:29:43,784] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0163581e-17 1.0387951e-18 2.9908145e-13 1.1159503e-16 1.0000000e+00
 8.2994824e-20 9.4289458e-18], sum to 1.0000
[2019-04-06 17:29:43,784] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9730
[2019-04-06 17:29:43,881] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 72.0, 0.0, 26.0, 25.53237796327514, 0.4928539435793035, 1.0, 1.0, 6715.717537553827], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1434600.0000, 
sim time next is 1436400.0000, 
raw observation next is [1.1, 92.0, 59.0, 0.0, 26.0, 26.01518199974294, 0.5397480944120818, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.92, 0.19666666666666666, 0.0, 0.6666666666666666, 0.6679318333119116, 0.679916031470694, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0014891], dtype=float32), 0.43890566]. 
=============================================
[2019-04-06 17:29:47,130] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 17:29:47,133] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:29:47,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:29:47,142] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:29:47,142] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:29:47,143] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:29:47,145] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run29
[2019-04-06 17:29:47,146] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run29
[2019-04-06 17:29:47,164] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:29:47,187] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run29
[2019-04-06 17:31:13,433] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.12647195]
[2019-04-06 17:31:13,433] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-1.443051668, 100.0, 0.0, 0.0, 26.0, 25.37490100371381, 0.3325802777040448, 0.0, 1.0, 46482.32517782622]
[2019-04-06 17:31:13,433] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 17:31:13,434] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.3649206e-15 2.6525273e-16 2.7080087e-12 6.3505245e-15 1.0000000e+00
 9.2225437e-19 7.5621110e-17], sampled 0.643833080982128
[2019-04-06 17:31:41,526] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 17:31:50,865] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.12647195]
[2019-04-06 17:31:50,866] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [3.5, 36.0, 93.0, 437.0, 26.0, 27.30413811518144, 0.784989043233531, 1.0, 1.0, 0.0]
[2019-04-06 17:31:50,866] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 17:31:50,867] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.6060525e-14 7.2505072e-15 4.2140944e-11 1.0719199e-13 1.0000000e+00
 2.7838347e-17 2.9979681e-15], sampled 0.3441438621633921
[2019-04-06 17:32:20,743] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 17:32:21,872] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 17:32:22,910] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 560000, evaluation results [560000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 17:32:22,941] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.0741011e-14 1.8336701e-15 1.6790092e-11 7.3456391e-14 1.0000000e+00
 6.3048699e-18 6.7186786e-16], sum to 1.0000
[2019-04-06 17:32:22,942] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1192
[2019-04-06 17:32:23,302] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 79.0, 72.0, 0.0, 26.0, 25.04405021163423, 0.2651958878506473, 0.0, 1.0, 37167.12690680621], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1870200.0000, 
sim time next is 1872000.0000, 
raw observation next is [-4.5, 75.0, 50.5, 0.0, 26.0, 25.01235936111144, 0.2587967396495659, 0.0, 1.0, 51232.756954378536], 
processed observation next is [0.0, 0.6956521739130435, 0.3379501385041552, 0.75, 0.16833333333333333, 0.0, 0.6666666666666666, 0.58436328009262, 0.5862655798831886, 0.0, 1.0, 0.24396550930656447], 
reward next is 0.7560, 
noisyNet noise sample is [array([0.37125593], dtype=float32), 2.1083956]. 
=============================================
[2019-04-06 17:32:23,306] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[76.72188 ]
 [76.969986]
 [76.71478 ]
 [76.25127 ]
 [76.633316]], R is [[76.11420441]
 [76.1760788 ]
 [76.23914337]
 [76.28520203]
 [76.35120392]].
[2019-04-06 17:32:25,331] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6342013e-14 3.1514583e-15 2.2343394e-11 2.4039791e-14 1.0000000e+00
 1.0917801e-17 3.8982899e-16], sum to 1.0000
[2019-04-06 17:32:25,331] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1529
[2019-04-06 17:32:25,729] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.2, 54.0, 0.0, 0.0, 26.0, 25.19791888559788, 0.333551261238253, 1.0, 1.0, 6231.649517079003], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2314800.0000, 
sim time next is 2316600.0000, 
raw observation next is [-1.45, 55.0, 0.0, 0.0, 26.0, 24.93680206034292, 0.3296028333556031, 0.0, 1.0, 91061.14679412065], 
processed observation next is [1.0, 0.8260869565217391, 0.422437673130194, 0.55, 0.0, 0.0, 0.6666666666666666, 0.57806683836191, 0.6098676111185344, 0.0, 1.0, 0.43362450854343165], 
reward next is 0.5664, 
noisyNet noise sample is [array([0.01205811], dtype=float32), 0.3260467]. 
=============================================
[2019-04-06 17:32:28,576] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8588976e-13 4.7295843e-14 1.4879745e-10 2.6314892e-12 1.0000000e+00
 3.5283602e-16 2.1396037e-14], sum to 1.0000
[2019-04-06 17:32:28,576] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9959
[2019-04-06 17:32:28,674] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.27388451597816, 0.1289497796008474, 0.0, 1.0, 40764.04118697188], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2350800.0000, 
sim time next is 2352600.0000, 
raw observation next is [-3.1, 67.0, 0.0, 0.0, 26.0, 24.1949156396906, 0.1135552215016692, 0.0, 1.0, 41028.86158894588], 
processed observation next is [0.0, 0.21739130434782608, 0.37673130193905824, 0.67, 0.0, 0.0, 0.6666666666666666, 0.5162429699742166, 0.5378517405005564, 0.0, 1.0, 0.19537553137593278], 
reward next is 0.8046, 
noisyNet noise sample is [array([0.0508009], dtype=float32), 0.7225571]. 
=============================================
[2019-04-06 17:32:31,574] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4879126e-17 1.1812294e-18 2.0388378e-14 6.5049616e-17 1.0000000e+00
 2.4311482e-21 1.4704123e-17], sum to 1.0000
[2019-04-06 17:32:31,574] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9039
[2019-04-06 17:32:32,009] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 100.0, 0.0, 0.0, 26.0, 25.49733024430627, 0.4670011918617336, 0.0, 1.0, 27444.846724787098], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1495800.0000, 
sim time next is 1497600.0000, 
raw observation next is [1.1, 100.0, 9.0, 0.0, 26.0, 25.46556309215823, 0.4414550557282066, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.49307479224376743, 1.0, 0.03, 0.0, 0.6666666666666666, 0.6221302576798525, 0.6471516852427356, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.079166], dtype=float32), -0.83023137]. 
=============================================
[2019-04-06 17:32:58,445] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [4.631385e-15 2.641268e-17 2.727926e-12 7.738822e-15 1.000000e+00
 9.336883e-19 7.628693e-17], sum to 1.0000
[2019-04-06 17:32:58,446] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7395
[2019-04-06 17:32:58,506] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.65, 89.0, 0.0, 0.0, 26.0, 23.97367864384918, 0.04358177531632262, 0.0, 1.0, 43571.82641221059], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2262600.0000, 
sim time next is 2264400.0000, 
raw observation next is [-8.9, 91.0, 0.0, 0.0, 26.0, 23.81046515723298, 0.008857092594477584, 0.0, 1.0, 43463.68065322928], 
processed observation next is [1.0, 0.21739130434782608, 0.21606648199445982, 0.91, 0.0, 0.0, 0.6666666666666666, 0.48420542976941494, 0.5029523641981591, 0.0, 1.0, 0.2069699078725204], 
reward next is 0.7930, 
noisyNet noise sample is [array([-1.0289828], dtype=float32), 0.7184774]. 
=============================================
[2019-04-06 17:33:04,267] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.2707331e-15 8.5791335e-17 7.3603124e-13 7.3886616e-15 1.0000000e+00
 1.9364356e-18 3.2145454e-16], sum to 1.0000
[2019-04-06 17:33:04,267] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1347
[2019-04-06 17:33:04,374] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.15, 83.0, 0.0, 0.0, 26.0, 25.26779081223661, 0.4091200305798619, 0.0, 1.0, 43120.817387697716], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2151000.0000, 
sim time next is 2152800.0000, 
raw observation next is [-6.7, 83.0, 0.0, 0.0, 26.0, 25.2172967190822, 0.3976150252859271, 0.0, 1.0, 42328.382675207096], 
processed observation next is [1.0, 0.9565217391304348, 0.2770083102493075, 0.83, 0.0, 0.0, 0.6666666666666666, 0.60144139325685, 0.6325383417619758, 0.0, 1.0, 0.2015637270247957], 
reward next is 0.7984, 
noisyNet noise sample is [array([-0.16037048], dtype=float32), 0.15050754]. 
=============================================
[2019-04-06 17:33:40,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0918833e-15 7.4121210e-15 2.2161908e-11 1.5195636e-14 1.0000000e+00
 1.2301411e-18 3.1481779e-15], sum to 1.0000
[2019-04-06 17:33:40,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5443
[2019-04-06 17:33:40,926] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 37.0, 118.5, 828.5, 26.0, 26.4329587033663, 0.5926371829816207, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4017600.0000, 
sim time next is 4019400.0000, 
raw observation next is [-5.0, 33.0, 118.0, 841.0, 26.0, 26.45736741539072, 0.4345178392532218, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.32409972299168976, 0.33, 0.3933333333333333, 0.9292817679558011, 0.6666666666666666, 0.7047806179492268, 0.6448392797510739, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6569734], dtype=float32), 0.2262317]. 
=============================================
[2019-04-06 17:34:06,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3556490e-13 3.1229176e-14 7.8689455e-10 5.8374122e-12 1.0000000e+00
 3.3259617e-16 2.5241775e-14], sum to 1.0000
[2019-04-06 17:34:06,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6274
[2019-04-06 17:34:06,844] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 47.0, 82.5, 199.5, 26.0, 25.00900758759506, 0.2986205659900015, 0.0, 1.0, 18924.568415004607], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2390400.0000, 
sim time next is 2392200.0000, 
raw observation next is [-0.3, 46.0, 79.0, 58.0, 26.0, 24.95384119541561, 0.2846457008857081, 0.0, 1.0, 44564.71700905254], 
processed observation next is [0.0, 0.6956521739130435, 0.4542936288088643, 0.46, 0.2633333333333333, 0.06408839779005525, 0.6666666666666666, 0.5794867662846341, 0.594881900295236, 0.0, 1.0, 0.21221293813834544], 
reward next is 0.7878, 
noisyNet noise sample is [array([-1.9132919], dtype=float32), -0.5980509]. 
=============================================
[2019-04-06 17:34:18,605] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7624441e-14 3.1296678e-14 5.1667065e-10 4.2209761e-13 1.0000000e+00
 2.7930371e-16 3.3451655e-14], sum to 1.0000
[2019-04-06 17:34:18,606] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2689
[2019-04-06 17:34:18,860] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.1, 67.0, 121.0, 360.0, 26.0, 25.26101668285654, 0.3199324216715708, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2367000.0000, 
sim time next is 2368800.0000, 
raw observation next is [-2.8, 65.0, 130.0, 405.0, 26.0, 25.10871357151723, 0.2965112639557635, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.38504155124653744, 0.65, 0.43333333333333335, 0.44751381215469616, 0.6666666666666666, 0.5923927976264359, 0.5988370879852545, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.34871987], dtype=float32), -0.45181796]. 
=============================================
[2019-04-06 17:34:24,026] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.5813706e-15 4.3435158e-17 8.5800065e-12 1.5716950e-14 1.0000000e+00
 2.7794178e-19 1.3333879e-16], sum to 1.0000
[2019-04-06 17:34:24,026] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8797
[2019-04-06 17:34:24,059] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 39.0, 225.0, 46.5, 26.0, 25.74831274672857, 0.3315827060351028, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2548800.0000, 
sim time next is 2550600.0000, 
raw observation next is [1.65, 34.5, 218.0, 22.0, 26.0, 25.73399171508054, 0.3141800160817041, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5083102493074793, 0.345, 0.7266666666666667, 0.02430939226519337, 0.6666666666666666, 0.6444993095900449, 0.6047266720272347, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.0405862], dtype=float32), -0.04287576]. 
=============================================
[2019-04-06 17:34:24,652] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [4.8623757e-16 2.3505625e-18 1.7073073e-12 3.2619302e-16 1.0000000e+00
 1.0546411e-21 3.7134027e-19], sum to 1.0000
[2019-04-06 17:34:24,652] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.0812
[2019-04-06 17:34:24,717] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.0, 100.0, 8.0, 116.0, 26.0, 27.24298223369487, 0.8481075150650087, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3173400.0000, 
sim time next is 3175200.0000, 
raw observation next is [6.0, 100.0, 0.0, 0.0, 26.0, 26.92555558180676, 0.8692470559500128, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6288088642659281, 1.0, 0.0, 0.0, 0.6666666666666666, 0.7437962984838965, 0.7897490186500042, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.77350754], dtype=float32), 1.0082054]. 
=============================================
[2019-04-06 17:34:24,994] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.5077064e-18 7.5448726e-19 2.4941514e-14 3.4732321e-17 1.0000000e+00
 1.9771721e-22 1.9958393e-19], sum to 1.0000
[2019-04-06 17:34:24,994] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2496
[2019-04-06 17:34:25,022] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.5, 100.0, 0.0, 0.0, 26.0, 25.82810205125442, 0.7196935996180333, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3187800.0000, 
sim time next is 3189600.0000, 
raw observation next is [2.0, 100.0, 0.0, 0.0, 26.0, 25.87784018697694, 0.7014768312198592, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.518005540166205, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6564866822480783, 0.7338256104066198, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3423395], dtype=float32), 0.78038216]. 
=============================================
[2019-04-06 17:34:36,479] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.5105600e-16 5.7429304e-17 3.6545064e-12 2.5143354e-15 1.0000000e+00
 8.8387692e-19 3.6937140e-16], sum to 1.0000
[2019-04-06 17:34:36,479] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1812
[2019-04-06 17:34:36,524] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.1, 69.0, 0.0, 0.0, 26.0, 25.41429053910755, 0.4430116676948388, 0.0, 1.0, 54558.490263664426], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2671200.0000, 
sim time next is 2673000.0000, 
raw observation next is [-4.05, 69.0, 0.0, 0.0, 26.0, 25.22055351898411, 0.3592776023462027, 0.0, 1.0, 54443.64019698595], 
processed observation next is [1.0, 0.9565217391304348, 0.350415512465374, 0.69, 0.0, 0.0, 0.6666666666666666, 0.601712793248676, 0.6197592007820676, 0.0, 1.0, 0.2592554295094569], 
reward next is 0.7407, 
noisyNet noise sample is [array([0.1469084], dtype=float32), -0.68408453]. 
=============================================
[2019-04-06 17:34:36,534] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[83.40503 ]
 [82.48089 ]
 [82.28574 ]
 [80.715355]
 [79.89981 ]], R is [[83.9426651 ]
 [83.84343719]
 [83.92575836]
 [83.81741333]
 [83.45337677]].
[2019-04-06 17:34:37,550] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8530593e-14 1.3763185e-15 1.4509925e-11 1.2833803e-13 1.0000000e+00
 3.1462900e-17 1.2450709e-15], sum to 1.0000
[2019-04-06 17:34:37,551] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1127
[2019-04-06 17:34:37,592] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.7, 44.5, 272.0, 388.0, 26.0, 25.07368952797404, 0.3665979716932402, 0.0, 1.0, 12509.36214278976], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4887000.0000, 
sim time next is 4888800.0000, 
raw observation next is [2.0, 44.0, 254.0, 381.0, 26.0, 25.09908409525446, 0.3678284228714754, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.518005540166205, 0.44, 0.8466666666666667, 0.42099447513812155, 0.6666666666666666, 0.5915903412712051, 0.6226094742904918, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.21141188], dtype=float32), 0.95683503]. 
=============================================
[2019-04-06 17:34:40,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:34:40,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:34:40,157] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run14
[2019-04-06 17:34:47,130] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.8800493e-15 3.2453839e-17 1.5691476e-12 6.5540299e-17 1.0000000e+00
 3.0557987e-18 8.4234383e-18], sum to 1.0000
[2019-04-06 17:34:47,130] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2129
[2019-04-06 17:34:47,194] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 100.0, 0.0, 0.0, 26.0, 25.47615396144981, 0.3179573539675322, 0.0, 1.0, 8221.03808765089], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3115800.0000, 
sim time next is 3117600.0000, 
raw observation next is [1.0, 100.0, 0.0, 0.0, 26.0, 25.25443173141058, 0.3149073818493442, 0.0, 1.0, 65275.649817385034], 
processed observation next is [1.0, 0.08695652173913043, 0.4903047091412743, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6045359776175484, 0.6049691272831147, 0.0, 1.0, 0.3108364277018335], 
reward next is 0.6892, 
noisyNet noise sample is [array([-0.27372575], dtype=float32), -0.8036919]. 
=============================================
[2019-04-06 17:34:48,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:34:48,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:34:48,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run14
[2019-04-06 17:35:22,188] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 17:35:22,193] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:35:22,193] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:35:22,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:35:22,194] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:35:22,194] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:35:22,196] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run30
[2019-04-06 17:35:22,194] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:35:22,231] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run30
[2019-04-06 17:35:22,254] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run30
[2019-04-06 17:37:16,239] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2455.1234 79914340.2400 535.0996
[2019-04-06 17:37:54,391] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 17:37:56,350] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 17:37:57,395] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 580000, evaluation results [580000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2455.1233888037063, 79914340.24000935, 535.0996202443389, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 17:38:03,537] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.12698506e-13 3.34198984e-14 1.92797084e-10 7.93886441e-14
 1.00000000e+00 1.05516694e-16 5.77084818e-15], sum to 1.0000
[2019-04-06 17:38:03,538] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0250
[2019-04-06 17:38:03,673] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.5, 44.5, 33.0, 187.0, 26.0, 25.03069615593456, 0.3205266171732084, 0.0, 1.0, 40163.993636972686], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4901400.0000, 
sim time next is 4903200.0000, 
raw observation next is [2.0, 44.0, 16.5, 93.5, 26.0, 25.01391451337708, 0.304722323219577, 0.0, 1.0, 35790.656396807164], 
processed observation next is [0.0, 0.782608695652174, 0.518005540166205, 0.44, 0.055, 0.10331491712707182, 0.6666666666666666, 0.5844928761147568, 0.601574107739859, 0.0, 1.0, 0.17043169712765316], 
reward next is 0.8296, 
noisyNet noise sample is [array([-0.02379333], dtype=float32), -0.63665843]. 
=============================================
[2019-04-06 17:38:14,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4719900e-16 2.7134540e-15 2.7573193e-12 2.4778107e-15 1.0000000e+00
 5.8486700e-19 2.6867141e-16], sum to 1.0000
[2019-04-06 17:38:14,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7474
[2019-04-06 17:38:14,346] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 60.0, 110.5, 797.0, 26.0, 26.57153055351618, 0.6531863651476875, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3765600.0000, 
sim time next is 3767400.0000, 
raw observation next is [0.0, 60.0, 106.0, 776.0, 26.0, 26.61452147963932, 0.656028476808945, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.46260387811634357, 0.6, 0.35333333333333333, 0.8574585635359117, 0.6666666666666666, 0.7178767899699432, 0.7186761589363151, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.30077025], dtype=float32), 0.8188692]. 
=============================================
[2019-04-06 17:38:19,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:38:19,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:38:19,096] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run14
[2019-04-06 17:38:29,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:38:29,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:38:29,091] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run14
[2019-04-06 17:38:37,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:38:37,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:38:37,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run14
[2019-04-06 17:38:42,183] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0190013e-16 1.9901014e-17 5.7082004e-14 5.0479216e-15 1.0000000e+00
 2.2197450e-18 4.7345231e-17], sum to 1.0000
[2019-04-06 17:38:42,183] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2355
[2019-04-06 17:38:42,566] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.3, 86.0, 91.5, 0.0, 26.0, 24.38962575454929, 0.1256243722380535, 0.0, 1.0, 18751.94371252156], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 46800.0000, 
sim time next is 48600.0000, 
raw observation next is [8.0, 86.0, 87.0, 0.0, 26.0, 24.37377597331348, 0.1341785677099526, 0.0, 1.0, 38653.588042765776], 
processed observation next is [0.0, 0.5652173913043478, 0.6842105263157896, 0.86, 0.29, 0.0, 0.6666666666666666, 0.5311479977761234, 0.5447261892366508, 0.0, 1.0, 0.1840647049655513], 
reward next is 0.8159, 
noisyNet noise sample is [array([-1.5519985], dtype=float32), -1.8206717]. 
=============================================
[2019-04-06 17:38:58,802] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:38:58,802] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:38:58,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run14
[2019-04-06 17:39:19,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:39:19,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:39:19,368] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run14
[2019-04-06 17:39:32,056] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.3717525e-16 5.8792094e-17 2.8418728e-13 4.4119858e-16 1.0000000e+00
 1.0686627e-19 3.7193892e-17], sum to 1.0000
[2019-04-06 17:39:32,056] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6619
[2019-04-06 17:39:32,467] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.9, 72.0, 0.0, 0.0, 26.0, 25.54001129230506, 0.4324297221910243, 1.0, 1.0, 13478.929877043576], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4519800.0000, 
sim time next is 4521600.0000, 
raw observation next is [-0.8, 73.0, 55.5, 33.0, 26.0, 25.48394701310502, 0.4158301953106818, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4404432132963989, 0.73, 0.185, 0.036464088397790057, 0.6666666666666666, 0.623662251092085, 0.6386100651035606, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.49391672], dtype=float32), -0.26021388]. 
=============================================
[2019-04-06 17:39:36,135] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8318862e-16 4.0773039e-18 2.9666346e-13 2.0014319e-15 1.0000000e+00
 5.5689248e-21 4.9084211e-18], sum to 1.0000
[2019-04-06 17:39:36,135] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3421
[2019-04-06 17:39:36,255] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 26.0, 25.41168550529675, 0.4729496973293982, 0.0, 1.0, 29800.398876287818], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4577400.0000, 
sim time next is 4579200.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 26.0, 25.51566275050096, 0.4717625247270281, 0.0, 1.0, 12506.99758782501], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.61, 0.0, 0.0, 0.6666666666666666, 0.6263052292084135, 0.6572541749090094, 0.0, 1.0, 0.05955713137059528], 
reward next is 0.9404, 
noisyNet noise sample is [array([0.18884811], dtype=float32), 0.23268327]. 
=============================================
[2019-04-06 17:39:36,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:39:36,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:39:36,866] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run14
[2019-04-06 17:39:49,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:39:49,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:39:49,636] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run14
[2019-04-06 17:39:52,805] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:39:52,805] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:39:52,808] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run14
[2019-04-06 17:39:56,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:39:56,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:39:56,482] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run14
[2019-04-06 17:39:57,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:39:57,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:39:57,011] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run14
[2019-04-06 17:40:03,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:40:03,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:40:03,336] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run14
[2019-04-06 17:40:04,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:40:04,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:40:04,134] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run14
[2019-04-06 17:40:09,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:40:09,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:40:09,608] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run14
[2019-04-06 17:40:09,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:40:09,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:40:09,926] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run14
[2019-04-06 17:40:44,284] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.4424417e-14 1.2917633e-15 4.0756780e-11 1.2355338e-13 1.0000000e+00
 1.5806242e-17 7.0994287e-15], sum to 1.0000
[2019-04-06 17:40:44,284] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2131
[2019-04-06 17:40:44,368] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-12.0, 68.5, 0.0, 0.0, 26.0, 22.59039486645723, -0.2621837682673009, 0.0, 1.0, 47832.44220731096], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 282600.0000, 
sim time next is 284400.0000, 
raw observation next is [-12.3, 67.0, 0.0, 0.0, 26.0, 22.52879198744119, -0.2782123628571202, 0.0, 1.0, 47921.512865421006], 
processed observation next is [1.0, 0.30434782608695654, 0.12188365650969527, 0.67, 0.0, 0.0, 0.6666666666666666, 0.3773993322867657, 0.40726254571429327, 0.0, 1.0, 0.2281976803115286], 
reward next is 0.7718, 
noisyNet noise sample is [array([-0.3924929], dtype=float32), -1.6385123]. 
=============================================
[2019-04-06 17:40:50,348] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6228110e-18 1.3056420e-19 4.5805919e-14 1.7118868e-18 1.0000000e+00
 1.0878736e-22 2.1654386e-19], sum to 1.0000
[2019-04-06 17:40:50,348] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6197
[2019-04-06 17:40:50,520] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 46.0, 0.0, 26.0, 25.91053852511479, 0.51570699518312, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1438200.0000, 
sim time next is 1440000.0000, 
raw observation next is [1.1, 92.0, 32.0, 0.0, 26.0, 24.68953359370274, 0.4065330781092626, 1.0, 1.0, 65533.811145302294], 
processed observation next is [1.0, 0.6956521739130435, 0.49307479224376743, 0.92, 0.10666666666666667, 0.0, 0.6666666666666666, 0.5574611328085618, 0.6355110260364208, 1.0, 1.0, 0.3120657673585823], 
reward next is 0.6879, 
noisyNet noise sample is [array([1.1232728], dtype=float32), -0.2897336]. 
=============================================
[2019-04-06 17:40:50,549] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[94.63408]
 [95.28115]
 [95.72986]
 [95.98685]
 [96.02565]], R is [[94.38225555]
 [94.43843079]
 [94.49404907]
 [94.51712799]
 [94.57196045]].
[2019-04-06 17:40:52,264] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.11467144e-13 8.74117408e-16 2.34287225e-11 1.33365961e-13
 1.00000000e+00 1.28242893e-16 2.32784750e-15], sum to 1.0000
[2019-04-06 17:40:52,264] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9568
[2019-04-06 17:40:52,326] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-15.0, 69.0, 0.0, 0.0, 26.0, 23.00054527457736, -0.1948471482582496, 0.0, 1.0, 48809.58413430696], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 354600.0000, 
sim time next is 356400.0000, 
raw observation next is [-15.0, 69.0, 0.0, 0.0, 26.0, 22.74697055004533, -0.2488831498180419, 0.0, 1.0, 49186.781698020415], 
processed observation next is [1.0, 0.13043478260869565, 0.04709141274238226, 0.69, 0.0, 0.0, 0.6666666666666666, 0.3955808791704441, 0.41703895006065267, 0.0, 1.0, 0.2342227699905734], 
reward next is 0.7658, 
noisyNet noise sample is [array([-0.45198146], dtype=float32), -0.21632372]. 
=============================================
[2019-04-06 17:41:08,814] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.2037100e-17 1.4080308e-18 5.9330909e-13 1.6382194e-16 1.0000000e+00
 8.2007794e-22 1.4023380e-18], sum to 1.0000
[2019-04-06 17:41:08,814] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6561
[2019-04-06 17:41:08,845] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 26.0, 26.09401100302438, 0.5720306337735205, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1015200.0000, 
sim time next is 1017000.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 26.0, 25.77469002020555, 0.5306643700382541, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.8614958448753465, 0.81, 0.0, 0.0, 0.6666666666666666, 0.6478908350171292, 0.6768881233460847, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7371294], dtype=float32), -1.274428]. 
=============================================
[2019-04-06 17:41:08,870] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[96.37425 ]
 [96.451645]
 [96.991554]
 [97.14133 ]
 [97.44744 ]], R is [[96.36404419]
 [96.40040588]
 [96.43640137]
 [96.47203827]
 [96.50731659]].
[2019-04-06 17:41:13,219] A3C_AGENT_WORKER-Thread-8 INFO:Evaluating...
[2019-04-06 17:41:13,220] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:41:13,220] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:41:13,222] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run31
[2019-04-06 17:41:13,266] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:41:13,271] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:41:13,273] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run31
[2019-04-06 17:41:13,297] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:41:13,298] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:41:13,305] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run31
[2019-04-06 17:43:08,011] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 17:43:47,902] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 17:43:48,796] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 17:43:49,831] A3C_AGENT_WORKER-Thread-8 INFO:Global step: 600000, evaluation results [600000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 17:44:13,708] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.3753102e-16 1.7999665e-16 8.2731605e-14 8.8468107e-16 1.0000000e+00
 3.6330181e-19 8.0586392e-18], sum to 1.0000
[2019-04-06 17:44:13,708] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5621
[2019-04-06 17:44:13,982] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 83.0, 0.0, 0.0, 26.0, 24.88513294412665, 0.3042541629610848, 0.0, 1.0, 98018.57964329574], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 849600.0000, 
sim time next is 851400.0000, 
raw observation next is [-3.4, 83.0, 0.0, 0.0, 26.0, 25.08144573491207, 0.3103045695674536, 0.0, 1.0, 52154.24625253476], 
processed observation next is [1.0, 0.8695652173913043, 0.368421052631579, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5901204779093391, 0.6034348565224845, 0.0, 1.0, 0.24835355358349884], 
reward next is 0.7516, 
noisyNet noise sample is [array([1.2159439], dtype=float32), 1.4315896]. 
=============================================
[2019-04-06 17:44:28,283] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3668770e-16 1.9574838e-18 1.8049533e-14 6.8264576e-17 1.0000000e+00
 7.2974625e-21 4.8442646e-18], sum to 1.0000
[2019-04-06 17:44:28,283] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8065
[2019-04-06 17:44:28,583] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.8, 82.0, 191.0, 89.0, 26.0, 25.84297535449792, 0.4027884884151169, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2109600.0000, 
sim time next is 2111400.0000, 
raw observation next is [-7.55, 78.5, 208.0, 60.0, 26.0, 25.84750627230694, 0.3909506073607714, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.25346260387811637, 0.785, 0.6933333333333334, 0.06629834254143646, 0.6666666666666666, 0.6539588560255784, 0.6303168691202571, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.28285402], dtype=float32), 1.1964476]. 
=============================================
[2019-04-06 17:44:41,594] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8596867e-16 8.9926684e-18 1.4671012e-13 3.3376928e-16 1.0000000e+00
 1.3458292e-19 2.4591353e-17], sum to 1.0000
[2019-04-06 17:44:41,595] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0223
[2019-04-06 17:44:41,680] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 91.0, 0.0, 0.0, 26.0, 24.68987815783604, 0.2353502511048313, 0.0, 1.0, 42639.801098101954], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2077200.0000, 
sim time next is 2079000.0000, 
raw observation next is [-4.5, 88.5, 0.0, 0.0, 26.0, 24.62504751260379, 0.224015856032955, 0.0, 1.0, 42700.4465793667], 
processed observation next is [1.0, 0.043478260869565216, 0.3379501385041552, 0.885, 0.0, 0.0, 0.6666666666666666, 0.5520872927169824, 0.574671952010985, 0.0, 1.0, 0.20333545990174617], 
reward next is 0.7967, 
noisyNet noise sample is [array([-0.66624165], dtype=float32), 0.12182877]. 
=============================================
[2019-04-06 17:44:41,693] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[85.495285]
 [85.38803 ]
 [85.82721 ]
 [86.37656 ]
 [86.8051  ]], R is [[85.53092957]
 [85.47257233]
 [85.41381836]
 [85.35652161]
 [85.30063629]].
[2019-04-06 17:44:41,834] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.9372069e-18 1.3624742e-17 3.0894457e-13 6.1164166e-18 1.0000000e+00
 2.2939372e-21 1.9123409e-20], sum to 1.0000
[2019-04-06 17:44:41,835] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5434
[2019-04-06 17:44:42,110] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 26.0, 25.62146180896612, 0.5839535891392191, 1.0, 1.0, 18827.568381840232], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1323000.0000, 
sim time next is 1324800.0000, 
raw observation next is [1.1, 92.0, 9.0, 0.0, 26.0, 25.7275705617436, 0.5471187031496704, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.49307479224376743, 0.92, 0.03, 0.0, 0.6666666666666666, 0.6439642134786334, 0.6823729010498901, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6547053], dtype=float32), 1.5353988]. 
=============================================
[2019-04-06 17:44:53,669] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.4576216e-15 9.5141474e-17 2.9396780e-12 4.9049844e-15 1.0000000e+00
 4.6188488e-19 5.2559354e-17], sum to 1.0000
[2019-04-06 17:44:53,669] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7705
[2019-04-06 17:44:54,062] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.6, 70.0, 0.0, 0.0, 26.0, 25.61073404656082, 0.398345887876014, 0.0, 1.0, 6455.798281200089], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2228400.0000, 
sim time next is 2230200.0000, 
raw observation next is [-4.8, 70.5, 0.0, 0.0, 26.0, 25.09577336604728, 0.345559504325844, 1.0, 1.0, 56828.75138939277], 
processed observation next is [1.0, 0.8260869565217391, 0.3296398891966759, 0.705, 0.0, 0.0, 0.6666666666666666, 0.5913144471706065, 0.615186501441948, 1.0, 1.0, 0.2706131018542513], 
reward next is 0.7294, 
noisyNet noise sample is [array([0.80200446], dtype=float32), 0.058661666]. 
=============================================
[2019-04-06 17:45:32,771] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8773950e-15 9.4365069e-17 2.5563698e-13 4.8282556e-16 1.0000000e+00
 5.8160284e-20 6.3070346e-18], sum to 1.0000
[2019-04-06 17:45:32,772] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3161
[2019-04-06 17:45:32,845] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 26.0, 25.09924865493867, 0.3343577674419624, 0.0, 1.0, 43925.61565192548], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3814200.0000, 
sim time next is 3816000.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 26.0, 25.00050004307195, 0.3142445472476397, 0.0, 1.0, 43680.064279584374], 
processed observation next is [1.0, 0.17391304347826086, 0.3518005540166205, 0.71, 0.0, 0.0, 0.6666666666666666, 0.583375003589329, 0.6047481824158799, 0.0, 1.0, 0.20800030609325892], 
reward next is 0.7920, 
noisyNet noise sample is [array([-0.46441498], dtype=float32), 0.57532126]. 
=============================================
[2019-04-06 17:45:32,874] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[81.40179 ]
 [81.53323 ]
 [81.413284]
 [81.48821 ]
 [81.52533 ]], R is [[81.18995667]
 [81.16889191]
 [81.10448456]
 [81.0885849 ]
 [81.12390137]].
[2019-04-06 17:45:36,330] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.47657795e-14 1.09692495e-14 2.53991585e-11 7.33761535e-14
 1.00000000e+00 5.54144795e-18 6.38199515e-16], sum to 1.0000
[2019-04-06 17:45:36,331] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8645
[2019-04-06 17:45:36,506] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.15, 78.0, 148.0, 94.0, 26.0, 25.1878447422167, 0.2623413711852061, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1848600.0000, 
sim time next is 1850400.0000, 
raw observation next is [-5.6, 78.0, 134.0, 72.5, 26.0, 25.01957800783478, 0.2180394905388855, 0.0, 1.0, 6252.4497852414725], 
processed observation next is [0.0, 0.43478260869565216, 0.30747922437673136, 0.78, 0.44666666666666666, 0.08011049723756906, 0.6666666666666666, 0.5849648339862318, 0.5726798301796285, 0.0, 1.0, 0.029773570405911772], 
reward next is 0.9702, 
noisyNet noise sample is [array([0.8562597], dtype=float32), -2.1034398]. 
=============================================
[2019-04-06 17:45:41,750] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.1611259e-16 2.0210170e-17 1.8624983e-13 3.2764341e-16 1.0000000e+00
 1.4647620e-19 1.9788824e-17], sum to 1.0000
[2019-04-06 17:45:41,750] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2081
[2019-04-06 17:45:41,789] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.55896156975153, 0.2056281803015261, 0.0, 1.0, 42951.154941222114], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1985400.0000, 
sim time next is 1987200.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.45593604778467, 0.1849520715197642, 0.0, 1.0, 42748.31070878858], 
processed observation next is [1.0, 0.0, 0.30747922437673136, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5379946706487226, 0.561650690506588, 0.0, 1.0, 0.20356338432756466], 
reward next is 0.7964, 
noisyNet noise sample is [array([0.9741399], dtype=float32), 0.9218106]. 
=============================================
[2019-04-06 17:46:34,890] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.6647878e-16 6.0328164e-16 1.3079373e-12 1.8243391e-14 1.0000000e+00
 3.1747655e-18 1.2334545e-17], sum to 1.0000
[2019-04-06 17:46:34,890] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5829
[2019-04-06 17:46:34,986] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-11.95, 79.5, 0.0, 0.0, 26.0, 24.1110243643232, 0.120134434280129, 0.0, 1.0, 44438.81200579699], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2687400.0000, 
sim time next is 2689200.0000, 
raw observation next is [-12.9, 83.0, 0.0, 0.0, 26.0, 23.91421338037578, 0.07049474863385058, 0.0, 1.0, 44474.33114475008], 
processed observation next is [1.0, 0.13043478260869565, 0.10526315789473682, 0.83, 0.0, 0.0, 0.6666666666666666, 0.49285111503131507, 0.5234982495446169, 0.0, 1.0, 0.21178252926071467], 
reward next is 0.7882, 
noisyNet noise sample is [array([-0.2677978], dtype=float32), 2.129118]. 
=============================================
[2019-04-06 17:46:40,604] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:46:40,604] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:46:40,608] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run15
[2019-04-06 17:46:46,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:46:46,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:46:46,056] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run15
[2019-04-06 17:46:50,099] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3316762e-14 1.4059504e-15 3.4817725e-11 2.2777180e-14 1.0000000e+00
 2.8710420e-17 1.0982768e-15], sum to 1.0000
[2019-04-06 17:46:50,099] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8914
[2019-04-06 17:46:50,157] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 26.0, 24.55336482993545, 0.2482640537537246, 0.0, 1.0, 42681.09081004522], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2950200.0000, 
sim time next is 2952000.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 26.0, 24.44530112656864, 0.223961777454935, 0.0, 1.0, 42744.76838346376], 
processed observation next is [0.0, 0.17391304347826086, 0.3795013850415513, 0.84, 0.0, 0.0, 0.6666666666666666, 0.5371084272140534, 0.5746539258183117, 0.0, 1.0, 0.2035465161117322], 
reward next is 0.7965, 
noisyNet noise sample is [array([-0.19290887], dtype=float32), -0.7966052]. 
=============================================
[2019-04-06 17:46:50,169] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[78.73273 ]
 [78.999794]
 [79.525566]
 [81.24258 ]
 [82.20742 ]], R is [[78.45841217]
 [78.47058105]
 [78.48188019]
 [78.49208069]
 [78.50149536]].
[2019-04-06 17:46:50,697] A3C_AGENT_WORKER-Thread-8 INFO:Evaluating...
[2019-04-06 17:46:50,701] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:46:50,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:46:50,703] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run32
[2019-04-06 17:46:50,757] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:46:50,757] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:46:50,759] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run32
[2019-04-06 17:46:50,780] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:46:50,797] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:46:50,801] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run32
[2019-04-06 17:48:07,263] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.12768905]
[2019-04-06 17:48:07,264] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [3.5, 73.5, 19.0, 133.0, 26.0, 25.45709223858825, 0.5556215131122921, 1.0, 1.0, 25153.797374709862]
[2019-04-06 17:48:07,264] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 17:48:07,265] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.6668709e-15 3.5198507e-16 3.6091752e-12 6.9029551e-15 1.0000000e+00
 1.0802008e-18 1.3896122e-16], sampled 0.4730064438752041
[2019-04-06 17:48:50,134] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 17:49:24,145] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 17:49:27,649] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 17:49:28,702] A3C_AGENT_WORKER-Thread-8 INFO:Global step: 620000, evaluation results [620000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 17:49:37,523] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.5068148e-18 1.9343315e-18 4.3843408e-14 1.4579743e-16 1.0000000e+00
 4.6355775e-21 2.1856883e-19], sum to 1.0000
[2019-04-06 17:49:37,524] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3999
[2019-04-06 17:49:37,611] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 93.0, 0.0, 0.0, 26.0, 25.59335540253585, 0.6251389730954163, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3195000.0000, 
sim time next is 3196800.0000, 
raw observation next is [2.0, 93.0, 0.0, 0.0, 26.0, 25.54473635776569, 0.5940379177673911, 0.0, 1.0, 20044.06347871457], 
processed observation next is [1.0, 0.0, 0.518005540166205, 0.93, 0.0, 0.0, 0.6666666666666666, 0.6287280298138075, 0.698012639255797, 0.0, 1.0, 0.09544792132721223], 
reward next is 0.9046, 
noisyNet noise sample is [array([-0.20228136], dtype=float32), -0.6893037]. 
=============================================
[2019-04-06 17:49:57,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.4637125e-14 8.3542970e-15 5.1024766e-12 3.7396396e-14 1.0000000e+00
 1.4848081e-17 9.3993997e-16], sum to 1.0000
[2019-04-06 17:49:57,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9406
[2019-04-06 17:49:58,034] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.0, 52.0, 154.0, 782.0, 26.0, 25.34480425151693, 0.4350168107912443, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4280400.0000, 
sim time next is 4282200.0000, 
raw observation next is [7.0, 54.5, 188.0, 717.0, 26.0, 25.35908893822257, 0.4411965861271539, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.6565096952908588, 0.545, 0.6266666666666667, 0.7922651933701658, 0.6666666666666666, 0.6132574115185475, 0.6470655287090513, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.38239446], dtype=float32), -0.771429]. 
=============================================
[2019-04-06 17:50:15,914] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0127452e-16 3.7555598e-17 2.6544105e-12 6.5483609e-16 1.0000000e+00
 6.2706598e-20 2.1361508e-17], sum to 1.0000
[2019-04-06 17:50:15,914] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2996
[2019-04-06 17:50:16,127] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 78.0, 60.0, 0.0, 26.0, 25.33985070894622, 0.5344268452248072, 1.0, 1.0, 81163.33811065888], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4464000.0000, 
sim time next is 4465800.0000, 
raw observation next is [0.0, 78.0, 49.0, 0.0, 26.0, 26.02812142822339, 0.5771252747005096, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.46260387811634357, 0.78, 0.16333333333333333, 0.0, 0.6666666666666666, 0.6690101190186158, 0.6923750915668365, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.81774545], dtype=float32), -0.15209064]. 
=============================================
[2019-04-06 17:50:25,442] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.2082598e-14 2.9008253e-14 9.4920995e-11 5.1338393e-13 1.0000000e+00
 1.2330458e-16 1.9345263e-15], sum to 1.0000
[2019-04-06 17:50:25,442] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9219
[2019-04-06 17:50:25,775] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.75, 41.0, 0.0, 0.0, 26.0, 25.08809899312381, 0.2949865054488969, 1.0, 1.0, 96998.99469433054], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 415800.0000, 
sim time next is 417600.0000, 
raw observation next is [-10.0, 42.0, 0.0, 0.0, 26.0, 25.12014030936391, 0.2961676415838883, 0.0, 1.0, 59356.078432441405], 
processed observation next is [1.0, 0.8695652173913043, 0.18559556786703602, 0.42, 0.0, 0.0, 0.6666666666666666, 0.593345025780326, 0.5987225471946295, 0.0, 1.0, 0.28264799253543527], 
reward next is 0.7174, 
noisyNet noise sample is [array([-2.3091042], dtype=float32), -0.98347896]. 
=============================================
[2019-04-06 17:50:50,055] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:50:50,055] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:50:50,059] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run15
[2019-04-06 17:51:00,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:51:00,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:51:00,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run15
[2019-04-06 17:51:03,627] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8239491e-16 3.4173376e-17 5.0208768e-13 6.6641084e-15 1.0000000e+00
 1.1896398e-19 3.6002417e-17], sum to 1.0000
[2019-04-06 17:51:03,627] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9634
[2019-04-06 17:51:03,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:51:03,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:51:03,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run15
[2019-04-06 17:51:03,720] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.8, 75.0, 0.0, 0.0, 26.0, 24.26490759316018, 0.03775433616667515, 0.0, 1.0, 41631.97308207557], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 705600.0000, 
sim time next is 707400.0000, 
raw observation next is [-2.55, 75.5, 0.0, 0.0, 26.0, 24.29818165952525, 0.04525741332377155, 0.0, 1.0, 41596.08409019124], 
processed observation next is [1.0, 0.17391304347826086, 0.3919667590027701, 0.755, 0.0, 0.0, 0.6666666666666666, 0.5248484716271044, 0.5150858044412572, 0.0, 1.0, 0.19807659090567256], 
reward next is 0.8019, 
noisyNet noise sample is [array([-0.9498693], dtype=float32), 0.48265442]. 
=============================================
[2019-04-06 17:51:16,182] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3963766e-16 2.7856832e-17 1.0910986e-11 2.9826938e-15 1.0000000e+00
 6.5248120e-19 8.7433044e-17], sum to 1.0000
[2019-04-06 17:51:16,182] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0958
[2019-04-06 17:51:16,321] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.1, 87.5, 0.0, 0.0, 26.0, 24.60347509734166, 0.2056744940667044, 0.0, 1.0, 37550.622315221604], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 66600.0000, 
sim time next is 68400.0000, 
raw observation next is [3.8, 86.0, 0.0, 0.0, 26.0, 24.61430153745386, 0.2096662101395844, 0.0, 1.0, 41008.4179034336], 
processed observation next is [0.0, 0.8260869565217391, 0.5678670360110805, 0.86, 0.0, 0.0, 0.6666666666666666, 0.5511917947878215, 0.5698887367131947, 0.0, 1.0, 0.19527818049254095], 
reward next is 0.8047, 
noisyNet noise sample is [array([0.85796887], dtype=float32), -1.1184808]. 
=============================================
[2019-04-06 17:51:17,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:51:17,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:51:17,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run15
[2019-04-06 17:51:23,811] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:51:23,811] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:51:23,816] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run15
[2019-04-06 17:51:26,496] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2295280e-16 3.2961768e-17 3.7756275e-13 2.9661959e-15 1.0000000e+00
 1.0137869e-19 7.2769866e-18], sum to 1.0000
[2019-04-06 17:51:26,496] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0228
[2019-04-06 17:51:26,537] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 26.0, 25.41168550529675, 0.4729496973293982, 0.0, 1.0, 29800.398876287818], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4577400.0000, 
sim time next is 4579200.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 26.0, 25.51566275050096, 0.4717625247270281, 0.0, 1.0, 12506.99758782501], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.61, 0.0, 0.0, 0.6666666666666666, 0.6263052292084135, 0.6572541749090094, 0.0, 1.0, 0.05955713137059528], 
reward next is 0.9404, 
noisyNet noise sample is [array([1.233328], dtype=float32), -0.16875993]. 
=============================================
[2019-04-06 17:51:31,818] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4245147e-17 5.4923080e-18 9.2596530e-14 3.0344250e-18 1.0000000e+00
 1.0245003e-21 2.4631110e-21], sum to 1.0000
[2019-04-06 17:51:31,818] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3693
[2019-04-06 17:51:31,876] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.5, 100.0, 0.0, 0.0, 26.0, 25.44002243830656, 0.5947765643279371, 0.0, 1.0, 43892.37159284068], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1288800.0000, 
sim time next is 1290600.0000, 
raw observation next is [5.5, 100.0, 0.0, 0.0, 26.0, 25.50434040872601, 0.5965231912662003, 0.0, 1.0, 25191.229367046373], 
processed observation next is [0.0, 0.9565217391304348, 0.6149584487534627, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6253617007271673, 0.6988410637554002, 0.0, 1.0, 0.1199582350811732], 
reward next is 0.8800, 
noisyNet noise sample is [array([-0.9479694], dtype=float32), -0.5808045]. 
=============================================
[2019-04-06 17:51:39,068] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:51:39,068] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:51:39,072] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run15
[2019-04-06 17:51:43,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:51:43,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:51:43,952] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run15
[2019-04-06 17:51:44,647] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:51:44,647] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:51:44,654] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run15
[2019-04-06 17:51:47,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:51:47,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:51:47,868] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run15
[2019-04-06 17:51:49,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:51:49,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:51:49,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run15
[2019-04-06 17:51:49,633] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9588617e-17 4.5429451e-17 6.6310693e-14 2.0447240e-16 1.0000000e+00
 4.5505871e-20 1.9903216e-17], sum to 1.0000
[2019-04-06 17:51:49,633] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2329
[2019-04-06 17:51:49,860] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.7, 82.0, 89.0, 135.0, 26.0, 24.87012992404298, 0.271339985947782, 0.0, 1.0, 35808.808266370455], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 559800.0000, 
sim time next is 561600.0000, 
raw observation next is [-0.8, 81.0, 109.5, 265.5, 26.0, 24.83444883640875, 0.3077431383187642, 0.0, 1.0, 54258.136838019476], 
processed observation next is [0.0, 0.5217391304347826, 0.4404432132963989, 0.81, 0.365, 0.29337016574585634, 0.6666666666666666, 0.5695374030340625, 0.6025810461062547, 0.0, 1.0, 0.2583720801810451], 
reward next is 0.7416, 
noisyNet noise sample is [array([0.00325784], dtype=float32), -0.9468007]. 
=============================================
[2019-04-06 17:51:49,990] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5956186e-19 3.6761936e-19 2.0646030e-14 4.3027636e-18 1.0000000e+00
 1.2423758e-23 3.2722680e-20], sum to 1.0000
[2019-04-06 17:51:49,990] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9083
[2019-04-06 17:51:50,049] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.6, 97.0, 0.0, 0.0, 26.0, 25.54808049643276, 0.5774298990447116, 0.0, 1.0, 84805.80955677103], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1654200.0000, 
sim time next is 1656000.0000, 
raw observation next is [6.6, 97.0, 0.0, 0.0, 26.0, 25.64814487667868, 0.568496180964187, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.6454293628808865, 0.97, 0.0, 0.0, 0.6666666666666666, 0.6373454063898899, 0.6894987269880622, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16368066], dtype=float32), -0.7107727]. 
=============================================
[2019-04-06 17:51:50,064] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[95.95514 ]
 [94.91547 ]
 [94.49977 ]
 [94.433975]
 [94.25952 ]], R is [[95.90788269]
 [95.54496765]
 [95.42034149]
 [95.4112854 ]
 [95.45717621]].
[2019-04-06 17:51:52,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:51:52,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:51:52,520] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run15
[2019-04-06 17:51:53,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:51:53,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:51:53,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run15
[2019-04-06 17:52:01,203] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:52:01,203] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:52:01,212] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run15
[2019-04-06 17:52:01,393] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 17:52:01,393] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:52:01,396] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run15
[2019-04-06 17:52:02,757] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3751424e-16 2.8425337e-17 6.0301881e-14 1.4417361e-16 1.0000000e+00
 8.2708117e-21 3.7303731e-17], sum to 1.0000
[2019-04-06 17:52:02,757] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3248
[2019-04-06 17:52:03,030] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.45, 86.0, 79.0, 0.0, 26.0, 24.4585915207352, 0.1657255515690211, 0.0, 1.0, 26483.88374573109], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 52200.0000, 
sim time next is 54000.0000, 
raw observation next is [7.2, 86.0, 64.5, 0.0, 26.0, 24.47161442805653, 0.1615151389058745, 0.0, 1.0, 29927.54599159672], 
processed observation next is [0.0, 0.6521739130434783, 0.662049861495845, 0.86, 0.215, 0.0, 0.6666666666666666, 0.5393012023380441, 0.5538383796352915, 0.0, 1.0, 0.14251212376950817], 
reward next is 0.8575, 
noisyNet noise sample is [array([1.7486162], dtype=float32), -0.3944595]. 
=============================================
[2019-04-06 17:52:03,046] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[83.943474]
 [84.22337 ]
 [84.39943 ]
 [84.500656]
 [84.76324 ]], R is [[83.68584442]
 [83.72286987]
 [83.72138214]
 [83.70010376]
 [83.77381134]].
[2019-04-06 17:52:20,704] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.66994421e-19 4.38514912e-19 1.41723215e-14 2.28062695e-17
 1.00000000e+00 1.51635525e-22 3.29774550e-19], sum to 1.0000
[2019-04-06 17:52:20,704] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2995
[2019-04-06 17:52:20,782] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.7, 81.5, 0.0, 0.0, 26.0, 25.47806803966535, 0.4507693244556925, 0.0, 1.0, 29560.769435517414], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 963000.0000, 
sim time next is 964800.0000, 
raw observation next is [7.7, 83.0, 0.0, 0.0, 26.0, 25.53945168552768, 0.4476293307651325, 0.0, 1.0, 12505.124207932366], 
processed observation next is [1.0, 0.17391304347826086, 0.6759002770083103, 0.83, 0.0, 0.0, 0.6666666666666666, 0.62828764046064, 0.6492097769217108, 0.0, 1.0, 0.05954821051396365], 
reward next is 0.9405, 
noisyNet noise sample is [array([1.4047838], dtype=float32), -0.85272217]. 
=============================================
[2019-04-06 17:52:21,096] A3C_AGENT_WORKER-Thread-7 INFO:Evaluating...
[2019-04-06 17:52:21,097] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:52:21,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:52:21,110] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run33
[2019-04-06 17:52:21,165] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:52:21,165] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:52:21,167] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run33
[2019-04-06 17:52:21,184] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:52:21,184] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:52:21,191] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run33
[2019-04-06 17:54:22,667] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 17:55:01,612] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 17:55:09,266] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 17:55:10,299] A3C_AGENT_WORKER-Thread-7 INFO:Global step: 640000, evaluation results [640000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 17:56:11,805] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6281647e-15 4.9622515e-16 1.0801799e-11 3.7049509e-14 1.0000000e+00
 6.3798921e-19 7.9370698e-16], sum to 1.0000
[2019-04-06 17:56:11,806] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7564
[2019-04-06 17:56:12,186] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 38.5, 20.0, 0.0, 26.0, 24.34800900691103, 0.1718641840029153, 1.0, 1.0, 77402.20591672313], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 491400.0000, 
sim time next is 493200.0000, 
raw observation next is [1.1, 43.0, 10.0, 0.0, 26.0, 25.55330865812043, 0.2946453861647172, 1.0, 1.0, 20145.365663731613], 
processed observation next is [1.0, 0.7391304347826086, 0.49307479224376743, 0.43, 0.03333333333333333, 0.0, 0.6666666666666666, 0.6294423881767024, 0.5982151287215723, 1.0, 1.0, 0.09593031268443625], 
reward next is 0.9041, 
noisyNet noise sample is [array([0.9739094], dtype=float32), -2.4364874]. 
=============================================
[2019-04-06 17:56:29,019] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [3.0351660e-18 3.1517060e-18 2.9533203e-14 3.0904652e-17 1.0000000e+00
 6.5304577e-21 1.0751273e-19], sum to 1.0000
[2019-04-06 17:56:29,019] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8029
[2019-04-06 17:56:29,159] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.6, 86.0, 0.0, 0.0, 26.0, 26.06696184677726, 0.7111131819938162, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1634400.0000, 
sim time next is 1636200.0000, 
raw observation next is [6.9, 84.0, 0.0, 0.0, 26.0, 25.8298723484888, 0.6095916266512215, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.6537396121883658, 0.84, 0.0, 0.0, 0.6666666666666666, 0.6524893623740665, 0.7031972088837405, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6494213], dtype=float32), 1.8200738]. 
=============================================
[2019-04-06 17:56:52,913] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1861531e-15 2.3755047e-18 2.2455680e-14 2.8916524e-16 1.0000000e+00
 8.0194046e-21 4.7137247e-18], sum to 1.0000
[2019-04-06 17:56:52,916] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9799
[2019-04-06 17:56:52,954] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 26.0, 24.50031093487727, 0.158091835253973, 0.0, 1.0, 42528.86684839772], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2169000.0000, 
sim time next is 2170800.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 26.0, 24.49881978720017, 0.1600538937934436, 0.0, 1.0, 42433.24138277672], 
processed observation next is [1.0, 0.13043478260869565, 0.2770083102493075, 0.78, 0.0, 0.0, 0.6666666666666666, 0.5415683156000141, 0.5533512979311479, 0.0, 1.0, 0.2020630542036987], 
reward next is 0.7979, 
noisyNet noise sample is [array([-0.85584635], dtype=float32), -0.31501806]. 
=============================================
[2019-04-06 17:57:17,486] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5132562e-19 2.7517983e-19 1.0416940e-14 1.0437011e-17 1.0000000e+00
 2.6136270e-23 3.2960100e-19], sum to 1.0000
[2019-04-06 17:57:17,487] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9486
[2019-04-06 17:57:17,567] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.6, 97.0, 0.0, 0.0, 26.0, 25.56543085747993, 0.5512754937376564, 0.0, 1.0, 51021.40375493136], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1659600.0000, 
sim time next is 1661400.0000, 
raw observation next is [6.05, 97.0, 0.0, 0.0, 26.0, 25.5915686374713, 0.5383198760292326, 0.0, 1.0, 22355.167028569354], 
processed observation next is [1.0, 0.21739130434782608, 0.6301939058171746, 0.97, 0.0, 0.0, 0.6666666666666666, 0.6326307197892751, 0.6794399586764109, 0.0, 1.0, 0.10645317632652074], 
reward next is 0.8935, 
noisyNet noise sample is [array([-1.2844429], dtype=float32), 1.073061]. 
=============================================
[2019-04-06 17:57:50,134] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.4224389e-16 1.6855474e-16 7.9785489e-13 9.7396676e-15 1.0000000e+00
 1.7703832e-18 1.6355468e-16], sum to 1.0000
[2019-04-06 17:57:50,134] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2963
[2019-04-06 17:57:50,281] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 34.0, 46.0, 234.5, 26.0, 25.36681940987892, 0.3312716499942291, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4089600.0000, 
sim time next is 4091400.0000, 
raw observation next is [-3.5, 36.0, 92.0, 469.0, 26.0, 25.56949868601247, 0.4188368007500062, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.36565096952908593, 0.36, 0.30666666666666664, 0.518232044198895, 0.6666666666666666, 0.6307915571677057, 0.6396122669166687, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7930796], dtype=float32), -0.8102986]. 
=============================================
[2019-04-06 17:57:50,771] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7658336e-14 3.0388431e-15 9.3928598e-12 2.6475968e-14 1.0000000e+00
 1.7569217e-17 2.0407422e-16], sum to 1.0000
[2019-04-06 17:57:50,771] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5461
[2019-04-06 17:57:50,838] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.5, 65.0, 0.0, 0.0, 26.0, 25.29920563558002, 0.355776543867228, 0.0, 1.0, 40260.49795930434], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3013200.0000, 
sim time next is 3015000.0000, 
raw observation next is [-3.75, 65.0, 0.0, 0.0, 26.0, 25.22136788486831, 0.337101370996386, 0.0, 1.0, 39513.53554303326], 
processed observation next is [0.0, 0.9130434782608695, 0.3587257617728532, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6017806570723593, 0.612367123665462, 0.0, 1.0, 0.18815969306206312], 
reward next is 0.8118, 
noisyNet noise sample is [array([0.28670943], dtype=float32), 0.035428755]. 
=============================================
[2019-04-06 17:57:50,848] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[78.770775]
 [78.63265 ]
 [77.847855]
 [76.85005 ]
 [75.36225 ]], R is [[78.67250824]
 [78.69406128]
 [78.71348572]
 [78.68252563]
 [78.39211273]].
[2019-04-06 17:58:10,928] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 17:58:10,936] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:58:10,936] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:58:10,938] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run34
[2019-04-06 17:58:10,968] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 17:58:10,976] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:58:10,978] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run34
[2019-04-06 17:58:10,997] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 17:58:10,998] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 17:58:11,000] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run34
[2019-04-06 17:58:36,374] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.12849905]
[2019-04-06 17:58:36,374] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-4.2, 75.0, 0.0, 0.0, 26.0, 24.18032410240955, 0.07775810847753321, 0.0, 1.0, 43151.98142569843]
[2019-04-06 17:58:36,374] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 17:58:36,375] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.0424215e-14 1.8852777e-15 9.8395406e-12 2.8322608e-14 1.0000000e+00
 6.2693743e-18 4.4420965e-16], sampled 0.7546467534185138
[2019-04-06 18:00:11,750] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 18:00:49,822] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 18:00:58,228] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 18:00:59,266] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 660000, evaluation results [660000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 18:01:01,202] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1256176e-15 5.0225263e-16 1.2931210e-12 1.3143280e-14 1.0000000e+00
 9.2682517e-19 5.8065517e-16], sum to 1.0000
[2019-04-06 18:01:01,202] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1468
[2019-04-06 18:01:01,301] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.7, 55.0, 0.0, 0.0, 26.0, 25.43326457122292, 0.4261901609275353, 0.0, 1.0, 23266.89033305176], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2323800.0000, 
sim time next is 2325600.0000, 
raw observation next is [-1.7, 56.0, 0.0, 0.0, 26.0, 25.35601964343591, 0.4261324167191057, 0.0, 1.0, 53914.33233799585], 
processed observation next is [1.0, 0.9565217391304348, 0.4155124653739613, 0.56, 0.0, 0.0, 0.6666666666666666, 0.6130016369529926, 0.6420441389063686, 0.0, 1.0, 0.25673491589521835], 
reward next is 0.7433, 
noisyNet noise sample is [array([-0.03826661], dtype=float32), 0.89159065]. 
=============================================
[2019-04-06 18:01:41,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:01:41,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:01:41,836] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run16
[2019-04-06 18:01:45,547] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3146371e-14 8.8814697e-16 2.6316171e-10 8.3874431e-15 1.0000000e+00
 6.9047916e-17 6.3617722e-16], sum to 1.0000
[2019-04-06 18:01:45,547] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3353
[2019-04-06 18:01:45,629] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 28.0, 171.0, 482.0, 26.0, 25.41841486332736, 0.3428289143284406, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2554200.0000, 
sim time next is 2556000.0000, 
raw observation next is [3.8, 26.0, 165.0, 378.5, 26.0, 25.72790539894842, 0.3669857544353481, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5678670360110805, 0.26, 0.55, 0.41823204419889504, 0.6666666666666666, 0.6439921165790349, 0.6223285848117827, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.74030566], dtype=float32), -0.37459445]. 
=============================================
[2019-04-06 18:01:45,632] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[79.03398 ]
 [79.5166  ]
 [79.77542 ]
 [80.05005 ]
 [80.197624]], R is [[78.5605011 ]
 [78.77489471]
 [78.98714447]
 [79.19727325]
 [79.40530396]].
[2019-04-06 18:01:48,797] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:01:48,797] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:01:48,800] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run16
[2019-04-06 18:01:58,638] A3C_AGENT_WORKER-Thread-17 INFO:Local step 42500, global step 665594: loss 18.3740
[2019-04-06 18:01:58,658] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 42500, global step 665596: learning rate 0.0000
[2019-04-06 18:02:02,684] A3C_AGENT_WORKER-Thread-14 INFO:Local step 42500, global step 666113: loss 18.0709
[2019-04-06 18:02:02,685] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 42500, global step 666113: learning rate 0.0000
[2019-04-06 18:02:15,135] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [8.4844901e-17 5.8829562e-17 1.9123186e-13 8.1610147e-16 1.0000000e+00
 5.2820998e-19 6.6695912e-18], sum to 1.0000
[2019-04-06 18:02:15,136] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.0421
[2019-04-06 18:02:15,207] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 37.0, 0.0, 0.0, 26.0, 25.13008391979872, 0.3611293601393389, 0.0, 1.0, 40776.28066163391], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4059000.0000, 
sim time next is 4060800.0000, 
raw observation next is [-6.0, 37.0, 0.0, 0.0, 26.0, 25.04773428210123, 0.3389952670389068, 0.0, 1.0, 40594.548465498854], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.37, 0.0, 0.0, 0.6666666666666666, 0.5873111901751026, 0.6129984223463022, 0.0, 1.0, 0.19330737364523265], 
reward next is 0.8067, 
noisyNet noise sample is [array([2.2502427], dtype=float32), -2.6407783]. 
=============================================
[2019-04-06 18:02:42,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:02:42,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:02:42,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run16
[2019-04-06 18:02:42,145] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:02:42,145] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:02:42,148] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run16
[2019-04-06 18:02:49,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:02:49,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:02:49,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run16
[2019-04-06 18:02:51,905] A3C_AGENT_WORKER-Thread-19 INFO:Local step 42500, global step 673931: loss 18.3427
[2019-04-06 18:02:51,906] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 42500, global step 673931: learning rate 0.0000
[2019-04-06 18:02:52,116] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0049689e-16 1.0714920e-18 8.3490764e-14 6.3247222e-17 1.0000000e+00
 1.5705665e-20 8.2716219e-16], sum to 1.0000
[2019-04-06 18:02:52,116] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2323
[2019-04-06 18:02:52,187] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.5, 68.0, 0.0, 0.0, 26.0, 25.36373195437421, 0.3986288549172086, 0.0, 1.0, 61097.154339064524], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3900600.0000, 
sim time next is 3902400.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.324750875777, 0.3891461131252158, 0.0, 1.0, 39862.24198777904], 
processed observation next is [1.0, 0.17391304347826086, 0.3795013850415513, 0.71, 0.0, 0.0, 0.6666666666666666, 0.6103959063147499, 0.6297153710417386, 0.0, 1.0, 0.18982019994180493], 
reward next is 0.8102, 
noisyNet noise sample is [array([1.4287307], dtype=float32), 1.3389871]. 
=============================================
[2019-04-06 18:02:52,643] A3C_AGENT_WORKER-Thread-18 INFO:Local step 42500, global step 674039: loss 18.5167
[2019-04-06 18:02:52,644] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 42500, global step 674039: learning rate 0.0000
[2019-04-06 18:02:56,841] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6667891e-14 3.3094598e-15 5.2048608e-12 2.8082214e-14 1.0000000e+00
 8.8148328e-18 3.6154516e-16], sum to 1.0000
[2019-04-06 18:02:56,841] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4336
[2019-04-06 18:02:56,911] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 39.0, 0.0, 0.0, 26.0, 25.38938810155294, 0.4249171193300638, 0.0, 1.0, 30678.48859508256], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4150800.0000, 
sim time next is 4152600.0000, 
raw observation next is [-1.5, 42.5, 0.0, 0.0, 26.0, 25.3324145968968, 0.4152996154112376, 0.0, 1.0, 45725.79447979031], 
processed observation next is [0.0, 0.043478260869565216, 0.4210526315789474, 0.425, 0.0, 0.0, 0.6666666666666666, 0.6110345497414, 0.6384332051370792, 0.0, 1.0, 0.21774187847519197], 
reward next is 0.7823, 
noisyNet noise sample is [array([-0.5642607], dtype=float32), -2.0124135]. 
=============================================
[2019-04-06 18:02:58,427] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.6121606e-15 6.3853801e-16 3.0014569e-12 1.2270691e-14 1.0000000e+00
 1.6833032e-18 7.8511219e-17], sum to 1.0000
[2019-04-06 18:02:58,455] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2462
[2019-04-06 18:02:58,534] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 49.0, 0.0, 0.0, 26.0, 25.31938994463913, 0.3181015089228126, 0.0, 1.0, 39166.30423008942], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4260600.0000, 
sim time next is 4262400.0000, 
raw observation next is [3.0, 49.0, 55.0, 26.5, 26.0, 25.31670556015939, 0.3283689260318319, 0.0, 1.0, 39067.377218490736], 
processed observation next is [0.0, 0.34782608695652173, 0.5457063711911359, 0.49, 0.18333333333333332, 0.029281767955801105, 0.6666666666666666, 0.6097254633466159, 0.6094563086772773, 0.0, 1.0, 0.18603512961186064], 
reward next is 0.8140, 
noisyNet noise sample is [array([-1.6593997], dtype=float32), 0.02930114]. 
=============================================
[2019-04-06 18:02:59,730] A3C_AGENT_WORKER-Thread-15 INFO:Local step 42500, global step 675082: loss 18.3741
[2019-04-06 18:02:59,731] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 42500, global step 675082: learning rate 0.0000
[2019-04-06 18:03:04,659] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:03:04,659] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:03:04,664] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run16
[2019-04-06 18:03:12,926] A3C_AGENT_WORKER-Thread-17 INFO:Local step 43000, global step 677074: loss 0.5043
[2019-04-06 18:03:12,927] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 43000, global step 677074: learning rate 0.0000
[2019-04-06 18:03:14,635] A3C_AGENT_WORKER-Thread-8 INFO:Local step 42500, global step 677371: loss 18.1989
[2019-04-06 18:03:14,635] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 42500, global step 677371: learning rate 0.0000
[2019-04-06 18:03:15,006] A3C_AGENT_WORKER-Thread-14 INFO:Local step 43000, global step 677426: loss 0.5166
[2019-04-06 18:03:15,006] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 43000, global step 677426: learning rate 0.0000
[2019-04-06 18:03:19,639] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:03:19,640] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:03:19,644] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run16
[2019-04-06 18:03:24,923] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.6497050e-13 6.1653414e-14 3.7391534e-11 2.7325749e-13 1.0000000e+00
 3.9161308e-16 4.4929463e-14], sum to 1.0000
[2019-04-06 18:03:24,923] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2128
[2019-04-06 18:03:25,011] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.5, 41.5, 0.0, 0.0, 26.0, 25.01663453933694, 0.3465017648907112, 0.0, 1.0, 38874.71055118723], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4818600.0000, 
sim time next is 4820400.0000, 
raw observation next is [1.0, 43.0, 0.0, 0.0, 26.0, 24.99643900597122, 0.3293538981530804, 0.0, 1.0, 29597.698412779147], 
processed observation next is [0.0, 0.8260869565217391, 0.4903047091412743, 0.43, 0.0, 0.0, 0.6666666666666666, 0.5830365838309349, 0.6097846327176935, 0.0, 1.0, 0.14094142101323404], 
reward next is 0.8591, 
noisyNet noise sample is [array([0.25878814], dtype=float32), -1.5604457]. 
=============================================
[2019-04-06 18:03:27,322] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3385433e-17 1.6459609e-17 6.0593723e-13 7.7038255e-16 1.0000000e+00
 5.0151234e-21 1.1455164e-17], sum to 1.0000
[2019-04-06 18:03:27,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7598
[2019-04-06 18:03:27,366] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.65, 66.0, 0.0, 0.0, 26.0, 25.48842793085601, 0.443109622940167, 0.0, 1.0, 22895.559345545105], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4588200.0000, 
sim time next is 4590000.0000, 
raw observation next is [-1.1, 67.0, 0.0, 0.0, 26.0, 25.33627689591001, 0.4222472248416098, 0.0, 1.0, 54679.77905544846], 
processed observation next is [1.0, 0.13043478260869565, 0.4321329639889197, 0.67, 0.0, 0.0, 0.6666666666666666, 0.6113564079925009, 0.6407490749472032, 0.0, 1.0, 0.2603799002640403], 
reward next is 0.7396, 
noisyNet noise sample is [array([-0.9708377], dtype=float32), 0.23456359]. 
=============================================
[2019-04-06 18:03:27,382] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[85.76624]
 [85.97611]
 [85.99512]
 [85.96544]
 [85.96947]], R is [[85.99465942]
 [86.02568817]
 [86.02464294]
 [85.98849487]
 [85.96521759]].
[2019-04-06 18:03:29,685] A3C_AGENT_WORKER-Thread-7 INFO:Local step 42500, global step 679876: loss 18.3292
[2019-04-06 18:03:29,685] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 42500, global step 679876: learning rate 0.0000
[2019-04-06 18:03:30,491] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-06 18:03:30,498] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:03:30,498] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:03:30,500] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run35
[2019-04-06 18:03:30,533] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:03:30,534] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:03:30,534] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:03:30,535] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:03:30,538] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run35
[2019-04-06 18:03:30,556] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run35
[2019-04-06 18:03:37,018] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13046914]
[2019-04-06 18:03:37,019] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [6.6, 50.0, 90.5, 500.0, 26.0, 24.6660744826898, 0.1959509829270997, 0.0, 1.0, 18719.56952651209]
[2019-04-06 18:03:37,019] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 18:03:37,019] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [6.4667425e-15 9.1267684e-16 6.4716388e-12 1.8310008e-14 1.0000000e+00
 4.7576769e-18 3.5354470e-16], sampled 0.2261451191470747
[2019-04-06 18:05:39,963] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 18:06:03,684] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13046914]
[2019-04-06 18:06:03,685] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-1.1070755655, 87.44261868999999, 0.0, 0.0, 26.0, 25.16441965718056, 0.3444534753547824, 0.0, 1.0, 11951.513530989481]
[2019-04-06 18:06:03,685] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 18:06:03,686] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [5.6091708e-16 7.6975059e-17 8.2158314e-13 1.5564293e-15 1.0000000e+00
 1.8953114e-19 1.6837601e-17], sampled 0.33412250455161996
[2019-04-06 18:06:16,851] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 18:06:20,800] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 18:06:21,838] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 680000, evaluation results [680000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 18:06:34,188] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:06:34,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:06:34,192] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run16
[2019-04-06 18:06:40,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:06:40,015] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:06:40,018] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run16
[2019-04-06 18:06:44,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:06:44,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:06:44,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run16
[2019-04-06 18:06:48,912] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8881135e-15 2.9648466e-17 1.7751358e-12 1.0510372e-16 1.0000000e+00
 1.9637943e-20 1.1112938e-17], sum to 1.0000
[2019-04-06 18:06:48,913] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5945
[2019-04-06 18:06:48,966] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 34.0, 0.0, 0.0, 26.0, 25.47045485031579, 0.4960558002809082, 0.0, 1.0, 95332.47360988363], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5007600.0000, 
sim time next is 5009400.0000, 
raw observation next is [2.5, 37.0, 0.0, 0.0, 26.0, 25.57456230408929, 0.4820685529077287, 0.0, 1.0, 12496.306955887901], 
processed observation next is [1.0, 1.0, 0.5318559556786704, 0.37, 0.0, 0.0, 0.6666666666666666, 0.6312135253407742, 0.6606895176359096, 0.0, 1.0, 0.059506223599466196], 
reward next is 0.9405, 
noisyNet noise sample is [array([-0.3937436], dtype=float32), 3.0151322]. 
=============================================
[2019-04-06 18:06:51,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:06:51,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:06:51,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run16
[2019-04-06 18:06:54,936] A3C_AGENT_WORKER-Thread-6 INFO:Local step 42500, global step 682896: loss 18.3186
[2019-04-06 18:06:54,937] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 42500, global step 682896: learning rate 0.0000
[2019-04-06 18:06:55,306] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:06:55,306] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:06:55,316] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run16
[2019-04-06 18:06:56,791] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:06:56,792] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:06:56,795] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run16
[2019-04-06 18:06:57,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:06:57,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:06:57,879] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run16
[2019-04-06 18:07:00,078] A3C_AGENT_WORKER-Thread-16 INFO:Local step 42500, global step 683194: loss 18.2080
[2019-04-06 18:07:00,079] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 42500, global step 683194: learning rate 0.0000
[2019-04-06 18:07:00,326] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3556735e-15 4.0967049e-15 4.4784766e-11 2.0729920e-14 1.0000000e+00
 1.4527819e-18 9.6755932e-17], sum to 1.0000
[2019-04-06 18:07:00,326] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9538
[2019-04-06 18:07:00,386] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.7, 44.5, 272.0, 388.0, 26.0, 25.07368952797404, 0.3665979716932402, 0.0, 1.0, 12509.36214278976], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4887000.0000, 
sim time next is 4888800.0000, 
raw observation next is [2.0, 44.0, 254.0, 381.0, 26.0, 25.09908409525446, 0.3678284228714754, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.518005540166205, 0.44, 0.8466666666666667, 0.42099447513812155, 0.6666666666666666, 0.5915903412712051, 0.6226094742904918, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.02392611], dtype=float32), -1.1125342]. 
=============================================
[2019-04-06 18:07:01,460] A3C_AGENT_WORKER-Thread-17 INFO:Local step 43500, global step 683302: loss 1.0006
[2019-04-06 18:07:01,461] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 43500, global step 683302: learning rate 0.0000
[2019-04-06 18:07:01,730] A3C_AGENT_WORKER-Thread-14 INFO:Local step 43500, global step 683324: loss 1.0434
[2019-04-06 18:07:01,730] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 43500, global step 683324: learning rate 0.0000
[2019-04-06 18:07:03,058] A3C_AGENT_WORKER-Thread-12 INFO:Local step 42500, global step 683413: loss 18.3155
[2019-04-06 18:07:03,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 42500, global step 683413: learning rate 0.0000
[2019-04-06 18:07:09,384] A3C_AGENT_WORKER-Thread-20 INFO:Local step 42500, global step 683838: loss 18.5939
[2019-04-06 18:07:09,385] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 42500, global step 683838: learning rate 0.0000
[2019-04-06 18:07:09,678] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:07:09,678] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:07:09,682] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run16
[2019-04-06 18:07:11,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:07:11,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:07:11,980] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run16
[2019-04-06 18:07:13,089] A3C_AGENT_WORKER-Thread-13 INFO:Local step 42500, global step 684128: loss 18.4868
[2019-04-06 18:07:13,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 42500, global step 684128: learning rate 0.0000
[2019-04-06 18:07:13,596] A3C_AGENT_WORKER-Thread-5 INFO:Local step 42500, global step 684152: loss 18.2836
[2019-04-06 18:07:13,596] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 42500, global step 684152: learning rate 0.0000
[2019-04-06 18:07:14,699] A3C_AGENT_WORKER-Thread-3 INFO:Local step 42500, global step 684203: loss 18.6168
[2019-04-06 18:07:14,700] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 42500, global step 684203: learning rate 0.0000
[2019-04-06 18:07:14,997] A3C_AGENT_WORKER-Thread-19 INFO:Local step 43000, global step 684215: loss 0.5347
[2019-04-06 18:07:14,998] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 43000, global step 684215: learning rate 0.0000
[2019-04-06 18:07:16,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.09149092e-17 4.43011135e-18 1.17919234e-14 8.34906347e-17
 1.00000000e+00 1.76888277e-20 7.94596417e-19], sum to 1.0000
[2019-04-06 18:07:16,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6583
[2019-04-06 18:07:17,136] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.0, 89.5, 96.0, 0.0, 26.0, 24.33587326671604, 0.115697220550398, 0.0, 1.0, 33249.754627486785], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 45000.0000, 
sim time next is 46800.0000, 
raw observation next is [8.3, 86.0, 91.5, 0.0, 26.0, 24.38962575454929, 0.1256243722380535, 0.0, 1.0, 18751.94371252156], 
processed observation next is [0.0, 0.5652173913043478, 0.6925207756232689, 0.86, 0.305, 0.0, 0.6666666666666666, 0.5324688128791074, 0.5418747907460179, 0.0, 1.0, 0.08929497005962647], 
reward next is 0.9107, 
noisyNet noise sample is [array([-0.22162877], dtype=float32), 0.61586076]. 
=============================================
[2019-04-06 18:07:19,171] A3C_AGENT_WORKER-Thread-18 INFO:Local step 43000, global step 684462: loss 0.5114
[2019-04-06 18:07:19,171] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 43000, global step 684462: learning rate 0.0000
[2019-04-06 18:07:30,264] A3C_AGENT_WORKER-Thread-4 INFO:Local step 42500, global step 685323: loss 18.5046
[2019-04-06 18:07:30,264] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 42500, global step 685323: learning rate 0.0000
[2019-04-06 18:07:31,696] A3C_AGENT_WORKER-Thread-15 INFO:Local step 43000, global step 685413: loss 0.4989
[2019-04-06 18:07:31,697] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 43000, global step 685413: learning rate 0.0000
[2019-04-06 18:07:33,346] A3C_AGENT_WORKER-Thread-2 INFO:Local step 42500, global step 685533: loss 18.7313
[2019-04-06 18:07:33,346] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 42500, global step 685533: learning rate 0.0000
[2019-04-06 18:07:35,799] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.0808732e-16 1.7425786e-16 9.0951760e-12 1.6472102e-14 1.0000000e+00
 3.4801950e-17 6.2446942e-18], sum to 1.0000
[2019-04-06 18:07:35,799] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6690
[2019-04-06 18:07:35,866] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.4, 71.0, 0.0, 0.0, 26.0, 24.21313300010855, 0.1208772033420362, 0.0, 1.0, 45086.427261536846], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 167400.0000, 
sim time next is 169200.0000, 
raw observation next is [-8.4, 71.0, 0.0, 0.0, 26.0, 24.08662581975225, 0.08910567901276274, 0.0, 1.0, 44962.56216143093], 
processed observation next is [1.0, 1.0, 0.2299168975069252, 0.71, 0.0, 0.0, 0.6666666666666666, 0.5072188183126874, 0.5297018930042542, 0.0, 1.0, 0.2141074388639568], 
reward next is 0.7859, 
noisyNet noise sample is [array([-0.79628557], dtype=float32), -0.08301768]. 
=============================================
[2019-04-06 18:07:44,724] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1626592e-17 3.6174362e-17 4.7217628e-13 1.4505689e-15 1.0000000e+00
 1.9028021e-19 3.2421665e-17], sum to 1.0000
[2019-04-06 18:07:44,724] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1908
[2019-04-06 18:07:44,814] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.2, 79.0, 0.0, 0.0, 26.0, 23.77274864198521, 0.007498322277272883, 0.0, 1.0, 41901.17054273912], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2181600.0000, 
sim time next is 2183400.0000, 
raw observation next is [-5.9, 77.0, 0.0, 0.0, 26.0, 23.68417570450821, -0.01092888061809012, 0.0, 1.0, 41893.63360537669], 
processed observation next is [1.0, 0.2608695652173913, 0.2991689750692521, 0.77, 0.0, 0.0, 0.6666666666666666, 0.4736813087090175, 0.49635703979397, 0.0, 1.0, 0.19949349335893662], 
reward next is 0.8005, 
noisyNet noise sample is [array([1.6378641], dtype=float32), 0.5450816]. 
=============================================
[2019-04-06 18:07:45,568] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8671987e-17 6.7745927e-19 1.3265662e-13 2.6003683e-17 1.0000000e+00
 1.0019143e-20 8.3574674e-19], sum to 1.0000
[2019-04-06 18:07:45,568] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1406
[2019-04-06 18:07:45,750] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 26.0, 25.01101285720608, 0.303803900589144, 1.0, 1.0, 106522.6642105432], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 241200.0000, 
sim time next is 243000.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 26.0, 25.17689030414882, 0.244522987363453, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.368421052631579, 0.65, 0.0, 0.0, 0.6666666666666666, 0.5980741920124016, 0.5815076624544843, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3869196], dtype=float32), -0.79810643]. 
=============================================
[2019-04-06 18:07:45,754] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.06427001e-17 2.88247545e-18 1.04316986e-13 3.51884188e-17
 1.00000000e+00 8.59693395e-22 9.81970714e-19], sum to 1.0000
[2019-04-06 18:07:45,754] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6364
[2019-04-06 18:07:45,783] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[87.3832  ]
 [86.604324]
 [86.018814]
 [86.216805]
 [85.42712 ]], R is [[87.07309723]
 [86.69512177]
 [86.55814362]
 [86.69256592]
 [86.50856781]].
[2019-04-06 18:07:45,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4931634e-17 2.3453868e-17 1.1048105e-12 3.2212739e-15 1.0000000e+00
 7.8395280e-20 2.3651155e-18], sum to 1.0000
[2019-04-06 18:07:45,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7201
[2019-04-06 18:07:45,861] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 26.0, 25.52220789139897, 0.5395620774585641, 0.0, 1.0, 32211.392367597975], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1461600.0000, 
sim time next is 1463400.0000, 
raw observation next is [1.35, 92.0, 0.0, 0.0, 26.0, 25.3606636120719, 0.4814936254659727, 0.0, 1.0, 68952.47506819088], 
processed observation next is [1.0, 0.9565217391304348, 0.5000000000000001, 0.92, 0.0, 0.0, 0.6666666666666666, 0.613388634339325, 0.6604978751553242, 0.0, 1.0, 0.3283451193723375], 
reward next is 0.6717, 
noisyNet noise sample is [array([2.0345592], dtype=float32), 0.055936623]. 
=============================================
[2019-04-06 18:07:46,023] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 26.0, 25.17689030414882, 0.244522987363453, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 243000.0000, 
sim time next is 244800.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 26.0, 24.78060563442181, 0.2599691426137334, 0.0, 1.0, 118403.52815421025], 
processed observation next is [1.0, 0.8695652173913043, 0.368421052631579, 0.65, 0.0, 0.0, 0.6666666666666666, 0.5650504695351509, 0.5866563808712445, 0.0, 1.0, 0.5638263245438583], 
reward next is 0.4362, 
noisyNet noise sample is [array([0.27763474], dtype=float32), -1.5374831]. 
=============================================
[2019-04-06 18:07:50,088] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2507490e-17 4.1258717e-17 4.0945238e-12 4.7886515e-17 1.0000000e+00
 3.7242515e-21 9.2470322e-18], sum to 1.0000
[2019-04-06 18:07:50,089] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3168
[2019-04-06 18:07:50,169] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.4381759e-16 7.2671973e-17 3.9145857e-12 1.3230582e-14 1.0000000e+00
 3.1888922e-19 2.0441606e-18], sum to 1.0000
[2019-04-06 18:07:50,169] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6761
[2019-04-06 18:07:50,292] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.2, 69.5, 35.0, 0.0, 26.0, 25.99977809896943, 0.4167840345047423, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2219400.0000, 
sim time next is 2221200.0000, 
raw observation next is [-4.5, 71.0, 19.0, 0.0, 26.0, 25.64413645531486, 0.4001973030437097, 1.0, 1.0, 64733.19297669977], 
processed observation next is [1.0, 0.7391304347826086, 0.3379501385041552, 0.71, 0.06333333333333334, 0.0, 0.6666666666666666, 0.6370113712762384, 0.6333991010145699, 1.0, 1.0, 0.30825329988904654], 
reward next is 0.6917, 
noisyNet noise sample is [array([1.2087553], dtype=float32), -0.9431971]. 
=============================================
[2019-04-06 18:07:50,420] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-11.15, 61.5, 87.0, 512.0, 26.0, 25.82905016912032, 0.3618216500030257, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 297000.0000, 
sim time next is 298800.0000, 
raw observation next is [-10.6, 60.0, 96.5, 585.0, 26.0, 25.77380673580033, 0.3553597702292168, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.1689750692520776, 0.6, 0.32166666666666666, 0.6464088397790055, 0.6666666666666666, 0.6478172279833609, 0.6184532567430723, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0812107], dtype=float32), -1.9346709]. 
=============================================
[2019-04-06 18:07:51,708] A3C_AGENT_WORKER-Thread-8 INFO:Local step 43000, global step 687322: loss 0.4543
[2019-04-06 18:07:51,708] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 43000, global step 687322: learning rate 0.0000
[2019-04-06 18:08:04,944] A3C_AGENT_WORKER-Thread-19 INFO:Local step 43500, global step 688899: loss 0.8019
[2019-04-06 18:08:04,945] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 43500, global step 688899: learning rate 0.0000
[2019-04-06 18:08:06,901] A3C_AGENT_WORKER-Thread-18 INFO:Local step 43500, global step 689134: loss 0.9803
[2019-04-06 18:08:06,901] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 43500, global step 689134: learning rate 0.0000
[2019-04-06 18:08:08,185] A3C_AGENT_WORKER-Thread-7 INFO:Local step 43000, global step 689273: loss 0.4891
[2019-04-06 18:08:08,186] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 43000, global step 689273: learning rate 0.0000
[2019-04-06 18:08:14,487] A3C_AGENT_WORKER-Thread-15 INFO:Local step 43500, global step 690013: loss 0.7684
[2019-04-06 18:08:14,549] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 43500, global step 690013: learning rate 0.0000
[2019-04-06 18:08:14,600] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9455379e-15 2.5645132e-15 4.1623701e-11 4.4706863e-14 1.0000000e+00
 2.0878202e-18 4.6568249e-15], sum to 1.0000
[2019-04-06 18:08:14,600] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2897
[2019-04-06 18:08:14,693] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.3, 29.0, 114.0, 351.0, 26.0, 25.79353914404819, 0.3964741683816709, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2561400.0000, 
sim time next is 2563200.0000, 
raw observation next is [3.3, 29.0, 92.0, 256.5, 26.0, 25.92266348158057, 0.3076393803762318, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.554016620498615, 0.29, 0.30666666666666664, 0.28342541436464086, 0.6666666666666666, 0.6602219567983809, 0.6025464601254106, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2551192], dtype=float32), -0.15027583]. 
=============================================
[2019-04-06 18:08:20,759] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4697671e-17 7.3825365e-18 1.7409544e-12 1.2377072e-15 1.0000000e+00
 4.2085408e-20 2.5115624e-17], sum to 1.0000
[2019-04-06 18:08:20,759] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2324
[2019-04-06 18:08:20,872] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.9, 62.5, 0.0, 0.0, 26.0, 24.90348507615874, 0.2770440968966069, 0.0, 1.0, 44162.739396596495], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 768600.0000, 
sim time next is 770400.0000, 
raw observation next is [-6.2, 64.0, 0.0, 0.0, 26.0, 24.75824149909222, 0.250106046255693, 0.0, 1.0, 43477.38659648553], 
processed observation next is [1.0, 0.9565217391304348, 0.2908587257617729, 0.64, 0.0, 0.0, 0.6666666666666666, 0.5631867915910185, 0.583368682085231, 0.0, 1.0, 0.20703517426897872], 
reward next is 0.7930, 
noisyNet noise sample is [array([0.82337403], dtype=float32), 1.2036413]. 
=============================================
[2019-04-06 18:08:27,655] A3C_AGENT_WORKER-Thread-17 INFO:Local step 44000, global step 691603: loss 0.0431
[2019-04-06 18:08:27,656] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 44000, global step 691603: learning rate 0.0000
[2019-04-06 18:08:29,649] A3C_AGENT_WORKER-Thread-14 INFO:Local step 44000, global step 691859: loss 0.0403
[2019-04-06 18:08:29,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 44000, global step 691859: learning rate 0.0000
[2019-04-06 18:08:31,049] A3C_AGENT_WORKER-Thread-6 INFO:Local step 43000, global step 692002: loss 0.5267
[2019-04-06 18:08:31,053] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 43000, global step 692002: learning rate 0.0000
[2019-04-06 18:08:34,151] A3C_AGENT_WORKER-Thread-16 INFO:Local step 43000, global step 692371: loss 0.5491
[2019-04-06 18:08:34,151] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 43000, global step 692371: learning rate 0.0000
[2019-04-06 18:08:34,658] A3C_AGENT_WORKER-Thread-8 INFO:Local step 43500, global step 692433: loss 0.8681
[2019-04-06 18:08:34,659] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 43500, global step 692433: learning rate 0.0000
[2019-04-06 18:08:36,240] A3C_AGENT_WORKER-Thread-12 INFO:Local step 43000, global step 692648: loss 0.5042
[2019-04-06 18:08:36,241] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 43000, global step 692648: learning rate 0.0000
[2019-04-06 18:08:36,677] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.2343739e-17 2.9421779e-17 1.9959711e-13 4.5927099e-17 1.0000000e+00
 5.4183225e-20 1.7036068e-18], sum to 1.0000
[2019-04-06 18:08:36,677] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9835
[2019-04-06 18:08:36,717] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.55, 55.0, 171.0, 0.0, 26.0, 27.36251619618025, 0.9434886478633016, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1085400.0000, 
sim time next is 1087200.0000, 
raw observation next is [18.8, 54.0, 155.5, 0.0, 26.0, 26.56320268945002, 0.8772444294485341, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.9833795013850417, 0.54, 0.5183333333333333, 0.0, 0.6666666666666666, 0.7136002241208349, 0.7924148098161781, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5506864], dtype=float32), 2.0286582]. 
=============================================
[2019-04-06 18:08:39,866] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7822977e-18 3.1867640e-19 7.6715706e-15 1.8036152e-17 1.0000000e+00
 4.5543139e-23 2.9854538e-19], sum to 1.0000
[2019-04-06 18:08:39,866] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8746
[2019-04-06 18:08:39,902] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 26.0, 26.09401100302438, 0.5720306337735205, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1015200.0000, 
sim time next is 1017000.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 26.0, 25.77469002020555, 0.5306643700382541, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.8614958448753465, 0.81, 0.0, 0.0, 0.6666666666666666, 0.6478908350171292, 0.6768881233460847, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.82171226], dtype=float32), -0.050021537]. 
=============================================
[2019-04-06 18:08:39,931] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[97.035805]
 [97.10197 ]
 [97.59916 ]
 [97.73065 ]
 [97.991455]], R is [[97.14975739]
 [97.1782608 ]
 [97.20648193]
 [97.23442078]
 [97.26207733]].
[2019-04-06 18:08:40,472] A3C_AGENT_WORKER-Thread-20 INFO:Local step 43000, global step 693303: loss 0.5126
[2019-04-06 18:08:40,472] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 43000, global step 693303: learning rate 0.0000
[2019-04-06 18:08:41,308] A3C_AGENT_WORKER-Thread-13 INFO:Local step 43000, global step 693420: loss 0.4559
[2019-04-06 18:08:41,308] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 43000, global step 693420: learning rate 0.0000
[2019-04-06 18:08:43,482] A3C_AGENT_WORKER-Thread-5 INFO:Local step 43000, global step 693783: loss 0.4727
[2019-04-06 18:08:43,482] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 43000, global step 693783: learning rate 0.0000
[2019-04-06 18:08:44,045] A3C_AGENT_WORKER-Thread-3 INFO:Local step 43000, global step 693873: loss 0.5241
[2019-04-06 18:08:44,046] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 43000, global step 693873: learning rate 0.0000
[2019-04-06 18:08:48,320] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5340711e-18 2.5028660e-19 4.0863452e-13 3.3570987e-18 1.0000000e+00
 6.8437271e-22 1.0610104e-18], sum to 1.0000
[2019-04-06 18:08:48,321] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1305
[2019-04-06 18:08:48,383] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [11.6, 80.0, 0.0, 0.0, 26.0, 25.6941216539068, 0.6139182567883178, 0.0, 1.0, 12482.337555594751], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1143000.0000, 
sim time next is 1144800.0000, 
raw observation next is [11.6, 83.0, 0.0, 0.0, 26.0, 25.64118335954192, 0.6069886865431512, 0.0, 1.0, 29367.241782456913], 
processed observation next is [0.0, 0.2608695652173913, 0.7839335180055402, 0.83, 0.0, 0.0, 0.6666666666666666, 0.6367652799618266, 0.7023295621810504, 0.0, 1.0, 0.13984400848789005], 
reward next is 0.8602, 
noisyNet noise sample is [array([-0.57880175], dtype=float32), 1.6398478]. 
=============================================
[2019-04-06 18:08:48,712] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3747646e-16 1.5812755e-17 6.9787092e-14 3.9145477e-16 1.0000000e+00
 1.3809956e-20 1.5610709e-18], sum to 1.0000
[2019-04-06 18:08:48,720] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3991
[2019-04-06 18:08:48,762] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 80.0, 0.0, 0.0, 26.0, 24.65253492006498, 0.2233786372398943, 0.0, 1.0, 39911.69076796202], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 865800.0000, 
sim time next is 867600.0000, 
raw observation next is [-2.3, 80.0, 0.0, 0.0, 26.0, 24.77071461533044, 0.226995726844178, 0.0, 1.0, 39567.90908309933], 
processed observation next is [1.0, 0.043478260869565216, 0.3988919667590028, 0.8, 0.0, 0.0, 0.6666666666666666, 0.5642262179442034, 0.5756652422813927, 0.0, 1.0, 0.18841861468142537], 
reward next is 0.8116, 
noisyNet noise sample is [array([2.113872], dtype=float32), -0.8366634]. 
=============================================
[2019-04-06 18:08:49,956] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.3165914e-19 7.6140032e-19 1.4854435e-12 9.3853858e-17 1.0000000e+00
 1.6231668e-22 2.5832724e-18], sum to 1.0000
[2019-04-06 18:08:49,965] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8032
[2019-04-06 18:08:49,982] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 57.5, 0.0, 26.0, 25.73887149486551, 0.5139645712797466, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1350000.0000, 
sim time next is 1351800.0000, 
raw observation next is [1.1, 92.5, 44.0, 0.0, 26.0, 25.70442399784238, 0.506170565890728, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.925, 0.14666666666666667, 0.0, 0.6666666666666666, 0.6420353331535317, 0.668723521963576, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.31443235], dtype=float32), 1.4378659]. 
=============================================
[2019-04-06 18:08:50,114] A3C_AGENT_WORKER-Thread-7 INFO:Local step 43500, global step 694910: loss 0.8195
[2019-04-06 18:08:50,114] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 43500, global step 694910: learning rate 0.0000
[2019-04-06 18:08:52,699] A3C_AGENT_WORKER-Thread-4 INFO:Local step 43000, global step 695326: loss 0.5113
[2019-04-06 18:08:52,701] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 43000, global step 695326: learning rate 0.0000
[2019-04-06 18:08:53,025] A3C_AGENT_WORKER-Thread-2 INFO:Local step 43000, global step 695384: loss 0.4747
[2019-04-06 18:08:53,032] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 43000, global step 695384: learning rate 0.0000
[2019-04-06 18:09:11,333] A3C_AGENT_WORKER-Thread-19 INFO:Local step 44000, global step 698530: loss 0.0405
[2019-04-06 18:09:11,345] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 44000, global step 698530: learning rate 0.0000
[2019-04-06 18:09:12,991] A3C_AGENT_WORKER-Thread-6 INFO:Local step 43500, global step 698777: loss 0.9321
[2019-04-06 18:09:12,992] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 43500, global step 698777: learning rate 0.0000
[2019-04-06 18:09:13,869] A3C_AGENT_WORKER-Thread-18 INFO:Local step 44000, global step 698897: loss 0.0505
[2019-04-06 18:09:13,871] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 44000, global step 698897: learning rate 0.0000
[2019-04-06 18:09:17,509] A3C_AGENT_WORKER-Thread-16 INFO:Local step 43500, global step 699392: loss 0.9218
[2019-04-06 18:09:17,515] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 43500, global step 699392: learning rate 0.0000
[2019-04-06 18:09:18,056] A3C_AGENT_WORKER-Thread-12 INFO:Local step 43500, global step 699448: loss 0.9291
[2019-04-06 18:09:18,057] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 43500, global step 699448: learning rate 0.0000
[2019-04-06 18:09:18,420] A3C_AGENT_WORKER-Thread-17 INFO:Local step 44500, global step 699489: loss 0.8674
[2019-04-06 18:09:18,421] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 44500, global step 699489: learning rate 0.0000
[2019-04-06 18:09:21,193] A3C_AGENT_WORKER-Thread-14 INFO:Local step 44500, global step 699890: loss 0.8925
[2019-04-06 18:09:21,194] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 44500, global step 699890: learning rate 0.0000
[2019-04-06 18:09:22,000] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-06 18:09:22,005] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:09:22,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:09:22,007] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run36
[2019-04-06 18:09:22,025] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:09:22,031] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:09:22,031] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:09:22,031] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:09:22,035] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run36
[2019-04-06 18:09:22,054] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run36
[2019-04-06 18:11:29,405] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 18:12:06,038] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13019224]
[2019-04-06 18:12:06,039] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [6.0, 23.0, 0.0, 0.0, 26.0, 26.32327287867116, 0.6623150067665848, 1.0, 1.0, 0.0]
[2019-04-06 18:12:06,039] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 18:12:06,040] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [5.2431843e-15 1.5594365e-15 7.7927933e-12 1.9006088e-14 1.0000000e+00
 4.7631612e-18 5.4848809e-16], sampled 0.708791860928274
[2019-04-06 18:12:08,562] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 18:12:12,236] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 18:12:13,274] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 700000, evaluation results [700000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 18:12:13,650] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3270285e-18 1.8941477e-19 3.9085217e-15 1.0242870e-18 1.0000000e+00
 4.4099026e-22 2.9657585e-20], sum to 1.0000
[2019-04-06 18:12:13,651] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5155
[2019-04-06 18:12:14,093] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2336338e-17 5.3829523e-19 8.2912803e-14 3.9819871e-18 1.0000000e+00
 8.8344448e-21 1.3586639e-18], sum to 1.0000
[2019-04-06 18:12:14,094] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4203
[2019-04-06 18:12:14,183] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 100.0, 127.0, 0.0, 26.0, 25.44219871776797, 0.342186897574229, 1.0, 1.0, 12453.607780153694], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2901600.0000, 
sim time next is 2903400.0000, 
raw observation next is [2.0, 100.0, 90.0, 0.0, 26.0, 24.24583702364944, 0.3103256159888872, 1.0, 1.0, 134222.8838768403], 
processed observation next is [1.0, 0.6086956521739131, 0.518005540166205, 1.0, 0.3, 0.0, 0.6666666666666666, 0.5204864186374533, 0.6034418719962957, 1.0, 1.0, 0.6391565898897157], 
reward next is 0.3608, 
noisyNet noise sample is [array([0.68548054], dtype=float32), 1.1795068]. 
=============================================
[2019-04-06 18:12:14,278] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.75, 52.5, 50.0, 37.0, 26.0, 27.48703531805883, 0.8715455452478112, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1614600.0000, 
sim time next is 1616400.0000, 
raw observation next is [12.2, 54.0, 25.5, 18.5, 26.0, 26.08209787821028, 0.7129098829059254, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.8005540166204987, 0.54, 0.085, 0.020441988950276244, 0.6666666666666666, 0.6735081565175234, 0.7376366276353085, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.94516844], dtype=float32), 0.3926494]. 
=============================================
[2019-04-06 18:12:14,635] A3C_AGENT_WORKER-Thread-15 INFO:Local step 44000, global step 700127: loss 0.0397
[2019-04-06 18:12:14,636] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 44000, global step 700127: learning rate 0.0000
[2019-04-06 18:12:14,858] A3C_AGENT_WORKER-Thread-20 INFO:Local step 43500, global step 700147: loss 0.9769
[2019-04-06 18:12:14,859] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 43500, global step 700147: learning rate 0.0000
[2019-04-06 18:12:15,076] A3C_AGENT_WORKER-Thread-13 INFO:Local step 43500, global step 700169: loss 0.7329
[2019-04-06 18:12:15,077] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 43500, global step 700169: learning rate 0.0000
[2019-04-06 18:12:21,220] A3C_AGENT_WORKER-Thread-3 INFO:Local step 43500, global step 700706: loss 0.6419
[2019-04-06 18:12:21,221] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 43500, global step 700706: learning rate 0.0000
[2019-04-06 18:12:21,471] A3C_AGENT_WORKER-Thread-5 INFO:Local step 43500, global step 700728: loss 0.9392
[2019-04-06 18:12:21,471] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 43500, global step 700728: learning rate 0.0000
[2019-04-06 18:12:35,586] A3C_AGENT_WORKER-Thread-4 INFO:Local step 43500, global step 701752: loss 0.9562
[2019-04-06 18:12:35,597] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 43500, global step 701752: learning rate 0.0000
[2019-04-06 18:12:36,724] A3C_AGENT_WORKER-Thread-2 INFO:Local step 43500, global step 701836: loss 0.8431
[2019-04-06 18:12:36,724] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 43500, global step 701836: learning rate 0.0000
[2019-04-06 18:12:44,489] A3C_AGENT_WORKER-Thread-8 INFO:Local step 44000, global step 702435: loss 0.0411
[2019-04-06 18:12:44,489] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 44000, global step 702435: learning rate 0.0000
[2019-04-06 18:13:10,072] A3C_AGENT_WORKER-Thread-7 INFO:Local step 44000, global step 704646: loss 0.0430
[2019-04-06 18:13:10,072] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 44000, global step 704646: learning rate 0.0000
[2019-04-06 18:13:12,733] A3C_AGENT_WORKER-Thread-17 INFO:Local step 45000, global step 704886: loss 1.4038
[2019-04-06 18:13:12,782] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 45000, global step 704886: learning rate 0.0000
[2019-04-06 18:13:14,570] A3C_AGENT_WORKER-Thread-19 INFO:Local step 44500, global step 705148: loss 0.9353
[2019-04-06 18:13:14,571] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 44500, global step 705148: learning rate 0.0000
[2019-04-06 18:13:15,644] A3C_AGENT_WORKER-Thread-14 INFO:Local step 45000, global step 705287: loss 1.4369
[2019-04-06 18:13:15,645] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 45000, global step 705287: learning rate 0.0000
[2019-04-06 18:13:15,759] A3C_AGENT_WORKER-Thread-18 INFO:Local step 44500, global step 705301: loss 0.9771
[2019-04-06 18:13:15,760] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 44500, global step 705301: learning rate 0.0000
[2019-04-06 18:13:20,940] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3817518e-17 3.9851047e-17 8.8990461e-14 1.1584504e-15 1.0000000e+00
 7.0237702e-20 4.3099072e-19], sum to 1.0000
[2019-04-06 18:13:20,941] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4240
[2019-04-06 18:13:20,994] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.59010801985841, 0.5529688686188413, 0.0, 1.0, 36650.74111701015], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3790800.0000, 
sim time next is 3792600.0000, 
raw observation next is [-3.0, 74.0, 0.0, 0.0, 26.0, 25.60559869627094, 0.523869505287112, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.3795013850415513, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6337998913559115, 0.6746231684290374, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.1249788], dtype=float32), -0.26705742]. 
=============================================
[2019-04-06 18:13:28,221] A3C_AGENT_WORKER-Thread-15 INFO:Local step 44500, global step 707070: loss 0.8401
[2019-04-06 18:13:28,229] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 44500, global step 707070: learning rate 0.0000
[2019-04-06 18:13:35,488] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.2893822e-16 4.3179281e-16 1.0313514e-12 1.1707831e-15 1.0000000e+00
 1.8273129e-18 5.9891516e-18], sum to 1.0000
[2019-04-06 18:13:35,488] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8909
[2019-04-06 18:13:35,558] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 45.0, 216.0, 130.0, 26.0, 26.42136218408088, 0.4347141848331331, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2644200.0000, 
sim time next is 2646000.0000, 
raw observation next is [0.5, 47.0, 185.5, 168.0, 26.0, 25.58254118764808, 0.4385070432945035, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.4764542936288089, 0.47, 0.6183333333333333, 0.1856353591160221, 0.6666666666666666, 0.6318784323040066, 0.6461690144315012, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3757981], dtype=float32), -0.062188823]. 
=============================================
[2019-04-06 18:13:35,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[81.65775 ]
 [81.96405 ]
 [82.169464]
 [82.681915]
 [81.97814 ]], R is [[81.23433685]
 [81.42199707]
 [81.60778046]
 [81.79170227]
 [81.34515381]].
[2019-04-06 18:13:37,259] A3C_AGENT_WORKER-Thread-6 INFO:Local step 44000, global step 708352: loss 0.0389
[2019-04-06 18:13:37,260] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 44000, global step 708352: learning rate 0.0000
[2019-04-06 18:13:41,524] A3C_AGENT_WORKER-Thread-12 INFO:Local step 44000, global step 709029: loss 0.0601
[2019-04-06 18:13:41,524] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 44000, global step 709029: learning rate 0.0000
[2019-04-06 18:13:41,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:13:41,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:13:41,688] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run17
[2019-04-06 18:13:42,371] A3C_AGENT_WORKER-Thread-16 INFO:Local step 44000, global step 709125: loss 0.0388
[2019-04-06 18:13:42,371] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 44000, global step 709125: learning rate 0.0000
[2019-04-06 18:13:44,704] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:13:44,704] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:13:44,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run17
[2019-04-06 18:13:46,245] A3C_AGENT_WORKER-Thread-8 INFO:Local step 44500, global step 709636: loss 0.9071
[2019-04-06 18:13:46,253] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 44500, global step 709638: learning rate 0.0000
[2019-04-06 18:13:47,228] A3C_AGENT_WORKER-Thread-13 INFO:Local step 44000, global step 709763: loss 0.0394
[2019-04-06 18:13:47,228] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 44000, global step 709763: learning rate 0.0000
[2019-04-06 18:13:48,418] A3C_AGENT_WORKER-Thread-20 INFO:Local step 44000, global step 709915: loss 0.0382
[2019-04-06 18:13:48,419] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 44000, global step 709915: learning rate 0.0000
[2019-04-06 18:13:50,280] A3C_AGENT_WORKER-Thread-5 INFO:Local step 44000, global step 710168: loss 0.0393
[2019-04-06 18:13:50,280] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 44000, global step 710168: learning rate 0.0000
[2019-04-06 18:13:50,949] A3C_AGENT_WORKER-Thread-3 INFO:Local step 44000, global step 710267: loss 0.0444
[2019-04-06 18:13:50,965] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 44000, global step 710267: learning rate 0.0000
[2019-04-06 18:13:53,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4124479e-15 3.0446782e-16 3.3911903e-13 2.1839997e-16 1.0000000e+00
 2.1895365e-18 9.0067784e-18], sum to 1.0000
[2019-04-06 18:13:53,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0356
[2019-04-06 18:13:53,699] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.8, 24.5, 95.0, 0.0, 26.0, 25.66033518937199, 0.381976773819219, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2820600.0000, 
sim time next is 2822400.0000, 
raw observation next is [6.6, 25.0, 83.0, 38.0, 26.0, 25.90981334894045, 0.4270837605869173, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.6454293628808865, 0.25, 0.27666666666666667, 0.041988950276243095, 0.6666666666666666, 0.6591511124117041, 0.6423612535289724, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2562149], dtype=float32), -0.5017545]. 
=============================================
[2019-04-06 18:13:59,155] A3C_AGENT_WORKER-Thread-19 INFO:Local step 45000, global step 711424: loss 1.1972
[2019-04-06 18:13:59,158] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 45000, global step 711424: learning rate 0.0000
[2019-04-06 18:14:00,093] A3C_AGENT_WORKER-Thread-2 INFO:Local step 44000, global step 711557: loss 0.0390
[2019-04-06 18:14:00,097] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 44000, global step 711557: learning rate 0.0000
[2019-04-06 18:14:00,643] A3C_AGENT_WORKER-Thread-4 INFO:Local step 44000, global step 711620: loss 0.0386
[2019-04-06 18:14:00,644] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 44000, global step 711620: learning rate 0.0000
[2019-04-06 18:14:01,507] A3C_AGENT_WORKER-Thread-18 INFO:Local step 45000, global step 711741: loss 1.5732
[2019-04-06 18:14:01,543] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 45000, global step 711741: learning rate 0.0000
[2019-04-06 18:14:05,646] A3C_AGENT_WORKER-Thread-7 INFO:Local step 44500, global step 712322: loss 0.8201
[2019-04-06 18:14:05,648] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 44500, global step 712322: learning rate 0.0000
[2019-04-06 18:14:12,781] A3C_AGENT_WORKER-Thread-15 INFO:Local step 45000, global step 713424: loss 1.3995
[2019-04-06 18:14:12,782] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 45000, global step 713424: learning rate 0.0000
[2019-04-06 18:14:27,329] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:14:27,329] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:14:27,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run17
[2019-04-06 18:14:28,905] A3C_AGENT_WORKER-Thread-8 INFO:Local step 45000, global step 716037: loss 1.1865
[2019-04-06 18:14:28,906] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 45000, global step 716037: learning rate 0.0000
[2019-04-06 18:14:29,432] A3C_AGENT_WORKER-Thread-6 INFO:Local step 44500, global step 716117: loss 0.7765
[2019-04-06 18:14:29,432] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 44500, global step 716117: learning rate 0.0000
[2019-04-06 18:14:29,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:14:29,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:14:29,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run17
[2019-04-06 18:14:32,920] A3C_AGENT_WORKER-Thread-12 INFO:Local step 44500, global step 716626: loss 0.8006
[2019-04-06 18:14:32,920] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 44500, global step 716626: learning rate 0.0000
[2019-04-06 18:14:33,872] A3C_AGENT_WORKER-Thread-16 INFO:Local step 44500, global step 716761: loss 0.8532
[2019-04-06 18:14:33,873] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 44500, global step 716761: learning rate 0.0000
[2019-04-06 18:14:36,354] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7744155e-15 4.2983407e-15 7.6633630e-12 1.9190031e-15 1.0000000e+00
 9.4100100e-18 3.0956951e-15], sum to 1.0000
[2019-04-06 18:14:36,355] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2132
[2019-04-06 18:14:36,418] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.5, 70.0, 3.0, 121.0, 26.0, 24.28451695673412, 0.1902419361874061, 0.0, 1.0, 41448.90862776351], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3569400.0000, 
sim time next is 3571200.0000, 
raw observation next is [-7.0, 70.0, 45.5, 273.0, 26.0, 24.20441849000851, 0.1986919864685137, 0.0, 1.0, 41494.04482403348], 
processed observation next is [0.0, 0.34782608695652173, 0.2686980609418283, 0.7, 0.15166666666666667, 0.30165745856353593, 0.6666666666666666, 0.5170348741673759, 0.5662306621561712, 0.0, 1.0, 0.19759068963825466], 
reward next is 0.8024, 
noisyNet noise sample is [array([0.10095196], dtype=float32), 0.7497681]. 
=============================================
[2019-04-06 18:14:40,090] A3C_AGENT_WORKER-Thread-13 INFO:Local step 44500, global step 717735: loss 0.8081
[2019-04-06 18:14:40,091] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 44500, global step 717735: learning rate 0.0000
[2019-04-06 18:14:40,281] A3C_AGENT_WORKER-Thread-20 INFO:Local step 44500, global step 717769: loss 0.7762
[2019-04-06 18:14:40,283] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 44500, global step 717769: learning rate 0.0000
[2019-04-06 18:14:40,951] A3C_AGENT_WORKER-Thread-5 INFO:Local step 44500, global step 717886: loss 0.7182
[2019-04-06 18:14:40,953] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 44500, global step 717886: learning rate 0.0000
[2019-04-06 18:14:41,750] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:14:41,750] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:14:41,755] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run17
[2019-04-06 18:14:42,859] A3C_AGENT_WORKER-Thread-3 INFO:Local step 44500, global step 718209: loss 0.7733
[2019-04-06 18:14:42,895] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 44500, global step 718209: learning rate 0.0000
[2019-04-06 18:14:50,055] A3C_AGENT_WORKER-Thread-7 INFO:Local step 45000, global step 719272: loss 1.0996
[2019-04-06 18:14:50,058] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 45000, global step 719272: learning rate 0.0000
[2019-04-06 18:14:51,780] A3C_AGENT_WORKER-Thread-4 INFO:Local step 44500, global step 719561: loss 0.8287
[2019-04-06 18:14:51,781] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 44500, global step 719561: learning rate 0.0000
[2019-04-06 18:14:52,718] A3C_AGENT_WORKER-Thread-2 INFO:Local step 44500, global step 719713: loss 0.8452
[2019-04-06 18:14:52,719] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 44500, global step 719713: learning rate 0.0000
[2019-04-06 18:14:54,612] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 18:14:54,616] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:14:54,616] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:14:54,618] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run37
[2019-04-06 18:14:54,638] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:14:54,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:14:54,641] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:14:54,642] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:14:54,643] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run37
[2019-04-06 18:14:54,660] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run37
[2019-04-06 18:16:23,485] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13129833]
[2019-04-06 18:16:23,486] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [0.779800623, 94.36047013, 45.41494583, 37.2927081, 26.0, 25.07250095618177, 0.237894085373723, 1.0, 1.0, 0.0]
[2019-04-06 18:16:23,486] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 18:16:23,487] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [5.1579936e-17 6.9590755e-18 1.2358615e-13 1.5783656e-16 1.0000000e+00
 1.1517894e-20 1.4621501e-18], sampled 0.4200749564884767
[2019-04-06 18:16:58,451] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 18:17:38,399] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 18:17:44,407] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 18:17:45,454] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 720000, evaluation results [720000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 18:17:47,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:17:47,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:17:47,612] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run17
[2019-04-06 18:17:51,877] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2788077e-17 7.4154790e-17 1.4908422e-12 5.3721726e-15 1.0000000e+00
 2.8977862e-20 5.8140408e-17], sum to 1.0000
[2019-04-06 18:17:51,878] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2981
[2019-04-06 18:17:52,036] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.0, 35.0, 100.0, 744.5, 26.0, 27.11390624400034, 0.7706834053809537, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4114800.0000, 
sim time next is 4116600.0000, 
raw observation next is [4.0, 35.0, 94.0, 695.0, 26.0, 25.93534144411896, 0.6546307830735225, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5734072022160666, 0.35, 0.31333333333333335, 0.7679558011049724, 0.6666666666666666, 0.6612784536765801, 0.7182102610245075, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.96753937], dtype=float32), 1.7943093]. 
=============================================
[2019-04-06 18:18:14,968] A3C_AGENT_WORKER-Thread-6 INFO:Local step 45000, global step 722701: loss 1.1067
[2019-04-06 18:18:15,055] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 45000, global step 722701: learning rate 0.0000
[2019-04-06 18:18:19,521] A3C_AGENT_WORKER-Thread-12 INFO:Local step 45000, global step 723168: loss 1.5288
[2019-04-06 18:18:19,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 45000, global step 723168: learning rate 0.0000
[2019-04-06 18:18:21,939] A3C_AGENT_WORKER-Thread-16 INFO:Local step 45000, global step 723403: loss 1.3510
[2019-04-06 18:18:22,014] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 45000, global step 723403: learning rate 0.0000
[2019-04-06 18:18:23,720] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:18:23,720] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:18:23,724] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run17
[2019-04-06 18:18:27,858] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.4058442e-18 1.2238171e-19 4.2196698e-14 7.7958133e-19 1.0000000e+00
 8.4469428e-22 1.6353330e-18], sum to 1.0000
[2019-04-06 18:18:27,858] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1098
[2019-04-06 18:18:27,896] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 86.0, 196.5, 73.0, 26.0, 26.47055401099288, 0.652253373841977, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4446000.0000, 
sim time next is 4447800.0000, 
raw observation next is [1.0, 86.0, 142.0, 0.0, 26.0, 26.47507829036509, 0.6339295377352562, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4903047091412743, 0.86, 0.47333333333333333, 0.0, 0.6666666666666666, 0.7062565241970908, 0.7113098459117521, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.63413465], dtype=float32), 0.57177585]. 
=============================================
[2019-04-06 18:18:34,465] A3C_AGENT_WORKER-Thread-20 INFO:Local step 45000, global step 724595: loss 1.2897
[2019-04-06 18:18:34,465] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 45000, global step 724595: learning rate 0.0000
[2019-04-06 18:18:35,484] A3C_AGENT_WORKER-Thread-13 INFO:Local step 45000, global step 724692: loss 1.3862
[2019-04-06 18:18:35,484] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 45000, global step 724692: learning rate 0.0000
[2019-04-06 18:18:36,023] A3C_AGENT_WORKER-Thread-5 INFO:Local step 45000, global step 724749: loss 1.4412
[2019-04-06 18:18:36,037] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 45000, global step 724749: learning rate 0.0000
[2019-04-06 18:18:39,101] A3C_AGENT_WORKER-Thread-3 INFO:Local step 45000, global step 725044: loss 1.2661
[2019-04-06 18:18:39,101] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 45000, global step 725044: learning rate 0.0000
[2019-04-06 18:18:50,331] A3C_AGENT_WORKER-Thread-4 INFO:Local step 45000, global step 726121: loss 1.5456
[2019-04-06 18:18:50,332] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 45000, global step 726121: learning rate 0.0000
[2019-04-06 18:18:52,790] A3C_AGENT_WORKER-Thread-2 INFO:Local step 45000, global step 726356: loss 1.4007
[2019-04-06 18:18:52,795] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 45000, global step 726356: learning rate 0.0000
[2019-04-06 18:19:01,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:19:01,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:19:01,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run17
[2019-04-06 18:19:03,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:19:03,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:19:03,612] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run17
[2019-04-06 18:19:06,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:19:06,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:19:06,040] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run17
[2019-04-06 18:19:10,558] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8537688e-17 5.3681697e-18 4.7131204e-15 1.2103595e-16 1.0000000e+00
 6.2563919e-21 6.9874552e-19], sum to 1.0000
[2019-04-06 18:19:10,559] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6847
[2019-04-06 18:19:10,606] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.9, 90.5, 97.0, 0.0, 26.0, 25.35470529794026, 0.2807033926609229, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 905400.0000, 
sim time next is 907200.0000, 
raw observation next is [2.7, 97.0, 100.5, 0.0, 26.0, 25.31773867047569, 0.2736945731753942, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5373961218836566, 0.97, 0.335, 0.0, 0.6666666666666666, 0.6098115558729743, 0.591231524391798, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4563415], dtype=float32), 1.2555784]. 
=============================================
[2019-04-06 18:19:12,225] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:19:12,225] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:19:12,228] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run17
[2019-04-06 18:19:13,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:19:13,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:19:13,508] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run17
[2019-04-06 18:19:13,929] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:19:13,929] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:19:13,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run17
[2019-04-06 18:19:15,410] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:19:15,410] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:19:15,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run17
[2019-04-06 18:19:15,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.9618183e-15 8.2130141e-16 9.5898896e-12 1.5627117e-15 1.0000000e+00
 1.5917813e-18 3.5376866e-16], sum to 1.0000
[2019-04-06 18:19:15,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2673
[2019-04-06 18:19:15,989] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 77.0, 186.0, 84.0, 26.0, 25.02400287137179, 0.2848329772363838, 0.0, 1.0, 40225.9140753217], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1866600.0000, 
sim time next is 1868400.0000, 
raw observation next is [-4.5, 83.0, 129.0, 42.0, 26.0, 25.05675712925748, 0.285634841704951, 0.0, 1.0, 36788.02930955776], 
processed observation next is [0.0, 0.6521739130434783, 0.3379501385041552, 0.83, 0.43, 0.04640883977900553, 0.6666666666666666, 0.5880630941047901, 0.5952116139016503, 0.0, 1.0, 0.17518109195027504], 
reward next is 0.8248, 
noisyNet noise sample is [array([-0.3159483], dtype=float32), 0.98949033]. 
=============================================
[2019-04-06 18:19:17,950] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.1698495e-16 9.0972133e-18 2.3070914e-14 7.9611769e-16 1.0000000e+00
 3.0974828e-20 4.9653138e-18], sum to 1.0000
[2019-04-06 18:19:17,950] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3315
[2019-04-06 18:19:18,238] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.3, 68.0, 18.5, 4.5, 26.0, 24.79452336000355, 0.2297489401481081, 1.0, 1.0, 92782.65688089172], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 115200.0000, 
sim time next is 117000.0000, 
raw observation next is [-7.55, 64.5, 37.0, 9.0, 26.0, 25.17632608306518, 0.2695840529009718, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.25346260387811637, 0.645, 0.12333333333333334, 0.009944751381215469, 0.6666666666666666, 0.5980271735887651, 0.5898613509669907, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.60492235], dtype=float32), 0.13495728]. 
=============================================
[2019-04-06 18:19:18,252] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[84.5493 ]
 [83.10453]
 [81.24569]
 [82.27752]
 [83.29902]], R is [[84.4358902 ]
 [84.14970398]
 [83.59119415]
 [83.53733826]
 [83.48558807]].
[2019-04-06 18:19:20,868] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9650110e-13 5.0921342e-15 4.8871858e-11 7.8468671e-14 1.0000000e+00
 1.2217007e-17 1.6713279e-15], sum to 1.0000
[2019-04-06 18:19:20,868] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8449
[2019-04-06 18:19:20,875] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 26.0, 23.54161122248833, 0.1569648596506685, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1233000.0000, 
sim time next is 1234800.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 26.0, 23.48190203740111, 0.1450161665399247, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.8781163434903049, 0.96, 0.0, 0.0, 0.6666666666666666, 0.4568251697834258, 0.5483387221799749, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.56788576], dtype=float32), 0.8443896]. 
=============================================
[2019-04-06 18:19:23,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:19:23,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:19:23,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run17
[2019-04-06 18:19:24,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:19:24,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:19:24,202] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run17
[2019-04-06 18:19:29,158] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0355628e-16 5.2612285e-18 6.6945630e-13 1.2341847e-16 1.0000000e+00
 8.7966509e-20 6.6663065e-19], sum to 1.0000
[2019-04-06 18:19:29,159] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2880
[2019-04-06 18:19:29,290] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.7, 89.0, 0.0, 0.0, 26.0, 24.76302009380306, 0.2414665132173253, 0.0, 1.0, 46727.08612142938], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 72000.0000, 
sim time next is 73800.0000, 
raw observation next is [2.15, 87.0, 0.0, 0.0, 26.0, 24.72891833459106, 0.2325488084706193, 0.0, 1.0, 41363.108367452565], 
processed observation next is [0.0, 0.8695652173913043, 0.5221606648199446, 0.87, 0.0, 0.0, 0.6666666666666666, 0.560743194549255, 0.5775162694902064, 0.0, 1.0, 0.19696718270215507], 
reward next is 0.8030, 
noisyNet noise sample is [array([0.89334244], dtype=float32), 0.8614675]. 
=============================================
[2019-04-06 18:19:33,850] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1214825e-19 2.0133584e-19 7.4767228e-16 1.6144577e-17 1.0000000e+00
 8.5230665e-23 2.8071540e-19], sum to 1.0000
[2019-04-06 18:19:33,850] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1218
[2019-04-06 18:19:33,906] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 26.0, 25.38750663428533, 0.4888479649776842, 0.0, 1.0, 32834.34056289907], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1467000.0000, 
sim time next is 1468800.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 26.0, 25.35619113467727, 0.4833602599296083, 0.0, 1.0, 41468.903395248904], 
processed observation next is [1.0, 0.0, 0.5069252077562327, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6130159278897725, 0.6611200866432028, 0.0, 1.0, 0.1974709685488043], 
reward next is 0.8025, 
noisyNet noise sample is [array([0.8805005], dtype=float32), -0.4977045]. 
=============================================
[2019-04-06 18:19:39,461] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7338659e-16 1.0602537e-18 1.2155152e-14 3.0113424e-16 1.0000000e+00
 2.8448088e-19 6.6967464e-17], sum to 1.0000
[2019-04-06 18:19:39,461] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5478
[2019-04-06 18:19:39,516] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.4, 71.0, 0.0, 0.0, 26.0, 23.83111906754072, 0.03036862498501211, 0.0, 1.0, 44645.383959365565], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 172800.0000, 
sim time next is 174600.0000, 
raw observation next is [-8.65, 72.5, 0.0, 0.0, 26.0, 23.77452333576235, 0.01902177049051786, 0.0, 1.0, 44484.57759034191], 
processed observation next is [1.0, 0.0, 0.22299168975069253, 0.725, 0.0, 0.0, 0.6666666666666666, 0.48121027798019583, 0.506340590163506, 0.0, 1.0, 0.21183132185877102], 
reward next is 0.7882, 
noisyNet noise sample is [array([-0.0541188], dtype=float32), -0.38195622]. 
=============================================
[2019-04-06 18:19:45,287] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.3463638e-18 1.0907216e-19 2.5701347e-15 5.5717410e-17 1.0000000e+00
 1.3768598e-22 2.4898767e-19], sum to 1.0000
[2019-04-06 18:19:45,287] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3543
[2019-04-06 18:19:45,340] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.8, 93.0, 100.0, 0.0, 26.0, 25.16041495045255, 0.2523087719790451, 1.0, 1.0, 6226.803890076847], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 910800.0000, 
sim time next is 912600.0000, 
raw observation next is [3.8, 93.0, 96.0, 0.0, 26.0, 25.06163939066338, 0.1595988371560272, 1.0, 1.0, 32708.09005385809], 
processed observation next is [1.0, 0.5652173913043478, 0.5678670360110805, 0.93, 0.32, 0.0, 0.6666666666666666, 0.5884699492219484, 0.5531996123853424, 1.0, 1.0, 0.1557528097802766], 
reward next is 0.8442, 
noisyNet noise sample is [array([0.7259403], dtype=float32), -0.8755479]. 
=============================================
[2019-04-06 18:19:59,806] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.0024329e-15 1.3380094e-16 3.9096065e-13 6.3103175e-15 1.0000000e+00
 1.2740123e-17 3.3609318e-17], sum to 1.0000
[2019-04-06 18:19:59,806] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6869
[2019-04-06 18:20:00,205] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-10.6, 49.0, 12.0, 123.0, 26.0, 25.73770581043334, 0.3034602691692624, 1.0, 1.0, 123946.38004885237], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 320400.0000, 
sim time next is 322200.0000, 
raw observation next is [-11.15, 53.0, 0.0, 0.0, 26.0, 25.69481169029178, 0.4010175401446385, 1.0, 1.0, 87434.64669312385], 
processed observation next is [1.0, 0.7391304347826086, 0.15373961218836565, 0.53, 0.0, 0.0, 0.6666666666666666, 0.6412343075243149, 0.6336725133815462, 1.0, 1.0, 0.4163554604434469], 
reward next is 0.5836, 
noisyNet noise sample is [array([-2.0673172], dtype=float32), -0.9109275]. 
=============================================
[2019-04-06 18:20:25,521] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4558005e-15 2.7486641e-17 2.1111966e-12 2.0912989e-15 1.0000000e+00
 3.9651920e-18 5.3122945e-17], sum to 1.0000
[2019-04-06 18:20:25,524] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4854
[2019-04-06 18:20:25,588] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.65, 70.0, 0.0, 0.0, 26.0, 24.71147647869514, 0.1608814635250343, 0.0, 1.0, 41843.920408450154], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 685800.0000, 
sim time next is 687600.0000, 
raw observation next is [-3.9, 71.0, 0.0, 0.0, 26.0, 24.65055066132891, 0.1402537811148311, 0.0, 1.0, 41634.72396876032], 
processed observation next is [0.0, 1.0, 0.3545706371191136, 0.71, 0.0, 0.0, 0.6666666666666666, 0.5542125551107425, 0.5467512603716104, 0.0, 1.0, 0.1982605903274301], 
reward next is 0.8017, 
noisyNet noise sample is [array([0.6800709], dtype=float32), -0.74059594]. 
=============================================
[2019-04-06 18:20:43,305] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8724562e-16 4.5530251e-17 1.8670794e-13 3.4012645e-16 1.0000000e+00
 1.9103889e-18 5.7777368e-17], sum to 1.0000
[2019-04-06 18:20:43,311] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3948
[2019-04-06 18:20:43,556] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 69.0, 19.5, 0.0, 26.0, 23.91063895871935, 0.06930556240758923, 0.0, 1.0, 41888.83506701159], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2361600.0000, 
sim time next is 2363400.0000, 
raw observation next is [-3.4, 69.0, 37.0, 0.0, 26.0, 24.32653716107244, 0.2248567102113566, 0.0, 1.0, 149018.30715154903], 
processed observation next is [0.0, 0.34782608695652173, 0.368421052631579, 0.69, 0.12333333333333334, 0.0, 0.6666666666666666, 0.5272114300893701, 0.5749522367371188, 0.0, 1.0, 0.7096109864359478], 
reward next is 0.2904, 
noisyNet noise sample is [array([-0.18723573], dtype=float32), -0.45037997]. 
=============================================
[2019-04-06 18:20:47,694] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 18:20:47,695] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:20:47,695] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:20:47,705] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:20:47,706] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:20:47,708] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run38
[2019-04-06 18:20:47,737] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:20:47,739] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:20:47,743] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run38
[2019-04-06 18:20:47,763] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run38
[2019-04-06 18:22:50,834] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13130842]
[2019-04-06 18:22:50,834] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [6.5, 33.5, 183.0, 549.0, 26.0, 26.59657383175288, 0.6487038241788783, 1.0, 1.0, 0.0]
[2019-04-06 18:22:50,834] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 18:22:50,835] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.1875022e-15 2.7180938e-16 2.2644046e-12 4.8497261e-15 1.0000000e+00
 9.1396799e-19 9.7051288e-17], sampled 0.0730763530849452
[2019-04-06 18:22:53,388] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 18:23:30,600] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 18:23:35,990] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 18:23:37,026] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 740000, evaluation results [740000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 18:23:49,313] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.9858183e-19 5.4536814e-19 8.3414915e-16 1.2639760e-19 1.0000000e+00
 6.4913079e-23 1.3747514e-20], sum to 1.0000
[2019-04-06 18:23:49,314] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7919
[2019-04-06 18:23:49,376] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.4, 77.0, 0.0, 0.0, 26.0, 25.97328306175707, 0.6235589188547771, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1051200.0000, 
sim time next is 1053000.0000, 
raw observation next is [14.1, 77.5, 0.0, 0.0, 26.0, 25.82285785317278, 0.598940394872573, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.8531855955678671, 0.775, 0.0, 0.0, 0.6666666666666666, 0.6519048210977317, 0.6996467982908577, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.58432615], dtype=float32), -0.16592796]. 
=============================================
[2019-04-06 18:23:49,481] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[95.99159 ]
 [95.938446]
 [95.87439 ]
 [94.39377 ]
 [94.63963 ]], R is [[95.71056366]
 [95.75345612]
 [95.79592133]
 [95.33237457]
 [95.37905121]].
[2019-04-06 18:24:25,038] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.1675165e-18 1.0560160e-17 6.2597327e-14 7.0409730e-18 1.0000000e+00
 9.0002049e-21 1.5713659e-17], sum to 1.0000
[2019-04-06 18:24:25,038] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2574
[2019-04-06 18:24:25,106] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 26.0, 25.34692421454712, 0.4667020706658292, 0.0, 1.0, 43137.29154876463], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1729800.0000, 
sim time next is 1731600.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 26.0, 25.37278151432364, 0.4633704071008434, 0.0, 1.0, 42147.8122985275], 
processed observation next is [0.0, 0.043478260869565216, 0.4764542936288089, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6143984595269701, 0.6544568023669478, 0.0, 1.0, 0.20070386808822618], 
reward next is 0.7993, 
noisyNet noise sample is [array([2.1548352], dtype=float32), 0.7083268]. 
=============================================
[2019-04-06 18:24:35,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3415372e-14 1.7379590e-15 4.8798688e-13 8.0640942e-15 1.0000000e+00
 2.7072861e-19 2.5080105e-17], sum to 1.0000
[2019-04-06 18:24:35,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0950
[2019-04-06 18:24:35,714] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.5, 40.5, 99.0, 775.0, 26.0, 25.11734990882496, 0.3631023763620092, 0.0, 1.0, 12469.973876226446], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3076200.0000, 
sim time next is 3078000.0000, 
raw observation next is [0.0, 39.0, 91.5, 724.0, 26.0, 25.11709159150148, 0.3645796427223548, 0.0, 1.0, 18702.64314491442], 
processed observation next is [0.0, 0.6521739130434783, 0.46260387811634357, 0.39, 0.305, 0.8, 0.6666666666666666, 0.5930909659584568, 0.6215265475741183, 0.0, 1.0, 0.08906020545197342], 
reward next is 0.9109, 
noisyNet noise sample is [array([1.0653895], dtype=float32), 0.6222952]. 
=============================================
[2019-04-06 18:24:35,718] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.91938 ]
 [75.21422 ]
 [75.35723 ]
 [75.471054]
 [75.57208 ]], R is [[74.86653137]
 [75.05848694]
 [75.21880341]
 [75.37749481]
 [75.5940094 ]].
[2019-04-06 18:24:37,426] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.03212473e-16 4.31244202e-18 1.62246312e-12 3.47508951e-16
 1.00000000e+00 2.92682641e-20 9.95777392e-18], sum to 1.0000
[2019-04-06 18:24:37,427] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9585
[2019-04-06 18:24:37,463] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 51.0, 0.0, 0.0, 26.0, 25.46452565877328, 0.4886306625651453, 0.0, 1.0, 12453.607780153694], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3871800.0000, 
sim time next is 3873600.0000, 
raw observation next is [1.0, 51.0, 0.0, 0.0, 26.0, 25.20402174094051, 0.4437359299083017, 0.0, 1.0, 19319.763637894284], 
processed observation next is [1.0, 0.8695652173913043, 0.4903047091412743, 0.51, 0.0, 0.0, 0.6666666666666666, 0.6003351450783759, 0.6479119766361006, 0.0, 1.0, 0.09199887446616326], 
reward next is 0.9080, 
noisyNet noise sample is [array([1.4616143], dtype=float32), -0.7941982]. 
=============================================
[2019-04-06 18:24:39,808] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3801882e-15 2.0162734e-17 1.2722187e-12 1.3202839e-16 1.0000000e+00
 8.7781137e-20 5.6684279e-17], sum to 1.0000
[2019-04-06 18:24:39,808] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9881
[2019-04-06 18:24:39,893] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.9, 85.0, 0.0, 0.0, 26.0, 24.36732572253373, 0.143270463792201, 0.0, 1.0, 41829.95009241509], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1992600.0000, 
sim time next is 1994400.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.28276289388952, 0.1261620316988798, 0.0, 1.0, 41731.88489302605], 
processed observation next is [1.0, 0.08695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5235635744907933, 0.5420540105662933, 0.0, 1.0, 0.19872326139536214], 
reward next is 0.8013, 
noisyNet noise sample is [array([0.49251527], dtype=float32), -0.011835456]. 
=============================================
[2019-04-06 18:24:45,067] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.0170525e-15 1.1191226e-15 2.7554846e-12 8.9425022e-14 1.0000000e+00
 4.3042575e-18 6.2635958e-16], sum to 1.0000
[2019-04-06 18:24:45,068] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4946
[2019-04-06 18:24:45,278] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 71.0, 152.0, 40.5, 26.0, 24.98430078594512, 0.2632197226867747, 0.0, 1.0, 39311.0313140884], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1857600.0000, 
sim time next is 1859400.0000, 
raw observation next is [-4.75, 71.0, 120.0, 0.0, 26.0, 24.9656901510483, 0.2507693813165084, 0.0, 1.0, 43346.348652794004], 
processed observation next is [0.0, 0.5217391304347826, 0.3310249307479225, 0.71, 0.4, 0.0, 0.6666666666666666, 0.580474179254025, 0.5835897937721695, 0.0, 1.0, 0.20641118406092382], 
reward next is 0.7936, 
noisyNet noise sample is [array([1.1421956], dtype=float32), -1.7598957]. 
=============================================
[2019-04-06 18:24:51,659] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.9179124e-17 1.1911078e-17 9.3535596e-13 1.1132123e-16 1.0000000e+00
 1.0846922e-20 5.5592095e-19], sum to 1.0000
[2019-04-06 18:24:51,659] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8756
[2019-04-06 18:24:51,851] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 83.0, 124.5, 0.0, 26.0, 25.53249960942394, 0.3152969786836625, 1.0, 1.0, 32853.23922616997], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2026800.0000, 
sim time next is 2028600.0000, 
raw observation next is [-5.05, 79.0, 147.0, 0.0, 26.0, 25.61360581714872, 0.3350991692650219, 1.0, 1.0, 26122.145766541948], 
processed observation next is [1.0, 0.4782608695652174, 0.32271468144044324, 0.79, 0.49, 0.0, 0.6666666666666666, 0.63446715142906, 0.6116997230883406, 1.0, 1.0, 0.12439117031686642], 
reward next is 0.8756, 
noisyNet noise sample is [array([-0.4225736], dtype=float32), 0.036573887]. 
=============================================
[2019-04-06 18:25:08,757] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.8742851e-15 1.5064440e-15 5.8067743e-12 3.3397211e-14 1.0000000e+00
 4.3495655e-18 6.0212751e-16], sum to 1.0000
[2019-04-06 18:25:08,757] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2204
[2019-04-06 18:25:08,845] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-16.0, 83.0, 0.0, 0.0, 26.0, 23.08827818626275, -0.1239048486875138, 0.0, 1.0, 43419.67227082703], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2700000.0000, 
sim time next is 2701800.0000, 
raw observation next is [-15.5, 83.0, 0.0, 0.0, 26.0, 22.92639158909322, -0.1496839344129082, 0.0, 1.0, 43242.13674230963], 
processed observation next is [1.0, 0.2608695652173913, 0.033240997229916885, 0.83, 0.0, 0.0, 0.6666666666666666, 0.4105326324244351, 0.4501053551956973, 0.0, 1.0, 0.2059149368681411], 
reward next is 0.7941, 
noisyNet noise sample is [array([1.4762442], dtype=float32), -0.87974143]. 
=============================================
[2019-04-06 18:25:18,000] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8788599e-15 1.6428888e-15 3.0126123e-12 7.1943889e-14 1.0000000e+00
 3.7954253e-17 1.8435382e-15], sum to 1.0000
[2019-04-06 18:25:18,006] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2612
[2019-04-06 18:25:18,074] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.95, 33.0, 0.0, 0.0, 26.0, 25.3138474893419, 0.2850559906886002, 0.0, 1.0, 40430.331885385574], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2493000.0000, 
sim time next is 2494800.0000, 
raw observation next is [-1.2, 37.0, 0.0, 0.0, 26.0, 25.28502979956934, 0.2753387514382495, 0.0, 1.0, 40037.99526287254], 
processed observation next is [0.0, 0.9130434782608695, 0.42936288088642666, 0.37, 0.0, 0.0, 0.6666666666666666, 0.6070858166307783, 0.5917795838127499, 0.0, 1.0, 0.19065712029939302], 
reward next is 0.8093, 
noisyNet noise sample is [array([-1.3063387], dtype=float32), 0.18371752]. 
=============================================
[2019-04-06 18:25:31,773] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.6351699e-14 2.7309605e-16 7.1602546e-12 7.5586035e-14 1.0000000e+00
 1.0793487e-17 2.9902927e-15], sum to 1.0000
[2019-04-06 18:25:31,773] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2844
[2019-04-06 18:25:31,822] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 41.0, 0.0, 0.0, 26.0, 24.74371517271761, 0.1846276973966529, 0.0, 1.0, 43039.324776003945], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2415600.0000, 
sim time next is 2417400.0000, 
raw observation next is [-5.3, 42.0, 0.0, 0.0, 26.0, 24.65099208725127, 0.1708642532139223, 0.0, 1.0, 43101.10712954394], 
processed observation next is [0.0, 1.0, 0.31578947368421056, 0.42, 0.0, 0.0, 0.6666666666666666, 0.5542493406042727, 0.5569547510713074, 0.0, 1.0, 0.20524336728354256], 
reward next is 0.7948, 
noisyNet noise sample is [array([-0.36999863], dtype=float32), -2.8223152]. 
=============================================
[2019-04-06 18:25:33,633] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.9227906e-16 7.2533185e-18 1.6054828e-12 4.8952808e-16 1.0000000e+00
 2.0817512e-19 4.4123013e-18], sum to 1.0000
[2019-04-06 18:25:33,633] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.5315
[2019-04-06 18:25:33,678] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 60.0, 104.0, 720.0, 26.0, 26.13592173441813, 0.5618222830934493, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3492000.0000, 
sim time next is 3493800.0000, 
raw observation next is [0.5, 60.5, 109.0, 770.0, 26.0, 26.21580275249475, 0.5809408680963203, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4764542936288089, 0.605, 0.36333333333333334, 0.850828729281768, 0.6666666666666666, 0.6846502293745624, 0.6936469560321067, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.73536354], dtype=float32), -1.0485379]. 
=============================================
[2019-04-06 18:25:34,798] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.61616863e-17 1.20031236e-17 1.03450766e-12 1.89658724e-16
 1.00000000e+00 4.65860786e-20 2.56187907e-18], sum to 1.0000
[2019-04-06 18:25:34,798] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2200
[2019-04-06 18:25:34,888] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 74.0, 0.0, 0.0, 26.0, 25.39492280982281, 0.3764409168856777, 0.0, 1.0, 43020.21332986234], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3810600.0000, 
sim time next is 3812400.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 26.0, 25.12611141566085, 0.3484292691727429, 0.0, 1.0, 53069.78138269106], 
processed observation next is [1.0, 0.13043478260869565, 0.3518005540166205, 0.71, 0.0, 0.0, 0.6666666666666666, 0.5938426179717377, 0.6161430897242476, 0.0, 1.0, 0.2527132446794812], 
reward next is 0.7473, 
noisyNet noise sample is [array([0.01055996], dtype=float32), 0.20006524]. 
=============================================
[2019-04-06 18:25:35,112] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.0861964e-14 7.4139024e-15 2.2584792e-11 1.1409354e-13 1.0000000e+00
 2.3281724e-18 3.7015446e-15], sum to 1.0000
[2019-04-06 18:25:35,113] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5197
[2019-04-06 18:25:35,237] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 54.0, 102.5, 697.0, 26.0, 25.24292876861779, 0.3175853109060395, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3060000.0000, 
sim time next is 3061800.0000, 
raw observation next is [-4.0, 54.0, 106.0, 759.0, 26.0, 25.13153105868141, 0.3080045427752775, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3518005540166205, 0.54, 0.35333333333333333, 0.8386740331491712, 0.6666666666666666, 0.5942942548901176, 0.6026681809250926, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5680091], dtype=float32), -0.09718032]. 
=============================================
[2019-04-06 18:25:38,355] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:25:38,356] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:25:38,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run18
[2019-04-06 18:25:40,602] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:25:40,602] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:25:40,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run18
[2019-04-06 18:25:49,288] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.6150597e-20 1.5513403e-19 1.9860462e-15 3.8023648e-18 1.0000000e+00
 4.3898289e-22 2.0790440e-20], sum to 1.0000
[2019-04-06 18:25:49,288] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2744
[2019-04-06 18:25:49,323] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.0, 50.0, 0.0, 0.0, 26.0, 27.32204991381068, 0.9397251282103382, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4388400.0000, 
sim time next is 4390200.0000, 
raw observation next is [11.5, 54.0, 0.0, 0.0, 26.0, 27.25898856043647, 0.9146860115989578, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.7811634349030472, 0.54, 0.0, 0.0, 0.6666666666666666, 0.7715823800363726, 0.8048953371996527, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.30429968], dtype=float32), -0.93570864]. 
=============================================
[2019-04-06 18:25:53,862] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5501696e-19 8.9252354e-19 9.7137732e-14 7.5457682e-18 1.0000000e+00
 6.3919194e-21 7.6378575e-19], sum to 1.0000
[2019-04-06 18:25:53,863] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9604
[2019-04-06 18:25:53,959] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.1, 83.0, 0.0, 0.0, 26.0, 24.06341296119863, 0.06909757563308432, 0.0, 1.0, 43208.97476201256], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 99000.0000, 
sim time next is 100800.0000, 
raw observation next is [-3.4, 79.0, 0.0, 0.0, 26.0, 23.91595697544757, 0.04986446072843837, 0.0, 1.0, 43535.963794111995], 
processed observation next is [1.0, 0.17391304347826086, 0.368421052631579, 0.79, 0.0, 0.0, 0.6666666666666666, 0.49299641462063093, 0.5166214869094795, 0.0, 1.0, 0.2073141133052952], 
reward next is 0.7927, 
noisyNet noise sample is [array([-0.1572554], dtype=float32), 0.82002145]. 
=============================================
[2019-04-06 18:25:59,243] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4723237e-18 4.5872076e-19 2.5163662e-14 7.1121889e-17 1.0000000e+00
 2.0161857e-20 1.7995802e-18], sum to 1.0000
[2019-04-06 18:25:59,243] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5711
[2019-04-06 18:25:59,342] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 96.5, 87.0, 0.0, 26.0, 25.39289984933112, 0.3132248134223299, 1.0, 1.0, 18680.41167023054], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2892600.0000, 
sim time next is 2894400.0000, 
raw observation next is [1.0, 100.0, 131.0, 0.0, 26.0, 25.40512871382575, 0.3216095845062352, 1.0, 1.0, 18680.41167023054], 
processed observation next is [1.0, 0.5217391304347826, 0.4903047091412743, 1.0, 0.43666666666666665, 0.0, 0.6666666666666666, 0.6170940594854791, 0.6072031948354117, 1.0, 1.0, 0.0889543412868121], 
reward next is 0.9110, 
noisyNet noise sample is [array([-0.39435965], dtype=float32), -0.27727222]. 
=============================================
[2019-04-06 18:26:11,941] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.6197104e-16 3.7627728e-17 4.0388458e-13 5.8772585e-17 1.0000000e+00
 3.5309920e-20 7.7937652e-18], sum to 1.0000
[2019-04-06 18:26:11,941] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0851
[2019-04-06 18:26:12,015] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 52.0, 28.0, 28.0, 26.0, 25.83402368948806, 0.4629001211636688, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4555800.0000, 
sim time next is 4557600.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 26.0, 25.6113145336126, 0.493389105293675, 1.0, 1.0, 3113.4019450384226], 
processed observation next is [1.0, 0.782608695652174, 0.518005540166205, 0.52, 0.0, 0.0, 0.6666666666666666, 0.6342762111343833, 0.6644630350978916, 1.0, 1.0, 0.014825723547802013], 
reward next is 0.9852, 
noisyNet noise sample is [array([1.6662028], dtype=float32), 0.7143356]. 
=============================================
[2019-04-06 18:26:16,058] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 18:26:16,058] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:26:16,059] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:26:16,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run39
[2019-04-06 18:26:16,078] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:26:16,080] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:26:16,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:26:16,104] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:26:16,105] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run39
[2019-04-06 18:26:16,120] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run39
[2019-04-06 18:26:41,460] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13194284]
[2019-04-06 18:26:41,461] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-13.2, 58.5, 0.0, 0.0, 26.0, 23.18011120888162, -0.2334588077499159, 0.0, 1.0, 45220.30258088216]
[2019-04-06 18:26:41,461] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 18:26:41,461] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [3.9986807e-13 8.0701911e-14 1.3785263e-10 1.0635625e-12 1.0000000e+00
 7.1532234e-16 2.9662199e-14], sampled 0.47112917863539017
[2019-04-06 18:27:07,894] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13194284]
[2019-04-06 18:27:07,894] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-9.326355511, 81.27657812, 0.0, 0.0, 26.0, 23.22566781033228, -0.1612820805967734, 0.0, 1.0, 45216.94362853474]
[2019-04-06 18:27:07,894] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 18:27:07,895] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.7846396e-14 3.6017565e-15 1.2974303e-11 5.0149690e-14 1.0000000e+00
 1.5823980e-17 9.6703581e-16], sampled 0.543001966620985
[2019-04-06 18:28:21,006] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 18:29:01,448] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 18:29:03,615] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 18:29:04,653] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 760000, evaluation results [760000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 18:29:10,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:29:10,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:29:10,734] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run18
[2019-04-06 18:29:17,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:29:17,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:29:17,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run18
[2019-04-06 18:29:39,974] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:29:39,974] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:29:39,983] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run18
[2019-04-06 18:29:56,607] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.79545701e-16 1.29930354e-17 5.04608562e-14 2.89040623e-16
 1.00000000e+00 2.58234365e-20 2.62221197e-18], sum to 1.0000
[2019-04-06 18:29:56,607] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2787
[2019-04-06 18:29:56,695] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.24829227968733, 0.3021250354346093, 0.0, 1.0, 46187.41669063864], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3733200.0000, 
sim time next is 3735000.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.10996185246686, 0.2868299143924279, 0.0, 1.0, 41723.4329227602], 
processed observation next is [1.0, 0.21739130434782608, 0.3795013850415513, 0.65, 0.0, 0.0, 0.6666666666666666, 0.592496821038905, 0.5956099714641426, 0.0, 1.0, 0.19868301391790572], 
reward next is 0.8013, 
noisyNet noise sample is [array([-0.1845413], dtype=float32), 0.11614488]. 
=============================================
[2019-04-06 18:29:56,858] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[85.222336]
 [85.33919 ]
 [85.6225  ]
 [85.831436]
 [85.925385]], R is [[85.04520416]
 [84.97481537]
 [84.9411087 ]
 [84.91691589]
 [84.87138367]].
[2019-04-06 18:30:05,286] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:30:05,286] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:30:05,290] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run18
[2019-04-06 18:30:25,965] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.8280607e-16 9.2434301e-19 3.5873556e-13 9.7716675e-16 1.0000000e+00
 4.2387181e-20 1.1814328e-17], sum to 1.0000
[2019-04-06 18:30:25,965] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4521
[2019-04-06 18:30:26,012] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.5, 37.0, 0.0, 0.0, 26.0, 25.57456230408929, 0.4820685529077287, 0.0, 1.0, 12496.306955887901], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5009400.0000, 
sim time next is 5011200.0000, 
raw observation next is [2.0, 40.0, 0.0, 0.0, 26.0, 25.51119518938529, 0.4630208083884829, 0.0, 1.0, 38582.90069391825], 
processed observation next is [1.0, 0.0, 0.518005540166205, 0.4, 0.0, 0.0, 0.6666666666666666, 0.6259329324487742, 0.6543402694628276, 0.0, 1.0, 0.18372809854246785], 
reward next is 0.8163, 
noisyNet noise sample is [array([0.59053004], dtype=float32), 0.80108654]. 
=============================================
[2019-04-06 18:30:28,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.9987244e-18 3.6700023e-18 1.7693528e-15 3.3657943e-17 1.0000000e+00
 3.2284697e-23 2.6964216e-20], sum to 1.0000
[2019-04-06 18:30:28,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7471
[2019-04-06 18:30:29,019] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.1, 96.0, 0.0, 0.0, 26.0, 25.0815605584149, 0.5647033383834766, 0.0, 1.0, 64752.39531341789], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1281600.0000, 
sim time next is 1283400.0000, 
raw observation next is [5.8, 98.0, 0.0, 0.0, 26.0, 25.40365502951709, 0.6049126764226388, 0.0, 1.0, 35209.50484412345], 
processed observation next is [0.0, 0.8695652173913043, 0.6232686980609419, 0.98, 0.0, 0.0, 0.6666666666666666, 0.6169712524597575, 0.7016375588075463, 0.0, 1.0, 0.16766430878154023], 
reward next is 0.8323, 
noisyNet noise sample is [array([1.6088119], dtype=float32), 0.15977961]. 
=============================================
[2019-04-06 18:30:30,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:30:30,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:30:30,868] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run18
[2019-04-06 18:30:40,190] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3611425e-16 1.6337509e-16 4.9884695e-13 9.3716122e-17 1.0000000e+00
 1.0826140e-18 3.7064153e-17], sum to 1.0000
[2019-04-06 18:30:40,200] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3902
[2019-04-06 18:30:40,417] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 32.0, 80.0, 0.0, 26.0, 25.54762069955776, 0.1979925940151861, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 468000.0000, 
sim time next is 469800.0000, 
raw observation next is [-3.4, 30.0, 98.0, 0.0, 26.0, 25.47246915676806, 0.1736126650857671, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.368421052631579, 0.3, 0.32666666666666666, 0.0, 0.6666666666666666, 0.622705763064005, 0.5578708883619223, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.30835715], dtype=float32), 0.77817273]. 
=============================================
[2019-04-06 18:30:46,335] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:30:46,335] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:30:46,338] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run18
[2019-04-06 18:30:50,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:30:50,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:30:50,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run18
[2019-04-06 18:30:51,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:30:51,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:30:51,232] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run18
[2019-04-06 18:31:02,159] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:31:02,159] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:31:02,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run18
[2019-04-06 18:31:03,560] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:31:03,560] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:31:03,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run18
[2019-04-06 18:31:03,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:31:03,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:31:03,640] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run18
[2019-04-06 18:31:06,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:31:06,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:31:06,574] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run18
[2019-04-06 18:31:07,886] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:31:07,887] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:31:07,915] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run18
[2019-04-06 18:31:09,196] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:31:09,196] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:31:09,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run18
[2019-04-06 18:31:50,073] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4692131e-16 1.0209404e-17 2.5284302e-12 5.2076433e-15 1.0000000e+00
 4.4080088e-19 5.3637104e-17], sum to 1.0000
[2019-04-06 18:31:50,074] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5466
[2019-04-06 18:31:50,298] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 87.0, 110.5, 122.0, 26.0, 24.80475359900517, 0.2553015656336332, 0.0, 1.0, 50847.34767278377], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 554400.0000, 
sim time next is 556200.0000, 
raw observation next is [-0.6, 85.0, 77.0, 141.0, 26.0, 24.82079665983977, 0.2764827355065332, 0.0, 1.0, 47058.545585883345], 
processed observation next is [0.0, 0.43478260869565216, 0.44598337950138506, 0.85, 0.25666666666666665, 0.1558011049723757, 0.6666666666666666, 0.568399721653314, 0.592160911835511, 0.0, 1.0, 0.22408831231373022], 
reward next is 0.7759, 
noisyNet noise sample is [array([-0.48342416], dtype=float32), -0.118688926]. 
=============================================
[2019-04-06 18:31:54,530] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-06 18:31:54,533] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:31:54,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:31:54,535] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run40
[2019-04-06 18:31:54,579] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:31:54,580] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:31:54,582] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run40
[2019-04-06 18:31:54,610] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:31:54,610] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:31:54,613] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run40
[2019-04-06 18:33:20,414] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13215706]
[2019-04-06 18:33:20,415] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [5.807034878, 14.41971023, 0.0, 0.0, 26.0, 25.55640942631806, 0.372713762262294, 1.0, 1.0, 0.0]
[2019-04-06 18:33:20,415] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 18:33:20,416] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [3.4210454e-15 8.2353519e-16 3.6524156e-12 1.1872265e-14 1.0000000e+00
 3.5594363e-18 3.1009651e-16], sampled 0.07851130823348007
[2019-04-06 18:34:01,369] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 18:34:39,945] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 18:34:42,661] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 18:34:43,699] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 780000, evaluation results [780000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 18:35:15,444] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.86254447e-16 1.25902076e-17 4.86957642e-13 3.80461958e-15
 1.00000000e+00 1.39282227e-17 2.26238712e-17], sum to 1.0000
[2019-04-06 18:35:15,444] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1230
[2019-04-06 18:35:15,748] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.3, 68.0, 125.0, 0.0, 26.0, 26.01929547125336, 0.489035249375664, 1.0, 1.0, 61828.33734574416], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2125800.0000, 
sim time next is 2127600.0000, 
raw observation next is [-5.0, 68.0, 105.5, 0.0, 26.0, 26.29080768315135, 0.5086173506240171, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.32409972299168976, 0.68, 0.3516666666666667, 0.0, 0.6666666666666666, 0.6909006402626124, 0.6695391168746724, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.03121538], dtype=float32), 1.0718827]. 
=============================================
[2019-04-06 18:35:18,314] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6791755e-15 7.0460548e-17 1.9957742e-12 4.0775124e-15 1.0000000e+00
 4.4677489e-20 1.8066659e-17], sum to 1.0000
[2019-04-06 18:35:18,314] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3641
[2019-04-06 18:35:18,658] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 59.0, 147.0, 96.5, 26.0, 24.89957619796551, 0.2384969290424512, 0.0, 1.0, 39441.830635911756], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 651600.0000, 
sim time next is 653400.0000, 
raw observation next is [-1.75, 59.5, 182.0, 93.0, 26.0, 24.91700825499426, 0.246111184464696, 0.0, 1.0, 29000.118837127025], 
processed observation next is [0.0, 0.5652173913043478, 0.4141274238227147, 0.595, 0.6066666666666667, 0.10276243093922652, 0.6666666666666666, 0.5764173545828551, 0.582037061488232, 0.0, 1.0, 0.13809580398631918], 
reward next is 0.8619, 
noisyNet noise sample is [array([0.45449612], dtype=float32), -0.7962973]. 
=============================================
[2019-04-06 18:36:22,551] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1567445e-16 1.4356498e-16 1.0521185e-12 1.4277150e-15 1.0000000e+00
 2.0687367e-19 7.0614999e-17], sum to 1.0000
[2019-04-06 18:36:22,551] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1140
[2019-04-06 18:36:22,604] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.3, 82.0, 0.0, 0.0, 26.0, 24.17706666968999, 0.05933058208053874, 0.0, 1.0, 44982.29574986626], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1900800.0000, 
sim time next is 1902600.0000, 
raw observation next is [-7.3, 78.5, 0.0, 0.0, 26.0, 24.13179953816098, 0.05252207346607241, 0.0, 1.0, 45072.54917395368], 
processed observation next is [1.0, 0.0, 0.26038781163434904, 0.785, 0.0, 0.0, 0.6666666666666666, 0.5109832948467483, 0.5175073578220242, 0.0, 1.0, 0.21463118654263658], 
reward next is 0.7854, 
noisyNet noise sample is [array([-2.328833], dtype=float32), 0.16022079]. 
=============================================
[2019-04-06 18:36:52,287] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.7458177e-14 4.0529616e-16 2.4819578e-12 1.7668370e-15 1.0000000e+00
 8.4931276e-19 1.3251437e-15], sum to 1.0000
[2019-04-06 18:36:52,287] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9010
[2019-04-06 18:36:52,465] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 69.0, 37.0, 0.0, 26.0, 24.32653716107244, 0.2248567102113566, 0.0, 1.0, 149018.30715154903], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2363400.0000, 
sim time next is 2365200.0000, 
raw observation next is [-3.4, 69.0, 79.0, 180.0, 26.0, 25.33227008004238, 0.3230099088845539, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.368421052631579, 0.69, 0.2633333333333333, 0.19889502762430938, 0.6666666666666666, 0.6110225066701984, 0.6076699696281846, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5013989], dtype=float32), -0.5275368]. 
=============================================
[2019-04-06 18:37:10,908] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [2.37615188e-15 1.10429214e-16 5.62990063e-12 1.82939499e-14
 1.00000000e+00 2.75437134e-19 3.44199911e-17], sum to 1.0000
[2019-04-06 18:37:10,908] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2045
[2019-04-06 18:37:10,939] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 54.0, 116.0, 805.5, 26.0, 25.94004022833148, 0.5579133828906297, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3330000.0000, 
sim time next is 3331800.0000, 
raw observation next is [-4.5, 52.0, 114.0, 800.0, 26.0, 26.00723091264307, 0.5800741409950951, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3379501385041552, 0.52, 0.38, 0.8839779005524862, 0.6666666666666666, 0.6672692427202559, 0.6933580469983651, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4994531], dtype=float32), -0.580569]. 
=============================================
[2019-04-06 18:37:30,627] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 18:37:30,628] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:37:30,628] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:37:30,630] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run41
[2019-04-06 18:37:30,650] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:37:30,650] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:37:30,653] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run41
[2019-04-06 18:37:30,685] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:37:30,685] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:37:30,688] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run41
[2019-04-06 18:39:37,784] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 18:40:14,314] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2417.0861 87791866.1671 515.2451
[2019-04-06 18:40:17,480] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 18:40:18,518] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 800000, evaluation results [800000.0, 2417.086098461385, 87791866.16713928, 515.2451498045025, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 18:40:19,953] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:40:19,953] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:40:19,970] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run19
[2019-04-06 18:40:23,362] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:40:23,362] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:40:23,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run19
[2019-04-06 18:40:58,810] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.95536406e-17 7.97801142e-18 5.77557479e-14 3.05813411e-16
 1.00000000e+00 1.04575194e-20 6.35141162e-18], sum to 1.0000
[2019-04-06 18:40:58,810] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5056
[2019-04-06 18:40:58,894] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 26.0, 25.3860730028754, 0.4808073182012942, 0.0, 1.0, 56045.52961964544], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3277800.0000, 
sim time next is 3279600.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 26.0, 25.31567294143807, 0.4710915337042705, 0.0, 1.0, 52653.9518054283], 
processed observation next is [1.0, 1.0, 0.296398891966759, 0.92, 0.0, 0.0, 0.6666666666666666, 0.6096394117865058, 0.6570305112347569, 0.0, 1.0, 0.2507331038353729], 
reward next is 0.7493, 
noisyNet noise sample is [array([-2.1012902], dtype=float32), -0.10483609]. 
=============================================
[2019-04-06 18:41:04,776] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [4.1628337e-17 6.7178514e-18 6.2768681e-13 5.1266467e-17 1.0000000e+00
 6.3282572e-21 4.6878330e-17], sum to 1.0000
[2019-04-06 18:41:04,776] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6668
[2019-04-06 18:41:04,844] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.9, 70.0, 0.0, 0.0, 26.0, 25.46671179365979, 0.3951787694962587, 0.0, 1.0, 34011.00761412237], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4334400.0000, 
sim time next is 4336200.0000, 
raw observation next is [3.75, 69.5, 0.0, 0.0, 26.0, 25.58668826468577, 0.379508918621603, 0.0, 1.0, 6245.654183079223], 
processed observation next is [1.0, 0.17391304347826086, 0.5664819944598338, 0.695, 0.0, 0.0, 0.6666666666666666, 0.6322240220571475, 0.6265029728738677, 0.0, 1.0, 0.029741210395615347], 
reward next is 0.9703, 
noisyNet noise sample is [array([-1.2294947], dtype=float32), 0.83352524]. 
=============================================
[2019-04-06 18:41:13,954] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.3858364e-18 2.9864008e-18 1.3129431e-13 8.6602184e-17 1.0000000e+00
 2.6062931e-20 2.1476622e-18], sum to 1.0000
[2019-04-06 18:41:13,954] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4068
[2019-04-06 18:41:14,202] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 60.0, 93.0, 540.0, 26.0, 26.14295009466814, 0.5053138448538617, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3402000.0000, 
sim time next is 3403800.0000, 
raw observation next is [0.5, 54.0, 99.0, 658.0, 26.0, 26.34266404834072, 0.5624543147010855, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4764542936288089, 0.54, 0.33, 0.7270718232044199, 0.6666666666666666, 0.6952220040283933, 0.6874847715670285, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7661301], dtype=float32), -0.19114126]. 
=============================================
[2019-04-06 18:41:16,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:41:16,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:41:16,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run19
[2019-04-06 18:41:22,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:41:22,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:41:23,006] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run19
[2019-04-06 18:41:23,954] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5417448e-15 2.9278371e-16 6.9557099e-13 8.4611629e-15 1.0000000e+00
 9.8015138e-20 3.8380283e-16], sum to 1.0000
[2019-04-06 18:41:23,954] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2563
[2019-04-06 18:41:24,370] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-11.0, 76.0, 0.0, 0.0, 26.0, 23.85952085122058, 0.08832376882528759, 0.0, 1.0, 44001.19678493165], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3308400.0000, 
sim time next is 3310200.0000, 
raw observation next is [-11.0, 80.0, 2.0, 94.0, 26.0, 24.15937709640109, 0.2605454637838147, 1.0, 1.0, 149849.83398420666], 
processed observation next is [1.0, 0.30434782608695654, 0.15789473684210528, 0.8, 0.006666666666666667, 0.10386740331491713, 0.6666666666666666, 0.5132814247000909, 0.5868484879279382, 1.0, 1.0, 0.7135706380200317], 
reward next is 0.2864, 
noisyNet noise sample is [array([1.2445914], dtype=float32), 1.9689943]. 
=============================================
[2019-04-06 18:41:28,473] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.0857181e-15 2.5708294e-16 7.6923442e-12 1.1324496e-13 1.0000000e+00
 3.5438961e-18 9.9868050e-17], sum to 1.0000
[2019-04-06 18:41:28,474] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8997
[2019-04-06 18:41:28,553] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 48.0, 0.0, 0.0, 26.0, 25.42735921939956, 0.3628700873971062, 0.0, 1.0, 31405.44118721907], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4233600.0000, 
sim time next is 4235400.0000, 
raw observation next is [2.0, 48.0, 0.0, 0.0, 26.0, 25.42063275486584, 0.3583495015486013, 0.0, 1.0, 38344.89718758538], 
processed observation next is [0.0, 0.0, 0.518005540166205, 0.48, 0.0, 0.0, 0.6666666666666666, 0.6183860629054866, 0.6194498338495338, 0.0, 1.0, 0.18259474851231133], 
reward next is 0.8174, 
noisyNet noise sample is [array([1.6273049], dtype=float32), -0.66166425]. 
=============================================
[2019-04-06 18:41:32,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:41:32,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:41:32,132] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run19
[2019-04-06 18:41:41,800] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.9264953e-17 4.1281995e-18 1.6901648e-15 2.6360021e-18 1.0000000e+00
 4.2376628e-22 2.9923734e-20], sum to 1.0000
[2019-04-06 18:41:41,801] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1340
[2019-04-06 18:41:42,058] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.8, 73.0, 55.5, 33.0, 26.0, 25.48394701310502, 0.4158301953106818, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4521600.0000, 
sim time next is 4523400.0000, 
raw observation next is [-0.4, 72.5, 111.0, 66.0, 26.0, 25.64515558570582, 0.4764161249092442, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.45152354570637127, 0.725, 0.37, 0.07292817679558011, 0.6666666666666666, 0.6370962988088182, 0.6588053749697481, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.85451233], dtype=float32), -0.41052863]. 
=============================================
[2019-04-06 18:41:45,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:41:45,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:41:45,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run19
[2019-04-06 18:41:46,341] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.0651753e-17 8.2272692e-19 5.6382768e-14 1.3433794e-16 1.0000000e+00
 1.9475384e-20 8.4141565e-18], sum to 1.0000
[2019-04-06 18:41:46,342] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2398
[2019-04-06 18:41:46,400] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 60.0, 0.0, 0.0, 26.0, 25.46304355994044, 0.5658045635557445, 0.0, 1.0, 90084.15763454213], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3877200.0000, 
sim time next is 3879000.0000, 
raw observation next is [-1.0, 57.5, 0.0, 0.0, 26.0, 25.72827498474857, 0.5697539993599916, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.575, 0.0, 0.0, 0.6666666666666666, 0.6440229153957141, 0.6899179997866639, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.95509154], dtype=float32), 0.103156105]. 
=============================================
[2019-04-06 18:41:46,412] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[86.956604]
 [85.80128 ]
 [84.11676 ]
 [84.96251 ]
 [86.276825]], R is [[86.87480927]
 [86.57709503]
 [85.97893524]
 [86.02715302]
 [86.10758209]].
[2019-04-06 18:41:58,016] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [2.6401397e-17 9.1438348e-18 2.0009903e-14 1.4478263e-16 1.0000000e+00
 1.4149475e-21 1.4241981e-19], sum to 1.0000
[2019-04-06 18:41:58,016] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.1662
[2019-04-06 18:41:58,149] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.45, 86.0, 79.0, 0.0, 26.0, 24.45491296545203, 0.1635910425434488, 0.0, 1.0, 26564.4821136309], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 52200.0000, 
sim time next is 54000.0000, 
raw observation next is [7.2, 86.0, 64.5, 0.0, 26.0, 24.46810928881984, 0.1594900478409137, 0.0, 1.0, 29980.655421888034], 
processed observation next is [0.0, 0.6521739130434783, 0.662049861495845, 0.86, 0.215, 0.0, 0.6666666666666666, 0.5390091074016533, 0.5531633492803046, 0.0, 1.0, 0.14276502581851444], 
reward next is 0.8572, 
noisyNet noise sample is [array([2.1952791], dtype=float32), 0.6216228]. 
=============================================
[2019-04-06 18:41:58,153] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[84.59929 ]
 [84.78986 ]
 [84.898026]
 [84.90315 ]
 [85.06235 ]], R is [[84.35766602]
 [84.38759613]
 [84.37788391]
 [84.35572052]
 [84.40337372]].
[2019-04-06 18:42:07,728] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.2487989e-17 8.2877211e-18 6.4584378e-14 1.6108527e-17 1.0000000e+00
 4.5803985e-22 5.1197207e-20], sum to 1.0000
[2019-04-06 18:42:07,728] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4432
[2019-04-06 18:42:07,794] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 92.0, 0.0, 0.0, 26.0, 25.42248274478519, 0.4734204037010393, 0.0, 1.0, 74521.30336818144], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4680000.0000, 
sim time next is 4681800.0000, 
raw observation next is [-0.5, 96.0, 0.0, 0.0, 26.0, 25.60687986015116, 0.4594757457435543, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.44875346260387816, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6339066550125967, 0.6531585819145181, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5897217], dtype=float32), -0.28611475]. 
=============================================
[2019-04-06 18:42:09,737] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0886202e-15 5.4108799e-15 1.4504853e-12 7.4539402e-16 1.0000000e+00
 5.4180568e-19 5.9606873e-17], sum to 1.0000
[2019-04-06 18:42:09,737] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0556
[2019-04-06 18:42:09,773] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.5, 69.0, 0.0, 0.0, 26.0, 25.41670783861156, 0.4051097571660228, 0.0, 1.0, 30150.87136224449], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4593600.0000, 
sim time next is 4595400.0000, 
raw observation next is [-1.75, 70.0, 0.0, 0.0, 26.0, 25.26984539532487, 0.4009126129168717, 0.0, 1.0, 52915.0737569597], 
processed observation next is [1.0, 0.17391304347826086, 0.4141274238227147, 0.7, 0.0, 0.0, 0.6666666666666666, 0.6058204496104059, 0.6336375376389572, 0.0, 1.0, 0.2519765416998081], 
reward next is 0.7480, 
noisyNet noise sample is [array([1.0639275], dtype=float32), -0.21371146]. 
=============================================
[2019-04-06 18:42:11,101] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:42:11,101] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:42:11,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run19
[2019-04-06 18:42:16,137] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.0195524e-14 1.3553484e-14 2.0790892e-11 1.4819224e-13 1.0000000e+00
 3.3796122e-17 3.7932867e-15], sum to 1.0000
[2019-04-06 18:42:16,150] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9482
[2019-04-06 18:42:16,187] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.6, 75.0, 0.0, 0.0, 26.0, 24.38793751347774, 0.3296307196160886, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1204200.0000, 
sim time next is 1206000.0000, 
raw observation next is [16.6, 75.0, 0.0, 0.0, 26.0, 24.33014817528441, 0.3182985085741415, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 1.0, 0.922437673130194, 0.75, 0.0, 0.0, 0.6666666666666666, 0.5275123479403675, 0.6060995028580471, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.026063], dtype=float32), 0.38807112]. 
=============================================
[2019-04-06 18:42:16,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.478516]
 [69.45663 ]
 [69.43002 ]
 [69.42374 ]
 [69.530716]], R is [[69.77066803]
 [70.0729599 ]
 [70.37223053]
 [70.66851044]
 [70.96182251]].
[2019-04-06 18:42:24,716] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.0260975e-17 3.6694141e-18 8.7446140e-15 1.6346353e-17 1.0000000e+00
 6.2654472e-20 5.9883265e-19], sum to 1.0000
[2019-04-06 18:42:24,722] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0279
[2019-04-06 18:42:24,762] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 26.0, 24.55568516333071, 0.1999666862281546, 0.0, 1.0, 40402.08158719632], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 79200.0000, 
sim time next is 81000.0000, 
raw observation next is [0.4, 95.5, 0.0, 0.0, 26.0, 24.48951420102817, 0.1875265648274645, 0.0, 1.0, 40210.46767663549], 
processed observation next is [0.0, 0.9565217391304348, 0.4736842105263158, 0.955, 0.0, 0.0, 0.6666666666666666, 0.540792850085681, 0.5625088549424881, 0.0, 1.0, 0.19147841750778805], 
reward next is 0.8085, 
noisyNet noise sample is [array([-0.558548], dtype=float32), 0.43462712]. 
=============================================
[2019-04-06 18:42:24,766] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[84.527084]
 [84.78546 ]
 [85.18687 ]
 [85.61345 ]
 [85.76965 ]], R is [[84.35211945]
 [84.31620789]
 [84.2797699 ]
 [84.24307251]
 [84.20367432]].
[2019-04-06 18:42:28,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:42:28,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:42:28,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run19
[2019-04-06 18:42:32,978] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0537027e-17 9.5576849e-18 5.2490280e-15 7.9510970e-17 1.0000000e+00
 2.4903574e-22 5.4405252e-20], sum to 1.0000
[2019-04-06 18:42:32,979] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2321
[2019-04-06 18:42:33,032] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.8, 75.5, 0.0, 0.0, 26.0, 25.11113941235421, 0.3445540795331076, 0.0, 1.0, 36203.34751386731], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4602600.0000, 
sim time next is 4604400.0000, 
raw observation next is [-3.0, 77.0, 0.0, 0.0, 26.0, 25.03599866719812, 0.3323284728143391, 0.0, 1.0, 36243.49912783006], 
processed observation next is [1.0, 0.30434782608695654, 0.3795013850415513, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5863332222665099, 0.6107761576047798, 0.0, 1.0, 0.17258809108490505], 
reward next is 0.8274, 
noisyNet noise sample is [array([-0.40921947], dtype=float32), 2.3877778]. 
=============================================
[2019-04-06 18:42:34,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:42:34,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:42:34,904] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run19
[2019-04-06 18:42:37,838] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:42:37,838] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:42:37,845] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8281675e-22 6.8916205e-21 2.2532855e-15 8.0847765e-19 1.0000000e+00
 4.6849380e-24 5.1077767e-22], sum to 1.0000
[2019-04-06 18:42:37,853] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7181
[2019-04-06 18:42:37,864] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run19
[2019-04-06 18:42:37,931] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.6, 97.0, 0.0, 0.0, 26.0, 25.54808049643276, 0.5774298990447116, 0.0, 1.0, 84805.80955677103], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1654200.0000, 
sim time next is 1656000.0000, 
raw observation next is [6.6, 97.0, 0.0, 0.0, 26.0, 25.64814487667868, 0.568496180964187, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.6454293628808865, 0.97, 0.0, 0.0, 0.6666666666666666, 0.6373454063898899, 0.6894987269880622, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.08669619], dtype=float32), 0.3626922]. 
=============================================
[2019-04-06 18:42:37,959] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[97.30719 ]
 [96.26269 ]
 [95.7098  ]
 [95.49809 ]
 [95.385254]], R is [[97.24794006]
 [96.87162018]
 [96.73373413]
 [96.71154022]
 [96.74442291]].
[2019-04-06 18:42:47,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:42:47,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:42:47,776] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run19
[2019-04-06 18:42:51,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:42:51,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:42:51,123] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run19
[2019-04-06 18:42:52,046] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-06 18:42:52,061] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:42:52,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:42:52,063] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run42
[2019-04-06 18:42:52,084] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:42:52,084] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:42:52,087] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run42
[2019-04-06 18:42:52,105] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:42:52,105] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:42:52,107] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run42
[2019-04-06 18:44:46,162] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13335904]
[2019-04-06 18:44:46,163] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [9.4, 42.0, 0.0, 0.0, 26.0, 25.91801268624598, 0.6408096892847249, 0.0, 1.0, 0.0]
[2019-04-06 18:44:46,163] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 18:44:46,163] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.3628595e-16 2.0027053e-17 1.7781916e-13 3.3545035e-16 1.0000000e+00
 5.4444492e-20 4.8621854e-18], sampled 0.23661646371008138
[2019-04-06 18:44:59,969] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 18:45:39,727] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 18:45:41,719] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 18:45:42,758] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 820000, evaluation results [820000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 18:45:46,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:45:46,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:45:46,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run19
[2019-04-06 18:45:51,058] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:45:51,058] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:45:51,076] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run19
[2019-04-06 18:45:53,464] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:45:53,464] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:45:53,468] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run19
[2019-04-06 18:45:54,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:45:54,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:45:54,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run19
[2019-04-06 18:46:45,978] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2896166e-15 1.3366116e-16 1.0625858e-11 2.4351003e-15 1.0000000e+00
 3.3639570e-18 1.8990488e-16], sum to 1.0000
[2019-04-06 18:46:45,978] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8461
[2019-04-06 18:46:46,265] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.8, 63.5, 0.0, 0.0, 26.0, 25.42346973840102, 0.2177325074956026, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 495000.0000, 
sim time next is 496800.0000, 
raw observation next is [0.5, 84.0, 0.0, 0.0, 26.0, 24.78713387943422, 0.1522260441150962, 1.0, 1.0, 75266.2473619037], 
processed observation next is [1.0, 0.782608695652174, 0.4764542936288089, 0.84, 0.0, 0.0, 0.6666666666666666, 0.5655944899528516, 0.550742014705032, 1.0, 1.0, 0.358410701723351], 
reward next is 0.6416, 
noisyNet noise sample is [array([0.6672698], dtype=float32), -1.1258681]. 
=============================================
[2019-04-06 18:46:59,209] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1245573e-16 7.0252542e-17 1.4016631e-12 2.0535983e-14 1.0000000e+00
 1.0304124e-18 3.3380093e-17], sum to 1.0000
[2019-04-06 18:46:59,209] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4216
[2019-04-06 18:46:59,550] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 54.0, 55.0, 26.5, 26.0, 24.87719647224227, 0.2227260340197465, 0.0, 1.0, 44767.058319824915], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 662400.0000, 
sim time next is 664200.0000, 
raw observation next is [-0.8999999999999999, 55.5, 27.0, 15.0, 26.0, 24.88801265194335, 0.2118475376732372, 0.0, 1.0, 38897.08549205649], 
processed observation next is [0.0, 0.6956521739130435, 0.43767313019390586, 0.555, 0.09, 0.016574585635359115, 0.6666666666666666, 0.5740010543286124, 0.570615845891079, 0.0, 1.0, 0.18522421662884042], 
reward next is 0.8148, 
noisyNet noise sample is [array([0.4494825], dtype=float32), -0.5057785]. 
=============================================
[2019-04-06 18:47:15,053] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.5062057e-16 4.8420105e-18 7.8315569e-14 3.5485923e-17 1.0000000e+00
 1.2830875e-19 2.7154172e-18], sum to 1.0000
[2019-04-06 18:47:15,053] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3461
[2019-04-06 18:47:15,109] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 82.0, 0.0, 0.0, 26.0, 23.36195827630972, -0.1522925475339754, 0.0, 1.0, 44927.50755302754], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1922400.0000, 
sim time next is 1924200.0000, 
raw observation next is [-9.2, 86.5, 0.0, 0.0, 26.0, 23.19585543197481, -0.1795809945697271, 0.0, 1.0, 44696.019598169165], 
processed observation next is [1.0, 0.2608695652173913, 0.20775623268698065, 0.865, 0.0, 0.0, 0.6666666666666666, 0.43298795266456747, 0.4401396684767576, 0.0, 1.0, 0.2128381885627103], 
reward next is 0.7872, 
noisyNet noise sample is [array([1.6806779], dtype=float32), -0.26236722]. 
=============================================
[2019-04-06 18:47:19,005] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.91360026e-22 1.43901265e-21 6.13113999e-16 5.85194417e-21
 1.00000000e+00 4.35376432e-26 1.02149106e-22], sum to 1.0000
[2019-04-06 18:47:19,005] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2119
[2019-04-06 18:47:19,070] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.2, 86.0, 124.0, 0.0, 26.0, 26.69533414783693, 0.6988809646153671, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 993600.0000, 
sim time next is 995400.0000, 
raw observation next is [12.45, 86.0, 128.0, 0.0, 26.0, 25.73355392420446, 0.553330080370764, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.8074792243767314, 0.86, 0.4266666666666667, 0.0, 0.6666666666666666, 0.6444628270170384, 0.6844433601235881, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1356876], dtype=float32), -0.29887936]. 
=============================================
[2019-04-06 18:47:42,128] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6097342e-15 1.6211862e-15 1.3187621e-11 8.3341799e-15 1.0000000e+00
 2.5288480e-17 1.5890777e-15], sum to 1.0000
[2019-04-06 18:47:42,129] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8675
[2019-04-06 18:47:42,252] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.9, 45.5, 0.0, 0.0, 26.0, 24.55131920301381, 0.1345237281887559, 0.0, 1.0, 43145.67236550039], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2421000.0000, 
sim time next is 2422800.0000, 
raw observation next is [-6.2, 48.0, 0.0, 0.0, 26.0, 24.40112030633113, 0.1008887098368895, 0.0, 1.0, 43255.068804474984], 
processed observation next is [0.0, 0.043478260869565216, 0.2908587257617729, 0.48, 0.0, 0.0, 0.6666666666666666, 0.5334266921942609, 0.5336295699456298, 0.0, 1.0, 0.20597651811654755], 
reward next is 0.7940, 
noisyNet noise sample is [array([0.8445244], dtype=float32), 1.1463572]. 
=============================================
[2019-04-06 18:48:00,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.25689166e-16 7.99187084e-18 7.02569377e-14 5.66717386e-17
 1.00000000e+00 1.12117934e-20 9.25133686e-18], sum to 1.0000
[2019-04-06 18:48:00,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2578
[2019-04-06 18:48:00,420] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.82734232866132, 0.2768626552325354, 0.0, 1.0, 41117.31062182662], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3382200.0000, 
sim time next is 3384000.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.8641904871592, 0.2653378785480913, 0.0, 1.0, 41279.72107097644], 
processed observation next is [1.0, 0.17391304347826086, 0.296398891966759, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5720158739299332, 0.5884459595160304, 0.0, 1.0, 0.19657010033798306], 
reward next is 0.8034, 
noisyNet noise sample is [array([1.2623397], dtype=float32), 0.64004976]. 
=============================================
[2019-04-06 18:48:00,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[81.63408 ]
 [81.733536]
 [81.53537 ]
 [81.54085 ]
 [81.4664  ]], R is [[81.52495575]
 [81.51391602]
 [81.5030365 ]
 [81.49199677]
 [81.48097229]].
[2019-04-06 18:48:00,616] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.3944937e-19 1.1279240e-18 1.0270239e-14 2.2938095e-18 1.0000000e+00
 2.2524094e-22 2.2632566e-19], sum to 1.0000
[2019-04-06 18:48:00,616] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9141
[2019-04-06 18:48:00,659] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.7, 84.0, 0.0, 0.0, 26.0, 25.40774916638167, 0.524443494338105, 0.0, 1.0, 72027.91439338618], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1573200.0000, 
sim time next is 1575000.0000, 
raw observation next is [4.85, 83.0, 0.0, 0.0, 26.0, 25.63600451841815, 0.5183087233356558, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.5969529085872576, 0.83, 0.0, 0.0, 0.6666666666666666, 0.6363337098681793, 0.6727695744452186, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.0203385], dtype=float32), -0.018793564]. 
=============================================
[2019-04-06 18:48:00,682] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[91.411514]
 [90.9254  ]
 [91.11488 ]
 [90.89976 ]
 [90.80577 ]], R is [[91.2020874 ]
 [90.94708252]
 [90.95821381]
 [90.84111023]
 [90.779953  ]].
[2019-04-06 18:48:22,620] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.4924146e-18 1.0595467e-17 1.3939407e-14 6.6538611e-18 1.0000000e+00
 2.0098265e-21 1.5437315e-18], sum to 1.0000
[2019-04-06 18:48:22,620] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3593
[2019-04-06 18:48:22,676] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.6, 97.0, 0.0, 0.0, 26.0, 25.64814487667868, 0.568496180964187, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1656000.0000, 
sim time next is 1657800.0000, 
raw observation next is [6.6, 97.0, 0.0, 0.0, 26.0, 25.70209260834917, 0.5582983242348646, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.6454293628808865, 0.97, 0.0, 0.0, 0.6666666666666666, 0.641841050695764, 0.6860994414116215, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.28895897], dtype=float32), -2.3655083]. 
=============================================
[2019-04-06 18:48:36,000] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.9277029e-17 1.3418620e-18 5.3183349e-14 2.2643211e-17 1.0000000e+00
 3.4852614e-22 1.1599211e-18], sum to 1.0000
[2019-04-06 18:48:36,000] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2595
[2019-04-06 18:48:36,095] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 86.0, 0.0, 0.0, 26.0, 24.49357222215501, 0.177284632561743, 0.0, 1.0, 43005.563230575724], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2084400.0000, 
sim time next is 2086200.0000, 
raw observation next is [-5.3, 88.5, 0.0, 0.0, 26.0, 24.45774198467779, 0.1579082727744123, 0.0, 1.0, 43298.7666734411], 
processed observation next is [1.0, 0.13043478260869565, 0.31578947368421056, 0.885, 0.0, 0.0, 0.6666666666666666, 0.5381451653898157, 0.5526360909248041, 0.0, 1.0, 0.20618460320686238], 
reward next is 0.7938, 
noisyNet noise sample is [array([-0.06708471], dtype=float32), -0.6048531]. 
=============================================
[2019-04-06 18:48:41,159] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.0730108e-15 2.9092018e-15 1.4947066e-11 2.2750085e-14 1.0000000e+00
 1.0046101e-17 1.1010532e-16], sum to 1.0000
[2019-04-06 18:48:41,159] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0608
[2019-04-06 18:48:41,225] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.55, 63.5, 0.0, 0.0, 26.0, 24.52189992175888, 0.1861356203630252, 0.0, 1.0, 39754.46078599709], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2345400.0000, 
sim time next is 2347200.0000, 
raw observation next is [-2.8, 65.0, 0.0, 0.0, 26.0, 24.42526171353844, 0.1717942166658694, 0.0, 1.0, 40097.288658369995], 
processed observation next is [0.0, 0.17391304347826086, 0.38504155124653744, 0.65, 0.0, 0.0, 0.6666666666666666, 0.5354384761282033, 0.5572647388886232, 0.0, 1.0, 0.19093946980176188], 
reward next is 0.8091, 
noisyNet noise sample is [array([-0.8970827], dtype=float32), -1.1183106]. 
=============================================
[2019-04-06 18:48:42,830] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-06 18:48:42,841] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:48:42,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:48:42,843] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run43
[2019-04-06 18:48:42,862] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:48:42,863] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:48:42,866] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run43
[2019-04-06 18:48:42,893] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:48:42,896] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:48:42,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run43
[2019-04-06 18:50:48,956] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 18:51:26,317] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2417.1457 87799918.2793 515.5929
[2019-04-06 18:51:29,751] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 18:51:30,789] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 840000, evaluation results [840000.0, 2417.145689747748, 87799918.2792703, 515.5929457382857, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 18:52:32,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:52:32,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:52:32,520] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run20
[2019-04-06 18:52:35,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:52:35,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:52:35,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run20
[2019-04-06 18:52:51,346] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7311363e-16 1.7531057e-17 1.6795208e-12 9.4738073e-16 1.0000000e+00
 8.7291937e-20 1.4220064e-17], sum to 1.0000
[2019-04-06 18:52:51,349] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5132
[2019-04-06 18:52:51,505] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.8, 67.5, 45.0, 0.0, 26.0, 25.36420517265353, 0.2572962681754978, 1.0, 1.0, 6246.100014065297], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 120600.0000, 
sim time next is 122400.0000, 
raw observation next is [-7.8, 74.0, 117.5, 18.0, 26.0, 25.32410477562814, 0.260489366692883, 1.0, 1.0, 36759.64596716578], 
processed observation next is [1.0, 0.43478260869565216, 0.24653739612188366, 0.74, 0.39166666666666666, 0.019889502762430938, 0.6666666666666666, 0.6103420646356783, 0.5868297888976276, 1.0, 1.0, 0.1750459331769799], 
reward next is 0.8250, 
noisyNet noise sample is [array([1.2052919], dtype=float32), -0.5998245]. 
=============================================
[2019-04-06 18:52:59,758] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.4435581e-15 3.4962444e-16 1.0370488e-11 1.5774583e-14 1.0000000e+00
 9.1670554e-19 4.9356676e-17], sum to 1.0000
[2019-04-06 18:52:59,758] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1283
[2019-04-06 18:52:59,817] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 43.0, 0.0, 0.0, 26.0, 25.66172441848761, 0.3600182603476704, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4928400.0000, 
sim time next is 4930200.0000, 
raw observation next is [-0.5, 46.5, 0.0, 0.0, 26.0, 25.42834077757421, 0.3137879389284037, 0.0, 1.0, 35158.65144380543], 
processed observation next is [1.0, 0.043478260869565216, 0.44875346260387816, 0.465, 0.0, 0.0, 0.6666666666666666, 0.6190283981311842, 0.6045959796428012, 0.0, 1.0, 0.1674221497324068], 
reward next is 0.8326, 
noisyNet noise sample is [array([-1.2770998], dtype=float32), -0.25549647]. 
=============================================
[2019-04-06 18:53:07,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:53:07,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:53:07,896] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run20
[2019-04-06 18:53:07,938] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [2.4894303e-19 2.1898372e-18 5.5712364e-15 6.8545877e-17 1.0000000e+00
 4.8746929e-22 1.3966517e-19], sum to 1.0000
[2019-04-06 18:53:07,939] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2251
[2019-04-06 18:53:08,179] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.5, 96.0, 0.0, 0.0, 26.0, 25.69141524025198, 0.4747338425534697, 1.0, 1.0, 17889.604464126984], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4692600.0000, 
sim time next is 4694400.0000, 
raw observation next is [0.0, 92.0, 31.5, 0.0, 26.0, 25.78180899085527, 0.4675683332460697, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.46260387811634357, 0.92, 0.105, 0.0, 0.6666666666666666, 0.6484840825712727, 0.6558561110820232, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.45570436], dtype=float32), 0.06556236]. 
=============================================
[2019-04-06 18:53:08,664] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:53:08,664] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:53:08,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run20
[2019-04-06 18:53:15,725] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:53:15,725] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:53:15,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run20
[2019-04-06 18:53:24,652] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2669846e-17 1.5636507e-19 3.1950371e-14 3.1154747e-18 1.0000000e+00
 6.5314791e-21 2.1222757e-19], sum to 1.0000
[2019-04-06 18:53:24,653] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9460
[2019-04-06 18:53:24,729] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 92.0, 101.0, 653.0, 26.0, 26.17344068649289, 0.6515067193470717, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3231000.0000, 
sim time next is 3232800.0000, 
raw observation next is [-3.0, 92.0, 105.0, 702.5, 26.0, 26.32269299774201, 0.6766164564843377, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.92, 0.35, 0.7762430939226519, 0.6666666666666666, 0.6935577498118342, 0.7255388188281126, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.06149336], dtype=float32), -0.6895373]. 
=============================================
[2019-04-06 18:53:30,086] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:53:30,086] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:53:30,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run20
[2019-04-06 18:53:36,830] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.3000654e-18 7.9847397e-18 1.2746104e-13 1.2644602e-16 1.0000000e+00
 7.5155070e-21 1.0188623e-18], sum to 1.0000
[2019-04-06 18:53:36,830] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3197
[2019-04-06 18:53:36,964] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.88689296361131, 0.2995143824513624, 0.0, 1.0, 41182.62585013091], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3376800.0000, 
sim time next is 3378600.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.82535232009826, 0.2875639705798471, 0.0, 1.0, 41161.25793677017], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5687793600081884, 0.5958546568599491, 0.0, 1.0, 0.19600599017509604], 
reward next is 0.8040, 
noisyNet noise sample is [array([-0.73374224], dtype=float32), -1.0950866]. 
=============================================
[2019-04-06 18:53:39,085] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.1197219e-20 2.1439344e-21 6.4460261e-16 1.8972293e-18 1.0000000e+00
 9.2592525e-24 1.1940306e-21], sum to 1.0000
[2019-04-06 18:53:39,085] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3892
[2019-04-06 18:53:39,162] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 89.0, 213.0, 6.0, 26.0, 26.36078766603275, 0.5744767056791849, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4707000.0000, 
sim time next is 4708800.0000, 
raw observation next is [1.0, 86.0, 160.5, 3.0, 26.0, 26.30327647843557, 0.5516058308317295, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4903047091412743, 0.86, 0.535, 0.0033149171270718232, 0.6666666666666666, 0.6919397065362975, 0.6838686102772432, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.99448967], dtype=float32), -0.8809459]. 
=============================================
[2019-04-06 18:53:59,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:53:59,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:53:59,340] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run20
[2019-04-06 18:54:00,379] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4653384e-18 5.6611369e-20 1.7048243e-16 2.0832538e-18 1.0000000e+00
 8.6416462e-23 1.1325789e-21], sum to 1.0000
[2019-04-06 18:54:00,380] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4129
[2019-04-06 18:54:00,449] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [9.7, 88.0, 0.0, 0.0, 26.0, 25.48271965550069, 0.4528158415263341, 1.0, 1.0, 16470.99848336989], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 977400.0000, 
sim time next is 979200.0000, 
raw observation next is [9.4, 93.0, 13.5, 0.0, 26.0, 25.41414989406065, 0.4374141272243708, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.7229916897506927, 0.93, 0.045, 0.0, 0.6666666666666666, 0.6178458245050541, 0.6458047090747903, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.58320755], dtype=float32), -0.28844604]. 
=============================================
[2019-04-06 18:54:01,722] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.50262586e-17 1.23232574e-17 1.06651565e-13 2.26137018e-16
 1.00000000e+00 2.97922927e-20 2.17753254e-19], sum to 1.0000
[2019-04-06 18:54:01,722] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4638
[2019-04-06 18:54:01,774] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 26.0, 25.60802925059653, 0.5234558355095167, 0.0, 1.0, 17455.473748668355], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4669200.0000, 
sim time next is 4671000.0000, 
raw observation next is [2.0, 57.0, 0.0, 0.0, 26.0, 25.69137900273159, 0.4959690184433054, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.518005540166205, 0.57, 0.0, 0.0, 0.6666666666666666, 0.6409482502276326, 0.6653230061477685, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8176046], dtype=float32), 0.1785007]. 
=============================================
[2019-04-06 18:54:01,778] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[85.73416]
 [85.9116 ]
 [85.94952]
 [86.46568]
 [87.01953]], R is [[85.52508545]
 [85.5867157 ]
 [85.45986938]
 [85.50698853]
 [85.61547089]].
[2019-04-06 18:54:10,022] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 18:54:10,037] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:54:10,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:54:10,046] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:54:10,046] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:54:10,048] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run44
[2019-04-06 18:54:10,069] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:54:10,069] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:54:10,071] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run44
[2019-04-06 18:54:10,094] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run44
[2019-04-06 18:54:19,920] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13429177]
[2019-04-06 18:54:19,921] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [6.9, 91.0, 148.5, 19.0, 26.0, 25.19542325226032, 0.3446424773667494, 1.0, 1.0, 0.0]
[2019-04-06 18:54:19,921] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 18:54:19,921] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [5.0890579e-18 7.8015250e-19 1.6445011e-14 1.8702904e-17 1.0000000e+00
 1.3102059e-21 2.1442310e-19], sampled 0.7269637298255501
[2019-04-06 18:56:11,959] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 18:56:51,443] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 18:56:59,953] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 18:57:00,990] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 860000, evaluation results [860000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 18:57:21,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:57:21,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:57:21,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run20
[2019-04-06 18:57:22,660] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.1517315e-17 3.5765877e-17 1.6696377e-13 6.1750528e-17 1.0000000e+00
 7.1340244e-20 8.7499058e-18], sum to 1.0000
[2019-04-06 18:57:22,660] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7295
[2019-04-06 18:57:22,778] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.4, 73.0, 0.0, 0.0, 26.0, 25.35297095991674, 0.4495210158685476, 0.0, 1.0, 112023.09334761469], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4305600.0000, 
sim time next is 4307400.0000, 
raw observation next is [5.25, 73.0, 0.0, 0.0, 26.0, 25.78560239082308, 0.474883310352533, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.60803324099723, 0.73, 0.0, 0.0, 0.6666666666666666, 0.6488001992352567, 0.6582944367841777, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0166526], dtype=float32), -0.008705913]. 
=============================================
[2019-04-06 18:57:29,567] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.9844338e-16 2.1968833e-17 1.1367849e-12 9.1569683e-16 1.0000000e+00
 1.5139416e-19 2.7542046e-18], sum to 1.0000
[2019-04-06 18:57:29,567] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6734
[2019-04-06 18:57:29,909] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 65.0, 163.5, 575.5, 26.0, 25.5767713017465, 0.4614856155855407, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4788000.0000, 
sim time next is 4789800.0000, 
raw observation next is [-2.5, 55.5, 153.0, 730.0, 26.0, 25.42316647963983, 0.4519601698475925, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.39335180055401664, 0.555, 0.51, 0.8066298342541437, 0.6666666666666666, 0.6185972066366524, 0.6506533899491975, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3696136], dtype=float32), 0.39515552]. 
=============================================
[2019-04-06 18:57:31,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:57:31,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:57:31,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run20
[2019-04-06 18:57:41,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:57:41,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:57:41,268] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run20
[2019-04-06 18:57:52,738] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.7977050e-18 6.5985014e-19 3.6045055e-15 1.4625524e-17 1.0000000e+00
 2.5364741e-22 4.7466167e-19], sum to 1.0000
[2019-04-06 18:57:52,738] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3712
[2019-04-06 18:57:52,770] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.55, 19.5, 0.0, 0.0, 26.0, 26.53909836617753, 0.6707485313579827, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5092200.0000, 
sim time next is 5094000.0000, 
raw observation next is [8.4, 20.0, 0.0, 0.0, 26.0, 26.18480145334091, 0.6095048643602813, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.6952908587257619, 0.2, 0.0, 0.0, 0.6666666666666666, 0.6820667877784091, 0.7031682881200938, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8268486], dtype=float32), 0.78829384]. 
=============================================
[2019-04-06 18:57:52,828] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[83.97234]
 [84.47643]
 [85.16529]
 [85.4764 ]
 [86.0539 ]], R is [[83.93343353]
 [84.09410095]
 [84.25315857]
 [84.41062927]
 [84.56652069]].
[2019-04-06 18:57:53,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:57:53,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:57:53,145] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run20
[2019-04-06 18:57:53,750] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0189922e-15 2.1353941e-16 4.8559169e-12 5.6044037e-15 1.0000000e+00
 2.3420149e-18 8.8756017e-18], sum to 1.0000
[2019-04-06 18:57:53,751] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5562
[2019-04-06 18:57:53,940] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.5, 44.5, 122.0, 839.0, 26.0, 25.07481794738438, 0.4085883427085478, 0.0, 1.0, 6235.968357908444], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4793400.0000, 
sim time next is 4795200.0000, 
raw observation next is [1.0, 43.0, 146.0, 813.0, 26.0, 25.02700400569832, 0.4197352528191058, 0.0, 1.0, 19942.25245563593], 
processed observation next is [0.0, 0.5217391304347826, 0.4903047091412743, 0.43, 0.4866666666666667, 0.8983425414364641, 0.6666666666666666, 0.5855836671415267, 0.639911750939702, 0.0, 1.0, 0.09496310693159968], 
reward next is 0.9050, 
noisyNet noise sample is [array([-0.05301059], dtype=float32), -0.32152984]. 
=============================================
[2019-04-06 18:57:54,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:57:54,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:57:54,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run20
[2019-04-06 18:57:56,631] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [2.3939832e-16 2.0782949e-16 6.7057194e-13 3.1915151e-15 1.0000000e+00
 4.8436314e-20 1.2516700e-17], sum to 1.0000
[2019-04-06 18:57:56,631] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6777
[2019-04-06 18:57:57,081] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.45, 75.0, 32.0, 0.0, 26.0, 25.59156396008195, 0.3122607650205687, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 808200.0000, 
sim time next is 810000.0000, 
raw observation next is [-6.2, 75.0, 46.5, 0.0, 26.0, 25.79266366489884, 0.3061739348591928, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.2908587257617729, 0.75, 0.155, 0.0, 0.6666666666666666, 0.6493886387415699, 0.6020579782863976, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.46051142], dtype=float32), 0.60706264]. 
=============================================
[2019-04-06 18:57:57,085] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[84.016   ]
 [83.52073 ]
 [81.91484 ]
 [79.26706 ]
 [79.577156]], R is [[84.05397797]
 [84.21343994]
 [84.13256073]
 [83.58145905]
 [83.54542542]].
[2019-04-06 18:58:07,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:58:07,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:58:07,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run20
[2019-04-06 18:58:15,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:58:15,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:58:15,872] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run20
[2019-04-06 18:58:16,528] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:58:16,528] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:58:16,532] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run20
[2019-04-06 18:58:20,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 18:58:20,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:58:20,192] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run20
[2019-04-06 18:59:03,198] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.5449274e-16 9.2737786e-17 1.6119695e-12 5.5165054e-15 1.0000000e+00
 1.4216903e-19 1.7887204e-16], sum to 1.0000
[2019-04-06 18:59:03,198] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7105
[2019-04-06 18:59:03,289] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.3, 71.0, 0.0, 0.0, 26.0, 24.36195161590883, 0.1583055512792143, 0.0, 1.0, 41970.4935255698], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 777600.0000, 
sim time next is 779400.0000, 
raw observation next is [-7.3, 71.0, 0.0, 0.0, 26.0, 24.25278376005203, 0.1386439952678525, 0.0, 1.0, 41756.61603241621], 
processed observation next is [1.0, 0.0, 0.26038781163434904, 0.71, 0.0, 0.0, 0.6666666666666666, 0.5210653133376691, 0.5462146650892842, 0.0, 1.0, 0.19884102872579149], 
reward next is 0.8012, 
noisyNet noise sample is [array([-2.4826105], dtype=float32), 0.5973736]. 
=============================================
[2019-04-06 18:59:07,506] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.2920853e-18 5.0712267e-19 8.1091589e-16 2.0614833e-17 1.0000000e+00
 5.5231003e-21 4.8058304e-19], sum to 1.0000
[2019-04-06 18:59:07,506] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9900
[2019-04-06 18:59:07,584] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 26.0, 25.24129340885852, 0.4588937177009141, 0.0, 1.0, 58608.08068415909], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1396800.0000, 
sim time next is 1398600.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 26.0, 25.28999201522946, 0.4598330174426719, 0.0, 1.0, 39860.10372454486], 
processed observation next is [1.0, 0.17391304347826086, 0.44598337950138506, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6074993346024549, 0.6532776724808906, 0.0, 1.0, 0.1898100177359279], 
reward next is 0.8102, 
noisyNet noise sample is [array([1.1099408], dtype=float32), 0.7703696]. 
=============================================
[2019-04-06 18:59:18,174] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4499793e-16 6.4931573e-18 4.8670042e-13 2.9472681e-16 1.0000000e+00
 3.3487176e-20 1.5227230e-18], sum to 1.0000
[2019-04-06 18:59:18,175] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5778
[2019-04-06 18:59:18,231] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 26.0, 24.78319693598615, 0.2493409324779826, 0.0, 1.0, 38571.23459636968], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2338200.0000, 
sim time next is 2340000.0000, 
raw observation next is [-2.3, 62.0, 0.0, 0.0, 26.0, 24.70228108593336, 0.2352730515577023, 0.0, 1.0, 38820.69021599196], 
processed observation next is [0.0, 0.08695652173913043, 0.3988919667590028, 0.62, 0.0, 0.0, 0.6666666666666666, 0.5585234238277801, 0.5784243505192341, 0.0, 1.0, 0.18486042959996174], 
reward next is 0.8151, 
noisyNet noise sample is [array([1.2151146], dtype=float32), -1.3056598]. 
=============================================
[2019-04-06 18:59:18,234] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.081894]
 [77.574524]
 [78.395645]
 [79.20365 ]
 [80.36895 ]], R is [[76.48877716]
 [76.54022217]
 [76.59147644]
 [76.64259338]
 [76.69271851]].
[2019-04-06 18:59:18,831] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8100315e-14 2.3138745e-17 4.1038534e-11 2.4147141e-14 1.0000000e+00
 6.2443813e-19 2.2956149e-16], sum to 1.0000
[2019-04-06 18:59:18,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3015
[2019-04-06 18:59:18,926] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.00624576689416, 0.05958411438520859, 0.0, 1.0, 41522.375272370715], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2359800.0000, 
sim time next is 2361600.0000, 
raw observation next is [-3.4, 69.0, 19.5, 0.0, 26.0, 23.91063895871935, 0.06930556240758923, 0.0, 1.0, 41888.83506701159], 
processed observation next is [0.0, 0.34782608695652173, 0.368421052631579, 0.69, 0.065, 0.0, 0.6666666666666666, 0.4925532465599458, 0.5231018541358631, 0.0, 1.0, 0.19947064317624566], 
reward next is 0.8005, 
noisyNet noise sample is [array([0.7843562], dtype=float32), 0.9831536]. 
=============================================
[2019-04-06 18:59:27,120] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5989371e-17 1.9671338e-17 2.1386622e-13 2.3646229e-15 1.0000000e+00
 1.9700229e-19 2.1217193e-17], sum to 1.0000
[2019-04-06 18:59:27,121] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0993
[2019-04-06 18:59:27,164] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.4, 49.0, 63.5, 0.0, 26.0, 27.53986112275522, 0.974108954515068, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1094400.0000, 
sim time next is 1096200.0000, 
raw observation next is [18.55, 49.5, 35.0, 0.0, 26.0, 27.85908079589682, 1.014301527347682, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.976454293628809, 0.495, 0.11666666666666667, 0.0, 0.6666666666666666, 0.821590066324735, 0.8381005091158941, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03702671], dtype=float32), -1.7460501]. 
=============================================
[2019-04-06 18:59:47,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.67586633e-16 1.32850815e-17 1.01378229e-13 5.58621273e-17
 1.00000000e+00 2.66080189e-20 5.41479460e-18], sum to 1.0000
[2019-04-06 18:59:47,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9556
[2019-04-06 18:59:47,526] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.04999999999999999, 52.0, 7.0, 82.0, 26.0, 25.83169362130595, 0.4159489954629341, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2655000.0000, 
sim time next is 2656800.0000, 
raw observation next is [-0.6, 54.0, 0.0, 0.0, 26.0, 25.1294078974784, 0.3862018454667015, 1.0, 1.0, 40279.767480266215], 
processed observation next is [1.0, 0.782608695652174, 0.44598337950138506, 0.54, 0.0, 0.0, 0.6666666666666666, 0.5941173247898668, 0.6287339484889005, 1.0, 1.0, 0.19180841657269626], 
reward next is 0.8082, 
noisyNet noise sample is [array([-0.10081524], dtype=float32), -0.76841897]. 
=============================================
[2019-04-06 18:59:51,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0404267e-15 4.2820523e-17 1.5145218e-12 3.7129128e-16 1.0000000e+00
 5.0830797e-19 1.6046705e-17], sum to 1.0000
[2019-04-06 18:59:51,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7000
[2019-04-06 18:59:52,046] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.7, 50.0, 18.0, 1.5, 26.0, 27.96473503501493, 1.028035610171029, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1098000.0000, 
sim time next is 1099800.0000, 
raw observation next is [16.9, 51.5, 0.0, 0.0, 26.0, 27.24712426464432, 0.8508561902121623, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.9307479224376731, 0.515, 0.0, 0.0, 0.6666666666666666, 0.77059368872036, 0.7836187300707208, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.74056375], dtype=float32), 0.18060002]. 
=============================================
[2019-04-06 18:59:59,421] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 18:59:59,425] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:59:59,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:59:59,427] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run45
[2019-04-06 18:59:59,460] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 18:59:59,463] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:59:59,463] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 18:59:59,466] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 18:59:59,466] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run45
[2019-04-06 18:59:59,468] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run45
[2019-04-06 19:02:04,586] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 19:02:36,219] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13422853]
[2019-04-06 19:02:36,219] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-7.064900709, 100.0, 0.0, 0.0, 26.0, 24.68989715597126, 0.2674753921447627, 0.0, 1.0, 40573.32015188757]
[2019-04-06 19:02:36,219] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 19:02:36,220] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.8980203e-16 2.8523530e-17 2.3580047e-13 5.2091309e-16 1.0000000e+00
 7.6014913e-20 6.4616285e-18], sampled 0.3781652104730784
[2019-04-06 19:02:44,361] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 19:02:46,219] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 19:02:47,280] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 880000, evaluation results [880000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 19:02:55,749] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3430887e-14 3.3497977e-16 2.3968084e-11 1.8608223e-13 1.0000000e+00
 4.4419396e-18 2.9137650e-16], sum to 1.0000
[2019-04-06 19:02:55,750] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3720
[2019-04-06 19:02:56,149] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 75.0, 152.0, 66.0, 26.0, 24.97488536829866, 0.2485302876158147, 0.0, 1.0, 30739.74426008534], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1854000.0000, 
sim time next is 1855800.0000, 
raw observation next is [-5.3, 73.0, 184.0, 81.0, 26.0, 24.94885415013587, 0.2594453386430056, 0.0, 1.0, 48283.97706839114], 
processed observation next is [0.0, 0.4782608695652174, 0.31578947368421056, 0.73, 0.6133333333333333, 0.08950276243093923, 0.6666666666666666, 0.5790711791779891, 0.5864817795476686, 0.0, 1.0, 0.2299237003256721], 
reward next is 0.7701, 
noisyNet noise sample is [array([2.0782897], dtype=float32), 1.6329935]. 
=============================================
[2019-04-06 19:03:30,921] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.3558287e-15 2.9975761e-17 9.9715603e-13 1.5643519e-15 1.0000000e+00
 3.7451980e-19 3.8591377e-17], sum to 1.0000
[2019-04-06 19:03:30,921] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6803
[2019-04-06 19:03:30,953] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 47.0, 182.5, 58.0, 26.0, 25.71945801551436, 0.3013663453632665, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2545200.0000, 
sim time next is 2547000.0000, 
raw observation next is [0.2500000000000001, 43.0, 232.0, 71.0, 26.0, 25.68309325100917, 0.3192747609446805, 1.0, 1.0, 12454.781382346364], 
processed observation next is [1.0, 0.4782608695652174, 0.46952908587257625, 0.43, 0.7733333333333333, 0.07845303867403315, 0.6666666666666666, 0.6402577709174307, 0.6064249203148935, 1.0, 1.0, 0.059308482773077924], 
reward next is 0.9407, 
noisyNet noise sample is [array([0.45798057], dtype=float32), -0.86609966]. 
=============================================
[2019-04-06 19:03:30,958] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[79.12469]
 [78.98556]
 [79.36358]
 [79.50367]
 [79.48734]], R is [[79.72667694]
 [79.92941284]
 [80.13011932]
 [80.32881927]
 [80.52553558]].
[2019-04-06 19:03:36,944] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.09373243e-16 1.45073980e-16 2.19579129e-12 1.20687524e-14
 1.00000000e+00 1.57152620e-19 1.82263650e-16], sum to 1.0000
[2019-04-06 19:03:36,945] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6288
[2019-04-06 19:03:37,030] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 26.0, 25.56471510241536, 0.5089438780733767, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3360600.0000, 
sim time next is 3362400.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 26.0, 25.40983143502091, 0.5007536710504704, 0.0, 1.0, 63507.32206302204], 
processed observation next is [1.0, 0.9565217391304348, 0.3518005540166205, 0.65, 0.0, 0.0, 0.6666666666666666, 0.617485952918409, 0.6669178903501568, 0.0, 1.0, 0.302415819347724], 
reward next is 0.6976, 
noisyNet noise sample is [array([0.08496623], dtype=float32), 1.3303589]. 
=============================================
[2019-04-06 19:03:55,660] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.1444152e-17 1.6493730e-18 5.3525482e-14 1.3525006e-17 1.0000000e+00
 1.1067902e-21 2.6678059e-19], sum to 1.0000
[2019-04-06 19:03:55,661] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2163
[2019-04-06 19:03:56,067] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 79.0, 152.0, 0.0, 26.0, 25.36742702635645, 0.2169546130634417, 1.0, 1.0, 36881.28171039645], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2034000.0000, 
sim time next is 2035800.0000, 
raw observation next is [-4.2, 79.0, 148.0, 0.0, 26.0, 25.08361989845746, 0.3985630893502738, 1.0, 1.0, 132787.47118566823], 
processed observation next is [1.0, 0.5652173913043478, 0.34626038781163443, 0.79, 0.49333333333333335, 0.0, 0.6666666666666666, 0.5903016582047883, 0.6328543631167579, 1.0, 1.0, 0.6323212913603249], 
reward next is 0.3677, 
noisyNet noise sample is [array([-0.35053718], dtype=float32), 1.1614577]. 
=============================================
[2019-04-06 19:04:02,915] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7494520e-16 1.8604626e-18 2.3436832e-13 6.2847264e-17 1.0000000e+00
 7.4929251e-20 5.0694302e-18], sum to 1.0000
[2019-04-06 19:04:02,916] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5249
[2019-04-06 19:04:02,952] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 26.0, 24.50031093487727, 0.158091835253973, 0.0, 1.0, 42528.86684839772], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2169000.0000, 
sim time next is 2170800.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 26.0, 24.49881978720017, 0.1600538937934436, 0.0, 1.0, 42433.24138277672], 
processed observation next is [1.0, 0.13043478260869565, 0.2770083102493075, 0.78, 0.0, 0.0, 0.6666666666666666, 0.5415683156000141, 0.5533512979311479, 0.0, 1.0, 0.2020630542036987], 
reward next is 0.7979, 
noisyNet noise sample is [array([0.97233075], dtype=float32), 1.1018084]. 
=============================================
[2019-04-06 19:04:04,922] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3498557e-18 1.1954036e-19 1.7817894e-14 3.9386767e-17 1.0000000e+00
 7.8325855e-22 1.2738451e-20], sum to 1.0000
[2019-04-06 19:04:04,922] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0017
[2019-04-06 19:04:04,979] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 86.0, 160.5, 3.0, 26.0, 26.30327647843557, 0.5516058308317295, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4708800.0000, 
sim time next is 4710600.0000, 
raw observation next is [1.0, 86.0, 108.0, 0.0, 26.0, 26.18853608383834, 0.5071466598348825, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4903047091412743, 0.86, 0.36, 0.0, 0.6666666666666666, 0.6823780069865283, 0.6690488866116274, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.43957135], dtype=float32), 0.68480796]. 
=============================================
[2019-04-06 19:04:25,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:04:25,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:04:25,147] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run21
[2019-04-06 19:04:26,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:04:26,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:04:26,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run21
[2019-04-06 19:04:31,217] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5038201e-15 3.2916299e-16 1.2252251e-12 6.4508018e-15 1.0000000e+00
 1.2687695e-17 1.5753219e-16], sum to 1.0000
[2019-04-06 19:04:31,225] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9096
[2019-04-06 19:04:31,317] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.6, 28.0, 88.5, 838.5, 26.0, 24.94169573274729, 0.2737868143586528, 0.0, 1.0, 14947.12643727028], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2466000.0000, 
sim time next is 2467800.0000, 
raw observation next is [1.9, 27.5, 87.0, 832.0, 26.0, 24.96750611947289, 0.2717404336087993, 0.0, 1.0, 6236.545614343474], 
processed observation next is [0.0, 0.5652173913043478, 0.515235457063712, 0.275, 0.29, 0.9193370165745857, 0.6666666666666666, 0.5806255099560742, 0.5905801445362665, 0.0, 1.0, 0.02969783625877845], 
reward next is 0.9703, 
noisyNet noise sample is [array([-0.2087718], dtype=float32), -0.59718925]. 
=============================================
[2019-04-06 19:04:35,804] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.9262475e-17 1.4102507e-18 1.2242060e-13 1.1852484e-15 1.0000000e+00
 2.3566744e-20 7.2937999e-18], sum to 1.0000
[2019-04-06 19:04:35,804] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8758
[2019-04-06 19:04:35,906] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 36.0, 0.0, 0.0, 26.0, 25.56495234824319, 0.5833578905319962, 0.0, 1.0, 99246.41595745152], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4136400.0000, 
sim time next is 4138200.0000, 
raw observation next is [1.0, 38.0, 0.0, 0.0, 26.0, 25.87402978505841, 0.5869239683654595, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4903047091412743, 0.38, 0.0, 0.0, 0.6666666666666666, 0.6561691487548676, 0.6956413227884864, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16121916], dtype=float32), -0.15866831]. 
=============================================
[2019-04-06 19:04:45,761] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3120481e-17 9.8226387e-17 1.6510358e-13 9.5614508e-16 1.0000000e+00
 8.5653906e-19 1.8803765e-18], sum to 1.0000
[2019-04-06 19:04:45,761] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1229
[2019-04-06 19:04:45,885] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 59.0, 0.0, 0.0, 26.0, 25.11395632076757, 0.4171188428733539, 0.0, 1.0, 68007.43857994363], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2750400.0000, 
sim time next is 2752200.0000, 
raw observation next is [-5.5, 61.5, 0.0, 0.0, 26.0, 25.20122103349085, 0.4415420220450967, 0.0, 1.0, 103872.04384579178], 
processed observation next is [1.0, 0.8695652173913043, 0.3102493074792244, 0.615, 0.0, 0.0, 0.6666666666666666, 0.6001017527909042, 0.6471806740150322, 0.0, 1.0, 0.49462878021805606], 
reward next is 0.5054, 
noisyNet noise sample is [array([1.4124707], dtype=float32), -1.0296628]. 
=============================================
[2019-04-06 19:04:56,718] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5383616e-16 6.4370505e-18 6.6791529e-14 5.0759593e-15 1.0000000e+00
 2.7469198e-20 7.9043684e-18], sum to 1.0000
[2019-04-06 19:04:56,718] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3329
[2019-04-06 19:04:56,802] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.1, 69.0, 0.0, 0.0, 26.0, 23.86094508942061, 0.01085919593699672, 0.0, 1.0, 45594.00714431636], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 268200.0000, 
sim time next is 270000.0000, 
raw observation next is [-8.9, 67.0, 0.0, 0.0, 26.0, 23.75827299002911, -0.02509131593474348, 0.0, 1.0, 45725.92211948958], 
processed observation next is [1.0, 0.13043478260869565, 0.21606648199445982, 0.67, 0.0, 0.0, 0.6666666666666666, 0.4798560825024258, 0.49163622802175216, 0.0, 1.0, 0.21774248628328371], 
reward next is 0.7823, 
noisyNet noise sample is [array([-0.10392112], dtype=float32), -0.85012615]. 
=============================================
[2019-04-06 19:04:56,815] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[79.21568 ]
 [79.952736]
 [80.376366]
 [80.72585 ]
 [81.06421 ]], R is [[78.59079742]
 [78.58777618]
 [78.58542633]
 [78.58443451]
 [78.58573914]].
[2019-04-06 19:04:58,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:04:58,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:04:58,234] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run21
[2019-04-06 19:05:01,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:05:01,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:05:01,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run21
[2019-04-06 19:05:01,162] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.4929524e-15 8.3632804e-17 7.5884373e-13 2.0133702e-15 1.0000000e+00
 4.7976057e-19 4.0397314e-17], sum to 1.0000
[2019-04-06 19:05:01,162] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4905
[2019-04-06 19:05:01,367] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.0698483e-14 5.1107965e-15 1.0128358e-12 4.9111465e-14 1.0000000e+00
 6.7968318e-18 4.3979380e-16], sum to 1.0000
[2019-04-06 19:05:01,367] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0625
[2019-04-06 19:05:01,421] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 39.0, 91.5, 724.0, 26.0, 25.11709159150148, 0.3645796427223548, 0.0, 1.0, 18702.64314491442], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3078000.0000, 
sim time next is 3079800.0000, 
raw observation next is [0.5, 39.5, 84.0, 673.0, 26.0, 25.12733424884191, 0.366575038564407, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.4764542936288089, 0.395, 0.28, 0.7436464088397791, 0.6666666666666666, 0.5939445207368257, 0.6221916795214689, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9486237], dtype=float32), -0.64455163]. 
=============================================
[2019-04-06 19:05:01,435] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.0, 30.0, 0.0, 0.0, 26.0, 25.46268491161345, 0.3656151422705246, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2829600.0000, 
sim time next is 2831400.0000, 
raw observation next is [4.0, 33.5, 0.0, 0.0, 26.0, 23.5373993325947, 0.133380544830742, 1.0, 1.0, 130941.76765853673], 
processed observation next is [1.0, 0.782608695652174, 0.5734072022160666, 0.335, 0.0, 0.0, 0.6666666666666666, 0.4614499443828916, 0.5444601816102473, 1.0, 1.0, 0.623532226945413], 
reward next is 0.3765, 
noisyNet noise sample is [array([-0.8192649], dtype=float32), 2.024408]. 
=============================================
[2019-04-06 19:05:03,329] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8757741e-17 4.6677357e-19 6.1955162e-15 2.3557971e-17 1.0000000e+00
 1.1893942e-20 1.1799144e-18], sum to 1.0000
[2019-04-06 19:05:03,329] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3618
[2019-04-06 19:05:03,560] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 78.0, 0.0, 0.0, 26.0, 24.91720594726637, 0.4025110198617031, 0.0, 1.0, 85612.4058522579], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2923200.0000, 
sim time next is 2925000.0000, 
raw observation next is [-1.0, 81.5, 0.0, 0.0, 26.0, 25.00056629515927, 0.4417730359972545, 0.0, 1.0, 97463.09029802117], 
processed observation next is [1.0, 0.8695652173913043, 0.4349030470914128, 0.815, 0.0, 0.0, 0.6666666666666666, 0.5833805245966058, 0.6472576786657515, 0.0, 1.0, 0.4641099538001008], 
reward next is 0.5359, 
noisyNet noise sample is [array([1.3787018], dtype=float32), -2.0605607]. 
=============================================
[2019-04-06 19:05:03,564] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[87.62818 ]
 [88.96442 ]
 [89.660965]
 [89.94296 ]
 [90.41594 ]], R is [[86.57457733]
 [86.30115509]
 [86.33956146]
 [86.22486877]
 [86.22621155]].
[2019-04-06 19:05:08,152] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:05:08,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:05:08,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run21
[2019-04-06 19:05:22,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:05:22,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:05:22,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run21
[2019-04-06 19:05:27,795] A3C_AGENT_WORKER-Thread-14 INFO:Local step 57000, global step 899431: loss 0.0462
[2019-04-06 19:05:27,804] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 57000, global step 899431: learning rate 0.0000
[2019-04-06 19:05:28,037] A3C_AGENT_WORKER-Thread-17 INFO:Local step 57000, global step 899456: loss 0.0416
[2019-04-06 19:05:28,045] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 57000, global step 899456: learning rate 0.0000
[2019-04-06 19:05:31,800] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 19:05:31,800] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:05:31,800] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:05:31,801] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:05:31,801] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:05:31,803] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run46
[2019-04-06 19:05:31,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:05:31,826] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run46
[2019-04-06 19:05:31,822] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:05:31,847] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run46
[2019-04-06 19:07:36,482] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 19:08:15,854] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 19:08:17,884] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 19:08:18,922] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 900000, evaluation results [900000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 19:08:34,236] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.9462193e-17 7.9243592e-17 3.2430930e-14 3.0056828e-17 1.0000000e+00
 4.6718482e-20 5.6747212e-18], sum to 1.0000
[2019-04-06 19:08:34,237] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3966
[2019-04-06 19:08:34,330] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 57.5, 0.0, 0.0, 26.0, 25.37199942528237, 0.447037605428497, 0.0, 1.0, 81370.82829385408], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3882600.0000, 
sim time next is 3884400.0000, 
raw observation next is [-1.0, 60.0, 0.0, 0.0, 26.0, 25.29155082583561, 0.4665884804270711, 0.0, 1.0, 65660.7097030285], 
processed observation next is [1.0, 1.0, 0.4349030470914128, 0.6, 0.0, 0.0, 0.6666666666666666, 0.6076292354863009, 0.6555294934756903, 0.0, 1.0, 0.3126700462048976], 
reward next is 0.6873, 
noisyNet noise sample is [array([-2.0717132], dtype=float32), 0.84728914]. 
=============================================
[2019-04-06 19:08:56,014] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.1563951e-19 4.4822759e-20 8.0506585e-16 3.4482811e-17 1.0000000e+00
 5.0670779e-23 3.8605308e-20], sum to 1.0000
[2019-04-06 19:08:56,014] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5391
[2019-04-06 19:08:56,112] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.0, 19.0, 96.0, 745.0, 26.0, 28.27605896393112, 1.077955687150343, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5067000.0000, 
sim time next is 5068800.0000, 
raw observation next is [12.0, 19.0, 86.0, 665.0, 26.0, 28.56674971759686, 1.135081636064829, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.7950138504155125, 0.19, 0.2866666666666667, 0.7348066298342542, 0.6666666666666666, 0.880562476466405, 0.8783605453549429, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9624813], dtype=float32), -0.14626616]. 
=============================================
[2019-04-06 19:08:58,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:08:58,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:08:58,420] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run21
[2019-04-06 19:08:59,160] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.10187254e-16 2.59611628e-17 2.93568858e-12 5.28888219e-16
 1.00000000e+00 2.20347908e-18 3.06286240e-16], sum to 1.0000
[2019-04-06 19:08:59,160] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9865
[2019-04-06 19:08:59,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.85850665e-16 1.23283354e-17 7.37401297e-13 1.64200623e-14
 1.00000000e+00 2.56798449e-18 1.11589866e-17], sum to 1.0000
[2019-04-06 19:08:59,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1126
[2019-04-06 19:08:59,371] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.7, 41.0, 0.0, 0.0, 26.0, 25.02990134484786, 0.3248234273667024, 0.0, 1.0, 56071.605044706164], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4212000.0000, 
sim time next is 4213800.0000, 
raw observation next is [1.55, 41.5, 0.0, 0.0, 26.0, 25.03047967636806, 0.3130968313348907, 0.0, 1.0, 27923.17017657788], 
processed observation next is [0.0, 0.782608695652174, 0.5055401662049862, 0.415, 0.0, 0.0, 0.6666666666666666, 0.585873306364005, 0.6043656104449636, 0.0, 1.0, 0.13296747703132325], 
reward next is 0.8670, 
noisyNet noise sample is [array([-0.42139682], dtype=float32), 1.0802727]. 
=============================================
[2019-04-06 19:08:59,525] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 38.0, 96.5, 756.0, 26.0, 27.02168461938209, 0.7899254005110411, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3942000.0000, 
sim time next is 3943800.0000, 
raw observation next is [-4.0, 36.0, 88.0, 724.0, 26.0, 25.78299230211829, 0.6303426331174837, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.3518005540166205, 0.36, 0.29333333333333333, 0.8, 0.6666666666666666, 0.648582691843191, 0.7101142110391612, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16944434], dtype=float32), -1.2541004]. 
=============================================
[2019-04-06 19:09:03,384] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.3338998e-16 1.6389811e-17 2.3767753e-13 2.5109410e-16 1.0000000e+00
 6.1283945e-19 7.7780537e-18], sum to 1.0000
[2019-04-06 19:09:03,384] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4448
[2019-04-06 19:09:03,434] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-11.0, 58.0, 0.0, 0.0, 26.0, 24.70983590926927, 0.2763791389490934, 0.0, 1.0, 43938.5136258724], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3978000.0000, 
sim time next is 3979800.0000, 
raw observation next is [-11.5, 60.5, 0.0, 0.0, 26.0, 24.68552887992348, 0.2481322584148454, 0.0, 1.0, 43788.945892139745], 
processed observation next is [1.0, 0.043478260869565216, 0.1440443213296399, 0.605, 0.0, 0.0, 0.6666666666666666, 0.5571274066602901, 0.5827107528049484, 0.0, 1.0, 0.20851878996257023], 
reward next is 0.7915, 
noisyNet noise sample is [array([-0.04663601], dtype=float32), -0.1269745]. 
=============================================
[2019-04-06 19:09:11,709] A3C_AGENT_WORKER-Thread-19 INFO:Local step 57000, global step 905038: loss 0.0347
[2019-04-06 19:09:11,717] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 57000, global step 905038: learning rate 0.0000
[2019-04-06 19:09:16,179] A3C_AGENT_WORKER-Thread-18 INFO:Local step 57000, global step 905465: loss 0.0303
[2019-04-06 19:09:16,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 57000, global step 905465: learning rate 0.0000
[2019-04-06 19:09:22,443] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.4633177e-19 4.1123675e-20 8.7141776e-15 2.0328857e-17 1.0000000e+00
 3.0965582e-22 2.9069977e-20], sum to 1.0000
[2019-04-06 19:09:22,443] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8267
[2019-04-06 19:09:22,598] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 65.5, 164.0, 509.0, 26.0, 26.10880306291595, 0.570980237018667, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4613400.0000, 
sim time next is 4615200.0000, 
raw observation next is [0.0, 60.0, 146.5, 638.0, 26.0, 26.44746717667299, 0.6277571343243454, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.46260387811634357, 0.6, 0.48833333333333334, 0.7049723756906078, 0.6666666666666666, 0.7039555980560825, 0.7092523781081151, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.39201486], dtype=float32), -0.42413273]. 
=============================================
[2019-04-06 19:09:29,919] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.0908903e-15 1.7384564e-15 1.9310419e-12 1.3036024e-14 1.0000000e+00
 1.8708962e-18 1.2440028e-15], sum to 1.0000
[2019-04-06 19:09:29,919] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7915
[2019-04-06 19:09:30,301] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 49.5, 92.0, 488.0, 26.0, 24.96241070947192, 0.3967406547743133, 0.0, 1.0, 80530.73597252266], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4177800.0000, 
sim time next is 4179600.0000, 
raw observation next is [-4.0, 45.0, 100.0, 574.0, 26.0, 25.64886847583017, 0.438301824558077, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3518005540166205, 0.45, 0.3333333333333333, 0.6342541436464089, 0.6666666666666666, 0.6374057063191808, 0.6461006081860257, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0027403], dtype=float32), 0.7077734]. 
=============================================
[2019-04-06 19:09:31,320] A3C_AGENT_WORKER-Thread-14 INFO:Local step 57500, global step 906949: loss 2.7802
[2019-04-06 19:09:31,329] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 57500, global step 906949: learning rate 0.0000
[2019-04-06 19:09:31,337] A3C_AGENT_WORKER-Thread-17 INFO:Local step 57500, global step 906950: loss 2.8047
[2019-04-06 19:09:31,337] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 57500, global step 906950: learning rate 0.0000
[2019-04-06 19:09:32,303] A3C_AGENT_WORKER-Thread-15 INFO:Local step 57000, global step 907055: loss 0.0304
[2019-04-06 19:09:32,304] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 57000, global step 907055: learning rate 0.0000
[2019-04-06 19:09:38,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:09:38,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:09:38,542] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run21
[2019-04-06 19:09:45,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:09:45,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:09:45,712] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run21
[2019-04-06 19:09:46,700] A3C_AGENT_WORKER-Thread-8 INFO:Local step 57000, global step 908949: loss 0.0369
[2019-04-06 19:09:46,700] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 57000, global step 908949: learning rate 0.0000
[2019-04-06 19:09:52,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:09:52,182] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:09:52,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run21
[2019-04-06 19:09:53,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7693452e-16 3.2042598e-17 7.4813948e-14 7.1549159e-16 1.0000000e+00
 3.5523132e-19 3.0504645e-18], sum to 1.0000
[2019-04-06 19:09:53,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4408
[2019-04-06 19:09:53,970] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.5, 62.5, 207.0, 179.0, 26.0, 25.47833949822803, 0.3653353713948804, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4872600.0000, 
sim time next is 4874400.0000, 
raw observation next is [-2.0, 60.0, 253.5, 171.5, 26.0, 25.33154024844334, 0.3481634780470933, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.40720221606648205, 0.6, 0.845, 0.18950276243093922, 0.6666666666666666, 0.6109616873702782, 0.6160544926823645, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7630897], dtype=float32), 1.7308745]. 
=============================================
[2019-04-06 19:09:55,368] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:09:55,368] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:09:55,371] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run21
[2019-04-06 19:09:59,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:09:59,950] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:09:59,953] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run21
[2019-04-06 19:10:03,131] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.9847180e-17 2.2481673e-16 2.8346184e-13 4.8698356e-17 1.0000000e+00
 2.5888929e-20 8.1219988e-18], sum to 1.0000
[2019-04-06 19:10:03,131] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2674
[2019-04-06 19:10:03,223] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.5, 41.5, 170.0, 787.0, 26.0, 25.08958592487038, 0.4318786094572221, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4797000.0000, 
sim time next is 4798800.0000, 
raw observation next is [2.0, 40.0, 195.0, 677.5, 26.0, 25.18792079753937, 0.4431182295613867, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.518005540166205, 0.4, 0.65, 0.7486187845303868, 0.6666666666666666, 0.5989933997949475, 0.6477060765204622, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8820726], dtype=float32), -0.33056098]. 
=============================================
[2019-04-06 19:10:05,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:10:05,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:10:05,423] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run21
[2019-04-06 19:10:08,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:10:08,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:10:08,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run21
[2019-04-06 19:10:10,348] A3C_AGENT_WORKER-Thread-19 INFO:Local step 57500, global step 912144: loss 2.7192
[2019-04-06 19:10:10,359] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 57500, global step 912144: learning rate 0.0000
[2019-04-06 19:10:11,309] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:10:11,309] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:10:11,312] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run21
[2019-04-06 19:10:13,516] A3C_AGENT_WORKER-Thread-18 INFO:Local step 57500, global step 912487: loss 2.7688
[2019-04-06 19:10:13,516] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 57500, global step 912487: learning rate 0.0000
[2019-04-06 19:10:18,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:10:18,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:10:18,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run21
[2019-04-06 19:10:19,722] A3C_AGENT_WORKER-Thread-15 INFO:Local step 57500, global step 913237: loss 2.6833
[2019-04-06 19:10:19,722] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 57500, global step 913237: learning rate 0.0000
[2019-04-06 19:10:20,125] A3C_AGENT_WORKER-Thread-7 INFO:Local step 57000, global step 913280: loss 0.0340
[2019-04-06 19:10:20,125] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 57000, global step 913280: learning rate 0.0000
[2019-04-06 19:10:31,539] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.3540868e-15 7.4685625e-18 7.1307543e-14 1.5427501e-16 1.0000000e+00
 1.5341441e-19 3.0866344e-18], sum to 1.0000
[2019-04-06 19:10:31,539] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7318
[2019-04-06 19:10:31,751] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.45, 86.0, 79.0, 0.0, 26.0, 24.4585915207352, 0.1657255515690211, 0.0, 1.0, 26483.88374573109], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 52200.0000, 
sim time next is 54000.0000, 
raw observation next is [7.2, 86.0, 64.5, 0.0, 26.0, 24.47161442805653, 0.1615151389058745, 0.0, 1.0, 29927.54599159672], 
processed observation next is [0.0, 0.6521739130434783, 0.662049861495845, 0.86, 0.215, 0.0, 0.6666666666666666, 0.5393012023380441, 0.5538383796352915, 0.0, 1.0, 0.14251212376950817], 
reward next is 0.8575, 
noisyNet noise sample is [array([0.47964925], dtype=float32), 2.0507514]. 
=============================================
[2019-04-06 19:10:31,756] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[85.4631 ]
 [85.64289]
 [85.76213]
 [85.73654]
 [85.93313]], R is [[85.21521759]
 [85.23695374]
 [85.22032166]
 [85.18405151]
 [85.24291992]].
[2019-04-06 19:10:34,585] A3C_AGENT_WORKER-Thread-8 INFO:Local step 57500, global step 914762: loss 2.8646
[2019-04-06 19:10:34,600] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 57500, global step 914762: learning rate 0.0000
[2019-04-06 19:10:41,693] A3C_AGENT_WORKER-Thread-17 INFO:Local step 58000, global step 915491: loss 0.2464
[2019-04-06 19:10:41,696] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 58000, global step 915491: learning rate 0.0000
[2019-04-06 19:10:41,876] A3C_AGENT_WORKER-Thread-14 INFO:Local step 58000, global step 915516: loss 0.2950
[2019-04-06 19:10:41,877] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 58000, global step 915516: learning rate 0.0000
[2019-04-06 19:10:44,286] A3C_AGENT_WORKER-Thread-6 INFO:Local step 57000, global step 915796: loss 0.0215
[2019-04-06 19:10:44,287] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 57000, global step 915796: learning rate 0.0000
[2019-04-06 19:10:52,700] A3C_AGENT_WORKER-Thread-12 INFO:Local step 57000, global step 916809: loss 0.0297
[2019-04-06 19:10:52,701] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 57000, global step 916809: learning rate 0.0000
[2019-04-06 19:10:57,811] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3605036e-18 1.4451982e-18 3.2174868e-14 9.1696174e-17 1.0000000e+00
 3.4393540e-21 8.6901547e-20], sum to 1.0000
[2019-04-06 19:10:57,811] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3926
[2019-04-06 19:10:57,893] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.9, 77.0, 0.0, 0.0, 26.0, 23.68417570450821, -0.01092888061809012, 0.0, 1.0, 41893.63360537669], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2183400.0000, 
sim time next is 2185200.0000, 
raw observation next is [-5.6, 75.0, 0.0, 0.0, 26.0, 23.64665749583741, -0.02124952680231236, 0.0, 1.0, 41909.56239847943], 
processed observation next is [1.0, 0.30434782608695654, 0.30747922437673136, 0.75, 0.0, 0.0, 0.6666666666666666, 0.4705547913197841, 0.49291682439922924, 0.0, 1.0, 0.19956934475466395], 
reward next is 0.8004, 
noisyNet noise sample is [array([-0.04784521], dtype=float32), 1.132429]. 
=============================================
[2019-04-06 19:10:59,640] A3C_AGENT_WORKER-Thread-16 INFO:Local step 57000, global step 917543: loss 0.0238
[2019-04-06 19:10:59,640] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 57000, global step 917543: learning rate 0.0000
[2019-04-06 19:11:01,241] A3C_AGENT_WORKER-Thread-20 INFO:Local step 57000, global step 917690: loss 0.0200
[2019-04-06 19:11:01,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 57000, global step 917690: learning rate 0.0000
[2019-04-06 19:11:05,188] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1571478e-16 1.6736038e-17 2.0691179e-13 7.3426899e-16 1.0000000e+00
 8.7057116e-21 1.7605237e-18], sum to 1.0000
[2019-04-06 19:11:05,189] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2705
[2019-04-06 19:11:05,229] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 91.0, 0.0, 0.0, 26.0, 23.81046515723298, 0.008857092594477584, 0.0, 1.0, 43463.68065322928], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2264400.0000, 
sim time next is 2266200.0000, 
raw observation next is [-8.9, 91.0, 0.0, 0.0, 26.0, 23.68423470208621, -0.01660039872610628, 0.0, 1.0, 43319.35876837976], 
processed observation next is [1.0, 0.21739130434782608, 0.21606648199445982, 0.91, 0.0, 0.0, 0.6666666666666666, 0.47368622517385095, 0.49446653375796457, 0.0, 1.0, 0.20628266080180838], 
reward next is 0.7937, 
noisyNet noise sample is [array([2.3298123], dtype=float32), -0.7168095]. 
=============================================
[2019-04-06 19:11:07,280] A3C_AGENT_WORKER-Thread-7 INFO:Local step 57500, global step 918378: loss 2.8791
[2019-04-06 19:11:07,281] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 57500, global step 918378: learning rate 0.0000
[2019-04-06 19:11:08,362] A3C_AGENT_WORKER-Thread-5 INFO:Local step 57000, global step 918513: loss 0.0311
[2019-04-06 19:11:08,362] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 57000, global step 918513: learning rate 0.0000
[2019-04-06 19:11:12,411] A3C_AGENT_WORKER-Thread-13 INFO:Local step 57000, global step 919042: loss 0.0178
[2019-04-06 19:11:12,412] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 57000, global step 919042: learning rate 0.0000
[2019-04-06 19:11:13,250] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4645005e-16 3.5852911e-16 1.5197216e-12 1.2334605e-15 1.0000000e+00
 1.3597053e-19 3.2365811e-17], sum to 1.0000
[2019-04-06 19:11:13,251] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4210
[2019-04-06 19:11:13,321] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 57.5, 0.0, 0.0, 26.0, 25.33125079230672, 0.3653666782311405, 0.0, 1.0, 40473.25788316814], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2327400.0000, 
sim time next is 2329200.0000, 
raw observation next is [-2.3, 59.0, 0.0, 0.0, 26.0, 25.12106731503795, 0.3311190278228924, 0.0, 1.0, 38870.513737749854], 
processed observation next is [1.0, 1.0, 0.3988919667590028, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5934222762531626, 0.6103730092742975, 0.0, 1.0, 0.1850976844654755], 
reward next is 0.8149, 
noisyNet noise sample is [array([-0.5757666], dtype=float32), -1.6493658]. 
=============================================
[2019-04-06 19:11:15,063] A3C_AGENT_WORKER-Thread-3 INFO:Local step 57000, global step 919385: loss 0.0245
[2019-04-06 19:11:15,064] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 57000, global step 919385: learning rate 0.0000
[2019-04-06 19:11:16,787] A3C_AGENT_WORKER-Thread-2 INFO:Local step 57000, global step 919617: loss 0.0261
[2019-04-06 19:11:16,788] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 57000, global step 919617: learning rate 0.0000
[2019-04-06 19:11:18,814] A3C_AGENT_WORKER-Thread-19 INFO:Local step 58000, global step 919876: loss 0.2273
[2019-04-06 19:11:18,837] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 58000, global step 919876: learning rate 0.0000
[2019-04-06 19:11:19,696] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4937957e-17 6.7687548e-19 3.9796871e-14 6.8113671e-18 1.0000000e+00
 5.8080186e-22 2.9407260e-20], sum to 1.0000
[2019-04-06 19:11:19,696] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3332
[2019-04-06 19:11:19,741] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 19:11:19,753] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.7, 79.0, 0.0, 0.0, 26.0, 24.73796027695566, 0.1989819529289752, 0.0, 1.0, 39365.93383576605], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 873000.0000, 
sim time next is 874800.0000, 
raw observation next is [-1.7, 79.0, 0.0, 0.0, 26.0, 24.60868136822765, 0.1834388642260507, 0.0, 1.0, 39361.364741401936], 
processed observation next is [1.0, 0.13043478260869565, 0.4155124653739613, 0.79, 0.0, 0.0, 0.6666666666666666, 0.5507234473523042, 0.5611462880753503, 0.0, 1.0, 0.18743507019715208], 
reward next is 0.8126, 
noisyNet noise sample is [array([0.30099523], dtype=float32), 0.47142726]. 
=============================================
[2019-04-06 19:11:19,753] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:11:19,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:11:19,758] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run47
[2019-04-06 19:11:19,802] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:11:19,803] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:11:19,805] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run47
[2019-04-06 19:11:19,821] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:11:19,822] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:11:19,825] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run47
[2019-04-06 19:13:23,920] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 19:14:05,992] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 19:14:06,498] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 19:14:07,536] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 920000, evaluation results [920000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 19:14:10,424] A3C_AGENT_WORKER-Thread-18 INFO:Local step 58000, global step 920257: loss 0.2469
[2019-04-06 19:14:10,426] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 58000, global step 920257: learning rate 0.0000
[2019-04-06 19:14:16,021] A3C_AGENT_WORKER-Thread-4 INFO:Local step 57000, global step 920754: loss 0.0248
[2019-04-06 19:14:16,021] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 57000, global step 920754: learning rate 0.0000
[2019-04-06 19:14:20,748] A3C_AGENT_WORKER-Thread-15 INFO:Local step 58000, global step 921177: loss 0.1908
[2019-04-06 19:14:20,749] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 58000, global step 921177: learning rate 0.0000
[2019-04-06 19:14:28,671] A3C_AGENT_WORKER-Thread-6 INFO:Local step 57500, global step 921991: loss 2.6596
[2019-04-06 19:14:28,671] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 57500, global step 921991: learning rate 0.0000
[2019-04-06 19:14:32,543] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.7152571e-21 1.6235755e-22 8.8960118e-17 3.7733011e-21 1.0000000e+00
 6.0079201e-24 6.1950654e-23], sum to 1.0000
[2019-04-06 19:14:32,544] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0830
[2019-04-06 19:14:32,589] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.2, 83.0, 11.5, 38.0, 26.0, 25.9238869584286, 0.624215766368566, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1065600.0000, 
sim time next is 1067400.0000, 
raw observation next is [12.2, 83.0, 22.0, 69.0, 26.0, 26.06927661407415, 0.6824415106432492, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.8005540166204987, 0.83, 0.07333333333333333, 0.07624309392265194, 0.6666666666666666, 0.6724397178395124, 0.7274805035477497, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.38232946], dtype=float32), -1.0247036]. 
=============================================
[2019-04-06 19:14:38,308] A3C_AGENT_WORKER-Thread-12 INFO:Local step 57500, global step 922962: loss 2.7490
[2019-04-06 19:14:38,317] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 57500, global step 922962: learning rate 0.0000
[2019-04-06 19:14:42,481] A3C_AGENT_WORKER-Thread-14 INFO:Local step 58500, global step 923389: loss 0.2433
[2019-04-06 19:14:42,482] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 58500, global step 923389: learning rate 0.0000
[2019-04-06 19:14:42,574] A3C_AGENT_WORKER-Thread-17 INFO:Local step 58500, global step 923400: loss 0.2471
[2019-04-06 19:14:42,574] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 58500, global step 923400: learning rate 0.0000
[2019-04-06 19:14:44,165] A3C_AGENT_WORKER-Thread-8 INFO:Local step 58000, global step 923578: loss 0.3196
[2019-04-06 19:14:44,170] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 58000, global step 923578: learning rate 0.0000
[2019-04-06 19:14:46,429] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1342456e-19 3.5378990e-18 4.0779344e-14 6.9358102e-17 1.0000000e+00
 8.7509186e-23 1.3500610e-19], sum to 1.0000
[2019-04-06 19:14:46,430] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9022
[2019-04-06 19:14:46,440] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.41791036e-18 1.01508865e-16 4.49324849e-13 1.81090324e-16
 1.00000000e+00 3.75869287e-20 4.20702033e-18], sum to 1.0000
[2019-04-06 19:14:46,440] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9407
[2019-04-06 19:14:46,486] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [11.6, 80.0, 0.0, 0.0, 26.0, 25.6941216539068, 0.6139182567883178, 0.0, 1.0, 12482.337555594751], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1143000.0000, 
sim time next is 1144800.0000, 
raw observation next is [11.6, 83.0, 0.0, 0.0, 26.0, 25.64118335954192, 0.6069886865431512, 0.0, 1.0, 29367.241782456913], 
processed observation next is [0.0, 0.2608695652173913, 0.7839335180055402, 0.83, 0.0, 0.0, 0.6666666666666666, 0.6367652799618266, 0.7023295621810504, 0.0, 1.0, 0.13984400848789005], 
reward next is 0.8602, 
noisyNet noise sample is [array([-0.32313925], dtype=float32), 0.41804662]. 
=============================================
[2019-04-06 19:14:46,589] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 55.0, 163.0, 370.5, 26.0, 25.93306304381839, 0.4203800812206802, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2800800.0000, 
sim time next is 2802600.0000, 
raw observation next is [-2.0, 52.5, 174.0, 508.0, 26.0, 26.01850419346533, 0.4521597167640981, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.40720221606648205, 0.525, 0.58, 0.5613259668508287, 0.6666666666666666, 0.6682086827887774, 0.6507199055880327, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.39416465], dtype=float32), 1.3629186]. 
=============================================
[2019-04-06 19:14:48,860] A3C_AGENT_WORKER-Thread-16 INFO:Local step 57500, global step 924089: loss 2.6185
[2019-04-06 19:14:48,860] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 57500, global step 924089: learning rate 0.0000
[2019-04-06 19:14:53,752] A3C_AGENT_WORKER-Thread-20 INFO:Local step 57500, global step 924622: loss 2.6716
[2019-04-06 19:14:53,778] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 57500, global step 924622: learning rate 0.0000
[2019-04-06 19:15:04,047] A3C_AGENT_WORKER-Thread-5 INFO:Local step 57500, global step 925632: loss 2.7126
[2019-04-06 19:15:04,048] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 57500, global step 925632: learning rate 0.0000
[2019-04-06 19:15:09,463] A3C_AGENT_WORKER-Thread-13 INFO:Local step 57500, global step 926392: loss 2.7394
[2019-04-06 19:15:09,465] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 57500, global step 926392: learning rate 0.0000
[2019-04-06 19:15:11,381] A3C_AGENT_WORKER-Thread-3 INFO:Local step 57500, global step 926661: loss 2.6532
[2019-04-06 19:15:11,381] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 57500, global step 926661: learning rate 0.0000
[2019-04-06 19:15:13,933] A3C_AGENT_WORKER-Thread-2 INFO:Local step 57500, global step 927046: loss 2.7348
[2019-04-06 19:15:13,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 57500, global step 927046: learning rate 0.0000
[2019-04-06 19:15:22,489] A3C_AGENT_WORKER-Thread-4 INFO:Local step 57500, global step 928233: loss 2.7668
[2019-04-06 19:15:22,489] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 57500, global step 928233: learning rate 0.0000
[2019-04-06 19:15:22,970] A3C_AGENT_WORKER-Thread-7 INFO:Local step 58000, global step 928287: loss 0.2736
[2019-04-06 19:15:22,972] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 58000, global step 928287: learning rate 0.0000
[2019-04-06 19:15:27,708] A3C_AGENT_WORKER-Thread-19 INFO:Local step 58500, global step 928929: loss 0.2153
[2019-04-06 19:15:27,709] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 58500, global step 928929: learning rate 0.0000
[2019-04-06 19:15:28,221] A3C_AGENT_WORKER-Thread-18 INFO:Local step 58500, global step 928998: loss 0.2142
[2019-04-06 19:15:28,222] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 58500, global step 928998: learning rate 0.0000
[2019-04-06 19:15:31,801] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.3539009e-15 5.6042516e-16 2.1345707e-13 7.2510332e-15 1.0000000e+00
 9.6454750e-19 8.5533551e-16], sum to 1.0000
[2019-04-06 19:15:31,801] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8385
[2019-04-06 19:15:32,033] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.08180957563697, 0.3274616993294566, 0.0, 1.0, 32551.85485826053], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3002400.0000, 
sim time next is 3004200.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.00609928078497, 0.3208933170664817, 0.0, 1.0, 50754.72086062302], 
processed observation next is [0.0, 0.782608695652174, 0.40720221606648205, 0.6, 0.0, 0.0, 0.6666666666666666, 0.5838416067320807, 0.6069644390221606, 0.0, 1.0, 0.2416891469553477], 
reward next is 0.7583, 
noisyNet noise sample is [array([-1.5366434], dtype=float32), -1.9349608]. 
=============================================
[2019-04-06 19:15:33,166] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4836072e-14 4.7405231e-17 8.9420463e-13 3.3633097e-14 1.0000000e+00
 8.1936314e-19 2.0508641e-16], sum to 1.0000
[2019-04-06 19:15:33,166] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1664
[2019-04-06 19:15:33,233] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 46.0, 0.0, 0.0, 26.0, 25.32728418931422, 0.4001531562246245, 0.0, 1.0, 39310.8965873961], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4154400.0000, 
sim time next is 4156200.0000, 
raw observation next is [-2.5, 48.0, 0.0, 0.0, 26.0, 25.25881304431227, 0.3806642329146626, 0.0, 1.0, 39213.440413691766], 
processed observation next is [0.0, 0.08695652173913043, 0.39335180055401664, 0.48, 0.0, 0.0, 0.6666666666666666, 0.6049010870260224, 0.6268880776382209, 0.0, 1.0, 0.18673066863662746], 
reward next is 0.8133, 
noisyNet noise sample is [array([0.7842169], dtype=float32), -1.1355081]. 
=============================================
[2019-04-06 19:15:35,479] A3C_AGENT_WORKER-Thread-15 INFO:Local step 58500, global step 929901: loss 0.2221
[2019-04-06 19:15:35,479] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 58500, global step 929901: learning rate 0.0000
[2019-04-06 19:15:36,123] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.5552487e-17 1.6674590e-19 1.5570000e-14 1.6817773e-16 1.0000000e+00
 1.0823115e-20 9.1407304e-18], sum to 1.0000
[2019-04-06 19:15:36,123] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2199
[2019-04-06 19:15:36,175] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.9, 89.0, 0.0, 0.0, 26.0, 24.30892611744592, 0.1345760953275573, 0.0, 1.0, 43551.43031052792], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2089800.0000, 
sim time next is 2091600.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.19889966961679, 0.09552433232834034, 0.0, 1.0, 43446.216471869215], 
processed observation next is [1.0, 0.21739130434782608, 0.2908587257617729, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5165749724680658, 0.5318414441094468, 0.0, 1.0, 0.20688674510413912], 
reward next is 0.7931, 
noisyNet noise sample is [array([0.48901886], dtype=float32), 1.5608875]. 
=============================================
[2019-04-06 19:15:36,598] A3C_AGENT_WORKER-Thread-17 INFO:Local step 59000, global step 930050: loss 0.3564
[2019-04-06 19:15:36,600] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 59000, global step 930050: learning rate 0.0000
[2019-04-06 19:15:37,984] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1831653e-16 2.9527711e-16 1.8550823e-12 1.2348351e-15 1.0000000e+00
 1.2658531e-19 3.8914831e-17], sum to 1.0000
[2019-04-06 19:15:37,984] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1031
[2019-04-06 19:15:38,080] A3C_AGENT_WORKER-Thread-14 INFO:Local step 59000, global step 930246: loss 0.3816
[2019-04-06 19:15:38,081] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 59000, global step 930246: learning rate 0.0000
[2019-04-06 19:15:38,348] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.5, 91.0, 0.0, 0.0, 26.0, 23.11919144320184, -0.193361869069363, 0.0, 1.0, 44542.00452495085], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1926000.0000, 
sim time next is 1927800.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 26.0, 23.62478035044371, 0.009829222835690885, 1.0, 1.0, 150047.45305300364], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.6666666666666666, 0.4687316958703092, 0.503276407611897, 1.0, 1.0, 0.7145116812047793], 
reward next is 0.2855, 
noisyNet noise sample is [array([-0.76393116], dtype=float32), 0.9644308]. 
=============================================
[2019-04-06 19:15:44,138] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.0675856e-19 2.3449739e-18 8.8969715e-15 1.0665495e-18 1.0000000e+00
 5.7666433e-23 8.6493107e-20], sum to 1.0000
[2019-04-06 19:15:44,139] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3202
[2019-04-06 19:15:44,208] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 80.0, 0.0, 0.0, 26.0, 25.61142461750777, 0.5079774115859205, 0.0, 1.0, 13912.538064527624], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4431600.0000, 
sim time next is 4433400.0000, 
raw observation next is [2.0, 80.0, 0.0, 0.0, 26.0, 25.57272841516341, 0.4993420097531622, 1.0, 1.0, 9930.72777549967], 
processed observation next is [1.0, 0.30434782608695654, 0.518005540166205, 0.8, 0.0, 0.0, 0.6666666666666666, 0.6310607012636176, 0.6664473365843874, 1.0, 1.0, 0.04728917988333176], 
reward next is 0.9527, 
noisyNet noise sample is [array([-1.4534898], dtype=float32), 0.2970726]. 
=============================================
[2019-04-06 19:15:48,110] A3C_AGENT_WORKER-Thread-6 INFO:Local step 58000, global step 931650: loss 0.2739
[2019-04-06 19:15:48,111] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 58000, global step 931650: learning rate 0.0000
[2019-04-06 19:15:49,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.18705057e-18 4.59086853e-18 3.54921374e-14 4.09938933e-17
 1.00000000e+00 1.16461085e-20 3.94647819e-19], sum to 1.0000
[2019-04-06 19:15:49,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2251
[2019-04-06 19:15:49,785] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 26.0, 25.05310048318311, 0.3887794018504194, 1.0, 1.0, 84693.8973116807], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2232000.0000, 
sim time next is 2233800.0000, 
raw observation next is [-5.0, 69.5, 0.0, 0.0, 26.0, 25.13868880096807, 0.4023537964244205, 0.0, 1.0, 77847.57681208254], 
processed observation next is [1.0, 0.8695652173913043, 0.32409972299168976, 0.695, 0.0, 0.0, 0.6666666666666666, 0.5948907334140058, 0.6341179321414735, 0.0, 1.0, 0.37070274672420256], 
reward next is 0.6293, 
noisyNet noise sample is [array([0.750784], dtype=float32), -0.7275514]. 
=============================================
[2019-04-06 19:15:51,371] A3C_AGENT_WORKER-Thread-8 INFO:Local step 58500, global step 932068: loss 0.1686
[2019-04-06 19:15:51,371] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 58500, global step 932068: learning rate 0.0000
[2019-04-06 19:15:53,633] A3C_AGENT_WORKER-Thread-12 INFO:Local step 58000, global step 932390: loss 0.1973
[2019-04-06 19:15:53,634] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 58000, global step 932390: learning rate 0.0000
[2019-04-06 19:16:01,517] A3C_AGENT_WORKER-Thread-16 INFO:Local step 58000, global step 933483: loss 0.3795
[2019-04-06 19:16:01,518] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 58000, global step 933483: learning rate 0.0000
[2019-04-06 19:16:04,861] A3C_AGENT_WORKER-Thread-20 INFO:Local step 58000, global step 933961: loss 0.1464
[2019-04-06 19:16:04,862] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 58000, global step 933961: learning rate 0.0000
[2019-04-06 19:16:08,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8771045e-17 1.8605132e-17 6.5291766e-13 6.2921148e-17 1.0000000e+00
 6.3389881e-20 3.5724545e-18], sum to 1.0000
[2019-04-06 19:16:08,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2781
[2019-04-06 19:16:08,929] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 39.0, 225.0, 46.5, 26.0, 25.74831274672857, 0.3315827060351028, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2548800.0000, 
sim time next is 2550600.0000, 
raw observation next is [1.65, 34.5, 218.0, 22.0, 26.0, 25.73399171508054, 0.3141800160817041, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5083102493074793, 0.345, 0.7266666666666667, 0.02430939226519337, 0.6666666666666666, 0.6444993095900449, 0.6047266720272347, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.570776], dtype=float32), 0.57207066]. 
=============================================
[2019-04-06 19:16:10,600] A3C_AGENT_WORKER-Thread-5 INFO:Local step 58000, global step 934775: loss 0.3459
[2019-04-06 19:16:10,600] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 58000, global step 934775: learning rate 0.0000
[2019-04-06 19:16:10,891] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [4.4779737e-18 5.8253124e-19 2.6344056e-13 6.1216487e-17 1.0000000e+00
 5.6969254e-20 9.9091522e-19], sum to 1.0000
[2019-04-06 19:16:10,891] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3093
[2019-04-06 19:16:10,959] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.5, 77.0, 100.0, 675.0, 26.0, 26.12956698453755, 0.4860433475144302, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3749400.0000, 
sim time next is 3751200.0000, 
raw observation next is [-3.0, 77.0, 105.5, 722.0, 26.0, 26.22033247025841, 0.5171322371897314, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.77, 0.3516666666666667, 0.7977900552486188, 0.6666666666666666, 0.6850277058548674, 0.6723774123965772, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.35660642], dtype=float32), 0.55361295]. 
=============================================
[2019-04-06 19:16:13,767] A3C_AGENT_WORKER-Thread-19 INFO:Local step 59000, global step 935230: loss 0.3511
[2019-04-06 19:16:13,767] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 59000, global step 935230: learning rate 0.0000
[2019-04-06 19:16:15,931] A3C_AGENT_WORKER-Thread-18 INFO:Local step 59000, global step 935578: loss 0.3544
[2019-04-06 19:16:15,935] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 59000, global step 935578: learning rate 0.0000
[2019-04-06 19:16:16,699] A3C_AGENT_WORKER-Thread-13 INFO:Local step 58000, global step 935720: loss 0.2857
[2019-04-06 19:16:16,700] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 58000, global step 935720: learning rate 0.0000
[2019-04-06 19:16:17,268] A3C_AGENT_WORKER-Thread-3 INFO:Local step 58000, global step 935819: loss 0.2849
[2019-04-06 19:16:17,269] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 58000, global step 935819: learning rate 0.0000
[2019-04-06 19:16:17,384] A3C_AGENT_WORKER-Thread-2 INFO:Local step 58000, global step 935837: loss 0.3198
[2019-04-06 19:16:17,385] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 58000, global step 935837: learning rate 0.0000
[2019-04-06 19:16:17,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:16:17,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:16:17,664] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run22
[2019-04-06 19:16:19,334] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:16:19,334] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:16:19,338] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run22
[2019-04-06 19:16:21,852] A3C_AGENT_WORKER-Thread-15 INFO:Local step 59000, global step 936447: loss 0.3367
[2019-04-06 19:16:21,853] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 59000, global step 936447: learning rate 0.0000
[2019-04-06 19:16:21,862] A3C_AGENT_WORKER-Thread-7 INFO:Local step 58500, global step 936449: loss 0.2680
[2019-04-06 19:16:21,875] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 58500, global step 936449: learning rate 0.0000
[2019-04-06 19:16:24,961] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.3429714e-16 3.1859166e-17 8.2880111e-13 1.0768821e-15 1.0000000e+00
 1.7782617e-18 1.9537846e-17], sum to 1.0000
[2019-04-06 19:16:24,962] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6602
[2019-04-06 19:16:25,168] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 54.0, 221.5, 212.0, 26.0, 25.03374196044328, 0.3227336915688491, 0.0, 1.0, 6238.399902571663], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2379600.0000, 
sim time next is 2381400.0000, 
raw observation next is [-0.3, 53.0, 191.0, 0.0, 26.0, 24.93894207320054, 0.2907654882471321, 0.0, 1.0, 41313.27829596607], 
processed observation next is [0.0, 0.5652173913043478, 0.4542936288088643, 0.53, 0.6366666666666667, 0.0, 0.6666666666666666, 0.5782451727667116, 0.5969218294157107, 0.0, 1.0, 0.19672989664745746], 
reward next is 0.8033, 
noisyNet noise sample is [array([0.93960935], dtype=float32), -1.5459175]. 
=============================================
[2019-04-06 19:16:29,055] A3C_AGENT_WORKER-Thread-4 INFO:Local step 58000, global step 937434: loss 0.3394
[2019-04-06 19:16:29,055] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 58000, global step 937434: learning rate 0.0000
[2019-04-06 19:16:37,641] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2726178e-14 1.5083588e-15 3.4811268e-12 9.3898007e-15 1.0000000e+00
 2.2646309e-18 5.4702304e-17], sum to 1.0000
[2019-04-06 19:16:37,641] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0001
[2019-04-06 19:16:37,764] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.5, 57.5, 6.0, 99.0, 26.0, 25.05515923606761, 0.3403489332055329, 0.0, 1.0, 38284.69373341822], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3000600.0000, 
sim time next is 3002400.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.08180957563697, 0.3274616993294566, 0.0, 1.0, 32551.85485826053], 
processed observation next is [0.0, 0.782608695652174, 0.40720221606648205, 0.6, 0.0, 0.0, 0.6666666666666666, 0.5901507979697476, 0.6091538997764855, 0.0, 1.0, 0.15500883265838347], 
reward next is 0.8450, 
noisyNet noise sample is [array([-0.6018364], dtype=float32), -0.35625654]. 
=============================================
[2019-04-06 19:16:37,863] A3C_AGENT_WORKER-Thread-8 INFO:Local step 59000, global step 938695: loss 0.2946
[2019-04-06 19:16:37,869] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 59000, global step 938695: learning rate 0.0000
[2019-04-06 19:16:37,936] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.2534200e-15 6.7542952e-16 7.4989277e-13 1.5974660e-14 1.0000000e+00
 2.5191990e-18 1.7837258e-16], sum to 1.0000
[2019-04-06 19:16:37,937] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2135
[2019-04-06 19:16:37,967] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 39.5, 84.0, 673.0, 26.0, 25.12733424884191, 0.366575038564407, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3079800.0000, 
sim time next is 3081600.0000, 
raw observation next is [1.0, 40.0, 70.5, 579.5, 26.0, 25.19838181596482, 0.3613957298244097, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.4903047091412743, 0.4, 0.235, 0.6403314917127072, 0.6666666666666666, 0.5998651513304015, 0.6204652432748032, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7150097], dtype=float32), 0.6909573]. 
=============================================
[2019-04-06 19:16:38,790] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4345486e-17 1.4255584e-17 1.4484776e-13 1.2237115e-16 1.0000000e+00
 2.4366911e-21 2.1858718e-19], sum to 1.0000
[2019-04-06 19:16:38,790] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4602
[2019-04-06 19:16:38,884] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.5, 50.5, 122.0, 833.0, 26.0, 26.544017036968, 0.4747866553543674, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4620600.0000, 
sim time next is 4622400.0000, 
raw observation next is [3.0, 49.0, 121.0, 846.0, 26.0, 26.7252412766721, 0.744941997322837, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5457063711911359, 0.49, 0.4033333333333333, 0.9348066298342541, 0.6666666666666666, 0.7271034397226751, 0.7483139991076123, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.83976644], dtype=float32), 0.64481086]. 
=============================================
[2019-04-06 19:16:44,163] A3C_AGENT_WORKER-Thread-6 INFO:Local step 58500, global step 939642: loss 0.3120
[2019-04-06 19:16:44,163] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 58500, global step 939642: learning rate 0.0000
[2019-04-06 19:16:46,493] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 19:16:46,494] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:16:46,494] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:16:46,496] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:16:46,497] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:16:46,499] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run48
[2019-04-06 19:16:46,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run48
[2019-04-06 19:16:46,539] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:16:46,561] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:16:46,563] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run48
[2019-04-06 19:18:51,858] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 19:19:31,095] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 19:19:35,081] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 19:19:36,129] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 940000, evaluation results [940000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 19:19:45,857] A3C_AGENT_WORKER-Thread-12 INFO:Local step 58500, global step 940914: loss 0.2945
[2019-04-06 19:19:45,859] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 58500, global step 940914: learning rate 0.0000
[2019-04-06 19:19:47,963] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.1090974e-16 2.9283845e-16 3.2892643e-12 8.7231908e-15 1.0000000e+00
 4.9061958e-17 5.8316800e-16], sum to 1.0000
[2019-04-06 19:19:47,963] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6474
[2019-04-06 19:19:48,046] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-13.5, 66.0, 0.0, 0.0, 26.0, 23.47564094892818, -0.0444622172679193, 0.0, 1.0, 43422.17925539488], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3997800.0000, 
sim time next is 3999600.0000, 
raw observation next is [-14.0, 69.0, 0.0, 0.0, 26.0, 23.38155321515822, -0.06579972353448021, 0.0, 1.0, 43099.14786803343], 
processed observation next is [1.0, 0.30434782608695654, 0.07479224376731301, 0.69, 0.0, 0.0, 0.6666666666666666, 0.4484627679298517, 0.4780667588218399, 0.0, 1.0, 0.20523403746682586], 
reward next is 0.7948, 
noisyNet noise sample is [array([-0.55857664], dtype=float32), -0.18609275]. 
=============================================
[2019-04-06 19:19:48,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:19:48,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:19:48,644] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run22
[2019-04-06 19:19:50,943] A3C_AGENT_WORKER-Thread-16 INFO:Local step 58500, global step 941400: loss 0.2862
[2019-04-06 19:19:50,944] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 58500, global step 941400: learning rate 0.0000
[2019-04-06 19:19:52,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:19:52,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:19:52,232] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run22
[2019-04-06 19:19:57,967] A3C_AGENT_WORKER-Thread-20 INFO:Local step 58500, global step 942028: loss 0.2424
[2019-04-06 19:19:57,968] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 58500, global step 942028: learning rate 0.0000
[2019-04-06 19:20:01,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:20:01,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:20:01,552] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run22
[2019-04-06 19:20:06,339] A3C_AGENT_WORKER-Thread-5 INFO:Local step 58500, global step 942808: loss 0.3572
[2019-04-06 19:20:06,339] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 58500, global step 942808: learning rate 0.0000
[2019-04-06 19:20:07,607] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6165213e-18 1.2307695e-19 2.3120417e-15 2.8665194e-19 1.0000000e+00
 4.2811248e-23 9.5820206e-21], sum to 1.0000
[2019-04-06 19:20:07,608] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1454
[2019-04-06 19:20:07,791] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 92.0, 93.0, 511.5, 26.0, 26.00457841728247, 0.606461344494508, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3229200.0000, 
sim time next is 3231000.0000, 
raw observation next is [-3.0, 92.0, 101.0, 653.0, 26.0, 26.17344068649289, 0.6515067193470717, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.92, 0.33666666666666667, 0.7215469613259669, 0.6666666666666666, 0.6811200572077407, 0.7171689064490239, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.08276588], dtype=float32), -1.601899]. 
=============================================
[2019-04-06 19:20:07,795] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[88.86412]
 [89.1243 ]
 [89.14218]
 [88.78607]
 [88.15435]], R is [[89.00740051]
 [89.11732483]
 [89.22615051]
 [89.33389282]
 [89.37528229]].
[2019-04-06 19:20:08,407] A3C_AGENT_WORKER-Thread-7 INFO:Local step 59000, global step 943005: loss 0.3512
[2019-04-06 19:20:08,408] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 59000, global step 943005: learning rate 0.0000
[2019-04-06 19:20:15,502] A3C_AGENT_WORKER-Thread-3 INFO:Local step 58500, global step 943650: loss 0.2993
[2019-04-06 19:20:15,503] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 58500, global step 943650: learning rate 0.0000
[2019-04-06 19:20:18,362] A3C_AGENT_WORKER-Thread-2 INFO:Local step 58500, global step 943924: loss 0.3313
[2019-04-06 19:20:18,381] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 58500, global step 943925: learning rate 0.0000
[2019-04-06 19:20:20,250] A3C_AGENT_WORKER-Thread-13 INFO:Local step 58500, global step 944136: loss 0.1661
[2019-04-06 19:20:20,250] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 58500, global step 944136: learning rate 0.0000
[2019-04-06 19:20:26,167] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:20:26,167] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:20:26,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run22
[2019-04-06 19:20:29,242] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4752466e-18 7.5043707e-19 1.9966250e-14 3.1995938e-17 1.0000000e+00
 1.1573470e-21 8.7713229e-19], sum to 1.0000
[2019-04-06 19:20:29,242] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0501
[2019-04-06 19:20:29,301] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 60.0, 113.5, 798.5, 26.0, 26.57345040190001, 0.6404826430591312, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3841200.0000, 
sim time next is 3843000.0000, 
raw observation next is [-1.0, 60.0, 117.0, 822.0, 26.0, 26.49444707482614, 0.6394970301875124, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4349030470914128, 0.6, 0.39, 0.9082872928176795, 0.6666666666666666, 0.7078705895688451, 0.7131656767291709, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1706547], dtype=float32), -1.8910197]. 
=============================================
[2019-04-06 19:20:29,306] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[86.57038 ]
 [86.51437 ]
 [86.843216]
 [86.99444 ]
 [87.026375]], R is [[86.91452026]
 [87.04537964]
 [87.17492676]
 [87.30317688]
 [87.43014526]].
[2019-04-06 19:20:31,240] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1597886e-18 2.1481045e-18 1.4116234e-14 2.3198568e-18 1.0000000e+00
 4.8062263e-22 1.5170858e-20], sum to 1.0000
[2019-04-06 19:20:31,241] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5613
[2019-04-06 19:20:31,365] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.15, 91.0, 0.0, 0.0, 26.0, 24.34891918321836, 0.1365266343467615, 0.0, 1.0, 41210.99484934915], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 91800.0000, 
sim time next is 93600.0000, 
raw observation next is [-1.7, 91.0, 0.0, 0.0, 26.0, 24.24484456415385, 0.123461045069995, 0.0, 1.0, 41806.345971288014], 
processed observation next is [1.0, 0.08695652173913043, 0.4155124653739613, 0.91, 0.0, 0.0, 0.6666666666666666, 0.5204037136794876, 0.5411536816899983, 0.0, 1.0, 0.19907783795851436], 
reward next is 0.8009, 
noisyNet noise sample is [array([0.4471378], dtype=float32), 1.2596426]. 
=============================================
[2019-04-06 19:20:38,141] A3C_AGENT_WORKER-Thread-4 INFO:Local step 58500, global step 945739: loss 0.2894
[2019-04-06 19:20:38,142] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 58500, global step 945739: learning rate 0.0000
[2019-04-06 19:20:41,808] A3C_AGENT_WORKER-Thread-6 INFO:Local step 59000, global step 946217: loss 0.2639
[2019-04-06 19:20:41,813] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 59000, global step 946218: learning rate 0.0000
[2019-04-06 19:20:50,152] A3C_AGENT_WORKER-Thread-12 INFO:Local step 59000, global step 947493: loss 0.2985
[2019-04-06 19:20:50,165] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 59000, global step 947493: learning rate 0.0000
[2019-04-06 19:20:54,463] A3C_AGENT_WORKER-Thread-16 INFO:Local step 59000, global step 948098: loss 0.2825
[2019-04-06 19:20:54,468] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 59000, global step 948098: learning rate 0.0000
[2019-04-06 19:20:54,764] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.2020561e-16 4.3232988e-17 1.9547315e-13 1.1015537e-15 1.0000000e+00
 1.0893744e-19 2.3112632e-17], sum to 1.0000
[2019-04-06 19:20:54,765] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3088
[2019-04-06 19:20:54,921] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [9.5, 26.0, 0.0, 0.0, 26.0, 25.50675110261584, 0.3559049823061033, 0.0, 1.0, 22331.49899530163], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3648600.0000, 
sim time next is 3650400.0000, 
raw observation next is [10.0, 25.0, 0.0, 0.0, 26.0, 25.50097556096551, 0.3653154319510698, 0.0, 1.0, 33541.87004329206], 
processed observation next is [0.0, 0.2608695652173913, 0.739612188365651, 0.25, 0.0, 0.0, 0.6666666666666666, 0.6250812967471259, 0.6217718106503566, 0.0, 1.0, 0.15972319068234314], 
reward next is 0.8403, 
noisyNet noise sample is [array([-1.0635309], dtype=float32), -0.2637272]. 
=============================================
[2019-04-06 19:20:57,674] A3C_AGENT_WORKER-Thread-20 INFO:Local step 59000, global step 948605: loss 0.2716
[2019-04-06 19:20:57,675] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 59000, global step 948605: learning rate 0.0000
[2019-04-06 19:20:59,570] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:20:59,570] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:20:59,574] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run22
[2019-04-06 19:21:03,526] A3C_AGENT_WORKER-Thread-5 INFO:Local step 59000, global step 949487: loss 0.3232
[2019-04-06 19:21:03,527] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 59000, global step 949487: learning rate 0.0000
[2019-04-06 19:21:09,030] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6093876e-15 6.1683464e-16 3.7539008e-12 1.5040073e-14 1.0000000e+00
 2.8847619e-19 4.4034083e-17], sum to 1.0000
[2019-04-06 19:21:09,031] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2467
[2019-04-06 19:21:09,068] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 37.0, 114.0, 544.0, 26.0, 25.36455317130548, 0.4485332761531703, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4204800.0000, 
sim time next is 4206600.0000, 
raw observation next is [2.5, 38.5, 68.0, 550.0, 26.0, 25.47476244655589, 0.4584554063696133, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5318559556786704, 0.385, 0.22666666666666666, 0.6077348066298343, 0.6666666666666666, 0.6228968705463241, 0.6528184687898712, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.331658], dtype=float32), -1.2169322]. 
=============================================
[2019-04-06 19:21:10,835] A3C_AGENT_WORKER-Thread-3 INFO:Local step 59000, global step 950722: loss 0.2572
[2019-04-06 19:21:10,850] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 59000, global step 950722: learning rate 0.0000
[2019-04-06 19:21:11,988] A3C_AGENT_WORKER-Thread-2 INFO:Local step 59000, global step 950888: loss 0.2515
[2019-04-06 19:21:11,988] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 59000, global step 950888: learning rate 0.0000
[2019-04-06 19:21:14,375] A3C_AGENT_WORKER-Thread-13 INFO:Local step 59000, global step 951284: loss 0.2675
[2019-04-06 19:21:14,381] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 59000, global step 951284: learning rate 0.0000
[2019-04-06 19:21:23,055] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:21:23,055] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:21:23,059] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run22
[2019-04-06 19:21:24,281] A3C_AGENT_WORKER-Thread-4 INFO:Local step 59000, global step 952829: loss 0.3435
[2019-04-06 19:21:24,286] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 59000, global step 952829: learning rate 0.0000
[2019-04-06 19:21:32,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:21:32,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:21:32,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run22
[2019-04-06 19:21:35,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:21:35,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:21:35,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run22
[2019-04-06 19:21:40,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:21:40,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:21:40,528] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run22
[2019-04-06 19:21:45,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:21:45,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:21:45,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run22
[2019-04-06 19:21:46,141] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8118055e-19 1.2115344e-21 2.0024018e-15 1.0126323e-17 1.0000000e+00
 3.2091202e-22 1.3488969e-20], sum to 1.0000
[2019-04-06 19:21:46,141] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9822
[2019-04-06 19:21:46,156] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [13.8, 100.0, 77.0, 0.0, 26.0, 24.7326025758897, 0.4469563113689781, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1261800.0000, 
sim time next is 1263600.0000, 
raw observation next is [13.8, 100.0, 64.0, 0.0, 26.0, 24.72645791493686, 0.4380756783040398, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.844875346260388, 1.0, 0.21333333333333335, 0.0, 0.6666666666666666, 0.5605381595780715, 0.6460252261013466, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.864637], dtype=float32), -0.068258256]. 
=============================================
[2019-04-06 19:21:54,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:21:54,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:21:54,688] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run22
[2019-04-06 19:21:55,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:21:55,266] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:21:55,271] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run22
[2019-04-06 19:21:56,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:21:56,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:21:56,628] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run22
[2019-04-06 19:22:06,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:22:06,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:22:06,910] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run22
[2019-04-06 19:22:07,118] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1622782e-17 1.6120874e-18 1.5063786e-14 5.0564128e-18 1.0000000e+00
 3.1859724e-20 7.3759737e-19], sum to 1.0000
[2019-04-06 19:22:07,118] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7500
[2019-04-06 19:22:07,257] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.5, 44.0, 89.0, 694.5, 26.0, 25.47943764613223, 0.4482690677246429, 1.0, 1.0, 100888.95712585753], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 306000.0000, 
sim time next is 307800.0000, 
raw observation next is [-9.5, 44.0, 95.0, 631.0, 26.0, 26.15371299881651, 0.5193687668123476, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.1994459833795014, 0.44, 0.31666666666666665, 0.6972375690607735, 0.6666666666666666, 0.6794760832347091, 0.6731229222707825, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4905407], dtype=float32), -1.4474741]. 
=============================================
[2019-04-06 19:22:21,038] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 19:22:21,038] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:22:21,038] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:22:21,040] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run49
[2019-04-06 19:22:21,059] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:22:21,059] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:22:21,063] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run49
[2019-04-06 19:22:21,085] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:22:21,086] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:22:21,088] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run49
[2019-04-06 19:24:30,643] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 19:25:10,666] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 19:25:13,845] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 19:25:14,882] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 960000, evaluation results [960000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 19:25:42,201] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4002013e-16 9.8976679e-19 2.0575347e-14 7.6889654e-17 1.0000000e+00
 3.2383174e-20 1.6463933e-18], sum to 1.0000
[2019-04-06 19:25:42,201] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6456
[2019-04-06 19:25:42,619] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.05, 63.0, 89.0, 38.0, 26.0, 24.84901334532915, 0.2076126341216319, 0.0, 1.0, 48652.290698609024], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 646200.0000, 
sim time next is 648000.0000, 
raw observation next is [-2.7, 61.0, 100.5, 69.0, 26.0, 24.87410867992033, 0.2233109228409196, 0.0, 1.0, 42239.6464960571], 
processed observation next is [0.0, 0.5217391304347826, 0.38781163434903054, 0.61, 0.335, 0.07624309392265194, 0.6666666666666666, 0.5728423899933608, 0.5744369742803065, 0.0, 1.0, 0.2011411737907481], 
reward next is 0.7989, 
noisyNet noise sample is [array([-0.41661912], dtype=float32), -0.29754302]. 
=============================================
[2019-04-06 19:25:42,622] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[76.19765]
 [76.11574]
 [76.27313]
 [75.8406 ]
 [76.36435]], R is [[76.0332489 ]
 [76.04124451]
 [76.12858582]
 [75.95146179]
 [76.19194794]].
[2019-04-06 19:25:47,569] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.77838956e-19 1.05152085e-19 2.23179523e-16 9.34469081e-18
 1.00000000e+00 3.12959225e-24 8.94851095e-21], sum to 1.0000
[2019-04-06 19:25:47,570] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7403
[2019-04-06 19:25:47,617] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 95.0, 72.0, 0.0, 26.0, 25.94363271677675, 0.5004952129386699, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1420200.0000, 
sim time next is 1422000.0000, 
raw observation next is [0.0, 95.0, 81.0, 0.0, 26.0, 25.86656648465155, 0.4873875621119479, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.46260387811634357, 0.95, 0.27, 0.0, 0.6666666666666666, 0.6555472070542958, 0.6624625207039826, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0929599], dtype=float32), -0.14374015]. 
=============================================
[2019-04-06 19:25:47,629] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[91.691025]
 [91.88249 ]
 [91.98266 ]
 [92.255325]
 [92.32992 ]], R is [[91.2629776 ]
 [91.35034943]
 [91.43684387]
 [91.5224762 ]
 [91.60725403]].
[2019-04-06 19:26:16,211] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.8176520e-15 3.8544592e-17 5.3613689e-13 5.9657886e-15 1.0000000e+00
 6.7298042e-18 2.8016045e-17], sum to 1.0000
[2019-04-06 19:26:16,211] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1255
[2019-04-06 19:26:16,228] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 26.0, 23.58357639551268, 0.1641455987682474, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1231200.0000, 
sim time next is 1233000.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 26.0, 23.54161122248833, 0.1569648596506685, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.8781163434903049, 0.96, 0.0, 0.0, 0.6666666666666666, 0.46180093520736093, 0.5523216198835562, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5042408], dtype=float32), -0.5405591]. 
=============================================
[2019-04-06 19:26:16,272] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[71.82966]
 [71.84081]
 [71.72913]
 [71.63335]
 [71.5037 ]], R is [[72.0018692 ]
 [72.28185272]
 [72.55903625]
 [72.83345032]
 [73.1051178 ]].
[2019-04-06 19:26:33,652] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3576695e-20 1.3275986e-21 1.0106458e-15 4.7285981e-19 1.0000000e+00
 9.4857791e-23 2.0985407e-21], sum to 1.0000
[2019-04-06 19:26:33,652] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3041
[2019-04-06 19:26:33,725] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [10.5, 77.0, 0.0, 0.0, 26.0, 25.65098694417057, 0.6423447411558288, 0.0, 1.0, 34970.96903034316], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1126800.0000, 
sim time next is 1128600.0000, 
raw observation next is [10.25, 78.0, 0.0, 0.0, 26.0, 25.65927336624772, 0.6394019976682043, 0.0, 1.0, 22143.912309993393], 
processed observation next is [0.0, 0.043478260869565216, 0.7465373961218837, 0.78, 0.0, 0.0, 0.6666666666666666, 0.6382727805206434, 0.7131339992227348, 0.0, 1.0, 0.10544720147615902], 
reward next is 0.8946, 
noisyNet noise sample is [array([0.54897654], dtype=float32), -2.27452]. 
=============================================
[2019-04-06 19:26:51,952] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.6323528e-18 1.0484452e-18 6.2935287e-14 7.1239971e-18 1.0000000e+00
 9.3256956e-21 5.0028969e-20], sum to 1.0000
[2019-04-06 19:26:51,952] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6772
[2019-04-06 19:26:52,003] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.5, 48.5, 109.0, 764.0, 26.0, 26.54249672606654, 0.6209665376933992, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3407400.0000, 
sim time next is 3409200.0000, 
raw observation next is [3.0, 49.0, 112.0, 784.0, 26.0, 26.62958541066947, 0.619334266600129, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.5457063711911359, 0.49, 0.37333333333333335, 0.8662983425414365, 0.6666666666666666, 0.7191321175557892, 0.7064447555333763, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.01902361], dtype=float32), -0.015500915]. 
=============================================
[2019-04-06 19:26:52,160] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4004455e-18 2.6949524e-19 1.0347903e-15 2.4520055e-18 1.0000000e+00
 1.5655344e-22 2.9057559e-20], sum to 1.0000
[2019-04-06 19:26:52,160] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4755
[2019-04-06 19:26:52,216] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [10.0, 79.0, 0.0, 0.0, 26.0, 25.64832861728629, 0.6312939582167555, 0.0, 1.0, 24281.712778888497], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1130400.0000, 
sim time next is 1132200.0000, 
raw observation next is [10.55, 78.0, 0.0, 0.0, 26.0, 25.63017950017051, 0.6302402082386934, 0.0, 1.0, 30272.086207263037], 
processed observation next is [0.0, 0.08695652173913043, 0.754847645429363, 0.78, 0.0, 0.0, 0.6666666666666666, 0.6358482916808758, 0.7100800694128978, 0.0, 1.0, 0.14415279146315732], 
reward next is 0.8558, 
noisyNet noise sample is [array([0.28605455], dtype=float32), -1.2348945]. 
=============================================
[2019-04-06 19:26:58,136] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2760704e-16 1.0514176e-17 6.3051832e-14 1.0911197e-14 1.0000000e+00
 1.0913959e-19 1.4777892e-18], sum to 1.0000
[2019-04-06 19:26:58,136] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2751
[2019-04-06 19:26:58,269] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 25.0946703603187, 0.5138785082666822, 0.0, 1.0, 146751.853147859], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3529800.0000, 
sim time next is 3531600.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 25.66606020238242, 0.610482349911705, 0.0, 1.0, 53986.79891827159], 
processed observation next is [1.0, 0.9130434782608695, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.6388383501985349, 0.703494116637235, 0.0, 1.0, 0.2570799948489123], 
reward next is 0.7429, 
noisyNet noise sample is [array([1.6739975], dtype=float32), -2.9328265]. 
=============================================
[2019-04-06 19:27:09,648] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0175051e-19 3.2398390e-19 1.3729344e-14 1.7488375e-17 1.0000000e+00
 3.5870586e-22 5.5404250e-21], sum to 1.0000
[2019-04-06 19:27:09,648] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5860
[2019-04-06 19:27:09,826] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.6, 76.0, 76.0, 85.5, 26.0, 26.16465647312799, 0.5959719874759837, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1587600.0000, 
sim time next is 1589400.0000, 
raw observation next is [7.15, 72.0, 115.0, 136.0, 26.0, 26.33565161450372, 0.6556480824119953, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6606648199445985, 0.72, 0.38333333333333336, 0.15027624309392265, 0.6666666666666666, 0.6946376345419768, 0.7185493608039984, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.971072], dtype=float32), -0.72845626]. 
=============================================
[2019-04-06 19:27:23,703] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1300804e-17 1.8015857e-18 5.9784098e-15 2.8446705e-17 1.0000000e+00
 8.3442070e-21 6.7330615e-19], sum to 1.0000
[2019-04-06 19:27:23,704] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8863
[2019-04-06 19:27:23,907] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.65, 84.5, 28.0, 0.0, 26.0, 24.98691472173229, 0.3342825152569738, 0.0, 1.0, 55964.1043243423], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1787400.0000, 
sim time next is 1789200.0000, 
raw observation next is [-3.9, 82.0, 14.5, 0.0, 26.0, 25.01069075861322, 0.3284738237380634, 0.0, 1.0, 40860.274677392874], 
processed observation next is [0.0, 0.7391304347826086, 0.3545706371191136, 0.82, 0.04833333333333333, 0.0, 0.6666666666666666, 0.5842242298844349, 0.6094912745793545, 0.0, 1.0, 0.1945727365590137], 
reward next is 0.8054, 
noisyNet noise sample is [array([0.28651962], dtype=float32), 0.69482553]. 
=============================================
[2019-04-06 19:27:42,888] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [3.7155461e-17 3.4018726e-17 1.1539000e-13 4.7808599e-16 1.0000000e+00
 8.1470007e-20 8.7523722e-19], sum to 1.0000
[2019-04-06 19:27:42,888] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6862
[2019-04-06 19:27:42,975] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 26.0, 25.56471510241536, 0.5089438780733767, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3360600.0000, 
sim time next is 3362400.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 26.0, 25.40983143502091, 0.5007536710504704, 0.0, 1.0, 63507.32206302204], 
processed observation next is [1.0, 0.9565217391304348, 0.3518005540166205, 0.65, 0.0, 0.0, 0.6666666666666666, 0.617485952918409, 0.6669178903501568, 0.0, 1.0, 0.302415819347724], 
reward next is 0.6976, 
noisyNet noise sample is [array([-0.19594447], dtype=float32), 0.1968406]. 
=============================================
[2019-04-06 19:27:49,139] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.8278517e-18 2.9227680e-18 4.1152185e-15 1.9792675e-17 1.0000000e+00
 9.7309428e-22 6.2357166e-19], sum to 1.0000
[2019-04-06 19:27:49,139] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9132
[2019-04-06 19:27:49,220] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.2, 75.0, 0.0, 0.0, 26.0, 24.789923925979, 0.2670558621913227, 0.0, 1.0, 44235.423081642075], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2242800.0000, 
sim time next is 2244600.0000, 
raw observation next is [-6.45, 76.5, 0.0, 0.0, 26.0, 24.61629171346024, 0.2323281465398602, 0.0, 1.0, 44132.766275784445], 
processed observation next is [1.0, 1.0, 0.28393351800554023, 0.765, 0.0, 0.0, 0.6666666666666666, 0.5513576427883532, 0.5774427155132867, 0.0, 1.0, 0.21015602988468784], 
reward next is 0.7898, 
noisyNet noise sample is [array([-0.0838829], dtype=float32), 1.0026629]. 
=============================================
[2019-04-06 19:28:04,049] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.7750924e-17 8.0635287e-18 5.5010314e-14 1.7507541e-16 1.0000000e+00
 3.2215606e-20 4.1215122e-18], sum to 1.0000
[2019-04-06 19:28:04,049] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6601
[2019-04-06 19:28:04,177] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 54.0, 0.0, 0.0, 26.0, 25.1294078974784, 0.3862018454667015, 1.0, 1.0, 40279.767480266215], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2656800.0000, 
sim time next is 2658600.0000, 
raw observation next is [-0.8999999999999999, 57.0, 0.0, 0.0, 26.0, 25.1682967793044, 0.3463903050165566, 1.0, 1.0, 22158.995394055353], 
processed observation next is [1.0, 0.782608695652174, 0.43767313019390586, 0.57, 0.0, 0.0, 0.6666666666666666, 0.5973580649420333, 0.6154634350055189, 1.0, 1.0, 0.10551902568597787], 
reward next is 0.8945, 
noisyNet noise sample is [array([0.24772501], dtype=float32), -1.6860553]. 
=============================================
[2019-04-06 19:28:04,786] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 19:28:04,786] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:28:04,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:28:04,797] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run50
[2019-04-06 19:28:04,816] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:28:04,819] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:28:04,825] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run50
[2019-04-06 19:28:04,819] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:28:04,843] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:28:04,847] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run50
[2019-04-06 19:30:11,841] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 19:30:51,473] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 19:30:55,487] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 19:30:56,526] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 980000, evaluation results [980000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 19:31:14,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:31:14,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:31:14,864] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run23
[2019-04-06 19:31:16,659] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:31:16,659] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:31:16,663] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run23
[2019-04-06 19:31:49,495] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.64018462e-18 2.22153958e-19 9.39055284e-15 1.34317886e-17
 1.00000000e+00 4.20458899e-22 1.26652022e-18], sum to 1.0000
[2019-04-06 19:31:49,496] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5899
[2019-04-06 19:31:49,568] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 47.0, 125.0, 763.0, 26.0, 26.02832233228444, 0.4537091926109288, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2806200.0000, 
sim time next is 2808000.0000, 
raw observation next is [2.0, 44.0, 151.5, 724.0, 26.0, 25.91324366199191, 0.4422550844405906, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.518005540166205, 0.44, 0.505, 0.8, 0.6666666666666666, 0.6594369718326591, 0.6474183614801968, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.21998939], dtype=float32), -0.09689875]. 
=============================================
[2019-04-06 19:31:49,590] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[83.508995]
 [83.364365]
 [83.17496 ]
 [83.07886 ]
 [83.188995]], R is [[83.92804718]
 [84.08876801]
 [84.24787903]
 [84.40540314]
 [84.56134796]].
[2019-04-06 19:31:54,753] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.7002476e-18 8.0668208e-18 2.2252262e-14 9.0348630e-17 1.0000000e+00
 2.0111774e-20 4.2599879e-19], sum to 1.0000
[2019-04-06 19:31:54,753] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5095
[2019-04-06 19:31:54,819] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 53.0, 0.0, 0.0, 26.0, 25.3324178985343, 0.3596516350606147, 0.0, 1.0, 63022.68357871199], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2845800.0000, 
sim time next is 2847600.0000, 
raw observation next is [2.0, 62.0, 0.0, 0.0, 26.0, 25.22922068946401, 0.3564658685199449, 0.0, 1.0, 53761.18096202467], 
processed observation next is [1.0, 1.0, 0.518005540166205, 0.62, 0.0, 0.0, 0.6666666666666666, 0.6024350574553342, 0.6188219561733149, 0.0, 1.0, 0.2560056236286889], 
reward next is 0.7440, 
noisyNet noise sample is [array([-1.2385588], dtype=float32), -1.1889879]. 
=============================================
[2019-04-06 19:32:00,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:32:00,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:32:00,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run23
[2019-04-06 19:32:03,725] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:32:03,726] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:32:03,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run23
[2019-04-06 19:32:04,382] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.2882005e-18 4.2564001e-18 3.5802944e-13 8.6479422e-16 1.0000000e+00
 2.6576688e-19 4.6667611e-17], sum to 1.0000
[2019-04-06 19:32:04,382] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5299
[2019-04-06 19:32:04,607] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-10.6, 49.0, 94.5, 708.0, 26.0, 25.91230408965574, 0.4385472727950053, 1.0, 1.0, 45888.021193090135], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 302400.0000, 
sim time next is 304200.0000, 
raw observation next is [-10.05, 46.5, 83.0, 758.0, 26.0, 25.40230771378179, 0.3539653708281629, 1.0, 1.0, 47584.8594241491], 
processed observation next is [1.0, 0.5217391304347826, 0.18421052631578946, 0.465, 0.27666666666666667, 0.8375690607734807, 0.6666666666666666, 0.6168589761484826, 0.617988456942721, 1.0, 1.0, 0.2265945686864243], 
reward next is 0.7734, 
noisyNet noise sample is [array([-0.16460334], dtype=float32), -0.17276861]. 
=============================================
[2019-04-06 19:32:06,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.01407590e-18 1.02726035e-19 2.84983261e-15 4.22387471e-17
 1.00000000e+00 1.39134780e-22 1.30020519e-18], sum to 1.0000
[2019-04-06 19:32:06,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9654
[2019-04-06 19:32:06,695] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.5, 25.5, 124.0, 865.0, 26.0, 27.44774137611623, 0.8706036852674708, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5056200.0000, 
sim time next is 5058000.0000, 
raw observation next is [9.0, 25.0, 121.0, 862.5, 26.0, 27.58023112877113, 0.903934497434534, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.7119113573407203, 0.25, 0.4033333333333333, 0.9530386740331491, 0.6666666666666666, 0.7983525940642607, 0.8013114991448447, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0701789], dtype=float32), -1.4403249]. 
=============================================
[2019-04-06 19:32:06,737] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[88.59639]
 [88.12868]
 [87.73311]
 [87.34679]
 [86.99097]], R is [[89.10800171]
 [89.21691895]
 [89.32475281]
 [89.4315033 ]
 [89.53718567]].
[2019-04-06 19:32:09,371] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:32:09,371] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:32:09,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run23
[2019-04-06 19:32:13,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6780778e-16 1.4041427e-17 7.5258620e-14 2.8122600e-16 1.0000000e+00
 1.6704122e-20 1.4336678e-17], sum to 1.0000
[2019-04-06 19:32:13,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7292
[2019-04-06 19:32:13,290] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 26.0, 25.01444909561403, 0.3510856674635332, 0.0, 1.0, 41172.19614697999], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3556800.0000, 
sim time next is 3558600.0000, 
raw observation next is [-4.5, 68.0, 0.0, 0.0, 26.0, 24.97704285625972, 0.3428621942637395, 0.0, 1.0, 41006.23162717834], 
processed observation next is [0.0, 0.17391304347826086, 0.3379501385041552, 0.68, 0.0, 0.0, 0.6666666666666666, 0.5814202380216434, 0.6142873980879132, 0.0, 1.0, 0.1952677696532302], 
reward next is 0.8047, 
noisyNet noise sample is [array([0.10418633], dtype=float32), -1.2923706]. 
=============================================
[2019-04-06 19:32:18,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:32:18,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:32:18,456] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run23
[2019-04-06 19:32:40,205] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.64784497e-14 6.47414725e-15 1.42308795e-11 2.63220926e-14
 1.00000000e+00 2.56714345e-17 2.44766370e-15], sum to 1.0000
[2019-04-06 19:32:40,215] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3539
[2019-04-06 19:32:40,588] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-16.2, 78.0, 0.0, 0.0, 26.0, 21.63934592576606, -0.5058383759504606, 0.0, 1.0, 49268.974654125224], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 370800.0000, 
sim time next is 372600.0000, 
raw observation next is [-16.45, 79.5, 0.0, 0.0, 26.0, 21.92814864295924, -0.3417879679824652, 1.0, 1.0, 151694.2667057717], 
processed observation next is [1.0, 0.30434782608695654, 0.006925207756232688, 0.795, 0.0, 0.0, 0.6666666666666666, 0.3273457202466033, 0.38607067733917827, 1.0, 1.0, 0.7223536509798653], 
reward next is 0.2776, 
noisyNet noise sample is [array([0.7500619], dtype=float32), 0.45255923]. 
=============================================
[2019-04-06 19:32:43,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3711718e-15 5.6392899e-17 3.3212867e-14 3.1813033e-16 1.0000000e+00
 4.0612818e-19 6.3736438e-18], sum to 1.0000
[2019-04-06 19:32:43,473] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9411
[2019-04-06 19:32:43,709] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 53.0, 146.0, 92.0, 26.0, 25.71238119304284, 0.399482745146084, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4266000.0000, 
sim time next is 4267800.0000, 
raw observation next is [3.5, 53.5, 182.0, 131.0, 26.0, 25.69705233066898, 0.4088862482443305, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.5595567867036012, 0.535, 0.6066666666666667, 0.14475138121546963, 0.6666666666666666, 0.6414210275557485, 0.6362954160814435, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2047187], dtype=float32), 0.25796932]. 
=============================================
[2019-04-06 19:32:45,040] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:32:45,040] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:32:45,044] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run23
[2019-04-06 19:33:13,038] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.9000757e-19 2.7856393e-18 1.7812652e-15 5.9508465e-18 1.0000000e+00
 5.0213039e-22 1.3772454e-19], sum to 1.0000
[2019-04-06 19:33:13,038] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6631
[2019-04-06 19:33:13,088] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 26.0, 25.08757048724531, 0.4078658431604851, 0.0, 1.0, 38516.58648339542], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1405800.0000, 
sim time next is 1407600.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 26.0, 25.05670125619244, 0.4145846761176715, 0.0, 1.0, 38613.74028493546], 
processed observation next is [1.0, 0.30434782608695654, 0.44598337950138506, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5880584380160366, 0.6381948920392239, 0.0, 1.0, 0.18387495373778792], 
reward next is 0.8161, 
noisyNet noise sample is [array([-1.2481143], dtype=float32), -0.86382174]. 
=============================================
[2019-04-06 19:33:14,594] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:33:14,595] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:33:14,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run23
[2019-04-06 19:33:23,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:33:23,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:33:23,980] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run23
[2019-04-06 19:33:29,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:33:29,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:33:29,451] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run23
[2019-04-06 19:33:30,204] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-06 19:33:30,204] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:33:30,204] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:33:30,208] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:33:30,209] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:33:30,210] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run51
[2019-04-06 19:33:30,227] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:33:30,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:33:31,432] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run51
[2019-04-06 19:33:31,582] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run51
[2019-04-06 19:35:40,344] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 19:36:15,515] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 19:36:22,521] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 19:36:23,558] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 1000000, evaluation results [1000000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 19:36:30,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:36:30,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:36:30,140] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run23
[2019-04-06 19:36:33,664] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.5200289e-17 4.1842609e-18 3.7544339e-14 1.1811180e-16 1.0000000e+00
 2.6704314e-20 7.6928560e-20], sum to 1.0000
[2019-04-06 19:36:33,664] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6998
[2019-04-06 19:36:33,826] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 79.0, 0.0, 0.0, 26.0, 24.5312327979765, 0.1923709259689241, 0.0, 1.0, 45511.81512317722], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1814400.0000, 
sim time next is 1816200.0000, 
raw observation next is [-5.3, 78.5, 0.0, 0.0, 26.0, 24.44108096562876, 0.1716773118120301, 0.0, 1.0, 45649.807014204154], 
processed observation next is [0.0, 0.0, 0.31578947368421056, 0.785, 0.0, 0.0, 0.6666666666666666, 0.5367567471357301, 0.55722577060401, 0.0, 1.0, 0.21738003340097217], 
reward next is 0.7826, 
noisyNet noise sample is [array([-0.5192776], dtype=float32), -1.4477047]. 
=============================================
[2019-04-06 19:36:41,172] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:36:41,172] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:36:41,175] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run23
[2019-04-06 19:36:56,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:36:56,266] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:36:56,286] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run23
[2019-04-06 19:36:56,685] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.9942970e-17 3.5194711e-18 5.1536846e-14 5.2969385e-16 1.0000000e+00
 1.0069144e-20 9.9676122e-19], sum to 1.0000
[2019-04-06 19:36:56,686] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4125
[2019-04-06 19:36:57,210] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 65.0, 139.0, 0.0, 26.0, 25.1437140952652, 0.2362276968271078, 1.0, 1.0, 47866.01273451695], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 219600.0000, 
sim time next is 221400.0000, 
raw observation next is [-3.95, 63.5, 149.0, 0.0, 26.0, 24.38171928744288, 0.2867574754810047, 1.0, 1.0, 139746.37318987874], 
processed observation next is [1.0, 0.5652173913043478, 0.3531855955678671, 0.635, 0.49666666666666665, 0.0, 0.6666666666666666, 0.53180994062024, 0.5955858251603349, 1.0, 1.0, 0.6654589199518035], 
reward next is 0.3345, 
noisyNet noise sample is [array([-0.91559047], dtype=float32), -0.7434087]. 
=============================================
[2019-04-06 19:36:57,699] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:36:57,699] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:36:57,719] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run23
[2019-04-06 19:36:59,115] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:36:59,115] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:36:59,118] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run23
[2019-04-06 19:37:02,216] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.9383858e-20 9.0861660e-22 1.5757186e-16 4.1062070e-20 1.0000000e+00
 8.5317063e-26 1.6366902e-22], sum to 1.0000
[2019-04-06 19:37:02,216] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8870
[2019-04-06 19:37:02,414] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.3, 96.0, 0.0, 0.0, 26.0, 24.71114540386998, 0.4497393335498525, 0.0, 1.0, 25762.045970028834], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1274400.0000, 
sim time next is 1276200.0000, 
raw observation next is [7.75, 96.0, 0.0, 0.0, 26.0, 24.69607936269874, 0.4428310574420908, 0.0, 1.0, 24383.236539530695], 
processed observation next is [0.0, 0.782608695652174, 0.6772853185595569, 0.96, 0.0, 0.0, 0.6666666666666666, 0.5580066135582283, 0.647610352480697, 0.0, 1.0, 0.1161106501882414], 
reward next is 0.8839, 
noisyNet noise sample is [array([-0.3485641], dtype=float32), -0.9135452]. 
=============================================
[2019-04-06 19:37:03,804] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.5804379e-18 4.2504756e-19 5.2853480e-14 5.0885339e-18 1.0000000e+00
 3.9782268e-23 1.9839067e-19], sum to 1.0000
[2019-04-06 19:37:03,804] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4768
[2019-04-06 19:37:03,864] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.95, 98.0, 0.0, 0.0, 26.0, 25.45624306010877, 0.5845001636298404, 0.0, 1.0, 40615.012640349196], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1294200.0000, 
sim time next is 1296000.0000, 
raw observation next is [4.4, 96.0, 0.0, 0.0, 26.0, 25.41546928089696, 0.5825476653992266, 0.0, 1.0, 47391.23041127069], 
processed observation next is [1.0, 0.0, 0.5844875346260389, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6179557734080801, 0.6941825551330756, 0.0, 1.0, 0.22567252576795568], 
reward next is 0.7743, 
noisyNet noise sample is [array([-0.29084858], dtype=float32), -0.12317014]. 
=============================================
[2019-04-06 19:37:03,867] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[91.21401]
 [91.14245]
 [91.13452]
 [91.31156]
 [91.40374]], R is [[92.0082016 ]
 [91.89471436]
 [91.83053589]
 [91.79227448]
 [91.66533661]].
[2019-04-06 19:37:04,638] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:37:04,638] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:37:04,642] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run23
[2019-04-06 19:37:25,227] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [3.6407891e-18 5.4708506e-19 2.0804427e-14 2.1814080e-18 1.0000000e+00
 2.1535153e-22 3.7405826e-21], sum to 1.0000
[2019-04-06 19:37:25,227] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3584
[2019-04-06 19:37:25,296] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.7, 68.0, 157.5, 112.0, 26.0, 26.60589753698853, 0.6990119448049686, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1591200.0000, 
sim time next is 1593000.0000, 
raw observation next is [8.55, 64.5, 200.0, 88.0, 26.0, 26.78196484575543, 0.7272443855441114, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.6994459833795015, 0.645, 0.6666666666666666, 0.09723756906077348, 0.6666666666666666, 0.7318304038129524, 0.7424147951813705, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4263232], dtype=float32), -0.08082245]. 
=============================================
[2019-04-06 19:37:25,301] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[92.36121 ]
 [92.45627 ]
 [92.42112 ]
 [92.54723 ]
 [92.617905]], R is [[92.29893494]
 [92.37594604]
 [92.45218658]
 [92.52766418]
 [92.60238647]].
[2019-04-06 19:38:17,847] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8014512e-18 5.8376553e-20 1.1262061e-15 1.9515275e-17 1.0000000e+00
 6.2197221e-21 5.2633735e-19], sum to 1.0000
[2019-04-06 19:38:17,848] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8161
[2019-04-06 19:38:17,918] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.6, 65.0, 217.5, 266.0, 26.0, 27.17988971747023, 0.6307766065387382, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1080000.0000, 
sim time next is 1081800.0000, 
raw observation next is [17.45, 60.5, 181.0, 317.0, 26.0, 27.00662362253207, 0.7245839329470888, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.9459833795013851, 0.605, 0.6033333333333334, 0.35027624309392263, 0.6666666666666666, 0.7505519685443393, 0.7415279776490297, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.28092003], dtype=float32), -0.3472027]. 
=============================================
[2019-04-06 19:38:22,482] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5290401e-16 2.6261562e-18 2.5597802e-13 2.9284837e-17 1.0000000e+00
 2.0881607e-20 5.4830707e-20], sum to 1.0000
[2019-04-06 19:38:22,482] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3587
[2019-04-06 19:38:22,589] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 75.0, 0.0, 0.0, 26.0, 24.27174342251567, 0.05338294032933822, 0.0, 1.0, 41349.35272920836], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 702000.0000, 
sim time next is 703800.0000, 
raw observation next is [-3.1, 75.0, 0.0, 0.0, 26.0, 24.36373910836976, 0.05828737094043055, 0.0, 1.0, 41543.4058987512], 
processed observation next is [1.0, 0.13043478260869565, 0.37673130193905824, 0.75, 0.0, 0.0, 0.6666666666666666, 0.5303115923641467, 0.5194291236468102, 0.0, 1.0, 0.19782574237500572], 
reward next is 0.8022, 
noisyNet noise sample is [array([-0.29924512], dtype=float32), -1.1564204]. 
=============================================
[2019-04-06 19:38:25,023] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4086661e-16 3.0504327e-16 1.1031254e-13 3.7191480e-17 1.0000000e+00
 5.8807482e-20 7.7425045e-17], sum to 1.0000
[2019-04-06 19:38:25,023] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2234
[2019-04-06 19:38:25,055] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.3, 29.0, 136.5, 313.0, 26.0, 25.77890676590753, 0.3783041246713987, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2559600.0000, 
sim time next is 2561400.0000, 
raw observation next is [3.3, 29.0, 114.0, 351.0, 26.0, 25.79353914404819, 0.3964741683816709, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.554016620498615, 0.29, 0.38, 0.3878453038674033, 0.6666666666666666, 0.6494615953373492, 0.6321580561272236, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.30456078], dtype=float32), 0.69426304]. 
=============================================
[2019-04-06 19:38:39,242] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1527898e-17 3.8128100e-17 8.4577785e-14 1.1801542e-16 1.0000000e+00
 1.3062641e-20 3.7440305e-17], sum to 1.0000
[2019-04-06 19:38:39,246] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3169
[2019-04-06 19:38:39,363] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.55, 76.0, 29.0, 0.0, 26.0, 25.11637423675631, 0.271188672065881, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 894600.0000, 
sim time next is 896400.0000, 
raw observation next is [1.1, 80.0, 38.5, 0.0, 26.0, 25.43885423202639, 0.2926945109784787, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49307479224376743, 0.8, 0.12833333333333333, 0.0, 0.6666666666666666, 0.6199045193355325, 0.5975648369928263, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.02551822], dtype=float32), 0.84049624]. 
=============================================
[2019-04-06 19:38:40,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6285398e-19 5.4330179e-20 4.6268819e-15 1.6060301e-17 1.0000000e+00
 4.6320422e-21 3.6454292e-19], sum to 1.0000
[2019-04-06 19:38:40,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9436
[2019-04-06 19:38:40,726] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 26.0, 25.28016944841621, 0.5114772088442154, 0.0, 1.0, 47772.213913502324], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1378800.0000, 
sim time next is 1380600.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 26.0, 25.28773107549329, 0.5022253235192805, 0.0, 1.0, 41710.84243184334], 
processed observation next is [1.0, 1.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.6666666666666666, 0.6073109229577742, 0.6674084411730935, 0.0, 1.0, 0.198623059199254], 
reward next is 0.8014, 
noisyNet noise sample is [array([-1.1630367], dtype=float32), -0.6255896]. 
=============================================
[2019-04-06 19:38:54,616] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.5760302e-19 2.7358585e-18 3.0167133e-15 2.6265369e-18 1.0000000e+00
 1.9095763e-22 6.3329697e-20], sum to 1.0000
[2019-04-06 19:38:54,616] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0165
[2019-04-06 19:38:54,693] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [11.35, 54.0, 87.0, 28.0, 26.0, 27.24837126005239, 0.7000306230471485, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1528200.0000, 
sim time next is 1530000.0000, 
raw observation next is [10.5, 58.0, 44.5, 17.0, 26.0, 26.47149336196462, 0.7116778758053354, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.7534626038781165, 0.58, 0.14833333333333334, 0.01878453038674033, 0.6666666666666666, 0.7059577801637182, 0.7372259586017784, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.01094868], dtype=float32), -1.1905857]. 
=============================================
[2019-04-06 19:38:54,702] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[91.26947 ]
 [91.325455]
 [91.63101 ]
 [92.06103 ]
 [92.56    ]], R is [[90.96735382]
 [91.05767822]
 [91.14710236]
 [91.23563385]
 [91.32328033]].
[2019-04-06 19:39:18,493] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 19:39:18,497] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:39:18,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:39:18,521] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:39:18,521] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:39:18,534] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run52
[2019-04-06 19:39:18,554] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:39:18,555] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:39:18,555] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run52
[2019-04-06 19:39:18,579] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run52
[2019-04-06 19:41:25,765] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 19:42:02,344] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 19:42:10,189] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 19:42:11,234] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1020000, evaluation results [1020000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 19:42:12,051] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0315240e-18 1.2958083e-18 4.5665992e-14 6.4990551e-18 1.0000000e+00
 3.0170017e-22 1.6831988e-20], sum to 1.0000
[2019-04-06 19:42:12,051] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4243
[2019-04-06 19:42:12,353] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.5, 60.0, 87.0, 422.0, 26.0, 25.73103673209472, 0.4457944190469241, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3400200.0000, 
sim time next is 3402000.0000, 
raw observation next is [-1.0, 60.0, 93.0, 540.0, 26.0, 26.14295009466814, 0.5053138448538617, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4349030470914128, 0.6, 0.31, 0.5966850828729282, 0.6666666666666666, 0.6785791745556784, 0.6684379482846206, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.26581126], dtype=float32), 0.8496371]. 
=============================================
[2019-04-06 19:42:12,360] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[85.66459 ]
 [85.15621 ]
 [84.277145]
 [82.2734  ]
 [82.4489  ]], R is [[85.89784241]
 [86.03886414]
 [86.17847443]
 [85.92765808]
 [85.86460114]].
[2019-04-06 19:42:20,347] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7786489e-18 2.8480676e-18 1.3735185e-14 1.0090616e-17 1.0000000e+00
 6.0503399e-21 1.0578622e-18], sum to 1.0000
[2019-04-06 19:42:20,347] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7825
[2019-04-06 19:42:20,447] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 49.0, 75.0, 606.0, 26.0, 26.72866249837497, 0.7418040397472011, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3513600.0000, 
sim time next is 3515400.0000, 
raw observation next is [3.0, 49.0, 62.0, 525.0, 26.0, 26.89664160902308, 0.7412004909364104, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.49, 0.20666666666666667, 0.580110497237569, 0.6666666666666666, 0.7413868007519234, 0.7470668303121367, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2669128], dtype=float32), -0.387881]. 
=============================================
[2019-04-06 19:43:13,601] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.9228656e-15 3.0901145e-15 1.1727433e-11 5.7828389e-14 1.0000000e+00
 1.3345132e-15 1.0916479e-15], sum to 1.0000
[2019-04-06 19:43:13,601] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9044
[2019-04-06 19:43:13,676] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.8, 55.0, 0.0, 0.0, 26.0, 23.84699076546807, -0.01007939233728231, 0.0, 1.0, 43786.56626283182], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2430000.0000, 
sim time next is 2431800.0000, 
raw observation next is [-8.1, 58.0, 0.0, 0.0, 26.0, 23.72755340389881, -0.03941634477648954, 0.0, 1.0, 44043.379724865146], 
processed observation next is [0.0, 0.13043478260869565, 0.23822714681440446, 0.58, 0.0, 0.0, 0.6666666666666666, 0.4772961169915675, 0.48686121840783686, 0.0, 1.0, 0.20973037964221497], 
reward next is 0.7903, 
noisyNet noise sample is [array([0.4284972], dtype=float32), 0.67357534]. 
=============================================
[2019-04-06 19:43:20,329] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:43:20,329] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:43:20,332] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run24
[2019-04-06 19:43:25,221] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:43:25,221] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:43:25,225] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run24
[2019-04-06 19:43:25,465] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.0685372e-19 7.7885271e-20 1.9207681e-15 5.8469136e-17 1.0000000e+00
 2.7298913e-21 3.7093679e-19], sum to 1.0000
[2019-04-06 19:43:25,465] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0021
[2019-04-06 19:43:25,529] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 77.0, 105.5, 722.0, 26.0, 26.22033247025841, 0.5171322371897314, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3751200.0000, 
sim time next is 3753000.0000, 
raw observation next is [-3.0, 74.0, 111.0, 769.0, 26.0, 26.34102141964437, 0.5505344807381253, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.74, 0.37, 0.8497237569060774, 0.6666666666666666, 0.6950851183036976, 0.683511493579375, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.9442698], dtype=float32), 0.36578596]. 
=============================================
[2019-04-06 19:43:25,585] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[86.79669 ]
 [86.617455]
 [85.74523 ]
 [84.87032 ]
 [84.0135  ]], R is [[86.79074097]
 [86.9228363 ]
 [87.05361176]
 [87.1230545 ]
 [87.23696899]].
[2019-04-06 19:43:41,995] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0998269e-17 1.3269012e-19 3.7393401e-14 7.2835404e-18 1.0000000e+00
 2.9035400e-20 2.6483895e-18], sum to 1.0000
[2019-04-06 19:43:41,995] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0364
[2019-04-06 19:43:42,142] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 62.0, 188.0, 223.0, 26.0, 25.7298167215263, 0.3624264854868629, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2631600.0000, 
sim time next is 2633400.0000, 
raw observation next is [-3.1, 58.0, 224.0, 171.0, 26.0, 25.73345810005536, 0.3870051961469149, 1.0, 1.0, 43665.46746916317], 
processed observation next is [1.0, 0.4782608695652174, 0.37673130193905824, 0.58, 0.7466666666666667, 0.18895027624309393, 0.6666666666666666, 0.6444548416712799, 0.6290017320489717, 1.0, 1.0, 0.20793079747220558], 
reward next is 0.7921, 
noisyNet noise sample is [array([0.43746075], dtype=float32), 0.832705]. 
=============================================
[2019-04-06 19:43:51,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:43:51,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:43:51,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run24
[2019-04-06 19:43:53,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:43:53,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:43:53,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run24
[2019-04-06 19:43:53,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:43:53,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:43:53,352] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run24
[2019-04-06 19:44:06,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:44:06,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:44:06,080] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run24
[2019-04-06 19:44:30,937] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5132775e-16 6.5636629e-17 2.4935737e-12 1.1611049e-15 1.0000000e+00
 3.3957253e-18 1.6630212e-16], sum to 1.0000
[2019-04-06 19:44:30,937] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4318
[2019-04-06 19:44:31,199] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-11.7, 57.0, 0.0, 0.0, 26.0, 25.70939552143673, 0.4117194497322374, 1.0, 1.0, 48268.832178661774], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 324000.0000, 
sim time next is 325800.0000, 
raw observation next is [-12.0, 60.0, 0.0, 0.0, 26.0, 25.54269067506392, 0.3520670943052243, 1.0, 1.0, 63433.20443249736], 
processed observation next is [1.0, 0.782608695652174, 0.13019390581717452, 0.6, 0.0, 0.0, 0.6666666666666666, 0.6285575562553266, 0.6173556981017415, 1.0, 1.0, 0.30206287824998745], 
reward next is 0.6979, 
noisyNet noise sample is [array([1.4545051], dtype=float32), -1.9028137]. 
=============================================
[2019-04-06 19:44:33,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:44:33,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:44:33,616] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run24
[2019-04-06 19:44:36,963] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.0770712e-19 8.2284263e-20 9.6570872e-16 1.7098253e-17 1.0000000e+00
 1.2979590e-20 6.3023388e-20], sum to 1.0000
[2019-04-06 19:44:36,963] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1121
[2019-04-06 19:44:37,042] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 60.0, 0.0, 0.0, 26.0, 25.29155082583561, 0.4665884804270711, 0.0, 1.0, 65660.7097030285], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3884400.0000, 
sim time next is 3886200.0000, 
raw observation next is [-1.5, 62.5, 0.0, 0.0, 26.0, 25.42754593305239, 0.4622937963814053, 0.0, 1.0, 27609.92687626547], 
processed observation next is [1.0, 1.0, 0.4210526315789474, 0.625, 0.0, 0.0, 0.6666666666666666, 0.6189621610876991, 0.6540979321271351, 0.0, 1.0, 0.1314758422679308], 
reward next is 0.8685, 
noisyNet noise sample is [array([0.07001314], dtype=float32), 0.8342829]. 
=============================================
[2019-04-06 19:44:50,868] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 19:44:50,869] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:44:50,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:44:50,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run53
[2019-04-06 19:44:50,889] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:44:50,892] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:44:50,894] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:44:50,895] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:44:50,900] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run53
[2019-04-06 19:44:50,919] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run53
[2019-04-06 19:45:03,237] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13791814]
[2019-04-06 19:45:03,237] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-4.2, 51.0, 0.0, 0.0, 26.0, 24.94021900161658, 0.3776571584637982, 0.0, 1.0, 101419.91323663485]
[2019-04-06 19:45:03,237] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 19:45:03,238] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [3.6152862e-16 9.4895358e-17 3.8520418e-13 1.2491384e-15 1.0000000e+00
 4.1889703e-19 2.8184770e-17], sampled 0.9553659798918077
[2019-04-06 19:46:54,956] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 19:47:37,850] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 19:47:42,543] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 19:47:43,581] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1040000, evaluation results [1040000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 19:48:12,150] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:48:12,150] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:48:12,154] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run24
[2019-04-06 19:48:23,551] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.0784805e-20 5.1371933e-19 9.5435643e-15 4.9866492e-18 1.0000000e+00
 4.3382554e-22 1.4095017e-20], sum to 1.0000
[2019-04-06 19:48:23,551] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9648
[2019-04-06 19:48:23,663] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.0, 71.0, 0.0, 0.0, 26.0, 25.42597305867709, 0.3864769071404976, 0.0, 1.0, 73609.13301311833], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4330800.0000, 
sim time next is 4332600.0000, 
raw observation next is [3.95, 70.5, 0.0, 0.0, 26.0, 25.66520258531298, 0.4037992180740356, 0.0, 1.0, 13799.68524048654], 
processed observation next is [1.0, 0.13043478260869565, 0.57202216066482, 0.705, 0.0, 0.0, 0.6666666666666666, 0.6387668821094149, 0.6345997393580118, 0.0, 1.0, 0.06571278685945972], 
reward next is 0.9343, 
noisyNet noise sample is [array([0.5986978], dtype=float32), -1.7803442]. 
=============================================
[2019-04-06 19:48:29,186] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:48:29,186] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:48:29,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run24
[2019-04-06 19:48:31,809] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [2.0850744e-18 8.2899938e-19 5.7516431e-14 7.3314626e-17 1.0000000e+00
 2.2620805e-21 1.7687487e-19], sum to 1.0000
[2019-04-06 19:48:31,810] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.9388
[2019-04-06 19:48:32,188] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 58.0, 0.0, 0.0, 26.0, 24.92430726028971, 0.3093458470799302, 1.0, 1.0, 84551.9078587289], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 763200.0000, 
sim time next is 765000.0000, 
raw observation next is [-5.3, 59.5, 0.0, 0.0, 26.0, 25.02808199907029, 0.3206431688471651, 0.0, 1.0, 66144.09084125987], 
processed observation next is [1.0, 0.8695652173913043, 0.31578947368421056, 0.595, 0.0, 0.0, 0.6666666666666666, 0.5856734999225243, 0.6068810562823884, 0.0, 1.0, 0.3149718611488565], 
reward next is 0.6850, 
noisyNet noise sample is [array([1.6803625], dtype=float32), -1.0573324]. 
=============================================
[2019-04-06 19:48:32,191] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[82.83021 ]
 [82.580025]
 [82.75757 ]
 [82.541084]
 [83.04594 ]], R is [[81.39917755]
 [81.18256378]
 [81.21247864]
 [81.07170868]
 [81.26099396]].
[2019-04-06 19:48:32,257] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.93088653e-17 8.52234094e-18 1.96248962e-14 1.36246896e-17
 1.00000000e+00 3.45601755e-21 1.07582935e-18], sum to 1.0000
[2019-04-06 19:48:32,258] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6726
[2019-04-06 19:48:32,665] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.5, 84.5, 124.0, 419.0, 26.0, 24.3176406855364, 0.3488954712996868, 0.0, 1.0, 148650.4777939373], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4782600.0000, 
sim time next is 4784400.0000, 
raw observation next is [-5.0, 77.0, 149.0, 420.0, 26.0, 25.63642003720515, 0.4660650236823513, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.32409972299168976, 0.77, 0.49666666666666665, 0.46408839779005523, 0.6666666666666666, 0.6363683364337623, 0.6553550078941172, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.36428356], dtype=float32), 0.7079792]. 
=============================================
[2019-04-06 19:48:34,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:48:34,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:48:34,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run24
[2019-04-06 19:48:50,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:48:50,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:48:50,128] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run24
[2019-04-06 19:48:54,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:48:54,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:48:54,900] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run24
[2019-04-06 19:49:00,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3763615e-19 2.4194736e-20 4.8832529e-15 2.5987619e-17 1.0000000e+00
 1.0161360e-21 2.1309885e-19], sum to 1.0000
[2019-04-06 19:49:00,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3630
[2019-04-06 19:49:00,755] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.9, 92.0, 0.0, 0.0, 26.0, 25.46946857028155, 0.4658849571797473, 0.0, 1.0, 24754.517237725417], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1474200.0000, 
sim time next is 1476000.0000, 
raw observation next is [2.2, 92.0, 0.0, 0.0, 26.0, 25.34652134048034, 0.4679145625722043, 0.0, 1.0, 64413.78933300252], 
processed observation next is [1.0, 0.08695652173913043, 0.5235457063711911, 0.92, 0.0, 0.0, 0.6666666666666666, 0.612210111706695, 0.6559715208574014, 0.0, 1.0, 0.30673233015715484], 
reward next is 0.6933, 
noisyNet noise sample is [array([-0.3681366], dtype=float32), -0.13101397]. 
=============================================
[2019-04-06 19:49:00,776] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[91.87405]
 [91.7792 ]
 [91.88649]
 [91.69398]
 [91.63189]], R is [[92.15926361]
 [92.11978912]
 [92.19859314]
 [92.09481049]
 [91.97639465]].
[2019-04-06 19:49:01,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:49:01,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:49:01,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run24
[2019-04-06 19:49:06,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3771489e-18 1.2067899e-18 7.1525995e-15 5.5380910e-17 1.0000000e+00
 2.7679890e-20 5.6228274e-20], sum to 1.0000
[2019-04-06 19:49:06,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7260
[2019-04-06 19:49:06,654] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.65, 78.0, 34.0, 296.0, 26.0, 25.0960273584078, 0.2229103724860597, 1.0, 1.0, 20150.119902359304], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 203400.0000, 
sim time next is 205200.0000, 
raw observation next is [-8.4, 78.0, 56.5, 148.0, 26.0, 25.30918009777394, 0.2201754597472716, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.2299168975069252, 0.78, 0.18833333333333332, 0.16353591160220995, 0.6666666666666666, 0.6090983414811616, 0.5733918199157572, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2765987], dtype=float32), -0.8143348]. 
=============================================
[2019-04-06 19:49:06,975] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:49:06,976] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:49:06,992] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run24
[2019-04-06 19:49:11,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:49:11,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:49:11,470] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run24
[2019-04-06 19:49:13,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:49:13,530] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:49:13,812] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run24
[2019-04-06 19:49:15,101] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.6093225e-18 1.7246214e-19 2.1157405e-15 4.9471046e-19 1.0000000e+00
 1.6485016e-22 2.7235477e-20], sum to 1.0000
[2019-04-06 19:49:15,101] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7706
[2019-04-06 19:49:15,167] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 83.0, 0.0, 0.0, 26.0, 24.87162685318082, 0.2682995107074918, 0.0, 1.0, 42442.39598009299], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 855000.0000, 
sim time next is 856800.0000, 
raw observation next is [-3.4, 83.0, 0.0, 0.0, 26.0, 24.81198999606459, 0.2606473548184193, 0.0, 1.0, 41699.48691161441], 
processed observation next is [1.0, 0.9565217391304348, 0.368421052631579, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5676658330053824, 0.5868824516061397, 0.0, 1.0, 0.19856898529340195], 
reward next is 0.8014, 
noisyNet noise sample is [array([0.9365119], dtype=float32), 0.30051142]. 
=============================================
[2019-04-06 19:49:21,775] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.9492797e-17 3.3511618e-18 3.0547501e-14 2.2384714e-16 1.0000000e+00
 6.4547236e-20 2.1509500e-18], sum to 1.0000
[2019-04-06 19:49:21,775] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4129
[2019-04-06 19:49:21,953] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.75, 73.5, 124.0, 0.0, 26.0, 25.30226962965027, 0.2101535619382642, 1.0, 1.0, 23826.02405564401], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 210600.0000, 
sim time next is 212400.0000, 
raw observation next is [-6.2, 72.0, 138.5, 0.0, 26.0, 25.28164876803787, 0.2222122222645382, 1.0, 1.0, 27809.62291120701], 
processed observation next is [1.0, 0.4782608695652174, 0.2908587257617729, 0.72, 0.46166666666666667, 0.0, 0.6666666666666666, 0.6068040640031557, 0.5740707407548461, 1.0, 1.0, 0.13242677576765244], 
reward next is 0.8676, 
noisyNet noise sample is [array([0.66866404], dtype=float32), -0.10879059]. 
=============================================
[2019-04-06 19:49:36,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3437357e-15 2.6532865e-16 1.9837199e-13 7.9464650e-15 1.0000000e+00
 1.4427305e-18 1.9367913e-17], sum to 1.0000
[2019-04-06 19:49:36,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2930
[2019-04-06 19:49:36,329] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.4, 43.0, 0.0, 0.0, 26.0, 24.95991379065343, 0.2562777574081865, 0.0, 1.0, 44804.5421967149], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2401200.0000, 
sim time next is 2403000.0000, 
raw observation next is [-2.9, 42.5, 0.0, 0.0, 26.0, 24.96447782892782, 0.2773626739011987, 0.0, 1.0, 92988.85317573366], 
processed observation next is [0.0, 0.8260869565217391, 0.38227146814404434, 0.425, 0.0, 0.0, 0.6666666666666666, 0.5803731524106516, 0.5924542246337329, 0.0, 1.0, 0.44280406274158884], 
reward next is 0.5572, 
noisyNet noise sample is [array([0.15181975], dtype=float32), 0.7450373]. 
=============================================
[2019-04-06 19:49:36,333] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[74.21749 ]
 [74.3393  ]
 [74.740585]
 [75.00739 ]
 [75.44057 ]], R is [[74.46312714]
 [74.50514221]
 [74.58178711]
 [74.60572052]
 [74.66818237]].
[2019-04-06 19:49:53,194] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7516885e-17 1.2031402e-18 1.5246413e-14 4.9686321e-17 1.0000000e+00
 2.9157685e-22 5.6787862e-20], sum to 1.0000
[2019-04-06 19:49:53,194] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6366
[2019-04-06 19:49:53,362] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.3, 73.0, 102.0, 451.0, 26.0, 25.98020086031194, 0.4309613717150306, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2194200.0000, 
sim time next is 2196000.0000, 
raw observation next is [-5.0, 71.0, 109.5, 225.5, 26.0, 26.01545503245368, 0.4176792926713171, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.32409972299168976, 0.71, 0.365, 0.24917127071823206, 0.6666666666666666, 0.6679545860378067, 0.6392264308904391, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.396586], dtype=float32), -0.02028949]. 
=============================================
[2019-04-06 19:49:53,385] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[86.32148]
 [86.36105]
 [86.24681]
 [85.71482]
 [84.16677]], R is [[85.88991547]
 [86.03101349]
 [86.1707077 ]
 [86.30899811]
 [86.24205017]].
[2019-04-06 19:50:07,366] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.4505181e-17 8.0402421e-19 6.9331193e-15 1.2653274e-18 1.0000000e+00
 1.7106307e-21 2.2937119e-19], sum to 1.0000
[2019-04-06 19:50:07,366] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2709
[2019-04-06 19:50:07,638] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 76.0, 14.5, 0.0, 26.0, 25.61688202177895, 0.2850206967671358, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 720000.0000, 
sim time next is 721800.0000, 
raw observation next is [-2.3, 76.0, 29.0, 0.0, 26.0, 25.62488794825378, 0.2866839568211833, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3988919667590028, 0.76, 0.09666666666666666, 0.0, 0.6666666666666666, 0.6354073290211483, 0.5955613189403944, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02718458], dtype=float32), -0.31231362]. 
=============================================
[2019-04-06 19:50:25,230] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6591117e-23 6.5111766e-22 3.4786422e-17 4.8332745e-21 1.0000000e+00
 9.9174420e-25 5.0289501e-23], sum to 1.0000
[2019-04-06 19:50:25,230] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7489
[2019-04-06 19:50:25,302] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.1, 77.5, 0.0, 0.0, 26.0, 25.82285785317278, 0.598940394872573, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1053000.0000, 
sim time next is 1054800.0000, 
raw observation next is [13.8, 78.0, 0.0, 0.0, 26.0, 25.69417145401271, 0.5729115417073346, 0.0, 1.0, 24024.369995123587], 
processed observation next is [1.0, 0.21739130434782608, 0.844875346260388, 0.78, 0.0, 0.0, 0.6666666666666666, 0.6411809545010593, 0.6909705139024448, 0.0, 1.0, 0.11440176188154089], 
reward next is 0.8856, 
noisyNet noise sample is [array([-1.7358848], dtype=float32), -2.0736392]. 
=============================================
[2019-04-06 19:50:38,653] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 19:50:38,654] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:50:38,654] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:50:38,658] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run54
[2019-04-06 19:50:38,675] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:50:38,681] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:50:38,682] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:50:38,682] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:50:38,688] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run54
[2019-04-06 19:50:38,710] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run54
[2019-04-06 19:51:46,078] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13809417]
[2019-04-06 19:51:46,078] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-5.206290793, 65.37531003, 0.0, 0.0, 26.0, 23.91924167439771, 0.03768655482171192, 0.0, 1.0, 41731.7313815812]
[2019-04-06 19:51:46,079] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 19:51:46,079] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.6735661e-16 4.8087510e-17 2.2547151e-13 7.1142276e-16 1.0000000e+00
 1.9847924e-19 1.1752208e-17], sampled 0.359313659495322
[2019-04-06 19:52:47,726] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 19:53:20,036] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 19:53:31,133] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 19:53:32,170] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 1060000, evaluation results [1060000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 19:53:46,544] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9680682e-19 2.0267976e-19 3.3322242e-15 2.3706707e-18 1.0000000e+00
 8.1232439e-24 3.0930566e-19], sum to 1.0000
[2019-04-06 19:53:46,616] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3997
[2019-04-06 19:53:46,633] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 49.0, 102.0, 781.0, 26.0, 26.62314986513393, 0.7140391882206462, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3508200.0000, 
sim time next is 3510000.0000, 
raw observation next is [3.0, 49.0, 95.0, 734.0, 26.0, 26.75374470256775, 0.7315632060215503, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.49, 0.31666666666666665, 0.8110497237569061, 0.6666666666666666, 0.7294787252139793, 0.7438544020071834, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.50320333], dtype=float32), -0.20270829]. 
=============================================
[2019-04-06 19:53:46,644] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[85.52033 ]
 [85.712776]
 [85.80199 ]
 [85.90036 ]
 [86.010544]], R is [[85.47356415]
 [85.61882782]
 [85.73299408]
 [85.87566376]
 [86.01690674]].
[2019-04-06 19:53:48,376] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.1899002e-20 3.3012271e-22 2.8042804e-15 1.4045973e-18 1.0000000e+00
 2.8343176e-23 2.9393675e-21], sum to 1.0000
[2019-04-06 19:53:48,376] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4379
[2019-04-06 19:53:48,478] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [10.0, 63.0, 80.0, 682.0, 26.0, 26.63091062315612, 0.73076749992746, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1519200.0000, 
sim time next is 1521000.0000, 
raw observation next is [10.8, 57.5, 75.0, 663.0, 26.0, 26.86830389040363, 0.775748981286514, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.7617728531855957, 0.575, 0.25, 0.7325966850828729, 0.6666666666666666, 0.7390253242003025, 0.7585829937621713, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.22384894], dtype=float32), -1.3281155]. 
=============================================
[2019-04-06 19:53:48,557] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[94.56338 ]
 [95.03234 ]
 [95.285484]
 [95.68404 ]
 [95.48648 ]], R is [[94.2088623 ]
 [94.26677704]
 [94.32411194]
 [94.38087463]
 [94.43706512]].
[2019-04-06 19:54:19,700] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8111369e-17 5.0694717e-17 1.5978812e-13 7.1803989e-16 1.0000000e+00
 3.1519313e-20 3.5587440e-18], sum to 1.0000
[2019-04-06 19:54:19,700] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4162
[2019-04-06 19:54:19,766] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.55, 76.5, 0.0, 0.0, 26.0, 24.05536724972026, 0.02238013934827341, 0.0, 1.0, 45191.02294401869], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1906200.0000, 
sim time next is 1908000.0000, 
raw observation next is [-7.8, 78.0, 0.0, 0.0, 26.0, 24.02638410624683, 0.009412502321475011, 0.0, 1.0, 45071.51952957284], 
processed observation next is [1.0, 0.08695652173913043, 0.24653739612188366, 0.78, 0.0, 0.0, 0.6666666666666666, 0.5021986755205692, 0.503137500773825, 0.0, 1.0, 0.21462628347415638], 
reward next is 0.7854, 
noisyNet noise sample is [array([-0.8328896], dtype=float32), 0.77819777]. 
=============================================
[2019-04-06 19:54:19,770] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[77.505196]
 [77.09858 ]
 [76.29382 ]
 [75.83867 ]
 [75.2651  ]], R is [[78.06910706]
 [78.0732193 ]
 [78.07757568]
 [78.08216858]
 [78.08714294]].
[2019-04-06 19:54:47,565] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.8555096e-16 6.7062527e-18 3.3015821e-13 7.1490772e-16 1.0000000e+00
 9.5375298e-21 3.1546875e-19], sum to 1.0000
[2019-04-06 19:54:47,565] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8561
[2019-04-06 19:54:47,620] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.2, 27.0, 0.0, 0.0, 26.0, 25.47924807665508, 0.360046278662041, 0.0, 1.0, 37247.2562084141], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3639600.0000, 
sim time next is 3641400.0000, 
raw observation next is [8.1, 28.0, 0.0, 0.0, 26.0, 25.62408526796207, 0.3754644464955301, 0.0, 1.0, 12243.244670558588], 
processed observation next is [0.0, 0.13043478260869565, 0.6869806094182825, 0.28, 0.0, 0.0, 0.6666666666666666, 0.6353404389968391, 0.62515481549851, 0.0, 1.0, 0.05830116509789804], 
reward next is 0.9417, 
noisyNet noise sample is [array([1.3452593], dtype=float32), -1.4513204]. 
=============================================
[2019-04-06 19:55:13,953] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:55:13,953] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:55:13,970] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run25
[2019-04-06 19:55:15,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:55:15,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:55:15,752] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run25
[2019-04-06 19:55:18,575] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0726804e-17 8.0789845e-18 1.4876062e-13 3.3411817e-17 1.0000000e+00
 1.9985125e-20 4.5319840e-19], sum to 1.0000
[2019-04-06 19:55:18,575] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8601
[2019-04-06 19:55:18,644] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.7, 29.0, 38.5, 83.5, 26.0, 25.75917880379922, 0.3955902279713071, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2566800.0000, 
sim time next is 2568600.0000, 
raw observation next is [1.6, 32.0, 0.0, 0.0, 26.0, 25.66014298769075, 0.1747826764033261, 1.0, 1.0, 3113.4019450384226], 
processed observation next is [1.0, 0.7391304347826086, 0.5069252077562327, 0.32, 0.0, 0.0, 0.6666666666666666, 0.6383452489742293, 0.558260892134442, 1.0, 1.0, 0.014825723547802013], 
reward next is 0.9852, 
noisyNet noise sample is [array([0.78380007], dtype=float32), 1.5615283]. 
=============================================
[2019-04-06 19:55:40,414] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:55:40,414] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:55:40,427] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run25
[2019-04-06 19:55:41,118] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.0586778e-16 3.2256358e-17 2.5708727e-13 2.5173298e-15 1.0000000e+00
 2.2988275e-19 8.5966888e-18], sum to 1.0000
[2019-04-06 19:55:41,119] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3849
[2019-04-06 19:55:41,143] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.5, 40.5, 160.0, 538.0, 26.0, 25.31547419322047, 0.4477573154706787, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4203000.0000, 
sim time next is 4204800.0000, 
raw observation next is [3.0, 37.0, 114.0, 544.0, 26.0, 25.36455317130548, 0.4485332761531703, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.37, 0.38, 0.6011049723756906, 0.6666666666666666, 0.6137127642754567, 0.6495110920510568, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6456477], dtype=float32), 0.79506814]. 
=============================================
[2019-04-06 19:55:48,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:55:48,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:55:48,028] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run25
[2019-04-06 19:55:48,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:55:48,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:55:48,480] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run25
[2019-04-06 19:55:59,898] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:55:59,899] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:55:59,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run25
[2019-04-06 19:56:06,693] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.1397084e-21 4.6073658e-23 7.1114835e-17 3.5392570e-21 1.0000000e+00
 4.2658430e-26 4.7480919e-23], sum to 1.0000
[2019-04-06 19:56:06,694] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6574
[2019-04-06 19:56:06,731] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.8, 99.5, 84.0, 679.0, 26.0, 26.80410052691584, 0.8944369857798359, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3166200.0000, 
sim time next is 3168000.0000, 
raw observation next is [6.6, 99.0, 71.0, 589.0, 26.0, 27.56655343463767, 0.9888030085120922, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.6454293628808865, 0.99, 0.23666666666666666, 0.6508287292817679, 0.6666666666666666, 0.7972127862198057, 0.829601002837364, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0867819], dtype=float32), -0.6228394]. 
=============================================
[2019-04-06 19:56:06,765] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[100.233536]
 [100.40869 ]
 [100.41027 ]
 [100.284515]
 [100.12481 ]], R is [[100.09211731]
 [100.09119415]
 [100.09028625]
 [100.08938599]
 [100.08849335]].
[2019-04-06 19:56:07,177] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-06 19:56:07,177] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:56:07,177] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:56:07,201] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 19:56:07,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:56:07,205] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run55
[2019-04-06 19:56:07,229] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 19:56:07,232] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run55
[2019-04-06 19:56:07,250] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:56:07,258] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run55
[2019-04-06 19:58:18,937] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 19:58:54,558] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 19:58:59,026] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 19:59:00,064] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1080000, evaluation results [1080000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 19:59:15,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4113781e-17 1.5602330e-16 6.9973194e-13 1.5883316e-16 1.0000000e+00
 1.9224503e-19 8.8212575e-18], sum to 1.0000
[2019-04-06 19:59:15,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9601
[2019-04-06 19:59:16,226] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.5, 60.0, 112.0, 100.0, 26.0, 24.88906929851385, 0.2267259318378795, 0.0, 1.0, 35547.58918505093], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 649800.0000, 
sim time next is 651600.0000, 
raw observation next is [-2.3, 59.0, 147.0, 96.5, 26.0, 24.89957619796551, 0.2384969290424512, 0.0, 1.0, 39441.830635911756], 
processed observation next is [0.0, 0.5652173913043478, 0.3988919667590028, 0.59, 0.49, 0.10662983425414364, 0.6666666666666666, 0.5749646831637923, 0.5794989763474837, 0.0, 1.0, 0.18781824112338932], 
reward next is 0.8122, 
noisyNet noise sample is [array([-0.11789096], dtype=float32), -0.35070133]. 
=============================================
[2019-04-06 19:59:27,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 19:59:27,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 19:59:27,368] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run25
[2019-04-06 19:59:28,903] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.5037700e-19 9.9140343e-18 5.1592018e-14 5.2242494e-18 1.0000000e+00
 1.6127924e-21 1.7247614e-17], sum to 1.0000
[2019-04-06 19:59:28,903] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4764
[2019-04-06 19:59:29,082] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 38.0, 110.5, 806.0, 26.0, 26.55157819387288, 0.7264399501830222, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3938400.0000, 
sim time next is 3940200.0000, 
raw observation next is [-4.5, 38.0, 105.0, 788.0, 26.0, 26.89975139780804, 0.7609161829389349, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3379501385041552, 0.38, 0.35, 0.8707182320441988, 0.6666666666666666, 0.7416459498173366, 0.7536387276463117, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8015655], dtype=float32), 0.45500457]. 
=============================================
[2019-04-06 19:59:56,522] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.0046402e-18 2.4161003e-18 5.3488000e-15 1.4009372e-18 1.0000000e+00
 5.3341739e-21 3.9335505e-20], sum to 1.0000
[2019-04-06 19:59:56,522] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7118
[2019-04-06 19:59:56,622] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.8, 87.0, 0.0, 0.0, 26.0, 24.12249831499459, 0.08594783406296469, 0.0, 1.0, 42770.87779048009], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 97200.0000, 
sim time next is 99000.0000, 
raw observation next is [-3.1, 83.0, 0.0, 0.0, 26.0, 24.06341296119863, 0.06909757563308432, 0.0, 1.0, 43208.97476201256], 
processed observation next is [1.0, 0.13043478260869565, 0.37673130193905824, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5052844134332192, 0.523032525211028, 0.0, 1.0, 0.2057570226762503], 
reward next is 0.7942, 
noisyNet noise sample is [array([-0.30512783], dtype=float32), 1.4824451]. 
=============================================
[2019-04-06 19:59:56,636] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[88.100624]
 [88.47584 ]
 [88.073715]
 [87.67744 ]
 [87.37191 ]], R is [[87.28294373]
 [87.20644379]
 [87.13304901]
 [87.06263733]
 [86.99576569]].
[2019-04-06 20:00:15,699] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1203516e-17 2.1167142e-18 1.2649729e-14 1.3891239e-17 1.0000000e+00
 9.2586310e-21 7.8812373e-20], sum to 1.0000
[2019-04-06 20:00:15,699] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7939
[2019-04-06 20:00:15,783] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.8, 54.0, 34.0, 2.5, 26.0, 25.9762366955538, 0.4398660763451324, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 752400.0000, 
sim time next is 754200.0000, 
raw observation next is [-3.35, 55.0, 0.0, 0.0, 26.0, 25.62677596045384, 0.3080617909575663, 1.0, 1.0, 24940.62370229377], 
processed observation next is [1.0, 0.7391304347826086, 0.3698060941828255, 0.55, 0.0, 0.0, 0.6666666666666666, 0.6355646633711535, 0.6026872636525221, 1.0, 1.0, 0.11876487477282748], 
reward next is 0.8812, 
noisyNet noise sample is [array([-0.81244516], dtype=float32), 2.5377269]. 
=============================================
[2019-04-06 20:00:16,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:00:16,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:00:16,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run25
[2019-04-06 20:00:17,219] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5442346e-15 1.2402067e-16 3.7084100e-13 1.1817406e-15 1.0000000e+00
 4.4830139e-19 1.3685948e-17], sum to 1.0000
[2019-04-06 20:00:17,219] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1073
[2019-04-06 20:00:17,273] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.2, 46.0, 281.0, 390.0, 26.0, 25.11458268372014, 0.3603509117760991, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4883400.0000, 
sim time next is 4885200.0000, 
raw observation next is [1.4, 45.0, 276.5, 389.0, 26.0, 25.03328044725576, 0.35395258403943, 0.0, 1.0, 16794.88138031737], 
processed observation next is [0.0, 0.5652173913043478, 0.5013850415512465, 0.45, 0.9216666666666666, 0.4298342541436464, 0.6666666666666666, 0.5861067039379799, 0.61798419467981, 0.0, 1.0, 0.0799756256205589], 
reward next is 0.9200, 
noisyNet noise sample is [array([0.09828143], dtype=float32), 1.4760841]. 
=============================================
[2019-04-06 20:00:21,465] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.5188639e-19 1.6794924e-19 7.2319964e-16 6.9458909e-19 1.0000000e+00
 4.8426076e-23 5.5708824e-20], sum to 1.0000
[2019-04-06 20:00:21,465] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3006
[2019-04-06 20:00:21,511] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.6, 63.0, 0.0, 0.0, 26.0, 25.67485812974403, 0.6357356061087603, 0.0, 1.0, 88696.50000560253], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4406400.0000, 
sim time next is 4408200.0000, 
raw observation next is [7.199999999999999, 64.0, 0.0, 0.0, 26.0, 25.83010407582568, 0.6333124405736558, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.0, 0.662049861495845, 0.64, 0.0, 0.0, 0.6666666666666666, 0.6525086729854733, 0.7111041468578853, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.9987819], dtype=float32), 1.1542118]. 
=============================================
[2019-04-06 20:00:23,154] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2916079e-19 9.8021771e-22 8.1119710e-17 3.1409848e-20 1.0000000e+00
 4.0438489e-24 8.7246239e-22], sum to 1.0000
[2019-04-06 20:00:23,154] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4552
[2019-04-06 20:00:23,287] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.9, 100.0, 47.0, 0.0, 26.0, 25.95050566915682, 0.5192826211647036, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1503000.0000, 
sim time next is 1504800.0000, 
raw observation next is [2.2, 100.0, 60.0, 0.0, 26.0, 26.13015056828974, 0.5234339855670743, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.5235457063711911, 1.0, 0.2, 0.0, 0.6666666666666666, 0.6775125473574782, 0.6744779951890248, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8250484], dtype=float32), 0.7528009]. 
=============================================
[2019-04-06 20:00:28,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:00:28,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:00:28,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run25
[2019-04-06 20:00:28,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:00:28,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:00:28,177] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run25
[2019-04-06 20:00:28,796] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2056744e-17 1.2655405e-17 5.2948023e-14 1.7732837e-17 1.0000000e+00
 1.0914578e-20 1.6971964e-20], sum to 1.0000
[2019-04-06 20:00:28,796] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0168
[2019-04-06 20:00:28,870] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.5, 46.5, 0.0, 0.0, 26.0, 25.42834077757421, 0.3137879389284037, 0.0, 1.0, 35158.65144380543], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4930200.0000, 
sim time next is 4932000.0000, 
raw observation next is [-1.0, 50.0, 0.0, 0.0, 26.0, 25.35109888596118, 0.3477948478787742, 0.0, 1.0, 63673.324882866196], 
processed observation next is [1.0, 0.08695652173913043, 0.4349030470914128, 0.5, 0.0, 0.0, 0.6666666666666666, 0.6125915738300982, 0.6159316159595914, 0.0, 1.0, 0.3032063089660295], 
reward next is 0.6968, 
noisyNet noise sample is [array([0.96241874], dtype=float32), -1.6191168]. 
=============================================
[2019-04-06 20:00:28,876] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[78.71721 ]
 [77.96444 ]
 [77.079994]
 [76.01969 ]
 [75.0104  ]], R is [[79.81877899]
 [79.8531723 ]
 [80.05464172]
 [80.04714966]
 [80.09036255]].
[2019-04-06 20:00:38,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:00:38,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:00:38,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run25
[2019-04-06 20:00:42,738] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:00:42,739] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:00:42,756] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run25
[2019-04-06 20:00:44,335] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4901347e-19 1.7646099e-20 7.1301447e-17 6.0931455e-20 1.0000000e+00
 1.2407188e-22 1.0945928e-21], sum to 1.0000
[2019-04-06 20:00:44,335] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3344
[2019-04-06 20:00:44,376] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 92.0, 208.0, 6.0, 26.0, 26.44765148510169, 0.5932655567742384, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4703400.0000, 
sim time next is 4705200.0000, 
raw observation next is [0.0, 92.0, 210.5, 6.0, 26.0, 26.47418127793744, 0.5918476328623125, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.46260387811634357, 0.92, 0.7016666666666667, 0.0066298342541436465, 0.6666666666666666, 0.7061817731614534, 0.6972825442874374, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1563792], dtype=float32), -1.0855079]. 
=============================================
[2019-04-06 20:00:48,480] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.6640602e-18 7.6163565e-19 4.7941946e-15 1.4979492e-18 1.0000000e+00
 8.0782943e-21 2.4197136e-20], sum to 1.0000
[2019-04-06 20:00:48,481] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7263
[2019-04-06 20:00:48,780] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 76.0, 14.5, 0.0, 26.0, 25.61688202177895, 0.2850206967671358, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 720000.0000, 
sim time next is 721800.0000, 
raw observation next is [-2.3, 76.0, 29.0, 0.0, 26.0, 25.62488794825378, 0.2866839568211833, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3988919667590028, 0.76, 0.09666666666666666, 0.0, 0.6666666666666666, 0.6354073290211483, 0.5955613189403944, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2107955], dtype=float32), -0.5117392]. 
=============================================
[2019-04-06 20:00:48,866] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:00:48,866] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:00:48,878] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run25
[2019-04-06 20:00:49,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:00:49,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:00:49,568] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run25
[2019-04-06 20:00:56,546] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:00:56,546] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:00:56,550] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run25
[2019-04-06 20:00:59,995] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.38790585e-18 1.32563775e-17 4.56372373e-15 6.10947064e-17
 1.00000000e+00 4.25912036e-22 2.79421585e-19], sum to 1.0000
[2019-04-06 20:00:59,995] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6899
[2019-04-06 20:01:00,168] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.7, 93.0, 49.0, 0.0, 26.0, 23.47103262127986, -0.08100015174504369, 0.0, 1.0, 58184.481211890066], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 36000.0000, 
sim time next is 37800.0000, 
raw observation next is [7.7, 93.0, 60.0, 0.0, 26.0, 23.77303656205198, -0.00582012731863768, 0.0, 1.0, 57069.06617966958], 
processed observation next is [0.0, 0.43478260869565216, 0.6759002770083103, 0.93, 0.2, 0.0, 0.6666666666666666, 0.4810863801709984, 0.49805995756045407, 0.0, 1.0, 0.27175745799842654], 
reward next is 0.7282, 
noisyNet noise sample is [array([0.45604065], dtype=float32), 0.38220948]. 
=============================================
[2019-04-06 20:01:03,999] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.6785347e-16 2.6484124e-16 1.6529044e-13 2.9106212e-16 1.0000000e+00
 4.3668348e-20 8.1144731e-18], sum to 1.0000
[2019-04-06 20:01:03,999] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3907
[2019-04-06 20:01:04,064] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 80.5, 0.0, 0.0, 26.0, 24.62099743406924, 0.2120265021423644, 0.0, 1.0, 45505.7940454351], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1812600.0000, 
sim time next is 1814400.0000, 
raw observation next is [-5.0, 79.0, 0.0, 0.0, 26.0, 24.5312327979765, 0.1923709259689241, 0.0, 1.0, 45511.81512317722], 
processed observation next is [0.0, 0.0, 0.32409972299168976, 0.79, 0.0, 0.0, 0.6666666666666666, 0.544269399831375, 0.5641236419896414, 0.0, 1.0, 0.21672292915798677], 
reward next is 0.7833, 
noisyNet noise sample is [array([1.6494195], dtype=float32), 0.45952144]. 
=============================================
[2019-04-06 20:01:05,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:01:05,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:01:05,652] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run25
[2019-04-06 20:01:09,116] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2761825e-17 2.8848281e-19 3.0140676e-15 2.9969686e-18 1.0000000e+00
 9.6305704e-22 1.0097966e-18], sum to 1.0000
[2019-04-06 20:01:09,116] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0682
[2019-04-06 20:01:09,170] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.7, 83.0, 0.0, 0.0, 26.0, 25.2172967190822, 0.3976150252859271, 0.0, 1.0, 42328.382675207096], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2152800.0000, 
sim time next is 2154600.0000, 
raw observation next is [-7.0, 82.5, 0.0, 0.0, 26.0, 25.05533193212384, 0.3133345606531797, 0.0, 1.0, 42486.24501619544], 
processed observation next is [1.0, 0.9565217391304348, 0.2686980609418283, 0.825, 0.0, 0.0, 0.6666666666666666, 0.5879443276769866, 0.6044448535510599, 0.0, 1.0, 0.20231545245807353], 
reward next is 0.7977, 
noisyNet noise sample is [array([-0.31002212], dtype=float32), -1.400852]. 
=============================================
[2019-04-06 20:01:21,458] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.2597306e-17 4.1855405e-17 3.3150085e-14 2.0148366e-16 1.0000000e+00
 2.9991155e-20 1.1139465e-17], sum to 1.0000
[2019-04-06 20:01:21,458] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0006
[2019-04-06 20:01:21,517] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 26.0, 22.98739681561153, -0.185713050827865, 0.0, 1.0, 44335.44096280576], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 189000.0000, 
sim time next is 190800.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 26.0, 22.89020569416615, -0.2015100717051018, 0.0, 1.0, 44574.696685409166], 
processed observation next is [1.0, 0.21739130434782608, 0.21606648199445982, 0.78, 0.0, 0.0, 0.6666666666666666, 0.40751714118051235, 0.43282997609829943, 0.0, 1.0, 0.21226046040671032], 
reward next is 0.7877, 
noisyNet noise sample is [array([-0.43276808], dtype=float32), 1.0797542]. 
=============================================
[2019-04-06 20:01:23,580] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.6733141e-16 1.1554658e-17 1.0709492e-13 1.7686231e-16 1.0000000e+00
 3.6671595e-19 1.0228272e-17], sum to 1.0000
[2019-04-06 20:01:23,580] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1919
[2019-04-06 20:01:23,644] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 71.0, 0.0, 0.0, 26.0, 24.53253391434054, 0.1198684639267843, 0.0, 1.0, 41446.89934593706], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 689400.0000, 
sim time next is 691200.0000, 
raw observation next is [-3.9, 71.0, 0.0, 0.0, 26.0, 24.44114727006653, 0.1078568670768287, 0.0, 1.0, 41221.40352701094], 
processed observation next is [1.0, 0.0, 0.3545706371191136, 0.71, 0.0, 0.0, 0.6666666666666666, 0.5367622725055442, 0.5359522890256095, 0.0, 1.0, 0.19629239774767113], 
reward next is 0.8037, 
noisyNet noise sample is [array([-0.12830342], dtype=float32), 0.5240485]. 
=============================================
[2019-04-06 20:01:37,242] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.5603306e-15 2.4433991e-16 1.0498973e-12 3.8589229e-14 1.0000000e+00
 3.3650865e-18 2.4107815e-16], sum to 1.0000
[2019-04-06 20:01:37,242] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1803
[2019-04-06 20:01:37,304] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-15.0, 69.0, 0.0, 0.0, 26.0, 22.74697055004533, -0.2488831498180419, 0.0, 1.0, 49186.781698020415], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 356400.0000, 
sim time next is 358200.0000, 
raw observation next is [-15.3, 71.0, 0.0, 0.0, 26.0, 22.58897539764279, -0.2734997299895138, 0.0, 1.0, 49317.576195190915], 
processed observation next is [1.0, 0.13043478260869565, 0.03878116343490302, 0.71, 0.0, 0.0, 0.6666666666666666, 0.3824146164702326, 0.4088334233368287, 0.0, 1.0, 0.23484560092948054], 
reward next is 0.7652, 
noisyNet noise sample is [array([-1.7983787], dtype=float32), -1.2401139]. 
=============================================
[2019-04-06 20:01:49,668] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-06 20:01:49,673] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:01:49,673] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:01:49,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run56
[2019-04-06 20:01:49,724] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:01:49,725] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:01:49,729] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run56
[2019-04-06 20:01:49,745] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:01:49,746] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:01:49,751] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run56
[2019-04-06 20:03:58,401] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 20:04:39,792] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 20:04:40,945] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 20:04:41,982] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 1100000, evaluation results [1100000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 20:05:02,516] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.3381567e-17 1.4463067e-18 1.1387134e-13 1.0662287e-17 1.0000000e+00
 9.8859602e-21 7.8102497e-19], sum to 1.0000
[2019-04-06 20:05:02,517] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2537
[2019-04-06 20:05:02,849] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.2, 54.0, 0.0, 0.0, 26.0, 25.19791888559788, 0.333551261238253, 1.0, 1.0, 6231.649517079003], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2314800.0000, 
sim time next is 2316600.0000, 
raw observation next is [-1.45, 55.0, 0.0, 0.0, 26.0, 24.93680206034292, 0.3296028333556031, 0.0, 1.0, 91061.14679412065], 
processed observation next is [1.0, 0.8260869565217391, 0.422437673130194, 0.55, 0.0, 0.0, 0.6666666666666666, 0.57806683836191, 0.6098676111185344, 0.0, 1.0, 0.43362450854343165], 
reward next is 0.5664, 
noisyNet noise sample is [array([-0.92431134], dtype=float32), -0.69065934]. 
=============================================
[2019-04-06 20:05:03,968] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.3902060e-20 8.3480594e-21 4.6213763e-16 6.6462473e-19 1.0000000e+00
 6.5688530e-23 1.2443081e-20], sum to 1.0000
[2019-04-06 20:05:03,968] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9938
[2019-04-06 20:05:04,070] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.55, 96.5, 0.0, 0.0, 26.0, 24.83486133541347, 0.2346316952631697, 0.0, 1.0, 40125.09312091048], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 516600.0000, 
sim time next is 518400.0000, 
raw observation next is [3.8, 97.0, 0.0, 0.0, 26.0, 24.88402442094871, 0.2392944599932561, 0.0, 1.0, 39853.58477820855], 
processed observation next is [0.0, 0.0, 0.5678670360110805, 0.97, 0.0, 0.0, 0.6666666666666666, 0.5736687017457257, 0.579764819997752, 0.0, 1.0, 0.18977897513432643], 
reward next is 0.8102, 
noisyNet noise sample is [array([1.01974], dtype=float32), 0.45230207]. 
=============================================
[2019-04-06 20:05:04,375] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5095748e-19 4.0684922e-19 3.5228613e-15 2.0039348e-18 1.0000000e+00
 3.4003719e-22 6.3167079e-20], sum to 1.0000
[2019-04-06 20:05:04,375] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3549
[2019-04-06 20:05:04,478] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [11.6, 71.0, 0.0, 0.0, 26.0, 25.76273910687414, 0.6513874509973498, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1123200.0000, 
sim time next is 1125000.0000, 
raw observation next is [11.05, 74.0, 0.0, 0.0, 26.0, 25.67171232467269, 0.6402960743112888, 0.0, 1.0, 37405.26021291688], 
processed observation next is [0.0, 0.0, 0.7686980609418284, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6393093603893908, 0.7134320247704297, 0.0, 1.0, 0.17812028672817562], 
reward next is 0.8219, 
noisyNet noise sample is [array([0.45411417], dtype=float32), -0.8210088]. 
=============================================
[2019-04-06 20:05:04,500] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[93.41012 ]
 [94.44637 ]
 [94.81989 ]
 [94.270256]
 [91.751884]], R is [[93.01741791]
 [93.08724213]
 [93.12664795]
 [92.81182861]
 [92.88371277]].
[2019-04-06 20:05:11,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0135268e-20 1.7028188e-20 5.5558708e-15 1.5597010e-19 1.0000000e+00
 7.0186398e-24 4.2175387e-21], sum to 1.0000
[2019-04-06 20:05:11,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4680
[2019-04-06 20:05:11,968] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.5, 44.0, 0.0, 26.0, 25.70442399784238, 0.506170565890728, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1351800.0000, 
sim time next is 1353600.0000, 
raw observation next is [1.1, 93.0, 31.0, 0.0, 26.0, 25.70543298076546, 0.5189442600184521, 1.0, 1.0, 41869.62260386039], 
processed observation next is [1.0, 0.6956521739130435, 0.49307479224376743, 0.93, 0.10333333333333333, 0.0, 0.6666666666666666, 0.6421194150637882, 0.6729814200061507, 1.0, 1.0, 0.19937915525647806], 
reward next is 0.8006, 
noisyNet noise sample is [array([0.5451596], dtype=float32), 0.4603453]. 
=============================================
[2019-04-06 20:05:21,930] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0183865e-14 2.0249856e-15 1.2390295e-12 9.4857094e-15 1.0000000e+00
 4.3299646e-18 4.6199485e-16], sum to 1.0000
[2019-04-06 20:05:21,930] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4016
[2019-04-06 20:05:21,955] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.3, 65.0, 128.0, 0.0, 26.0, 25.07195693790423, 0.5006106069447139, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1175400.0000, 
sim time next is 1177200.0000, 
raw observation next is [18.3, 65.0, 104.0, 0.0, 26.0, 25.04230977955588, 0.4971079173811728, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.9695290858725764, 0.65, 0.3466666666666667, 0.0, 0.6666666666666666, 0.5868591482963232, 0.6657026391270576, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6596601], dtype=float32), -0.840411]. 
=============================================
[2019-04-06 20:05:27,134] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0404200e-20 9.7461095e-20 1.1020996e-16 1.3242003e-20 1.0000000e+00
 6.2643861e-23 5.4952515e-22], sum to 1.0000
[2019-04-06 20:05:27,134] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9455
[2019-04-06 20:05:27,244] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.2, 100.0, 60.0, 0.0, 26.0, 26.13015056828974, 0.5234339855670743, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1504800.0000, 
sim time next is 1506600.0000, 
raw observation next is [2.75, 98.0, 73.0, 0.0, 26.0, 26.09664208105307, 0.527569698575001, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.5387811634349031, 0.98, 0.24333333333333335, 0.0, 0.6666666666666666, 0.6747201734210891, 0.675856566191667, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.73772687], dtype=float32), -1.7645475]. 
=============================================
[2019-04-06 20:05:35,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0829496e-20 3.8776477e-22 3.8104236e-18 5.4536574e-20 1.0000000e+00
 3.2873483e-25 8.4686844e-23], sum to 1.0000
[2019-04-06 20:05:35,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2349
[2019-04-06 20:05:35,988] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.1, 76.5, 0.0, 0.0, 26.0, 25.98232199376704, 0.6082572405702793, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1042200.0000, 
sim time next is 1044000.0000, 
raw observation next is [13.8, 78.0, 0.0, 0.0, 26.0, 25.75314820867568, 0.5766227834554876, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.844875346260388, 0.78, 0.0, 0.0, 0.6666666666666666, 0.6460956840563066, 0.6922075944851626, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.49954468], dtype=float32), 0.25117424]. 
=============================================
[2019-04-06 20:05:36,010] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[97.24214 ]
 [97.1376  ]
 [96.730194]
 [96.510056]
 [96.14578 ]], R is [[97.20238495]
 [97.23036194]
 [97.25805664]
 [97.25574493]
 [97.02523041]].
[2019-04-06 20:05:38,596] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0662095e-20 7.5878963e-22 1.2483857e-15 8.4262207e-21 1.0000000e+00
 2.4154031e-23 8.9816790e-22], sum to 1.0000
[2019-04-06 20:05:38,596] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5206
[2019-04-06 20:05:38,625] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.15, 81.5, 0.0, 0.0, 26.0, 25.62832112890668, 0.6127584790513325, 0.0, 1.0, 31732.376537528453], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1146600.0000, 
sim time next is 1148400.0000, 
raw observation next is [12.7, 80.0, 0.0, 0.0, 26.0, 25.66619024769813, 0.614232893988135, 0.0, 1.0, 18727.03349702862], 
processed observation next is [0.0, 0.30434782608695654, 0.8144044321329641, 0.8, 0.0, 0.0, 0.6666666666666666, 0.6388491873081774, 0.704744297996045, 0.0, 1.0, 0.08917634998585057], 
reward next is 0.9108, 
noisyNet noise sample is [array([-0.03645459], dtype=float32), -0.1351513]. 
=============================================
[2019-04-06 20:05:42,548] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.7709552e-21 1.0120433e-21 2.0914255e-16 1.9545643e-20 1.0000000e+00
 6.4631586e-25 7.6073146e-22], sum to 1.0000
[2019-04-06 20:05:42,549] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0302
[2019-04-06 20:05:42,590] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [13.3, 80.0, 0.0, 0.0, 26.0, 25.83458566531822, 0.5992603336140879, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1058400.0000, 
sim time next is 1060200.0000, 
raw observation next is [13.3, 80.0, 0.0, 0.0, 26.0, 25.67324706827755, 0.5793426260013784, 0.0, 1.0, 19894.239670221777], 
processed observation next is [1.0, 0.2608695652173913, 0.8310249307479226, 0.8, 0.0, 0.0, 0.6666666666666666, 0.6394372556897959, 0.6931142086671261, 0.0, 1.0, 0.0947344746201037], 
reward next is 0.9053, 
noisyNet noise sample is [array([-0.17695326], dtype=float32), -1.5695268]. 
=============================================
[2019-04-06 20:05:49,714] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.7613158e-16 8.3822802e-18 4.9803033e-13 1.1431821e-15 1.0000000e+00
 1.4877946e-19 3.0030110e-18], sum to 1.0000
[2019-04-06 20:05:49,714] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4272
[2019-04-06 20:05:49,750] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 26.0, 23.99066926195958, 0.04843005236222925, 0.0, 1.0, 40155.93279956094], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3040200.0000, 
sim time next is 3042000.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 26.0, 23.91024994875439, 0.02968503840094978, 0.0, 1.0, 40206.09953712834], 
processed observation next is [0.0, 0.21739130434782608, 0.296398891966759, 0.77, 0.0, 0.0, 0.6666666666666666, 0.49252082906286593, 0.5098950128003166, 0.0, 1.0, 0.1914576168434683], 
reward next is 0.8085, 
noisyNet noise sample is [array([-1.0336035], dtype=float32), 0.7664483]. 
=============================================
[2019-04-06 20:05:49,755] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.244934]
 [77.4414  ]
 [77.59675 ]
 [77.7057  ]
 [77.547585]], R is [[77.06468201]
 [77.10282135]
 [77.14152527]
 [77.18144989]
 [77.22306061]].
[2019-04-06 20:05:53,782] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.7113406e-19 2.6043267e-19 1.7364084e-15 1.8524743e-18 1.0000000e+00
 1.9315267e-21 1.5058886e-20], sum to 1.0000
[2019-04-06 20:05:53,783] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9648
[2019-04-06 20:05:53,888] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 77.0, 94.5, 552.0, 26.0, 25.54629482750038, 0.4060175226325299, 1.0, 1.0, 12604.35843988143], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3747600.0000, 
sim time next is 3749400.0000, 
raw observation next is [-3.5, 77.0, 100.0, 675.0, 26.0, 26.12956698453755, 0.4860433475144302, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.36565096952908593, 0.77, 0.3333333333333333, 0.7458563535911602, 0.6666666666666666, 0.6774639153781292, 0.6620144491714767, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16712059], dtype=float32), 0.0383248]. 
=============================================
[2019-04-06 20:06:15,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5021249e-17 2.4193470e-18 1.3049788e-13 6.9191885e-17 1.0000000e+00
 4.4513812e-21 2.3967860e-18], sum to 1.0000
[2019-04-06 20:06:15,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7075
[2019-04-06 20:06:15,237] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.5, 60.0, 0.0, 0.0, 26.0, 25.11019814301135, 0.4746559824786725, 0.0, 1.0, 141681.2056870813], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3357000.0000, 
sim time next is 3358800.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 26.0, 25.51047061127208, 0.5364221979737605, 0.0, 1.0, 47938.6838511643], 
processed observation next is [1.0, 0.9130434782608695, 0.3518005540166205, 0.65, 0.0, 0.0, 0.6666666666666666, 0.62587255093934, 0.6788073993245868, 0.0, 1.0, 0.2282794469103062], 
reward next is 0.7717, 
noisyNet noise sample is [array([1.2009215], dtype=float32), 0.61717546]. 
=============================================
[2019-04-06 20:06:15,289] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3488424e-17 3.6388316e-18 5.2756719e-13 3.6216336e-17 1.0000000e+00
 1.4208276e-20 1.7322236e-19], sum to 1.0000
[2019-04-06 20:06:15,289] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7748
[2019-04-06 20:06:15,353] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 40.0, 0.0, 0.0, 26.0, 25.86186250452971, 0.5618175777390402, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4140000.0000, 
sim time next is 4141800.0000, 
raw observation next is [0.5, 41.5, 0.0, 0.0, 26.0, 25.53958222216713, 0.4454231859807916, 0.0, 1.0, 34528.53969060517], 
processed observation next is [1.0, 0.9565217391304348, 0.4764542936288089, 0.415, 0.0, 0.0, 0.6666666666666666, 0.6282985185139275, 0.6484743953269305, 0.0, 1.0, 0.1644216175743103], 
reward next is 0.8356, 
noisyNet noise sample is [array([-1.3474793], dtype=float32), 0.45720986]. 
=============================================
[2019-04-06 20:06:26,906] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1485890e-16 6.0633140e-17 7.4345705e-13 6.5695848e-14 1.0000000e+00
 8.1045388e-19 1.2723326e-16], sum to 1.0000
[2019-04-06 20:06:26,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7541
[2019-04-06 20:06:27,021] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 26.0, 25.11703411240696, 0.3475674674123907, 0.0, 1.0, 32709.111402573897], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3610800.0000, 
sim time next is 3612600.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 26.0, 25.07618174287926, 0.3704464439800041, 0.0, 1.0, 126704.22561096396], 
processed observation next is [0.0, 0.8260869565217391, 0.4349030470914128, 0.42, 0.0, 0.0, 0.6666666666666666, 0.5896818119066051, 0.6234821479933347, 0.0, 1.0, 0.6033534552903046], 
reward next is 0.3966, 
noisyNet noise sample is [array([-0.156278], dtype=float32), -1.9499418]. 
=============================================
[2019-04-06 20:06:30,145] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.6934992e-18 7.7151953e-19 1.2327226e-14 6.3347430e-17 1.0000000e+00
 1.3936380e-21 8.9654376e-18], sum to 1.0000
[2019-04-06 20:06:30,145] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4093
[2019-04-06 20:06:30,300] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 26.0, 25.02751294155262, 0.3730266370424637, 0.0, 1.0, 88236.91700020223], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2145600.0000, 
sim time next is 2147400.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 26.0, 25.13693707753088, 0.4101449025403063, 0.0, 1.0, 85194.23674603034], 
processed observation next is [1.0, 0.8695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5947447564609067, 0.6367149675134355, 0.0, 1.0, 0.40568684164776353], 
reward next is 0.5943, 
noisyNet noise sample is [array([-0.45920554], dtype=float32), 0.55024374]. 
=============================================
[2019-04-06 20:06:35,722] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8108324e-18 8.6142796e-19 5.1733101e-15 1.2307232e-18 1.0000000e+00
 2.4587833e-21 1.6553161e-19], sum to 1.0000
[2019-04-06 20:06:35,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2956
[2019-04-06 20:06:35,794] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 26.0, 24.19889966961679, 0.09552433232834034, 0.0, 1.0, 43446.216471869215], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2091600.0000, 
sim time next is 2093400.0000, 
raw observation next is [-6.45, 85.0, 0.0, 0.0, 26.0, 24.21908121727628, 0.0992850503009736, 0.0, 1.0, 43576.09911762699], 
processed observation next is [1.0, 0.21739130434782608, 0.28393351800554023, 0.85, 0.0, 0.0, 0.6666666666666666, 0.5182567681063567, 0.5330950167669912, 0.0, 1.0, 0.20750523389346184], 
reward next is 0.7925, 
noisyNet noise sample is [array([1.6612556], dtype=float32), -0.44529322]. 
=============================================
[2019-04-06 20:06:58,753] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5797088e-16 4.0005187e-17 1.9512785e-13 2.8670705e-16 1.0000000e+00
 2.6268661e-19 3.1734473e-17], sum to 1.0000
[2019-04-06 20:06:58,754] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1223
[2019-04-06 20:06:58,989] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.00609928078497, 0.3208933170664817, 0.0, 1.0, 50754.72086062302], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3004200.0000, 
sim time next is 3006000.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.0121029929357, 0.3165466785338046, 0.0, 1.0, 35539.65573767301], 
processed observation next is [0.0, 0.8260869565217391, 0.40720221606648205, 0.6, 0.0, 0.0, 0.6666666666666666, 0.5843419160779749, 0.6055155595112681, 0.0, 1.0, 0.169236455893681], 
reward next is 0.8308, 
noisyNet noise sample is [array([-1.0374056], dtype=float32), -1.5215511]. 
=============================================
[2019-04-06 20:06:59,021] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[75.20649]
 [74.99024]
 [75.19615]
 [75.48726]
 [75.89878]], R is [[75.32362366]
 [75.3286972 ]
 [75.42040253]
 [75.48389435]
 [75.56529999]].
[2019-04-06 20:07:02,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:07:02,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:07:02,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run26
[2019-04-06 20:07:08,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:07:08,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:07:08,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run26
[2019-04-06 20:07:12,711] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.41789438e-18 1.07037624e-19 1.17165885e-15 3.26791608e-19
 1.00000000e+00 1.57103820e-22 1.18962507e-21], sum to 1.0000
[2019-04-06 20:07:12,711] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2293
[2019-04-06 20:07:12,755] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.0, 67.0, 0.0, 0.0, 26.0, 25.71707206227094, 0.5604357784155939, 0.0, 1.0, 12974.710431338814], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4417200.0000, 
sim time next is 4419000.0000, 
raw observation next is [4.75, 67.0, 0.0, 0.0, 26.0, 25.62184332973351, 0.5621550430039501, 0.0, 1.0, 51380.450927432954], 
processed observation next is [1.0, 0.13043478260869565, 0.5941828254847646, 0.67, 0.0, 0.0, 0.6666666666666666, 0.635153610811126, 0.6873850143346502, 0.0, 1.0, 0.2446688139401569], 
reward next is 0.7553, 
noisyNet noise sample is [array([0.425517], dtype=float32), -0.87600857]. 
=============================================
[2019-04-06 20:07:12,758] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[90.609856]
 [90.81928 ]
 [90.47039 ]
 [91.09471 ]
 [91.75482 ]], R is [[90.65210724]
 [90.68380737]
 [90.38382721]
 [90.4799881 ]
 [90.57518768]].
[2019-04-06 20:07:13,460] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1323021e-15 4.5018521e-17 2.4963611e-13 6.2099231e-16 1.0000000e+00
 1.5383812e-19 2.1744884e-17], sum to 1.0000
[2019-04-06 20:07:13,460] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0714
[2019-04-06 20:07:13,558] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 70.0, 0.0, 0.0, 26.0, 23.78796573348578, -0.002759649973174585, 0.0, 1.0, 40165.4737232261], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3045600.0000, 
sim time next is 3047400.0000, 
raw observation next is [-6.0, 73.5, 0.0, 0.0, 26.0, 23.70705745287422, -0.01998956748393993, 0.0, 1.0, 40260.48045852601], 
processed observation next is [0.0, 0.2608695652173913, 0.296398891966759, 0.735, 0.0, 0.0, 0.6666666666666666, 0.4755881210728517, 0.4933368108386867, 0.0, 1.0, 0.19171657361202862], 
reward next is 0.8083, 
noisyNet noise sample is [array([1.6613861], dtype=float32), 0.17494127]. 
=============================================
[2019-04-06 20:07:14,694] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.2145850e-21 3.5952662e-21 2.4472597e-17 1.2387911e-19 1.0000000e+00
 6.0259412e-23 1.1005843e-21], sum to 1.0000
[2019-04-06 20:07:14,694] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6101
[2019-04-06 20:07:14,871] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 81.5, 71.0, 0.0, 26.0, 26.16827736400934, 0.4736648089174404, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4462200.0000, 
sim time next is 4464000.0000, 
raw observation next is [0.0, 78.0, 60.0, 0.0, 26.0, 25.33985070894622, 0.5344268452248072, 1.0, 1.0, 81163.33811065888], 
processed observation next is [1.0, 0.6956521739130435, 0.46260387811634357, 0.78, 0.2, 0.0, 0.6666666666666666, 0.6116542257455183, 0.6781422817416024, 1.0, 1.0, 0.38649208624123277], 
reward next is 0.6135, 
noisyNet noise sample is [array([-0.7631037], dtype=float32), 2.0694613]. 
=============================================
[2019-04-06 20:07:14,926] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[90.62866 ]
 [91.53892 ]
 [92.1492  ]
 [92.346634]
 [91.330345]], R is [[90.07133484]
 [90.17062378]
 [90.2689209 ]
 [90.36623383]
 [90.04277039]].
[2019-04-06 20:07:15,765] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.7651992e-17 5.1743878e-18 3.8933005e-14 2.1684579e-17 1.0000000e+00
 7.4523894e-20 1.0434179e-18], sum to 1.0000
[2019-04-06 20:07:15,765] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8289
[2019-04-06 20:07:15,831] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 55.0, 69.5, 570.5, 26.0, 25.14816283932767, 0.4076572628835464, 0.0, 1.0, 12471.873377873924], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2995200.0000, 
sim time next is 2997000.0000, 
raw observation next is [-1.0, 55.0, 56.0, 474.0, 26.0, 25.10878666972265, 0.3801211170056412, 0.0, 1.0, 20148.398093839565], 
processed observation next is [0.0, 0.6956521739130435, 0.4349030470914128, 0.55, 0.18666666666666668, 0.523756906077348, 0.6666666666666666, 0.5923988891435542, 0.6267070390018804, 0.0, 1.0, 0.09594475282780746], 
reward next is 0.9041, 
noisyNet noise sample is [array([-2.1459227], dtype=float32), 1.5186962]. 
=============================================
[2019-04-06 20:07:15,835] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[77.5579  ]
 [77.867676]
 [77.89825 ]
 [77.9404  ]
 [78.11158 ]], R is [[77.4005661 ]
 [77.56717682]
 [77.66833496]
 [77.76017761]
 [77.923172  ]].
[2019-04-06 20:07:18,269] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 20:07:18,272] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:07:18,272] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:07:18,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:07:18,274] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:07:18,274] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:07:18,281] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run57
[2019-04-06 20:07:18,288] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:07:18,312] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run57
[2019-04-06 20:07:18,332] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run57
[2019-04-06 20:09:25,210] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 20:10:05,941] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 20:10:08,507] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 20:10:09,545] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1120000, evaluation results [1120000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 20:10:26,633] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.0860018e-16 1.9614623e-16 2.6639788e-14 2.1146110e-15 1.0000000e+00
 5.9642714e-20 4.8940621e-18], sum to 1.0000
[2019-04-06 20:10:26,633] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4162
[2019-04-06 20:10:26,856] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 65.0, 181.0, 691.0, 26.0, 25.04826770340346, 0.3924107394211341, 0.0, 1.0, 22702.51673451406], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2982600.0000, 
sim time next is 2984400.0000, 
raw observation next is [-3.0, 65.0, 145.5, 745.5, 26.0, 25.06993791349919, 0.4027717088197163, 0.0, 1.0, 27570.863608804848], 
processed observation next is [0.0, 0.5652173913043478, 0.3795013850415513, 0.65, 0.485, 0.8237569060773481, 0.6666666666666666, 0.589161492791599, 0.6342572362732387, 0.0, 1.0, 0.13128982670859451], 
reward next is 0.8687, 
noisyNet noise sample is [array([-0.83178717], dtype=float32), -0.6379465]. 
=============================================
[2019-04-06 20:10:33,527] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:10:33,527] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:10:33,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run26
[2019-04-06 20:10:34,209] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.9854652e-19 5.8087337e-20 3.9793968e-15 2.8126112e-18 1.0000000e+00
 3.8970143e-22 3.0754087e-19], sum to 1.0000
[2019-04-06 20:10:34,210] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8329
[2019-04-06 20:10:34,264] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.45, 75.5, 0.0, 0.0, 26.0, 25.56183819202452, 0.4038188692348457, 0.0, 1.0, 23938.40103734567], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4318200.0000, 
sim time next is 4320000.0000, 
raw observation next is [4.5, 76.0, 0.0, 0.0, 26.0, 25.45222014402537, 0.4106769777094247, 0.0, 1.0, 61470.26896102188], 
processed observation next is [1.0, 0.0, 0.5872576177285319, 0.76, 0.0, 0.0, 0.6666666666666666, 0.6210183453354476, 0.6368923259031415, 0.0, 1.0, 0.29271556648105657], 
reward next is 0.7073, 
noisyNet noise sample is [array([2.311602], dtype=float32), -2.134315]. 
=============================================
[2019-04-06 20:10:34,290] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[85.856834]
 [85.97079 ]
 [86.110306]
 [86.17915 ]
 [85.925415]], R is [[87.11282349]
 [87.12770844]
 [87.15247345]
 [87.10463715]
 [86.92034912]].
[2019-04-06 20:10:42,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:10:42,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:10:42,788] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run26
[2019-04-06 20:10:44,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:10:44,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:10:44,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run26
[2019-04-06 20:10:49,169] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1123766: loss 0.9734
[2019-04-06 20:10:49,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1123766: learning rate 0.0000
[2019-04-06 20:10:52,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:10:52,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:10:52,376] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run26
[2019-04-06 20:10:57,926] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1124444: loss 1.0104
[2019-04-06 20:10:57,926] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1124444: learning rate 0.0000
[2019-04-06 20:10:59,352] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5794963e-18 4.4404321e-18 5.6176318e-15 4.5239368e-18 1.0000000e+00
 7.9768427e-21 1.6119637e-19], sum to 1.0000
[2019-04-06 20:10:59,353] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6786
[2019-04-06 20:10:59,465] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.2914148087929, 0.4323531758234129, 0.0, 1.0, 44242.762079729924], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3799800.0000, 
sim time next is 3801600.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.27951763209779, 0.4192877395338392, 0.0, 1.0, 43701.108557355095], 
processed observation next is [1.0, 0.0, 0.3795013850415513, 0.71, 0.0, 0.0, 0.6666666666666666, 0.6066264693414825, 0.639762579844613, 0.0, 1.0, 0.20810051693978618], 
reward next is 0.7919, 
noisyNet noise sample is [array([-0.88671297], dtype=float32), 0.019841237]. 
=============================================
[2019-04-06 20:11:09,076] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5310099e-17 1.1270774e-17 3.4395384e-13 1.4949652e-16 1.0000000e+00
 1.0488847e-19 3.7026685e-18], sum to 1.0000
[2019-04-06 20:11:09,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4635
[2019-04-06 20:11:09,148] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.5, 70.0, 3.0, 121.0, 26.0, 24.28451695673412, 0.1902419361874061, 0.0, 1.0, 41448.90862776351], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3569400.0000, 
sim time next is 3571200.0000, 
raw observation next is [-7.0, 70.0, 45.5, 273.0, 26.0, 24.20441849000851, 0.1986919864685137, 0.0, 1.0, 41494.04482403348], 
processed observation next is [0.0, 0.34782608695652173, 0.2686980609418283, 0.7, 0.15166666666666667, 0.30165745856353593, 0.6666666666666666, 0.5170348741673759, 0.5662306621561712, 0.0, 1.0, 0.19759068963825466], 
reward next is 0.8024, 
noisyNet noise sample is [array([0.34932926], dtype=float32), -1.216627]. 
=============================================
[2019-04-06 20:11:21,664] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7249884e-19 1.4309945e-19 2.3777024e-15 1.6724159e-18 1.0000000e+00
 4.3400764e-22 1.8148909e-19], sum to 1.0000
[2019-04-06 20:11:21,664] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1925
[2019-04-06 20:11:21,947] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.8, 59.0, 86.5, 0.0, 26.0, 25.62794247053095, 0.2946156875380395, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 226800.0000, 
sim time next is 228600.0000, 
raw observation next is [-3.1, 60.5, 56.0, 0.0, 26.0, 25.68746468468798, 0.3679755064204697, 1.0, 1.0, 66314.34175251544], 
processed observation next is [1.0, 0.6521739130434783, 0.37673130193905824, 0.605, 0.18666666666666668, 0.0, 0.6666666666666666, 0.6406220570573318, 0.6226585021401566, 1.0, 1.0, 0.315782579773883], 
reward next is 0.6842, 
noisyNet noise sample is [array([-0.13125141], dtype=float32), 0.931033]. 
=============================================
[2019-04-06 20:11:22,969] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:11:22,969] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:11:22,974] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run26
[2019-04-06 20:11:27,277] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1128220: loss 0.7611
[2019-04-06 20:11:27,281] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1128220: learning rate 0.0000
[2019-04-06 20:11:33,195] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1129079: loss 1.0697
[2019-04-06 20:11:33,196] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1129079: learning rate 0.0000
[2019-04-06 20:11:34,392] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1129265: loss 1.0343
[2019-04-06 20:11:34,393] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1129265: learning rate 0.0000
[2019-04-06 20:11:37,807] A3C_AGENT_WORKER-Thread-8 INFO:Local step 71000, global step 1129730: loss 0.8548
[2019-04-06 20:11:37,807] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 71000, global step 1129730: learning rate 0.0000
[2019-04-06 20:11:38,638] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.5818458e-18 2.8046306e-17 2.9127234e-14 6.9924793e-16 1.0000000e+00
 3.3229257e-19 2.1770510e-19], sum to 1.0000
[2019-04-06 20:11:38,638] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4031
[2019-04-06 20:11:38,799] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 77.0, 149.0, 420.0, 26.0, 25.63642003720515, 0.4660650236823513, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4784400.0000, 
sim time next is 4786200.0000, 
raw observation next is [-4.0, 71.0, 174.0, 421.0, 26.0, 25.61851992429605, 0.4614169388029776, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3518005540166205, 0.71, 0.58, 0.46519337016574586, 0.6666666666666666, 0.634876660358004, 0.6538056462676592, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4891899], dtype=float32), -0.45346949]. 
=============================================
[2019-04-06 20:11:42,146] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2943409e-19 1.0528781e-18 1.1308210e-15 1.7796799e-18 1.0000000e+00
 1.5789389e-22 9.1403983e-22], sum to 1.0000
[2019-04-06 20:11:42,147] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3364
[2019-04-06 20:11:42,262] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.40294709580129, 0.329523480745093, 0.0, 1.0, 38631.28114132987], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3731400.0000, 
sim time next is 3733200.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.24829227968733, 0.3021250354346093, 0.0, 1.0, 46187.41669063864], 
processed observation next is [1.0, 0.21739130434782608, 0.3795013850415513, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6040243566406108, 0.6007083451448697, 0.0, 1.0, 0.2199400794792316], 
reward next is 0.7801, 
noisyNet noise sample is [array([0.50230974], dtype=float32), 0.73875755]. 
=============================================
[2019-04-06 20:11:53,799] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4038513e-21 3.7674598e-22 2.9146989e-16 6.1844996e-19 1.0000000e+00
 4.9878898e-24 3.7954299e-22], sum to 1.0000
[2019-04-06 20:11:53,800] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3544
[2019-04-06 20:11:53,849] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 78.0, 49.0, 0.0, 26.0, 26.02812142822339, 0.5771252747005096, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4465800.0000, 
sim time next is 4467600.0000, 
raw observation next is [0.0, 78.0, 37.0, 27.5, 26.0, 26.20474417431367, 0.5853412978634994, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.46260387811634357, 0.78, 0.12333333333333334, 0.03038674033149171, 0.6666666666666666, 0.6837286811928059, 0.6951137659544998, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4041796], dtype=float32), 0.35776436]. 
=============================================
[2019-04-06 20:11:55,073] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1132453: loss 51.6172
[2019-04-06 20:11:55,074] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1132453: learning rate 0.0000
[2019-04-06 20:11:55,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:11:55,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:11:55,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run26
[2019-04-06 20:11:59,187] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1133085: loss 50.6528
[2019-04-06 20:11:59,189] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1133085: learning rate 0.0000
[2019-04-06 20:12:01,582] A3C_AGENT_WORKER-Thread-7 INFO:Local step 71000, global step 1133425: loss 1.0113
[2019-04-06 20:12:01,583] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 71000, global step 1133425: learning rate 0.0000
[2019-04-06 20:12:06,990] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:12:06,990] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:12:06,993] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run26
[2019-04-06 20:12:11,442] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:12:11,443] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:12:11,446] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run26
[2019-04-06 20:12:20,902] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.05322878e-19 2.44164381e-19 1.24255685e-14 4.32537540e-18
 1.00000000e+00 1.16988663e-21 1.01165393e-20], sum to 1.0000
[2019-04-06 20:12:20,903] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1631
[2019-04-06 20:12:20,903] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [2.0190653e-19 1.0743724e-20 1.4055964e-15 4.6773093e-18 1.0000000e+00
 1.9686226e-22 1.3736715e-20], sum to 1.0000
[2019-04-06 20:12:20,903] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2054
[2019-04-06 20:12:20,994] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 25.05229553623508, 0.5106241411661534, 0.0, 1.0, 127525.7143144296], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4480200.0000, 
sim time next is 4482000.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 25.57444897569913, 0.5807733261661219, 0.0, 1.0, 44610.451113334915], 
processed observation next is [1.0, 0.9130434782608695, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.6312040813082609, 0.6935911087220407, 0.0, 1.0, 0.2124307195873091], 
reward next is 0.7876, 
noisyNet noise sample is [array([0.05061003], dtype=float32), -0.5609468]. 
=============================================
[2019-04-06 20:12:21,068] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 82.0, 48.0, 0.0, 26.0, 25.44419509413319, 0.2931972066239109, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 898200.0000, 
sim time next is 900000.0000, 
raw observation next is [1.1, 84.0, 62.5, 0.0, 26.0, 25.44065731080764, 0.2949559790614668, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.49307479224376743, 0.84, 0.20833333333333334, 0.0, 0.6666666666666666, 0.6200547759006367, 0.5983186596871556, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.15349126], dtype=float32), 0.29186815]. 
=============================================
[2019-04-06 20:12:21,073] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[88.42524]
 [88.71252]
 [88.59594]
 [89.25015]
 [89.9153 ]], R is [[88.15117645]
 [87.66240692]
 [87.38909912]
 [87.47709656]
 [87.60232544]].
[2019-04-06 20:12:21,089] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[87.84604 ]
 [87.684006]
 [87.71484 ]
 [87.65867 ]
 [87.2859  ]], R is [[88.20877075]
 [88.32668304]
 [88.44342041]
 [88.55899048]
 [88.67340088]].
[2019-04-06 20:12:24,029] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1136823: loss 52.6167
[2019-04-06 20:12:24,029] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1136823: learning rate 0.0000
[2019-04-06 20:12:26,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:12:26,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:12:26,152] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run26
[2019-04-06 20:12:29,497] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1137736: loss 51.1764
[2019-04-06 20:12:29,499] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1137736: learning rate 0.0000
[2019-04-06 20:12:30,213] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:12:30,213] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:12:30,216] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run26
[2019-04-06 20:12:31,136] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1137958: loss 51.8196
[2019-04-06 20:12:31,137] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1137958: learning rate 0.0000
[2019-04-06 20:12:32,542] A3C_AGENT_WORKER-Thread-6 INFO:Local step 71000, global step 1138195: loss 1.0143
[2019-04-06 20:12:32,543] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 71000, global step 1138195: learning rate 0.0000
[2019-04-06 20:12:32,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.8270120e-19 2.9292643e-18 3.9762955e-14 6.4350900e-17 1.0000000e+00
 1.6899542e-20 3.8938847e-19], sum to 1.0000
[2019-04-06 20:12:32,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7622
[2019-04-06 20:12:33,144] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 65.0, 139.0, 0.0, 26.0, 25.1437140952652, 0.2362276968271078, 1.0, 1.0, 47866.01273451695], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 219600.0000, 
sim time next is 221400.0000, 
raw observation next is [-3.95, 63.5, 149.0, 0.0, 26.0, 24.38171928744288, 0.2867574754810047, 1.0, 1.0, 139746.37318987874], 
processed observation next is [1.0, 0.5652173913043478, 0.3531855955678671, 0.635, 0.49666666666666665, 0.0, 0.6666666666666666, 0.53180994062024, 0.5955858251603349, 1.0, 1.0, 0.6654589199518035], 
reward next is 0.3345, 
noisyNet noise sample is [array([-0.24190634], dtype=float32), 1.2451304]. 
=============================================
[2019-04-06 20:12:34,214] A3C_AGENT_WORKER-Thread-8 INFO:Local step 71500, global step 1138406: loss 50.8580
[2019-04-06 20:12:34,215] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 71500, global step 1138406: learning rate 0.0000
[2019-04-06 20:12:36,703] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:12:36,703] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:12:36,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run26
[2019-04-06 20:12:40,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:12:40,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:12:40,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run26
[2019-04-06 20:12:44,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:12:44,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:12:44,516] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run26
[2019-04-06 20:12:45,590] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1011231e-18 1.1611082e-17 3.1358942e-14 1.9190158e-17 1.0000000e+00
 4.6980789e-22 2.3848555e-19], sum to 1.0000
[2019-04-06 20:12:45,590] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9066
[2019-04-06 20:12:45,695] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.5, 24.5, 123.0, 865.0, 26.0, 27.08724519051458, 0.7269525037725323, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4969800.0000, 
sim time next is 4971600.0000, 
raw observation next is [7.0, 24.0, 120.0, 862.5, 26.0, 27.06780773907184, 0.6262892303214521, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.6565096952908588, 0.24, 0.4, 0.9530386740331491, 0.6666666666666666, 0.7556506449226532, 0.7087630767738173, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5100408], dtype=float32), -0.6399705]. 
=============================================
[2019-04-06 20:12:46,136] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1139822: loss 1.0368
[2019-04-06 20:12:46,136] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1139822: learning rate 0.0000
[2019-04-06 20:12:47,547] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-06 20:12:47,549] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:12:47,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:12:47,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run58
[2019-04-06 20:12:47,575] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:12:47,575] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:12:47,576] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:12:47,577] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:12:47,580] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run58
[2019-04-06 20:12:47,603] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run58
[2019-04-06 20:14:47,330] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14032795]
[2019-04-06 20:14:47,330] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [16.1, 67.0, 0.0, 0.0, 26.0, 27.16592758396276, 1.055133011629851, 0.0, 0.0, 0.0]
[2019-04-06 20:14:47,331] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 20:14:47,332] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.6770741e-17 2.2786865e-18 1.4231238e-14 3.1569901e-17 1.0000000e+00
 1.0155669e-20 5.1375464e-19], sampled 0.5044206803428257
[2019-04-06 20:14:56,327] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 20:15:34,187] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 20:15:37,618] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 20:15:38,655] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1140000, evaluation results [1140000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 20:15:41,581] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1140267: loss 0.9322
[2019-04-06 20:15:41,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1140267: learning rate 0.0000
[2019-04-06 20:15:44,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:15:44,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:15:44,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run26
[2019-04-06 20:15:49,609] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1140924: loss 2.2275
[2019-04-06 20:15:49,609] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1140924: learning rate 0.0000
[2019-04-06 20:15:50,001] A3C_AGENT_WORKER-Thread-7 INFO:Local step 71500, global step 1140959: loss 50.1230
[2019-04-06 20:15:50,001] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 71500, global step 1140959: learning rate 0.0000
[2019-04-06 20:15:55,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.6055173e-17 7.9485713e-19 1.2629912e-14 1.2717842e-16 1.0000000e+00
 8.8282466e-21 2.0529911e-18], sum to 1.0000
[2019-04-06 20:15:55,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9150
[2019-04-06 20:15:55,609] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.65, 84.5, 28.0, 0.0, 26.0, 24.98691472173229, 0.3342825152569738, 0.0, 1.0, 55964.1043243423], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1787400.0000, 
sim time next is 1789200.0000, 
raw observation next is [-3.9, 82.0, 14.5, 0.0, 26.0, 25.01069075861322, 0.3284738237380634, 0.0, 1.0, 40860.274677392874], 
processed observation next is [0.0, 0.7391304347826086, 0.3545706371191136, 0.82, 0.04833333333333333, 0.0, 0.6666666666666666, 0.5842242298844349, 0.6094912745793545, 0.0, 1.0, 0.1945727365590137], 
reward next is 0.8054, 
noisyNet noise sample is [array([0.233065], dtype=float32), -0.9719352]. 
=============================================
[2019-04-06 20:15:58,449] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1141489: loss 2.3439
[2019-04-06 20:15:58,450] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1141489: learning rate 0.0000
[2019-04-06 20:16:07,328] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1142125: loss 0.8992
[2019-04-06 20:16:07,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1142125: learning rate 0.0000
[2019-04-06 20:16:15,316] A3C_AGENT_WORKER-Thread-5 INFO:Local step 71000, global step 1142674: loss 0.9381
[2019-04-06 20:16:15,316] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 71000, global step 1142674: learning rate 0.0000
[2019-04-06 20:16:26,111] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1143393: loss 0.9449
[2019-04-06 20:16:26,112] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1143393: learning rate 0.0000
[2019-04-06 20:16:31,836] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1143769: loss 0.7634
[2019-04-06 20:16:31,837] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1143769: learning rate 0.0000
[2019-04-06 20:16:32,429] A3C_AGENT_WORKER-Thread-4 INFO:Local step 71000, global step 1143821: loss 0.8134
[2019-04-06 20:16:32,431] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 71000, global step 1143821: learning rate 0.0000
[2019-04-06 20:16:38,959] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1144315: loss 2.1815
[2019-04-06 20:16:38,960] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1144315: learning rate 0.0000
[2019-04-06 20:16:41,634] A3C_AGENT_WORKER-Thread-6 INFO:Local step 71500, global step 1144537: loss 50.6832
[2019-04-06 20:16:41,634] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 71500, global step 1144537: learning rate 0.0000
[2019-04-06 20:16:46,282] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1144840: loss 2.1998
[2019-04-06 20:16:46,283] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1144840: learning rate 0.0000
[2019-04-06 20:16:47,508] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1144934: loss 2.2416
[2019-04-06 20:16:47,509] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1144934: learning rate 0.0000
[2019-04-06 20:16:49,831] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1145130: loss 0.8027
[2019-04-06 20:16:49,832] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1145130: learning rate 0.0000
[2019-04-06 20:16:51,761] A3C_AGENT_WORKER-Thread-8 INFO:Local step 72000, global step 1145357: loss 2.4666
[2019-04-06 20:16:51,761] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 72000, global step 1145357: learning rate 0.0000
[2019-04-06 20:17:01,635] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1146570: loss 50.2241
[2019-04-06 20:17:01,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1146570: learning rate 0.0000
[2019-04-06 20:17:05,336] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0937160e-14 7.2696137e-16 1.0550323e-12 2.8880835e-14 1.0000000e+00
 9.8393605e-18 5.0473608e-16], sum to 1.0000
[2019-04-06 20:17:05,337] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5886
[2019-04-06 20:17:05,632] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.5, 58.0, 21.5, 228.0, 26.0, 22.83181662018244, -0.2198156499597087, 0.0, 1.0, 44162.01938527983], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2448000.0000, 
sim time next is 2449800.0000, 
raw observation next is [-8.4, 54.0, 40.0, 416.0, 26.0, 23.30744264149183, -0.00567590498779795, 0.0, 1.0, 149924.32074055568], 
processed observation next is [0.0, 0.34782608695652173, 0.2299168975069252, 0.54, 0.13333333333333333, 0.45966850828729283, 0.6666666666666666, 0.4422868867909857, 0.49810803167073403, 0.0, 1.0, 0.713925336859789], 
reward next is 0.2861, 
noisyNet noise sample is [array([-1.6500344], dtype=float32), 1.3027627]. 
=============================================
[2019-04-06 20:17:06,058] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1147228: loss 49.9081
[2019-04-06 20:17:06,069] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1147228: learning rate 0.0000
[2019-04-06 20:17:11,213] A3C_AGENT_WORKER-Thread-7 INFO:Local step 72000, global step 1147845: loss 2.3155
[2019-04-06 20:17:11,213] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 72000, global step 1147845: learning rate 0.0000
[2019-04-06 20:17:16,328] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1148544: loss 0.8828
[2019-04-06 20:17:16,328] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1148544: learning rate 0.0000
[2019-04-06 20:17:21,591] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1149337: loss 49.2028
[2019-04-06 20:17:21,605] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1149337: learning rate 0.0000
[2019-04-06 20:17:22,070] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1149412: loss 0.9162
[2019-04-06 20:17:22,078] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1149412: learning rate 0.0000
[2019-04-06 20:17:23,377] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5643037e-18 1.4989088e-19 1.2478198e-14 2.5219600e-17 1.0000000e+00
 3.6213224e-21 2.5835865e-19], sum to 1.0000
[2019-04-06 20:17:23,377] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7728
[2019-04-06 20:17:23,581] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.0, 61.5, 113.0, 799.0, 26.0, 25.86481673930652, 0.3619474276986732, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2723400.0000, 
sim time next is 2725200.0000, 
raw observation next is [-6.0, 59.0, 111.0, 793.5, 26.0, 25.36187789317043, 0.4880518870085745, 1.0, 1.0, 121803.56992693285], 
processed observation next is [1.0, 0.5652173913043478, 0.296398891966759, 0.59, 0.37, 0.8767955801104972, 0.6666666666666666, 0.6134898244308692, 0.6626839623361915, 1.0, 1.0, 0.5800169996520612], 
reward next is 0.4200, 
noisyNet noise sample is [array([-0.9817769], dtype=float32), -1.9851907]. 
=============================================
[2019-04-06 20:17:28,818] A3C_AGENT_WORKER-Thread-5 INFO:Local step 71500, global step 1150463: loss 49.4399
[2019-04-06 20:17:28,819] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 71500, global step 1150463: learning rate 0.0000
[2019-04-06 20:17:33,972] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1151299: loss 50.1132
[2019-04-06 20:17:33,972] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1151299: learning rate 0.0000
[2019-04-06 20:17:37,099] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1151813: loss 49.4615
[2019-04-06 20:17:37,101] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1151813: learning rate 0.0000
[2019-04-06 20:17:37,897] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.9856064e-16 1.1454297e-16 8.0783694e-14 6.9601714e-16 1.0000000e+00
 1.7866386e-18 4.2348111e-18], sum to 1.0000
[2019-04-06 20:17:37,897] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9020
[2019-04-06 20:17:37,908] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.1, 80.0, 0.0, 0.0, 26.0, 24.12549976935523, 0.273490727017861, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1213200.0000, 
sim time next is 1215000.0000, 
raw observation next is [16.1, 81.5, 0.0, 0.0, 26.0, 24.04438026601827, 0.2588012306726438, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.9085872576177286, 0.815, 0.0, 0.0, 0.6666666666666666, 0.5036983555015224, 0.5862670768908812, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.19273151], dtype=float32), 0.96399987]. 
=============================================
[2019-04-06 20:17:38,000] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[72.18388]
 [71.83637]
 [71.63922]
 [71.53718]
 [71.57862]], R is [[72.75843811]
 [73.03085327]
 [73.30054474]
 [73.56754303]
 [73.83187103]].
[2019-04-06 20:17:39,562] A3C_AGENT_WORKER-Thread-4 INFO:Local step 71500, global step 1152236: loss 49.5505
[2019-04-06 20:17:39,563] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 71500, global step 1152236: learning rate 0.0000
[2019-04-06 20:17:43,626] A3C_AGENT_WORKER-Thread-6 INFO:Local step 72000, global step 1152854: loss 2.6724
[2019-04-06 20:17:43,640] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 72000, global step 1152854: learning rate 0.0000
[2019-04-06 20:17:45,528] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1153171: loss 0.8052
[2019-04-06 20:17:45,529] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1153171: learning rate 0.0000
[2019-04-06 20:17:46,802] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1153353: loss 49.0897
[2019-04-06 20:17:46,802] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1153353: learning rate 0.0000
[2019-04-06 20:17:51,149] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1153976: loss 0.7039
[2019-04-06 20:17:51,154] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1153978: learning rate 0.0000
[2019-04-06 20:17:52,106] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1154129: loss 0.8556
[2019-04-06 20:17:52,106] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1154129: learning rate 0.0000
[2019-04-06 20:17:53,138] A3C_AGENT_WORKER-Thread-8 INFO:Local step 72500, global step 1154300: loss 0.7298
[2019-04-06 20:17:53,138] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 72500, global step 1154300: learning rate 0.0000
[2019-04-06 20:18:00,829] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1155494: loss 2.0917
[2019-04-06 20:18:00,837] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1155494: learning rate 0.0000
[2019-04-06 20:18:01,049] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.8580013e-20 6.7922923e-19 7.3138960e-16 5.1306131e-19 1.0000000e+00
 7.1840995e-23 1.5395244e-21], sum to 1.0000
[2019-04-06 20:18:01,049] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4605
[2019-04-06 20:18:01,095] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.54497405393963, 0.5478884011665139, 0.0, 1.0, 40145.39701584782], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3209400.0000, 
sim time next is 3211200.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.39899915100633, 0.5059667922742391, 0.0, 1.0, 50368.53036100648], 
processed observation next is [1.0, 0.17391304347826086, 0.4349030470914128, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6165832625838608, 0.6686555974247463, 0.0, 1.0, 0.23985014457622134], 
reward next is 0.7601, 
noisyNet noise sample is [array([1.7537411], dtype=float32), -0.9382312]. 
=============================================
[2019-04-06 20:18:01,385] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1155573: loss 0.9696
[2019-04-06 20:18:01,385] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1155573: learning rate 0.0000
[2019-04-06 20:18:05,569] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1156140: loss 2.0918
[2019-04-06 20:18:05,569] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1156140: learning rate 0.0000
[2019-04-06 20:18:07,046] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6250605e-17 2.3920729e-18 1.3734609e-14 1.4276917e-17 1.0000000e+00
 2.1534672e-21 2.2903894e-19], sum to 1.0000
[2019-04-06 20:18:07,046] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0546
[2019-04-06 20:18:07,257] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.55, 69.0, 0.0, 0.0, 26.0, 25.85477650040155, 0.4684777721710569, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2226600.0000, 
sim time next is 2228400.0000, 
raw observation next is [-4.6, 70.0, 0.0, 0.0, 26.0, 25.61073404656082, 0.398345887876014, 0.0, 1.0, 6455.798281200089], 
processed observation next is [1.0, 0.8260869565217391, 0.33518005540166207, 0.7, 0.0, 0.0, 0.6666666666666666, 0.6342278372134018, 0.632781962625338, 0.0, 1.0, 0.030741896577143282], 
reward next is 0.9693, 
noisyNet noise sample is [array([0.8062017], dtype=float32), -0.23218982]. 
=============================================
[2019-04-06 20:18:08,311] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1069566e-16 9.6208272e-17 1.1638290e-13 1.1630427e-14 1.0000000e+00
 3.7474989e-19 1.5763371e-17], sum to 1.0000
[2019-04-06 20:18:08,313] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6263
[2019-04-06 20:18:08,382] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.5, 39.5, 0.0, 0.0, 26.0, 25.09415744287852, 0.2998052075181497, 0.0, 1.0, 40841.75293907747], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4069800.0000, 
sim time next is 4071600.0000, 
raw observation next is [-5.0, 38.0, 0.0, 0.0, 26.0, 25.042541854259, 0.2848700346702867, 0.0, 1.0, 40762.84971826959], 
processed observation next is [1.0, 0.13043478260869565, 0.32409972299168976, 0.38, 0.0, 0.0, 0.6666666666666666, 0.5868784878549166, 0.5949566782234289, 0.0, 1.0, 0.19410880818223614], 
reward next is 0.8059, 
noisyNet noise sample is [array([1.0444071], dtype=float32), -1.1107931]. 
=============================================
[2019-04-06 20:18:09,156] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1156585: loss 0.9156
[2019-04-06 20:18:09,156] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1156585: learning rate 0.0000
[2019-04-06 20:18:13,005] A3C_AGENT_WORKER-Thread-7 INFO:Local step 72500, global step 1157087: loss 0.8140
[2019-04-06 20:18:13,005] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 72500, global step 1157087: learning rate 0.0000
[2019-04-06 20:18:16,110] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6903443e-18 2.4444394e-19 1.6731460e-15 1.8082094e-18 1.0000000e+00
 2.3487753e-21 4.0991798e-20], sum to 1.0000
[2019-04-06 20:18:16,121] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0550
[2019-04-06 20:18:16,364] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.7, 78.0, 139.5, 44.5, 26.0, 25.62985036618397, 0.3258346001854613, 1.0, 1.0, 18732.466268256652], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2282400.0000, 
sim time next is 2284200.0000, 
raw observation next is [-5.85, 73.0, 178.0, 50.0, 26.0, 25.74070977237601, 0.3466896078604058, 1.0, 1.0, 6242.586198204277], 
processed observation next is [1.0, 0.43478260869565216, 0.30055401662049863, 0.73, 0.5933333333333334, 0.055248618784530384, 0.6666666666666666, 0.6450591476980009, 0.6155632026201353, 1.0, 1.0, 0.02972660094382989], 
reward next is 0.9703, 
noisyNet noise sample is [array([-0.817679], dtype=float32), 0.0013604342]. 
=============================================
[2019-04-06 20:18:18,656] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9508288e-16 3.2665840e-18 7.0394293e-14 2.8051029e-16 1.0000000e+00
 7.5627915e-20 1.4617772e-17], sum to 1.0000
[2019-04-06 20:18:18,657] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4288
[2019-04-06 20:18:18,840] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 54.0, 221.5, 212.0, 26.0, 25.03374196044328, 0.3227336915688491, 0.0, 1.0, 6238.399902571663], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2379600.0000, 
sim time next is 2381400.0000, 
raw observation next is [-0.3, 53.0, 191.0, 0.0, 26.0, 24.93894207320054, 0.2907654882471321, 0.0, 1.0, 41313.27829596607], 
processed observation next is [0.0, 0.5652173913043478, 0.4542936288088643, 0.53, 0.6366666666666667, 0.0, 0.6666666666666666, 0.5782451727667116, 0.5969218294157107, 0.0, 1.0, 0.19672989664745746], 
reward next is 0.8033, 
noisyNet noise sample is [array([-1.0093338], dtype=float32), 2.4129813]. 
=============================================
[2019-04-06 20:18:20,726] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1158207: loss 2.2237
[2019-04-06 20:18:20,726] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1158207: learning rate 0.0000
[2019-04-06 20:18:27,522] A3C_AGENT_WORKER-Thread-5 INFO:Local step 72000, global step 1159231: loss 1.9665
[2019-04-06 20:18:27,522] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 72000, global step 1159231: learning rate 0.0000
[2019-04-06 20:18:30,944] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1159743: loss 0.9737
[2019-04-06 20:18:30,945] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1159743: learning rate 0.0000
[2019-04-06 20:18:32,791] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 20:18:32,791] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:18:32,791] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:18:32,795] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run59
[2019-04-06 20:18:32,813] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:18:32,813] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:18:32,833] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:18:32,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:18:32,840] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run59
[2019-04-06 20:18:32,865] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run59
[2019-04-06 20:18:58,909] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.13985372]
[2019-04-06 20:18:58,910] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-1.763515021, 67.70066712, 145.69507067, 166.20762925, 26.0, 25.05491546202447, 0.2650256488143464, 0.0, 1.0, 0.0]
[2019-04-06 20:18:58,910] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 20:18:58,911] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [6.9050814e-17 9.9689103e-18 5.9358497e-14 1.9667595e-16 1.0000000e+00
 5.8367874e-20 3.4773668e-18], sampled 0.7692737038914578
[2019-04-06 20:20:39,164] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 20:21:15,098] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 20:21:19,319] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 20:21:20,357] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1160000, evaluation results [1160000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 20:21:21,046] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.4484205e-19 2.5343585e-20 1.6088439e-14 3.7322803e-17 1.0000000e+00
 1.8378110e-20 1.1760768e-18], sum to 1.0000
[2019-04-06 20:21:21,046] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1615
[2019-04-06 20:21:21,138] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 44.0, 0.0, 0.0, 26.0, 25.49221027132557, 0.4280455584593958, 0.0, 1.0, 20531.62010942539], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2844000.0000, 
sim time next is 2845800.0000, 
raw observation next is [2.0, 53.0, 0.0, 0.0, 26.0, 25.3324178985343, 0.3596516350606147, 0.0, 1.0, 63022.68357871199], 
processed observation next is [1.0, 0.9565217391304348, 0.518005540166205, 0.53, 0.0, 0.0, 0.6666666666666666, 0.6110348248778582, 0.6198838783535382, 0.0, 1.0, 0.30010801704148565], 
reward next is 0.6999, 
noisyNet noise sample is [array([0.35847524], dtype=float32), 1.7026801]. 
=============================================
[2019-04-06 20:21:21,249] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1160088: loss 2.1384
[2019-04-06 20:21:21,251] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1160088: learning rate 0.0000
[2019-04-06 20:21:25,270] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1160431: loss 2.2452
[2019-04-06 20:21:25,270] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1160431: learning rate 0.0000
[2019-04-06 20:21:28,044] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1160648: loss 1.0943
[2019-04-06 20:21:28,044] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1160648: learning rate 0.0000
[2019-04-06 20:21:28,658] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6157885e-17 1.1752779e-19 1.3243148e-15 5.9916199e-18 1.0000000e+00
 2.3259408e-21 1.2794610e-19], sum to 1.0000
[2019-04-06 20:21:28,659] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0549
[2019-04-06 20:21:28,833] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 50.0, 109.0, 68.0, 26.0, 26.37854243787124, 0.5787929809757022, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4552200.0000, 
sim time next is 4554000.0000, 
raw observation next is [2.0, 52.0, 68.5, 48.0, 26.0, 25.07800248168648, 0.4516790753477093, 1.0, 1.0, 42834.0070557562], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.52, 0.22833333333333333, 0.05303867403314917, 0.6666666666666666, 0.5898335401405399, 0.6505596917825698, 1.0, 1.0, 0.20397146217026763], 
reward next is 0.7960, 
noisyNet noise sample is [array([-0.1968386], dtype=float32), -0.47434992]. 
=============================================
[2019-04-06 20:21:28,836] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[83.24783]
 [83.38907]
 [84.01123]
 [84.95804]
 [85.76718]], R is [[83.23831177]
 [83.40592957]
 [83.5718689 ]
 [83.73615265]
 [83.89878845]].
[2019-04-06 20:21:29,511] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1160764: loss 1.0004
[2019-04-06 20:21:29,511] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1160764: learning rate 0.0000
[2019-04-06 20:21:30,550] A3C_AGENT_WORKER-Thread-8 INFO:Local step 73000, global step 1160850: loss 1.0944
[2019-04-06 20:21:30,551] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 73000, global step 1160850: learning rate 0.0000
[2019-04-06 20:21:30,760] A3C_AGENT_WORKER-Thread-4 INFO:Local step 72000, global step 1160871: loss 2.3651
[2019-04-06 20:21:30,769] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 72000, global step 1160871: learning rate 0.0000
[2019-04-06 20:21:36,310] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.3375386e-17 4.0458694e-17 4.2225061e-13 1.9303520e-17 1.0000000e+00
 7.7386837e-20 3.1167584e-18], sum to 1.0000
[2019-04-06 20:21:36,310] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7804
[2019-04-06 20:21:36,949] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 69.0, 19.5, 0.0, 26.0, 23.91063895871935, 0.06930556240758923, 0.0, 1.0, 41888.83506701159], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2361600.0000, 
sim time next is 2363400.0000, 
raw observation next is [-3.4, 69.0, 37.0, 0.0, 26.0, 24.32653716107244, 0.2248567102113566, 0.0, 1.0, 149018.30715154903], 
processed observation next is [0.0, 0.34782608695652173, 0.368421052631579, 0.69, 0.12333333333333334, 0.0, 0.6666666666666666, 0.5272114300893701, 0.5749522367371188, 0.0, 1.0, 0.7096109864359478], 
reward next is 0.2904, 
noisyNet noise sample is [array([1.6325867], dtype=float32), -0.46436942]. 
=============================================
[2019-04-06 20:21:40,426] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1161715: loss 0.2593
[2019-04-06 20:21:40,427] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1161715: learning rate 0.0000
[2019-04-06 20:21:42,357] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1161874: loss 2.0207
[2019-04-06 20:21:42,360] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1161874: learning rate 0.0000
[2019-04-06 20:21:45,019] A3C_AGENT_WORKER-Thread-6 INFO:Local step 72500, global step 1162134: loss 0.9158
[2019-04-06 20:21:45,020] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 72500, global step 1162134: learning rate 0.0000
[2019-04-06 20:21:53,498] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1162948: loss 0.2632
[2019-04-06 20:21:53,499] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1162948: learning rate 0.0000
[2019-04-06 20:21:56,661] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.9930476e-17 1.6691090e-17 2.6303373e-14 1.5899198e-16 1.0000000e+00
 2.3418071e-20 1.1882390e-18], sum to 1.0000
[2019-04-06 20:21:56,662] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2157
[2019-04-06 20:21:57,152] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 69.0, 19.5, 0.0, 26.0, 23.91063895871935, 0.06930556240758923, 0.0, 1.0, 41888.83506701159], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2361600.0000, 
sim time next is 2363400.0000, 
raw observation next is [-3.4, 69.0, 37.0, 0.0, 26.0, 24.32653716107244, 0.2248567102113566, 0.0, 1.0, 149018.30715154903], 
processed observation next is [0.0, 0.34782608695652173, 0.368421052631579, 0.69, 0.12333333333333334, 0.0, 0.6666666666666666, 0.5272114300893701, 0.5749522367371188, 0.0, 1.0, 0.7096109864359478], 
reward next is 0.2904, 
noisyNet noise sample is [array([0.45046782], dtype=float32), 0.3934548]. 
=============================================
[2019-04-06 20:21:59,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:21:59,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:21:59,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run27
[2019-04-06 20:22:00,007] A3C_AGENT_WORKER-Thread-7 INFO:Local step 73000, global step 1163586: loss 1.1646
[2019-04-06 20:22:00,008] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 73000, global step 1163586: learning rate 0.0000
[2019-04-06 20:22:12,010] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:22:12,011] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:22:12,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run27
[2019-04-06 20:22:13,515] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1164799: loss 0.7974
[2019-04-06 20:22:13,516] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1164799: learning rate 0.0000
[2019-04-06 20:22:20,538] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1165416: loss 0.8836
[2019-04-06 20:22:20,538] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1165416: learning rate 0.0000
[2019-04-06 20:22:26,072] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1165939: loss 0.3210
[2019-04-06 20:22:26,072] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1165939: learning rate 0.0000
[2019-04-06 20:22:32,256] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8294541e-18 5.6100423e-18 3.5827928e-14 3.3807229e-16 1.0000000e+00
 4.1165385e-22 2.4649370e-19], sum to 1.0000
[2019-04-06 20:22:32,257] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8504
[2019-04-06 20:22:32,394] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 78.0, 0.0, 0.0, 26.0, 24.50093889030452, 0.1483958366915884, 0.0, 1.0, 42317.01559400284], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2606400.0000, 
sim time next is 2608200.0000, 
raw observation next is [-5.9, 80.5, 0.0, 0.0, 26.0, 24.36935951517355, 0.1326370932084503, 0.0, 1.0, 42632.54012850815], 
processed observation next is [1.0, 0.17391304347826086, 0.2991689750692521, 0.805, 0.0, 0.0, 0.6666666666666666, 0.5307799595977958, 0.5442123644028167, 0.0, 1.0, 0.20301209585003882], 
reward next is 0.7970, 
noisyNet noise sample is [array([1.3353974], dtype=float32), -0.33007857]. 
=============================================
[2019-04-06 20:22:33,661] A3C_AGENT_WORKER-Thread-8 INFO:Local step 73500, global step 1167058: loss 0.3158
[2019-04-06 20:22:33,663] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 73500, global step 1167058: learning rate 0.0000
[2019-04-06 20:22:33,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8169584e-19 2.9539962e-18 1.5590260e-15 2.8305755e-18 1.0000000e+00
 3.9616632e-21 2.4511520e-20], sum to 1.0000
[2019-04-06 20:22:33,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2710
[2019-04-06 20:22:33,772] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.0, 24.0, 106.5, 0.0, 26.0, 24.73762345529379, 0.3005808910791239, 1.0, 1.0, 63589.14842036654], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2818800.0000, 
sim time next is 2820600.0000, 
raw observation next is [6.8, 24.5, 95.0, 0.0, 26.0, 25.66033518937199, 0.381976773819219, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.6509695290858727, 0.245, 0.31666666666666665, 0.0, 0.6666666666666666, 0.6383612657809993, 0.627325591273073, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.04605089], dtype=float32), 0.95460653]. 
=============================================
[2019-04-06 20:22:33,788] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1167080: loss 0.3530
[2019-04-06 20:22:33,801] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1167080: learning rate 0.0000
[2019-04-06 20:22:34,123] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1167127: loss 0.3382
[2019-04-06 20:22:34,132] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1167127: learning rate 0.0000
[2019-04-06 20:22:36,610] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1167488: loss 0.9129
[2019-04-06 20:22:36,610] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1167488: learning rate 0.0000
[2019-04-06 20:22:36,628] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5856002e-19 2.9956754e-19 3.9470714e-16 3.2329992e-19 1.0000000e+00
 9.2003882e-23 7.2007332e-21], sum to 1.0000
[2019-04-06 20:22:36,628] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6187
[2019-04-06 20:22:36,676] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.5, 31.0, 123.0, 845.0, 26.0, 27.33913313909142, 0.8294039909983626, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5052600.0000, 
sim time next is 5054400.0000, 
raw observation next is [8.0, 26.0, 123.5, 855.0, 26.0, 27.36486379245746, 0.8535006671313328, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6842105263157896, 0.26, 0.4116666666666667, 0.9447513812154696, 0.6666666666666666, 0.7804053160381216, 0.7845002223771109, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7467419], dtype=float32), -0.5672873]. 
=============================================
[2019-04-06 20:22:36,823] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.7994378e-17 4.2624954e-17 1.2448816e-14 1.7264070e-17 1.0000000e+00
 1.2968850e-20 4.2231939e-19], sum to 1.0000
[2019-04-06 20:22:36,824] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1884
[2019-04-06 20:22:36,883] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.76120814708196, 0.2225198491705667, 0.0, 1.0, 41820.40381299078], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2772000.0000, 
sim time next is 2773800.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.63593307661485, 0.2053817639020753, 0.0, 1.0, 41500.0896204446], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5529944230512376, 0.5684605879673584, 0.0, 1.0, 0.19761947438306954], 
reward next is 0.8024, 
noisyNet noise sample is [array([2.0526335], dtype=float32), -0.15240857]. 
=============================================
[2019-04-06 20:22:36,956] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0131980e-20 2.9353590e-19 1.0916397e-15 4.8946753e-19 1.0000000e+00
 1.2245951e-22 4.2138883e-21], sum to 1.0000
[2019-04-06 20:22:36,956] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3713
[2019-04-06 20:22:37,012] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 48.0, 104.0, 711.0, 26.0, 26.53756548909371, 0.6001650453378713, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3405600.0000, 
sim time next is 3407400.0000, 
raw observation next is [2.5, 48.5, 109.0, 764.0, 26.0, 26.54249672606654, 0.6209665376933992, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.5318559556786704, 0.485, 0.36333333333333334, 0.8441988950276244, 0.6666666666666666, 0.7118747271722116, 0.7069888458977998, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7498671], dtype=float32), 0.9051027]. 
=============================================
[2019-04-06 20:22:37,823] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1648614e-17 4.8378170e-19 7.0969375e-15 1.0707087e-16 1.0000000e+00
 1.4097814e-20 8.7359268e-19], sum to 1.0000
[2019-04-06 20:22:37,823] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0813
[2019-04-06 20:22:37,921] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.05, 69.0, 0.0, 0.0, 26.0, 25.22055351898411, 0.3592776023462027, 0.0, 1.0, 54443.64019698595], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2673000.0000, 
sim time next is 2674800.0000, 
raw observation next is [-5.0, 69.0, 0.0, 0.0, 26.0, 24.98019332836897, 0.3210251784497325, 0.0, 1.0, 45497.4957809558], 
processed observation next is [1.0, 1.0, 0.32409972299168976, 0.69, 0.0, 0.0, 0.6666666666666666, 0.5816827773640808, 0.6070083928165775, 0.0, 1.0, 0.2166547418140752], 
reward next is 0.7833, 
noisyNet noise sample is [array([-0.48249087], dtype=float32), 0.3785393]. 
=============================================
[2019-04-06 20:22:38,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:22:38,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:22:38,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run27
[2019-04-06 20:22:43,445] A3C_AGENT_WORKER-Thread-5 INFO:Local step 72500, global step 1168475: loss 0.8835
[2019-04-06 20:22:43,445] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 72500, global step 1168475: learning rate 0.0000
[2019-04-06 20:22:46,009] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:22:46,009] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:22:46,047] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run27
[2019-04-06 20:22:46,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:22:46,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:22:46,860] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run27
[2019-04-06 20:22:47,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:22:47,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:22:47,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run27
[2019-04-06 20:22:47,387] A3C_AGENT_WORKER-Thread-6 INFO:Local step 73000, global step 1168964: loss 1.2638
[2019-04-06 20:22:47,387] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 73000, global step 1168964: learning rate 0.0000
[2019-04-06 20:22:49,749] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1169253: loss 0.8872
[2019-04-06 20:22:49,750] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1169253: learning rate 0.0000
[2019-04-06 20:22:52,703] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1169553: loss 0.8937
[2019-04-06 20:22:52,704] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1169553: learning rate 0.0000
[2019-04-06 20:22:53,911] A3C_AGENT_WORKER-Thread-7 INFO:Local step 73500, global step 1169688: loss 0.3100
[2019-04-06 20:22:53,912] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 73500, global step 1169688: learning rate 0.0000
[2019-04-06 20:22:56,421] A3C_AGENT_WORKER-Thread-4 INFO:Local step 72500, global step 1170038: loss 0.8501
[2019-04-06 20:22:56,421] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 72500, global step 1170038: learning rate 0.0000
[2019-04-06 20:23:02,838] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2753559e-19 1.7705366e-20 1.2099816e-15 2.6329859e-19 1.0000000e+00
 4.1877953e-23 8.0866457e-22], sum to 1.0000
[2019-04-06 20:23:02,838] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5294
[2019-04-06 20:23:02,888] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.25, 89.0, 0.0, 0.0, 26.0, 24.2290637948696, 0.1108596432935512, 0.0, 1.0, 42280.05455176283], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 95400.0000, 
sim time next is 97200.0000, 
raw observation next is [-2.8, 87.0, 0.0, 0.0, 26.0, 24.12249831499459, 0.08594783406296469, 0.0, 1.0, 42770.87779048009], 
processed observation next is [1.0, 0.13043478260869565, 0.38504155124653744, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5102081929162159, 0.5286492780209883, 0.0, 1.0, 0.20367084662133375], 
reward next is 0.7963, 
noisyNet noise sample is [array([0.49493453], dtype=float32), 1.0480837]. 
=============================================
[2019-04-06 20:23:04,453] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1171183: loss 1.1855
[2019-04-06 20:23:04,454] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1171183: learning rate 0.0000
[2019-04-06 20:23:04,733] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1171217: loss 0.7987
[2019-04-06 20:23:04,734] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1171217: learning rate 0.0000
[2019-04-06 20:23:06,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:23:06,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:23:06,836] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run27
[2019-04-06 20:23:09,916] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1171936: loss 1.2303
[2019-04-06 20:23:09,917] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1171936: learning rate 0.0000
[2019-04-06 20:23:22,925] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1173768: loss 1.2477
[2019-04-06 20:23:22,926] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1173768: learning rate 0.0000
[2019-04-06 20:23:23,801] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.8395720e-19 1.3202409e-20 2.1784831e-16 4.7789383e-19 1.0000000e+00
 6.0542815e-23 4.4650373e-21], sum to 1.0000
[2019-04-06 20:23:23,801] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8564
[2019-04-06 20:23:23,946] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 77.0, 48.0, 298.0, 26.0, 25.3924302335743, 0.376724376484267, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3830400.0000, 
sim time next is 3832200.0000, 
raw observation next is [-4.5, 74.0, 91.0, 447.0, 26.0, 25.55966713493557, 0.4589951950484685, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3379501385041552, 0.74, 0.30333333333333334, 0.49392265193370166, 0.6666666666666666, 0.6299722612446308, 0.6529983983494895, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.48801497], dtype=float32), -1.6286054]. 
=============================================
[2019-04-06 20:23:29,298] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1028350e-17 6.6800532e-19 1.6090566e-13 1.2291004e-17 1.0000000e+00
 6.8718494e-22 4.2534439e-19], sum to 1.0000
[2019-04-06 20:23:29,298] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7054
[2019-04-06 20:23:29,366] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 74.0, 0.0, 0.0, 26.0, 24.87011932505815, 0.2746775716912806, 0.0, 1.0, 43831.59905197171], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3821400.0000, 
sim time next is 3823200.0000, 
raw observation next is [-5.0, 77.0, 0.0, 0.0, 26.0, 24.87364227445928, 0.2763469555537154, 0.0, 1.0, 43543.01368574512], 
processed observation next is [1.0, 0.2608695652173913, 0.32409972299168976, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5728035228716065, 0.5921156518512385, 0.0, 1.0, 0.20734768421783392], 
reward next is 0.7927, 
noisyNet noise sample is [array([-0.89694935], dtype=float32), 0.025440704]. 
=============================================
[2019-04-06 20:23:30,918] A3C_AGENT_WORKER-Thread-5 INFO:Local step 73000, global step 1174921: loss 0.9793
[2019-04-06 20:23:30,919] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 73000, global step 1174921: learning rate 0.0000
[2019-04-06 20:23:32,837] A3C_AGENT_WORKER-Thread-6 INFO:Local step 73500, global step 1175192: loss 0.3431
[2019-04-06 20:23:32,838] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 73500, global step 1175192: learning rate 0.0000
[2019-04-06 20:23:37,302] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1175846: loss 1.1403
[2019-04-06 20:23:37,303] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1175846: learning rate 0.0000
[2019-04-06 20:23:39,634] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.7112958e-23 3.3077819e-22 2.9939991e-17 8.6849804e-21 1.0000000e+00
 4.2006686e-26 5.0383205e-23], sum to 1.0000
[2019-04-06 20:23:39,634] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5673
[2019-04-06 20:23:39,716] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1176206: loss 1.1691
[2019-04-06 20:23:39,717] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1176206: learning rate 0.0000
[2019-04-06 20:23:39,726] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [10.5, 93.0, 78.0, 0.0, 26.0, 26.47273914376582, 0.6299901681162962, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 986400.0000, 
sim time next is 988200.0000, 
raw observation next is [11.05, 89.5, 96.0, 0.0, 26.0, 26.60595180772037, 0.6549401751975935, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.7686980609418284, 0.895, 0.32, 0.0, 0.6666666666666666, 0.7171626506433642, 0.7183133917325312, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7565256], dtype=float32), -0.43724635]. 
=============================================
[2019-04-06 20:23:43,502] A3C_AGENT_WORKER-Thread-4 INFO:Local step 73000, global step 1176811: loss 1.1342
[2019-04-06 20:23:43,503] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 73000, global step 1176811: learning rate 0.0000
[2019-04-06 20:23:45,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:23:45,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:23:45,392] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run27
[2019-04-06 20:23:50,458] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1177892: loss 0.3012
[2019-04-06 20:23:50,461] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1177892: learning rate 0.0000
[2019-04-06 20:23:50,893] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1177956: loss 1.3124
[2019-04-06 20:23:50,894] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1177956: learning rate 0.0000
[2019-04-06 20:23:52,808] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.6529185e-19 1.9294666e-19 1.1195502e-14 1.5438376e-18 1.0000000e+00
 3.8510544e-22 2.1786770e-21], sum to 1.0000
[2019-04-06 20:23:52,821] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3639
[2019-04-06 20:23:52,893] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.0, 35.0, 94.0, 695.0, 26.0, 25.93534144411896, 0.6546307830735225, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4116600.0000, 
sim time next is 4118400.0000, 
raw observation next is [4.0, 35.0, 93.5, 566.0, 26.0, 26.96444015901703, 0.7716527201984364, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5734072022160666, 0.35, 0.31166666666666665, 0.625414364640884, 0.6666666666666666, 0.7470366799180859, 0.7572175733994788, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2180903], dtype=float32), 0.51116747]. 
=============================================
[2019-04-06 20:23:55,015] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1178653: loss 0.2926
[2019-04-06 20:23:55,016] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1178653: learning rate 0.0000
[2019-04-06 20:23:58,826] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.6174487e-19 5.5107310e-19 1.1305368e-14 5.7518724e-18 1.0000000e+00
 3.9339966e-22 1.4833516e-19], sum to 1.0000
[2019-04-06 20:23:58,826] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7528
[2019-04-06 20:23:58,861] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 45.0, 0.0, 0.0, 26.0, 25.38167556744833, 0.3409024804432597, 0.0, 1.0, 43038.81794236383], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4244400.0000, 
sim time next is 4246200.0000, 
raw observation next is [3.0, 45.0, 0.0, 0.0, 26.0, 25.41617705805561, 0.3386269160490409, 0.0, 1.0, 32666.70831390413], 
processed observation next is [0.0, 0.13043478260869565, 0.5457063711911359, 0.45, 0.0, 0.0, 0.6666666666666666, 0.6180147548379674, 0.6128756386830136, 0.0, 1.0, 0.15555575387573395], 
reward next is 0.8444, 
noisyNet noise sample is [array([0.8936631], dtype=float32), -0.24335614]. 
=============================================
[2019-04-06 20:24:03,492] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:24:03,492] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:24:03,496] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run27
[2019-04-06 20:24:03,661] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 20:24:03,661] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:24:03,662] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:24:03,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run60
[2019-04-06 20:24:03,694] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:24:03,696] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:24:03,700] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run60
[2019-04-06 20:24:03,717] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:24:03,718] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:24:03,722] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run60
[2019-04-06 20:26:08,466] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 20:26:46,447] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 20:26:50,460] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 20:26:51,499] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1180000, evaluation results [1180000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 20:26:56,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:26:56,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:26:56,664] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run27
[2019-04-06 20:26:56,794] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1180551: loss 0.3269
[2019-04-06 20:26:56,794] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1180551: learning rate 0.0000
[2019-04-06 20:27:09,732] A3C_AGENT_WORKER-Thread-5 INFO:Local step 73500, global step 1181859: loss 0.3515
[2019-04-06 20:27:09,732] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 73500, global step 1181859: learning rate 0.0000
[2019-04-06 20:27:09,872] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4584737e-21 3.3581549e-22 4.8416066e-17 2.7054150e-21 1.0000000e+00
 2.0284554e-24 1.5565721e-22], sum to 1.0000
[2019-04-06 20:27:09,872] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0153
[2019-04-06 20:27:09,966] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.5, 96.0, 0.0, 0.0, 26.0, 25.60687986015116, 0.4594757457435543, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4681800.0000, 
sim time next is 4683600.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.5829232637286, 0.4188764593280461, 0.0, 1.0, 14246.851305787926], 
processed observation next is [1.0, 0.21739130434782608, 0.4349030470914128, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6319102719773833, 0.639625486442682, 0.0, 1.0, 0.0678421490751806], 
reward next is 0.9322, 
noisyNet noise sample is [array([-1.3645195], dtype=float32), -1.2370484]. 
=============================================
[2019-04-06 20:27:16,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:27:16,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:27:16,584] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run27
[2019-04-06 20:27:22,466] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1183091: loss 0.3636
[2019-04-06 20:27:22,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1183091: learning rate 0.0000
[2019-04-06 20:27:24,838] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1183289: loss 0.2616
[2019-04-06 20:27:24,839] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1183289: learning rate 0.0000
[2019-04-06 20:27:28,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:27:28,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:27:28,736] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run27
[2019-04-06 20:27:30,718] A3C_AGENT_WORKER-Thread-4 INFO:Local step 73500, global step 1183804: loss 0.3370
[2019-04-06 20:27:30,723] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 73500, global step 1183804: learning rate 0.0000
[2019-04-06 20:27:39,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:27:39,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:27:39,972] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run27
[2019-04-06 20:27:41,675] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1184740: loss 0.2606
[2019-04-06 20:27:41,676] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1184740: learning rate 0.0000
[2019-04-06 20:27:42,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:27:42,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:27:42,635] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run27
[2019-04-06 20:27:49,139] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:27:49,139] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:27:49,142] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run27
[2019-04-06 20:27:58,823] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:27:58,823] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:27:58,832] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run27
[2019-04-06 20:28:21,577] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5279008e-17 7.4809371e-18 5.5584389e-14 6.0514633e-16 1.0000000e+00
 1.2294556e-19 4.9876766e-18], sum to 1.0000
[2019-04-06 20:28:21,577] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8116
[2019-04-06 20:28:21,634] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.1, 67.0, 0.0, 0.0, 26.0, 24.38290660279587, 0.1507350645069453, 0.0, 1.0, 40429.14002827604], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2349000.0000, 
sim time next is 2350800.0000, 
raw observation next is [-3.4, 69.0, 0.0, 0.0, 26.0, 24.27388451597816, 0.1289497796008474, 0.0, 1.0, 40764.04118697188], 
processed observation next is [0.0, 0.21739130434782608, 0.368421052631579, 0.69, 0.0, 0.0, 0.6666666666666666, 0.5228237096648467, 0.5429832598669492, 0.0, 1.0, 0.19411448184272323], 
reward next is 0.8059, 
noisyNet noise sample is [array([-1.5298982], dtype=float32), 0.24047685]. 
=============================================
[2019-04-06 20:28:35,320] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.60713131e-18 3.60367334e-19 8.98500109e-15 4.22728998e-18
 1.00000000e+00 1.14818776e-20 7.02661108e-20], sum to 1.0000
[2019-04-06 20:28:35,320] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6555
[2019-04-06 20:28:35,468] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.9, 66.0, 149.0, 0.0, 26.0, 25.5504742386505, 0.4209977725794377, 1.0, 1.0, 32526.60044782868], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2122200.0000, 
sim time next is 2124000.0000, 
raw observation next is [-5.6, 68.0, 137.0, 0.0, 26.0, 25.54711287449502, 0.3979398287033759, 1.0, 1.0, 17941.28023153859], 
processed observation next is [1.0, 0.6086956521739131, 0.30747922437673136, 0.68, 0.45666666666666667, 0.0, 0.6666666666666666, 0.628926072874585, 0.632646609567792, 1.0, 1.0, 0.08543466776923138], 
reward next is 0.9146, 
noisyNet noise sample is [array([-0.31238088], dtype=float32), 0.112438984]. 
=============================================
[2019-04-06 20:28:35,472] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[81.6724 ]
 [82.00012]
 [81.64326]
 [82.58648]
 [83.44727]], R is [[81.54814911]
 [81.57777405]
 [81.28570557]
 [81.47284698]
 [81.6581192 ]].
[2019-04-06 20:28:49,406] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7968158e-18 2.6812719e-20 1.7115172e-15 2.2775221e-18 1.0000000e+00
 6.2707970e-22 5.7429841e-21], sum to 1.0000
[2019-04-06 20:28:49,406] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3133
[2019-04-06 20:28:49,471] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.15, 94.0, 0.0, 0.0, 26.0, 24.86100994893366, 0.2340962933339965, 0.0, 1.0, 41779.411352758216], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 509400.0000, 
sim time next is 511200.0000, 
raw observation next is [2.7, 92.0, 0.0, 0.0, 26.0, 24.86015450507023, 0.2342903772820031, 0.0, 1.0, 41220.50486136686], 
processed observation next is [1.0, 0.9565217391304348, 0.5373961218836566, 0.92, 0.0, 0.0, 0.6666666666666666, 0.5716795420891859, 0.5780967924273344, 0.0, 1.0, 0.19628811838746124], 
reward next is 0.8037, 
noisyNet noise sample is [array([0.55215734], dtype=float32), 1.4482831]. 
=============================================
[2019-04-06 20:29:01,859] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6340680e-17 3.4958026e-17 5.6411247e-15 1.6153147e-16 1.0000000e+00
 2.7346154e-19 1.4353635e-18], sum to 1.0000
[2019-04-06 20:29:01,859] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5583
[2019-04-06 20:29:02,123] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 54.0, 83.0, 38.0, 26.0, 24.89313314038207, 0.2220593395384649, 0.0, 1.0, 32402.25097552603], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 660600.0000, 
sim time next is 662400.0000, 
raw observation next is [-0.6, 54.0, 55.0, 26.5, 26.0, 24.87719647224227, 0.2227260340197465, 0.0, 1.0, 44767.058319824915], 
processed observation next is [0.0, 0.6956521739130435, 0.44598337950138506, 0.54, 0.18333333333333332, 0.029281767955801105, 0.6666666666666666, 0.5730997060201893, 0.5742420113399155, 0.0, 1.0, 0.21317646818964245], 
reward next is 0.7868, 
noisyNet noise sample is [array([-0.40143615], dtype=float32), 2.2049973]. 
=============================================
[2019-04-06 20:29:05,566] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0597604e-18 6.4047158e-19 5.4112098e-15 5.6376528e-18 1.0000000e+00
 4.1931227e-21 1.9041299e-20], sum to 1.0000
[2019-04-06 20:29:05,566] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5708
[2019-04-06 20:29:05,706] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 45.0, 216.0, 130.0, 26.0, 26.42136218408088, 0.4347141848331331, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2644200.0000, 
sim time next is 2646000.0000, 
raw observation next is [0.5, 47.0, 185.5, 168.0, 26.0, 25.58254118764808, 0.4385070432945035, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.4764542936288089, 0.47, 0.6183333333333333, 0.1856353591160221, 0.6666666666666666, 0.6318784323040066, 0.6461690144315012, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5473894], dtype=float32), -0.58810574]. 
=============================================
[2019-04-06 20:29:05,709] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[82.515915]
 [82.523346]
 [82.5794  ]
 [83.068794]
 [82.34044 ]], R is [[82.03907013]
 [82.21868134]
 [82.396492  ]
 [82.57252502]
 [82.11817169]].
[2019-04-06 20:29:20,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8930806e-17 5.3565917e-18 9.3462069e-14 7.0226019e-17 1.0000000e+00
 1.6590766e-20 2.3595643e-18], sum to 1.0000
[2019-04-06 20:29:20,693] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8204
[2019-04-06 20:29:20,809] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.8, 74.0, 0.0, 0.0, 26.0, 23.87077233357337, 0.04655497755630863, 0.0, 1.0, 41385.24039685304], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 788400.0000, 
sim time next is 790200.0000, 
raw observation next is [-7.55, 74.5, 0.0, 0.0, 26.0, 23.93428075105701, 0.0351461702789788, 0.0, 1.0, 41223.0032238389], 
processed observation next is [1.0, 0.13043478260869565, 0.25346260387811637, 0.745, 0.0, 0.0, 0.6666666666666666, 0.4945233959214175, 0.5117153900929929, 0.0, 1.0, 0.19630001535161382], 
reward next is 0.8037, 
noisyNet noise sample is [array([0.27033857], dtype=float32), -0.6191804]. 
=============================================
[2019-04-06 20:29:31,137] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1212323e-17 7.4970497e-18 1.2197194e-13 9.0992660e-17 1.0000000e+00
 6.3434148e-20 2.1244314e-18], sum to 1.0000
[2019-04-06 20:29:31,137] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5360
[2019-04-06 20:29:31,154] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 26.0, 23.58357639551268, 0.1641455987682474, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1231200.0000, 
sim time next is 1233000.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 26.0, 23.54161122248833, 0.1569648596506685, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.8781163434903049, 0.96, 0.0, 0.0, 0.6666666666666666, 0.46180093520736093, 0.5523216198835562, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0188158], dtype=float32), -1.6780517]. 
=============================================
[2019-04-06 20:29:31,177] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.47226 ]
 [74.49832 ]
 [74.40944 ]
 [74.33587 ]
 [74.226685]], R is [[74.60900116]
 [74.86291504]
 [75.11428833]
 [75.36314392]
 [75.60951233]].
[2019-04-06 20:29:32,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5507982e-16 3.7821121e-18 7.9359120e-14 4.2255833e-17 1.0000000e+00
 2.1447454e-20 1.2394251e-18], sum to 1.0000
[2019-04-06 20:29:32,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5601
[2019-04-06 20:29:32,808] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 82.0, 0.0, 0.0, 26.0, 23.54398886307692, -0.112475144136061, 0.0, 1.0, 45133.0806984246], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1920600.0000, 
sim time next is 1922400.0000, 
raw observation next is [-8.9, 82.0, 0.0, 0.0, 26.0, 23.36192298534186, -0.1523010158423481, 0.0, 1.0, 44927.53272996672], 
processed observation next is [1.0, 0.2608695652173913, 0.21606648199445982, 0.82, 0.0, 0.0, 0.6666666666666666, 0.44682691544515496, 0.4492329947192173, 0.0, 1.0, 0.21394063204746055], 
reward next is 0.7861, 
noisyNet noise sample is [array([-1.186727], dtype=float32), 2.2867625]. 
=============================================
[2019-04-06 20:29:45,616] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.5567748e-21 3.7740601e-23 2.4435736e-18 1.7055160e-21 1.0000000e+00
 5.6660243e-26 1.6099324e-23], sum to 1.0000
[2019-04-06 20:29:45,616] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9561
[2019-04-06 20:29:45,645] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [13.3, 51.0, 64.0, 18.5, 26.0, 27.35773916925734, 0.853435400355289, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1612800.0000, 
sim time next is 1614600.0000, 
raw observation next is [12.75, 52.5, 50.0, 37.0, 26.0, 27.48703531805883, 0.8715455452478112, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.8157894736842106, 0.525, 0.16666666666666666, 0.04088397790055249, 0.6666666666666666, 0.7905862765049024, 0.7905151817492704, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7372396], dtype=float32), -0.4546277]. 
=============================================
[2019-04-06 20:29:49,515] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-06 20:29:49,523] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:29:49,524] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:29:49,541] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:29:49,541] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:29:49,552] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:29:49,552] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:29:49,556] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run61
[2019-04-06 20:29:49,573] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run61
[2019-04-06 20:29:49,596] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run61
[2019-04-06 20:31:37,876] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14092083]
[2019-04-06 20:31:37,876] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.0, 79.0, 0.0, 0.0, 26.0, 25.09733027245973, 0.4838866437387281, 0.0, 1.0, 133652.80577523774]
[2019-04-06 20:31:37,876] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 20:31:37,877] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.0740006e-18 2.0826567e-19 2.0980428e-15 3.6690225e-18 1.0000000e+00
 5.8755622e-22 5.7072793e-20], sampled 0.49039193490912214
[2019-04-06 20:31:57,852] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 20:32:05,227] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14092083]
[2019-04-06 20:32:05,228] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-1.813891717, 34.31755726, 0.0, 0.0, 26.0, 25.42607618187605, 0.4232776856139577, 0.0, 1.0, 46180.73603360407]
[2019-04-06 20:32:05,228] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 20:32:05,228] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [4.7356792e-17 8.3333087e-18 4.0616331e-14 1.5210352e-16 1.0000000e+00
 4.4439519e-20 2.3169205e-18], sampled 0.7858873631320623
[2019-04-06 20:32:29,876] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 20:32:34,573] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 20:32:35,612] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1200000, evaluation results [1200000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 20:32:57,527] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5668407e-17 5.5759269e-18 9.2251315e-15 1.5325380e-16 1.0000000e+00
 6.7337740e-21 1.0294223e-18], sum to 1.0000
[2019-04-06 20:32:57,528] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4852
[2019-04-06 20:32:57,598] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [9.5, 26.0, 0.0, 0.0, 26.0, 25.5356568867788, 0.3563704589366355, 0.0, 1.0, 19293.480394727918], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3652200.0000, 
sim time next is 3654000.0000, 
raw observation next is [9.0, 27.0, 0.0, 0.0, 26.0, 25.50393309022556, 0.3554846863097302, 0.0, 1.0, 36976.5937150515], 
processed observation next is [0.0, 0.30434782608695654, 0.7119113573407203, 0.27, 0.0, 0.0, 0.6666666666666666, 0.6253277575187965, 0.6184948954365767, 0.0, 1.0, 0.17607901769072143], 
reward next is 0.8239, 
noisyNet noise sample is [array([-1.8803577], dtype=float32), -0.31835872]. 
=============================================
[2019-04-06 20:32:57,603] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[78.95297 ]
 [79.02032 ]
 [78.922714]
 [78.9156  ]
 [78.975105]], R is [[79.05513   ]
 [79.1727066 ]
 [79.22126007]
 [79.32270813]
 [79.41946411]].
[2019-04-06 20:33:04,836] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4243185e-17 4.2072610e-18 1.4627778e-14 8.7291785e-16 1.0000000e+00
 8.2890049e-21 1.2005453e-18], sum to 1.0000
[2019-04-06 20:33:04,836] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1996
[2019-04-06 20:33:04,930] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.5, 23.0, 104.0, 794.0, 26.0, 26.37072609455304, 0.6435913782295777, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4026600.0000, 
sim time next is 4028400.0000, 
raw observation next is [-2.0, 20.0, 96.5, 753.0, 26.0, 26.64210496995876, 0.6760174207539639, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.40720221606648205, 0.2, 0.32166666666666666, 0.8320441988950277, 0.6666666666666666, 0.7201754141632298, 0.7253391402513213, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.01229023], dtype=float32), -0.033762693]. 
=============================================
[2019-04-06 20:33:09,575] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.4505442e-17 2.3488875e-17 3.0135057e-14 3.3577408e-17 1.0000000e+00
 6.3103011e-20 2.9658972e-18], sum to 1.0000
[2019-04-06 20:33:09,576] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7935
[2019-04-06 20:33:10,122] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.35, 68.5, 30.0, 0.0, 26.0, 25.5349981677665, 0.3250236101028856, 1.0, 1.0, 33080.43957251752], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1960200.0000, 
sim time next is 1962000.0000, 
raw observation next is [-3.9, 75.0, 17.5, 1.0, 26.0, 24.60892310007942, 0.2902737137017036, 1.0, 1.0, 100955.0268799294], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.75, 0.058333333333333334, 0.0011049723756906078, 0.6666666666666666, 0.5507435916732849, 0.5967579045672345, 1.0, 1.0, 0.48073822323775905], 
reward next is 0.5193, 
noisyNet noise sample is [array([-0.5467335], dtype=float32), 0.167202]. 
=============================================
[2019-04-06 20:33:10,145] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[80.4722 ]
 [80.08313]
 [79.86234]
 [79.38789]
 [79.70103]], R is [[81.17082977]
 [81.20159912]
 [81.25823212]
 [81.17973328]
 [81.36793518]].
[2019-04-06 20:33:20,777] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.0994328e-18 6.5988540e-19 1.7087977e-14 3.4320197e-18 1.0000000e+00
 7.1771726e-22 6.4900834e-19], sum to 1.0000
[2019-04-06 20:33:20,777] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2522
[2019-04-06 20:33:21,044] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.3, 79.0, 128.0, 392.5, 26.0, 25.64572818688902, 0.3195441814783935, 1.0, 1.0, 21203.234801128147], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1936800.0000, 
sim time next is 1938600.0000, 
raw observation next is [-6.449999999999999, 77.0, 171.0, 236.0, 26.0, 25.83540497595894, 0.3337829076582192, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.28393351800554023, 0.77, 0.57, 0.26077348066298345, 0.6666666666666666, 0.6529504146632451, 0.6112609692194064, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.23551826], dtype=float32), 0.3270304]. 
=============================================
[2019-04-06 20:33:29,325] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3497623e-19 1.8607101e-19 9.6900029e-16 4.4849680e-17 1.0000000e+00
 1.9070211e-22 1.6410126e-19], sum to 1.0000
[2019-04-06 20:33:29,325] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0425
[2019-04-06 20:33:29,453] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 55.5, 0.0, 0.0, 26.0, 25.06464981693899, 0.469777235082836, 0.0, 1.0, 153801.4006423836], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3875400.0000, 
sim time next is 3877200.0000, 
raw observation next is [-1.0, 60.0, 0.0, 0.0, 26.0, 25.46304355994044, 0.5658045635557445, 0.0, 1.0, 90084.15763454213], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.6, 0.0, 0.0, 0.6666666666666666, 0.6219202966617035, 0.6886015211852481, 0.0, 1.0, 0.4289721792121054], 
reward next is 0.5710, 
noisyNet noise sample is [array([2.181901], dtype=float32), -0.31071827]. 
=============================================
[2019-04-06 20:33:31,924] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8393734e-17 3.3625715e-18 1.0389518e-14 1.4837663e-17 1.0000000e+00
 2.4737797e-21 9.8807675e-19], sum to 1.0000
[2019-04-06 20:33:31,924] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8770
[2019-04-06 20:33:32,031] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 26.0, 23.87133009516239, 0.02381737433994694, 0.0, 1.0, 43799.34656082158], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2613600.0000, 
sim time next is 2615400.0000, 
raw observation next is [-7.0, 78.5, 0.0, 0.0, 26.0, 23.80996064101288, 0.02041208611355655, 0.0, 1.0, 44369.605947051874], 
processed observation next is [1.0, 0.2608695652173913, 0.2686980609418283, 0.785, 0.0, 0.0, 0.6666666666666666, 0.48416338675107323, 0.5068040287045189, 0.0, 1.0, 0.21128383784310417], 
reward next is 0.7887, 
noisyNet noise sample is [array([-0.27809373], dtype=float32), -1.5977752]. 
=============================================
[2019-04-06 20:33:55,680] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9632934e-19 1.6561426e-20 1.1925775e-15 3.3380460e-18 1.0000000e+00
 1.1073893e-22 3.2283270e-20], sum to 1.0000
[2019-04-06 20:33:55,680] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5749
[2019-04-06 20:33:55,781] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.4, 73.0, 0.0, 0.0, 26.0, 25.35297095991674, 0.4495210158685476, 0.0, 1.0, 112023.09334761469], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4305600.0000, 
sim time next is 4307400.0000, 
raw observation next is [5.25, 73.0, 0.0, 0.0, 26.0, 25.78560239082308, 0.474883310352533, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.60803324099723, 0.73, 0.0, 0.0, 0.6666666666666666, 0.6488001992352567, 0.6582944367841777, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0540316], dtype=float32), -1.3973418]. 
=============================================
[2019-04-06 20:34:02,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:34:02,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:34:02,840] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run28
[2019-04-06 20:34:09,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:34:09,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:34:09,140] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run28
[2019-04-06 20:34:22,601] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.08483923e-16 1.01569243e-17 7.28374948e-14 2.34685682e-15
 1.00000000e+00 1.10914968e-19 1.74033904e-17], sum to 1.0000
[2019-04-06 20:34:22,608] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2100
[2019-04-06 20:34:22,669] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.5, 53.0, 0.0, 0.0, 26.0, 25.40874249036821, 0.4061949888650296, 0.0, 1.0, 56801.85872858372], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4829400.0000, 
sim time next is 4831200.0000, 
raw observation next is [-1.0, 55.0, 0.0, 0.0, 26.0, 25.38950545740492, 0.4004385123674068, 0.0, 1.0, 43607.03412561959], 
processed observation next is [0.0, 0.9565217391304348, 0.4349030470914128, 0.55, 0.0, 0.0, 0.6666666666666666, 0.61579212145041, 0.6334795041224689, 0.0, 1.0, 0.20765254345533138], 
reward next is 0.7923, 
noisyNet noise sample is [array([-0.4425504], dtype=float32), 1.1626292]. 
=============================================
[2019-04-06 20:34:24,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:34:24,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:34:24,485] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run28
[2019-04-06 20:34:28,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:34:28,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:34:28,882] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run28
[2019-04-06 20:34:31,063] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.0590512e-20 2.0911431e-19 3.1090667e-16 3.7535814e-18 1.0000000e+00
 1.5964970e-22 1.4069447e-20], sum to 1.0000
[2019-04-06 20:34:31,063] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2440
[2019-04-06 20:34:31,096] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 49.0, 102.0, 781.0, 26.0, 26.62314986513393, 0.7140391882206462, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3508200.0000, 
sim time next is 3510000.0000, 
raw observation next is [3.0, 49.0, 95.0, 734.0, 26.0, 26.75374470256775, 0.7315632060215503, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.49, 0.31666666666666665, 0.8110497237569061, 0.6666666666666666, 0.7294787252139793, 0.7438544020071834, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.31960222], dtype=float32), -1.1248364]. 
=============================================
[2019-04-06 20:34:31,100] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[86.1311  ]
 [86.303505]
 [86.37146 ]
 [86.46261 ]
 [86.5645  ]], R is [[86.09916687]
 [86.23817444]
 [86.34614563]
 [86.48268127]
 [86.61785889]].
[2019-04-06 20:34:35,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:34:35,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:34:35,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run28
[2019-04-06 20:34:36,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:34:36,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:34:36,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run28
[2019-04-06 20:34:47,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:34:47,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:34:47,200] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run28
[2019-04-06 20:34:48,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9201069e-17 3.4356221e-18 2.3959181e-14 6.9802159e-17 1.0000000e+00
 6.6673682e-21 8.6065940e-19], sum to 1.0000
[2019-04-06 20:34:48,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8997
[2019-04-06 20:34:49,078] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.5, 54.5, 114.0, 816.0, 26.0, 25.1856661995042, 0.4333139537085726, 0.0, 1.0, 17636.317371740475], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3583800.0000, 
sim time next is 3585600.0000, 
raw observation next is [-3.0, 55.0, 116.0, 819.5, 26.0, 25.17900860207203, 0.4453516635712148, 0.0, 1.0, 27629.32992288579], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.55, 0.38666666666666666, 0.905524861878453, 0.6666666666666666, 0.598250716839336, 0.6484505545237383, 0.0, 1.0, 0.1315682377280276], 
reward next is 0.8684, 
noisyNet noise sample is [array([-0.7025265], dtype=float32), 0.3655334]. 
=============================================
[2019-04-06 20:34:56,695] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.1912144e-21 7.6161625e-24 3.7806695e-18 3.0063057e-22 1.0000000e+00
 2.1134379e-26 9.8927684e-25], sum to 1.0000
[2019-04-06 20:34:56,698] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9646
[2019-04-06 20:34:56,755] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.5, 96.5, 113.0, 823.0, 26.0, 27.31864267693958, 0.8363258048719366, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3155400.0000, 
sim time next is 3157200.0000, 
raw observation next is [7.0, 100.0, 112.5, 814.5, 26.0, 27.27757044545388, 0.8493033008982956, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.6565096952908588, 1.0, 0.375, 0.9, 0.6666666666666666, 0.7731308704544899, 0.7831011002994318, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.11106889], dtype=float32), 0.0011629208]. 
=============================================
[2019-04-06 20:35:21,812] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 20:35:21,813] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:35:21,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:35:21,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run62
[2019-04-06 20:35:21,839] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:35:21,841] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:35:21,845] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run62
[2019-04-06 20:35:21,861] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:35:21,861] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:35:21,871] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run62
[2019-04-06 20:37:31,424] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 20:38:11,965] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2417.0861 87791866.1671 515.2451
[2019-04-06 20:38:15,491] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 20:38:16,530] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1220000, evaluation results [1220000.0, 2417.086098461385, 87791866.16713928, 515.2451498045025, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 20:38:21,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9843655e-16 1.5043694e-17 5.1141047e-14 3.3769205e-16 1.0000000e+00
 6.1319896e-21 5.2216992e-18], sum to 1.0000
[2019-04-06 20:38:21,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3637
[2019-04-06 20:38:21,881] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.5, 27.5, 114.0, 830.0, 26.0, 26.12695767480832, 0.5759900558030154, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4023000.0000, 
sim time next is 4024800.0000, 
raw observation next is [-3.0, 26.0, 109.0, 812.0, 26.0, 25.37384126844737, 0.5286745123342734, 1.0, 1.0, 35246.95781933197], 
processed observation next is [1.0, 0.6086956521739131, 0.3795013850415513, 0.26, 0.36333333333333334, 0.8972375690607735, 0.6666666666666666, 0.6144867723706143, 0.6762248374447578, 1.0, 1.0, 0.16784265628253317], 
reward next is 0.8322, 
noisyNet noise sample is [array([0.42696735], dtype=float32), 2.1236868]. 
=============================================
[2019-04-06 20:38:41,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:38:41,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:38:41,280] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run28
[2019-04-06 20:39:00,983] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1843642e-18 2.2627042e-19 9.7107626e-16 3.2385961e-16 1.0000000e+00
 5.8036361e-21 1.6221921e-18], sum to 1.0000
[2019-04-06 20:39:00,983] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4535
[2019-04-06 20:39:01,362] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 45.0, 100.0, 574.0, 26.0, 25.64886847583017, 0.438301824558077, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4179600.0000, 
sim time next is 4181400.0000, 
raw observation next is [-3.0, 40.0, 108.0, 660.0, 26.0, 25.59188549785863, 0.4385173223216575, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3795013850415513, 0.4, 0.36, 0.7292817679558011, 0.6666666666666666, 0.6326571248215526, 0.6461724407738858, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9558853], dtype=float32), -1.2898331]. 
=============================================
[2019-04-06 20:39:01,804] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:39:01,804] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:39:01,807] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run28
[2019-04-06 20:39:07,317] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.02971689e-21 2.44603333e-20 1.99341515e-16 1.02233074e-19
 1.00000000e+00 1.91651430e-24 2.67572362e-20], sum to 1.0000
[2019-04-06 20:39:07,317] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.9205
[2019-04-06 20:39:07,386] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.9, 90.5, 97.0, 0.0, 26.0, 25.35470529794026, 0.2807033926609229, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 905400.0000, 
sim time next is 907200.0000, 
raw observation next is [2.7, 97.0, 100.5, 0.0, 26.0, 25.31773867047569, 0.2736945731753942, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5373961218836566, 0.97, 0.335, 0.0, 0.6666666666666666, 0.6098115558729743, 0.591231524391798, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9079203], dtype=float32), -0.42936677]. 
=============================================
[2019-04-06 20:39:23,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:39:23,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:39:23,448] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run28
[2019-04-06 20:39:26,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2454823e-18 9.2894496e-20 3.5653515e-16 8.2388900e-19 1.0000000e+00
 5.4539435e-22 1.0208299e-20], sum to 1.0000
[2019-04-06 20:39:26,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0862
[2019-04-06 20:39:26,734] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 26.0, 25.47710737801514, 0.5077633628061022, 0.0, 1.0, 56906.60008908678], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4667400.0000, 
sim time next is 4669200.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 26.0, 25.60802925059653, 0.5234558355095167, 0.0, 1.0, 17455.473748668355], 
processed observation next is [1.0, 0.043478260869565216, 0.518005540166205, 0.52, 0.0, 0.0, 0.6666666666666666, 0.6340024375497109, 0.6744852785031723, 0.0, 1.0, 0.0831213035650874], 
reward next is 0.9169, 
noisyNet noise sample is [array([1.5309389], dtype=float32), -1.5060662]. 
=============================================
[2019-04-06 20:39:31,268] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.0605540e-18 5.6532630e-19 2.3066238e-15 1.7732633e-17 1.0000000e+00
 2.4105638e-21 1.1740859e-19], sum to 1.0000
[2019-04-06 20:39:31,269] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3689
[2019-04-06 20:39:31,316] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 77.5, 0.0, 0.0, 26.0, 25.05592918745252, 0.380739015673395, 0.0, 1.0, 41416.43430765491], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4753800.0000, 
sim time next is 4755600.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 26.0, 24.95263347050005, 0.3594288135595583, 0.0, 1.0, 41222.33396961093], 
processed observation next is [0.0, 0.043478260869565216, 0.3518005540166205, 0.71, 0.0, 0.0, 0.6666666666666666, 0.5793861225416709, 0.6198096045198528, 0.0, 1.0, 0.19629682842671872], 
reward next is 0.8037, 
noisyNet noise sample is [array([0.16298708], dtype=float32), -1.2908236]. 
=============================================
[2019-04-06 20:39:36,159] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9668887e-17 1.6010385e-17 3.0254967e-14 8.7175980e-16 1.0000000e+00
 5.9913164e-20 3.6017235e-18], sum to 1.0000
[2019-04-06 20:39:36,160] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7218
[2019-04-06 20:39:36,221] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:39:36,221] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:39:36,224] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run28
[2019-04-06 20:39:36,252] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 60.0, 0.0, 0.0, 26.0, 24.86969649620447, 0.2486581477863211, 0.0, 1.0, 39202.532743117634], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4852800.0000, 
sim time next is 4854600.0000, 
raw observation next is [-3.5, 65.5, 0.0, 0.0, 26.0, 24.78671250020383, 0.2365167401446741, 0.0, 1.0, 39204.14927439279], 
processed observation next is [0.0, 0.17391304347826086, 0.36565096952908593, 0.655, 0.0, 0.0, 0.6666666666666666, 0.5655593750169858, 0.578838913381558, 0.0, 1.0, 0.18668642511615613], 
reward next is 0.8133, 
noisyNet noise sample is [array([0.29361862], dtype=float32), 0.5061077]. 
=============================================
[2019-04-06 20:39:38,916] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5704651e-18 1.6275226e-18 4.3381885e-15 3.2867724e-17 1.0000000e+00
 2.6083905e-21 3.7034013e-19], sum to 1.0000
[2019-04-06 20:39:38,916] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9427
[2019-04-06 20:39:38,967] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.7, 75.0, 0.0, 0.0, 26.0, 23.31481949458689, -0.06992216991093018, 0.0, 1.0, 44892.82520951633], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 108000.0000, 
sim time next is 109800.0000, 
raw observation next is [-7.0, 71.5, 0.0, 0.0, 26.0, 23.23702773187975, -0.09009006090948857, 0.0, 1.0, 45438.6349209477], 
processed observation next is [1.0, 0.2608695652173913, 0.2686980609418283, 0.715, 0.0, 0.0, 0.6666666666666666, 0.4364189776566458, 0.4699699796968371, 0.0, 1.0, 0.21637445200451286], 
reward next is 0.7836, 
noisyNet noise sample is [array([-0.73095936], dtype=float32), -0.17693491]. 
=============================================
[2019-04-06 20:39:43,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:39:43,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:39:43,684] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run28
[2019-04-06 20:39:46,198] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4072208e-18 2.0565811e-18 1.8240562e-15 1.4753623e-17 1.0000000e+00
 3.7950392e-22 1.8794208e-20], sum to 1.0000
[2019-04-06 20:39:46,199] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3863
[2019-04-06 20:39:46,302] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 39.0, 100.5, 638.5, 26.0, 25.70444017562088, 0.4102813419596115, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4957200.0000, 
sim time next is 4959000.0000, 
raw observation next is [0.0, 34.5, 108.0, 717.0, 26.0, 26.08217632017766, 0.470421916139721, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.46260387811634357, 0.345, 0.36, 0.7922651933701658, 0.6666666666666666, 0.6735146933481383, 0.656807305379907, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2013829], dtype=float32), -1.6823902]. 
=============================================
[2019-04-06 20:39:46,306] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[83.66544 ]
 [83.75195 ]
 [83.35341 ]
 [82.531715]
 [81.63949 ]], R is [[83.89234924]
 [84.05342865]
 [84.21289825]
 [84.37077332]
 [84.45232391]].
[2019-04-06 20:39:46,976] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2319807e-16 2.4034332e-18 1.0016026e-13 1.2639925e-16 1.0000000e+00
 2.1059207e-19 7.4975642e-18], sum to 1.0000
[2019-04-06 20:39:46,977] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0404
[2019-04-06 20:39:47,100] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.5, 42.0, 70.0, 477.0, 26.0, 26.26686855749149, 0.5286231187259661, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 315000.0000, 
sim time next is 316800.0000, 
raw observation next is [-9.5, 42.0, 47.0, 358.5, 26.0, 26.28631226630839, 0.4862436823783554, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.1994459833795014, 0.42, 0.15666666666666668, 0.3961325966850829, 0.6666666666666666, 0.6905260221923658, 0.6620812274594517, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.3760538], dtype=float32), 0.9482462]. 
=============================================
[2019-04-06 20:39:48,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:39:48,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:39:48,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run28
[2019-04-06 20:39:52,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:39:52,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:39:52,660] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run28
[2019-04-06 20:39:53,495] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.4921557e-19 1.9650981e-20 2.0370566e-15 5.5877870e-18 1.0000000e+00
 2.6501831e-22 9.8744317e-20], sum to 1.0000
[2019-04-06 20:39:53,495] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2210
[2019-04-06 20:39:53,788] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.2, 84.0, 71.0, 0.0, 26.0, 25.4621191527352, 0.3419172559255644, 1.0, 1.0, 22322.09435148058], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2043000.0000, 
sim time next is 2044800.0000, 
raw observation next is [-3.9, 82.0, 51.5, 0.0, 26.0, 25.65921737564791, 0.4101158606443163, 1.0, 1.0, 66106.51593429023], 
processed observation next is [1.0, 0.6956521739130435, 0.3545706371191136, 0.82, 0.17166666666666666, 0.0, 0.6666666666666666, 0.6382681146373258, 0.6367052868814388, 1.0, 1.0, 0.3147929330204297], 
reward next is 0.6852, 
noisyNet noise sample is [array([-0.92769223], dtype=float32), -1.192607]. 
=============================================
[2019-04-06 20:39:55,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:39:55,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:39:55,208] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run28
[2019-04-06 20:39:59,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:39:59,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:39:59,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run28
[2019-04-06 20:40:03,107] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0047230e-15 9.1381948e-16 1.6218320e-12 9.3972537e-15 1.0000000e+00
 6.8603912e-18 1.6845769e-16], sum to 1.0000
[2019-04-06 20:40:03,108] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4943
[2019-04-06 20:40:03,178] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-15.6, 73.0, 0.0, 0.0, 26.0, 22.21474872180155, -0.3689143285780139, 0.0, 1.0, 49253.29311540804], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 363600.0000, 
sim time next is 365400.0000, 
raw observation next is [-15.9, 75.5, 0.0, 0.0, 26.0, 22.09272538033382, -0.3987336158186034, 0.0, 1.0, 48640.3515693521], 
processed observation next is [1.0, 0.21739130434782608, 0.02216066481994457, 0.755, 0.0, 0.0, 0.6666666666666666, 0.34106044836115174, 0.3670887947271322, 0.0, 1.0, 0.2316207217588195], 
reward next is 0.7684, 
noisyNet noise sample is [array([-1.5550549], dtype=float32), 1.3448726]. 
=============================================
[2019-04-06 20:40:09,806] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0803738e-18 1.3095776e-19 8.4468720e-16 2.1179823e-18 1.0000000e+00
 1.3091012e-22 2.9526172e-21], sum to 1.0000
[2019-04-06 20:40:09,806] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3960
[2019-04-06 20:40:09,914] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.1, 83.0, 0.0, 0.0, 26.0, 24.06341296119863, 0.06909757563308432, 0.0, 1.0, 43208.97476201256], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 99000.0000, 
sim time next is 100800.0000, 
raw observation next is [-3.4, 79.0, 0.0, 0.0, 26.0, 23.91595697544757, 0.04986446072843837, 0.0, 1.0, 43535.963794111995], 
processed observation next is [1.0, 0.17391304347826086, 0.368421052631579, 0.79, 0.0, 0.0, 0.6666666666666666, 0.49299641462063093, 0.5166214869094795, 0.0, 1.0, 0.2073141133052952], 
reward next is 0.7927, 
noisyNet noise sample is [array([-0.6612814], dtype=float32), -0.021072397]. 
=============================================
[2019-04-06 20:40:15,968] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.3262635e-16 3.7994523e-17 8.0259367e-14 8.3913431e-16 1.0000000e+00
 2.5529510e-19 1.0979908e-17], sum to 1.0000
[2019-04-06 20:40:15,968] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3136
[2019-04-06 20:40:16,080] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-11.7, 70.0, 0.0, 0.0, 26.0, 22.77983705317815, -0.2238257875562239, 0.0, 1.0, 47823.28747755766], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 280800.0000, 
sim time next is 282600.0000, 
raw observation next is [-12.0, 68.5, 0.0, 0.0, 26.0, 22.59039486645723, -0.2621837682673009, 0.0, 1.0, 47832.44220731096], 
processed observation next is [1.0, 0.2608695652173913, 0.13019390581717452, 0.685, 0.0, 0.0, 0.6666666666666666, 0.3825329055381026, 0.41260541057756633, 0.0, 1.0, 0.22777353432052838], 
reward next is 0.7722, 
noisyNet noise sample is [array([-0.35647288], dtype=float32), -1.716253]. 
=============================================
[2019-04-06 20:40:17,771] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6450050e-19 6.6998822e-19 1.5960528e-14 8.4785004e-18 1.0000000e+00
 7.7689637e-22 6.2256831e-20], sum to 1.0000
[2019-04-06 20:40:17,771] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1841
[2019-04-06 20:40:17,928] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.7, 55.0, 0.0, 0.0, 26.0, 25.04033706685524, 0.3892027624111924, 0.0, 1.0, 95104.56291504884], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2320200.0000, 
sim time next is 2322000.0000, 
raw observation next is [-1.7, 54.0, 0.0, 0.0, 26.0, 25.3881033684244, 0.4340508873063194, 0.0, 1.0, 48065.81763477202], 
processed observation next is [1.0, 0.9130434782608695, 0.4155124653739613, 0.54, 0.0, 0.0, 0.6666666666666666, 0.6156752807020333, 0.6446836291021064, 0.0, 1.0, 0.22888484587986677], 
reward next is 0.7711, 
noisyNet noise sample is [array([0.3166955], dtype=float32), 1.5509744]. 
=============================================
[2019-04-06 20:40:17,953] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[80.27541]
 [79.41916]
 [79.76469]
 [80.32623]
 [80.24029]], R is [[80.58808899]
 [80.32933044]
 [80.295784  ]
 [80.0592041 ]
 [80.22894287]].
[2019-04-06 20:41:11,378] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 20:41:11,399] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:41:11,399] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:41:11,407] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run63
[2019-04-06 20:41:11,430] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:41:11,431] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:41:11,432] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:41:11,432] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:41:11,449] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run63
[2019-04-06 20:41:11,477] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run63
[2019-04-06 20:42:53,461] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14160246]
[2019-04-06 20:42:53,461] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-0.5, 100.0, 0.0, 0.0, 26.0, 25.361610929559, 0.3414971791708847, 0.0, 1.0, 43294.65117334361]
[2019-04-06 20:42:53,461] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 20:42:53,462] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [3.7864841e-19 4.5622675e-20 5.6896400e-16 1.1563427e-18 1.0000000e+00
 1.7154525e-22 1.2468073e-20], sampled 0.3390887113323503
[2019-04-06 20:43:18,997] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 20:43:58,867] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 20:44:01,489] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 20:44:02,550] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1240000, evaluation results [1240000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 20:44:12,889] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.1139856e-19 3.8465527e-19 6.7355416e-15 4.2761739e-18 1.0000000e+00
 1.0008556e-21 3.4371802e-19], sum to 1.0000
[2019-04-06 20:44:12,889] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5540
[2019-04-06 20:44:12,913] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.7, 50.0, 18.0, 1.5, 26.0, 27.96473503501493, 1.028035610171029, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1098000.0000, 
sim time next is 1099800.0000, 
raw observation next is [16.9, 51.5, 0.0, 0.0, 26.0, 27.24712426464432, 0.8508561902121623, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.9307479224376731, 0.515, 0.0, 0.0, 0.6666666666666666, 0.77059368872036, 0.7836187300707208, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9592013], dtype=float32), 1.3619963]. 
=============================================
[2019-04-06 20:45:07,287] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1663864e-23 4.5509297e-22 2.2335134e-18 3.1784322e-21 1.0000000e+00
 1.5363935e-26 1.4660007e-22], sum to 1.0000
[2019-04-06 20:45:07,301] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3300
[2019-04-06 20:45:07,336] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [10.5, 61.0, 0.0, 0.0, 26.0, 26.56044654913152, 0.7472308319638601, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1620000.0000, 
sim time next is 1621800.0000, 
raw observation next is [9.95, 63.5, 0.0, 0.0, 26.0, 26.46336820403207, 0.7182328840125044, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.7382271468144045, 0.635, 0.0, 0.0, 0.6666666666666666, 0.705280683669339, 0.7394109613375015, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6462076], dtype=float32), 0.8390788]. 
=============================================
[2019-04-06 20:45:15,887] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.3436984e-16 7.9676175e-16 8.6671061e-14 1.5264941e-15 1.0000000e+00
 1.5919452e-18 1.1979337e-17], sum to 1.0000
[2019-04-06 20:45:15,887] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3810
[2019-04-06 20:45:15,986] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.9, 45.5, 0.0, 0.0, 26.0, 24.55131920301381, 0.1345237281887559, 0.0, 1.0, 43145.67236550039], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2421000.0000, 
sim time next is 2422800.0000, 
raw observation next is [-6.2, 48.0, 0.0, 0.0, 26.0, 24.40112030633113, 0.1008887098368895, 0.0, 1.0, 43255.068804474984], 
processed observation next is [0.0, 0.043478260869565216, 0.2908587257617729, 0.48, 0.0, 0.0, 0.6666666666666666, 0.5334266921942609, 0.5336295699456298, 0.0, 1.0, 0.20597651811654755], 
reward next is 0.7940, 
noisyNet noise sample is [array([-1.4500177], dtype=float32), -1.0005082]. 
=============================================
[2019-04-06 20:45:17,634] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8043911e-20 1.1854935e-21 7.2828773e-17 2.6777059e-19 1.0000000e+00
 1.3089850e-24 5.2770391e-21], sum to 1.0000
[2019-04-06 20:45:17,634] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1732
[2019-04-06 20:45:17,735] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.8, 68.0, 0.0, 0.0, 26.0, 25.5523728136746, 0.5255179436570855, 0.0, 1.0, 68035.73384457623], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4424400.0000, 
sim time next is 4426200.0000, 
raw observation next is [3.4, 68.0, 0.0, 0.0, 26.0, 25.73638379480764, 0.5386468822720436, 0.0, 1.0, 19819.423231123237], 
processed observation next is [1.0, 0.21739130434782608, 0.556786703601108, 0.68, 0.0, 0.0, 0.6666666666666666, 0.6446986495673034, 0.6795489607573479, 0.0, 1.0, 0.09437820586249161], 
reward next is 0.9056, 
noisyNet noise sample is [array([-2.6510465], dtype=float32), 1.3330905]. 
=============================================
[2019-04-06 20:45:23,958] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1270252e-18 8.1812319e-19 3.3763297e-15 1.0924592e-17 1.0000000e+00
 1.4749702e-22 1.6380097e-20], sum to 1.0000
[2019-04-06 20:45:23,959] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1452
[2019-04-06 20:45:24,026] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.36278460412143, 0.3459070060411907, 0.0, 1.0, 41237.43976894042], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3727800.0000, 
sim time next is 3729600.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.35869318018969, 0.3341265280527899, 0.0, 1.0, 36704.58815164076], 
processed observation next is [1.0, 0.17391304347826086, 0.3795013850415513, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6132244316824741, 0.61137550935093, 0.0, 1.0, 0.17478375310305125], 
reward next is 0.8252, 
noisyNet noise sample is [array([-0.8073538], dtype=float32), 0.013447315]. 
=============================================
[2019-04-06 20:45:51,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:45:51,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:45:51,380] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run29
[2019-04-06 20:45:54,058] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.6467175e-17 5.5571793e-17 4.4006865e-14 1.2989969e-16 1.0000000e+00
 6.0907525e-20 6.1739429e-18], sum to 1.0000
[2019-04-06 20:45:54,058] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0526
[2019-04-06 20:45:54,143] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.5, 39.5, 0.0, 0.0, 26.0, 25.09415744287852, 0.2998052075181497, 0.0, 1.0, 40841.75293907747], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4069800.0000, 
sim time next is 4071600.0000, 
raw observation next is [-5.0, 38.0, 0.0, 0.0, 26.0, 25.042541854259, 0.2848700346702867, 0.0, 1.0, 40762.84971826959], 
processed observation next is [1.0, 0.13043478260869565, 0.32409972299168976, 0.38, 0.0, 0.0, 0.6666666666666666, 0.5868784878549166, 0.5949566782234289, 0.0, 1.0, 0.19410880818223614], 
reward next is 0.8059, 
noisyNet noise sample is [array([0.71596116], dtype=float32), -1.1367816]. 
=============================================
[2019-04-06 20:46:00,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:46:00,186] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:46:00,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run29
[2019-04-06 20:46:13,377] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7089714e-18 2.4269636e-18 1.7355012e-15 3.1144647e-18 1.0000000e+00
 1.4217493e-20 1.1869155e-19], sum to 1.0000
[2019-04-06 20:46:13,379] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0656
[2019-04-06 20:46:13,532] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 74.0, 0.0, 0.0, 26.0, 23.62755412879485, -0.03369897552882602, 0.0, 1.0, 44418.93876434205], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 178200.0000, 
sim time next is 180000.0000, 
raw observation next is [-8.9, 74.0, 0.0, 0.0, 26.0, 23.54558629068306, -0.05219830881738308, 0.0, 1.0, 44333.77678189508], 
processed observation next is [1.0, 0.08695652173913043, 0.21606648199445982, 0.74, 0.0, 0.0, 0.6666666666666666, 0.46213219089025515, 0.482600563727539, 0.0, 1.0, 0.21111322277092895], 
reward next is 0.7889, 
noisyNet noise sample is [array([1.1477696], dtype=float32), -0.49384195]. 
=============================================
[2019-04-06 20:46:13,538] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[76.8696  ]
 [76.7211  ]
 [76.62564 ]
 [76.595474]
 [76.799805]], R is [[76.87651825]
 [76.89624023]
 [76.91582489]
 [76.93483734]
 [76.95288849]].
[2019-04-06 20:46:18,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:46:18,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:46:18,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run29
[2019-04-06 20:46:26,615] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:46:26,615] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:46:26,675] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run29
[2019-04-06 20:46:31,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:46:31,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:46:31,888] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run29
[2019-04-06 20:46:33,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:46:33,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:46:33,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run29
[2019-04-06 20:46:36,020] A3C_AGENT_WORKER-Thread-7 INFO:Evaluating...
[2019-04-06 20:46:36,021] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:46:36,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:46:36,024] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run64
[2019-04-06 20:46:36,044] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:46:36,044] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:46:36,051] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run64
[2019-04-06 20:46:36,081] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:46:36,084] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:46:36,088] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run64
[2019-04-06 20:48:45,984] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 20:49:21,259] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 20:49:27,858] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 20:49:28,897] A3C_AGENT_WORKER-Thread-7 INFO:Global step: 1260000, evaluation results [1260000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 20:49:33,990] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.4521619e-20 3.3024001e-21 4.2510659e-16 1.1503766e-18 1.0000000e+00
 1.0023682e-22 4.8070721e-21], sum to 1.0000
[2019-04-06 20:49:33,990] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7712
[2019-04-06 20:49:34,406] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.45, 86.0, 79.0, 0.0, 26.0, 24.4585915207352, 0.1657255515690211, 0.0, 1.0, 26483.88374573109], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 52200.0000, 
sim time next is 54000.0000, 
raw observation next is [7.2, 86.0, 64.5, 0.0, 26.0, 24.47161442805653, 0.1615151389058745, 0.0, 1.0, 29927.54599159672], 
processed observation next is [0.0, 0.6521739130434783, 0.662049861495845, 0.86, 0.215, 0.0, 0.6666666666666666, 0.5393012023380441, 0.5538383796352915, 0.0, 1.0, 0.14251212376950817], 
reward next is 0.8575, 
noisyNet noise sample is [array([-0.32982627], dtype=float32), 0.6268365]. 
=============================================
[2019-04-06 20:49:34,410] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[89.26034]
 [89.44312]
 [89.58532]
 [89.54786]
 [89.73607]], R is [[88.97637177]
 [88.960495  ]
 [88.90663147]
 [88.83349609]
 [88.85586548]].
[2019-04-06 20:49:41,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:49:41,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:49:41,064] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run29
[2019-04-06 20:50:02,712] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2889998e-18 3.3423383e-19 1.1258661e-16 6.5635562e-19 1.0000000e+00
 4.0060212e-22 2.5964602e-19], sum to 1.0000
[2019-04-06 20:50:02,713] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0761
[2019-04-06 20:50:03,073] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 62.0, 37.0, 0.0, 26.0, 25.95157872359066, 0.362110452228482, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 230400.0000, 
sim time next is 232200.0000, 
raw observation next is [-3.4, 63.5, 18.0, 0.0, 26.0, 25.29234166455113, 0.2731900697424952, 1.0, 1.0, 11906.978562770282], 
processed observation next is [1.0, 0.6956521739130435, 0.368421052631579, 0.635, 0.06, 0.0, 0.6666666666666666, 0.6076951387125943, 0.5910633565808318, 1.0, 1.0, 0.056699897917953726], 
reward next is 0.9433, 
noisyNet noise sample is [array([0.27542296], dtype=float32), 0.048600513]. 
=============================================
[2019-04-06 20:50:46,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:50:46,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:50:46,644] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run29
[2019-04-06 20:50:54,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:50:54,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:50:54,439] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run29
[2019-04-06 20:50:58,985] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0063804e-20 6.6229056e-21 3.1581101e-17 8.6335490e-21 1.0000000e+00
 1.0235758e-26 5.6342440e-22], sum to 1.0000
[2019-04-06 20:50:58,985] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6631
[2019-04-06 20:50:59,018] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.5, 67.0, 0.0, 0.0, 26.0, 25.81397409243784, 0.5534039110081436, 0.0, 1.0, 6242.02127833994], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4420800.0000, 
sim time next is 4422600.0000, 
raw observation next is [4.15, 67.5, 0.0, 0.0, 26.0, 25.69312078588912, 0.5308659082483634, 0.0, 1.0, 16078.413403642337], 
processed observation next is [1.0, 0.17391304347826086, 0.5775623268698062, 0.675, 0.0, 0.0, 0.6666666666666666, 0.6410933988240934, 0.6769553027494545, 0.0, 1.0, 0.0765638733506778], 
reward next is 0.9234, 
noisyNet noise sample is [array([1.9349378], dtype=float32), -0.7384557]. 
=============================================
[2019-04-06 20:51:08,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:51:08,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:51:08,167] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run29
[2019-04-06 20:51:18,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:51:18,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:51:18,202] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run29
[2019-04-06 20:51:24,318] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.8032342e-20 1.6415557e-21 5.2067241e-17 2.6724593e-20 1.0000000e+00
 3.3970996e-25 8.2056530e-24], sum to 1.0000
[2019-04-06 20:51:24,318] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4148
[2019-04-06 20:51:24,448] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 92.0, 31.5, 0.0, 26.0, 26.07976479968931, 0.5890885810995627, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1328400.0000, 
sim time next is 1330200.0000, 
raw observation next is [0.5, 92.0, 45.0, 0.0, 26.0, 26.03727408089425, 0.5886171842586637, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4764542936288089, 0.92, 0.15, 0.0, 0.6666666666666666, 0.6697728400745208, 0.6962057280862212, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0825179], dtype=float32), 1.9767072]. 
=============================================
[2019-04-06 20:51:26,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:51:26,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:51:26,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run29
[2019-04-06 20:51:34,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:51:34,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:51:34,048] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run29
[2019-04-06 20:51:40,360] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.5334704e-19 4.4391888e-21 2.0047996e-17 4.7640441e-21 1.0000000e+00
 1.2675024e-24 5.3734857e-22], sum to 1.0000
[2019-04-06 20:51:40,366] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0600
[2019-04-06 20:51:40,438] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 93.0, 31.0, 0.0, 26.0, 25.70543298076546, 0.5189442600184521, 1.0, 1.0, 41869.62260386039], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1353600.0000, 
sim time next is 1355400.0000, 
raw observation next is [0.8, 94.5, 18.0, 0.0, 26.0, 25.69458516720178, 0.4853172651329179, 1.0, 1.0, 17429.35810155685], 
processed observation next is [1.0, 0.6956521739130435, 0.4847645429362882, 0.945, 0.06, 0.0, 0.6666666666666666, 0.6412154306001483, 0.6617724217109726, 1.0, 1.0, 0.08299694334074689], 
reward next is 0.9170, 
noisyNet noise sample is [array([-0.8587818], dtype=float32), -1.2249801]. 
=============================================
[2019-04-06 20:51:41,982] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:51:41,983] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:51:41,993] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run29
[2019-04-06 20:51:48,975] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:51:48,975] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:51:48,979] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run29
[2019-04-06 20:51:52,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:51:52,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:51:52,640] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run29
[2019-04-06 20:52:15,420] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4296156e-17 5.2383384e-18 3.6330134e-14 1.2681163e-17 1.0000000e+00
 1.0881984e-20 1.2566779e-19], sum to 1.0000
[2019-04-06 20:52:15,421] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1695
[2019-04-06 20:52:15,615] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.55, 62.5, 0.0, 0.0, 26.0, 25.20864639463401, 0.298150136524353, 1.0, 1.0, 11634.102517541005], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 153000.0000, 
sim time next is 154800.0000, 
raw observation next is [-7.8, 64.0, 0.0, 0.0, 26.0, 24.98858961646037, 0.324039780718453, 1.0, 1.0, 122851.28293297027], 
processed observation next is [1.0, 0.8260869565217391, 0.24653739612188366, 0.64, 0.0, 0.0, 0.6666666666666666, 0.5823824680383641, 0.6080132602394843, 1.0, 1.0, 0.5850061092046203], 
reward next is 0.4150, 
noisyNet noise sample is [array([0.01718184], dtype=float32), -0.035378616]. 
=============================================
[2019-04-06 20:52:16,641] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.3896926e-19 7.0510181e-20 1.9355514e-16 4.7068785e-18 1.0000000e+00
 2.9744340e-22 7.0332078e-20], sum to 1.0000
[2019-04-06 20:52:16,653] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2083
[2019-04-06 20:52:16,848] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 86.0, 59.0, 285.0, 26.0, 25.49554813468096, 0.2515662403259864, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1933200.0000, 
sim time next is 1935000.0000, 
raw observation next is [-8.1, 82.5, 85.0, 549.0, 26.0, 25.64493057672179, 0.3004683528233569, 1.0, 1.0, 12495.072275615299], 
processed observation next is [1.0, 0.391304347826087, 0.23822714681440446, 0.825, 0.2833333333333333, 0.6066298342541436, 0.6666666666666666, 0.6370775480601493, 0.6001561176077856, 1.0, 1.0, 0.05950034416959666], 
reward next is 0.9405, 
noisyNet noise sample is [array([0.98604846], dtype=float32), -0.7544521]. 
=============================================
[2019-04-06 20:52:16,853] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[81.47175 ]
 [81.10839 ]
 [80.880875]
 [79.2496  ]
 [76.59575 ]], R is [[82.10099792]
 [82.27999115]
 [82.45719147]
 [82.27253723]
 [81.73530579]].
[2019-04-06 20:52:17,270] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-06 20:52:17,297] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:52:17,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:52:17,301] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run65
[2019-04-06 20:52:17,324] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:52:17,325] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:52:17,330] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:52:17,331] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:52:17,337] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run65
[2019-04-06 20:52:17,357] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run65
[2019-04-06 20:54:30,178] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 20:55:04,776] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 20:55:10,084] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 20:55:11,154] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1280000, evaluation results [1280000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 20:55:23,347] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9536155e-22 1.6286240e-23 2.3894282e-18 9.1744225e-22 1.0000000e+00
 3.1143585e-25 4.2658335e-23], sum to 1.0000
[2019-04-06 20:55:23,347] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0512
[2019-04-06 20:55:23,414] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [11.05, 74.0, 0.0, 0.0, 26.0, 25.67171232467269, 0.6402960743112888, 0.0, 1.0, 37405.26021291688], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1125000.0000, 
sim time next is 1126800.0000, 
raw observation next is [10.5, 77.0, 0.0, 0.0, 26.0, 25.65098694417057, 0.6423447411558288, 0.0, 1.0, 34970.96903034316], 
processed observation next is [0.0, 0.043478260869565216, 0.7534626038781165, 0.77, 0.0, 0.0, 0.6666666666666666, 0.6375822453475474, 0.7141149137186096, 0.0, 1.0, 0.16652842395401507], 
reward next is 0.8335, 
noisyNet noise sample is [array([-1.5363096], dtype=float32), 0.38488328]. 
=============================================
[2019-04-06 20:55:40,186] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.1175552e-19 2.0555760e-19 2.0241284e-15 1.2733363e-18 1.0000000e+00
 1.4483079e-22 1.5400370e-19], sum to 1.0000
[2019-04-06 20:55:40,186] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8476
[2019-04-06 20:55:40,522] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 65.0, 56.0, 0.0, 26.0, 24.85976134547862, 0.3745891897478897, 1.0, 1.0, 91366.3599273888], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2131200.0000, 
sim time next is 2133000.0000, 
raw observation next is [-4.5, 66.5, 26.0, 0.0, 26.0, 25.98536597249922, 0.4584508629281542, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.3379501385041552, 0.665, 0.08666666666666667, 0.0, 0.6666666666666666, 0.665447164374935, 0.6528169543093848, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.18472], dtype=float32), 0.84547305]. 
=============================================
[2019-04-06 20:55:40,526] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[81.15606 ]
 [80.6431  ]
 [80.62661 ]
 [80.69846 ]
 [80.061165]], R is [[81.15609741]
 [80.90945435]
 [81.10035706]
 [81.28935242]
 [81.18204498]].
[2019-04-06 20:56:07,521] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.0012156e-19 2.5731287e-21 4.4450124e-16 6.0200944e-19 1.0000000e+00
 2.7996301e-23 3.1955621e-21], sum to 1.0000
[2019-04-06 20:56:07,522] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4041
[2019-04-06 20:56:07,558] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 83.0, 0.0, 0.0, 26.0, 24.81198999606459, 0.2606473548184193, 0.0, 1.0, 41699.48691161441], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 856800.0000, 
sim time next is 858600.0000, 
raw observation next is [-3.1, 81.0, 0.0, 0.0, 26.0, 24.78781224471633, 0.2468040230802864, 0.0, 1.0, 41482.01627686738], 
processed observation next is [1.0, 0.9565217391304348, 0.37673130193905824, 0.81, 0.0, 0.0, 0.6666666666666666, 0.5656510203930276, 0.5822680076934288, 0.0, 1.0, 0.19753341084222564], 
reward next is 0.8025, 
noisyNet noise sample is [array([-0.64136076], dtype=float32), 0.21100093]. 
=============================================
[2019-04-06 20:56:09,711] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5021455e-23 5.2487807e-25 8.5150205e-20 3.9949705e-23 1.0000000e+00
 7.1568412e-27 3.0596503e-24], sum to 1.0000
[2019-04-06 20:56:09,711] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4673
[2019-04-06 20:56:09,740] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.0, 100.0, 112.5, 814.5, 26.0, 27.27757044545388, 0.8493033008982956, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3157200.0000, 
sim time next is 3159000.0000, 
raw observation next is [7.0, 100.0, 112.0, 806.0, 26.0, 27.39755560148389, 0.8841992237569555, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.6565096952908588, 1.0, 0.37333333333333335, 0.8906077348066298, 0.6666666666666666, 0.7831296334569909, 0.7947330745856518, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1798329], dtype=float32), 0.89371616]. 
=============================================
[2019-04-06 20:56:09,770] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[99.8474 ]
 [99.60378]
 [99.3443 ]
 [99.05257]
 [98.53842]], R is [[100.11582184]
 [100.11466217]
 [100.11351776]
 [100.11238098]
 [100.11125946]].
[2019-04-06 20:56:17,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.9997395e-23 1.6877234e-22 2.6758387e-18 1.9524320e-21 1.0000000e+00
 7.4476245e-25 1.5135475e-21], sum to 1.0000
[2019-04-06 20:56:17,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7041
[2019-04-06 20:56:17,625] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.5, 100.0, 83.0, 392.0, 26.0, 25.76875457794866, 0.447342341101288, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3141000.0000, 
sim time next is 3142800.0000, 
raw observation next is [7.0, 100.0, 91.0, 519.5, 26.0, 26.21132954367206, 0.5173293611652391, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6565096952908588, 1.0, 0.30333333333333334, 0.5740331491712707, 0.6666666666666666, 0.6842774619726718, 0.672443120388413, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6626424], dtype=float32), 1.0371433]. 
=============================================
[2019-04-06 20:56:34,100] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3053885e-19 1.6745721e-20 1.4170361e-16 5.7734977e-20 1.0000000e+00
 2.4958736e-22 9.1545007e-21], sum to 1.0000
[2019-04-06 20:56:34,100] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9856
[2019-04-06 20:56:34,157] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.8, 93.0, 100.0, 0.0, 26.0, 25.16041495045255, 0.2523087719790451, 1.0, 1.0, 6226.803890076847], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 910800.0000, 
sim time next is 912600.0000, 
raw observation next is [3.8, 93.0, 96.0, 0.0, 26.0, 25.06163939066338, 0.1595988371560272, 1.0, 1.0, 32708.09005385809], 
processed observation next is [1.0, 0.5652173913043478, 0.5678670360110805, 0.93, 0.32, 0.0, 0.6666666666666666, 0.5884699492219484, 0.5531996123853424, 1.0, 1.0, 0.1557528097802766], 
reward next is 0.8442, 
noisyNet noise sample is [array([1.9297501], dtype=float32), -1.3132266]. 
=============================================
[2019-04-06 20:56:37,339] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5081106e-21 1.6534769e-22 4.1351209e-17 1.0704370e-20 1.0000000e+00
 5.1088628e-24 1.7791061e-22], sum to 1.0000
[2019-04-06 20:56:37,339] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4038
[2019-04-06 20:56:37,391] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [10.25, 92.5, 60.0, 0.0, 26.0, 26.35254753697788, 0.6070931444021544, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 984600.0000, 
sim time next is 986400.0000, 
raw observation next is [10.5, 93.0, 78.0, 0.0, 26.0, 26.47273914376582, 0.6299901681162962, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.7534626038781165, 0.93, 0.26, 0.0, 0.6666666666666666, 0.7060615953138184, 0.7099967227054321, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6729971], dtype=float32), -0.2646373]. 
=============================================
[2019-04-06 20:56:37,782] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.8318030e-20 4.4784262e-22 7.3590381e-16 4.3644699e-20 1.0000000e+00
 6.3956902e-24 1.6843091e-21], sum to 1.0000
[2019-04-06 20:56:37,782] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6851
[2019-04-06 20:56:37,817] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.2, 73.0, 92.5, 700.5, 26.0, 25.61566630736981, 0.5717442492239175, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1515600.0000, 
sim time next is 1517400.0000, 
raw observation next is [8.6, 68.0, 85.0, 701.0, 26.0, 26.15124334504864, 0.6600072229492467, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.700831024930748, 0.68, 0.2833333333333333, 0.7745856353591161, 0.6666666666666666, 0.6792702787540534, 0.720002407649749, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09742121], dtype=float32), -0.60657233]. 
=============================================
[2019-04-06 20:56:47,853] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8467895e-23 2.4681418e-22 5.2687425e-17 3.3138459e-21 1.0000000e+00
 1.3932206e-25 2.9817374e-23], sum to 1.0000
[2019-04-06 20:56:47,857] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4502
[2019-04-06 20:56:47,899] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.5, 100.0, 0.0, 0.0, 26.0, 26.19162305276514, 0.7257717721903999, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3180600.0000, 
sim time next is 3182400.0000, 
raw observation next is [3.0, 100.0, 0.0, 0.0, 26.0, 25.82283001045916, 0.6704899530828392, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.5457063711911359, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6519025008715967, 0.7234966510276131, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.629164], dtype=float32), -1.4055846]. 
=============================================
[2019-04-06 20:57:14,446] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2395339e-18 1.6623908e-19 4.7556675e-16 9.9671562e-19 1.0000000e+00
 1.1206951e-22 1.8116113e-20], sum to 1.0000
[2019-04-06 20:57:14,447] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6076
[2019-04-06 20:57:14,592] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.8, 87.0, 82.5, 0.0, 26.0, 24.98260541961841, 0.3462191962046241, 0.0, 1.0, 46478.678446131584], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1782000.0000, 
sim time next is 1783800.0000, 
raw observation next is [-3.1, 87.0, 66.0, 0.0, 26.0, 25.01625335013421, 0.3453564124939981, 0.0, 1.0, 35259.96207103026], 
processed observation next is [0.0, 0.6521739130434783, 0.37673130193905824, 0.87, 0.22, 0.0, 0.6666666666666666, 0.5846877791778509, 0.615118804164666, 0.0, 1.0, 0.1679045812906203], 
reward next is 0.8321, 
noisyNet noise sample is [array([0.27938744], dtype=float32), -1.2111106]. 
=============================================
[2019-04-06 20:57:45,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.88760477e-20 4.93490687e-20 4.32207892e-17 1.11056855e-18
 1.00000000e+00 1.15415825e-23 1.33228121e-21], sum to 1.0000
[2019-04-06 20:57:45,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7728
[2019-04-06 20:57:46,067] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 71.0, 0.0, 0.0, 26.0, 25.27391778584453, 0.3834427866212421, 0.0, 1.0, 40551.207572501], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4518000.0000, 
sim time next is 4519800.0000, 
raw observation next is [-0.9, 72.0, 0.0, 0.0, 26.0, 25.54001129230506, 0.4324297221910243, 1.0, 1.0, 13478.929877043576], 
processed observation next is [1.0, 0.30434782608695654, 0.43767313019390586, 0.72, 0.0, 0.0, 0.6666666666666666, 0.628334274358755, 0.6441432407303415, 1.0, 1.0, 0.06418538036687417], 
reward next is 0.9358, 
noisyNet noise sample is [array([-1.0314887], dtype=float32), 1.9379007]. 
=============================================
[2019-04-06 20:57:46,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 20:57:46,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:57:46,524] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run30
[2019-04-06 20:57:51,278] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-06 20:57:51,281] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:57:51,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:57:51,285] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 20:57:51,293] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:57:51,297] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 20:57:51,298] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 20:57:51,298] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run66
[2019-04-06 20:57:51,321] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run66
[2019-04-06 20:57:51,346] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run66
[2019-04-06 20:59:58,616] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 21:00:32,377] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14280815]
[2019-04-06 21:00:32,377] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-3.0, 50.0, 0.0, 0.0, 26.0, 25.02450275517615, 0.2279222550062414, 0.0, 1.0, 38645.062966309575]
[2019-04-06 21:00:32,377] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 21:00:32,378] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.7535071e-17 3.4525439e-18 1.5129496e-14 4.8056335e-17 1.0000000e+00
 1.6747444e-20 8.1569252e-19], sampled 0.25565585627626086
[2019-04-06 21:00:36,456] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 21:00:42,123] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 21:00:43,161] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1300000, evaluation results [1300000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 21:00:44,874] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.5034964e-19 8.0216725e-20 6.4685651e-16 2.7516107e-18 1.0000000e+00
 8.1293285e-22 9.8086528e-21], sum to 1.0000
[2019-04-06 21:00:44,874] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9611
[2019-04-06 21:00:44,922] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 26.0, 21.36958344547408, -0.5333790678074691, 0.0, 1.0, 40292.62206554392], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 27000.0000, 
sim time next is 28800.0000, 
raw observation next is [7.7, 93.0, 10.5, 0.0, 26.0, 21.43273754337256, -0.5059106808641772, 0.0, 1.0, 40269.61929931113], 
processed observation next is [0.0, 0.34782608695652173, 0.6759002770083103, 0.93, 0.035, 0.0, 0.6666666666666666, 0.28606146194771337, 0.3313631063786076, 0.0, 1.0, 0.19176009190148158], 
reward next is 0.8082, 
noisyNet noise sample is [array([-1.2941713], dtype=float32), -3.271843]. 
=============================================
[2019-04-06 21:00:51,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:00:51,646] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:00:51,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run30
[2019-04-06 21:01:19,102] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3727335e-18 1.2819092e-18 2.3750838e-14 9.7640557e-18 1.0000000e+00
 1.8646742e-20 2.2564032e-19], sum to 1.0000
[2019-04-06 21:01:19,102] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9038
[2019-04-06 21:01:19,329] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:01:19,329] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:01:19,332] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run30
[2019-04-06 21:01:19,554] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.8, 54.0, 0.0, 0.0, 26.0, 25.01537347013411, 0.2110483343203605, 1.0, 1.0, 42417.63777931501], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2532600.0000, 
sim time next is 2534400.0000, 
raw observation next is [-2.8, 54.0, 28.5, 9.0, 26.0, 25.180782053995, 0.1879792474751202, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.38504155124653744, 0.54, 0.095, 0.009944751381215469, 0.6666666666666666, 0.5983985044995833, 0.5626597491583735, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.31051254], dtype=float32), 1.1581866]. 
=============================================
[2019-04-06 21:01:35,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:01:35,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:01:35,428] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run30
[2019-04-06 21:01:36,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:01:36,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:01:36,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run30
[2019-04-06 21:01:37,179] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:01:37,179] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:01:37,186] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run30
[2019-04-06 21:01:50,702] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:01:50,702] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:01:50,710] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run30
[2019-04-06 21:02:13,938] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.0271961e-20 2.5051834e-22 6.3063678e-16 9.2066115e-21 1.0000000e+00
 6.0508181e-23 1.1604815e-21], sum to 1.0000
[2019-04-06 21:02:13,938] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9572
[2019-04-06 21:02:13,963] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 65.0, 117.0, 825.5, 26.0, 26.47677810272263, 0.5986181474576281, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3758400.0000, 
sim time next is 3760200.0000, 
raw observation next is [-1.5, 62.5, 119.0, 829.0, 26.0, 26.52165210294613, 0.595234926937392, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4210526315789474, 0.625, 0.39666666666666667, 0.9160220994475138, 0.6666666666666666, 0.710137675245511, 0.6984116423124641, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4401988], dtype=float32), -0.99829346]. 
=============================================
[2019-04-06 21:02:22,530] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2851653e-18 9.3903539e-19 2.0467541e-15 1.5133716e-17 1.0000000e+00
 1.3085077e-21 4.5908136e-19], sum to 1.0000
[2019-04-06 21:02:22,530] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4820
[2019-04-06 21:02:22,647] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.0, 35.0, 100.0, 744.5, 26.0, 27.11390624400034, 0.7706834053809537, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4114800.0000, 
sim time next is 4116600.0000, 
raw observation next is [4.0, 35.0, 94.0, 695.0, 26.0, 25.93534144411896, 0.6546307830735225, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5734072022160666, 0.35, 0.31333333333333335, 0.7679558011049724, 0.6666666666666666, 0.6612784536765801, 0.7182102610245075, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1732928], dtype=float32), -0.86746114]. 
=============================================
[2019-04-06 21:02:28,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:02:28,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:02:28,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run30
[2019-04-06 21:02:36,143] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:02:36,143] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:02:36,146] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run30
[2019-04-06 21:02:40,863] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.2792580e-18 1.9825081e-18 1.8451977e-16 7.1122432e-17 1.0000000e+00
 2.2760173e-20 8.1896004e-19], sum to 1.0000
[2019-04-06 21:02:40,863] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2120
[2019-04-06 21:02:41,001] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.5, 42.0, 112.0, 781.0, 26.0, 26.57831894959817, 0.5828714401330484, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4012200.0000, 
sim time next is 4014000.0000, 
raw observation next is [-8.0, 40.0, 115.5, 798.5, 26.0, 26.55457753919863, 0.5791722197610719, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.24099722991689754, 0.4, 0.385, 0.8823204419889503, 0.6666666666666666, 0.7128814615998857, 0.693057406587024, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.46850133], dtype=float32), -1.9504721]. 
=============================================
[2019-04-06 21:02:41,004] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[79.81459 ]
 [79.75184 ]
 [79.761955]
 [79.64384 ]
 [79.37895 ]], R is [[79.97195435]
 [80.17223358]
 [80.37051392]
 [80.56681061]
 [80.76114655]].
[2019-04-06 21:02:44,714] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3485999e-21 3.0199972e-21 1.4088643e-17 2.0230502e-20 1.0000000e+00
 2.0712729e-25 2.6082599e-22], sum to 1.0000
[2019-04-06 21:02:44,723] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7625
[2019-04-06 21:02:44,890] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 32.0, 0.0, 26.0, 24.68953359370274, 0.4065330781092626, 1.0, 1.0, 65533.811145302294], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1440000.0000, 
sim time next is 1441800.0000, 
raw observation next is [1.1, 92.0, 18.0, 0.0, 26.0, 25.80739979746473, 0.4985340668048986, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.49307479224376743, 0.92, 0.06, 0.0, 0.6666666666666666, 0.6506166497887275, 0.6661780222682995, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.5107944], dtype=float32), -0.76551914]. 
=============================================
[2019-04-06 21:02:46,402] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.7999294e-19 1.3102665e-20 1.0601174e-16 3.4965177e-20 1.0000000e+00
 2.8910575e-23 1.4650455e-21], sum to 1.0000
[2019-04-06 21:02:46,403] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.1928
[2019-04-06 21:02:46,517] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1400707e-20 1.2465980e-20 1.1858351e-17 1.9503794e-19 1.0000000e+00
 1.6025315e-22 1.3866970e-20], sum to 1.0000
[2019-04-06 21:02:46,517] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5329
[2019-04-06 21:02:46,547] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 76.0, 29.0, 0.0, 26.0, 25.62488794825378, 0.2866839568211833, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 721800.0000, 
sim time next is 723600.0000, 
raw observation next is [-2.3, 76.0, 65.0, 24.5, 26.0, 25.78851334206647, 0.3082391335322155, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3988919667590028, 0.76, 0.21666666666666667, 0.02707182320441989, 0.6666666666666666, 0.6490427785055392, 0.6027463778440718, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.510877], dtype=float32), -0.47039545]. 
=============================================
[2019-04-06 21:02:46,562] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.0, 56.0, 93.0, 605.5, 26.0, 25.52897859513121, 0.4730883122306116, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4291200.0000, 
sim time next is 4293000.0000, 
raw observation next is [6.8, 58.0, 70.0, 556.0, 26.0, 25.5592545279448, 0.4675021306570133, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.6509695290858727, 0.58, 0.23333333333333334, 0.6143646408839779, 0.6666666666666666, 0.6299378773287332, 0.6558340435523378, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5991975], dtype=float32), -0.40129977]. 
=============================================
[2019-04-06 21:02:46,643] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[83.94084 ]
 [84.176575]
 [84.27794 ]
 [84.15172 ]
 [84.053986]], R is [[84.03744507]
 [84.19707489]
 [84.35510254]
 [84.5115509 ]
 [84.66643524]].
[2019-04-06 21:02:52,204] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:02:52,204] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:02:52,208] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run30
[2019-04-06 21:03:10,041] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:03:10,041] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:03:10,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run30
[2019-04-06 21:03:13,702] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6289581e-18 3.4508435e-19 2.2398233e-14 1.2368428e-16 1.0000000e+00
 2.8277450e-20 2.3266797e-19], sum to 1.0000
[2019-04-06 21:03:13,702] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6152
[2019-04-06 21:03:13,765] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 60.0, 0.0, 0.0, 26.0, 24.86969649620447, 0.2486581477863211, 0.0, 1.0, 39202.532743117634], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4852800.0000, 
sim time next is 4854600.0000, 
raw observation next is [-3.5, 65.5, 0.0, 0.0, 26.0, 24.78671250020383, 0.2365167401446741, 0.0, 1.0, 39204.14927439279], 
processed observation next is [0.0, 0.17391304347826086, 0.36565096952908593, 0.655, 0.0, 0.0, 0.6666666666666666, 0.5655593750169858, 0.578838913381558, 0.0, 1.0, 0.18668642511615613], 
reward next is 0.8133, 
noisyNet noise sample is [array([-0.9910973], dtype=float32), 0.19907217]. 
=============================================
[2019-04-06 21:03:14,637] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [3.5838171e-22 9.0886527e-24 4.2147168e-17 6.2858822e-23 1.0000000e+00
 4.4490803e-25 1.9780236e-23], sum to 1.0000
[2019-04-06 21:03:14,640] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8097
[2019-04-06 21:03:14,662] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [13.8, 100.0, 77.0, 0.0, 26.0, 24.7326025758897, 0.4469563113689781, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1261800.0000, 
sim time next is 1263600.0000, 
raw observation next is [13.8, 100.0, 64.0, 0.0, 26.0, 24.72645791493686, 0.4380756783040398, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.844875346260388, 1.0, 0.21333333333333335, 0.0, 0.6666666666666666, 0.5605381595780715, 0.6460252261013466, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.26451004], dtype=float32), 1.3622833]. 
=============================================
[2019-04-06 21:03:20,451] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.5093608e-19 3.6420654e-19 2.5983879e-15 1.3819405e-18 1.0000000e+00
 2.7434077e-23 3.3175028e-20], sum to 1.0000
[2019-04-06 21:03:20,451] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9121
[2019-04-06 21:03:20,532] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.4419463052134, 0.3800243903639191, 0.0, 1.0, 36797.90945966392], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4838400.0000, 
sim time next is 4840200.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.29486507814012, 0.3512376161035633, 0.0, 1.0, 48976.35363211964], 
processed observation next is [0.0, 0.0, 0.40720221606648205, 0.6, 0.0, 0.0, 0.6666666666666666, 0.6079054231783433, 0.6170792053678544, 0.0, 1.0, 0.2332207315815221], 
reward next is 0.7668, 
noisyNet noise sample is [array([-0.2609972], dtype=float32), -1.8875432]. 
=============================================
[2019-04-06 21:03:20,571] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 21:03:20,571] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:03:20,572] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:03:20,573] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:03:20,573] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:03:20,580] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run67
[2019-04-06 21:03:20,600] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:03:20,602] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run67
[2019-04-06 21:03:20,620] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:03:20,630] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run67
[2019-04-06 21:04:58,080] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14381415]
[2019-04-06 21:04:58,080] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-1.05, 58.5, 82.0, 210.0, 26.0, 25.17254178556902, 0.3498323530394754, 1.0, 1.0, 0.0]
[2019-04-06 21:04:58,081] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 21:04:58,081] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [8.5607848e-19 1.5515533e-19 1.2870855e-15 2.5924434e-18 1.0000000e+00
 6.4674351e-22 3.7158666e-20], sampled 0.4546692263462292
[2019-04-06 21:05:29,887] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 21:06:10,696] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 21:06:13,200] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 21:06:14,239] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1320000, evaluation results [1320000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 21:06:15,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:06:15,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:06:15,720] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run30
[2019-04-06 21:06:18,851] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6941404e-19 1.9738046e-21 7.4173742e-17 2.1818742e-18 1.0000000e+00
 8.3951549e-23 2.9706159e-20], sum to 1.0000
[2019-04-06 21:06:18,852] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8710
[2019-04-06 21:06:18,953] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.5, 46.5, 195.0, 129.0, 26.0, 27.58341670156985, 0.8748765448147083, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4635000.0000, 
sim time next is 4636800.0000, 
raw observation next is [6.0, 43.0, 156.0, 138.0, 26.0, 27.60045447334303, 0.7751993590313736, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.6288088642659281, 0.43, 0.52, 0.15248618784530388, 0.6666666666666666, 0.800037872778586, 0.7583997863437912, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05399694], dtype=float32), -0.5039404]. 
=============================================
[2019-04-06 21:06:19,643] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.3000300e-17 1.9305426e-18 1.9569427e-14 1.0425835e-16 1.0000000e+00
 5.9304901e-20 7.3474137e-19], sum to 1.0000
[2019-04-06 21:06:19,643] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9370
[2019-04-06 21:06:19,734] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 45.0, 67.5, 252.0, 26.0, 25.1432764745138, 0.3392742343393951, 0.0, 1.0, 6226.803890076847], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4899600.0000, 
sim time next is 4901400.0000, 
raw observation next is [2.5, 44.5, 33.0, 187.0, 26.0, 25.03069615593456, 0.3205266171732084, 0.0, 1.0, 40163.993636972686], 
processed observation next is [0.0, 0.7391304347826086, 0.5318559556786704, 0.445, 0.11, 0.20662983425414364, 0.6666666666666666, 0.58589134632788, 0.6068422057244028, 0.0, 1.0, 0.19125711255701278], 
reward next is 0.8087, 
noisyNet noise sample is [array([-1.2201287], dtype=float32), 0.29202682]. 
=============================================
[2019-04-06 21:06:23,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:06:23,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:06:23,172] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run30
[2019-04-06 21:06:33,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:06:33,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:06:33,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run30
[2019-04-06 21:06:42,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:06:42,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:06:42,603] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run30
[2019-04-06 21:06:51,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:06:51,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:06:51,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run30
[2019-04-06 21:07:01,648] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8438234e-17 5.7493718e-18 9.2081900e-14 1.7178358e-15 1.0000000e+00
 1.1180328e-18 7.0220628e-18], sum to 1.0000
[2019-04-06 21:07:01,649] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2059
[2019-04-06 21:07:01,763] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-14.5, 69.0, 0.0, 0.0, 26.0, 23.26437589203579, -0.1081170125430946, 0.0, 1.0, 47629.70487613191], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 349200.0000, 
sim time next is 351000.0000, 
raw observation next is [-14.75, 69.0, 0.0, 0.0, 26.0, 23.29841756995755, -0.1211944765796741, 0.0, 1.0, 47807.401556462246], 
processed observation next is [1.0, 0.043478260869565216, 0.05401662049861495, 0.69, 0.0, 0.0, 0.6666666666666666, 0.4415347974964625, 0.4596018411401086, 0.0, 1.0, 0.22765429312601068], 
reward next is 0.7723, 
noisyNet noise sample is [array([-1.068992], dtype=float32), -0.12390343]. 
=============================================
[2019-04-06 21:07:01,771] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.71122 ]
 [72.164825]
 [72.799515]
 [73.480774]
 [74.340195]], R is [[71.4300766 ]
 [71.4889679 ]
 [71.54813385]
 [71.60761261]
 [71.66702271]].
[2019-04-06 21:07:15,178] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1134255e-17 1.7738791e-17 1.4755679e-13 2.7934421e-16 1.0000000e+00
 2.9441622e-19 1.3065744e-18], sum to 1.0000
[2019-04-06 21:07:15,178] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4249
[2019-04-06 21:07:15,361] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-10.6, 47.0, 0.0, 0.0, 26.0, 24.74620807647067, 0.1975642261199833, 0.0, 1.0, 45367.8721402385], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 421200.0000, 
sim time next is 423000.0000, 
raw observation next is [-10.6, 48.0, 0.0, 0.0, 26.0, 24.51732536804531, 0.1530913140993252, 0.0, 1.0, 45749.290682093975], 
processed observation next is [1.0, 0.9130434782608695, 0.1689750692520776, 0.48, 0.0, 0.0, 0.6666666666666666, 0.5431104473371091, 0.5510304380331084, 0.0, 1.0, 0.21785376515282845], 
reward next is 0.7821, 
noisyNet noise sample is [array([1.132458], dtype=float32), 0.4391653]. 
=============================================
[2019-04-06 21:07:15,365] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.72697 ]
 [73.109276]
 [73.77287 ]
 [75.18376 ]
 [74.74492 ]], R is [[72.39717865]
 [72.45717621]
 [72.51837158]
 [72.51054382]
 [72.32353973]].
[2019-04-06 21:07:16,255] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1554872e-18 2.2330704e-18 4.8775749e-15 2.9216324e-17 1.0000000e+00
 1.0415433e-21 2.1618390e-20], sum to 1.0000
[2019-04-06 21:07:16,255] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9022
[2019-04-06 21:07:16,336] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 65.0, 0.0, 0.0, 26.0, 24.90317703618964, 0.300620499776676, 0.0, 1.0, 38523.947862903915], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2332800.0000, 
sim time next is 2334600.0000, 
raw observation next is [-2.3, 63.5, 0.0, 0.0, 26.0, 24.88517795014916, 0.2797753940052417, 0.0, 1.0, 38422.53624005275], 
processed observation next is [0.0, 0.0, 0.3988919667590028, 0.635, 0.0, 0.0, 0.6666666666666666, 0.5737648291790967, 0.5932584646684139, 0.0, 1.0, 0.1829644582859655], 
reward next is 0.8170, 
noisyNet noise sample is [array([0.26131806], dtype=float32), -1.5210651]. 
=============================================
[2019-04-06 21:07:43,355] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.2891523e-18 8.9628638e-20 1.7043505e-15 9.0002483e-19 1.0000000e+00
 5.0717991e-22 3.0494491e-20], sum to 1.0000
[2019-04-06 21:07:43,355] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8067
[2019-04-06 21:07:43,544] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.2, 52.0, 0.0, 0.0, 26.0, 25.50693951556114, 0.4156843519525327, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2311200.0000, 
sim time next is 2313000.0000, 
raw observation next is [-1.2, 53.0, 0.0, 0.0, 26.0, 25.46724428486611, 0.3801439618317788, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.42936288088642666, 0.53, 0.0, 0.0, 0.6666666666666666, 0.6222703570721757, 0.6267146539439262, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.84188294], dtype=float32), 0.18016456]. 
=============================================
[2019-04-06 21:07:43,548] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[80.445915]
 [80.75063 ]
 [79.57337 ]
 [79.57484 ]
 [79.64361 ]], R is [[80.61818695]
 [80.81200409]
 [80.35311127]
 [80.54958344]
 [80.74408722]].
[2019-04-06 21:07:57,778] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.2618296e-20 1.3282281e-19 1.3646439e-16 1.5048729e-19 1.0000000e+00
 1.5007373e-22 1.5776279e-20], sum to 1.0000
[2019-04-06 21:07:57,778] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0246
[2019-04-06 21:07:57,955] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.3, 70.0, 232.0, 10.0, 26.0, 25.71274198182224, 0.302201319831109, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1942200.0000, 
sim time next is 1944000.0000, 
raw observation next is [-5.0, 65.0, 229.5, 7.0, 26.0, 25.6889257838243, 0.3449375629843592, 1.0, 1.0, 63157.593688550325], 
processed observation next is [1.0, 0.5217391304347826, 0.32409972299168976, 0.65, 0.765, 0.0077348066298342545, 0.6666666666666666, 0.6407438153186916, 0.6149791876614531, 1.0, 1.0, 0.3007504461359539], 
reward next is 0.6992, 
noisyNet noise sample is [array([2.3710473], dtype=float32), 1.2402883]. 
=============================================
[2019-04-06 21:07:57,958] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[81.69887 ]
 [82.1284  ]
 [82.38614 ]
 [82.461365]
 [82.34981 ]], R is [[81.61167908]
 [81.79556274]
 [81.97760773]
 [82.15782928]
 [82.2352829 ]].
[2019-04-06 21:07:59,561] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.4165556e-20 1.3017734e-18 3.1919047e-15 5.3662482e-17 1.0000000e+00
 1.8078204e-21 1.9559451e-19], sum to 1.0000
[2019-04-06 21:07:59,576] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1139
[2019-04-06 21:07:59,595] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.0947662e-19 1.6997621e-20 4.7954723e-16 1.5817462e-17 1.0000000e+00
 9.6119619e-22 4.4448700e-19], sum to 1.0000
[2019-04-06 21:07:59,596] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5467
[2019-04-06 21:07:59,689] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.1, 58.0, 224.0, 171.0, 26.0, 25.73345810005536, 0.3870051961469149, 1.0, 1.0, 43665.46746916317], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2633400.0000, 
sim time next is 2635200.0000, 
raw observation next is [-2.3, 54.0, 234.5, 159.0, 26.0, 25.75120977001484, 0.3944776945654317, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.3988919667590028, 0.54, 0.7816666666666666, 0.17569060773480663, 0.6666666666666666, 0.6459341475012366, 0.6314925648551438, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.14175753], dtype=float32), 1.4254328]. 
=============================================
[2019-04-06 21:07:59,716] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 71.0, 98.5, 0.0, 26.0, 25.59601056967243, 0.2991308920511574, 1.0, 1.0, 20158.06646739645], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 817200.0000, 
sim time next is 819000.0000, 
raw observation next is [-4.5, 71.0, 110.0, 0.0, 26.0, 25.63207784089732, 0.3124047497824566, 1.0, 1.0, 22825.888041644826], 
processed observation next is [1.0, 0.4782608695652174, 0.3379501385041552, 0.71, 0.36666666666666664, 0.0, 0.6666666666666666, 0.6360064867414433, 0.6041349165941522, 1.0, 1.0, 0.10869470496021345], 
reward next is 0.8913, 
noisyNet noise sample is [array([-0.2581708], dtype=float32), -1.0369384]. 
=============================================
[2019-04-06 21:07:59,748] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[79.9734 ]
 [79.57062]
 [79.13219]
 [79.15755]
 [79.20598]], R is [[80.35949707]
 [80.45990753]
 [80.53081512]
 [80.72550964]
 [80.91825867]].
[2019-04-06 21:08:20,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5964888e-20 2.9978445e-21 1.3210288e-17 6.4576574e-19 1.0000000e+00
 5.8316341e-24 9.7436464e-22], sum to 1.0000
[2019-04-06 21:08:20,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4829
[2019-04-06 21:08:20,653] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.45, 60.5, 181.0, 317.0, 26.0, 27.00662362253207, 0.7245839329470888, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1081800.0000, 
sim time next is 1083600.0000, 
raw observation next is [18.3, 56.0, 176.0, 158.5, 26.0, 26.92865898777615, 0.8690069452565092, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.9695290858725764, 0.56, 0.5866666666666667, 0.17513812154696132, 0.6666666666666666, 0.7440549156480124, 0.7896689817521697, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0947969], dtype=float32), 0.057088163]. 
=============================================
[2019-04-06 21:08:21,022] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6907241e-17 1.9067404e-19 2.0676049e-15 3.1997249e-19 1.0000000e+00
 4.1246828e-21 3.4386229e-19], sum to 1.0000
[2019-04-06 21:08:21,022] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3769
[2019-04-06 21:08:21,033] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.4, 49.0, 63.5, 0.0, 26.0, 27.53986112275522, 0.974108954515068, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1094400.0000, 
sim time next is 1096200.0000, 
raw observation next is [18.55, 49.5, 35.0, 0.0, 26.0, 27.85908079589682, 1.014301527347682, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.976454293628809, 0.495, 0.11666666666666667, 0.0, 0.6666666666666666, 0.821590066324735, 0.8381005091158941, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.93310654], dtype=float32), -0.4062445]. 
=============================================
[2019-04-06 21:08:48,427] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.29412679e-21 4.34178420e-21 3.00747220e-17 4.21538543e-20
 1.00000000e+00 5.11859971e-23 1.12832315e-20], sum to 1.0000
[2019-04-06 21:08:48,427] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7658
[2019-04-06 21:08:48,484] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 55.5, 117.0, 835.0, 26.0, 26.66007785578423, 0.6748209996294481, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3846600.0000, 
sim time next is 3848400.0000, 
raw observation next is [1.0, 51.0, 115.0, 829.5, 26.0, 26.62058722699472, 0.6763330252090117, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.4903047091412743, 0.51, 0.38333333333333336, 0.9165745856353591, 0.6666666666666666, 0.7183822689162266, 0.7254443417363373, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7524476], dtype=float32), -0.2028278]. 
=============================================
[2019-04-06 21:09:03,753] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.3493930e-21 1.9378748e-20 9.4914136e-18 7.3890933e-20 1.0000000e+00
 3.4127546e-23 4.3609205e-22], sum to 1.0000
[2019-04-06 21:09:03,753] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4869
[2019-04-06 21:09:03,997] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 93.0, 0.0, 0.0, 26.0, 24.80326367878236, 0.2324840349315615, 0.0, 1.0, 53875.206712898675], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2876400.0000, 
sim time next is 2878200.0000, 
raw observation next is [2.0, 93.0, 0.0, 0.0, 26.0, 24.93712789460242, 0.2600375468061251, 1.0, 1.0, 17282.888024901546], 
processed observation next is [1.0, 0.30434782608695654, 0.518005540166205, 0.93, 0.0, 0.0, 0.6666666666666666, 0.5780939912168682, 0.5866791822687084, 1.0, 1.0, 0.08229946678524545], 
reward next is 0.9177, 
noisyNet noise sample is [array([0.14046098], dtype=float32), 0.571675]. 
=============================================
[2019-04-06 21:09:05,722] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.4913193e-20 1.1131213e-19 3.7973244e-16 6.9947096e-19 1.0000000e+00
 2.2351794e-22 8.0416713e-22], sum to 1.0000
[2019-04-06 21:09:05,723] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6112
[2019-04-06 21:09:05,793] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.2, 65.0, 0.0, 0.0, 26.0, 25.36242218252059, 0.4588563999514226, 0.0, 1.0, 56508.50443193908], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2667600.0000, 
sim time next is 2669400.0000, 
raw observation next is [-2.15, 67.0, 0.0, 0.0, 26.0, 25.46142950173561, 0.442769520493662, 0.0, 1.0, 16641.38957256415], 
processed observation next is [1.0, 0.9130434782608695, 0.4030470914127424, 0.67, 0.0, 0.0, 0.6666666666666666, 0.6217857918113007, 0.647589840164554, 0.0, 1.0, 0.07924471225030547], 
reward next is 0.9208, 
noisyNet noise sample is [array([-0.4308586], dtype=float32), 0.15236503]. 
=============================================
[2019-04-06 21:09:06,991] A3C_AGENT_WORKER-Thread-8 INFO:Evaluating...
[2019-04-06 21:09:06,997] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:09:06,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:09:07,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run68
[2019-04-06 21:09:07,034] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:09:07,035] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:09:07,039] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run68
[2019-04-06 21:09:07,055] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:09:07,056] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:09:07,060] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run68
[2019-04-06 21:11:16,438] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 21:11:51,911] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 21:11:58,354] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 21:11:59,392] A3C_AGENT_WORKER-Thread-8 INFO:Global step: 1340000, evaluation results [1340000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 21:12:03,799] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1150306e-18 6.1364187e-19 2.0881751e-14 1.8218492e-18 1.0000000e+00
 1.4660014e-21 1.9871030e-19], sum to 1.0000
[2019-04-06 21:12:03,799] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3256
[2019-04-06 21:12:03,940] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.5, 61.0, 0.0, 0.0, 26.0, 24.94581945848122, 0.3543763719363094, 0.0, 1.0, 143168.81837086185], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3699000.0000, 
sim time next is 3700800.0000, 
raw observation next is [3.0, 63.0, 0.0, 0.0, 26.0, 25.41452532660796, 0.4590483879111076, 0.0, 1.0, 81265.2018848229], 
processed observation next is [0.0, 0.8695652173913043, 0.5457063711911359, 0.63, 0.0, 0.0, 0.6666666666666666, 0.6178771105506634, 0.6530161293037026, 0.0, 1.0, 0.38697715183249004], 
reward next is 0.6130, 
noisyNet noise sample is [array([-0.57998085], dtype=float32), -0.2877057]. 
=============================================
[2019-04-06 21:12:04,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7693614e-19 9.2665766e-22 5.9313620e-16 7.8191931e-19 1.0000000e+00
 1.3337451e-22 8.7519287e-21], sum to 1.0000
[2019-04-06 21:12:04,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1969
[2019-04-06 21:12:04,441] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 26.0, 25.39967830167274, 0.3782400449957748, 0.0, 1.0, 29737.487415398125], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3898800.0000, 
sim time next is 3900600.0000, 
raw observation next is [-2.5, 68.0, 0.0, 0.0, 26.0, 25.36373195437421, 0.3986288549172086, 0.0, 1.0, 61097.154339064524], 
processed observation next is [1.0, 0.13043478260869565, 0.39335180055401664, 0.68, 0.0, 0.0, 0.6666666666666666, 0.6136443295311841, 0.6328762849724029, 0.0, 1.0, 0.29093883018602157], 
reward next is 0.7091, 
noisyNet noise sample is [array([0.9237842], dtype=float32), -0.29645625]. 
=============================================
[2019-04-06 21:12:33,016] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.7670559e-19 5.8626022e-21 1.9212300e-15 1.1606559e-18 1.0000000e+00
 5.8440861e-23 4.8497351e-19], sum to 1.0000
[2019-04-06 21:12:33,016] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2761
[2019-04-06 21:12:33,046] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.5, 33.0, 106.0, 794.0, 26.0, 27.01924453996375, 0.7357166187406051, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4113000.0000, 
sim time next is 4114800.0000, 
raw observation next is [4.0, 35.0, 100.0, 744.5, 26.0, 27.11390624400034, 0.7706834053809537, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5734072022160666, 0.35, 0.3333333333333333, 0.8226519337016575, 0.6666666666666666, 0.7594921870000283, 0.7568944684603179, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9349427], dtype=float32), -0.06221641]. 
=============================================
[2019-04-06 21:12:40,032] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4287379e-20 1.6189634e-20 1.2903885e-16 1.2902001e-18 1.0000000e+00
 3.8405503e-22 1.0505620e-20], sum to 1.0000
[2019-04-06 21:12:40,032] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5895
[2019-04-06 21:12:40,112] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.0, 28.0, 38.0, 61.0, 26.0, 25.63202898584914, 0.3919668403244584, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2826000.0000, 
sim time next is 2827800.0000, 
raw observation next is [5.5, 29.0, 5.0, 46.0, 26.0, 25.73567396991816, 0.3610619558236619, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.6149584487534627, 0.29, 0.016666666666666666, 0.05082872928176796, 0.6666666666666666, 0.6446394974931801, 0.620353985274554, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5562947], dtype=float32), 0.39395243]. 
=============================================
[2019-04-06 21:12:47,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:12:47,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:12:47,096] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run31
[2019-04-06 21:12:59,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:12:59,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:12:59,944] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run31
[2019-04-06 21:13:00,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9884421e-17 3.2247008e-17 5.8247271e-14 1.2418637e-16 1.0000000e+00
 4.1538533e-18 7.5521941e-17], sum to 1.0000
[2019-04-06 21:13:00,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9962
[2019-04-06 21:13:01,042] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.5, 61.0, 0.0, 0.0, 26.0, 22.98828568383584, -0.208994287617452, 0.0, 1.0, 44060.76780300601], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2444400.0000, 
sim time next is 2446200.0000, 
raw observation next is [-9.5, 59.5, 0.0, 0.0, 26.0, 22.88128284412347, -0.2323631490240078, 0.0, 1.0, 44172.65888702584], 
processed observation next is [0.0, 0.30434782608695654, 0.1994459833795014, 0.595, 0.0, 0.0, 0.6666666666666666, 0.4067735703436224, 0.42254561699199744, 0.0, 1.0, 0.21034599470012305], 
reward next is 0.7897, 
noisyNet noise sample is [array([0.27123216], dtype=float32), -0.2333991]. 
=============================================
[2019-04-06 21:13:03,129] A3C_AGENT_WORKER-Thread-14 INFO:Local step 85000, global step 1346422: loss 0.2252
[2019-04-06 21:13:03,129] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 85000, global step 1346422: learning rate 0.0000
[2019-04-06 21:13:06,768] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7760913e-19 1.7582457e-21 7.2972307e-16 3.5258387e-19 1.0000000e+00
 2.4652153e-22 4.4340461e-20], sum to 1.0000
[2019-04-06 21:13:06,768] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2925
[2019-04-06 21:13:06,821] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 77.0, 0.0, 0.0, 26.0, 25.20478821592785, 0.4320188636106172, 0.0, 1.0, 45374.72149433667], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4748400.0000, 
sim time next is 4750200.0000, 
raw observation next is [-3.5, 80.5, 0.0, 0.0, 26.0, 25.13323861460689, 0.4102534314331797, 0.0, 1.0, 41937.92861320478], 
processed observation next is [1.0, 1.0, 0.36565096952908593, 0.805, 0.0, 0.0, 0.6666666666666666, 0.5944365512172407, 0.6367511438110599, 0.0, 1.0, 0.1997044219676418], 
reward next is 0.8003, 
noisyNet noise sample is [array([-1.6304361], dtype=float32), 0.20288043]. 
=============================================
[2019-04-06 21:13:13,592] A3C_AGENT_WORKER-Thread-17 INFO:Local step 85000, global step 1347959: loss 0.1804
[2019-04-06 21:13:13,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 85000, global step 1347959: learning rate 0.0000
[2019-04-06 21:13:22,246] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:13:22,246] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:13:22,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run31
[2019-04-06 21:13:24,887] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:13:24,887] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:13:24,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run31
[2019-04-06 21:13:26,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:13:26,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:13:26,640] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run31
[2019-04-06 21:13:31,493] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:13:31,493] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:13:31,496] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run31
[2019-04-06 21:13:33,994] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2883607e-18 1.2440992e-20 4.0435125e-15 1.9802473e-19 1.0000000e+00
 6.3049739e-23 3.0525319e-21], sum to 1.0000
[2019-04-06 21:13:33,994] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0867
[2019-04-06 21:13:34,055] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 26.0, 24.55336482993545, 0.2482640537537246, 0.0, 1.0, 42681.09081004522], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2950200.0000, 
sim time next is 2952000.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 26.0, 24.44530112656864, 0.223961777454935, 0.0, 1.0, 42744.76838346376], 
processed observation next is [0.0, 0.17391304347826086, 0.3795013850415513, 0.84, 0.0, 0.0, 0.6666666666666666, 0.5371084272140534, 0.5746539258183117, 0.0, 1.0, 0.2035465161117322], 
reward next is 0.7965, 
noisyNet noise sample is [array([0.074578], dtype=float32), 0.9089824]. 
=============================================
[2019-04-06 21:13:34,061] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[83.222046]
 [83.56352 ]
 [83.405304]
 [84.05442 ]
 [84.37202 ]], R is [[82.84625244]
 [82.81454468]
 [82.78240204]
 [82.74960327]
 [82.71644592]].
[2019-04-06 21:13:34,990] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3425379e-18 1.5331145e-19 1.0809032e-15 1.3204941e-18 1.0000000e+00
 1.1621870e-21 7.7070434e-20], sum to 1.0000
[2019-04-06 21:13:34,991] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6233
[2019-04-06 21:13:35,237] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:13:35,237] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:13:35,240] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run31
[2019-04-06 21:13:35,263] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.7, 93.0, 29.5, 0.0, 26.0, 22.74548019114894, -0.2198629713532898, 0.0, 1.0, 66340.32483914764], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 32400.0000, 
sim time next is 34200.0000, 
raw observation next is [7.7, 93.0, 38.0, 0.0, 26.0, 23.1784304872452, -0.1481667397014567, 0.0, 1.0, 58965.07379433524], 
processed observation next is [0.0, 0.391304347826087, 0.6759002770083103, 0.93, 0.12666666666666668, 0.0, 0.6666666666666666, 0.4315358739371001, 0.45061108676618106, 0.0, 1.0, 0.2807860656873107], 
reward next is 0.7192, 
noisyNet noise sample is [array([-0.6277172], dtype=float32), -0.55736595]. 
=============================================
[2019-04-06 21:13:36,250] A3C_AGENT_WORKER-Thread-19 INFO:Local step 85000, global step 1350981: loss 0.1652
[2019-04-06 21:13:36,250] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 85000, global step 1350981: learning rate 0.0000
[2019-04-06 21:13:40,102] A3C_AGENT_WORKER-Thread-18 INFO:Local step 85000, global step 1351407: loss 0.2348
[2019-04-06 21:13:40,103] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 85000, global step 1351407: learning rate 0.0000
[2019-04-06 21:13:42,532] A3C_AGENT_WORKER-Thread-8 INFO:Local step 85000, global step 1351721: loss 0.2217
[2019-04-06 21:13:42,533] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 85000, global step 1351721: learning rate 0.0000
[2019-04-06 21:13:47,052] A3C_AGENT_WORKER-Thread-15 INFO:Local step 85000, global step 1352285: loss 0.1722
[2019-04-06 21:13:47,053] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 85000, global step 1352285: learning rate 0.0000
[2019-04-06 21:13:49,332] A3C_AGENT_WORKER-Thread-7 INFO:Local step 85000, global step 1352612: loss 0.2324
[2019-04-06 21:13:49,333] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 85000, global step 1352612: learning rate 0.0000
[2019-04-06 21:13:51,477] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0534660e-20 1.4233555e-20 2.7503317e-17 5.6217790e-19 1.0000000e+00
 2.9347150e-23 1.3103915e-20], sum to 1.0000
[2019-04-06 21:13:51,477] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5706
[2019-04-06 21:13:51,623] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 81.5, 0.0, 0.0, 26.0, 25.00056629515927, 0.4417730359972545, 0.0, 1.0, 97463.09029802117], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2925000.0000, 
sim time next is 2926800.0000, 
raw observation next is [-1.0, 85.0, 0.0, 0.0, 26.0, 25.38471682377041, 0.4872595495708478, 0.0, 1.0, 51641.76533919828], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.85, 0.0, 0.0, 0.6666666666666666, 0.6153930686475343, 0.6624198498569492, 0.0, 1.0, 0.24591316828189658], 
reward next is 0.7541, 
noisyNet noise sample is [array([0.27969274], dtype=float32), -1.4864806]. 
=============================================
[2019-04-06 21:14:11,590] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:14:11,590] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:14:11,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run31
[2019-04-06 21:14:17,440] A3C_AGENT_WORKER-Thread-14 INFO:Local step 85500, global step 1356492: loss 0.0505
[2019-04-06 21:14:17,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 85500, global step 1356495: learning rate 0.0000
[2019-04-06 21:14:25,666] A3C_AGENT_WORKER-Thread-6 INFO:Local step 85000, global step 1357758: loss 0.2107
[2019-04-06 21:14:25,667] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 85000, global step 1357758: learning rate 0.0000
[2019-04-06 21:14:27,929] A3C_AGENT_WORKER-Thread-17 INFO:Local step 85500, global step 1358133: loss 0.0746
[2019-04-06 21:14:27,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 85500, global step 1358133: learning rate 0.0000
[2019-04-06 21:14:28,134] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.4240675e-20 2.1103507e-20 7.2534601e-17 1.8442449e-19 1.0000000e+00
 5.1404984e-22 1.2327612e-20], sum to 1.0000
[2019-04-06 21:14:28,134] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6791
[2019-04-06 21:14:28,196] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 86.0, 0.0, 0.0, 26.0, 24.46248911273731, 0.1525626174257895, 0.0, 1.0, 42189.98626475546], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 608400.0000, 
sim time next is 610200.0000, 
raw observation next is [-3.9, 86.0, 0.0, 0.0, 26.0, 24.4078897328339, 0.1406251871354252, 0.0, 1.0, 42120.349505786384], 
processed observation next is [0.0, 0.043478260869565216, 0.3545706371191136, 0.86, 0.0, 0.0, 0.6666666666666666, 0.5339908110694918, 0.546875062378475, 0.0, 1.0, 0.20057309288469707], 
reward next is 0.7994, 
noisyNet noise sample is [array([-0.12674573], dtype=float32), -0.776526]. 
=============================================
[2019-04-06 21:14:31,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:14:31,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:14:31,940] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run31
[2019-04-06 21:14:32,681] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7735746e-18 3.0770279e-19 4.5855899e-15 4.0742139e-16 1.0000000e+00
 1.3987564e-21 8.6190417e-20], sum to 1.0000
[2019-04-06 21:14:32,681] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5741
[2019-04-06 21:14:32,716] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.5, 48.5, 87.0, 705.0, 26.0, 25.51955161403906, 0.4882189469419352, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3684600.0000, 
sim time next is 3686400.0000, 
raw observation next is [5.0, 50.0, 75.5, 613.5, 26.0, 25.49315276473453, 0.4776549860631255, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.6011080332409973, 0.5, 0.25166666666666665, 0.6779005524861879, 0.6666666666666666, 0.6244293970612107, 0.6592183286877086, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5911294], dtype=float32), 0.0032919226]. 
=============================================
[2019-04-06 21:14:40,482] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-06 21:14:40,482] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:14:40,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:14:40,487] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run69
[2019-04-06 21:14:40,527] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:14:40,528] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:14:40,529] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:14:40,529] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:14:40,533] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run69
[2019-04-06 21:14:40,554] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run69
[2019-04-06 21:16:46,839] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 21:17:28,338] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 21:17:29,377] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 21:17:30,415] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 1360000, evaluation results [1360000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 21:17:36,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:17:36,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:17:36,866] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run31
[2019-04-06 21:17:42,121] A3C_AGENT_WORKER-Thread-16 INFO:Local step 85000, global step 1361036: loss 0.2050
[2019-04-06 21:17:42,123] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 85000, global step 1361036: learning rate 0.0000
[2019-04-06 21:17:44,818] A3C_AGENT_WORKER-Thread-19 INFO:Local step 85500, global step 1361288: loss 0.0428
[2019-04-06 21:17:44,819] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 85500, global step 1361288: learning rate 0.0000
[2019-04-06 21:17:52,462] A3C_AGENT_WORKER-Thread-18 INFO:Local step 85500, global step 1361985: loss 0.0668
[2019-04-06 21:17:52,462] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 85500, global step 1361985: learning rate 0.0000
[2019-04-06 21:17:53,221] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9712076e-22 7.7431565e-24 6.6547714e-19 8.2123898e-23 1.0000000e+00
 5.6053105e-27 8.9995729e-24], sum to 1.0000
[2019-04-06 21:17:53,221] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6578
[2019-04-06 21:17:53,519] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [9.7, 92.5, 27.0, 0.0, 26.0, 25.71155110480336, 0.5083110821663804, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 981000.0000, 
sim time next is 982800.0000, 
raw observation next is [10.0, 92.0, 43.5, 0.0, 26.0, 26.14641500394658, 0.5740197175022766, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.739612188365651, 0.92, 0.145, 0.0, 0.6666666666666666, 0.6788679169955483, 0.6913399058340922, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6098536], dtype=float32), -1.4124074]. 
=============================================
[2019-04-06 21:17:54,680] A3C_AGENT_WORKER-Thread-8 INFO:Local step 85500, global step 1362209: loss 0.0499
[2019-04-06 21:17:54,688] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 85500, global step 1362209: learning rate 0.0000
[2019-04-06 21:17:58,885] A3C_AGENT_WORKER-Thread-15 INFO:Local step 85500, global step 1362662: loss 0.0481
[2019-04-06 21:17:58,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 85500, global step 1362662: learning rate 0.0000
[2019-04-06 21:18:03,631] A3C_AGENT_WORKER-Thread-7 INFO:Local step 85500, global step 1363138: loss 0.0787
[2019-04-06 21:18:03,632] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 85500, global step 1363138: learning rate 0.0000
[2019-04-06 21:18:04,271] A3C_AGENT_WORKER-Thread-12 INFO:Local step 85000, global step 1363214: loss 0.2154
[2019-04-06 21:18:04,275] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 85000, global step 1363214: learning rate 0.0000
[2019-04-06 21:18:05,721] A3C_AGENT_WORKER-Thread-14 INFO:Local step 86000, global step 1363378: loss 0.0329
[2019-04-06 21:18:05,724] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 86000, global step 1363378: learning rate 0.0000
[2019-04-06 21:18:16,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:18:16,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:18:16,733] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run31
[2019-04-06 21:18:23,597] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5359710e-22 9.0038697e-23 2.6968563e-18 1.3296056e-21 1.0000000e+00
 9.5487861e-27 8.5579552e-24], sum to 1.0000
[2019-04-06 21:18:23,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1600
[2019-04-06 21:18:23,654] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.25, 80.5, 0.0, 0.0, 26.0, 25.51873764486726, 0.4951410458388264, 1.0, 1.0, 13102.44355962267], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1582200.0000, 
sim time next is 1584000.0000, 
raw observation next is [5.0, 82.0, 19.0, 20.0, 26.0, 25.40747152669786, 0.458351905662983, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.6011080332409973, 0.82, 0.06333333333333334, 0.022099447513812154, 0.6666666666666666, 0.6172892938914885, 0.6527839685543276, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.576821], dtype=float32), -0.51285577]. 
=============================================
[2019-04-06 21:18:23,662] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[95.30065]
 [94.26174]
 [94.02783]
 [94.19404]
 [94.54067]], R is [[95.56899261]
 [95.55091095]
 [95.28980255]
 [95.18912506]
 [95.23723602]].
[2019-04-06 21:18:24,387] A3C_AGENT_WORKER-Thread-17 INFO:Local step 86000, global step 1365223: loss 0.0342
[2019-04-06 21:18:24,388] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 86000, global step 1365223: learning rate 0.0000
[2019-04-06 21:18:27,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:18:27,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:18:27,780] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run31
[2019-04-06 21:18:37,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:18:37,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:18:37,239] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run31
[2019-04-06 21:18:40,318] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.55490909e-08 1.36425085e-08 3.36374711e-07 1.94475440e-08
 9.99999642e-01 1.60741509e-09 5.51235546e-09], sum to 1.0000
[2019-04-06 21:18:40,337] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5463
[2019-04-06 21:18:40,388] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.2, 96.0, 0.0, 0.0, 20.0, 19.61517134484243, -0.905993559456333, 0.0, 1.0, 30951.285189253234], 
current ob forecast is [], 
actual action is [20.5], 
sim time this is 3600.0000, 
sim time next is 5400.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 20.5, 19.97222257325213, -0.8486936907355379, 0.0, 1.0, 50266.047758067776], 
processed observation next is [0.0, 0.043478260869565216, 0.662049861495845, 0.96, 0.0, 0.0, 0.20833333333333334, 0.16435188110434407, 0.21710210308815403, 0.0, 1.0, 0.2393621321812751], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.35202682], dtype=float32), -0.6662639]. 
=============================================
[2019-04-06 21:18:40,719] A3C_AGENT_WORKER-Thread-20 INFO:Local step 85000, global step 1366797: loss 0.2324
[2019-04-06 21:18:40,719] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 85000, global step 1366797: learning rate 0.0000
[2019-04-06 21:18:47,199] A3C_AGENT_WORKER-Thread-5 INFO:Local step 85000, global step 1367578: loss 0.2475
[2019-04-06 21:18:47,200] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 85000, global step 1367578: learning rate 0.0000
[2019-04-06 21:18:47,784] A3C_AGENT_WORKER-Thread-19 INFO:Local step 86000, global step 1367648: loss 0.0329
[2019-04-06 21:18:47,785] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 86000, global step 1367648: learning rate 0.0000
[2019-04-06 21:18:48,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:18:48,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:18:48,556] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run31
[2019-04-06 21:18:52,251] A3C_AGENT_WORKER-Thread-2 INFO:Local step 85000, global step 1368154: loss 0.1634
[2019-04-06 21:18:52,252] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 85000, global step 1368154: learning rate 0.0000
[2019-04-06 21:18:55,057] A3C_AGENT_WORKER-Thread-6 INFO:Local step 85500, global step 1368450: loss 0.0667
[2019-04-06 21:18:55,057] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 85500, global step 1368450: learning rate 0.0000
[2019-04-06 21:18:55,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:18:55,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:18:55,260] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run31
[2019-04-06 21:18:55,943] A3C_AGENT_WORKER-Thread-18 INFO:Local step 86000, global step 1368525: loss 0.0336
[2019-04-06 21:18:55,944] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 86000, global step 1368525: learning rate 0.0000
[2019-04-06 21:18:56,070] A3C_AGENT_WORKER-Thread-8 INFO:Local step 86000, global step 1368542: loss 0.0429
[2019-04-06 21:18:56,070] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 86000, global step 1368542: learning rate 0.0000
[2019-04-06 21:18:58,573] A3C_AGENT_WORKER-Thread-15 INFO:Local step 86000, global step 1368841: loss 0.0355
[2019-04-06 21:18:58,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 86000, global step 1368841: learning rate 0.0000
[2019-04-06 21:19:00,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:19:00,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:19:00,248] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run31
[2019-04-06 21:19:01,870] A3C_AGENT_WORKER-Thread-7 INFO:Local step 86000, global step 1369181: loss 0.0326
[2019-04-06 21:19:01,871] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 86000, global step 1369181: learning rate 0.0000
[2019-04-06 21:19:04,321] A3C_AGENT_WORKER-Thread-4 INFO:Local step 85000, global step 1369434: loss 0.2143
[2019-04-06 21:19:04,322] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 85000, global step 1369434: learning rate 0.0000
[2019-04-06 21:19:11,097] A3C_AGENT_WORKER-Thread-13 INFO:Local step 85000, global step 1370122: loss 0.2777
[2019-04-06 21:19:11,097] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 85000, global step 1370122: learning rate 0.0000
[2019-04-06 21:19:13,454] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3153320e-20 4.6016492e-19 3.8086565e-15 4.4230676e-19 1.0000000e+00
 2.5227162e-20 2.7984402e-19], sum to 1.0000
[2019-04-06 21:19:13,454] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6685
[2019-04-06 21:19:13,648] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.2, 39.0, 37.0, 707.0, 26.0, 26.33559070628537, 0.3557337220412495, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 401400.0000, 
sim time next is 403200.0000, 
raw observation next is [-8.9, 38.0, 29.0, 555.0, 26.0, 25.76062661912154, 0.3996092482702513, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.21606648199445982, 0.38, 0.09666666666666666, 0.6132596685082873, 0.6666666666666666, 0.6467188849267949, 0.6332030827567504, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([3.02882], dtype=float32), 0.017457483]. 
=============================================
[2019-04-06 21:19:15,275] A3C_AGENT_WORKER-Thread-3 INFO:Local step 85000, global step 1370584: loss 0.1416
[2019-04-06 21:19:15,276] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 85000, global step 1370584: learning rate 0.0000
[2019-04-06 21:19:16,434] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1789191e-20 3.2841338e-21 7.8946435e-16 1.2227531e-19 1.0000000e+00
 1.1072837e-22 3.2957049e-21], sum to 1.0000
[2019-04-06 21:19:16,434] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3064
[2019-04-06 21:19:16,526] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.2, 76.5, 0.0, 0.0, 26.0, 23.91552709567785, 0.0380137027072067, 0.0, 1.0, 43711.11227345779], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 102600.0000, 
sim time next is 104400.0000, 
raw observation next is [-5.0, 74.0, 0.0, 0.0, 26.0, 23.72780645599079, -0.001704925065089231, 0.0, 1.0, 43983.410314703935], 
processed observation next is [1.0, 0.21739130434782608, 0.32409972299168976, 0.74, 0.0, 0.0, 0.6666666666666666, 0.4773172046658993, 0.4994316916449703, 0.0, 1.0, 0.2094448110223997], 
reward next is 0.7906, 
noisyNet noise sample is [array([-0.55276495], dtype=float32), -0.49055696]. 
=============================================
[2019-04-06 21:19:19,013] A3C_AGENT_WORKER-Thread-16 INFO:Local step 85500, global step 1370967: loss 0.0837
[2019-04-06 21:19:19,026] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 85500, global step 1370967: learning rate 0.0000
[2019-04-06 21:19:27,408] A3C_AGENT_WORKER-Thread-14 INFO:Local step 86500, global step 1371996: loss 0.0971
[2019-04-06 21:19:27,410] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 86500, global step 1371997: learning rate 0.0000
[2019-04-06 21:19:31,012] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5773490e-19 1.2260186e-18 2.3877096e-15 1.2932750e-18 1.0000000e+00
 5.7721075e-21 1.0246387e-18], sum to 1.0000
[2019-04-06 21:19:31,013] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4649
[2019-04-06 21:19:31,050] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.8, 86.0, 0.0, 0.0, 26.0, 24.1292957495006, 0.09781885190761747, 0.0, 1.0, 43932.53932522732], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2257200.0000, 
sim time next is 2259000.0000, 
raw observation next is [-8.1, 86.5, 0.0, 0.0, 26.0, 24.17377084350127, 0.084635754549585, 0.0, 1.0, 43687.47627955446], 
processed observation next is [1.0, 0.13043478260869565, 0.23822714681440446, 0.865, 0.0, 0.0, 0.6666666666666666, 0.5144809036251058, 0.528211918183195, 0.0, 1.0, 0.2080356013312117], 
reward next is 0.7920, 
noisyNet noise sample is [array([1.449889], dtype=float32), -0.57081866]. 
=============================================
[2019-04-06 21:19:31,055] A3C_AGENT_WORKER-Thread-12 INFO:Local step 85500, global step 1372438: loss 0.0841
[2019-04-06 21:19:31,055] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 85500, global step 1372438: learning rate 0.0000
[2019-04-06 21:19:31,070] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[80.73614]
 [80.64034]
 [80.58034]
 [80.55399]
 [80.5335 ]], R is [[80.62480164]
 [80.60935211]
 [80.5933075 ]
 [80.57788849]
 [80.56215668]].
[2019-04-06 21:19:31,269] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7462124e-23 3.1456787e-24 7.9964103e-19 3.8463856e-22 1.0000000e+00
 2.3069277e-26 4.7082110e-24], sum to 1.0000
[2019-04-06 21:19:31,277] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2745
[2019-04-06 21:19:31,316] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [9.7, 88.0, 0.0, 0.0, 26.0, 25.48271965550069, 0.4528158415263341, 1.0, 1.0, 16470.99848336989], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 977400.0000, 
sim time next is 979200.0000, 
raw observation next is [9.4, 93.0, 13.5, 0.0, 26.0, 25.41414989406065, 0.4374141272243708, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.7229916897506927, 0.93, 0.045, 0.0, 0.6666666666666666, 0.6178458245050541, 0.6458047090747903, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8005583], dtype=float32), -0.21379904]. 
=============================================
[2019-04-06 21:19:38,687] A3C_AGENT_WORKER-Thread-17 INFO:Local step 86500, global step 1373394: loss 0.0646
[2019-04-06 21:19:38,687] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 86500, global step 1373394: learning rate 0.0000
[2019-04-06 21:19:40,622] A3C_AGENT_WORKER-Thread-6 INFO:Local step 86000, global step 1373600: loss 0.0344
[2019-04-06 21:19:40,623] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 86000, global step 1373600: learning rate 0.0000
[2019-04-06 21:19:56,020] A3C_AGENT_WORKER-Thread-19 INFO:Local step 86500, global step 1375567: loss 0.0665
[2019-04-06 21:19:56,021] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 86500, global step 1375567: learning rate 0.0000
[2019-04-06 21:19:57,278] A3C_AGENT_WORKER-Thread-20 INFO:Local step 85500, global step 1375735: loss 0.0707
[2019-04-06 21:19:57,278] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 85500, global step 1375735: learning rate 0.0000
[2019-04-06 21:20:01,922] A3C_AGENT_WORKER-Thread-5 INFO:Local step 85500, global step 1376387: loss 0.0821
[2019-04-06 21:20:01,922] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 85500, global step 1376387: learning rate 0.0000
[2019-04-06 21:20:02,093] A3C_AGENT_WORKER-Thread-16 INFO:Local step 86000, global step 1376411: loss 0.0343
[2019-04-06 21:20:02,135] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 86000, global step 1376414: learning rate 0.0000
[2019-04-06 21:20:04,305] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.9449639e-20 2.1560668e-19 1.2015368e-15 1.0490859e-17 1.0000000e+00
 2.4082189e-22 1.5340622e-19], sum to 1.0000
[2019-04-06 21:20:04,306] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7409
[2019-04-06 21:20:04,464] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 54.0, 94.0, 673.5, 26.0, 26.03716206782303, 0.5715730811091763, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2732400.0000, 
sim time next is 2734200.0000, 
raw observation next is [-3.5, 52.0, 86.0, 614.0, 26.0, 26.32966823129698, 0.631121604193802, 1.0, 1.0, 21885.455343689817], 
processed observation next is [1.0, 0.6521739130434783, 0.36565096952908593, 0.52, 0.2866666666666667, 0.6784530386740332, 0.6666666666666666, 0.6941390192747484, 0.7103738680646007, 1.0, 1.0, 0.10421645401757056], 
reward next is 0.8958, 
noisyNet noise sample is [array([0.6217952], dtype=float32), 0.78143793]. 
=============================================
[2019-04-06 21:20:05,535] A3C_AGENT_WORKER-Thread-18 INFO:Local step 86500, global step 1376927: loss 0.0638
[2019-04-06 21:20:05,535] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 86500, global step 1376927: learning rate 0.0000
[2019-04-06 21:20:06,774] A3C_AGENT_WORKER-Thread-8 INFO:Local step 86500, global step 1377113: loss 0.0687
[2019-04-06 21:20:06,776] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 86500, global step 1377113: learning rate 0.0000
[2019-04-06 21:20:06,929] A3C_AGENT_WORKER-Thread-15 INFO:Local step 86500, global step 1377139: loss 0.0777
[2019-04-06 21:20:06,930] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 86500, global step 1377139: learning rate 0.0000
[2019-04-06 21:20:07,994] A3C_AGENT_WORKER-Thread-2 INFO:Local step 85500, global step 1377294: loss 0.0638
[2019-04-06 21:20:08,006] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 85500, global step 1377294: learning rate 0.0000
[2019-04-06 21:20:12,021] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1262542e-21 2.5089789e-23 2.7689649e-17 6.7489723e-21 1.0000000e+00
 2.2198735e-24 1.4660455e-22], sum to 1.0000
[2019-04-06 21:20:12,021] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6174
[2019-04-06 21:20:12,129] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.05, 67.5, 254.0, 215.0, 26.0, 27.48620456888316, 0.646005011882822, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1078200.0000, 
sim time next is 1080000.0000, 
raw observation next is [16.6, 65.0, 217.5, 266.0, 26.0, 27.17988971747023, 0.6307766065387382, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.922437673130194, 0.65, 0.725, 0.29392265193370165, 0.6666666666666666, 0.7649908097891857, 0.7102588688462461, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.01682087], dtype=float32), -0.58523995]. 
=============================================
[2019-04-06 21:20:12,149] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[ 98.79966]
 [101.28987]
 [100.57283]
 [100.80615]
 [101.04018]], R is [[97.15498352]
 [97.18343353]
 [97.21160126]
 [97.23948669]
 [97.26708984]].
[2019-04-06 21:20:13,084] A3C_AGENT_WORKER-Thread-7 INFO:Local step 86500, global step 1378068: loss 0.0448
[2019-04-06 21:20:13,084] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 86500, global step 1378068: learning rate 0.0000
[2019-04-06 21:20:16,334] A3C_AGENT_WORKER-Thread-12 INFO:Local step 86000, global step 1378506: loss 0.0334
[2019-04-06 21:20:16,335] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 86000, global step 1378506: learning rate 0.0000
[2019-04-06 21:20:19,449] A3C_AGENT_WORKER-Thread-14 INFO:Local step 87000, global step 1378980: loss 0.0849
[2019-04-06 21:20:19,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 87000, global step 1378980: learning rate 0.0000
[2019-04-06 21:20:19,457] A3C_AGENT_WORKER-Thread-4 INFO:Local step 85500, global step 1378981: loss 0.0472
[2019-04-06 21:20:19,457] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 85500, global step 1378981: learning rate 0.0000
[2019-04-06 21:20:20,927] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7546765e-22 1.5505088e-23 7.3483908e-20 2.5292274e-22 1.0000000e+00
 4.5426794e-27 2.8288813e-25], sum to 1.0000
[2019-04-06 21:20:20,928] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1403
[2019-04-06 21:20:20,998] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.0, 100.0, 101.0, 763.0, 26.0, 27.61609229611195, 0.9385155034750984, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3162600.0000, 
sim time next is 3164400.0000, 
raw observation next is [7.0, 100.0, 92.5, 721.0, 26.0, 27.7195523743597, 0.8403579672040237, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.6565096952908588, 1.0, 0.30833333333333335, 0.7966850828729282, 0.6666666666666666, 0.8099626978633084, 0.7801193224013412, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.19368218], dtype=float32), 1.5266081]. 
=============================================
[2019-04-06 21:20:24,462] A3C_AGENT_WORKER-Thread-13 INFO:Local step 85500, global step 1379733: loss 0.0697
[2019-04-06 21:20:24,463] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 85500, global step 1379733: learning rate 0.0000
[2019-04-06 21:20:26,016] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-06 21:20:26,016] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:20:26,016] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:20:26,020] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run70
[2019-04-06 21:20:26,040] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:20:26,042] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:20:26,054] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:20:26,061] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run70
[2019-04-06 21:20:26,063] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:20:26,087] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run70
[2019-04-06 21:22:32,563] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 21:23:08,950] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 21:23:14,905] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 21:23:15,954] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1380000, evaluation results [1380000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 21:23:18,856] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1170812e-17 3.8592809e-19 1.0957665e-14 1.6584907e-17 1.0000000e+00
 1.1947015e-19 1.2816354e-18], sum to 1.0000
[2019-04-06 21:23:18,856] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0487
[2019-04-06 21:23:18,934] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 39.0, 91.5, 724.0, 26.0, 25.11709159150148, 0.3645796427223548, 0.0, 1.0, 18702.64314491442], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3078000.0000, 
sim time next is 3079800.0000, 
raw observation next is [0.5, 39.5, 84.0, 673.0, 26.0, 25.12733424884191, 0.366575038564407, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.4764542936288089, 0.395, 0.28, 0.7436464088397791, 0.6666666666666666, 0.5939445207368257, 0.6221916795214689, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.34207082], dtype=float32), -0.21789157]. 
=============================================
[2019-04-06 21:23:20,472] A3C_AGENT_WORKER-Thread-3 INFO:Local step 85500, global step 1380482: loss 0.0838
[2019-04-06 21:23:20,472] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 85500, global step 1380482: learning rate 0.0000
[2019-04-06 21:23:21,267] A3C_AGENT_WORKER-Thread-17 INFO:Local step 87000, global step 1380563: loss 0.1049
[2019-04-06 21:23:21,268] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 87000, global step 1380563: learning rate 0.0000
[2019-04-06 21:23:27,240] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.0494993e-22 1.3903808e-24 4.0320138e-19 1.7104286e-21 1.0000000e+00
 9.7035666e-26 3.0657957e-24], sum to 1.0000
[2019-04-06 21:23:27,240] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6244
[2019-04-06 21:23:27,339] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.45, 60.5, 181.0, 317.0, 26.0, 27.00662362253207, 0.7245839329470888, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1081800.0000, 
sim time next is 1083600.0000, 
raw observation next is [18.3, 56.0, 176.0, 158.5, 26.0, 26.92865898777615, 0.8690069452565092, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.9695290858725764, 0.56, 0.5866666666666667, 0.17513812154696132, 0.6666666666666666, 0.7440549156480124, 0.7896689817521697, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7314601], dtype=float32), -0.23282154]. 
=============================================
[2019-04-06 21:23:41,992] A3C_AGENT_WORKER-Thread-20 INFO:Local step 86000, global step 1382712: loss 0.0340
[2019-04-06 21:23:41,993] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 86000, global step 1382712: learning rate 0.0000
[2019-04-06 21:23:49,724] A3C_AGENT_WORKER-Thread-5 INFO:Local step 86000, global step 1383381: loss 0.0355
[2019-04-06 21:23:49,725] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 86000, global step 1383381: learning rate 0.0000
[2019-04-06 21:23:50,342] A3C_AGENT_WORKER-Thread-19 INFO:Local step 87000, global step 1383449: loss 0.0868
[2019-04-06 21:23:50,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 87000, global step 1383449: learning rate 0.0000
[2019-04-06 21:23:54,135] A3C_AGENT_WORKER-Thread-6 INFO:Local step 86500, global step 1383854: loss 0.0471
[2019-04-06 21:23:54,136] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 86500, global step 1383854: learning rate 0.0000
[2019-04-06 21:24:00,170] A3C_AGENT_WORKER-Thread-2 INFO:Local step 86000, global step 1384459: loss 0.0399
[2019-04-06 21:24:00,173] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 86000, global step 1384459: learning rate 0.0000
[2019-04-06 21:24:02,172] A3C_AGENT_WORKER-Thread-18 INFO:Local step 87000, global step 1384675: loss 0.1065
[2019-04-06 21:24:02,194] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 87000, global step 1384675: learning rate 0.0000
[2019-04-06 21:24:04,215] A3C_AGENT_WORKER-Thread-8 INFO:Local step 87000, global step 1384986: loss 0.0996
[2019-04-06 21:24:04,227] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 87000, global step 1384986: learning rate 0.0000
[2019-04-06 21:24:05,773] A3C_AGENT_WORKER-Thread-15 INFO:Local step 87000, global step 1385203: loss 0.0863
[2019-04-06 21:24:05,774] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 87000, global step 1385203: learning rate 0.0000
[2019-04-06 21:24:09,792] A3C_AGENT_WORKER-Thread-14 INFO:Local step 87500, global step 1385775: loss 0.0354
[2019-04-06 21:24:09,792] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 87500, global step 1385775: learning rate 0.0000
[2019-04-06 21:24:11,151] A3C_AGENT_WORKER-Thread-4 INFO:Local step 86000, global step 1385976: loss 0.0331
[2019-04-06 21:24:11,151] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 86000, global step 1385976: learning rate 0.0000
[2019-04-06 21:24:11,313] A3C_AGENT_WORKER-Thread-7 INFO:Local step 87000, global step 1385995: loss 0.0878
[2019-04-06 21:24:11,313] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 87000, global step 1385995: learning rate 0.0000
[2019-04-06 21:24:15,875] A3C_AGENT_WORKER-Thread-13 INFO:Local step 86000, global step 1386657: loss 0.0330
[2019-04-06 21:24:15,876] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 86000, global step 1386657: learning rate 0.0000
[2019-04-06 21:24:16,469] A3C_AGENT_WORKER-Thread-16 INFO:Local step 86500, global step 1386733: loss 0.0633
[2019-04-06 21:24:16,470] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 86500, global step 1386733: learning rate 0.0000
[2019-04-06 21:24:20,801] A3C_AGENT_WORKER-Thread-17 INFO:Local step 87500, global step 1387317: loss 0.0582
[2019-04-06 21:24:20,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 87500, global step 1387317: learning rate 0.0000
[2019-04-06 21:24:21,336] A3C_AGENT_WORKER-Thread-3 INFO:Local step 86000, global step 1387396: loss 0.0337
[2019-04-06 21:24:21,336] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 86000, global step 1387396: learning rate 0.0000
[2019-04-06 21:24:29,602] A3C_AGENT_WORKER-Thread-12 INFO:Local step 86500, global step 1388574: loss 0.0697
[2019-04-06 21:24:29,603] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 86500, global step 1388574: learning rate 0.0000
[2019-04-06 21:24:32,257] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.1556108e-18 2.6380129e-19 2.4653652e-15 2.3316666e-17 1.0000000e+00
 7.8822894e-20 7.6827713e-19], sum to 1.0000
[2019-04-06 21:24:32,257] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4355
[2019-04-06 21:24:32,320] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 41.0, 0.0, 0.0, 26.0, 25.03489875887159, 0.3194813667302341, 0.0, 1.0, 40776.90991894503], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4066200.0000, 
sim time next is 4068000.0000, 
raw observation next is [-6.0, 41.0, 0.0, 0.0, 26.0, 25.08450894800896, 0.3021503410919481, 0.0, 1.0, 40824.228218629134], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.41, 0.0, 0.0, 0.6666666666666666, 0.5903757456674134, 0.6007167803639827, 0.0, 1.0, 0.19440108675537682], 
reward next is 0.8056, 
noisyNet noise sample is [array([-0.8751162], dtype=float32), 0.44119853]. 
=============================================
[2019-04-06 21:24:32,338] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[75.150764]
 [74.945755]
 [74.84238 ]
 [74.81333 ]
 [74.880226]], R is [[75.39699554]
 [75.44885254]
 [75.50074768]
 [75.55247498]
 [75.60364532]].
[2019-04-06 21:24:37,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:24:37,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:24:37,844] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run32
[2019-04-06 21:24:38,022] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.7393625e-18 1.0524202e-18 7.0024658e-15 3.8421298e-16 1.0000000e+00
 3.6719711e-21 1.1956043e-19], sum to 1.0000
[2019-04-06 21:24:38,022] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6764
[2019-04-06 21:24:38,251] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 47.0, 86.0, 341.0, 26.0, 24.98095460546822, 0.3184827947604267, 0.0, 1.0, 22439.957366114773], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2388600.0000, 
sim time next is 2390400.0000, 
raw observation next is [0.0, 47.0, 82.5, 199.5, 26.0, 25.00900758759506, 0.2986205659900015, 0.0, 1.0, 18924.568415004607], 
processed observation next is [0.0, 0.6956521739130435, 0.46260387811634357, 0.47, 0.275, 0.22044198895027625, 0.6666666666666666, 0.5840839656329218, 0.5995401886633338, 0.0, 1.0, 0.09011699245240289], 
reward next is 0.9099, 
noisyNet noise sample is [array([1.4973297], dtype=float32), -0.05934101]. 
=============================================
[2019-04-06 21:24:38,297] A3C_AGENT_WORKER-Thread-19 INFO:Local step 87500, global step 1389848: loss 0.0481
[2019-04-06 21:24:38,299] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 87500, global step 1389848: learning rate 0.0000
[2019-04-06 21:24:40,651] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.41153085e-20 1.01006516e-20 3.37534927e-16 1.79791183e-19
 1.00000000e+00 7.82920593e-23 2.22942421e-21], sum to 1.0000
[2019-04-06 21:24:40,651] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1478
[2019-04-06 21:24:40,724] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 49.0, 75.0, 606.0, 26.0, 26.72866249837497, 0.7418040397472011, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3513600.0000, 
sim time next is 3515400.0000, 
raw observation next is [3.0, 49.0, 62.0, 525.0, 26.0, 26.89664160902308, 0.7412004909364104, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.49, 0.20666666666666667, 0.580110497237569, 0.6666666666666666, 0.7413868007519234, 0.7470668303121367, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0714941], dtype=float32), -2.0471303]. 
=============================================
[2019-04-06 21:24:47,321] A3C_AGENT_WORKER-Thread-18 INFO:Local step 87500, global step 1391213: loss 0.0460
[2019-04-06 21:24:47,321] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 87500, global step 1391213: learning rate 0.0000
[2019-04-06 21:24:47,807] A3C_AGENT_WORKER-Thread-8 INFO:Local step 87500, global step 1391295: loss 0.0485
[2019-04-06 21:24:47,808] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 87500, global step 1391295: learning rate 0.0000
[2019-04-06 21:24:48,784] A3C_AGENT_WORKER-Thread-6 INFO:Local step 87000, global step 1391428: loss 0.0834
[2019-04-06 21:24:48,797] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 87000, global step 1391428: learning rate 0.0000
[2019-04-06 21:24:48,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:24:48,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:24:48,968] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run32
[2019-04-06 21:24:50,088] A3C_AGENT_WORKER-Thread-15 INFO:Local step 87500, global step 1391593: loss 0.0316
[2019-04-06 21:24:50,088] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 87500, global step 1391593: learning rate 0.0000
[2019-04-06 21:24:56,538] A3C_AGENT_WORKER-Thread-7 INFO:Local step 87500, global step 1392510: loss 0.0524
[2019-04-06 21:24:56,539] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 87500, global step 1392510: learning rate 0.0000
[2019-04-06 21:24:58,197] A3C_AGENT_WORKER-Thread-20 INFO:Local step 86500, global step 1392752: loss 0.0980
[2019-04-06 21:24:58,198] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 86500, global step 1392752: learning rate 0.0000
[2019-04-06 21:25:00,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9038112e-19 2.4791941e-20 1.2496948e-17 6.0116463e-20 1.0000000e+00
 4.0755984e-23 1.1587215e-20], sum to 1.0000
[2019-04-06 21:25:00,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9031
[2019-04-06 21:25:00,481] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.7, 86.0, 83.0, 0.0, 26.0, 24.41586523013396, 0.1505375692382594, 0.0, 1.0, 34494.64708711862], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 50400.0000, 
sim time next is 52200.0000, 
raw observation next is [7.45, 86.0, 79.0, 0.0, 26.0, 24.4585915207352, 0.1657255515690211, 0.0, 1.0, 26483.88374573109], 
processed observation next is [0.0, 0.6086956521739131, 0.6689750692520776, 0.86, 0.2633333333333333, 0.0, 0.6666666666666666, 0.5382159600612667, 0.555241850523007, 0.0, 1.0, 0.126113732122529], 
reward next is 0.8739, 
noisyNet noise sample is [array([0.27856067], dtype=float32), -0.63828534]. 
=============================================
[2019-04-06 21:25:03,902] A3C_AGENT_WORKER-Thread-5 INFO:Local step 86500, global step 1393562: loss 0.1048
[2019-04-06 21:25:03,902] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 86500, global step 1393562: learning rate 0.0000
[2019-04-06 21:25:05,432] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5764538e-19 1.0496933e-19 2.1963127e-14 4.3290067e-18 1.0000000e+00
 2.9128670e-22 1.2707688e-19], sum to 1.0000
[2019-04-06 21:25:05,432] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8104
[2019-04-06 21:25:05,577] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.8, 67.5, 45.0, 0.0, 26.0, 25.36420517265353, 0.2572962681754978, 1.0, 1.0, 6246.100014065297], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 120600.0000, 
sim time next is 122400.0000, 
raw observation next is [-7.8, 74.0, 117.5, 18.0, 26.0, 25.32410477562814, 0.260489366692883, 1.0, 1.0, 36759.64596716578], 
processed observation next is [1.0, 0.43478260869565216, 0.24653739612188366, 0.74, 0.39166666666666666, 0.019889502762430938, 0.6666666666666666, 0.6103420646356783, 0.5868297888976276, 1.0, 1.0, 0.1750459331769799], 
reward next is 0.8250, 
noisyNet noise sample is [array([0.02883685], dtype=float32), -2.3951797]. 
=============================================
[2019-04-06 21:25:06,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:25:06,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:25:06,547] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run32
[2019-04-06 21:25:06,903] A3C_AGENT_WORKER-Thread-16 INFO:Local step 87000, global step 1394010: loss 0.0939
[2019-04-06 21:25:06,903] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 87000, global step 1394010: learning rate 0.0000
[2019-04-06 21:25:08,861] A3C_AGENT_WORKER-Thread-2 INFO:Local step 86500, global step 1394267: loss 0.0729
[2019-04-06 21:25:08,861] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 86500, global step 1394267: learning rate 0.0000
[2019-04-06 21:25:13,819] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.0557564e-19 1.7681406e-20 3.5210476e-15 4.8005373e-18 1.0000000e+00
 2.4187617e-21 2.4230943e-20], sum to 1.0000
[2019-04-06 21:25:13,820] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4866
[2019-04-06 21:25:13,865] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.7, 44.5, 272.0, 388.0, 26.0, 25.07368952797404, 0.3665979716932402, 0.0, 1.0, 12509.36214278976], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4887000.0000, 
sim time next is 4888800.0000, 
raw observation next is [2.0, 44.0, 254.0, 381.0, 26.0, 25.09908409525446, 0.3678284228714754, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.518005540166205, 0.44, 0.8466666666666667, 0.42099447513812155, 0.6666666666666666, 0.5915903412712051, 0.6226094742904918, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.32806742], dtype=float32), 0.35803682]. 
=============================================
[2019-04-06 21:25:14,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:25:14,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:25:14,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run32
[2019-04-06 21:25:15,522] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:25:15,523] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:25:15,526] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run32
[2019-04-06 21:25:15,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:25:15,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:25:15,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run32
[2019-04-06 21:25:17,009] A3C_AGENT_WORKER-Thread-4 INFO:Local step 86500, global step 1395400: loss 0.1031
[2019-04-06 21:25:17,014] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 86500, global step 1395400: learning rate 0.0000
[2019-04-06 21:25:20,169] A3C_AGENT_WORKER-Thread-12 INFO:Local step 87000, global step 1395743: loss 0.0985
[2019-04-06 21:25:20,169] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 87000, global step 1395743: learning rate 0.0000
[2019-04-06 21:25:23,845] A3C_AGENT_WORKER-Thread-13 INFO:Local step 86500, global step 1396175: loss 0.0881
[2019-04-06 21:25:23,854] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 86500, global step 1396175: learning rate 0.0000
[2019-04-06 21:25:24,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:25:24,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:25:24,276] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run32
[2019-04-06 21:25:28,476] A3C_AGENT_WORKER-Thread-3 INFO:Local step 86500, global step 1396746: loss 0.0910
[2019-04-06 21:25:28,476] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 86500, global step 1396746: learning rate 0.0000
[2019-04-06 21:25:33,232] A3C_AGENT_WORKER-Thread-6 INFO:Local step 87500, global step 1397371: loss 0.0419
[2019-04-06 21:25:33,233] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 87500, global step 1397371: learning rate 0.0000
[2019-04-06 21:25:48,298] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.7123360e-18 1.1645137e-19 2.2149861e-15 5.6186305e-18 1.0000000e+00
 1.9002976e-21 1.0674363e-19], sum to 1.0000
[2019-04-06 21:25:48,298] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5706
[2019-04-06 21:25:48,339] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [9.0, 25.0, 0.0, 0.0, 26.0, 25.62637757899558, 0.3909099042180524, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3630600.0000, 
sim time next is 3632400.0000, 
raw observation next is [9.0, 25.0, 0.0, 0.0, 26.0, 25.56357427785613, 0.3672853592091651, 0.0, 1.0, 18760.88023689359], 
processed observation next is [0.0, 0.043478260869565216, 0.7119113573407203, 0.25, 0.0, 0.0, 0.6666666666666666, 0.6302978564880108, 0.6224284530697217, 0.0, 1.0, 0.08933752493758852], 
reward next is 0.9107, 
noisyNet noise sample is [array([0.16545942], dtype=float32), 0.3485352]. 
=============================================
[2019-04-06 21:25:49,648] A3C_AGENT_WORKER-Thread-20 INFO:Local step 87000, global step 1399598: loss 0.0836
[2019-04-06 21:25:49,649] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 87000, global step 1399598: learning rate 0.0000
[2019-04-06 21:25:49,768] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.3970094e-18 8.0413110e-20 2.2162274e-16 1.4095193e-18 1.0000000e+00
 4.6053649e-22 5.7614791e-22], sum to 1.0000
[2019-04-06 21:25:49,768] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0476
[2019-04-06 21:25:49,996] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.5, 73.5, 104.0, 615.0, 26.0, 26.20942432794059, 0.5343456237983569, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3317400.0000, 
sim time next is 3319200.0000, 
raw observation next is [-8.0, 70.0, 107.5, 677.5, 26.0, 26.31584181286727, 0.5684860938306995, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.24099722991689754, 0.7, 0.35833333333333334, 0.7486187845303868, 0.6666666666666666, 0.6929868177389391, 0.6894953646102332, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4164873], dtype=float32), -0.65955496]. 
=============================================
[2019-04-06 21:25:52,091] A3C_AGENT_WORKER-Thread-16 INFO:Local step 87500, global step 1399919: loss 0.0392
[2019-04-06 21:25:52,092] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 87500, global step 1399919: learning rate 0.0000
[2019-04-06 21:25:52,673] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-06 21:25:52,677] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:25:52,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:25:52,693] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run71
[2019-04-06 21:25:52,712] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:25:52,716] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:25:52,721] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run71
[2019-04-06 21:25:52,742] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:25:52,748] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:25:52,752] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run71
[2019-04-06 21:27:13,537] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14505106]
[2019-04-06 21:27:13,537] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-14.69031544, 92.70075979, 0.0, 0.0, 26.0, 22.51553733458846, -0.2445206256659835, 0.0, 1.0, 43942.006979682345]
[2019-04-06 21:27:13,537] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 21:27:13,538] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.6709768e-16 6.4658234e-17 1.1932819e-13 7.5990137e-16 1.0000000e+00
 6.1930459e-19 1.9391347e-17], sampled 0.13784023311695903
[2019-04-06 21:28:05,987] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 21:28:40,223] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 21:28:44,953] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 21:28:45,992] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1400000, evaluation results [1400000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 21:28:48,633] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6987445e-20 2.1236757e-20 6.6600864e-17 2.9147514e-18 1.0000000e+00
 1.3781570e-23 1.8229109e-20], sum to 1.0000
[2019-04-06 21:28:48,634] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8115
[2019-04-06 21:28:48,683] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.59010801985841, 0.5529688686188413, 0.0, 1.0, 36650.74111701015], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3790800.0000, 
sim time next is 3792600.0000, 
raw observation next is [-3.0, 74.0, 0.0, 0.0, 26.0, 25.60559869627094, 0.523869505287112, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.3795013850415513, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6337998913559115, 0.6746231684290374, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4765846], dtype=float32), 1.3096292]. 
=============================================
[2019-04-06 21:28:49,109] A3C_AGENT_WORKER-Thread-5 INFO:Local step 87000, global step 1400290: loss 0.0936
[2019-04-06 21:28:49,109] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 87000, global step 1400290: learning rate 0.0000
[2019-04-06 21:28:58,125] A3C_AGENT_WORKER-Thread-2 INFO:Local step 87000, global step 1401135: loss 0.0742
[2019-04-06 21:28:58,126] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 87000, global step 1401135: learning rate 0.0000
[2019-04-06 21:28:58,485] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.18914194e-17 1.85944101e-18 2.53453535e-14 9.35971539e-17
 1.00000000e+00 4.67186359e-21 2.55100536e-18], sum to 1.0000
[2019-04-06 21:28:58,485] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3603
[2019-04-06 21:28:58,772] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-11.1, 48.5, 55.0, 887.0, 26.0, 25.9160556744617, 0.4737083367189016, 1.0, 1.0, 54549.35389865053], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 394200.0000, 
sim time next is 396000.0000, 
raw observation next is [-10.5, 46.0, 51.5, 859.5, 26.0, 26.35096371237388, 0.5154427663446303, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.17174515235457063, 0.46, 0.17166666666666666, 0.9497237569060774, 0.6666666666666666, 0.6959136426978233, 0.67181425544821, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.54829866], dtype=float32), -0.45837438]. 
=============================================
[2019-04-06 21:28:58,776] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[78.40621 ]
 [77.96479 ]
 [78.106476]
 [78.36461 ]
 [77.65139 ]], R is [[78.12696838]
 [78.08594513]
 [78.16020203]
 [78.16989136]
 [77.83937836]].
[2019-04-06 21:28:58,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:28:58,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:28:58,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run32
[2019-04-06 21:29:00,358] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.1082733e-21 2.9540253e-21 1.9567242e-16 1.2400771e-19 1.0000000e+00
 8.6534839e-24 3.5900429e-22], sum to 1.0000
[2019-04-06 21:29:00,358] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6927
[2019-04-06 21:29:00,469] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 24.41642950211702, 0.1437891186188409, 0.0, 1.0, 38688.30335330574], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 887400.0000, 
sim time next is 889200.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 24.56031126187417, 0.1637731270333933, 0.0, 1.0, 38502.56259296218], 
processed observation next is [1.0, 0.30434782608695654, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.5466926051561808, 0.5545910423444644, 0.0, 1.0, 0.18334553615696278], 
reward next is 0.8167, 
noisyNet noise sample is [array([-0.10137428], dtype=float32), -0.85924244]. 
=============================================
[2019-04-06 21:29:03,286] A3C_AGENT_WORKER-Thread-12 INFO:Local step 87500, global step 1401546: loss 0.0765
[2019-04-06 21:29:03,288] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 87500, global step 1401546: learning rate 0.0000
[2019-04-06 21:29:08,127] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2305952e-19 4.6499587e-21 1.3573798e-17 4.0010028e-19 1.0000000e+00
 3.7518540e-23 4.9306119e-22], sum to 1.0000
[2019-04-06 21:29:08,127] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5481
[2019-04-06 21:29:08,570] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.7, 87.0, 20.5, 22.5, 26.0, 24.98334307345578, 0.3050346549286502, 0.0, 1.0, 41613.40506787581], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 579600.0000, 
sim time next is 581400.0000, 
raw observation next is [-2.0, 87.0, 0.0, 0.0, 26.0, 24.9433445698421, 0.2897799750245668, 0.0, 1.0, 45714.98845872764], 
processed observation next is [0.0, 0.7391304347826086, 0.40720221606648205, 0.87, 0.0, 0.0, 0.6666666666666666, 0.5786120474868417, 0.596593325008189, 0.0, 1.0, 0.21769042123203639], 
reward next is 0.7823, 
noisyNet noise sample is [array([-0.30852818], dtype=float32), 1.2521415]. 
=============================================
[2019-04-06 21:29:10,304] A3C_AGENT_WORKER-Thread-4 INFO:Local step 87000, global step 1402138: loss 0.0847
[2019-04-06 21:29:10,305] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 87000, global step 1402138: learning rate 0.0000
[2019-04-06 21:29:21,261] A3C_AGENT_WORKER-Thread-13 INFO:Local step 87000, global step 1403165: loss 0.0808
[2019-04-06 21:29:21,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 87000, global step 1403165: learning rate 0.0000
[2019-04-06 21:29:27,570] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:29:27,570] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:29:27,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run32
[2019-04-06 21:29:30,144] A3C_AGENT_WORKER-Thread-3 INFO:Local step 87000, global step 1403996: loss 0.0810
[2019-04-06 21:29:30,186] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 87000, global step 1403996: learning rate 0.0000
[2019-04-06 21:29:44,969] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:29:44,969] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:29:44,973] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run32
[2019-04-06 21:29:49,809] A3C_AGENT_WORKER-Thread-20 INFO:Local step 87500, global step 1405883: loss 0.0368
[2019-04-06 21:29:49,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 87500, global step 1405883: learning rate 0.0000
[2019-04-06 21:29:54,505] A3C_AGENT_WORKER-Thread-5 INFO:Local step 87500, global step 1406513: loss 0.0595
[2019-04-06 21:29:54,505] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 87500, global step 1406513: learning rate 0.0000
[2019-04-06 21:30:00,995] A3C_AGENT_WORKER-Thread-2 INFO:Local step 87500, global step 1407499: loss 0.0440
[2019-04-06 21:30:00,996] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 87500, global step 1407499: learning rate 0.0000
[2019-04-06 21:30:07,758] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.2121020e-22 3.0074644e-22 5.7707511e-18 3.6289145e-21 1.0000000e+00
 5.8003488e-25 7.6047610e-22], sum to 1.0000
[2019-04-06 21:30:07,758] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1026
[2019-04-06 21:30:07,826] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 26.0, 25.37630443524334, 0.5798126357282481, 0.0, 1.0, 53786.26099356374], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1371600.0000, 
sim time next is 1373400.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 26.0, 25.49362306906737, 0.5818924163384345, 0.0, 1.0, 18758.518701525765], 
processed observation next is [1.0, 0.9130434782608695, 0.4764542936288089, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6244685890889476, 0.6939641387794783, 0.0, 1.0, 0.08932627953107507], 
reward next is 0.9107, 
noisyNet noise sample is [array([0.6868386], dtype=float32), -0.5617636]. 
=============================================
[2019-04-06 21:30:08,422] A3C_AGENT_WORKER-Thread-4 INFO:Local step 87500, global step 1408706: loss 0.0433
[2019-04-06 21:30:08,422] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 87500, global step 1408706: learning rate 0.0000
[2019-04-06 21:30:10,342] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6999347e-23 1.7329868e-23 2.5846708e-19 1.0646531e-22 1.0000000e+00
 2.6979567e-26 2.4248277e-24], sum to 1.0000
[2019-04-06 21:30:10,343] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8405
[2019-04-06 21:30:10,511] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.7, 84.0, 16.0, 0.5, 26.0, 25.69418734082189, 0.6066802547302632, 0.0, 1.0, 7411.09635989292], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1152000.0000, 
sim time next is 1153800.0000, 
raw observation next is [14.1, 79.5, 31.0, 0.0, 26.0, 25.64964709745314, 0.6185021280292654, 0.0, 1.0, 11560.417364658642], 
processed observation next is [0.0, 0.34782608695652173, 0.8531855955678671, 0.795, 0.10333333333333333, 0.0, 0.6666666666666666, 0.6374705914544284, 0.7061673760097551, 0.0, 1.0, 0.05504960649837449], 
reward next is 0.9450, 
noisyNet noise sample is [array([-0.52899414], dtype=float32), 1.6134896]. 
=============================================
[2019-04-06 21:30:15,120] A3C_AGENT_WORKER-Thread-13 INFO:Local step 87500, global step 1409895: loss 0.0435
[2019-04-06 21:30:15,131] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 87500, global step 1409896: learning rate 0.0000
[2019-04-06 21:30:16,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:30:16,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:30:16,908] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run32
[2019-04-06 21:30:20,834] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:30:20,834] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:30:20,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run32
[2019-04-06 21:30:22,901] A3C_AGENT_WORKER-Thread-3 INFO:Local step 87500, global step 1411040: loss 0.0402
[2019-04-06 21:30:22,901] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 87500, global step 1411040: learning rate 0.0000
[2019-04-06 21:30:28,087] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3373102e-19 3.1044386e-20 5.9263634e-16 6.7985659e-19 1.0000000e+00
 1.7315537e-22 7.8780472e-21], sum to 1.0000
[2019-04-06 21:30:28,087] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4458
[2019-04-06 21:30:28,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:30:28,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:30:28,140] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run32
[2019-04-06 21:30:28,338] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.75, 69.5, 0.0, 0.0, 26.0, 25.5915518298468, 0.2936161348880668, 1.0, 1.0, 30330.23168740502], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2136600.0000, 
sim time next is 2138400.0000, 
raw observation next is [-5.0, 71.0, 0.0, 0.0, 26.0, 25.26303901068961, 0.4763334125510963, 1.0, 1.0, 132776.3577618103], 
processed observation next is [1.0, 0.782608695652174, 0.32409972299168976, 0.71, 0.0, 0.0, 0.6666666666666666, 0.6052532508908008, 0.6587778041836988, 1.0, 1.0, 0.6322683702943348], 
reward next is 0.3677, 
noisyNet noise sample is [array([-1.4202076], dtype=float32), 0.77679557]. 
=============================================
[2019-04-06 21:30:30,451] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2639666e-21 1.5274738e-21 1.5167533e-16 1.0811231e-20 1.0000000e+00
 7.7239725e-26 4.4137209e-23], sum to 1.0000
[2019-04-06 21:30:30,451] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3567
[2019-04-06 21:30:30,507] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.65, 84.5, 0.0, 0.0, 26.0, 25.55192344997032, 0.5013054664577342, 0.0, 1.0, 16673.123116000712], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1571400.0000, 
sim time next is 1573200.0000, 
raw observation next is [4.7, 84.0, 0.0, 0.0, 26.0, 25.40774916638167, 0.524443494338105, 0.0, 1.0, 72027.91439338618], 
processed observation next is [1.0, 0.21739130434782608, 0.592797783933518, 0.84, 0.0, 0.0, 0.6666666666666666, 0.6173124305318058, 0.6748144981127017, 0.0, 1.0, 0.3429900685399342], 
reward next is 0.6570, 
noisyNet noise sample is [array([0.5908445], dtype=float32), 1.0149269]. 
=============================================
[2019-04-06 21:30:35,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:30:35,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:30:35,284] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run32
[2019-04-06 21:30:42,141] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:30:42,141] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:30:42,145] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run32
[2019-04-06 21:30:50,362] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:30:50,362] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:30:50,366] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run32
[2019-04-06 21:30:59,147] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0191892e-20 2.0107478e-20 1.3209748e-15 6.0434260e-19 1.0000000e+00
 1.8756882e-21 2.2470812e-21], sum to 1.0000
[2019-04-06 21:30:59,147] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3922
[2019-04-06 21:30:59,257] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.7, 79.0, 0.0, 0.0, 26.0, 24.73796027695566, 0.1989819529289752, 0.0, 1.0, 39365.93383576605], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 873000.0000, 
sim time next is 874800.0000, 
raw observation next is [-1.7, 79.0, 0.0, 0.0, 26.0, 24.60868136822765, 0.1834388642260507, 0.0, 1.0, 39361.364741401936], 
processed observation next is [1.0, 0.13043478260869565, 0.4155124653739613, 0.79, 0.0, 0.0, 0.6666666666666666, 0.5507234473523042, 0.5611462880753503, 0.0, 1.0, 0.18743507019715208], 
reward next is 0.8126, 
noisyNet noise sample is [array([0.4246334], dtype=float32), -0.9256208]. 
=============================================
[2019-04-06 21:31:04,692] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.5078452e-17 3.3084197e-18 8.2840364e-15 5.7115601e-16 1.0000000e+00
 1.2847577e-19 2.5459127e-17], sum to 1.0000
[2019-04-06 21:31:04,692] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3836
[2019-04-06 21:31:04,932] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-13.1, 55.5, 58.0, 764.0, 26.0, 25.72611200811386, 0.3223546857477071, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 387000.0000, 
sim time next is 388800.0000, 
raw observation next is [-12.8, 51.0, 58.0, 834.5, 26.0, 25.88713359131809, 0.2804107103761659, 1.0, 1.0, 115251.3472459603], 
processed observation next is [1.0, 0.5217391304347826, 0.1080332409972299, 0.51, 0.19333333333333333, 0.9220994475138121, 0.6666666666666666, 0.6572611326098409, 0.5934702367920554, 1.0, 1.0, 0.5488159392664776], 
reward next is 0.4512, 
noisyNet noise sample is [array([-0.5969085], dtype=float32), -1.0405202]. 
=============================================
[2019-04-06 21:31:16,784] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6420009e-19 1.4161524e-20 1.0721034e-14 2.6399167e-18 1.0000000e+00
 1.7324928e-21 4.3840266e-20], sum to 1.0000
[2019-04-06 21:31:16,785] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1410
[2019-04-06 21:31:16,849] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 63.5, 0.0, 0.0, 26.0, 24.88517795014916, 0.2797753940052417, 0.0, 1.0, 38422.53624005275], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2334600.0000, 
sim time next is 2336400.0000, 
raw observation next is [-2.3, 62.0, 0.0, 0.0, 26.0, 24.79043117328441, 0.2689245916905573, 0.0, 1.0, 38501.76629110609], 
processed observation next is [0.0, 0.043478260869565216, 0.3988919667590028, 0.62, 0.0, 0.0, 0.6666666666666666, 0.5658692644403676, 0.5896415305635191, 0.0, 1.0, 0.18334174424336233], 
reward next is 0.8167, 
noisyNet noise sample is [array([0.39303592], dtype=float32), 0.89384484]. 
=============================================
[2019-04-06 21:31:18,851] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8804634e-17 8.7122322e-19 1.6629659e-14 1.8709676e-18 1.0000000e+00
 1.2042134e-20 2.9198356e-19], sum to 1.0000
[2019-04-06 21:31:18,851] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6114
[2019-04-06 21:31:19,108] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.5, 44.0, 89.0, 694.5, 26.0, 25.47943764613223, 0.4482690677246429, 1.0, 1.0, 100888.95712585753], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 306000.0000, 
sim time next is 307800.0000, 
raw observation next is [-9.5, 44.0, 95.0, 631.0, 26.0, 26.15371299881651, 0.5193687668123476, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.1994459833795014, 0.44, 0.31666666666666665, 0.6972375690607735, 0.6666666666666666, 0.6794760832347091, 0.6731229222707825, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6537112], dtype=float32), 1.3226458]. 
=============================================
[2019-04-06 21:31:29,200] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.7800495e-18 6.6444730e-19 6.8371754e-15 9.8504062e-17 1.0000000e+00
 5.1053054e-21 5.1999478e-20], sum to 1.0000
[2019-04-06 21:31:29,200] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8698
[2019-04-06 21:31:29,347] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.8, 63.5, 0.0, 0.0, 26.0, 25.42346973840102, 0.2177325074956026, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 495000.0000, 
sim time next is 496800.0000, 
raw observation next is [0.5, 84.0, 0.0, 0.0, 26.0, 24.78713387943422, 0.1522260441150962, 1.0, 1.0, 75266.2473619037], 
processed observation next is [1.0, 0.782608695652174, 0.4764542936288089, 0.84, 0.0, 0.0, 0.6666666666666666, 0.5655944899528516, 0.550742014705032, 1.0, 1.0, 0.358410701723351], 
reward next is 0.6416, 
noisyNet noise sample is [array([-0.03396536], dtype=float32), 0.0017249946]. 
=============================================
[2019-04-06 21:31:38,569] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 21:31:38,573] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:31:38,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:31:38,585] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:31:38,585] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:31:38,590] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run72
[2019-04-06 21:31:38,609] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:31:38,614] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run72
[2019-04-06 21:31:38,633] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:31:38,638] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run72
[2019-04-06 21:33:47,678] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 21:34:23,644] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 21:34:30,676] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 21:34:31,715] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1420000, evaluation results [1420000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 21:34:50,027] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.6397533e-21 7.3647485e-21 2.2731921e-17 1.2702695e-19 1.0000000e+00
 7.7159444e-23 7.4072085e-21], sum to 1.0000
[2019-04-06 21:34:50,027] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0016
[2019-04-06 21:34:50,113] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.83932532698437, 0.28286954179867, 0.0, 1.0, 41105.67880858061], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3380400.0000, 
sim time next is 3382200.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.82734232866132, 0.2768626552325354, 0.0, 1.0, 41117.31062182662], 
processed observation next is [1.0, 0.13043478260869565, 0.296398891966759, 0.77, 0.0, 0.0, 0.6666666666666666, 0.56894519405511, 0.5922875517441785, 0.0, 1.0, 0.19579671724679343], 
reward next is 0.8042, 
noisyNet noise sample is [array([0.8568291], dtype=float32), -1.7021707]. 
=============================================
[2019-04-06 21:35:53,357] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.5937705e-18 1.0479734e-18 3.8821442e-16 1.8659069e-18 1.0000000e+00
 6.3568522e-22 2.2820693e-19], sum to 1.0000
[2019-04-06 21:35:53,357] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7294
[2019-04-06 21:35:53,517] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 49.5, 92.0, 488.0, 26.0, 24.96241070947192, 0.3967406547743133, 0.0, 1.0, 80530.73597252266], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4177800.0000, 
sim time next is 4179600.0000, 
raw observation next is [-4.0, 45.0, 100.0, 574.0, 26.0, 25.64886847583017, 0.438301824558077, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3518005540166205, 0.45, 0.3333333333333333, 0.6342541436464089, 0.6666666666666666, 0.6374057063191808, 0.6461006081860257, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6192259], dtype=float32), -0.777433]. 
=============================================
[2019-04-06 21:36:06,677] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3825590e-21 1.2686950e-20 6.4869959e-17 3.1453013e-20 1.0000000e+00
 7.1644734e-24 9.3735901e-22], sum to 1.0000
[2019-04-06 21:36:06,677] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9587
[2019-04-06 21:36:06,883] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 77.0, 94.5, 552.0, 26.0, 25.54629482750038, 0.4060175226325299, 1.0, 1.0, 12604.35843988143], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3747600.0000, 
sim time next is 3749400.0000, 
raw observation next is [-3.5, 77.0, 100.0, 675.0, 26.0, 26.12956698453755, 0.4860433475144302, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.36565096952908593, 0.77, 0.3333333333333333, 0.7458563535911602, 0.6666666666666666, 0.6774639153781292, 0.6620144491714767, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17523956], dtype=float32), -1.5507116]. 
=============================================
[2019-04-06 21:36:26,664] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:36:26,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:36:26,670] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run33
[2019-04-06 21:36:34,562] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3888115e-20 2.0534835e-19 2.8793352e-16 9.6334456e-20 1.0000000e+00
 2.9092135e-22 1.4909016e-20], sum to 1.0000
[2019-04-06 21:36:34,563] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4791
[2019-04-06 21:36:34,698] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 71.0, 123.0, 171.0, 26.0, 25.63665671143734, 0.4752548632928397, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4609800.0000, 
sim time next is 4611600.0000, 
raw observation next is [-2.0, 71.0, 143.5, 340.0, 26.0, 26.0936667719119, 0.5248473112034727, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.40720221606648205, 0.71, 0.47833333333333333, 0.3756906077348066, 0.6666666666666666, 0.6744722309926582, 0.6749491037344909, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.07987265], dtype=float32), 2.0457346]. 
=============================================
[2019-04-06 21:36:38,626] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:36:38,626] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:36:38,643] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run33
[2019-04-06 21:36:59,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:36:59,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:36:59,311] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run33
[2019-04-06 21:36:59,482] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2837471e-19 7.8219633e-20 1.8399692e-15 1.8655725e-18 1.0000000e+00
 7.2918379e-22 5.1401902e-20], sum to 1.0000
[2019-04-06 21:36:59,496] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0579
[2019-04-06 21:36:59,563] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.63593307661485, 0.2053817639020753, 0.0, 1.0, 41500.0896204446], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2773800.0000, 
sim time next is 2775600.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.58907798228919, 0.187677973368832, 0.0, 1.0, 41158.415738415024], 
processed observation next is [1.0, 0.13043478260869565, 0.296398891966759, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5490898318574325, 0.5625593244562773, 0.0, 1.0, 0.1959924558972144], 
reward next is 0.8040, 
noisyNet noise sample is [array([-0.88864696], dtype=float32), -0.23907462]. 
=============================================
[2019-04-06 21:37:03,845] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 21:37:03,849] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:37:03,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:37:03,851] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:37:03,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:37:03,853] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:37:03,853] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:37:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run73
[2019-04-06 21:37:03,884] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run73
[2019-04-06 21:37:03,908] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run73
[2019-04-06 21:38:45,559] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14538983]
[2019-04-06 21:38:45,560] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [0.385962788, 74.47516922, 0.0, 0.0, 26.0, 25.396378284725, 0.3597061568930153, 0.0, 1.0, 48934.47046711948]
[2019-04-06 21:38:45,560] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 21:38:45,561] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.3047857e-19 1.6105368e-20 1.3172553e-16 3.2931947e-19 1.0000000e+00
 8.4081030e-23 4.6107112e-21], sampled 0.5363154631018965
[2019-04-06 21:39:11,174] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 21:39:52,164] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 21:39:55,331] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 21:39:56,397] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1440000, evaluation results [1440000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 21:39:57,712] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.8401333e-21 7.7643123e-22 6.9781393e-17 1.7819073e-19 1.0000000e+00
 8.6463242e-24 8.0992417e-22], sum to 1.0000
[2019-04-06 21:39:57,713] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0968
[2019-04-06 21:39:57,845] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 29.0, 118.0, 835.5, 26.0, 26.296410011957, 0.6135628352752728, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4107600.0000, 
sim time next is 4109400.0000, 
raw observation next is [3.0, 30.0, 116.0, 830.0, 26.0, 26.01921271785373, 0.6014241969601325, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.3, 0.38666666666666666, 0.9171270718232044, 0.6666666666666666, 0.6682677264878109, 0.7004747323200441, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.25377116], dtype=float32), -0.26573727]. 
=============================================
[2019-04-06 21:40:04,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:40:04,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:40:04,020] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run33
[2019-04-06 21:40:09,776] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:40:09,776] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:40:09,781] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run33
[2019-04-06 21:40:12,438] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:40:12,438] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:40:12,442] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run33
[2019-04-06 21:40:13,062] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9893187e-18 4.0724852e-18 8.6833506e-15 1.7197879e-17 1.0000000e+00
 2.0541328e-20 9.1707931e-20], sum to 1.0000
[2019-04-06 21:40:13,063] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0501
[2019-04-06 21:40:13,347] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 30.0, 98.0, 0.0, 26.0, 25.47246915676806, 0.1736126650857671, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 469800.0000, 
sim time next is 471600.0000, 
raw observation next is [-2.3, 28.0, 110.0, 0.0, 26.0, 25.29315421245249, 0.1607023208710906, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.3988919667590028, 0.28, 0.36666666666666664, 0.0, 0.6666666666666666, 0.6077628510377074, 0.5535674402903635, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.70208764], dtype=float32), -0.47758555]. 
=============================================
[2019-04-06 21:40:16,590] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:40:16,590] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:40:16,594] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run33
[2019-04-06 21:40:45,558] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4990092e-21 1.4943912e-21 2.1477205e-17 8.9000375e-20 1.0000000e+00
 2.2692939e-24 3.5421319e-22], sum to 1.0000
[2019-04-06 21:40:45,558] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2020
[2019-04-06 21:40:45,628] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.35, 73.5, 0.0, 0.0, 26.0, 25.68591158994328, 0.4331318679643812, 0.0, 1.0, 12898.181272150488], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4325400.0000, 
sim time next is 4327200.0000, 
raw observation next is [4.5, 72.0, 0.0, 0.0, 26.0, 25.75825475759387, 0.4056142406201502, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.5872576177285319, 0.72, 0.0, 0.0, 0.6666666666666666, 0.6465212297994892, 0.6352047468733834, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2750403], dtype=float32), 0.71770644]. 
=============================================
[2019-04-06 21:40:47,123] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1551409e-16 3.3318901e-17 1.1769992e-14 3.2473562e-15 1.0000000e+00
 8.4561483e-18 3.5344610e-17], sum to 1.0000
[2019-04-06 21:40:47,123] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9379
[2019-04-06 21:40:47,259] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-15.0, 69.0, 0.0, 0.0, 26.0, 23.26602886048717, -0.1446413529439553, 0.0, 1.0, 48209.79621882003], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 352800.0000, 
sim time next is 354600.0000, 
raw observation next is [-15.0, 69.0, 0.0, 0.0, 26.0, 23.00054527457736, -0.1948471482582496, 0.0, 1.0, 48809.58413430696], 
processed observation next is [1.0, 0.08695652173913043, 0.04709141274238226, 0.69, 0.0, 0.0, 0.6666666666666666, 0.4167121062147799, 0.43505095058058346, 0.0, 1.0, 0.23242659111574743], 
reward next is 0.7676, 
noisyNet noise sample is [array([0.98128504], dtype=float32), -0.38360193]. 
=============================================
[2019-04-06 21:41:04,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:41:04,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:41:04,008] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run33
[2019-04-06 21:41:05,650] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.43162120e-21 1.29230148e-21 4.64486266e-17 1.17609355e-20
 1.00000000e+00 1.55079262e-23 5.20937589e-21], sum to 1.0000
[2019-04-06 21:41:05,650] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5962
[2019-04-06 21:41:05,704] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 94.0, 0.0, 0.0, 26.0, 24.84530142752837, 0.2330662357558947, 0.0, 1.0, 40903.5955486112], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 513000.0000, 
sim time next is 514800.0000, 
raw observation next is [3.3, 96.0, 0.0, 0.0, 26.0, 24.83630677283674, 0.233610302472429, 0.0, 1.0, 40531.362512556276], 
processed observation next is [1.0, 1.0, 0.554016620498615, 0.96, 0.0, 0.0, 0.6666666666666666, 0.5696922310697282, 0.577870100824143, 0.0, 1.0, 0.19300648815502988], 
reward next is 0.8070, 
noisyNet noise sample is [array([0.4488689], dtype=float32), -0.028402187]. 
=============================================
[2019-04-06 21:41:22,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:41:22,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:41:22,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run33
[2019-04-06 21:41:22,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3979963e-17 5.4593011e-19 2.3516211e-14 2.3898565e-18 1.0000000e+00
 9.9816046e-21 1.7906506e-18], sum to 1.0000
[2019-04-06 21:41:22,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7445
[2019-04-06 21:41:22,668] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 33.0, 118.0, 841.0, 26.0, 26.45736741539072, 0.4345178392532218, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4019400.0000, 
sim time next is 4021200.0000, 
raw observation next is [-4.0, 29.0, 116.0, 835.5, 26.0, 25.96920914963087, 0.5382414498666795, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3518005540166205, 0.29, 0.38666666666666666, 0.9232044198895027, 0.6666666666666666, 0.6641007624692392, 0.6794138166222266, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.31627628], dtype=float32), 0.104330145]. 
=============================================
[2019-04-06 21:41:24,128] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7997903e-21 7.1221619e-22 7.4402679e-18 3.9798874e-20 1.0000000e+00
 3.3497586e-24 3.3195630e-22], sum to 1.0000
[2019-04-06 21:41:24,128] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9380
[2019-04-06 21:41:24,239] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.5, 31.0, 123.0, 845.0, 26.0, 27.33913313909142, 0.8294039909983626, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5052600.0000, 
sim time next is 5054400.0000, 
raw observation next is [8.0, 26.0, 123.5, 855.0, 26.0, 27.36486379245746, 0.8535006671313328, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6842105263157896, 0.26, 0.4116666666666667, 0.9447513812154696, 0.6666666666666666, 0.7804053160381216, 0.7845002223771109, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5586563], dtype=float32), -1.2977064]. 
=============================================
[2019-04-06 21:41:26,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:41:26,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:41:26,951] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run33
[2019-04-06 21:41:49,180] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.8311760e-19 9.8872097e-20 9.2586141e-17 1.3280355e-19 1.0000000e+00
 1.1547490e-22 8.5274332e-21], sum to 1.0000
[2019-04-06 21:41:49,180] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1443
[2019-04-06 21:41:49,560] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 92.0, 62.0, 209.5, 26.0, 23.79535813880517, 0.1128093166396828, 0.0, 1.0, 41768.49630383199], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4780800.0000, 
sim time next is 4782600.0000, 
raw observation next is [-5.5, 84.5, 124.0, 419.0, 26.0, 24.3176406855364, 0.3488954712996868, 0.0, 1.0, 148650.4777939373], 
processed observation next is [0.0, 0.34782608695652173, 0.3102493074792244, 0.845, 0.41333333333333333, 0.46298342541436466, 0.6666666666666666, 0.5264700571280333, 0.6162984904332289, 0.0, 1.0, 0.707859418066368], 
reward next is 0.2921, 
noisyNet noise sample is [array([2.7359083], dtype=float32), -0.56803316]. 
=============================================
[2019-04-06 21:41:58,324] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [3.5256835e-23 5.3217069e-24 1.4730326e-19 1.3999085e-22 1.0000000e+00
 1.2168068e-26 3.7975241e-25], sum to 1.0000
[2019-04-06 21:41:58,324] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3766
[2019-04-06 21:41:58,370] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.4, 77.0, 0.0, 0.0, 26.0, 25.18182361358856, 0.571603359227779, 0.0, 1.0, 150649.5915166957], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1026000.0000, 
sim time next is 1027800.0000, 
raw observation next is [14.4, 76.0, 0.0, 0.0, 26.0, 25.81657350520087, 0.6228835112451169, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.8614958448753465, 0.76, 0.0, 0.0, 0.6666666666666666, 0.651381125433406, 0.7076278370817056, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09190616], dtype=float32), 2.2838554]. 
=============================================
[2019-04-06 21:42:02,138] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:42:02,139] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:42:02,142] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run33
[2019-04-06 21:42:06,062] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:42:06,062] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:42:06,079] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run33
[2019-04-06 21:42:12,684] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.3622838e-19 1.3469495e-18 9.0800653e-15 9.5633378e-18 1.0000000e+00
 8.9547895e-22 2.6700253e-19], sum to 1.0000
[2019-04-06 21:42:12,684] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9448
[2019-04-06 21:42:12,756] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.5, 65.5, 0.0, 0.0, 26.0, 24.7476107053427, 0.2093918681364205, 0.0, 1.0, 39489.67508356677], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4858200.0000, 
sim time next is 4860000.0000, 
raw observation next is [-3.0, 60.0, 0.0, 0.0, 26.0, 24.6511606435122, 0.1928369447031478, 0.0, 1.0, 39554.43048772056], 
processed observation next is [0.0, 0.2608695652173913, 0.3795013850415513, 0.6, 0.0, 0.0, 0.6666666666666666, 0.55426338695935, 0.5642789815677159, 0.0, 1.0, 0.1883544308939074], 
reward next is 0.8116, 
noisyNet noise sample is [array([-0.946969], dtype=float32), -1.2895185]. 
=============================================
[2019-04-06 21:42:12,770] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[77.834526]
 [77.97553 ]
 [78.04681 ]
 [78.24142 ]
 [78.55656 ]], R is [[77.61657715]
 [77.65235901]
 [77.68869781]
 [77.72512817]
 [77.76119995]].
[2019-04-06 21:42:15,807] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2480584e-20 2.9947583e-21 8.5892198e-17 6.6717440e-21 1.0000000e+00
 5.8727780e-24 1.1183980e-21], sum to 1.0000
[2019-04-06 21:42:15,808] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0646
[2019-04-06 21:42:16,017] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.8, 86.0, 0.0, 0.0, 26.0, 24.61430153745386, 0.2096662101395844, 0.0, 1.0, 41008.4179034336], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 68400.0000, 
sim time next is 70200.0000, 
raw observation next is [3.25, 87.5, 0.0, 0.0, 26.0, 24.64402258420607, 0.231521671222768, 0.0, 1.0, 79466.62668672431], 
processed observation next is [0.0, 0.8260869565217391, 0.5526315789473685, 0.875, 0.0, 0.0, 0.6666666666666666, 0.5536685486838392, 0.5771738904075893, 0.0, 1.0, 0.37841250803202053], 
reward next is 0.6216, 
noisyNet noise sample is [array([0.94086236], dtype=float32), -0.103395805]. 
=============================================
[2019-04-06 21:42:16,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:42:16,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:42:16,412] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run33
[2019-04-06 21:42:25,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:42:25,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:42:25,336] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run33
[2019-04-06 21:42:28,997] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9083412e-19 2.3976171e-19 5.8109171e-16 1.0056794e-18 1.0000000e+00
 8.5327982e-22 7.6391945e-20], sum to 1.0000
[2019-04-06 21:42:28,997] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6869
[2019-04-06 21:42:29,048] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.0, 29.0, 0.0, 0.0, 26.0, 25.63078166083515, 0.5378599495263682, 0.0, 1.0, 130956.63534868175], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5000400.0000, 
sim time next is 5002200.0000, 
raw observation next is [3.5, 33.0, 0.0, 0.0, 26.0, 25.693752777018, 0.5792820586062586, 0.0, 1.0, 59493.82738266833], 
processed observation next is [1.0, 0.9130434782608695, 0.5595567867036012, 0.33, 0.0, 0.0, 0.6666666666666666, 0.6411460647514998, 0.6930940195354195, 0.0, 1.0, 0.2833039399174682], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.49015614], dtype=float32), -1.4869771]. 
=============================================
[2019-04-06 21:42:33,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0595529e-19 5.2543837e-20 4.0555135e-16 7.1291859e-19 1.0000000e+00
 1.7777561e-22 8.3464629e-22], sum to 1.0000
[2019-04-06 21:42:33,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0575
[2019-04-06 21:42:33,989] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 34.0, 0.0, 0.0, 26.0, 25.47045485031579, 0.4960558002809082, 0.0, 1.0, 95332.47360988363], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5007600.0000, 
sim time next is 5009400.0000, 
raw observation next is [2.5, 37.0, 0.0, 0.0, 26.0, 25.57456230408929, 0.4820685529077287, 0.0, 1.0, 12496.306955887901], 
processed observation next is [1.0, 1.0, 0.5318559556786704, 0.37, 0.0, 0.0, 0.6666666666666666, 0.6312135253407742, 0.6606895176359096, 0.0, 1.0, 0.059506223599466196], 
reward next is 0.9405, 
noisyNet noise sample is [array([0.6737873], dtype=float32), -1.9263912]. 
=============================================
[2019-04-06 21:42:34,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:42:34,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:42:34,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run33
[2019-04-06 21:42:38,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:42:38,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:42:38,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run33
[2019-04-06 21:42:39,486] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-06 21:42:39,493] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:42:39,494] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:42:39,510] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run74
[2019-04-06 21:42:39,543] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:42:39,545] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:42:39,549] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run74
[2019-04-06 21:42:39,566] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:42:39,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:42:39,571] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run74
[2019-04-06 21:42:51,455] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14567736]
[2019-04-06 21:42:51,456] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-4.297122136500001, 65.19932988, 112.3468234, 0.0, 26.0, 24.96174122727481, 0.1686886110583453, 1.0, 1.0, 59705.67664436868]
[2019-04-06 21:42:51,456] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 21:42:51,456] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.0112409e-18 5.7320246e-19 2.4502046e-15 8.2323910e-18 1.0000000e+00
 3.5836550e-21 1.9931003e-19], sampled 0.22529667570855005
[2019-04-06 21:43:31,749] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14567736]
[2019-04-06 21:43:31,749] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-4.358335955, 69.11624796, 87.36442475999999, 171.4249874, 26.0, 25.01851273665204, 0.2768376921970988, 0.0, 1.0, 38468.6451960717]
[2019-04-06 21:43:31,750] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 21:43:31,750] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.3014787e-18 2.9223653e-19 1.4444673e-15 6.5352525e-18 1.0000000e+00
 3.1526390e-21 1.1627603e-19], sampled 0.6792925703566635
[2019-04-06 21:44:31,170] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14567736]
[2019-04-06 21:44:31,171] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [7.7, 79.0, 0.0, 0.0, 26.0, 25.64642491884408, 0.5434990222796486, 0.0, 1.0, 34282.20420869784]
[2019-04-06 21:44:31,171] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 21:44:31,172] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.2128338e-21 1.5312068e-22 2.5086982e-18 2.9204789e-21 1.0000000e+00
 3.9214049e-25 3.1219148e-23], sampled 0.8169625953210576
[2019-04-06 21:44:46,595] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 21:45:27,590] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 21:45:33,126] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 21:45:34,164] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1460000, evaluation results [1460000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 21:45:40,013] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6864626e-20 3.3342755e-20 2.1935253e-17 1.7142786e-18 1.0000000e+00
 6.7388522e-24 2.3565744e-21], sum to 1.0000
[2019-04-06 21:45:40,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2387
[2019-04-06 21:45:40,349] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 82.0, 39.0, 0.0, 26.0, 26.01863555282188, 0.4054053702967595, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 835200.0000, 
sim time next is 837000.0000, 
raw observation next is [-3.9, 84.0, 29.0, 0.0, 26.0, 25.8996293311785, 0.2951072564722799, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.3545706371191136, 0.84, 0.09666666666666666, 0.0, 0.6666666666666666, 0.6583024442648749, 0.59836908549076, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5913872], dtype=float32), -0.17445658]. 
=============================================
[2019-04-06 21:45:40,358] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[85.6751  ]
 [85.67633 ]
 [85.17867 ]
 [85.042076]
 [84.872   ]], R is [[85.84764862]
 [85.98917389]
 [85.78771973]
 [85.92984009]
 [86.07054138]].
[2019-04-06 21:45:43,060] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.2148182e-19 2.9155870e-17 3.9437264e-14 9.5945804e-18 1.0000000e+00
 7.1218934e-21 3.1698039e-18], sum to 1.0000
[2019-04-06 21:45:43,060] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.5801
[2019-04-06 21:45:43,123] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 82.0, 0.0, 0.0, 26.0, 23.54398886307692, -0.112475144136061, 0.0, 1.0, 45133.0806984246], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1920600.0000, 
sim time next is 1922400.0000, 
raw observation next is [-8.9, 82.0, 0.0, 0.0, 26.0, 23.36192298534186, -0.1523010158423481, 0.0, 1.0, 44927.53272996672], 
processed observation next is [1.0, 0.2608695652173913, 0.21606648199445982, 0.82, 0.0, 0.0, 0.6666666666666666, 0.44682691544515496, 0.4492329947192173, 0.0, 1.0, 0.21394063204746055], 
reward next is 0.7861, 
noisyNet noise sample is [array([0.22601382], dtype=float32), 0.64871454]. 
=============================================
[2019-04-06 21:46:06,523] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.4652372e-20 1.5081133e-20 1.2369567e-15 2.1349846e-18 1.0000000e+00
 1.2555355e-22 1.1937032e-20], sum to 1.0000
[2019-04-06 21:46:06,523] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6175
[2019-04-06 21:46:06,641] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 91.0, 0.0, 0.0, 26.0, 24.71259540887069, 0.2535760168783924, 0.0, 1.0, 42664.47810186247], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2073600.0000, 
sim time next is 2075400.0000, 
raw observation next is [-4.5, 91.0, 0.0, 0.0, 26.0, 24.73115776813425, 0.2555381708435472, 0.0, 1.0, 42845.52001632943], 
processed observation next is [1.0, 0.0, 0.3379501385041552, 0.91, 0.0, 0.0, 0.6666666666666666, 0.5609298140111875, 0.5851793902811824, 0.0, 1.0, 0.2040262857920449], 
reward next is 0.7960, 
noisyNet noise sample is [array([0.69796157], dtype=float32), 0.8791126]. 
=============================================
[2019-04-06 21:46:09,478] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.4573152e-20 1.6036706e-20 4.1828131e-16 1.5053831e-20 1.0000000e+00
 6.5469669e-22 1.1285421e-21], sum to 1.0000
[2019-04-06 21:46:09,478] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2027
[2019-04-06 21:46:09,933] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.55, 80.5, 72.0, 37.0, 26.0, 25.40915436493076, 0.3263997384363098, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2104200.0000, 
sim time next is 2106000.0000, 
raw observation next is [-7.8, 82.0, 123.0, 77.5, 26.0, 25.48072611973065, 0.3381969780966735, 1.0, 1.0, 6247.159222802203], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.82, 0.41, 0.0856353591160221, 0.6666666666666666, 0.6233938433108875, 0.6127323260322245, 1.0, 1.0, 0.02974837725143906], 
reward next is 0.9703, 
noisyNet noise sample is [array([0.51840013], dtype=float32), 0.016452227]. 
=============================================
[2019-04-06 21:46:09,938] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[83.349464]
 [83.53263 ]
 [83.23777 ]
 [81.35901 ]
 [82.040276]], R is [[83.27114105]
 [83.43843079]
 [83.52184296]
 [82.9744873 ]
 [82.9375    ]].
[2019-04-06 21:46:52,187] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5613337e-24 9.3799383e-26 1.9101747e-21 1.7477442e-24 1.0000000e+00
 5.4616508e-28 2.9707895e-25], sum to 1.0000
[2019-04-06 21:46:52,187] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1043
[2019-04-06 21:46:52,247] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.4, 75.0, 0.0, 0.0, 26.0, 26.03200182639522, 0.6330668669996066, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1040400.0000, 
sim time next is 1042200.0000, 
raw observation next is [14.1, 76.5, 0.0, 0.0, 26.0, 25.98232199376704, 0.6082572405702793, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.8531855955678671, 0.765, 0.0, 0.0, 0.6666666666666666, 0.6651934994805867, 0.7027524135234264, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0392355], dtype=float32), -1.7347683]. 
=============================================
[2019-04-06 21:47:11,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.5666876e-20 3.5533007e-20 1.3100294e-16 1.4712082e-18 1.0000000e+00
 5.5066852e-23 2.0427153e-21], sum to 1.0000
[2019-04-06 21:47:11,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2214
[2019-04-06 21:47:12,116] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 68.0, 137.0, 0.0, 26.0, 25.54711287449502, 0.3979398287033759, 1.0, 1.0, 17941.28023153859], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2124000.0000, 
sim time next is 2125800.0000, 
raw observation next is [-5.3, 68.0, 125.0, 0.0, 26.0, 26.01929547125336, 0.489035249375664, 1.0, 1.0, 61828.33734574416], 
processed observation next is [1.0, 0.6086956521739131, 0.31578947368421056, 0.68, 0.4166666666666667, 0.0, 0.6666666666666666, 0.6682746226044468, 0.663011749791888, 1.0, 1.0, 0.2944206540273532], 
reward next is 0.7056, 
noisyNet noise sample is [array([-0.03930089], dtype=float32), -1.2881105]. 
=============================================
[2019-04-06 21:47:40,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1086327e-19 2.0087401e-19 3.9132211e-15 8.0439236e-19 1.0000000e+00
 3.5597415e-22 6.0913328e-20], sum to 1.0000
[2019-04-06 21:47:40,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5846
[2019-04-06 21:47:40,280] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 48.0, 0.0, 0.0, 26.0, 25.42063275486584, 0.3583495015486013, 0.0, 1.0, 38344.89718758538], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4235400.0000, 
sim time next is 4237200.0000, 
raw observation next is [2.0, 48.0, 0.0, 0.0, 26.0, 25.41061381985163, 0.3522718434366247, 0.0, 1.0, 40722.28821403897], 
processed observation next is [0.0, 0.043478260869565216, 0.518005540166205, 0.48, 0.0, 0.0, 0.6666666666666666, 0.6175511516543025, 0.6174239478122082, 0.0, 1.0, 0.19391565816209033], 
reward next is 0.8061, 
noisyNet noise sample is [array([-0.61660385], dtype=float32), -2.5380733]. 
=============================================
[2019-04-06 21:48:13,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3122875e-20 1.0252437e-20 1.1817985e-16 3.3072193e-19 1.0000000e+00
 1.0031863e-23 1.0574208e-21], sum to 1.0000
[2019-04-06 21:48:13,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8216
[2019-04-06 21:48:14,040] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.6, 47.5, 40.0, 145.0, 26.0, 27.315582230542, 0.7747691459212492, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4642200.0000, 
sim time next is 4644000.0000, 
raw observation next is [4.0, 49.0, 0.0, 0.0, 26.0, 26.26737358561961, 0.6964355351218657, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.5734072022160666, 0.49, 0.0, 0.0, 0.6666666666666666, 0.688947798801634, 0.7321451783739552, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1543149], dtype=float32), 0.40427282]. 
=============================================
[2019-04-06 21:48:14,067] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[86.190735]
 [86.23872 ]
 [86.40351 ]
 [86.86561 ]
 [86.82584 ]], R is [[85.7477951 ]
 [85.89031982]
 [86.03141785]
 [86.17110443]
 [86.30939484]].
[2019-04-06 21:48:22,176] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 21:48:22,185] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:48:22,186] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:48:22,193] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:48:22,186] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:48:22,210] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:48:22,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:48:22,217] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run75
[2019-04-06 21:48:22,214] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run75
[2019-04-06 21:48:22,210] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run75
[2019-04-06 21:48:22,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:48:22,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:48:22,603] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run34
[2019-04-06 21:50:25,964] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 21:51:07,492] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 21:51:13,236] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 21:51:14,274] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1480000, evaluation results [1480000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 21:51:21,782] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0873822e-18 7.6201597e-20 6.5675234e-16 1.8170323e-18 1.0000000e+00
 2.2523751e-22 7.0648572e-20], sum to 1.0000
[2019-04-06 21:51:21,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5253
[2019-04-06 21:51:21,867] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.3, 82.0, 0.0, 0.0, 26.0, 24.21164084768331, 0.1228908345217441, 0.0, 1.0, 43992.08082285448], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2253600.0000, 
sim time next is 2255400.0000, 
raw observation next is [-7.55, 84.0, 0.0, 0.0, 26.0, 24.28507323416927, 0.1386628941599293, 0.0, 1.0, 44090.670488945965], 
processed observation next is [1.0, 0.08695652173913043, 0.25346260387811637, 0.84, 0.0, 0.0, 0.6666666666666666, 0.5237561028474392, 0.5462209647199764, 0.0, 1.0, 0.20995557375688556], 
reward next is 0.7900, 
noisyNet noise sample is [array([-0.4351212], dtype=float32), -0.21226437]. 
=============================================
[2019-04-06 21:51:24,405] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5751341e-18 3.6993771e-19 4.6927198e-16 8.9791241e-19 1.0000000e+00
 2.8379773e-21 5.8571289e-20], sum to 1.0000
[2019-04-06 21:51:24,405] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7944
[2019-04-06 21:51:24,452] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 39.5, 0.0, 0.0, 26.0, 25.37383569255054, 0.3503093689934569, 0.0, 1.0, 48582.2861031616], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4923000.0000, 
sim time next is 4924800.0000, 
raw observation next is [1.0, 40.0, 0.0, 0.0, 26.0, 25.39888744387899, 0.3469244358359853, 0.0, 1.0, 32827.12889988648], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.4, 0.0, 0.0, 0.6666666666666666, 0.6165739536565825, 0.6156414786119951, 0.0, 1.0, 0.15631966142803083], 
reward next is 0.8437, 
noisyNet noise sample is [array([-0.51931506], dtype=float32), 0.19941574]. 
=============================================
[2019-04-06 21:51:37,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:51:37,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:51:37,440] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run34
[2019-04-06 21:51:50,976] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.23079496e-20 1.07061715e-19 1.18077621e-15 3.55499544e-20
 1.00000000e+00 1.48205902e-23 3.64799898e-21], sum to 1.0000
[2019-04-06 21:51:50,976] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6552
[2019-04-06 21:51:51,293] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.5, 74.0, 0.0, 0.0, 26.0, 25.09840461800194, 0.3656925096229233, 1.0, 1.0, 12095.069641779], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4606200.0000, 
sim time next is 4608000.0000, 
raw observation next is [-2.0, 71.0, 61.5, 85.5, 26.0, 25.46650844054541, 0.4053325739750562, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.40720221606648205, 0.71, 0.205, 0.09447513812154697, 0.6666666666666666, 0.6222090367121176, 0.6351108579916854, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.42372215], dtype=float32), 0.1815189]. 
=============================================
[2019-04-06 21:51:51,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[85.03979]
 [84.10973]
 [84.25747]
 [84.39256]
 [84.54116]], R is [[85.65964508]
 [85.74545288]
 [85.71541595]
 [85.68586731]
 [85.65665436]].
[2019-04-06 21:51:53,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7044685e-21 2.8738725e-22 5.6916747e-18 5.8973047e-20 1.0000000e+00
 2.0790555e-24 4.3314426e-22], sum to 1.0000
[2019-04-06 21:51:53,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3214
[2019-04-06 21:51:53,680] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.5, 43.5, 117.0, 829.0, 26.0, 25.35626563511233, 0.4554552965563402, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3673800.0000, 
sim time next is 3675600.0000, 
raw observation next is [5.0, 42.0, 115.0, 823.5, 26.0, 25.29318774018592, 0.4523369335117673, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.6011080332409973, 0.42, 0.38333333333333336, 0.9099447513812154, 0.6666666666666666, 0.6077656450154935, 0.6507789778372558, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.1419392], dtype=float32), 0.65288407]. 
=============================================
[2019-04-06 21:52:03,723] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:52:03,723] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:52:03,727] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run34
[2019-04-06 21:52:19,746] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:52:19,746] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:52:19,750] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run34
[2019-04-06 21:52:24,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:52:24,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:52:24,112] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run34
[2019-04-06 21:52:24,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:52:24,958] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:52:24,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run34
[2019-04-06 21:52:27,639] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:52:27,639] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:52:27,643] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run34
[2019-04-06 21:52:41,946] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5952271e-19 3.9619525e-20 1.6560575e-16 9.6750291e-19 1.0000000e+00
 1.1104186e-21 3.1102111e-20], sum to 1.0000
[2019-04-06 21:52:41,946] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6195
[2019-04-06 21:52:42,090] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 55.0, 116.0, 819.5, 26.0, 25.17900860207203, 0.4453516635712148, 0.0, 1.0, 27629.32992288579], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3585600.0000, 
sim time next is 3587400.0000, 
raw observation next is [-2.5, 52.5, 118.0, 823.0, 26.0, 25.18014097528396, 0.4492849772261505, 0.0, 1.0, 18711.25033153579], 
processed observation next is [0.0, 0.5217391304347826, 0.39335180055401664, 0.525, 0.3933333333333333, 0.9093922651933701, 0.6666666666666666, 0.5983450812736631, 0.6497616590753835, 0.0, 1.0, 0.08910119205493233], 
reward next is 0.9109, 
noisyNet noise sample is [array([-0.08551975], dtype=float32), 0.33313018]. 
=============================================
[2019-04-06 21:52:52,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:52:52,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:52:52,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run34
[2019-04-06 21:52:59,194] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.5058482e-22 2.6079216e-22 8.1500286e-17 8.8542156e-21 1.0000000e+00
 3.6342304e-23 3.5365425e-22], sum to 1.0000
[2019-04-06 21:52:59,194] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6227
[2019-04-06 21:52:59,275] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.59010801985841, 0.5529688686188413, 0.0, 1.0, 36650.74111701015], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3790800.0000, 
sim time next is 3792600.0000, 
raw observation next is [-3.0, 74.0, 0.0, 0.0, 26.0, 25.60559869627094, 0.523869505287112, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.3795013850415513, 0.74, 0.0, 0.0, 0.6666666666666666, 0.6337998913559115, 0.6746231684290374, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2402188], dtype=float32), 0.61124986]. 
=============================================
[2019-04-06 21:53:08,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:53:08,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:53:08,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run34
[2019-04-06 21:53:11,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:53:11,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:53:11,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run34
[2019-04-06 21:53:24,825] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2858881e-21 2.1431238e-22 3.8378488e-18 8.2425907e-21 1.0000000e+00
 6.6659304e-25 9.1021195e-23], sum to 1.0000
[2019-04-06 21:53:24,825] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3419
[2019-04-06 21:53:25,054] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.9, 84.0, 50.0, 0.0, 26.0, 24.46403510472185, 0.178858205317101, 0.0, 1.0, 47597.94832786437], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 55800.0000, 
sim time next is 57600.0000, 
raw observation next is [6.6, 82.0, 34.0, 0.0, 26.0, 24.55359484121273, 0.1832119358981565, 0.0, 1.0, 20732.116454336676], 
processed observation next is [0.0, 0.6956521739130435, 0.6454293628808865, 0.82, 0.11333333333333333, 0.0, 0.6666666666666666, 0.546132903434394, 0.5610706452993856, 0.0, 1.0, 0.09872436406826988], 
reward next is 0.9013, 
noisyNet noise sample is [array([0.48569787], dtype=float32), -0.41044208]. 
=============================================
[2019-04-06 21:53:31,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.91675061e-20 4.67222023e-21 1.30243475e-17 3.72995448e-20
 1.00000000e+00 9.81784649e-24 9.32622957e-21], sum to 1.0000
[2019-04-06 21:53:31,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4989
[2019-04-06 21:53:31,128] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 50.0, 110.0, 611.0, 26.0, 25.58459613956564, 0.3591375272923165, 1.0, 1.0, 24820.805173622783], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 738000.0000, 
sim time next is 739800.0000, 
raw observation next is [0.5, 47.5, 89.0, 773.0, 26.0, 25.3588383679842, 0.3820715348137063, 1.0, 1.0, 18680.59799159462], 
processed observation next is [1.0, 0.5652173913043478, 0.4764542936288089, 0.475, 0.2966666666666667, 0.8541436464088398, 0.6666666666666666, 0.6132365306653501, 0.6273571782712354, 1.0, 1.0, 0.08895522853140295], 
reward next is 0.9110, 
noisyNet noise sample is [array([-0.7690036], dtype=float32), -1.432332]. 
=============================================
[2019-04-06 21:53:43,263] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3162702e-17 9.4194148e-19 4.3817302e-15 3.1033775e-17 1.0000000e+00
 1.5299880e-20 4.1718591e-19], sum to 1.0000
[2019-04-06 21:53:43,263] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7253
[2019-04-06 21:53:43,348] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-11.7, 70.0, 0.0, 0.0, 26.0, 22.77983705317815, -0.2238257875562239, 0.0, 1.0, 47823.28747755766], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 280800.0000, 
sim time next is 282600.0000, 
raw observation next is [-12.0, 68.5, 0.0, 0.0, 26.0, 22.59039486645723, -0.2621837682673009, 0.0, 1.0, 47832.44220731096], 
processed observation next is [1.0, 0.2608695652173913, 0.13019390581717452, 0.685, 0.0, 0.0, 0.6666666666666666, 0.3825329055381026, 0.41260541057756633, 0.0, 1.0, 0.22777353432052838], 
reward next is 0.7722, 
noisyNet noise sample is [array([-0.01357317], dtype=float32), 0.9583631]. 
=============================================
[2019-04-06 21:53:49,023] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.1156915e-23 1.4530109e-23 1.1555716e-17 3.7136399e-21 1.0000000e+00
 7.5716926e-25 8.0754784e-24], sum to 1.0000
[2019-04-06 21:53:49,023] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6676
[2019-04-06 21:53:49,097] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.8, 28.5, 118.0, 853.0, 26.0, 28.29542115453561, 0.9130612640253547, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4365000.0000, 
sim time next is 4366800.0000, 
raw observation next is [14.6, 29.0, 116.5, 847.5, 26.0, 27.12875569066939, 0.9203936054687345, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.8670360110803325, 0.29, 0.3883333333333333, 0.93646408839779, 0.6666666666666666, 0.7607296408891159, 0.8067978684895781, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3729435], dtype=float32), -0.34888348]. 
=============================================
[2019-04-06 21:53:53,203] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4258104e-22 1.4394826e-24 4.5418465e-20 2.3646675e-23 1.0000000e+00
 2.4745367e-27 1.3127298e-25], sum to 1.0000
[2019-04-06 21:53:53,203] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9780
[2019-04-06 21:53:53,272] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.8, 83.0, 0.0, 0.0, 26.0, 25.51857597341465, 0.4408796669644681, 0.0, 1.0, 12502.285045790739], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 970200.0000, 
sim time next is 972000.0000, 
raw observation next is [8.8, 83.0, 0.0, 0.0, 26.0, 25.57202879286641, 0.4794593456180489, 0.0, 1.0, 31747.757371532585], 
processed observation next is [1.0, 0.2608695652173913, 0.7063711911357342, 0.83, 0.0, 0.0, 0.6666666666666666, 0.631002399405534, 0.659819781872683, 0.0, 1.0, 0.15117979700729803], 
reward next is 0.8488, 
noisyNet noise sample is [array([1.5621753], dtype=float32), -0.21828273]. 
=============================================
[2019-04-06 21:53:53,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[95.4025 ]
 [95.35102]
 [95.14255]
 [94.74501]
 [94.79358]], R is [[95.47108459]
 [95.45684052]
 [95.35902405]
 [95.13450623]
 [95.12361145]].
[2019-04-06 21:53:56,132] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 21:53:56,133] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:53:56,138] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:53:56,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:53:56,145] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:53:56,172] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:53:56,190] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:53:57,745] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run76
[2019-04-06 21:53:57,870] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run76
[2019-04-06 21:53:59,258] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run76
[2019-04-06 21:56:07,267] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 21:56:45,728] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 21:56:53,953] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 21:56:54,992] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1500000, evaluation results [1500000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 21:56:57,779] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:56:57,779] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:56:57,783] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run34
[2019-04-06 21:57:11,851] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:57:11,851] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:57:11,855] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run34
[2019-04-06 21:57:19,678] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5277768e-21 8.8687131e-22 3.8373070e-18 6.3567130e-20 1.0000000e+00
 9.5388619e-24 2.1395215e-22], sum to 1.0000
[2019-04-06 21:57:19,678] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1140
[2019-04-06 21:57:19,716] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 72.0, 147.0, 0.0, 26.0, 25.99956781548882, 0.5363401705940166, 1.0, 1.0, 4151.202593384563], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4721400.0000, 
sim time next is 4723200.0000, 
raw observation next is [1.0, 72.0, 123.5, 5.5, 26.0, 26.16205739521197, 0.5469138966606706, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4903047091412743, 0.72, 0.4116666666666667, 0.0060773480662983425, 0.6666666666666666, 0.6801714496009975, 0.6823046322202235, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.78495187], dtype=float32), -0.29882142]. 
=============================================
[2019-04-06 21:57:29,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:57:29,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:57:29,060] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run34
[2019-04-06 21:57:39,693] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:57:39,693] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:57:39,696] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run34
[2019-04-06 21:57:48,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:57:48,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:57:48,072] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run34
[2019-04-06 21:57:52,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 21:57:52,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:57:52,746] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run34
[2019-04-06 21:57:57,631] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.2085986e-21 3.2072843e-22 1.5834781e-18 3.1419298e-21 1.0000000e+00
 2.1822587e-24 1.1794710e-22], sum to 1.0000
[2019-04-06 21:57:57,631] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7646
[2019-04-06 21:57:57,689] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 26.0, 25.52220789139897, 0.5395620774585641, 0.0, 1.0, 32211.392367597975], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1461600.0000, 
sim time next is 1463400.0000, 
raw observation next is [1.35, 92.0, 0.0, 0.0, 26.0, 25.3606636120719, 0.4814936254659727, 0.0, 1.0, 68952.47506819088], 
processed observation next is [1.0, 0.9565217391304348, 0.5000000000000001, 0.92, 0.0, 0.0, 0.6666666666666666, 0.613388634339325, 0.6604978751553242, 0.0, 1.0, 0.3283451193723375], 
reward next is 0.6717, 
noisyNet noise sample is [array([-0.8178941], dtype=float32), -1.7467399]. 
=============================================
[2019-04-06 21:58:32,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9926312e-23 4.7974630e-25 1.5301339e-20 1.2234424e-21 1.0000000e+00
 5.5525955e-27 9.9421336e-26], sum to 1.0000
[2019-04-06 21:58:32,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9507
[2019-04-06 21:58:32,745] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.5, 100.0, 83.0, 392.0, 26.0, 25.76875457794866, 0.447342341101288, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3141000.0000, 
sim time next is 3142800.0000, 
raw observation next is [7.0, 100.0, 91.0, 519.5, 26.0, 26.21132954367206, 0.5173293611652391, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6565096952908588, 1.0, 0.30333333333333334, 0.5740331491712707, 0.6666666666666666, 0.6842774619726718, 0.672443120388413, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6142194], dtype=float32), -0.073168285]. 
=============================================
[2019-04-06 21:59:02,444] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2533368e-18 1.7023911e-19 2.8225037e-15 3.0859177e-17 1.0000000e+00
 7.0922886e-21 9.3335661e-20], sum to 1.0000
[2019-04-06 21:59:02,444] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0443
[2019-04-06 21:59:02,738] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.35, 55.0, 0.0, 0.0, 26.0, 25.62677596045384, 0.3080617909575663, 1.0, 1.0, 24940.62370229377], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 754200.0000, 
sim time next is 756000.0000, 
raw observation next is [-3.9, 56.0, 0.0, 0.0, 26.0, 25.03471463253553, 0.3756756860166901, 1.0, 1.0, 139170.1999739335], 
processed observation next is [1.0, 0.782608695652174, 0.3545706371191136, 0.56, 0.0, 0.0, 0.6666666666666666, 0.5862262193779607, 0.6252252286722301, 1.0, 1.0, 0.6627152379711119], 
reward next is 0.3373, 
noisyNet noise sample is [array([0.33168852], dtype=float32), -0.718634]. 
=============================================
[2019-04-06 21:59:02,782] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[79.4966  ]
 [79.853745]
 [80.19573 ]
 [80.110664]
 [80.70366 ]], R is [[80.04281616]
 [80.12361908]
 [80.32238007]
 [80.15742493]
 [80.23275757]].
[2019-04-06 21:59:31,471] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.7079296e-23 2.7457290e-25 1.5911239e-20 7.6864745e-24 1.0000000e+00
 4.8753101e-28 2.5414387e-25], sum to 1.0000
[2019-04-06 21:59:31,500] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1010
[2019-04-06 21:59:31,550] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 100.0, 0.0, 0.0, 26.0, 25.82283001045916, 0.6704899530828392, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3182400.0000, 
sim time next is 3184200.0000, 
raw observation next is [3.0, 100.0, 0.0, 0.0, 26.0, 25.60025455050485, 0.6661704796389124, 0.0, 1.0, 130887.2081225203], 
processed observation next is [1.0, 0.8695652173913043, 0.5457063711911359, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6333545458754042, 0.7220568265463041, 0.0, 1.0, 0.6232724196310491], 
reward next is 0.3767, 
noisyNet noise sample is [array([0.09252986], dtype=float32), 1.348131]. 
=============================================
[2019-04-06 21:59:42,089] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-06 21:59:42,090] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:59:42,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:59:42,095] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run77
[2019-04-06 21:59:42,120] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 21:59:42,128] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 21:59:42,129] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:59:42,129] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 21:59:42,135] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run77
[2019-04-06 21:59:42,163] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run77
[2019-04-06 22:01:54,780] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 22:02:33,584] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 22:02:36,736] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 22:02:37,803] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 1520000, evaluation results [1520000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 22:03:19,132] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:03:19,132] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:03:19,144] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run35
[2019-04-06 22:03:21,130] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9789240e-19 1.4054120e-18 1.8009540e-14 6.5376246e-17 1.0000000e+00
 3.0018498e-21 1.2358417e-18], sum to 1.0000
[2019-04-06 22:03:21,130] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3187
[2019-04-06 22:03:21,195] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.4, 78.0, 0.0, 0.0, 26.0, 23.80415012215935, -0.0602463476466733, 0.0, 1.0, 44944.06156932225], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1915200.0000, 
sim time next is 1917000.0000, 
raw observation next is [-8.65, 80.0, 0.0, 0.0, 26.0, 23.66565553923283, -0.07956634994791896, 0.0, 1.0, 45227.44848505772], 
processed observation next is [1.0, 0.17391304347826086, 0.22299168975069253, 0.8, 0.0, 0.0, 0.6666666666666666, 0.47213796160273586, 0.4734778833506937, 0.0, 1.0, 0.21536880230979868], 
reward next is 0.7846, 
noisyNet noise sample is [array([0.07066126], dtype=float32), 1.0225652]. 
=============================================
[2019-04-06 22:03:21,200] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[79.0767  ]
 [79.409645]
 [79.77253 ]
 [80.13924 ]
 [79.79785 ]], R is [[78.84143829]
 [78.83900452]
 [78.83757019]
 [78.83588409]
 [78.83385468]].
[2019-04-06 22:03:22,087] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.7224495e-18 4.5370716e-18 1.2306975e-14 1.0686439e-16 1.0000000e+00
 2.1931623e-20 5.5625823e-19], sum to 1.0000
[2019-04-06 22:03:22,088] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9591
[2019-04-06 22:03:22,159] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-12.0, 63.0, 0.0, 0.0, 26.0, 24.27867674540769, 0.1449179594060491, 0.0, 1.0, 43606.79205328124], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3987000.0000, 
sim time next is 3988800.0000, 
raw observation next is [-12.0, 63.0, 0.0, 0.0, 26.0, 24.16740527702597, 0.1114285040657355, 0.0, 1.0, 43624.07203948987], 
processed observation next is [1.0, 0.17391304347826086, 0.13019390581717452, 0.63, 0.0, 0.0, 0.6666666666666666, 0.5139504397521643, 0.5371428346885785, 0.0, 1.0, 0.20773367637852316], 
reward next is 0.7923, 
noisyNet noise sample is [array([1.2586224], dtype=float32), -0.93134797]. 
=============================================
[2019-04-06 22:03:33,325] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8853027e-19 1.1822116e-19 1.3051908e-16 5.0068136e-19 1.0000000e+00
 1.9108723e-23 1.2147838e-20], sum to 1.0000
[2019-04-06 22:03:33,325] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4705
[2019-04-06 22:03:33,538] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 26.0, 25.05310048318311, 0.3887794018504194, 1.0, 1.0, 84693.8973116807], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2232000.0000, 
sim time next is 2233800.0000, 
raw observation next is [-5.0, 69.5, 0.0, 0.0, 26.0, 25.13868880096807, 0.4023537964244205, 0.0, 1.0, 77847.57681208254], 
processed observation next is [1.0, 0.8695652173913043, 0.32409972299168976, 0.695, 0.0, 0.0, 0.6666666666666666, 0.5948907334140058, 0.6341179321414735, 0.0, 1.0, 0.37070274672420256], 
reward next is 0.6293, 
noisyNet noise sample is [array([2.624645], dtype=float32), 1.3283534]. 
=============================================
[2019-04-06 22:03:45,729] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.2198842e-19 1.3149991e-19 7.5629804e-16 1.5585904e-17 1.0000000e+00
 1.5624029e-21 9.4941561e-20], sum to 1.0000
[2019-04-06 22:03:45,729] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6398
[2019-04-06 22:03:45,911] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.5, 54.5, 114.0, 816.0, 26.0, 25.1856661995042, 0.4333139537085726, 0.0, 1.0, 17636.317371740475], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3583800.0000, 
sim time next is 3585600.0000, 
raw observation next is [-3.0, 55.0, 116.0, 819.5, 26.0, 25.17900860207203, 0.4453516635712148, 0.0, 1.0, 27629.32992288579], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.55, 0.38666666666666666, 0.905524861878453, 0.6666666666666666, 0.598250716839336, 0.6484505545237383, 0.0, 1.0, 0.1315682377280276], 
reward next is 0.8684, 
noisyNet noise sample is [array([1.0914415], dtype=float32), -1.2707317]. 
=============================================
[2019-04-06 22:03:46,311] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.08838223e-18 1.83787415e-20 2.50669183e-16 9.48764375e-19
 1.00000000e+00 1.00751276e-22 9.24836328e-20], sum to 1.0000
[2019-04-06 22:03:46,311] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3109
[2019-04-06 22:03:46,336] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.5, 46.0, 114.0, 812.0, 26.0, 25.23749571865481, 0.4513452748220907, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3591000.0000, 
sim time next is 3592800.0000, 
raw observation next is [-1.0, 42.0, 108.0, 800.0, 26.0, 25.19535697653536, 0.4508386609174075, 0.0, 1.0, 12463.334805436016], 
processed observation next is [0.0, 0.6086956521739131, 0.4349030470914128, 0.42, 0.36, 0.8839779005524862, 0.6666666666666666, 0.5996130813779468, 0.6502795536391358, 0.0, 1.0, 0.059349213359219125], 
reward next is 0.9407, 
noisyNet noise sample is [array([-0.9473369], dtype=float32), 0.56431854]. 
=============================================
[2019-04-06 22:03:46,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:03:46,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:03:46,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run35
[2019-04-06 22:03:51,344] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5058951e-19 3.5756000e-20 8.0231621e-15 1.0875396e-18 1.0000000e+00
 3.9071958e-22 2.7490585e-20], sum to 1.0000
[2019-04-06 22:03:51,344] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4306
[2019-04-06 22:03:51,415] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.40294709580129, 0.329523480745093, 0.0, 1.0, 38631.28114132987], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3731400.0000, 
sim time next is 3733200.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 26.0, 25.24829227968733, 0.3021250354346093, 0.0, 1.0, 46187.41669063864], 
processed observation next is [1.0, 0.21739130434782608, 0.3795013850415513, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6040243566406108, 0.6007083451448697, 0.0, 1.0, 0.2199400794792316], 
reward next is 0.7801, 
noisyNet noise sample is [array([0.8023801], dtype=float32), -0.06428881]. 
=============================================
[2019-04-06 22:03:59,965] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:03:59,965] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:03:59,970] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run35
[2019-04-06 22:04:10,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:04:10,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:04:10,351] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run35
[2019-04-06 22:04:17,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:04:17,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:04:17,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run35
[2019-04-06 22:04:19,495] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:04:19,495] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:04:19,498] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run35
[2019-04-06 22:04:20,540] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:04:20,540] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:04:20,552] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run35
[2019-04-06 22:04:24,406] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.04220869e-18 3.78675659e-20 1.12907523e-15 8.83142607e-18
 1.00000000e+00 3.04831782e-22 1.04958064e-20], sum to 1.0000
[2019-04-06 22:04:24,406] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4691
[2019-04-06 22:04:24,680] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 65.0, 181.0, 691.0, 26.0, 25.04826770340346, 0.3924107394211341, 0.0, 1.0, 22702.51673451406], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2982600.0000, 
sim time next is 2984400.0000, 
raw observation next is [-3.0, 65.0, 145.5, 745.5, 26.0, 25.06993791349919, 0.4027717088197163, 0.0, 1.0, 27570.863608804848], 
processed observation next is [0.0, 0.5652173913043478, 0.3795013850415513, 0.65, 0.485, 0.8237569060773481, 0.6666666666666666, 0.589161492791599, 0.6342572362732387, 0.0, 1.0, 0.13128982670859451], 
reward next is 0.8687, 
noisyNet noise sample is [array([-1.0900625], dtype=float32), -1.3079818]. 
=============================================
[2019-04-06 22:04:31,888] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.4230143e-19 1.3753531e-22 2.1867413e-17 1.0512676e-20 1.0000000e+00
 3.2267444e-24 4.6871035e-23], sum to 1.0000
[2019-04-06 22:04:31,888] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0322
[2019-04-06 22:04:32,150] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.05, 84.0, 18.0, 0.0, 26.0, 24.50363717623456, 0.1856374173861405, 0.0, 1.0, 46130.1477462242], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 59400.0000, 
sim time next is 61200.0000, 
raw observation next is [5.5, 86.0, 0.0, 0.0, 26.0, 24.54607850553036, 0.1943979489362506, 0.0, 1.0, 37164.82095182839], 
processed observation next is [0.0, 0.7391304347826086, 0.6149584487534627, 0.86, 0.0, 0.0, 0.6666666666666666, 0.54550654212753, 0.5647993163120836, 0.0, 1.0, 0.17697533786584949], 
reward next is 0.8230, 
noisyNet noise sample is [array([0.7048163], dtype=float32), 0.05644882]. 
=============================================
[2019-04-06 22:04:43,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:04:43,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:04:43,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run35
[2019-04-06 22:04:51,037] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0154620e-22 2.9655616e-23 7.0205858e-19 1.7516850e-21 1.0000000e+00
 6.1859878e-26 8.4502169e-25], sum to 1.0000
[2019-04-06 22:04:51,037] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3399
[2019-04-06 22:04:51,205] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 92.0, 85.0, 370.0, 26.0, 25.59845852718842, 0.5618858267362109, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3227400.0000, 
sim time next is 3229200.0000, 
raw observation next is [-3.0, 92.0, 93.0, 511.5, 26.0, 26.00457841728247, 0.606461344494508, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.92, 0.31, 0.5651933701657459, 0.6666666666666666, 0.6670482014402058, 0.7021537814981693, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.81762105], dtype=float32), 1.7224464]. 
=============================================
[2019-04-06 22:04:58,136] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.84208738e-18 1.92087417e-19 1.06582665e-16 2.07013508e-18
 1.00000000e+00 1.87405038e-21 2.98925851e-20], sum to 1.0000
[2019-04-06 22:04:58,136] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9583
[2019-04-06 22:04:58,329] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-12.8, 77.0, 0.0, 0.0, 26.0, 24.7393265518753, 0.2088246932181395, 0.0, 1.0, 43148.91555325989], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 334800.0000, 
sim time next is 336600.0000, 
raw observation next is [-13.1, 79.5, 0.0, 0.0, 26.0, 24.43393832151019, 0.1529637002113876, 0.0, 1.0, 47452.58763620732], 
processed observation next is [1.0, 0.9130434782608695, 0.0997229916897507, 0.795, 0.0, 0.0, 0.6666666666666666, 0.5361615267925158, 0.5509879000704626, 0.0, 1.0, 0.22596470302955865], 
reward next is 0.7740, 
noisyNet noise sample is [array([2.6398606], dtype=float32), 0.4722647]. 
=============================================
[2019-04-06 22:05:01,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:05:01,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:05:01,708] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run35
[2019-04-06 22:05:04,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:05:04,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:05:04,904] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run35
[2019-04-06 22:05:15,556] A3C_AGENT_WORKER-Thread-7 INFO:Evaluating...
[2019-04-06 22:05:15,557] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:05:15,557] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:05:15,560] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:05:15,560] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:05:15,563] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:05:15,564] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:05:15,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run78
[2019-04-06 22:05:15,595] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run78
[2019-04-06 22:05:15,629] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run78
[2019-04-06 22:07:31,086] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 22:08:10,613] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 22:08:13,553] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 22:08:14,592] A3C_AGENT_WORKER-Thread-7 INFO:Global step: 1540000, evaluation results [1540000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 22:08:34,769] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7507515e-19 9.6071277e-21 6.8947112e-17 4.1249723e-18 1.0000000e+00
 2.5803913e-22 9.6487775e-21], sum to 1.0000
[2019-04-06 22:08:34,769] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4772
[2019-04-06 22:08:35,093] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 68.5, 153.0, 0.0, 26.0, 25.27863313999471, 0.2277533283689925, 1.0, 1.0, 25998.280182644234], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 214200.0000, 
sim time next is 216000.0000, 
raw observation next is [-5.0, 65.0, 141.0, 0.0, 26.0, 25.23475751536186, 0.214872800982777, 1.0, 1.0, 24787.194350621012], 
processed observation next is [1.0, 0.5217391304347826, 0.32409972299168976, 0.65, 0.47, 0.0, 0.6666666666666666, 0.6028964596134884, 0.571624266994259, 1.0, 1.0, 0.118034258812481], 
reward next is 0.8820, 
noisyNet noise sample is [array([1.0713953], dtype=float32), -1.2668841]. 
=============================================
[2019-04-06 22:08:35,097] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[81.01149 ]
 [80.90032 ]
 [80.969536]
 [80.68078 ]
 [80.62934 ]], R is [[81.15945435]
 [81.22406006]
 [81.27939606]
 [81.35314941]
 [81.48014069]].
[2019-04-06 22:08:52,137] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2459842e-21 1.0920695e-21 9.7790400e-18 9.7537664e-21 1.0000000e+00
 2.7931735e-25 1.7194686e-22], sum to 1.0000
[2019-04-06 22:08:52,137] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4993
[2019-04-06 22:08:52,238] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.55, 79.5, 0.0, 0.0, 26.0, 24.69918337656546, 0.2250426987313801, 0.0, 1.0, 40789.223551813375], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 862200.0000, 
sim time next is 864000.0000, 
raw observation next is [-2.3, 80.0, 0.0, 0.0, 26.0, 24.67340863996842, 0.2192549618139537, 0.0, 1.0, 40356.33255166668], 
processed observation next is [1.0, 0.0, 0.3988919667590028, 0.8, 0.0, 0.0, 0.6666666666666666, 0.5561173866640351, 0.5730849872713178, 0.0, 1.0, 0.19217301215079372], 
reward next is 0.8078, 
noisyNet noise sample is [array([-0.0092064], dtype=float32), -3.1610348]. 
=============================================
[2019-04-06 22:08:52,248] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[84.41939 ]
 [84.658966]
 [84.58681 ]
 [84.55788 ]
 [84.69048 ]], R is [[84.4793396 ]
 [84.44030762]
 [84.39988708]
 [84.35835266]
 [84.31620026]].
[2019-04-06 22:09:10,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:09:10,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:09:10,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run35
[2019-04-06 22:09:19,335] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:09:19,336] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:09:19,339] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run35
[2019-04-06 22:09:20,326] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8104176e-21 1.3935681e-22 6.5440621e-17 3.9343308e-20 1.0000000e+00
 4.1959003e-24 8.8276691e-22], sum to 1.0000
[2019-04-06 22:09:20,326] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3853
[2019-04-06 22:09:20,390] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.75, 70.0, 0.0, 0.0, 26.0, 25.26984539532487, 0.4009126129168717, 0.0, 1.0, 52915.0737569597], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4595400.0000, 
sim time next is 4597200.0000, 
raw observation next is [-2.0, 71.0, 0.0, 0.0, 26.0, 25.29347953071126, 0.3983760902939262, 0.0, 1.0, 36883.3848137609], 
processed observation next is [1.0, 0.21739130434782608, 0.40720221606648205, 0.71, 0.0, 0.0, 0.6666666666666666, 0.607789960892605, 0.6327920300979754, 0.0, 1.0, 0.1756351657798138], 
reward next is 0.8244, 
noisyNet noise sample is [array([0.3979755], dtype=float32), 0.7540924]. 
=============================================
[2019-04-06 22:09:25,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:09:25,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:09:25,615] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run35
[2019-04-06 22:09:36,769] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:09:36,769] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:09:36,772] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run35
[2019-04-06 22:09:42,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:09:42,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:09:42,100] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run35
[2019-04-06 22:09:45,476] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:09:45,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:09:45,480] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run35
[2019-04-06 22:09:57,473] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4556009e-18 7.9412368e-19 8.2255598e-15 4.8751703e-17 1.0000000e+00
 2.3115153e-20 2.0084961e-18], sum to 1.0000
[2019-04-06 22:09:57,474] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1917
[2019-04-06 22:09:57,750] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.5, 40.0, 0.0, 0.0, 26.0, 25.52946289734129, 0.3412655952082284, 1.0, 1.0, 40504.40978481236], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 412200.0000, 
sim time next is 414000.0000, 
raw observation next is [-9.5, 40.0, 0.0, 0.0, 26.0, 25.24601991071001, 0.2857158019702646, 1.0, 1.0, 46892.69931542745], 
processed observation next is [1.0, 0.8260869565217391, 0.1994459833795014, 0.4, 0.0, 0.0, 0.6666666666666666, 0.6038349925591676, 0.5952386006567548, 1.0, 1.0, 0.22329856816870217], 
reward next is 0.7767, 
noisyNet noise sample is [array([0.37783483], dtype=float32), -1.0590719]. 
=============================================
[2019-04-06 22:09:57,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.7082 ]
 [73.96055]
 [73.34686]
 [73.70817]
 [74.7428 ]], R is [[73.90627289]
 [73.97433472]
 [73.77263641]
 [73.74149323]
 [74.00408173]].
[2019-04-06 22:10:21,726] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1623690e-18 1.0411194e-19 5.5750396e-16 2.5678656e-19 1.0000000e+00
 9.3400696e-23 8.0601251e-23], sum to 1.0000
[2019-04-06 22:10:21,727] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0205
[2019-04-06 22:10:22,004] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.5, 64.0, 0.0, 0.0, 26.0, 23.67797969447924, 0.1016650002786317, 1.0, 1.0, 156104.1042324577], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2791800.0000, 
sim time next is 2793600.0000, 
raw observation next is [-6.0, 64.0, 54.0, 103.5, 26.0, 25.38652186577157, 0.333425112521118, 1.0, 1.0, 64123.46961804423], 
processed observation next is [1.0, 0.34782608695652173, 0.296398891966759, 0.64, 0.18, 0.1143646408839779, 0.6666666666666666, 0.6155434888142975, 0.6111417041737061, 1.0, 1.0, 0.30534985532402015], 
reward next is 0.6947, 
noisyNet noise sample is [array([0.06192833], dtype=float32), -1.3721313]. 
=============================================
[2019-04-06 22:10:34,262] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6052329e-18 2.4561422e-19 8.1571242e-16 1.5602918e-17 1.0000000e+00
 2.2433898e-21 9.8222121e-20], sum to 1.0000
[2019-04-06 22:10:34,262] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7467
[2019-04-06 22:10:34,541] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 35.0, 106.5, 0.0, 26.0, 25.57521958806325, 0.2512857350619888, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 482400.0000, 
sim time next is 484200.0000, 
raw observation next is [-0.3, 36.0, 94.0, 0.0, 26.0, 24.44084101091754, 0.1805863810066851, 1.0, 1.0, 66131.95880630547], 
processed observation next is [1.0, 0.6086956521739131, 0.4542936288088643, 0.36, 0.31333333333333335, 0.0, 0.6666666666666666, 0.5367367509097951, 0.5601954603355617, 1.0, 1.0, 0.31491408955383554], 
reward next is 0.6851, 
noisyNet noise sample is [array([-0.02796369], dtype=float32), -0.83797145]. 
=============================================
[2019-04-06 22:10:55,657] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.6752314e-22 4.5260291e-24 1.8502346e-19 8.4680381e-23 1.0000000e+00
 3.7495160e-26 1.0289559e-24], sum to 1.0000
[2019-04-06 22:10:55,657] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1328
[2019-04-06 22:10:55,714] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.7, 82.0, 0.0, 0.0, 26.0, 25.67809700659674, 0.6162864369939469, 0.0, 1.0, 18725.02271692125], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1150200.0000, 
sim time next is 1152000.0000, 
raw observation next is [12.7, 84.0, 16.0, 0.5, 26.0, 25.69418734082189, 0.6066802547302632, 0.0, 1.0, 7411.09635989292], 
processed observation next is [0.0, 0.34782608695652173, 0.8144044321329641, 0.84, 0.05333333333333334, 0.0005524861878453039, 0.6666666666666666, 0.6411822784018243, 0.7022267515767545, 0.0, 1.0, 0.035290935047109145], 
reward next is 0.9647, 
noisyNet noise sample is [array([-0.10558376], dtype=float32), -1.3478657]. 
=============================================
[2019-04-06 22:10:55,736] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[94.22833]
 [94.03006]
 [93.83565]
 [93.51574]
 [93.24281]], R is [[94.41891479]
 [94.38555908]
 [94.3525238 ]
 [94.25788879]
 [94.17546082]].
[2019-04-06 22:11:00,274] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 22:11:00,277] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:11:00,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:11:00,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run79
[2019-04-06 22:11:00,300] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:11:00,302] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:11:00,307] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run79
[2019-04-06 22:11:00,328] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:11:00,328] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:11:00,332] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run79
[2019-04-06 22:12:56,241] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14752516]
[2019-04-06 22:12:56,241] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.5, 73.0, 0.0, 0.0, 26.0, 25.18645104434718, 0.429158725647888, 1.0, 1.0, 70282.68687748787]
[2019-04-06 22:12:56,241] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:12:56,243] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.1163164e-20 5.6120456e-21 4.2574579e-17 7.5544299e-20 1.0000000e+00
 2.5203558e-23 2.1078636e-21], sampled 0.04586612589832639
[2019-04-06 22:13:12,558] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 22:13:50,102] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 22:13:51,928] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 22:13:52,967] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1560000, evaluation results [1560000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 22:14:43,200] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.8286644e-19 1.7428411e-20 1.7061515e-16 1.5471155e-18 1.0000000e+00
 1.0044854e-21 2.3266164e-20], sum to 1.0000
[2019-04-06 22:14:43,200] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9554
[2019-04-06 22:14:43,254] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.5, 32.0, 118.0, 847.0, 26.0, 25.07988563165179, 0.3974703030652481, 0.0, 1.0, 12464.08976529947], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4192200.0000, 
sim time next is 4194000.0000, 
raw observation next is [2.0, 34.0, 166.0, 758.0, 26.0, 25.07535956124124, 0.4039798873248402, 0.0, 1.0, 6231.808117310936], 
processed observation next is [0.0, 0.5652173913043478, 0.518005540166205, 0.34, 0.5533333333333333, 0.8375690607734807, 0.6666666666666666, 0.5896132967701032, 0.6346599624416134, 0.0, 1.0, 0.029675276749099696], 
reward next is 0.9703, 
noisyNet noise sample is [array([0.04750958], dtype=float32), -0.4673776]. 
=============================================
[2019-04-06 22:14:43,283] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.437935]
 [76.22059 ]
 [76.09377 ]
 [76.20045 ]
 [76.38478 ]], R is [[76.94288635]
 [77.11411285]
 [77.28057861]
 [77.50777435]
 [77.73269653]].
[2019-04-06 22:14:46,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5610013e-23 3.6503200e-23 1.8592911e-19 1.3029242e-21 1.0000000e+00
 7.5830191e-26 6.4521008e-24], sum to 1.0000
[2019-04-06 22:14:46,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1845
[2019-04-06 22:14:46,755] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.0, 82.0, 0.0, 0.0, 26.0, 25.65219234518205, 0.5179599251471975, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1576800.0000, 
sim time next is 1578600.0000, 
raw observation next is [5.25, 80.5, 0.0, 0.0, 26.0, 25.5455179695393, 0.4849173145290138, 0.0, 1.0, 31034.814589633228], 
processed observation next is [1.0, 0.2608695652173913, 0.60803324099723, 0.805, 0.0, 0.0, 0.6666666666666666, 0.628793164128275, 0.6616391048430046, 0.0, 1.0, 0.14778483137920584], 
reward next is 0.8522, 
noisyNet noise sample is [array([0.82521296], dtype=float32), -0.1773427]. 
=============================================
[2019-04-06 22:15:03,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:15:03,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:15:03,204] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run36
[2019-04-06 22:15:10,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5682623e-19 1.6176670e-20 6.4984388e-17 2.2313153e-19 1.0000000e+00
 3.7117259e-22 3.4500388e-20], sum to 1.0000
[2019-04-06 22:15:10,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5176
[2019-04-06 22:15:10,447] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.3, 46.0, 79.0, 58.0, 26.0, 24.95384119541561, 0.2846457008857081, 0.0, 1.0, 44564.71700905254], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2392200.0000, 
sim time next is 2394000.0000, 
raw observation next is [-0.6, 45.0, 42.5, 37.0, 26.0, 24.95704285095009, 0.2818598999725644, 0.0, 1.0, 40042.68435897937], 
processed observation next is [0.0, 0.7391304347826086, 0.44598337950138506, 0.45, 0.14166666666666666, 0.04088397790055249, 0.6666666666666666, 0.5797535709125073, 0.5939532999908548, 0.0, 1.0, 0.1906794493284732], 
reward next is 0.8093, 
noisyNet noise sample is [array([-1.3040363], dtype=float32), -0.70278454]. 
=============================================
[2019-04-06 22:15:10,478] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[76.87817 ]
 [76.906044]
 [77.04057 ]
 [76.89407 ]
 [76.76251 ]], R is [[76.53377533]
 [76.55622864]
 [76.70054626]
 [76.82668304]
 [76.86760712]].
[2019-04-06 22:15:17,761] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4695637e-20 4.7194568e-21 6.4090728e-17 3.2224594e-19 1.0000000e+00
 2.3098032e-22 8.6893215e-21], sum to 1.0000
[2019-04-06 22:15:17,762] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0303
[2019-04-06 22:15:17,937] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.3, 75.0, 250.5, 80.5, 26.0, 25.7508194323526, 0.3830587544811767, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2113200.0000, 
sim time next is 2115000.0000, 
raw observation next is [-7.0, 69.5, 293.0, 101.0, 26.0, 25.79712931635326, 0.4347517821307368, 1.0, 1.0, 45578.7333421566], 
processed observation next is [1.0, 0.4782608695652174, 0.2686980609418283, 0.695, 0.9766666666666667, 0.11160220994475138, 0.6666666666666666, 0.6497607763627716, 0.6449172607102456, 1.0, 1.0, 0.21704158734360285], 
reward next is 0.7830, 
noisyNet noise sample is [array([0.6436149], dtype=float32), 0.25856212]. 
=============================================
[2019-04-06 22:15:17,941] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[81.67684 ]
 [81.904915]
 [82.30131 ]
 [82.6207  ]
 [82.496666]], R is [[81.88669586]
 [82.06783295]
 [82.24715424]
 [82.42468262]
 [82.47525787]].
[2019-04-06 22:15:22,244] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8097385e-21 2.7354773e-22 2.4866047e-17 1.6406237e-20 1.0000000e+00
 7.0704506e-24 3.6295770e-22], sum to 1.0000
[2019-04-06 22:15:22,244] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3172
[2019-04-06 22:15:22,279] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 79.0, 0.0, 0.0, 26.0, 25.43082664348466, 0.5524235683512718, 0.0, 1.0, 61111.83354477424], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3445200.0000, 
sim time next is 3447000.0000, 
raw observation next is [1.0, 82.5, 0.0, 0.0, 26.0, 25.66434923378835, 0.5553153067592183, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4903047091412743, 0.825, 0.0, 0.0, 0.6666666666666666, 0.6386957694823625, 0.6851051022530728, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.11576237], dtype=float32), -1.564965]. 
=============================================
[2019-04-06 22:15:22,283] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[87.62603 ]
 [87.05423 ]
 [86.071815]
 [86.70922 ]
 [86.21369 ]], R is [[87.54420471]
 [87.37775421]
 [86.86753082]
 [86.70959473]
 [86.64276886]].
[2019-04-06 22:15:22,585] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.3769810e-19 1.9242027e-20 8.7625366e-17 4.6504068e-19 1.0000000e+00
 4.3627367e-21 5.2755697e-21], sum to 1.0000
[2019-04-06 22:15:22,585] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9593
[2019-04-06 22:15:22,660] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 50.0, 0.0, 0.0, 26.0, 25.16237696095896, 0.3551643565013362, 0.0, 1.0, 39458.69691257453], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4159800.0000, 
sim time next is 4161600.0000, 
raw observation next is [-3.0, 50.0, 0.0, 0.0, 26.0, 25.11978846835505, 0.3392985356368385, 0.0, 1.0, 39476.60230002558], 
processed observation next is [0.0, 0.17391304347826086, 0.3795013850415513, 0.5, 0.0, 0.0, 0.6666666666666666, 0.5933157056962542, 0.6130995118789462, 0.0, 1.0, 0.1879838204763123], 
reward next is 0.8120, 
noisyNet noise sample is [array([-2.8493586], dtype=float32), 0.67535436]. 
=============================================
[2019-04-06 22:15:27,557] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:15:27,557] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:15:27,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run36
[2019-04-06 22:15:33,319] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7035357e-20 1.1407404e-19 1.3798235e-17 1.9462916e-19 1.0000000e+00
 1.2116546e-21 1.6727260e-21], sum to 1.0000
[2019-04-06 22:15:33,319] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8805
[2019-04-06 22:15:33,489] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.8, 54.0, 0.0, 0.0, 26.0, 24.82383889018919, 0.1303934697027216, 0.0, 1.0, 38883.85977409451], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2530800.0000, 
sim time next is 2532600.0000, 
raw observation next is [-2.8, 54.0, 0.0, 0.0, 26.0, 25.01537347013411, 0.2110483343203605, 1.0, 1.0, 42417.63777931501], 
processed observation next is [1.0, 0.30434782608695654, 0.38504155124653744, 0.54, 0.0, 0.0, 0.6666666666666666, 0.5846144558445093, 0.5703494447734535, 1.0, 1.0, 0.20198875133007146], 
reward next is 0.7980, 
noisyNet noise sample is [array([-0.24767648], dtype=float32), 0.14375752]. 
=============================================
[2019-04-06 22:15:35,347] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.9924741e-23 2.6658154e-24 2.2170876e-18 1.4336704e-21 1.0000000e+00
 1.3172099e-24 4.4960674e-25], sum to 1.0000
[2019-04-06 22:15:35,347] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0289
[2019-04-06 22:15:35,593] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.4495171252908, 0.4213323409173741, 0.0, 1.0, 38840.978438432554], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4690800.0000, 
sim time next is 4692600.0000, 
raw observation next is [-0.5, 96.0, 0.0, 0.0, 26.0, 25.69140690383123, 0.474734693171422, 1.0, 1.0, 17886.023143186703], 
processed observation next is [1.0, 0.30434782608695654, 0.44875346260387816, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6409505753192691, 0.6582448977238073, 1.0, 1.0, 0.08517153877707954], 
reward next is 0.9148, 
noisyNet noise sample is [array([-0.10727356], dtype=float32), -0.17834066]. 
=============================================
[2019-04-06 22:15:43,170] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6784344e-22 1.0924392e-23 1.8977568e-19 2.0933688e-20 1.0000000e+00
 4.4162236e-26 7.6565080e-24], sum to 1.0000
[2019-04-06 22:15:43,170] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2883
[2019-04-06 22:15:43,237] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.0, 19.0, 96.0, 745.0, 26.0, 28.27605896393112, 1.077955687150343, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5067000.0000, 
sim time next is 5068800.0000, 
raw observation next is [12.0, 19.0, 86.0, 665.0, 26.0, 28.56674971759686, 1.135081636064829, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.7950138504155125, 0.19, 0.2866666666666667, 0.7348066298342542, 0.6666666666666666, 0.880562476466405, 0.8783605453549429, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9632019], dtype=float32), 0.1281685]. 
=============================================
[2019-04-06 22:15:45,146] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:15:45,146] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:15:45,160] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run36
[2019-04-06 22:15:45,903] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.4615160e-23 2.8060360e-22 1.2124939e-17 6.1672248e-21 1.0000000e+00
 5.2517423e-26 1.4799412e-22], sum to 1.0000
[2019-04-06 22:15:45,903] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0094
[2019-04-06 22:15:45,922] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.0, 49.0, 0.0, 0.0, 26.0, 26.26737358561961, 0.6964355351218657, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4644000.0000, 
sim time next is 4645800.0000, 
raw observation next is [3.5, 51.0, 0.0, 0.0, 26.0, 26.40358697547667, 0.7035963686802913, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.5595567867036012, 0.51, 0.0, 0.0, 0.6666666666666666, 0.7002989146230559, 0.7345321228934304, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.34970713], dtype=float32), 2.5381494]. 
=============================================
[2019-04-06 22:15:54,071] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.5294005e-22 4.6202714e-21 2.6537407e-17 1.8209501e-21 1.0000000e+00
 4.1729787e-24 1.3288248e-21], sum to 1.0000
[2019-04-06 22:15:54,071] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3525
[2019-04-06 22:15:54,103] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 89.0, 102.0, 0.0, 26.0, 26.30730575941058, 0.5827848793021063, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4451400.0000, 
sim time next is 4453200.0000, 
raw observation next is [0.0, 92.0, 149.0, 3.0, 26.0, 26.04866748413657, 0.5359997901207258, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.46260387811634357, 0.92, 0.49666666666666665, 0.0033149171270718232, 0.6666666666666666, 0.6707222903447141, 0.6786665967069085, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.48454875], dtype=float32), 0.33668035]. 
=============================================
[2019-04-06 22:15:57,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:15:57,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:15:57,183] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run36
[2019-04-06 22:15:58,137] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.7822334e-20 1.6767573e-21 9.0446218e-17 1.3845048e-18 1.0000000e+00
 7.0136959e-22 5.7200707e-21], sum to 1.0000
[2019-04-06 22:15:58,137] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2533
[2019-04-06 22:15:58,179] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.0, 72.0, 0.0, 0.0, 26.0, 24.70070838944294, 0.2625313194001737, 0.0, 1.0, 44407.68733284991], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2678400.0000, 
sim time next is 2680200.0000, 
raw observation next is [-8.0, 70.5, 0.0, 0.0, 26.0, 24.61960432337316, 0.2403299219084025, 0.0, 1.0, 44424.79157017933], 
processed observation next is [1.0, 0.0, 0.24099722991689754, 0.705, 0.0, 0.0, 0.6666666666666666, 0.55163369361443, 0.5801099739694675, 0.0, 1.0, 0.2115466265246635], 
reward next is 0.7885, 
noisyNet noise sample is [array([-0.09332118], dtype=float32), 2.5233607]. 
=============================================
[2019-04-06 22:16:06,424] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:16:06,424] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:16:06,428] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run36
[2019-04-06 22:16:08,940] A3C_AGENT_WORKER-Thread-14 INFO:Local step 99500, global step 1578578: loss 0.0774
[2019-04-06 22:16:08,958] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 99500, global step 1578578: learning rate 0.0000
[2019-04-06 22:16:09,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:16:09,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:16:09,724] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run36
[2019-04-06 22:16:10,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:16:10,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:16:10,528] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run36
[2019-04-06 22:16:12,865] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.5529748e-21 8.4046163e-21 2.7951462e-17 2.0228661e-19 1.0000000e+00
 2.4141976e-22 8.3136783e-20], sum to 1.0000
[2019-04-06 22:16:12,866] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6732
[2019-04-06 22:16:12,930] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.75024004566561, 0.2486822856181245, 0.0, 1.0, 42709.65228341534], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2768400.0000, 
sim time next is 2770200.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.78319802838507, 0.2471733038388196, 0.0, 1.0, 42222.580744961815], 
processed observation next is [1.0, 0.043478260869565216, 0.296398891966759, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5652665023654224, 0.5823911012796065, 0.0, 1.0, 0.20105990830934198], 
reward next is 0.7989, 
noisyNet noise sample is [array([1.0364572], dtype=float32), 1.4834626]. 
=============================================
[2019-04-06 22:16:20,796] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 22:16:20,797] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:16:20,797] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:16:20,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run80
[2019-04-06 22:16:20,830] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:16:20,831] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:16:20,845] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run80
[2019-04-06 22:16:20,871] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:16:20,872] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:16:20,876] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run80
[2019-04-06 22:16:58,601] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14830525]
[2019-04-06 22:16:58,601] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [16.1, 81.5, 0.0, 0.0, 26.0, 24.04438026601827, 0.2588012306726438, 0.0, 0.0, 0.0]
[2019-04-06 22:16:58,602] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:16:58,602] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.1501090e-18 1.7087021e-19 4.4851760e-16 1.7465832e-18 1.0000000e+00
 1.7140863e-21 4.2246741e-20], sampled 0.8776494222579005
[2019-04-06 22:17:21,205] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14830525]
[2019-04-06 22:17:21,205] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-4.5, 61.0, 0.0, 0.0, 26.0, 25.42804789746918, 0.4139739367980142, 0.0, 1.0, 43312.85993774597]
[2019-04-06 22:17:21,205] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:17:21,206] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [4.0233791e-19 7.6184737e-20 2.5307600e-16 1.1690453e-18 1.0000000e+00
 7.4451647e-22 2.6284787e-20], sampled 0.24972760304413955
[2019-04-06 22:18:34,502] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 22:19:13,458] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 22:19:18,827] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 22:19:19,888] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1580000, evaluation results [1580000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 22:19:29,117] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:19:29,117] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:19:29,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run36
[2019-04-06 22:19:36,688] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7721956e-21 4.3624205e-21 4.4716747e-18 1.7680732e-20 1.0000000e+00
 1.0707579e-23 8.4216857e-22], sum to 1.0000
[2019-04-06 22:19:36,689] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3842
[2019-04-06 22:19:36,770] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.5, 84.5, 0.0, 0.0, 26.0, 25.49839631980257, 0.514542515239259, 0.0, 1.0, 8303.65984637517], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4743000.0000, 
sim time next is 4744800.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 26.0, 25.37149283861453, 0.511602060732651, 0.0, 1.0, 68775.4340963834], 
processed observation next is [1.0, 0.9565217391304348, 0.3795013850415513, 0.84, 0.0, 0.0, 0.6666666666666666, 0.6142910698845441, 0.6705340202442169, 0.0, 1.0, 0.32750206712563523], 
reward next is 0.6725, 
noisyNet noise sample is [array([0.5620265], dtype=float32), 0.78724176]. 
=============================================
[2019-04-06 22:19:46,361] A3C_AGENT_WORKER-Thread-17 INFO:Local step 99500, global step 1582319: loss 0.0585
[2019-04-06 22:19:46,361] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 99500, global step 1582319: learning rate 0.0000
[2019-04-06 22:19:47,473] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.2850333e-20 4.0075078e-20 9.5525874e-17 5.8742011e-20 1.0000000e+00
 2.0174762e-22 2.4217162e-21], sum to 1.0000
[2019-04-06 22:19:47,474] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5677
[2019-04-06 22:19:47,874] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 65.0, 174.0, 246.0, 26.0, 25.55612164323841, 0.3864527032164656, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4870800.0000, 
sim time next is 4872600.0000, 
raw observation next is [-2.5, 62.5, 207.0, 179.0, 26.0, 25.47833949822803, 0.3653353713948804, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.39335180055401664, 0.625, 0.69, 0.19779005524861878, 0.6666666666666666, 0.6231949581856693, 0.6217784571316268, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.30999485], dtype=float32), -1.5185773]. 
=============================================
[2019-04-06 22:19:55,010] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:19:55,010] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:19:55,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run36
[2019-04-06 22:20:04,547] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:20:04,548] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:20:04,551] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run36
[2019-04-06 22:20:10,479] A3C_AGENT_WORKER-Thread-14 INFO:Local step 100000, global step 1584467: loss 1.1713
[2019-04-06 22:20:10,480] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 100000, global step 1584467: learning rate 0.0000
[2019-04-06 22:20:12,870] A3C_AGENT_WORKER-Thread-19 INFO:Local step 99500, global step 1584770: loss 0.0567
[2019-04-06 22:20:12,870] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 99500, global step 1584770: learning rate 0.0000
[2019-04-06 22:20:25,985] A3C_AGENT_WORKER-Thread-15 INFO:Local step 99500, global step 1586655: loss 0.0791
[2019-04-06 22:20:25,986] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 99500, global step 1586655: learning rate 0.0000
[2019-04-06 22:20:31,740] A3C_AGENT_WORKER-Thread-18 INFO:Local step 99500, global step 1587430: loss 0.0439
[2019-04-06 22:20:31,747] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 99500, global step 1587430: learning rate 0.0000
[2019-04-06 22:20:37,565] A3C_AGENT_WORKER-Thread-7 INFO:Local step 99500, global step 1588249: loss 0.0492
[2019-04-06 22:20:37,565] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 99500, global step 1588249: learning rate 0.0000
[2019-04-06 22:20:38,296] A3C_AGENT_WORKER-Thread-8 INFO:Local step 99500, global step 1588364: loss 0.0777
[2019-04-06 22:20:38,298] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 99500, global step 1588364: learning rate 0.0000
[2019-04-06 22:20:40,652] A3C_AGENT_WORKER-Thread-17 INFO:Local step 100000, global step 1588755: loss 1.2159
[2019-04-06 22:20:40,652] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 100000, global step 1588755: learning rate 0.0000
[2019-04-06 22:20:44,362] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4572700e-21 1.3250638e-21 1.4653503e-17 2.1564123e-19 1.0000000e+00
 2.7674569e-23 1.6390707e-22], sum to 1.0000
[2019-04-06 22:20:44,362] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7237
[2019-04-06 22:20:44,525] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 26.0, 26.25501059498738, 0.5321301097011238, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2053800.0000, 
sim time next is 2055600.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 26.0, 25.95853886510356, 0.4684954541113598, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3545706371191136, 0.82, 0.0, 0.0, 0.6666666666666666, 0.6632115720919632, 0.6561651513704533, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.62551653], dtype=float32), 1.3737698]. 
=============================================
[2019-04-06 22:20:53,474] A3C_AGENT_WORKER-Thread-6 INFO:Local step 99500, global step 1590656: loss 0.0521
[2019-04-06 22:20:53,477] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 99500, global step 1590656: learning rate 0.0000
[2019-04-06 22:20:56,123] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:20:56,123] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:20:56,128] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run36
[2019-04-06 22:20:57,313] A3C_AGENT_WORKER-Thread-19 INFO:Local step 100000, global step 1591303: loss 1.1909
[2019-04-06 22:20:57,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 100000, global step 1591303: learning rate 0.0000
[2019-04-06 22:20:58,700] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.5830309e-26 3.2160484e-27 1.9268756e-21 4.1028303e-25 1.0000000e+00
 9.1074055e-29 9.9845447e-27], sum to 1.0000
[2019-04-06 22:20:58,708] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1007
[2019-04-06 22:20:58,743] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 26.0, 26.09401100302438, 0.5720306337735205, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1015200.0000, 
sim time next is 1017000.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 26.0, 25.77469002020555, 0.5306643700382541, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.8614958448753465, 0.81, 0.0, 0.0, 0.6666666666666666, 0.6478908350171292, 0.6768881233460847, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.682689], dtype=float32), -0.87842894]. 
=============================================
[2019-04-06 22:20:58,748] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[101.38029 ]
 [101.45545 ]
 [101.71633 ]
 [101.77047 ]
 [101.851326]], R is [[101.60234833]
 [101.5863266 ]
 [101.57046509]
 [101.55476379]
 [101.53921509]].
[2019-04-06 22:21:03,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:21:03,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:21:03,824] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run36
[2019-04-06 22:21:04,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.0470644e-24 5.4684139e-25 1.4252635e-19 2.0658078e-22 1.0000000e+00
 2.9791520e-26 5.5684671e-25], sum to 1.0000
[2019-04-06 22:21:04,976] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5541
[2019-04-06 22:21:05,097] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.5, 79.5, 135.0, 0.0, 26.0, 24.35311084004933, 0.3895998849826993, 1.0, 1.0, 165818.71186468456], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4714200.0000, 
sim time next is 4716000.0000, 
raw observation next is [2.0, 73.0, 165.5, 3.0, 26.0, 26.07386385358204, 0.582772174457028, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.518005540166205, 0.73, 0.5516666666666666, 0.0033149171270718232, 0.6666666666666666, 0.6728219877985033, 0.6942573914856759, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6305563], dtype=float32), 0.5603702]. 
=============================================
[2019-04-06 22:21:05,101] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[90.49753 ]
 [89.40057 ]
 [89.8822  ]
 [90.492775]
 [91.0271  ]], R is [[90.3892746 ]
 [89.69577026]
 [89.79881287]
 [89.9008255 ]
 [90.0018158 ]].
[2019-04-06 22:21:08,153] A3C_AGENT_WORKER-Thread-16 INFO:Local step 99500, global step 1593003: loss 0.0604
[2019-04-06 22:21:08,154] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 99500, global step 1593003: learning rate 0.0000
[2019-04-06 22:21:08,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:21:08,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:21:08,756] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run36
[2019-04-06 22:21:12,000] A3C_AGENT_WORKER-Thread-15 INFO:Local step 100000, global step 1593502: loss 1.1891
[2019-04-06 22:21:12,002] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 100000, global step 1593502: learning rate 0.0000
[2019-04-06 22:21:13,174] A3C_AGENT_WORKER-Thread-12 INFO:Local step 99500, global step 1593659: loss 0.0676
[2019-04-06 22:21:13,174] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 99500, global step 1593659: learning rate 0.0000
[2019-04-06 22:21:13,826] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0794241e-22 5.9831534e-23 3.2816091e-18 3.4463392e-22 1.0000000e+00
 3.3104009e-26 3.8915581e-24], sum to 1.0000
[2019-04-06 22:21:13,827] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9533
[2019-04-06 22:21:13,892] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.2, 96.0, 0.0, 0.0, 26.0, 25.36549071076314, 0.4476538426512185, 0.0, 1.0, 33578.19051132017], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1483200.0000, 
sim time next is 1485000.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 26.0, 25.35459362458958, 0.4532732050776208, 0.0, 1.0, 42241.554448012175], 
processed observation next is [1.0, 0.17391304347826086, 0.5235457063711911, 0.96, 0.0, 0.0, 0.6666666666666666, 0.6128828020491316, 0.6510910683592069, 0.0, 1.0, 0.20115025927624847], 
reward next is 0.7988, 
noisyNet noise sample is [array([1.1171325], dtype=float32), 0.2707751]. 
=============================================
[2019-04-06 22:21:13,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[92.44455]
 [92.35341]
 [92.15021]
 [91.75823]
 [91.54739]], R is [[92.47383881]
 [92.38920593]
 [92.26636505]
 [92.15106964]
 [92.12738037]].
[2019-04-06 22:21:16,180] A3C_AGENT_WORKER-Thread-14 INFO:Local step 100500, global step 1594055: loss 0.1659
[2019-04-06 22:21:16,182] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 100500, global step 1594056: learning rate 0.0000
[2019-04-06 22:21:17,939] A3C_AGENT_WORKER-Thread-18 INFO:Local step 100000, global step 1594330: loss 1.1831
[2019-04-06 22:21:17,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 100000, global step 1594330: learning rate 0.0000
[2019-04-06 22:21:22,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:21:22,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:21:22,604] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run36
[2019-04-06 22:21:22,766] A3C_AGENT_WORKER-Thread-7 INFO:Local step 100000, global step 1595055: loss 1.1161
[2019-04-06 22:21:22,779] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 100000, global step 1595055: learning rate 0.0000
[2019-04-06 22:21:24,359] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.00610476e-19 4.92360357e-21 3.71507857e-17 1.06868711e-19
 1.00000000e+00 4.18744610e-22 4.23931647e-20], sum to 1.0000
[2019-04-06 22:21:24,360] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2379
[2019-04-06 22:21:24,500] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 26.0, 25.00089181292586, 0.3190628361296484, 0.0, 1.0, 45663.12973524799], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1792800.0000, 
sim time next is 1794600.0000, 
raw observation next is [-4.2, 82.5, 0.0, 0.0, 26.0, 25.00176453669699, 0.3164679900180871, 0.0, 1.0, 48386.76084563742], 
processed observation next is [0.0, 0.782608695652174, 0.34626038781163443, 0.825, 0.0, 0.0, 0.6666666666666666, 0.5834803780580824, 0.605489330006029, 0.0, 1.0, 0.23041314688398773], 
reward next is 0.7696, 
noisyNet noise sample is [array([-1.7448583], dtype=float32), -0.48679516]. 
=============================================
[2019-04-06 22:21:24,860] A3C_AGENT_WORKER-Thread-8 INFO:Local step 100000, global step 1595339: loss 1.1700
[2019-04-06 22:21:24,862] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 100000, global step 1595339: learning rate 0.0000
[2019-04-06 22:21:25,369] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5423232e-20 3.7676936e-20 4.8572776e-16 4.5387636e-20 1.0000000e+00
 6.8356910e-22 3.2054147e-21], sum to 1.0000
[2019-04-06 22:21:25,369] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3055
[2019-04-06 22:21:25,434] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 48.0, 0.0, 0.0, 26.0, 25.1884934233071, 0.2752445884415352, 0.0, 1.0, 38377.9381603329], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4941000.0000, 
sim time next is 4942800.0000, 
raw observation next is [-2.0, 46.0, 0.0, 0.0, 26.0, 25.20681335425375, 0.2692319005114968, 0.0, 1.0, 38391.58919244509], 
processed observation next is [1.0, 0.21739130434782608, 0.40720221606648205, 0.46, 0.0, 0.0, 0.6666666666666666, 0.6005677795211458, 0.5897439668371657, 0.0, 1.0, 0.18281709139259567], 
reward next is 0.8172, 
noisyNet noise sample is [array([-0.23291099], dtype=float32), -1.2702956]. 
=============================================
[2019-04-06 22:21:26,301] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:21:26,301] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:21:26,304] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run36
[2019-04-06 22:21:33,379] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:21:33,379] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:21:33,383] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run36
[2019-04-06 22:21:38,985] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [9.1483261e-20 3.7495398e-21 7.2191209e-17 1.2751731e-19 1.0000000e+00
 7.4284838e-22 2.0605840e-20], sum to 1.0000
[2019-04-06 22:21:38,985] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3020
[2019-04-06 22:21:39,122] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 83.0, 0.0, 0.0, 26.0, 25.1250713594843, 0.3300778044800908, 0.0, 1.0, 51588.24133738256], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1800000.0000, 
sim time next is 1801800.0000, 
raw observation next is [-4.75, 84.5, 0.0, 0.0, 26.0, 25.0601212955051, 0.3128352428608898, 0.0, 1.0, 46509.557859383116], 
processed observation next is [0.0, 0.8695652173913043, 0.3310249307479225, 0.845, 0.0, 0.0, 0.6666666666666666, 0.5883434412920915, 0.6042784142869633, 0.0, 1.0, 0.2214740850446815], 
reward next is 0.7785, 
noisyNet noise sample is [array([-0.7011409], dtype=float32), 0.19493578]. 
=============================================
[2019-04-06 22:21:39,472] A3C_AGENT_WORKER-Thread-6 INFO:Local step 100000, global step 1597072: loss 1.1578
[2019-04-06 22:21:39,473] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 100000, global step 1597072: learning rate 0.0000
[2019-04-06 22:21:40,428] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.0552229e-21 3.9959197e-21 9.8964269e-18 9.3420347e-22 1.0000000e+00
 6.4998285e-24 1.6215454e-22], sum to 1.0000
[2019-04-06 22:21:40,428] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8809
[2019-04-06 22:21:40,733] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.3, 68.0, 0.0, 0.0, 26.0, 23.38712716019697, 0.04991591398517378, 1.0, 1.0, 150571.59093809107], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 113400.0000, 
sim time next is 115200.0000, 
raw observation next is [-7.3, 68.0, 18.5, 4.5, 26.0, 24.79452336000355, 0.2297489401481081, 1.0, 1.0, 92782.65688089172], 
processed observation next is [1.0, 0.34782608695652173, 0.26038781163434904, 0.68, 0.06166666666666667, 0.004972375690607734, 0.6666666666666666, 0.5662102800002957, 0.5765829800493694, 1.0, 1.0, 0.4418221756232939], 
reward next is 0.5582, 
noisyNet noise sample is [array([0.05800337], dtype=float32), 0.21684745]. 
=============================================
[2019-04-06 22:21:47,550] A3C_AGENT_WORKER-Thread-17 INFO:Local step 100500, global step 1598024: loss 0.1770
[2019-04-06 22:21:47,551] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 100500, global step 1598024: learning rate 0.0000
[2019-04-06 22:21:52,527] A3C_AGENT_WORKER-Thread-16 INFO:Local step 100000, global step 1598597: loss 1.1747
[2019-04-06 22:21:52,527] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 100000, global step 1598597: learning rate 0.0000
[2019-04-06 22:21:59,195] A3C_AGENT_WORKER-Thread-12 INFO:Local step 100000, global step 1599360: loss 1.2282
[2019-04-06 22:21:59,195] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 100000, global step 1599360: learning rate 0.0000
[2019-04-06 22:22:01,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7487427e-19 7.3344444e-20 5.9089111e-17 7.4721779e-19 1.0000000e+00
 1.0540901e-21 2.1609402e-20], sum to 1.0000
[2019-04-06 22:22:01,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9132
[2019-04-06 22:22:02,141] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 37.0, 75.0, 0.0, 26.0, 25.59506559493416, 0.2857617517574293, 1.0, 1.0, 8032.259575345291], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 486000.0000, 
sim time next is 487800.0000, 
raw observation next is [0.55, 35.5, 56.0, 0.0, 26.0, 25.73356785272627, 0.2852151510116198, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.4778393351800555, 0.355, 0.18666666666666668, 0.0, 0.6666666666666666, 0.6444639877271893, 0.5950717170038733, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0674727], dtype=float32), -0.9215474]. 
=============================================
[2019-04-06 22:22:04,731] A3C_AGENT_WORKER-Thread-20 INFO:Local step 99500, global step 1599978: loss 0.0488
[2019-04-06 22:22:04,732] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 99500, global step 1599978: learning rate 0.0000
[2019-04-06 22:22:04,905] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 22:22:04,906] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:22:04,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:22:04,921] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:22:04,921] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:22:04,941] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run81
[2019-04-06 22:22:04,966] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:22:04,970] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:22:04,970] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run81
[2019-04-06 22:22:04,995] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run81
[2019-04-06 22:22:23,106] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14807954]
[2019-04-06 22:22:23,106] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-12.25, 51.0, 58.0, 905.0, 26.0, 25.6622775796147, 0.373519899956694, 1.0, 1.0, 43828.72915689327]
[2019-04-06 22:22:23,106] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:22:23,107] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [3.7554145e-18 1.5103314e-18 3.8919326e-15 1.5994148e-17 1.0000000e+00
 1.7640040e-20 6.5726009e-19], sampled 0.1919698149071326
[2019-04-06 22:24:20,444] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 22:24:31,481] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14807954]
[2019-04-06 22:24:31,481] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-4.0, 54.0, 0.0, 0.0, 26.0, 24.93279283983418, 0.2918151216008447, 0.0, 1.0, 39459.40932037065]
[2019-04-06 22:24:31,481] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:24:31,482] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [7.3289945e-19 1.5040522e-19 4.6748707e-16 1.7435344e-18 1.0000000e+00
 1.2520160e-21 3.9329352e-20], sampled 0.19368725637239625
[2019-04-06 22:24:37,068] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.14807954]
[2019-04-06 22:24:37,069] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [14.2, 31.5, 195.0, 629.0, 26.0, 28.23629824788256, 1.116868567642435, 1.0, 1.0, 0.0]
[2019-04-06 22:24:37,069] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:24:37,070] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [6.7170395e-23 1.4025912e-23 3.3404262e-19 2.4019252e-22 1.0000000e+00
 4.7215698e-26 4.5884209e-24], sampled 0.9331823460391466
[2019-04-06 22:24:58,305] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 22:25:01,410] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 22:25:02,449] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1600000, evaluation results [1600000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 22:25:03,591] A3C_AGENT_WORKER-Thread-19 INFO:Local step 100500, global step 1600089: loss 0.1700
[2019-04-06 22:25:03,592] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 100500, global step 1600089: learning rate 0.0000
[2019-04-06 22:25:14,564] A3C_AGENT_WORKER-Thread-5 INFO:Local step 99500, global step 1600859: loss 0.0419
[2019-04-06 22:25:14,565] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 99500, global step 1600859: learning rate 0.0000
[2019-04-06 22:25:15,300] A3C_AGENT_WORKER-Thread-14 INFO:Local step 101000, global step 1600918: loss 0.0387
[2019-04-06 22:25:15,301] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 101000, global step 1600918: learning rate 0.0000
[2019-04-06 22:25:24,563] A3C_AGENT_WORKER-Thread-2 INFO:Local step 99500, global step 1601565: loss 0.0425
[2019-04-06 22:25:24,564] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 99500, global step 1601565: learning rate 0.0000
[2019-04-06 22:25:27,218] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1261946e-20 1.1666925e-19 1.8579396e-16 1.6806461e-19 1.0000000e+00
 5.4991521e-22 7.8273621e-21], sum to 1.0000
[2019-04-06 22:25:27,218] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3117
[2019-04-06 22:25:27,575] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-10.5, 70.0, 117.0, 674.0, 26.0, 26.07603091099318, 0.4683770561953833, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2716200.0000, 
sim time next is 2718000.0000, 
raw observation next is [-9.0, 64.0, 114.5, 727.5, 26.0, 26.09700434827075, 0.4794214612063117, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.21329639889196678, 0.64, 0.38166666666666665, 0.8038674033149171, 0.6666666666666666, 0.6747503623558959, 0.6598071537354372, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6669778], dtype=float32), 0.6480412]. 
=============================================
[2019-04-06 22:25:27,580] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[78.38509]
 [78.17418]
 [78.11844]
 [77.57352]
 [76.68518]], R is [[78.79728699]
 [79.00931549]
 [79.21922302]
 [79.42703247]
 [79.63275909]].
[2019-04-06 22:25:28,411] A3C_AGENT_WORKER-Thread-15 INFO:Local step 100500, global step 1601850: loss 0.1533
[2019-04-06 22:25:28,411] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 100500, global step 1601850: learning rate 0.0000
[2019-04-06 22:25:38,011] A3C_AGENT_WORKER-Thread-18 INFO:Local step 100500, global step 1602612: loss 0.1288
[2019-04-06 22:25:38,011] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 100500, global step 1602612: learning rate 0.0000
[2019-04-06 22:25:39,134] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.7302939e-19 5.9068538e-19 3.2619927e-16 4.1839577e-18 1.0000000e+00
 2.5619240e-21 2.4128295e-19], sum to 1.0000
[2019-04-06 22:25:39,134] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0284
[2019-04-06 22:25:39,198] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 65.0, 0.0, 0.0, 26.0, 23.72191280770341, -0.01661277189311125, 0.0, 1.0, 43982.426422323304], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 626400.0000, 
sim time next is 628200.0000, 
raw observation next is [-4.5, 66.5, 0.0, 0.0, 26.0, 23.67205266219918, -0.02855838856684346, 0.0, 1.0, 43783.83186520024], 
processed observation next is [0.0, 0.2608695652173913, 0.3379501385041552, 0.665, 0.0, 0.0, 0.6666666666666666, 0.47267105518326513, 0.4904805371443855, 0.0, 1.0, 0.20849443745333449], 
reward next is 0.7915, 
noisyNet noise sample is [array([-0.12851255], dtype=float32), -0.5216236]. 
=============================================
[2019-04-06 22:25:43,256] A3C_AGENT_WORKER-Thread-7 INFO:Local step 100500, global step 1603210: loss 0.1394
[2019-04-06 22:25:43,257] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 100500, global step 1603210: learning rate 0.0000
[2019-04-06 22:25:45,699] A3C_AGENT_WORKER-Thread-4 INFO:Local step 99500, global step 1603554: loss 0.0942
[2019-04-06 22:25:45,703] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 99500, global step 1603554: learning rate 0.0000
[2019-04-06 22:25:46,766] A3C_AGENT_WORKER-Thread-8 INFO:Local step 100500, global step 1603671: loss 0.1601
[2019-04-06 22:25:46,767] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 100500, global step 1603671: learning rate 0.0000
[2019-04-06 22:25:48,405] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.0764013e-23 3.4767841e-25 2.1254100e-20 1.6121387e-23 1.0000000e+00
 2.4747443e-27 1.2822868e-24], sum to 1.0000
[2019-04-06 22:25:48,405] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9238
[2019-04-06 22:25:48,433] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.6, 65.0, 217.5, 266.0, 26.0, 27.17988971747023, 0.6307766065387382, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1080000.0000, 
sim time next is 1081800.0000, 
raw observation next is [17.45, 60.5, 181.0, 317.0, 26.0, 27.00662362253207, 0.7245839329470888, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.9459833795013851, 0.605, 0.6033333333333334, 0.35027624309392263, 0.6666666666666666, 0.7505519685443393, 0.7415279776490297, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.56956416], dtype=float32), 1.0327824]. 
=============================================
[2019-04-06 22:25:50,434] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4937293e-22 2.0449898e-23 2.5721806e-18 2.2904633e-23 1.0000000e+00
 4.4462976e-25 5.0862697e-23], sum to 1.0000
[2019-04-06 22:25:50,434] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2582
[2019-04-06 22:25:50,587] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 26.0, 25.25166812546388, 0.4487323429513752, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1362600.0000, 
sim time next is 1364400.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 26.0, 24.95389150085407, 0.4906449882796367, 1.0, 1.0, 104813.81838150391], 
processed observation next is [1.0, 0.8260869565217391, 0.4764542936288089, 0.96, 0.0, 0.0, 0.6666666666666666, 0.5794909584045058, 0.6635483294265455, 1.0, 1.0, 0.4991134208643043], 
reward next is 0.5009, 
noisyNet noise sample is [array([0.90801877], dtype=float32), -1.1848924]. 
=============================================
[2019-04-06 22:25:50,962] A3C_AGENT_WORKER-Thread-13 INFO:Local step 99500, global step 1604285: loss 0.0566
[2019-04-06 22:25:50,963] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 99500, global step 1604285: learning rate 0.0000
[2019-04-06 22:25:53,124] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1880740e-21 2.4442597e-21 4.1029544e-18 2.6606903e-20 1.0000000e+00
 8.7147026e-24 4.3569300e-22], sum to 1.0000
[2019-04-06 22:25:53,124] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1955
[2019-04-06 22:25:53,351] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 26.0, 25.51216227958429, 0.4275809902436539, 1.0, 1.0, 6239.044134375344], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2142000.0000, 
sim time next is 2143800.0000, 
raw observation next is [-5.3, 78.5, 0.0, 0.0, 26.0, 25.38047964687423, 0.3813887124353092, 0.0, 1.0, 30650.546759043773], 
processed observation next is [1.0, 0.8260869565217391, 0.31578947368421056, 0.785, 0.0, 0.0, 0.6666666666666666, 0.6150399705728526, 0.6271295708117698, 0.0, 1.0, 0.1459549845668751], 
reward next is 0.8540, 
noisyNet noise sample is [array([0.7126571], dtype=float32), -0.5302224]. 
=============================================
[2019-04-06 22:25:55,094] A3C_AGENT_WORKER-Thread-17 INFO:Local step 101000, global step 1604853: loss 0.0388
[2019-04-06 22:25:55,098] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 101000, global step 1604853: learning rate 0.0000
[2019-04-06 22:25:57,010] A3C_AGENT_WORKER-Thread-3 INFO:Local step 99500, global step 1605119: loss 0.0524
[2019-04-06 22:25:57,011] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 99500, global step 1605119: learning rate 0.0000
[2019-04-06 22:26:00,200] A3C_AGENT_WORKER-Thread-6 INFO:Local step 100500, global step 1605571: loss 0.1076
[2019-04-06 22:26:00,200] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 100500, global step 1605571: learning rate 0.0000
[2019-04-06 22:26:02,335] A3C_AGENT_WORKER-Thread-20 INFO:Local step 100000, global step 1605895: loss 1.2589
[2019-04-06 22:26:02,336] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 100000, global step 1605895: learning rate 0.0000
[2019-04-06 22:26:09,455] A3C_AGENT_WORKER-Thread-14 INFO:Local step 101500, global step 1606941: loss 1.9812
[2019-04-06 22:26:09,456] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 101500, global step 1606941: learning rate 0.0000
[2019-04-06 22:26:10,999] A3C_AGENT_WORKER-Thread-5 INFO:Local step 100000, global step 1607189: loss 1.1618
[2019-04-06 22:26:11,000] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 100000, global step 1607189: learning rate 0.0000
[2019-04-06 22:26:12,365] A3C_AGENT_WORKER-Thread-16 INFO:Local step 100500, global step 1607408: loss 0.1288
[2019-04-06 22:26:12,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 100500, global step 1607408: learning rate 0.0000
[2019-04-06 22:26:13,991] A3C_AGENT_WORKER-Thread-19 INFO:Local step 101000, global step 1607686: loss 0.0523
[2019-04-06 22:26:13,993] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 101000, global step 1607686: learning rate 0.0000
[2019-04-06 22:26:17,249] A3C_AGENT_WORKER-Thread-2 INFO:Local step 100000, global step 1608261: loss 1.1663
[2019-04-06 22:26:17,249] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 100000, global step 1608261: learning rate 0.0000
[2019-04-06 22:26:19,017] A3C_AGENT_WORKER-Thread-12 INFO:Local step 100500, global step 1608555: loss 0.1313
[2019-04-06 22:26:19,046] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 100500, global step 1608555: learning rate 0.0000
[2019-04-06 22:26:22,605] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0771259e-20 1.1770271e-20 1.8178939e-16 2.1423588e-19 1.0000000e+00
 7.0859833e-22 2.8077614e-21], sum to 1.0000
[2019-04-06 22:26:22,617] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6399
[2019-04-06 22:26:22,645] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.2500000000000001, 43.0, 232.0, 71.0, 26.0, 25.68309325100917, 0.3192747609446805, 1.0, 1.0, 12454.781382346364], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2547000.0000, 
sim time next is 2548800.0000, 
raw observation next is [1.1, 39.0, 225.0, 46.5, 26.0, 25.74831274672857, 0.3315827060351028, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.49307479224376743, 0.39, 0.75, 0.05138121546961326, 0.6666666666666666, 0.6456927288940474, 0.6105275686783677, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16107865], dtype=float32), 0.1142609]. 
=============================================
[2019-04-06 22:26:28,352] A3C_AGENT_WORKER-Thread-15 INFO:Local step 101000, global step 1610070: loss 0.0645
[2019-04-06 22:26:28,353] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 101000, global step 1610070: learning rate 0.0000
[2019-04-06 22:26:32,264] A3C_AGENT_WORKER-Thread-4 INFO:Local step 100000, global step 1610688: loss 1.1311
[2019-04-06 22:26:32,265] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 100000, global step 1610688: learning rate 0.0000
[2019-04-06 22:26:34,591] A3C_AGENT_WORKER-Thread-18 INFO:Local step 101000, global step 1611032: loss 0.0748
[2019-04-06 22:26:34,592] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 101000, global step 1611032: learning rate 0.0000
[2019-04-06 22:26:36,059] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7524148e-21 7.1261297e-22 1.3093485e-18 5.4751876e-21 1.0000000e+00
 8.2612093e-25 3.0228309e-22], sum to 1.0000
[2019-04-06 22:26:36,059] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9889
[2019-04-06 22:26:36,249] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 86.0, 0.0, 0.0, 26.0, 25.21335108680883, 0.4197706482361368, 0.0, 1.0, 79957.25786151638], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2061000.0000, 
sim time next is 2062800.0000, 
raw observation next is [-3.9, 86.0, 0.0, 0.0, 26.0, 25.37527428074278, 0.4346399601390121, 0.0, 1.0, 48119.492752187456], 
processed observation next is [1.0, 0.9130434782608695, 0.3545706371191136, 0.86, 0.0, 0.0, 0.6666666666666666, 0.6146061900618983, 0.6448799867130041, 0.0, 1.0, 0.2291404416770831], 
reward next is 0.7709, 
noisyNet noise sample is [array([-1.8869263], dtype=float32), -0.855539]. 
=============================================
[2019-04-06 22:26:36,503] A3C_AGENT_WORKER-Thread-13 INFO:Local step 100000, global step 1611330: loss 1.1767
[2019-04-06 22:26:36,503] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 100000, global step 1611330: learning rate 0.0000
[2019-04-06 22:26:38,582] A3C_AGENT_WORKER-Thread-7 INFO:Local step 101000, global step 1611643: loss 0.0623
[2019-04-06 22:26:38,583] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 101000, global step 1611643: learning rate 0.0000
[2019-04-06 22:26:41,570] A3C_AGENT_WORKER-Thread-8 INFO:Local step 101000, global step 1612101: loss 0.0625
[2019-04-06 22:26:41,577] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 101000, global step 1612101: learning rate 0.0000
[2019-04-06 22:26:41,656] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.8480080e-24 2.5288486e-24 9.6691486e-22 3.7475894e-24 1.0000000e+00
 1.6847143e-28 1.0122376e-26], sum to 1.0000
[2019-04-06 22:26:41,656] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9861
[2019-04-06 22:26:41,685] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.0, 100.0, 103.5, 696.5, 26.0, 26.64421874045031, 0.6346002778595335, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3146400.0000, 
sim time next is 3148200.0000, 
raw observation next is [7.0, 100.0, 108.0, 746.0, 26.0, 26.89580613410198, 0.6992921798233386, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.6565096952908588, 1.0, 0.36, 0.8243093922651934, 0.6666666666666666, 0.7413171778418318, 0.7330973932744462, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.10838609], dtype=float32), -0.059439715]. 
=============================================
[2019-04-06 22:26:42,378] A3C_AGENT_WORKER-Thread-3 INFO:Local step 100000, global step 1612234: loss 1.1847
[2019-04-06 22:26:42,379] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 100000, global step 1612234: learning rate 0.0000
[2019-04-06 22:26:43,101] A3C_AGENT_WORKER-Thread-17 INFO:Local step 101500, global step 1612343: loss 2.0980
[2019-04-06 22:26:43,108] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 101500, global step 1612343: learning rate 0.0000
[2019-04-06 22:26:48,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:26:48,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:26:48,796] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run37
[2019-04-06 22:26:53,735] A3C_AGENT_WORKER-Thread-6 INFO:Local step 101000, global step 1613922: loss 0.0506
[2019-04-06 22:26:53,736] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 101000, global step 1613922: learning rate 0.0000
[2019-04-06 22:26:57,846] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8132347e-23 2.4719755e-23 2.3017758e-19 7.1557093e-23 1.0000000e+00
 8.2493958e-26 1.5261610e-24], sum to 1.0000
[2019-04-06 22:26:57,847] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2339
[2019-04-06 22:26:57,895] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 26.0, 25.39899915100633, 0.5059667922742391, 0.0, 1.0, 50368.53036100648], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3211200.0000, 
sim time next is 3213000.0000, 
raw observation next is [-1.5, 100.0, 0.0, 0.0, 26.0, 25.28499520755225, 0.5062444181824722, 0.0, 1.0, 63524.626713724865], 
processed observation next is [1.0, 0.17391304347826086, 0.4210526315789474, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6070829339626874, 0.6687481393941574, 0.0, 1.0, 0.30249822244630886], 
reward next is 0.6975, 
noisyNet noise sample is [array([-0.46225202], dtype=float32), -0.98565686]. 
=============================================
[2019-04-06 22:26:57,899] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[91.624504]
 [91.79485 ]
 [91.96261 ]
 [92.27235 ]
 [92.089935]], R is [[91.3218689 ]
 [91.16880035]
 [91.06594086]
 [91.15528107]
 [90.98783112]].
[2019-04-06 22:27:00,782] A3C_AGENT_WORKER-Thread-19 INFO:Local step 101500, global step 1614928: loss 2.1603
[2019-04-06 22:27:00,782] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 101500, global step 1614928: learning rate 0.0000
[2019-04-06 22:27:07,434] A3C_AGENT_WORKER-Thread-16 INFO:Local step 101000, global step 1615894: loss 0.0725
[2019-04-06 22:27:07,437] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 101000, global step 1615894: learning rate 0.0000
[2019-04-06 22:27:08,358] A3C_AGENT_WORKER-Thread-20 INFO:Local step 100500, global step 1616028: loss 0.1256
[2019-04-06 22:27:08,359] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 100500, global step 1616028: learning rate 0.0000
[2019-04-06 22:27:12,377] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5504410e-18 2.6042970e-19 2.8454331e-15 4.7721092e-18 1.0000000e+00
 4.7611530e-22 8.5485061e-21], sum to 1.0000
[2019-04-06 22:27:12,378] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4129
[2019-04-06 22:27:12,452] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 47.0, 0.0, 0.0, 26.0, 25.38555445029439, 0.3276472557412934, 0.0, 1.0, 34610.775833855216], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4253400.0000, 
sim time next is 4255200.0000, 
raw observation next is [3.0, 49.0, 0.0, 0.0, 26.0, 25.37217285967992, 0.327840592257076, 0.0, 1.0, 43274.61535411016], 
processed observation next is [0.0, 0.2608695652173913, 0.5457063711911359, 0.49, 0.0, 0.0, 0.6666666666666666, 0.6143477383066601, 0.6092801974190253, 0.0, 1.0, 0.2060695969243341], 
reward next is 0.7939, 
noisyNet noise sample is [array([-1.1470276], dtype=float32), 0.7499373]. 
=============================================
[2019-04-06 22:27:13,398] A3C_AGENT_WORKER-Thread-12 INFO:Local step 101000, global step 1616784: loss 0.0653
[2019-04-06 22:27:13,398] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 101000, global step 1616784: learning rate 0.0000
[2019-04-06 22:27:14,078] A3C_AGENT_WORKER-Thread-15 INFO:Local step 101500, global step 1616891: loss 2.0193
[2019-04-06 22:27:14,078] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 101500, global step 1616891: learning rate 0.0000
[2019-04-06 22:27:17,090] A3C_AGENT_WORKER-Thread-5 INFO:Local step 100500, global step 1617308: loss 0.1173
[2019-04-06 22:27:17,090] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 100500, global step 1617308: learning rate 0.0000
[2019-04-06 22:27:20,316] A3C_AGENT_WORKER-Thread-18 INFO:Local step 101500, global step 1617832: loss 2.1131
[2019-04-06 22:27:20,318] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 101500, global step 1617833: learning rate 0.0000
[2019-04-06 22:27:23,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:27:23,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:27:23,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run37
[2019-04-06 22:27:23,662] A3C_AGENT_WORKER-Thread-2 INFO:Local step 100500, global step 1618335: loss 0.1264
[2019-04-06 22:27:23,663] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 100500, global step 1618335: learning rate 0.0000
[2019-04-06 22:27:25,267] A3C_AGENT_WORKER-Thread-7 INFO:Local step 101500, global step 1618550: loss 1.9979
[2019-04-06 22:27:25,268] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 101500, global step 1618550: learning rate 0.0000
[2019-04-06 22:27:28,992] A3C_AGENT_WORKER-Thread-8 INFO:Local step 101500, global step 1619094: loss 1.9735
[2019-04-06 22:27:28,993] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 101500, global step 1619094: learning rate 0.0000
[2019-04-06 22:27:34,580] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1933144e-23 1.0404587e-22 4.1500953e-20 6.7933445e-22 1.0000000e+00
 2.8784530e-26 6.5460360e-24], sum to 1.0000
[2019-04-06 22:27:34,581] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6675
[2019-04-06 22:27:34,610] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.0, 26.0, 53.0, 472.5, 26.0, 26.99263414235079, 0.827476345871776, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4986000.0000, 
sim time next is 4987800.0000, 
raw observation next is [7.0, 25.5, 34.0, 304.0, 26.0, 27.50529530675639, 0.8256197751974917, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.6565096952908588, 0.255, 0.11333333333333333, 0.33591160220994476, 0.6666666666666666, 0.7921079422296993, 0.7752065917324972, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.56747353], dtype=float32), -1.7924579]. 
=============================================
[2019-04-06 22:27:34,943] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 22:27:34,944] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:27:34,944] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:27:34,948] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run82
[2019-04-06 22:27:34,973] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:27:34,975] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:27:34,976] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:27:34,990] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run82
[2019-04-06 22:27:35,022] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:27:35,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run82
[2019-04-06 22:29:47,471] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 22:30:23,063] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 22:30:29,917] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 22:30:30,963] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1620000, evaluation results [1620000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 22:30:36,462] A3C_AGENT_WORKER-Thread-4 INFO:Local step 100500, global step 1620524: loss 0.1482
[2019-04-06 22:30:36,462] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 100500, global step 1620524: learning rate 0.0000
[2019-04-06 22:30:38,058] A3C_AGENT_WORKER-Thread-6 INFO:Local step 101500, global step 1620673: loss 2.0399
[2019-04-06 22:30:38,065] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 101500, global step 1620673: learning rate 0.0000
[2019-04-06 22:30:38,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:30:38,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:30:38,843] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run37
[2019-04-06 22:30:45,550] A3C_AGENT_WORKER-Thread-13 INFO:Local step 100500, global step 1621320: loss 0.1443
[2019-04-06 22:30:45,550] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 100500, global step 1621320: learning rate 0.0000
[2019-04-06 22:30:52,518] A3C_AGENT_WORKER-Thread-3 INFO:Local step 100500, global step 1621953: loss 0.1620
[2019-04-06 22:30:52,519] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 100500, global step 1621953: learning rate 0.0000
[2019-04-06 22:30:58,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:30:58,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:30:58,556] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run37
[2019-04-06 22:31:00,039] A3C_AGENT_WORKER-Thread-16 INFO:Local step 101500, global step 1622680: loss 1.8866
[2019-04-06 22:31:00,061] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 101500, global step 1622680: learning rate 0.0000
[2019-04-06 22:31:08,625] A3C_AGENT_WORKER-Thread-12 INFO:Local step 101500, global step 1623502: loss 2.0481
[2019-04-06 22:31:08,625] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 101500, global step 1623502: learning rate 0.0000
[2019-04-06 22:31:08,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:31:08,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:31:08,832] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run37
[2019-04-06 22:31:15,216] A3C_AGENT_WORKER-Thread-20 INFO:Local step 101000, global step 1624067: loss 0.0795
[2019-04-06 22:31:15,216] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 101000, global step 1624067: learning rate 0.0000
[2019-04-06 22:31:15,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:31:15,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:31:15,768] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run37
[2019-04-06 22:31:20,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:31:20,602] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:31:20,614] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run37
[2019-04-06 22:31:23,790] A3C_AGENT_WORKER-Thread-5 INFO:Local step 101000, global step 1625079: loss 0.0978
[2019-04-06 22:31:23,791] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 101000, global step 1625079: learning rate 0.0000
[2019-04-06 22:31:30,374] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:31:30,374] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:31:30,390] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run37
[2019-04-06 22:31:32,390] A3C_AGENT_WORKER-Thread-2 INFO:Local step 101000, global step 1626213: loss 0.0616
[2019-04-06 22:31:32,396] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 101000, global step 1626213: learning rate 0.0000
[2019-04-06 22:31:40,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.5927275e-23 9.7050989e-23 5.0402529e-19 2.2730735e-22 1.0000000e+00
 7.6663789e-26 6.8883768e-24], sum to 1.0000
[2019-04-06 22:31:40,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3782
[2019-04-06 22:31:40,549] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.5, 75.0, 0.0, 0.0, 26.0, 25.91876341175026, 0.6034098961000977, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3533400.0000, 
sim time next is 3535200.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 26.0, 25.78724551873482, 0.5638864983346566, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4349030470914128, 0.78, 0.0, 0.0, 0.6666666666666666, 0.648937126561235, 0.6879621661115523, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.00440831], dtype=float32), 0.6973918]. 
=============================================
[2019-04-06 22:31:45,769] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.7014255e-21 3.1302417e-21 4.4115292e-17 4.5118142e-21 1.0000000e+00
 3.0897482e-23 2.5760539e-22], sum to 1.0000
[2019-04-06 22:31:45,769] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0239
[2019-04-06 22:31:45,834] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.2, 76.5, 0.0, 0.0, 26.0, 23.91552709567785, 0.0380137027072067, 0.0, 1.0, 43711.11227345779], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 102600.0000, 
sim time next is 104400.0000, 
raw observation next is [-5.0, 74.0, 0.0, 0.0, 26.0, 23.72780645599079, -0.001704925065089231, 0.0, 1.0, 43983.410314703935], 
processed observation next is [1.0, 0.21739130434782608, 0.32409972299168976, 0.74, 0.0, 0.0, 0.6666666666666666, 0.4773172046658993, 0.4994316916449703, 0.0, 1.0, 0.2094448110223997], 
reward next is 0.7906, 
noisyNet noise sample is [array([-0.9004946], dtype=float32), 0.08237405]. 
=============================================
[2019-04-06 22:31:45,977] A3C_AGENT_WORKER-Thread-4 INFO:Local step 101000, global step 1628089: loss 0.0900
[2019-04-06 22:31:45,978] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 101000, global step 1628089: learning rate 0.0000
[2019-04-06 22:31:46,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:31:46,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:31:46,320] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run37
[2019-04-06 22:31:51,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:31:51,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:31:51,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run37
[2019-04-06 22:31:53,783] A3C_AGENT_WORKER-Thread-13 INFO:Local step 101000, global step 1629054: loss 0.0887
[2019-04-06 22:31:53,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 101000, global step 1629054: learning rate 0.0000
[2019-04-06 22:31:57,692] A3C_AGENT_WORKER-Thread-3 INFO:Local step 101000, global step 1629510: loss 0.0761
[2019-04-06 22:31:57,692] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 101000, global step 1629510: learning rate 0.0000
[2019-04-06 22:32:00,628] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [3.9296681e-19 6.5886420e-19 3.5473776e-15 7.4550945e-19 1.0000000e+00
 4.6678375e-21 1.7262472e-19], sum to 1.0000
[2019-04-06 22:32:00,628] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7490
[2019-04-06 22:32:00,691] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-15.0, 69.0, 0.0, 0.0, 26.0, 22.74697055004533, -0.2488831498180419, 0.0, 1.0, 49186.781698020415], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 356400.0000, 
sim time next is 358200.0000, 
raw observation next is [-15.3, 71.0, 0.0, 0.0, 26.0, 22.58897539764279, -0.2734997299895138, 0.0, 1.0, 49317.576195190915], 
processed observation next is [1.0, 0.13043478260869565, 0.03878116343490302, 0.71, 0.0, 0.0, 0.6666666666666666, 0.3824146164702326, 0.4088334233368287, 0.0, 1.0, 0.23484560092948054], 
reward next is 0.7652, 
noisyNet noise sample is [array([-0.7244669], dtype=float32), 0.7699917]. 
=============================================
[2019-04-06 22:32:02,776] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5444250e-20 1.0108824e-20 8.0386246e-17 2.8052057e-19 1.0000000e+00
 2.3669147e-23 1.4442866e-21], sum to 1.0000
[2019-04-06 22:32:02,777] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9701
[2019-04-06 22:32:02,839] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 65.0, 0.0, 0.0, 26.0, 24.9024634579274, 0.3145134376102326, 0.0, 1.0, 40873.36497064207], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3560400.0000, 
sim time next is 3562200.0000, 
raw observation next is [-5.5, 67.5, 0.0, 0.0, 26.0, 24.74610259064296, 0.2917416417913127, 0.0, 1.0, 40879.23448900134], 
processed observation next is [0.0, 0.21739130434782608, 0.3102493074792244, 0.675, 0.0, 0.0, 0.6666666666666666, 0.5621752158869132, 0.5972472139304376, 0.0, 1.0, 0.19466302137619687], 
reward next is 0.8053, 
noisyNet noise sample is [array([-0.9721662], dtype=float32), -1.4548056]. 
=============================================
[2019-04-06 22:32:02,905] A3C_AGENT_WORKER-Thread-20 INFO:Local step 101500, global step 1630197: loss 1.9609
[2019-04-06 22:32:02,906] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 101500, global step 1630197: learning rate 0.0000
[2019-04-06 22:32:11,862] A3C_AGENT_WORKER-Thread-5 INFO:Local step 101500, global step 1631451: loss 1.9786
[2019-04-06 22:32:11,863] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 101500, global step 1631451: learning rate 0.0000
[2019-04-06 22:32:18,968] A3C_AGENT_WORKER-Thread-2 INFO:Local step 101500, global step 1632497: loss 1.9286
[2019-04-06 22:32:18,980] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 101500, global step 1632497: learning rate 0.0000
[2019-04-06 22:32:31,326] A3C_AGENT_WORKER-Thread-4 INFO:Local step 101500, global step 1634292: loss 1.9584
[2019-04-06 22:32:31,331] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 101500, global step 1634292: learning rate 0.0000
[2019-04-06 22:32:40,354] A3C_AGENT_WORKER-Thread-13 INFO:Local step 101500, global step 1635667: loss 1.9571
[2019-04-06 22:32:40,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 101500, global step 1635667: learning rate 0.0000
[2019-04-06 22:32:42,262] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.0446521e-19 1.3517189e-21 2.1184440e-17 1.0733160e-19 1.0000000e+00
 1.8909034e-22 9.6317872e-21], sum to 1.0000
[2019-04-06 22:32:42,262] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7211
[2019-04-06 22:32:42,407] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 47.0, 0.0, 0.0, 26.0, 24.97271554276458, 0.2912344428918638, 0.0, 1.0, 34398.33796355273], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4906800.0000, 
sim time next is 4908600.0000, 
raw observation next is [1.0, 43.5, 0.0, 0.0, 26.0, 25.12709766586153, 0.3480990435707901, 0.0, 1.0, 126999.28580313576], 
processed observation next is [0.0, 0.8260869565217391, 0.4903047091412743, 0.435, 0.0, 0.0, 0.6666666666666666, 0.5939248054884608, 0.6160330145235967, 0.0, 1.0, 0.604758503824456], 
reward next is 0.3952, 
noisyNet noise sample is [array([-1.2702414], dtype=float32), -1.265687]. 
=============================================
[2019-04-06 22:32:43,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:32:43,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:32:43,056] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run37
[2019-04-06 22:32:44,482] A3C_AGENT_WORKER-Thread-3 INFO:Local step 101500, global step 1636343: loss 1.8960
[2019-04-06 22:32:44,483] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 101500, global step 1636343: learning rate 0.0000
[2019-04-06 22:32:51,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:32:51,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:32:51,766] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run37
[2019-04-06 22:32:58,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:32:58,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:32:58,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run37
[2019-04-06 22:33:05,865] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6557417e-20 5.7900558e-22 3.1842033e-17 4.1108598e-21 1.0000000e+00
 1.6362578e-24 1.0531410e-22], sum to 1.0000
[2019-04-06 22:33:05,865] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0092
[2019-04-06 22:33:05,930] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.7, 83.0, 0.0, 0.0, 26.0, 24.06252781856041, 0.07263505791914475, 0.0, 1.0, 43496.34934096512], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2095200.0000, 
sim time next is 2097000.0000, 
raw observation next is [-6.7, 80.5, 0.0, 0.0, 26.0, 23.91867028822132, 0.04001375658078202, 0.0, 1.0, 43616.968211556225], 
processed observation next is [1.0, 0.2608695652173913, 0.2770083102493075, 0.805, 0.0, 0.0, 0.6666666666666666, 0.4932225240184434, 0.5133379188602607, 0.0, 1.0, 0.2076998486264582], 
reward next is 0.7923, 
noisyNet noise sample is [array([-1.334775], dtype=float32), -1.0195904]. 
=============================================
[2019-04-06 22:33:05,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[82.90293 ]
 [83.48862 ]
 [83.958855]
 [84.40934 ]
 [84.7579  ]], R is [[82.2806778 ]
 [82.25074768]
 [82.22073364]
 [82.19164276]
 [82.16233826]].
[2019-04-06 22:33:08,505] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 22:33:08,521] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:33:08,521] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:33:08,524] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run83
[2019-04-06 22:33:08,566] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:33:08,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:33:08,571] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run83
[2019-04-06 22:33:08,596] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:33:08,596] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:33:08,600] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run83
[2019-04-06 22:35:21,118] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 22:35:57,986] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.1494149]
[2019-04-06 22:35:57,986] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-5.014517725, 92.98243597, 40.910641555, 217.40016985, 26.0, 23.89020095818649, 0.1053313395623742, 0.0, 1.0, 41521.57333121743]
[2019-04-06 22:35:57,986] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 22:35:57,987] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [8.7848132e-20 1.4341690e-20 6.2076696e-17 2.0722436e-19 1.0000000e+00
 1.2459692e-22 3.8252434e-21], sampled 0.8853375205603555
[2019-04-06 22:36:00,034] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 22:36:07,269] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 22:36:08,307] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 1640000, evaluation results [1640000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 22:36:11,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:36:11,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:36:11,904] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run37
[2019-04-06 22:36:19,959] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8143365e-25 1.8695973e-26 2.7516182e-20 3.8826297e-25 1.0000000e+00
 1.4848904e-28 3.3758988e-26], sum to 1.0000
[2019-04-06 22:36:19,960] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8874
[2019-04-06 22:36:20,038] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.2, 83.0, 11.5, 38.0, 26.0, 25.9238869584286, 0.624215766368566, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1065600.0000, 
sim time next is 1067400.0000, 
raw observation next is [12.2, 83.0, 22.0, 69.0, 26.0, 26.06927661407415, 0.6824415106432492, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.8005540166204987, 0.83, 0.07333333333333333, 0.07624309392265194, 0.6666666666666666, 0.6724397178395124, 0.7274805035477497, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6996306], dtype=float32), -0.22595088]. 
=============================================
[2019-04-06 22:36:24,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:36:24,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:36:24,204] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run37
[2019-04-06 22:36:27,747] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8678754e-21 1.1221030e-21 1.0188162e-17 1.8447638e-21 1.0000000e+00
 2.2575180e-23 6.2149042e-22], sum to 1.0000
[2019-04-06 22:36:27,747] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9814
[2019-04-06 22:36:28,161] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 26.0, 25.00175977169466, 0.322203882553548, 0.0, 1.0, 46285.86894279844], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1791000.0000, 
sim time next is 1792800.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 26.0, 25.00089181292586, 0.3190628361296484, 0.0, 1.0, 45663.12973524799], 
processed observation next is [0.0, 0.782608695652174, 0.3545706371191136, 0.82, 0.0, 0.0, 0.6666666666666666, 0.5834076510771551, 0.6063542787098828, 0.0, 1.0, 0.21744347492975233], 
reward next is 0.7826, 
noisyNet noise sample is [array([-1.1276956], dtype=float32), 0.08691842]. 
=============================================
[2019-04-06 22:36:33,396] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:36:33,396] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:36:33,399] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run37
[2019-04-06 22:36:58,147] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6369394e-21 1.4943164e-22 3.7964387e-17 2.7385708e-20 1.0000000e+00
 3.3798450e-24 7.4332494e-21], sum to 1.0000
[2019-04-06 22:36:58,147] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3649
[2019-04-06 22:36:58,223] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.15, 91.0, 0.0, 0.0, 26.0, 24.34891918321836, 0.1365266343467615, 0.0, 1.0, 41210.99484934915], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 91800.0000, 
sim time next is 93600.0000, 
raw observation next is [-1.7, 91.0, 0.0, 0.0, 26.0, 24.24484456415385, 0.123461045069995, 0.0, 1.0, 41806.345971288014], 
processed observation next is [1.0, 0.08695652173913043, 0.4155124653739613, 0.91, 0.0, 0.0, 0.6666666666666666, 0.5204037136794876, 0.5411536816899983, 0.0, 1.0, 0.19907783795851436], 
reward next is 0.8009, 
noisyNet noise sample is [array([0.01690566], dtype=float32), -0.00072138285]. 
=============================================
[2019-04-06 22:37:19,574] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.7367019e-21 9.6628113e-21 2.2919649e-17 2.5288719e-21 1.0000000e+00
 2.7498289e-24 5.5544075e-23], sum to 1.0000
[2019-04-06 22:37:19,574] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.1170
[2019-04-06 22:37:19,764] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 71.0, 132.0, 0.0, 26.0, 25.54535080605206, 0.4550583383014901, 1.0, 1.0, 110094.42200783784], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2210400.0000, 
sim time next is 2212200.0000, 
raw observation next is [-3.9, 69.5, 120.0, 0.0, 26.0, 26.36562272639121, 0.5083345345365574, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3545706371191136, 0.695, 0.4, 0.0, 0.6666666666666666, 0.6971352271992673, 0.6694448448455191, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.67254597], dtype=float32), -0.19479801]. 
=============================================
[2019-04-06 22:37:24,252] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.3079042e-19 1.9025471e-20 3.8395951e-16 3.1609272e-19 1.0000000e+00
 2.6135186e-22 6.8656952e-21], sum to 1.0000
[2019-04-06 22:37:24,253] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4826
[2019-04-06 22:37:24,541] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 49.0, 23.0, 0.0, 26.0, 25.72872847434925, 0.2706968822282746, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2307600.0000, 
sim time next is 2309400.0000, 
raw observation next is [-0.8999999999999999, 50.5, 0.0, 0.0, 26.0, 24.89544273284384, 0.3161780082806147, 1.0, 1.0, 136661.67647732294], 
processed observation next is [1.0, 0.7391304347826086, 0.43767313019390586, 0.505, 0.0, 0.0, 0.6666666666666666, 0.5746202277369866, 0.6053926694268715, 1.0, 1.0, 0.6507698879872521], 
reward next is 0.3492, 
noisyNet noise sample is [array([0.7590451], dtype=float32), -0.55219555]. 
=============================================
[2019-04-06 22:37:35,607] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6599392e-18 1.8140603e-19 7.6433781e-16 4.6511365e-18 1.0000000e+00
 1.0593067e-20 5.2342555e-21], sum to 1.0000
[2019-04-06 22:37:35,608] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5850
[2019-04-06 22:37:35,690] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.35, 29.5, 0.0, 0.0, 26.0, 24.94151395378024, 0.2494479272814587, 0.0, 1.0, 105197.34737680068], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2489400.0000, 
sim time next is 2491200.0000, 
raw observation next is [-0.7, 29.0, 0.0, 0.0, 26.0, 25.24051476125931, 0.2844649225545803, 0.0, 1.0, 50801.63719226895], 
processed observation next is [0.0, 0.8695652173913043, 0.443213296398892, 0.29, 0.0, 0.0, 0.6666666666666666, 0.6033762301049425, 0.5948216408515268, 0.0, 1.0, 0.24191255805842357], 
reward next is 0.7581, 
noisyNet noise sample is [array([-0.34469503], dtype=float32), 0.15114819]. 
=============================================
[2019-04-06 22:37:39,247] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6907335e-21 9.3962472e-23 3.1751063e-17 8.3908370e-22 1.0000000e+00
 3.3846318e-24 8.0486033e-23], sum to 1.0000
[2019-04-06 22:37:39,247] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3339
[2019-04-06 22:37:39,315] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 68.0, 0.0, 0.0, 26.0, 25.15253645929211, 0.3252331149232246, 0.0, 1.0, 41121.99331309652], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3907800.0000, 
sim time next is 3909600.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 26.0, 24.92348755827294, 0.2943918066468074, 0.0, 1.0, 41583.86644409148], 
processed observation next is [1.0, 0.2608695652173913, 0.296398891966759, 0.59, 0.0, 0.0, 0.6666666666666666, 0.5769572965227449, 0.5981306022156024, 0.0, 1.0, 0.19801841163853084], 
reward next is 0.8020, 
noisyNet noise sample is [array([0.5908113], dtype=float32), 1.0243124]. 
=============================================
[2019-04-06 22:37:40,935] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.9839438e-20 1.8950285e-20 6.5471332e-17 5.7777971e-19 1.0000000e+00
 1.3397118e-21 7.3010822e-21], sum to 1.0000
[2019-04-06 22:37:40,935] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4415
[2019-04-06 22:37:41,058] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 47.0, 123.0, 170.5, 26.0, 24.93705125787067, 0.3037817383661635, 0.0, 1.0, 40070.84575385947], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2386800.0000, 
sim time next is 2388600.0000, 
raw observation next is [0.0, 47.0, 86.0, 341.0, 26.0, 24.98095460546822, 0.3184827947604267, 0.0, 1.0, 22439.957366114773], 
processed observation next is [0.0, 0.6521739130434783, 0.46260387811634357, 0.47, 0.2866666666666667, 0.37679558011049724, 0.6666666666666666, 0.5817462171223516, 0.606160931586809, 0.0, 1.0, 0.10685693983864178], 
reward next is 0.8931, 
noisyNet noise sample is [array([-0.94308317], dtype=float32), 0.5410681]. 
=============================================
[2019-04-06 22:37:41,704] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.9584882e-20 4.0686941e-19 1.0830866e-15 2.3190073e-18 1.0000000e+00
 2.1183508e-21 3.2520603e-19], sum to 1.0000
[2019-04-06 22:37:41,704] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6613
[2019-04-06 22:37:41,729] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 47.0, 182.5, 58.0, 26.0, 25.71945801551436, 0.3013663453632665, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2545200.0000, 
sim time next is 2547000.0000, 
raw observation next is [0.2500000000000001, 43.0, 232.0, 71.0, 26.0, 25.68309325100917, 0.3192747609446805, 1.0, 1.0, 12454.781382346364], 
processed observation next is [1.0, 0.4782608695652174, 0.46952908587257625, 0.43, 0.7733333333333333, 0.07845303867403315, 0.6666666666666666, 0.6402577709174307, 0.6064249203148935, 1.0, 1.0, 0.059308482773077924], 
reward next is 0.9407, 
noisyNet noise sample is [array([-0.937165], dtype=float32), -0.5349992]. 
=============================================
[2019-04-06 22:37:41,733] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[80.19364 ]
 [80.013466]
 [80.40479 ]
 [80.71789 ]
 [80.83792 ]], R is [[80.80714417]
 [80.99907684]
 [81.18908691]
 [81.37719727]
 [81.56342316]].
[2019-04-06 22:37:58,469] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1421599e-19 2.0703608e-21 2.6918729e-17 4.5114701e-21 1.0000000e+00
 2.5883051e-24 2.3250892e-21], sum to 1.0000
[2019-04-06 22:37:58,470] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8786
[2019-04-06 22:37:58,533] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.0, 62.0, 0.0, 0.0, 26.0, 25.22922068946401, 0.3564658685199449, 0.0, 1.0, 53761.18096202467], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2847600.0000, 
sim time next is 2849400.0000, 
raw observation next is [1.5, 67.0, 0.0, 0.0, 26.0, 25.22425540424171, 0.3497150496911699, 0.0, 1.0, 43272.57731378624], 
processed observation next is [1.0, 1.0, 0.5041551246537397, 0.67, 0.0, 0.0, 0.6666666666666666, 0.6020212836868092, 0.6165716832303899, 0.0, 1.0, 0.20605989197041066], 
reward next is 0.7939, 
noisyNet noise sample is [array([-0.95983624], dtype=float32), 0.591516]. 
=============================================
[2019-04-06 22:38:40,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:38:40,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:38:40,210] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run38
[2019-04-06 22:38:51,512] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-06 22:38:51,525] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:38:51,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:38:51,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run84
[2019-04-06 22:38:51,548] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:38:51,551] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:38:51,550] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:38:51,554] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:38:51,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run84
[2019-04-06 22:38:51,560] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run84
[2019-04-06 22:41:03,222] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 22:41:40,890] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 22:41:45,914] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 22:41:46,952] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1660000, evaluation results [1660000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 22:41:48,765] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.0733938e-19 7.8096464e-21 4.9232003e-17 3.4016210e-20 1.0000000e+00
 9.1983130e-24 7.7155660e-22], sum to 1.0000
[2019-04-06 22:41:48,765] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8775
[2019-04-06 22:41:49,142] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.35, 68.5, 30.0, 0.0, 26.0, 25.5349981677665, 0.3250236101028856, 1.0, 1.0, 33080.43957251752], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1960200.0000, 
sim time next is 1962000.0000, 
raw observation next is [-3.9, 75.0, 17.5, 1.0, 26.0, 24.60892310007942, 0.2902737137017036, 1.0, 1.0, 100955.0268799294], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.75, 0.058333333333333334, 0.0011049723756906078, 0.6666666666666666, 0.5507435916732849, 0.5967579045672345, 1.0, 1.0, 0.48073822323775905], 
reward next is 0.5193, 
noisyNet noise sample is [array([0.38114917], dtype=float32), -0.75977737]. 
=============================================
[2019-04-06 22:41:49,147] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[81.872795]
 [81.500694]
 [81.28269 ]
 [80.77218 ]
 [81.01386 ]], R is [[82.4972229 ]
 [82.51472473]
 [82.55821991]
 [82.46672058]
 [82.6420517 ]].
[2019-04-06 22:41:52,013] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.0995382e-21 5.7572417e-21 3.8293976e-17 3.9095125e-19 1.0000000e+00
 6.2061593e-23 5.5003689e-22], sum to 1.0000
[2019-04-06 22:41:52,013] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3965
[2019-04-06 22:41:52,117] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [9.5, 26.0, 0.0, 0.0, 26.0, 25.50675110261584, 0.3559049823061033, 0.0, 1.0, 22331.49899530163], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3648600.0000, 
sim time next is 3650400.0000, 
raw observation next is [10.0, 25.0, 0.0, 0.0, 26.0, 25.50097556096551, 0.3653154319510698, 0.0, 1.0, 33541.87004329206], 
processed observation next is [0.0, 0.2608695652173913, 0.739612188365651, 0.25, 0.0, 0.0, 0.6666666666666666, 0.6250812967471259, 0.6217718106503566, 0.0, 1.0, 0.15972319068234314], 
reward next is 0.8403, 
noisyNet noise sample is [array([1.9251524], dtype=float32), -0.7795676]. 
=============================================
[2019-04-06 22:41:59,977] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3585647e-19 1.1298819e-21 3.2544465e-17 4.3063410e-19 1.0000000e+00
 7.2615776e-23 2.0397329e-21], sum to 1.0000
[2019-04-06 22:41:59,977] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4753
[2019-04-06 22:42:00,095] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.5, 74.0, 0.0, 0.0, 26.0, 25.1048566725157, 0.3853761292217195, 0.0, 1.0, 42256.14380726274], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3367800.0000, 
sim time next is 3369600.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 26.0, 25.0218928407818, 0.3634981345643582, 0.0, 1.0, 41572.870478854515], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5851577367318166, 0.6211660448547861, 0.0, 1.0, 0.19796604989930722], 
reward next is 0.8020, 
noisyNet noise sample is [array([2.3236856], dtype=float32), 0.01585499]. 
=============================================
[2019-04-06 22:42:03,510] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.6737663e-20 1.6137910e-19 4.2008463e-18 2.8346029e-20 1.0000000e+00
 1.7672411e-23 8.6244928e-22], sum to 1.0000
[2019-04-06 22:42:03,510] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6981
[2019-04-06 22:42:03,606] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 77.0, 0.0, 0.0, 26.0, 24.87364227445928, 0.2763469555537154, 0.0, 1.0, 43543.01368574512], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3823200.0000, 
sim time next is 3825000.0000, 
raw observation next is [-5.0, 77.0, 0.0, 0.0, 26.0, 24.78272540490646, 0.2434265207446161, 0.0, 1.0, 43159.01797231498], 
processed observation next is [1.0, 0.2608695652173913, 0.32409972299168976, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5652271170755384, 0.5811421735815386, 0.0, 1.0, 0.2055191332014999], 
reward next is 0.7945, 
noisyNet noise sample is [array([-0.13838178], dtype=float32), -0.31941003]. 
=============================================
[2019-04-06 22:42:03,610] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[80.992805]
 [81.227066]
 [81.55903 ]
 [81.88168 ]
 [82.15555 ]], R is [[80.8418045 ]
 [80.82604218]
 [80.80905914]
 [80.79155731]
 [80.77468872]].
[2019-04-06 22:42:23,410] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:42:23,410] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:42:23,414] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run38
[2019-04-06 22:42:45,760] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:42:45,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:42:45,764] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run38
[2019-04-06 22:42:49,206] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.2089202e-23 3.7880369e-23 7.2713535e-18 1.1103763e-21 1.0000000e+00
 3.6229179e-25 2.4977772e-23], sum to 1.0000
[2019-04-06 22:42:49,208] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5372
[2019-04-06 22:42:49,295] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 47.0, 264.0, 113.0, 26.0, 26.24250151003524, 0.6071625901761127, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4545000.0000, 
sim time next is 4546800.0000, 
raw observation next is [3.0, 45.0, 208.5, 62.5, 26.0, 26.01541744065154, 0.5506750102753838, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.45, 0.695, 0.06906077348066299, 0.6666666666666666, 0.6679514533876283, 0.6835583367584612, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1605977], dtype=float32), -0.371676]. 
=============================================
[2019-04-06 22:43:00,256] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:43:00,256] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:43:00,259] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run38
[2019-04-06 22:43:05,326] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:43:05,326] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:43:05,344] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run38
[2019-04-06 22:43:07,805] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:43:07,805] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:43:07,808] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run38
[2019-04-06 22:43:11,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:43:11,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:43:11,004] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run38
[2019-04-06 22:43:18,179] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:43:18,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:43:18,183] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run38
[2019-04-06 22:43:29,466] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.5492160e-20 3.9054712e-20 7.8622114e-17 3.6513021e-19 1.0000000e+00
 6.2457776e-22 2.2394492e-20], sum to 1.0000
[2019-04-06 22:43:29,469] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5933
[2019-04-06 22:43:29,499] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 43.0, 74.5, 607.0, 26.0, 25.33869809021173, 0.4605521517329501, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3600000.0000, 
sim time next is 3601800.0000, 
raw observation next is [0.0, 41.0, 63.0, 515.0, 26.0, 25.2809736415907, 0.439677494061915, 0.0, 1.0, 9342.141211298913], 
processed observation next is [0.0, 0.6956521739130435, 0.46260387811634357, 0.41, 0.21, 0.569060773480663, 0.6666666666666666, 0.6067478034658915, 0.646559164687305, 0.0, 1.0, 0.04448638672047101], 
reward next is 0.9555, 
noisyNet noise sample is [array([0.9255735], dtype=float32), 0.27186814]. 
=============================================
[2019-04-06 22:43:31,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:43:31,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:43:31,172] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run38
[2019-04-06 22:43:38,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:43:38,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:43:38,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run38
[2019-04-06 22:43:45,271] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7788043e-18 9.0548012e-18 1.2391717e-15 4.1621487e-18 1.0000000e+00
 3.8537624e-20 8.6727726e-19], sum to 1.0000
[2019-04-06 22:43:45,272] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2711
[2019-04-06 22:43:45,317] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-14.75, 69.0, 0.0, 0.0, 26.0, 23.29841756995755, -0.1211944765796741, 0.0, 1.0, 47807.401556462246], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 351000.0000, 
sim time next is 352800.0000, 
raw observation next is [-15.0, 69.0, 0.0, 0.0, 26.0, 23.26602886048717, -0.1446413529439553, 0.0, 1.0, 48209.79621882003], 
processed observation next is [1.0, 0.08695652173913043, 0.04709141274238226, 0.69, 0.0, 0.0, 0.6666666666666666, 0.438835738373931, 0.4517862156853482, 0.0, 1.0, 0.2295704581848573], 
reward next is 0.7704, 
noisyNet noise sample is [array([-0.14573732], dtype=float32), 1.3022712]. 
=============================================
[2019-04-06 22:43:48,323] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.1012262e-22 1.8286830e-22 2.2464664e-19 1.0997822e-22 1.0000000e+00
 1.0353541e-24 4.8048465e-24], sum to 1.0000
[2019-04-06 22:43:48,323] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3069
[2019-04-06 22:43:48,423] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 79.0, 0.0, 0.0, 26.0, 25.09733027245973, 0.4838866437387281, 0.0, 1.0, 133652.80577523774], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3443400.0000, 
sim time next is 3445200.0000, 
raw observation next is [1.0, 79.0, 0.0, 0.0, 26.0, 25.43082664348466, 0.5524235683512718, 0.0, 1.0, 61111.83354477424], 
processed observation next is [1.0, 0.9130434782608695, 0.4903047091412743, 0.79, 0.0, 0.0, 0.6666666666666666, 0.6192355536237217, 0.684141189450424, 0.0, 1.0, 0.2910087311655916], 
reward next is 0.7090, 
noisyNet noise sample is [array([-0.65131956], dtype=float32), 0.14406258]. 
=============================================
[2019-04-06 22:44:01,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3815918e-19 8.3712791e-20 1.8309980e-17 8.7247371e-19 1.0000000e+00
 3.4717927e-22 4.2258969e-21], sum to 1.0000
[2019-04-06 22:44:01,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3916
[2019-04-06 22:44:01,392] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [15.8, 88.0, 0.0, 0.0, 26.0, 24.0049826441485, 0.2456462007426482, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1218600.0000, 
sim time next is 1220400.0000, 
raw observation next is [15.5, 93.0, 0.0, 0.0, 26.0, 23.92211593293877, 0.2303064331286534, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.8919667590027703, 0.93, 0.0, 0.0, 0.6666666666666666, 0.4935096610782308, 0.5767688110428845, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3401794], dtype=float32), -0.47964123]. 
=============================================
[2019-04-06 22:44:26,634] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 22:44:26,644] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:44:26,644] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:44:26,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run85
[2019-04-06 22:44:26,689] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:44:26,698] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:44:26,702] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run85
[2019-04-06 22:44:26,726] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:44:26,728] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:44:26,732] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run85
[2019-04-06 22:44:48,250] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15014769]
[2019-04-06 22:44:48,250] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [0.0, 37.0, 75.0, 0.0, 26.0, 25.59506559493416, 0.2857617517574293, 1.0, 1.0, 8032.259575345291]
[2019-04-06 22:44:48,250] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:44:48,251] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [8.1072292e-19 2.5809762e-19 5.7223333e-16 2.6240733e-18 1.0000000e+00
 3.1327862e-21 1.0214420e-19], sampled 0.5735269409272402
[2019-04-06 22:45:05,466] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15014769]
[2019-04-06 22:45:05,467] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [1.4973551625, 85.42201348, 0.0, 0.0, 26.0, 25.39398106283578, 0.5730596926190796, 0.0, 1.0, 50966.631359789695]
[2019-04-06 22:45:05,467] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 22:45:05,467] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [6.3041800e-23 8.9093951e-24 1.3345055e-19 1.5246321e-22 1.0000000e+00
 3.6898648e-26 1.8134191e-24], sampled 0.02448731455789599
[2019-04-06 22:46:39,781] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 22:47:19,183] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 22:47:25,876] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 22:47:26,915] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 1680000, evaluation results [1680000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 22:47:39,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:47:39,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:47:39,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run38
[2019-04-06 22:47:40,958] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.24173163e-21 3.61582860e-21 4.73127326e-17 1.60274800e-19
 1.00000000e+00 9.16141302e-22 1.12309284e-20], sum to 1.0000
[2019-04-06 22:47:40,958] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0162
[2019-04-06 22:47:41,045] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 40.0, 0.0, 0.0, 26.0, 25.3801731583332, 0.3983494772838179, 0.0, 1.0, 58637.634077014074], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4910400.0000, 
sim time next is 4912200.0000, 
raw observation next is [1.0, 38.0, 0.0, 0.0, 26.0, 25.54330807217976, 0.3897504189774068, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.4903047091412743, 0.38, 0.0, 0.0, 0.6666666666666666, 0.6286090060149799, 0.6299168063258023, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.018815], dtype=float32), 0.6291396]. 
=============================================
[2019-04-06 22:47:55,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:47:55,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:47:55,284] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run38
[2019-04-06 22:47:56,648] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8844304e-21 7.1944423e-22 3.5887750e-19 2.8173747e-21 1.0000000e+00
 2.9499911e-23 2.8617622e-22], sum to 1.0000
[2019-04-06 22:47:56,649] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7117
[2019-04-06 22:47:56,957] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.3, 70.0, 232.0, 10.0, 26.0, 25.71274198182224, 0.302201319831109, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1942200.0000, 
sim time next is 1944000.0000, 
raw observation next is [-5.0, 65.0, 229.5, 7.0, 26.0, 25.6889257838243, 0.3449375629843592, 1.0, 1.0, 63157.593688550325], 
processed observation next is [1.0, 0.5217391304347826, 0.32409972299168976, 0.65, 0.765, 0.0077348066298342545, 0.6666666666666666, 0.6407438153186916, 0.6149791876614531, 1.0, 1.0, 0.3007504461359539], 
reward next is 0.6992, 
noisyNet noise sample is [array([1.6953524], dtype=float32), 1.3299781]. 
=============================================
[2019-04-06 22:47:56,979] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[82.3139  ]
 [82.73346 ]
 [83.041115]
 [83.14256 ]
 [83.08958 ]], R is [[82.25740051]
 [82.43482971]
 [82.61048126]
 [82.78437805]
 [82.85556793]].
[2019-04-06 22:48:08,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:48:08,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:48:08,376] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run38
[2019-04-06 22:48:24,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:48:24,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:48:24,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run38
[2019-04-06 22:48:29,217] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:48:29,217] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:48:29,221] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run38
[2019-04-06 22:48:35,734] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:48:35,734] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:48:35,738] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run38
[2019-04-06 22:49:03,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1036100e-20 1.8721865e-20 2.0177441e-16 1.3365942e-19 1.0000000e+00
 1.8629161e-22 4.9361874e-20], sum to 1.0000
[2019-04-06 22:49:03,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4425
[2019-04-06 22:49:04,010] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.2, 72.0, 138.5, 0.0, 26.0, 25.28164876803787, 0.2222122222645382, 1.0, 1.0, 27809.62291120701], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 212400.0000, 
sim time next is 214200.0000, 
raw observation next is [-5.6, 68.5, 153.0, 0.0, 26.0, 25.27863313999471, 0.2277533283689925, 1.0, 1.0, 25998.280182644234], 
processed observation next is [1.0, 0.4782608695652174, 0.30747922437673136, 0.685, 0.51, 0.0, 0.6666666666666666, 0.6065527616662258, 0.5759177761229975, 1.0, 1.0, 0.12380133420306778], 
reward next is 0.8762, 
noisyNet noise sample is [array([0.4141021], dtype=float32), -1.2810303]. 
=============================================
[2019-04-06 22:49:51,666] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8105954e-22 1.1446274e-21 8.8576750e-18 2.0876190e-20 1.0000000e+00
 8.1598030e-23 1.4931425e-22], sum to 1.0000
[2019-04-06 22:49:51,666] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9742
[2019-04-06 22:49:51,700] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.0, 53.5, 121.0, 822.0, 26.0, 25.21081893293099, 0.3967899510587167, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4275000.0000, 
sim time next is 4276800.0000, 
raw observation next is [7.0, 52.0, 120.5, 834.5, 26.0, 25.20452517166166, 0.4048336811812807, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.6565096952908588, 0.52, 0.40166666666666667, 0.9220994475138121, 0.6666666666666666, 0.6003770976384718, 0.6349445603937602, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1918969], dtype=float32), -0.8093506]. 
=============================================
[2019-04-06 22:50:07,606] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-06 22:50:07,609] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:50:07,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:50:07,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run86
[2019-04-06 22:50:07,634] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:50:07,637] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:50:07,638] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:50:07,638] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:50:07,645] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run86
[2019-04-06 22:50:07,646] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run86
[2019-04-06 22:50:47,833] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15016565]
[2019-04-06 22:50:47,833] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [0.8, 94.5, 18.0, 0.0, 26.0, 25.69458516720178, 0.4853172651329179, 1.0, 1.0, 17429.35810155685]
[2019-04-06 22:50:47,833] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:50:47,834] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.8825467e-22 1.0617370e-22 9.2152997e-19 1.5753239e-21 1.0000000e+00
 7.0151034e-25 3.4841430e-23], sampled 0.5464077596315717
[2019-04-06 22:52:22,065] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 22:53:00,523] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 22:53:07,154] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 22:53:08,233] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1700000, evaluation results [1700000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 22:53:25,072] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5504653e-22 1.8893037e-21 1.1355619e-17 1.2362642e-21 1.0000000e+00
 2.9809285e-24 1.3911779e-22], sum to 1.0000
[2019-04-06 22:53:25,072] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0342
[2019-04-06 22:53:25,151] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 77.0, 0.0, 0.0, 26.0, 24.87364227445928, 0.2763469555537154, 0.0, 1.0, 43543.01368574512], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3823200.0000, 
sim time next is 3825000.0000, 
raw observation next is [-5.0, 77.0, 0.0, 0.0, 26.0, 24.78272540490646, 0.2434265207446161, 0.0, 1.0, 43159.01797231498], 
processed observation next is [1.0, 0.2608695652173913, 0.32409972299168976, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5652271170755384, 0.5811421735815386, 0.0, 1.0, 0.2055191332014999], 
reward next is 0.7945, 
noisyNet noise sample is [array([-1.0680443], dtype=float32), -0.24988279]. 
=============================================
[2019-04-06 22:53:25,171] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[83.92882]
 [84.17349]
 [84.5166 ]
 [84.85267]
 [85.13864]], R is [[83.74170685]
 [83.69694519]
 [83.65125275]
 [83.60533142]
 [83.56032562]].
[2019-04-06 22:53:36,581] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5972871e-23 1.6774520e-24 1.1760448e-19 1.5570761e-23 1.0000000e+00
 3.0750324e-27 5.3131619e-26], sum to 1.0000
[2019-04-06 22:53:36,581] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9371
[2019-04-06 22:53:36,740] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.3, 92.0, 15.5, 0.0, 26.0, 25.49240972187731, 0.4995707487540709, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1670400.0000, 
sim time next is 1672200.0000, 
raw observation next is [2.75, 92.0, 30.0, 0.0, 26.0, 25.61121799678467, 0.5147709927862518, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.5387811634349031, 0.92, 0.1, 0.0, 0.6666666666666666, 0.6342681663987225, 0.6715903309287506, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0545679], dtype=float32), 0.21214342]. 
=============================================
[2019-04-06 22:53:41,371] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:53:41,371] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:53:41,375] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run39
[2019-04-06 22:53:52,452] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.2116697e-21 3.1058110e-21 4.0325237e-18 5.9083128e-21 1.0000000e+00
 1.5249637e-22 1.6100930e-22], sum to 1.0000
[2019-04-06 22:53:52,452] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9156
[2019-04-06 22:53:52,566] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.65, 63.5, 137.0, 0.0, 26.0, 25.54630111577517, 0.3306305441716627, 1.0, 1.0, 22865.438722506373], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1949400.0000, 
sim time next is 1951200.0000, 
raw observation next is [-3.4, 62.0, 124.5, 0.0, 26.0, 25.74432708486339, 0.3451868592906828, 1.0, 1.0, 15370.067427184034], 
processed observation next is [1.0, 0.6086956521739131, 0.368421052631579, 0.62, 0.415, 0.0, 0.6666666666666666, 0.6453605904052825, 0.6150622864302276, 1.0, 1.0, 0.07319079727230493], 
reward next is 0.9268, 
noisyNet noise sample is [array([0.17097197], dtype=float32), -0.6850544]. 
=============================================
[2019-04-06 22:54:10,823] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.01260158e-24 3.36213627e-25 1.25039384e-20 1.13643381e-23
 1.00000000e+00 3.69627287e-27 2.48776161e-25], sum to 1.0000
[2019-04-06 22:54:10,823] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0192
[2019-04-06 22:54:10,847] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.6, 29.0, 116.5, 847.5, 26.0, 27.12875569066939, 0.9203936054687345, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4366800.0000, 
sim time next is 4368600.0000, 
raw observation next is [14.55, 30.0, 115.0, 842.0, 26.0, 27.86224241741284, 1.045263407407878, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.865650969529086, 0.3, 0.38333333333333336, 0.9303867403314917, 0.6666666666666666, 0.8218535347844034, 0.848421135802626, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3680177], dtype=float32), 1.698058]. 
=============================================
[2019-04-06 22:54:12,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0873743e-17 1.9027669e-18 9.7346056e-17 2.1773344e-18 1.0000000e+00
 7.5408935e-21 1.2909527e-19], sum to 1.0000
[2019-04-06 22:54:12,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3811
[2019-04-06 22:54:12,526] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.75, 50.5, 0.0, 0.0, 26.0, 24.2846251320811, 0.07842324474098407, 0.0, 1.0, 43427.19554952405], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2424600.0000, 
sim time next is 2426400.0000, 
raw observation next is [-7.3, 53.0, 0.0, 0.0, 26.0, 24.1314386218806, 0.0451547282835044, 0.0, 1.0, 43523.79317193197], 
processed observation next is [0.0, 0.08695652173913043, 0.26038781163434904, 0.53, 0.0, 0.0, 0.6666666666666666, 0.5109532184900502, 0.5150515760945015, 0.0, 1.0, 0.2072561579615808], 
reward next is 0.7927, 
noisyNet noise sample is [array([-0.8062798], dtype=float32), 0.5674308]. 
=============================================
[2019-04-06 22:54:14,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:54:14,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:54:14,878] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run39
[2019-04-06 22:54:25,254] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8495631e-21 2.8630384e-23 4.3454672e-19 9.9012728e-23 1.0000000e+00
 4.8857065e-25 2.2850365e-22], sum to 1.0000
[2019-04-06 22:54:25,258] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4081
[2019-04-06 22:54:25,569] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.7, 93.0, 85.5, 0.0, 26.0, 24.29945537470929, 0.09293300960841822, 0.0, 1.0, 28724.54696943832], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 43200.0000, 
sim time next is 45000.0000, 
raw observation next is [8.0, 89.5, 96.0, 0.0, 26.0, 24.33587326671604, 0.115697220550398, 0.0, 1.0, 33249.754627486785], 
processed observation next is [0.0, 0.5217391304347826, 0.6842105263157896, 0.895, 0.32, 0.0, 0.6666666666666666, 0.5279894388930032, 0.5385657401834659, 0.0, 1.0, 0.15833216489279422], 
reward next is 0.8417, 
noisyNet noise sample is [array([-0.7650577], dtype=float32), -0.7147738]. 
=============================================
[2019-04-06 22:54:25,580] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[90.30571 ]
 [89.93175 ]
 [89.455734]
 [88.61954 ]
 [87.80534 ]], R is [[90.46097565]
 [90.41958618]
 [90.41278839]
 [90.23949432]
 [90.06533813]].
[2019-04-06 22:54:31,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:54:31,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:54:31,620] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run39
[2019-04-06 22:54:36,982] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.9359461e-20 8.7472189e-22 2.5700647e-16 1.4184726e-19 1.0000000e+00
 1.8798778e-22 7.5615435e-22], sum to 1.0000
[2019-04-06 22:54:36,982] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7313
[2019-04-06 22:54:37,029] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.7, 49.0, 0.0, 0.0, 26.0, 24.97488895627242, 0.1691680635279124, 0.0, 1.0, 38402.75783826267], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2520000.0000, 
sim time next is 2521800.0000, 
raw observation next is [-2.0, 53.0, 0.0, 0.0, 26.0, 24.8241191941854, 0.1506002695370273, 0.0, 1.0, 38400.797494993756], 
processed observation next is [1.0, 0.17391304347826086, 0.40720221606648205, 0.53, 0.0, 0.0, 0.6666666666666666, 0.56867659951545, 0.5502000898456757, 0.0, 1.0, 0.1828609404523512], 
reward next is 0.8171, 
noisyNet noise sample is [array([0.4309506], dtype=float32), -1.1497579]. 
=============================================
[2019-04-06 22:54:46,521] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:54:46,521] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:54:46,636] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run39
[2019-04-06 22:54:50,434] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:54:50,434] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:54:50,438] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run39
[2019-04-06 22:54:55,493] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:54:55,493] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:54:55,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run39
[2019-04-06 22:54:55,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:54:55,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:54:55,855] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run39
[2019-04-06 22:54:56,914] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.6689181e-20 5.7645377e-21 4.2319205e-18 2.5604220e-19 1.0000000e+00
 7.2913853e-24 2.2726846e-21], sum to 1.0000
[2019-04-06 22:54:56,915] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8421
[2019-04-06 22:54:56,982] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 68.0, 0.0, 0.0, 26.0, 24.41973735155766, 0.1400126421142812, 0.0, 1.0, 39573.89768532833], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4865400.0000, 
sim time next is 4867200.0000, 
raw observation next is [-4.0, 71.0, 70.5, 156.5, 26.0, 24.36356347446054, 0.1585495546977057, 0.0, 1.0, 39443.69278231362], 
processed observation next is [0.0, 0.34782608695652173, 0.3518005540166205, 0.71, 0.235, 0.17292817679558012, 0.6666666666666666, 0.5302969562050451, 0.5528498515659019, 0.0, 1.0, 0.1878271084872077], 
reward next is 0.8122, 
noisyNet noise sample is [array([-0.7434677], dtype=float32), -3.0079682]. 
=============================================
[2019-04-06 22:55:01,666] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.6478180e-21 1.9973758e-21 1.1971617e-17 4.5262108e-20 1.0000000e+00
 1.7026928e-23 6.1479134e-22], sum to 1.0000
[2019-04-06 22:55:01,666] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6927
[2019-04-06 22:55:01,728] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 26.0, 25.06760816997892, 0.355091782145153, 0.0, 1.0, 41427.187082374505], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3373200.0000, 
sim time next is 3375000.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 26.0, 24.99246940215512, 0.3248759537483213, 0.0, 1.0, 41199.445086335145], 
processed observation next is [1.0, 0.043478260869565216, 0.296398891966759, 0.77, 0.0, 0.0, 0.6666666666666666, 0.5827057835129267, 0.6082919845827738, 0.0, 1.0, 0.19618783374445306], 
reward next is 0.8038, 
noisyNet noise sample is [array([0.9160193], dtype=float32), -0.862895]. 
=============================================
[2019-04-06 22:55:01,745] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[81.83279 ]
 [81.74259 ]
 [81.66579 ]
 [81.517586]
 [81.21425 ]], R is [[81.97272491]
 [81.95572662]
 [81.93876648]
 [81.92140961]
 [81.90097809]].
[2019-04-06 22:55:04,572] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.4889236e-20 1.7221939e-21 2.6033063e-17 5.4044504e-20 1.0000000e+00
 4.0241691e-23 7.8671460e-21], sum to 1.0000
[2019-04-06 22:55:04,572] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2891
[2019-04-06 22:55:04,586] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.0, 23.0, 0.0, 0.0, 26.0, 26.22348350473622, 0.6209000405981525, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4995000.0000, 
sim time next is 4996800.0000, 
raw observation next is [6.0, 23.0, 0.0, 0.0, 26.0, 26.04839705221967, 0.587017060254821, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.6288088642659281, 0.23, 0.0, 0.0, 0.6666666666666666, 0.6706997543516392, 0.6956723534182737, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5494415], dtype=float32), 1.4132929]. 
=============================================
[2019-04-06 22:55:09,033] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.5794160e-23 1.9934308e-23 2.5890115e-20 6.1076811e-23 1.0000000e+00
 9.7579099e-26 9.1516187e-25], sum to 1.0000
[2019-04-06 22:55:09,034] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7454
[2019-04-06 22:55:09,047] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.85, 19.0, 0.0, 0.0, 26.0, 26.94011389620564, 0.8161660899122176, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5088600.0000, 
sim time next is 5090400.0000, 
raw observation next is [8.7, 19.0, 0.0, 0.0, 26.0, 26.77392777301225, 0.7796437692863494, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.703601108033241, 0.19, 0.0, 0.0, 0.6666666666666666, 0.7311606477510209, 0.7598812564287831, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8158855], dtype=float32), 0.11111455]. 
=============================================
[2019-04-06 22:55:10,291] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:55:10,292] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:55:10,295] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run39
[2019-04-06 22:55:20,491] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:55:20,491] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:55:20,495] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run39
[2019-04-06 22:55:28,614] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:55:28,615] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:55:28,618] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run39
[2019-04-06 22:55:32,099] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1620662e-23 2.8071039e-24 5.1580083e-19 7.2749971e-23 1.0000000e+00
 2.0302592e-24 3.5412637e-24], sum to 1.0000
[2019-04-06 22:55:32,100] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9643
[2019-04-06 22:55:32,167] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 92.0, 101.0, 653.0, 26.0, 26.17344068649289, 0.6515067193470717, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3231000.0000, 
sim time next is 3232800.0000, 
raw observation next is [-3.0, 92.0, 105.0, 702.5, 26.0, 26.32269299774201, 0.6766164564843377, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.92, 0.35, 0.7762430939226519, 0.6666666666666666, 0.6935577498118342, 0.7255388188281126, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3161786], dtype=float32), 1.1939288]. 
=============================================
[2019-04-06 22:55:35,864] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 22:55:35,864] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:55:35,864] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:55:35,898] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 22:55:35,898] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 22:55:35,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:55:35,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:55:35,905] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run87
[2019-04-06 22:55:35,927] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run87
[2019-04-06 22:55:35,944] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run87
[2019-04-06 22:57:27,205] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15070423]
[2019-04-06 22:57:27,206] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [3.15, 44.0, 198.0, 375.0, 26.0, 26.000675626775, 0.5423946533073208, 1.0, 1.0, 0.0]
[2019-04-06 22:57:27,206] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 22:57:27,207] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.2920211e-20 3.2280174e-21 1.6357331e-17 4.3559706e-20 1.0000000e+00
 3.6362272e-23 1.3217268e-21], sampled 0.7750516682710692
[2019-04-06 22:57:55,210] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 22:58:35,173] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 22:58:38,229] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 22:58:39,267] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 1720000, evaluation results [1720000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 22:58:48,788] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.4188824e-21 1.4294872e-21 1.6281383e-17 5.4510136e-21 1.0000000e+00
 1.7769832e-22 5.6619709e-23], sum to 1.0000
[2019-04-06 22:58:48,788] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8426
[2019-04-06 22:58:48,878] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 41.5, 0.0, 0.0, 26.0, 25.53958222216713, 0.4454231859807916, 0.0, 1.0, 34528.53969060517], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4141800.0000, 
sim time next is 4143600.0000, 
raw observation next is [0.0, 43.0, 0.0, 0.0, 26.0, 25.32423756532482, 0.4617483940628076, 0.0, 1.0, 103666.89581905385], 
processed observation next is [1.0, 1.0, 0.46260387811634357, 0.43, 0.0, 0.0, 0.6666666666666666, 0.6103531304437352, 0.6539161313542692, 0.0, 1.0, 0.4936518848526374], 
reward next is 0.5063, 
noisyNet noise sample is [array([-1.0646515], dtype=float32), 1.5471807]. 
=============================================
[2019-04-06 22:59:27,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9802175e-22 3.6642872e-22 7.5870718e-18 2.9269938e-20 1.0000000e+00
 8.4498347e-24 8.5136151e-22], sum to 1.0000
[2019-04-06 22:59:27,811] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9046
[2019-04-06 22:59:27,903] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.0, 24.0, 120.0, 862.5, 26.0, 27.06780773907184, 0.6262892303214521, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4971600.0000, 
sim time next is 4973400.0000, 
raw observation next is [7.5, 25.0, 117.0, 860.0, 26.0, 26.50663066045843, 0.6827323577048453, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.6703601108033241, 0.25, 0.39, 0.9502762430939227, 0.6666666666666666, 0.7088858883715359, 0.7275774525682818, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.66936076], dtype=float32), -0.13866234]. 
=============================================
[2019-04-06 22:59:34,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:59:34,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:59:34,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run39
[2019-04-06 22:59:35,576] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5502439e-20 1.5834696e-21 6.6200076e-19 3.9613308e-21 1.0000000e+00
 5.2619949e-24 9.4357584e-23], sum to 1.0000
[2019-04-06 22:59:35,576] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0508
[2019-04-06 22:59:35,723] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.7, 82.0, 89.0, 135.0, 26.0, 24.87012992404298, 0.271339985947782, 0.0, 1.0, 35808.808266370455], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 559800.0000, 
sim time next is 561600.0000, 
raw observation next is [-0.8, 81.0, 109.5, 265.5, 26.0, 24.83444883640875, 0.3077431383187642, 0.0, 1.0, 54258.136838019476], 
processed observation next is [0.0, 0.5217391304347826, 0.4404432132963989, 0.81, 0.365, 0.29337016574585634, 0.6666666666666666, 0.5695374030340625, 0.6025810461062547, 0.0, 1.0, 0.2583720801810451], 
reward next is 0.7416, 
noisyNet noise sample is [array([0.05096702], dtype=float32), -0.09314356]. 
=============================================
[2019-04-06 22:59:44,307] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:59:44,307] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:59:44,311] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run39
[2019-04-06 22:59:55,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 22:59:55,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 22:59:55,436] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run39
[2019-04-06 23:00:03,626] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.6838810e-21 1.6421336e-19 1.1535109e-16 7.1279039e-20 1.0000000e+00
 8.5070855e-23 7.9653747e-22], sum to 1.0000
[2019-04-06 23:00:03,627] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4836
[2019-04-06 23:00:03,698] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.1, 92.5, 0.0, 0.0, 26.0, 23.85188883901559, 0.08932634649217319, 0.0, 1.0, 41899.96008219374], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4779000.0000, 
sim time next is 4780800.0000, 
raw observation next is [-6.0, 92.0, 62.0, 209.5, 26.0, 23.79535813880517, 0.1128093166396828, 0.0, 1.0, 41768.49630383199], 
processed observation next is [0.0, 0.34782608695652173, 0.296398891966759, 0.92, 0.20666666666666667, 0.23149171270718233, 0.6666666666666666, 0.4829465115670975, 0.537603105546561, 0.0, 1.0, 0.198897601446819], 
reward next is 0.8011, 
noisyNet noise sample is [array([1.1222805], dtype=float32), -0.56377465]. 
=============================================
[2019-04-06 23:00:11,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:00:11,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:00:11,140] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run39
[2019-04-06 23:00:18,846] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:00:18,846] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:00:18,867] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run39
[2019-04-06 23:00:20,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:00:20,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:00:20,464] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run39
[2019-04-06 23:00:43,001] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5827202e-21 4.3836710e-22 1.0183301e-18 1.7629335e-21 1.0000000e+00
 3.4620952e-24 4.5836494e-22], sum to 1.0000
[2019-04-06 23:00:43,001] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6360
[2019-04-06 23:00:43,227] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.8, 83.0, 119.0, 0.0, 26.0, 24.96449927967818, 0.3463207507462213, 0.0, 1.0, 47951.173857913294], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1776600.0000, 
sim time next is 1778400.0000, 
raw observation next is [-2.8, 83.0, 109.0, 0.0, 26.0, 25.06010929888711, 0.3534175665629782, 0.0, 1.0, 22840.699361447], 
processed observation next is [0.0, 0.6086956521739131, 0.38504155124653744, 0.83, 0.36333333333333334, 0.0, 0.6666666666666666, 0.5883424415739258, 0.6178058555209928, 0.0, 1.0, 0.10876523505450952], 
reward next is 0.8912, 
noisyNet noise sample is [array([-1.9530145], dtype=float32), 1.100534]. 
=============================================
[2019-04-06 23:01:09,028] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.5373048e-22 4.9379714e-22 3.0445588e-18 1.8918937e-20 1.0000000e+00
 3.3964406e-24 4.2698709e-23], sum to 1.0000
[2019-04-06 23:01:09,028] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1059
[2019-04-06 23:01:09,183] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 72.0, 14.5, 0.0, 26.0, 24.9825817038496, 0.2257825027469351, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 892800.0000, 
sim time next is 894600.0000, 
raw observation next is [0.55, 76.0, 29.0, 0.0, 26.0, 25.11637423675631, 0.271188672065881, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4778393351800555, 0.76, 0.09666666666666666, 0.0, 0.6666666666666666, 0.5930311863963592, 0.5903962240219603, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.19662349], dtype=float32), -0.67697996]. 
=============================================
[2019-04-06 23:01:10,421] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.03954385e-19 9.22228835e-21 8.62678506e-17 8.95616496e-20
 1.00000000e+00 4.32409404e-23 5.57398321e-21], sum to 1.0000
[2019-04-06 23:01:10,422] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6124
[2019-04-06 23:01:10,728] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 71.0, 19.0, 0.0, 26.0, 25.64413645531486, 0.4001973030437097, 1.0, 1.0, 64733.19297669977], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2221200.0000, 
sim time next is 2223000.0000, 
raw observation next is [-4.5, 69.5, 0.0, 0.0, 26.0, 24.62710299449316, 0.2786265530011779, 1.0, 1.0, 89505.84754044667], 
processed observation next is [1.0, 0.7391304347826086, 0.3379501385041552, 0.695, 0.0, 0.0, 0.6666666666666666, 0.5522585828744301, 0.5928755176670593, 1.0, 1.0, 0.4262183216211746], 
reward next is 0.5738, 
noisyNet noise sample is [array([0.3227749], dtype=float32), -0.57613426]. 
=============================================
[2019-04-06 23:01:10,745] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[82.0041  ]
 [81.65308 ]
 [82.3952  ]
 [83.440575]
 [83.0914  ]], R is [[81.71520996]
 [81.5898056 ]
 [81.77391052]
 [81.95616913]
 [81.94002533]].
[2019-04-06 23:01:15,802] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0186753e-19 4.6483980e-21 1.7103276e-17 1.2470927e-20 1.0000000e+00
 5.9905302e-23 2.7903785e-21], sum to 1.0000
[2019-04-06 23:01:15,802] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9157
[2019-04-06 23:01:16,075] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 26.0, 25.02751294155262, 0.3730266370424637, 0.0, 1.0, 88236.91700020223], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2145600.0000, 
sim time next is 2147400.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 26.0, 25.13693707753088, 0.4101449025403063, 0.0, 1.0, 85194.23674603034], 
processed observation next is [1.0, 0.8695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5947447564609067, 0.6367149675134355, 0.0, 1.0, 0.40568684164776353], 
reward next is 0.5943, 
noisyNet noise sample is [array([-0.35644153], dtype=float32), -0.87492806]. 
=============================================
[2019-04-06 23:01:21,054] A3C_AGENT_WORKER-Thread-7 INFO:Evaluating...
[2019-04-06 23:01:21,057] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:01:21,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:01:21,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run88
[2019-04-06 23:01:21,097] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:01:21,114] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:01:21,115] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:01:21,117] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:01:21,122] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run88
[2019-04-06 23:01:21,119] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run88
[2019-04-06 23:03:30,307] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15060148]
[2019-04-06 23:03:30,307] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-0.907549088, 73.09456833, 0.0, 0.0, 26.0, 25.6343650897242, 0.5839127921707329, 0.0, 1.0, 41351.25822558371]
[2019-04-06 23:03:30,308] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 23:03:30,310] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [5.6320765e-21 1.1354730e-21 4.7738024e-18 1.5723589e-20 1.0000000e+00
 1.1101464e-23 3.8554051e-22], sampled 0.5168730934131421
[2019-04-06 23:03:38,760] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 23:04:15,335] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 23:04:22,363] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 23:04:23,402] A3C_AGENT_WORKER-Thread-7 INFO:Global step: 1740000, evaluation results [1740000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 23:04:26,485] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3386980e-20 2.5716861e-21 6.6266339e-17 6.0447108e-21 1.0000000e+00
 3.4025484e-24 5.4400631e-22], sum to 1.0000
[2019-04-06 23:04:26,485] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1267
[2019-04-06 23:04:26,571] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.5, 84.5, 0.0, 0.0, 26.0, 24.69570084102215, 0.2803840631001179, 0.0, 1.0, 43045.5917819876], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2946600.0000, 
sim time next is 2948400.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 26.0, 24.64397279523831, 0.2656844910296977, 0.0, 1.0, 42838.98987209386], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.84, 0.0, 0.0, 0.6666666666666666, 0.5536643996031924, 0.5885614970098992, 0.0, 1.0, 0.2039951898671136], 
reward next is 0.7960, 
noisyNet noise sample is [array([1.1114492], dtype=float32), 0.013738278]. 
=============================================
[2019-04-06 23:04:54,482] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4366282e-19 1.7365308e-19 3.3345368e-16 1.9396951e-19 1.0000000e+00
 1.2511566e-21 9.0411883e-21], sum to 1.0000
[2019-04-06 23:04:54,482] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7974
[2019-04-06 23:04:54,566] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 73.5, 0.0, 0.0, 26.0, 23.86301472143329, 0.01674785228857173, 0.0, 1.0, 40163.71012383811], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3043800.0000, 
sim time next is 3045600.0000, 
raw observation next is [-6.0, 70.0, 0.0, 0.0, 26.0, 23.78796573348578, -0.002759649973174585, 0.0, 1.0, 40165.4737232261], 
processed observation next is [0.0, 0.2608695652173913, 0.296398891966759, 0.7, 0.0, 0.0, 0.6666666666666666, 0.4823304777904817, 0.4990801166756085, 0.0, 1.0, 0.19126416058679097], 
reward next is 0.8087, 
noisyNet noise sample is [array([-2.1579244], dtype=float32), -1.4070395]. 
=============================================
[2019-04-06 23:05:21,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.4435235e-23 3.8503619e-23 5.1623217e-18 4.6609139e-22 1.0000000e+00
 2.7077339e-24 9.5395166e-24], sum to 1.0000
[2019-04-06 23:05:21,646] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6452
[2019-04-06 23:05:21,687] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.0, 25.5, 34.0, 304.0, 26.0, 27.50529530675639, 0.8256197751974917, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4987800.0000, 
sim time next is 4989600.0000, 
raw observation next is [6.0, 25.0, 17.0, 152.0, 26.0, 27.21153110534608, 0.6694150549200996, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6288088642659281, 0.25, 0.056666666666666664, 0.16795580110497238, 0.6666666666666666, 0.7676275921121732, 0.7231383516400332, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2898968], dtype=float32), 0.48489004]. 
=============================================
[2019-04-06 23:05:22,064] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.1719417e-20 2.8804045e-21 8.6549588e-19 1.4520711e-20 1.0000000e+00
 4.9203854e-24 3.0008062e-22], sum to 1.0000
[2019-04-06 23:05:22,064] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9180
[2019-04-06 23:05:22,204] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.8, 82.0, 123.0, 77.5, 26.0, 25.48072611973065, 0.3381969780966735, 1.0, 1.0, 6247.159222802203], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2106000.0000, 
sim time next is 2107800.0000, 
raw observation next is [-7.8, 82.0, 174.0, 118.0, 26.0, 25.66159515707759, 0.3846056576461008, 1.0, 1.0, 26286.945855584567], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.82, 0.58, 0.13038674033149172, 0.6666666666666666, 0.638466263089799, 0.6282018858820336, 1.0, 1.0, 0.12517593264564078], 
reward next is 0.8748, 
noisyNet noise sample is [array([2.5736043], dtype=float32), 1.4439574]. 
=============================================
[2019-04-06 23:05:27,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:05:27,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:05:27,464] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run40
[2019-04-06 23:05:34,301] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4975213e-22 2.3517506e-22 2.0988461e-20 9.7078018e-23 1.0000000e+00
 3.6603679e-26 3.1995476e-23], sum to 1.0000
[2019-04-06 23:05:34,301] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9148
[2019-04-06 23:05:34,377] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.5, 96.5, 0.0, 0.0, 26.0, 25.45410465247415, 0.5995548874792868, 0.0, 1.0, 58518.01476251527], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3198600.0000, 
sim time next is 3200400.0000, 
raw observation next is [1.0, 100.0, 0.0, 0.0, 26.0, 25.69193436808127, 0.613873469210989, 0.0, 1.0, 6250.028071174277], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6409945306734391, 0.7046244897369963, 0.0, 1.0, 0.029762038434163224], 
reward next is 0.9702, 
noisyNet noise sample is [array([0.84808844], dtype=float32), 0.37366816]. 
=============================================
[2019-04-06 23:05:55,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0096910e-21 2.7466460e-21 1.5299670e-17 1.5867780e-20 1.0000000e+00
 8.1339416e-24 1.1405913e-21], sum to 1.0000
[2019-04-06 23:05:55,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2084
[2019-04-06 23:05:55,548] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 50.0, 70.0, 534.0, 26.0, 26.60468620573909, 0.5961820356307692, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2736000.0000, 
sim time next is 2737800.0000, 
raw observation next is [-3.0, 50.0, 54.0, 454.0, 26.0, 26.01438905578488, 0.5037683075535228, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.3795013850415513, 0.5, 0.18, 0.5016574585635359, 0.6666666666666666, 0.6678657546487399, 0.6679227691845075, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8654071], dtype=float32), -0.5774312]. 
=============================================
[2019-04-06 23:05:55,999] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:05:56,000] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:05:56,003] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run40
[2019-04-06 23:05:56,606] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.4013693e-19 5.7199643e-20 1.8370638e-17 7.2701845e-19 1.0000000e+00
 2.3966270e-21 2.6878669e-20], sum to 1.0000
[2019-04-06 23:05:56,607] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7800
[2019-04-06 23:05:56,652] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 47.0, 0.0, 0.0, 26.0, 25.42298330721757, 0.3742948649108788, 0.0, 1.0, 42717.64263074147], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4228200.0000, 
sim time next is 4230000.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 26.0, 25.41053659470184, 0.3689087395037879, 0.0, 1.0, 42272.52162819905], 
processed observation next is [0.0, 1.0, 0.4903047091412743, 0.47, 0.0, 0.0, 0.6666666666666666, 0.6175447162251532, 0.6229695798345959, 0.0, 1.0, 0.2012977220390431], 
reward next is 0.7987, 
noisyNet noise sample is [array([1.0239811], dtype=float32), -0.26264158]. 
=============================================
[2019-04-06 23:05:56,659] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[78.44492 ]
 [78.39736 ]
 [78.467804]
 [78.33931 ]
 [78.56781 ]], R is [[78.5741806 ]
 [78.58502197]
 [78.66847992]
 [78.60176086]
 [78.70035553]].
[2019-04-06 23:06:01,986] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.4179866e-22 1.5748605e-22 8.0119250e-18 5.3354563e-21 1.0000000e+00
 3.0174245e-24 4.3591056e-23], sum to 1.0000
[2019-04-06 23:06:01,987] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7698
[2019-04-06 23:06:02,109] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.4, 72.5, 111.0, 66.0, 26.0, 25.64515558570582, 0.4764161249092442, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4523400.0000, 
sim time next is 4525200.0000, 
raw observation next is [0.0, 72.0, 117.0, 33.0, 26.0, 26.06685797531848, 0.5222597984844254, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.46260387811634357, 0.72, 0.39, 0.036464088397790057, 0.6666666666666666, 0.6722381646098734, 0.6740865994948084, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([3.0965965], dtype=float32), 0.13027872]. 
=============================================
[2019-04-06 23:06:21,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:06:21,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:06:21,272] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run40
[2019-04-06 23:06:31,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:06:31,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:06:31,191] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run40
[2019-04-06 23:06:37,102] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.14311010e-19 1.35441915e-20 1.00991308e-16 1.31805259e-19
 1.00000000e+00 1.36807010e-21 7.63983561e-20], sum to 1.0000
[2019-04-06 23:06:37,102] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0316
[2019-04-06 23:06:37,170] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 68.0, 0.0, 0.0, 26.0, 24.41973735155766, 0.1400126421142812, 0.0, 1.0, 39573.89768532833], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4865400.0000, 
sim time next is 4867200.0000, 
raw observation next is [-4.0, 71.0, 70.5, 156.5, 26.0, 24.36356347446054, 0.1585495546977057, 0.0, 1.0, 39443.69278231362], 
processed observation next is [0.0, 0.34782608695652173, 0.3518005540166205, 0.71, 0.235, 0.17292817679558012, 0.6666666666666666, 0.5302969562050451, 0.5528498515659019, 0.0, 1.0, 0.1878271084872077], 
reward next is 0.8122, 
noisyNet noise sample is [array([-0.9410936], dtype=float32), -1.1049069]. 
=============================================
[2019-04-06 23:06:39,153] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.0561434e-20 1.1696597e-20 4.1372371e-16 1.0173627e-19 1.0000000e+00
 1.7404342e-22 1.1192692e-20], sum to 1.0000
[2019-04-06 23:06:39,153] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8701
[2019-04-06 23:06:39,194] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 45.0, 102.0, 317.0, 26.0, 25.21751492750841, 0.3723090647416595, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4897800.0000, 
sim time next is 4899600.0000, 
raw observation next is [3.0, 45.0, 67.5, 252.0, 26.0, 25.1432764745138, 0.3392742343393951, 0.0, 1.0, 6226.803890076847], 
processed observation next is [0.0, 0.7391304347826086, 0.5457063711911359, 0.45, 0.225, 0.27845303867403315, 0.6666666666666666, 0.5952730395428167, 0.6130914114464651, 0.0, 1.0, 0.029651447095604033], 
reward next is 0.9703, 
noisyNet noise sample is [array([0.909582], dtype=float32), -0.940562]. 
=============================================
[2019-04-06 23:06:39,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:06:39,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:06:39,980] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run40
[2019-04-06 23:06:40,520] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-06 23:06:40,521] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:06:40,522] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:06:40,527] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run89
[2019-04-06 23:06:40,560] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:06:40,573] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:06:40,576] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:06:40,576] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:06:40,580] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run89
[2019-04-06 23:06:40,614] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run89
[2019-04-06 23:08:59,773] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 23:09:39,093] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 23:09:41,681] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 23:09:42,735] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 1760000, evaluation results [1760000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 23:09:48,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:09:48,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:09:48,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run40
[2019-04-06 23:09:55,511] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:09:55,511] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:09:55,539] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run40
[2019-04-06 23:10:06,922] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:10:06,922] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:10:06,967] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run40
[2019-04-06 23:10:20,951] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:10:20,952] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:10:20,955] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run40
[2019-04-06 23:10:24,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:10:24,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:10:24,992] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run40
[2019-04-06 23:10:30,982] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4193275e-20 3.4865017e-20 5.6010212e-17 1.1355006e-18 1.0000000e+00
 5.5326319e-21 3.7993595e-20], sum to 1.0000
[2019-04-06 23:10:30,982] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7659
[2019-04-06 23:10:31,282] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 38.0, 29.0, 555.0, 26.0, 25.76062661912154, 0.3996092482702513, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 403200.0000, 
sim time next is 405000.0000, 
raw observation next is [-8.9, 37.0, 21.0, 403.0, 26.0, 25.90203122949388, 0.4764481995097403, 1.0, 1.0, 101959.96649008016], 
processed observation next is [1.0, 0.6956521739130435, 0.21606648199445982, 0.37, 0.07, 0.4453038674033149, 0.6666666666666666, 0.6585026024578232, 0.6588160665032468, 1.0, 1.0, 0.48552364995276265], 
reward next is 0.5145, 
noisyNet noise sample is [array([0.64162505], dtype=float32), 1.4979591]. 
=============================================
[2019-04-06 23:10:31,285] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[74.60241]
 [75.25585]
 [75.82646]
 [76.35175]
 [76.35462]], R is [[74.58989716]
 [74.84400177]
 [75.0955658 ]
 [75.34461212]
 [75.29971313]].
[2019-04-06 23:10:41,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0175513e-22 3.2553428e-23 6.4331935e-19 2.7513875e-20 1.0000000e+00
 3.6049134e-25 2.9586786e-24], sum to 1.0000
[2019-04-06 23:10:41,334] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4332
[2019-04-06 23:10:41,422] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.55, 96.5, 0.0, 0.0, 26.0, 24.83486133541347, 0.2346316952631697, 0.0, 1.0, 40125.09312091048], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 516600.0000, 
sim time next is 518400.0000, 
raw observation next is [3.8, 97.0, 0.0, 0.0, 26.0, 24.88402442094871, 0.2392944599932561, 0.0, 1.0, 39853.58477820855], 
processed observation next is [0.0, 0.0, 0.5678670360110805, 0.97, 0.0, 0.0, 0.6666666666666666, 0.5736687017457257, 0.579764819997752, 0.0, 1.0, 0.18977897513432643], 
reward next is 0.8102, 
noisyNet noise sample is [array([-1.9993855], dtype=float32), -0.5799959]. 
=============================================
[2019-04-06 23:10:47,650] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3527678e-21 1.9828616e-20 2.2085536e-18 5.6726748e-22 1.0000000e+00
 6.6666931e-25 3.3386886e-22], sum to 1.0000
[2019-04-06 23:10:47,651] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8927
[2019-04-06 23:10:47,718] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.43367669916667, 0.4670464912587235, 0.0, 1.0, 34180.39320055914], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3544200.0000, 
sim time next is 3546000.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 26.0, 25.36527945233146, 0.4471240351740415, 0.0, 1.0, 46376.2684009597], 
processed observation next is [0.0, 0.043478260869565216, 0.40720221606648205, 0.6, 0.0, 0.0, 0.6666666666666666, 0.6137732876942884, 0.6490413450580138, 0.0, 1.0, 0.22083937333790332], 
reward next is 0.7792, 
noisyNet noise sample is [array([-1.1333802], dtype=float32), -2.2585578]. 
=============================================
[2019-04-06 23:10:47,735] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[82.29491]
 [83.61124]
 [85.33092]
 [85.84021]
 [85.67611]], R is [[81.08101654]
 [81.10744476]
 [81.10215759]
 [81.0761261 ]
 [80.81808472]].
[2019-04-06 23:11:12,771] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:11:12,771] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:11:12,800] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run40
[2019-04-06 23:11:26,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.3287557e-23 7.1472445e-25 4.5052638e-20 5.1965887e-23 1.0000000e+00
 2.9939184e-25 4.3574053e-25], sum to 1.0000
[2019-04-06 23:11:26,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4737
[2019-04-06 23:11:26,130] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.1, 73.0, 0.0, 0.0, 26.0, 25.78306584261765, 0.4502026418504956, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4309200.0000, 
sim time next is 4311000.0000, 
raw observation next is [4.949999999999999, 74.5, 0.0, 0.0, 26.0, 25.63950873762881, 0.4155987004354464, 0.0, 1.0, 10271.227759674724], 
processed observation next is [0.0, 0.9130434782608695, 0.5997229916897507, 0.745, 0.0, 0.0, 0.6666666666666666, 0.636625728135734, 0.6385329001451489, 0.0, 1.0, 0.04891060837940345], 
reward next is 0.9511, 
noisyNet noise sample is [array([1.4401214], dtype=float32), -0.38405293]. 
=============================================
[2019-04-06 23:11:26,145] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[88.89379 ]
 [89.112785]
 [89.13117 ]
 [87.80869 ]
 [85.95171 ]], R is [[88.52223206]
 [88.63700867]
 [88.75064087]
 [88.32969666]
 [87.73045349]].
[2019-04-06 23:11:29,507] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:11:29,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:11:29,536] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run40
[2019-04-06 23:11:37,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:11:37,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:11:37,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run40
[2019-04-06 23:11:57,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:11:57,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:11:57,704] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run40
[2019-04-06 23:12:00,356] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:12:00,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:12:00,370] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run40
[2019-04-06 23:12:05,093] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9262737e-23 1.5636169e-24 2.8627930e-19 7.7486266e-23 1.0000000e+00
 2.6023113e-26 2.3820843e-25], sum to 1.0000
[2019-04-06 23:12:05,093] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3943
[2019-04-06 23:12:05,162] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.0, 89.0, 0.0, 0.0, 26.0, 24.84487043586205, 0.2558227028016593, 0.0, 1.0, 39733.31165664175], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 522000.0000, 
sim time next is 523800.0000, 
raw observation next is [4.65, 88.5, 0.0, 0.0, 26.0, 25.02973844973089, 0.2586517493135633, 0.0, 1.0, 39547.2578415889], 
processed observation next is [0.0, 0.043478260869565216, 0.5914127423822716, 0.885, 0.0, 0.0, 0.6666666666666666, 0.5858115374775741, 0.5862172497711877, 0.0, 1.0, 0.1883202754361376], 
reward next is 0.8117, 
noisyNet noise sample is [array([-0.6438718], dtype=float32), 0.08458165]. 
=============================================
[2019-04-06 23:12:05,687] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:12:05,687] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:12:05,704] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run40
[2019-04-06 23:12:06,634] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.4801930e-23 1.9931409e-24 1.7843619e-20 1.2218886e-22 1.0000000e+00
 4.8661155e-27 4.6995595e-25], sum to 1.0000
[2019-04-06 23:12:06,634] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3719
[2019-04-06 23:12:06,756] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 88.0, 100.0, 0.0, 26.0, 25.79358592794027, 0.5838244497979612, 1.0, 1.0, 25057.579153278755], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1690200.0000, 
sim time next is 1692000.0000, 
raw observation next is [1.1, 88.0, 90.0, 0.0, 26.0, 26.27113395408745, 0.6224176691036524, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.88, 0.3, 0.0, 0.6666666666666666, 0.6892611628406208, 0.7074725563678842, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0444377], dtype=float32), -1.5770441]. 
=============================================
[2019-04-06 23:12:06,760] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[90.456406]
 [90.47003 ]
 [89.46374 ]
 [89.79002 ]
 [90.21004 ]], R is [[90.29840851]
 [90.27610016]
 [89.59914398]
 [89.70315552]
 [89.80612183]].
[2019-04-06 23:12:18,492] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1576720e-24 1.3714800e-24 4.9190791e-21 4.9215864e-24 1.0000000e+00
 1.4102120e-27 1.1281992e-26], sum to 1.0000
[2019-04-06 23:12:18,493] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8223
[2019-04-06 23:12:18,525] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.2, 54.0, 25.5, 18.5, 26.0, 26.08209787821028, 0.7129098829059254, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1616400.0000, 
sim time next is 1618200.0000, 
raw observation next is [11.35, 57.5, 0.0, 0.0, 26.0, 26.80893977517496, 0.7372001491016578, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.7770083102493075, 0.575, 0.0, 0.0, 0.6666666666666666, 0.7340783145979133, 0.7457333830338859, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.75841165], dtype=float32), 0.15041885]. 
=============================================
[2019-04-06 23:12:19,627] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-06 23:12:19,628] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:12:19,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:12:19,632] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run90
[2019-04-06 23:12:19,667] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:12:19,693] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:12:19,697] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run90
[2019-04-06 23:12:19,736] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:12:19,737] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:12:19,741] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run90
[2019-04-06 23:13:00,163] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.1514395]
[2019-04-06 23:13:00,163] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-0.6, 100.0, 9.0, 0.0, 26.0, 25.41889721934284, 0.4415741307398887, 1.0, 1.0, 0.0]
[2019-04-06 23:13:00,163] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 23:13:00,164] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.1501549e-22 1.7679963e-23 1.5103018e-19 2.6608803e-22 1.0000000e+00
 1.1613471e-25 4.7983624e-24], sampled 0.042652804318925264
[2019-04-06 23:14:40,443] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 23:15:17,416] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 23:15:22,299] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 23:15:23,338] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1780000, evaluation results [1780000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 23:15:54,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2253349e-22 5.0099387e-22 7.2239933e-18 1.5383277e-20 1.0000000e+00
 4.4558934e-24 7.4387166e-23], sum to 1.0000
[2019-04-06 23:15:54,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7963
[2019-04-06 23:15:54,666] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.5, 91.0, 17.5, 11.0, 26.0, 24.98529498979374, 0.1812945020825992, 1.0, 1.0, 75617.99293311416], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1929600.0000, 
sim time next is 1931400.0000, 
raw observation next is [-9.2, 88.5, 33.0, 21.0, 26.0, 25.36108489854021, 0.2105978861232931, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.20775623268698065, 0.885, 0.11, 0.023204419889502764, 0.6666666666666666, 0.6134237415450174, 0.570199295374431, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.46052685], dtype=float32), 0.035719886]. 
=============================================
[2019-04-06 23:16:14,245] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.4158848e-21 7.2813349e-21 1.4440189e-18 5.9097809e-20 1.0000000e+00
 3.4773561e-24 1.4299454e-21], sum to 1.0000
[2019-04-06 23:16:14,246] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4603
[2019-04-06 23:16:14,326] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 86.0, 0.0, 0.0, 26.0, 24.31138331130288, 0.1182306073623108, 0.0, 1.0, 42153.28178553305], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 612000.0000, 
sim time next is 613800.0000, 
raw observation next is [-3.9, 80.5, 0.0, 0.0, 26.0, 24.22129491139195, 0.1033303705828422, 0.0, 1.0, 42341.00652703562], 
processed observation next is [0.0, 0.08695652173913043, 0.3545706371191136, 0.805, 0.0, 0.0, 0.6666666666666666, 0.5184412426159959, 0.5344434568609474, 0.0, 1.0, 0.20162384060493152], 
reward next is 0.7984, 
noisyNet noise sample is [array([0.27822497], dtype=float32), -0.6844387]. 
=============================================
[2019-04-06 23:16:14,895] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2834668e-23 1.4785628e-24 1.1340067e-19 2.1591983e-23 1.0000000e+00
 3.9874583e-26 7.8686602e-25], sum to 1.0000
[2019-04-06 23:16:14,895] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5992
[2019-04-06 23:16:14,965] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.3, 96.0, 80.5, 354.0, 26.0, 26.06669671896136, 0.5663894370962742, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1508400.0000, 
sim time next is 1510200.0000, 
raw observation next is [3.85, 94.5, 88.0, 708.0, 26.0, 26.27387760604324, 0.6351477047008504, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.569252077562327, 0.945, 0.29333333333333333, 0.7823204419889502, 0.6666666666666666, 0.6894898005036033, 0.7117159015669502, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1369313], dtype=float32), -1.7608783]. 
=============================================
[2019-04-06 23:16:47,691] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.7143112e-24 7.1637864e-25 5.9629265e-21 1.9151634e-23 1.0000000e+00
 3.2992420e-27 1.1113232e-25], sum to 1.0000
[2019-04-06 23:16:47,691] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7631
[2019-04-06 23:16:47,754] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.1, 79.5, 31.0, 0.0, 26.0, 25.64964709745314, 0.6185021280292654, 0.0, 1.0, 11560.417364658642], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1153800.0000, 
sim time next is 1155600.0000, 
raw observation next is [15.5, 75.0, 57.0, 0.0, 26.0, 25.72571110148605, 0.6132438911187217, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.8919667590027703, 0.75, 0.19, 0.0, 0.6666666666666666, 0.6438092584571707, 0.7044146303729072, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9273486], dtype=float32), 0.35181445]. 
=============================================
[2019-04-06 23:16:52,612] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6897909e-20 3.4036847e-20 3.5026103e-17 1.7854590e-19 1.0000000e+00
 5.4043861e-21 4.6890219e-21], sum to 1.0000
[2019-04-06 23:16:52,613] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6211
[2019-04-06 23:16:52,621] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.3, 63.0, 0.0, 0.0, 26.0, 24.81422587321096, 0.4299081382905868, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1188000.0000, 
sim time next is 1189800.0000, 
raw observation next is [18.0, 65.0, 0.0, 0.0, 26.0, 24.79346678968571, 0.4237684345952058, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.9612188365650972, 0.65, 0.0, 0.0, 0.6666666666666666, 0.5661222324738091, 0.6412561448650685, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.236459], dtype=float32), -0.20873332]. 
=============================================
[2019-04-06 23:16:56,538] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9833879e-21 2.7575510e-23 5.8747674e-18 6.2557511e-20 1.0000000e+00
 4.9833470e-23 3.7486352e-23], sum to 1.0000
[2019-04-06 23:16:56,539] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1766
[2019-04-06 23:16:56,737] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.2, 64.0, 150.0, 67.0, 26.0, 25.57212232384506, 0.2698859660632643, 1.0, 1.0, 100020.08122587924], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2120400.0000, 
sim time next is 2122200.0000, 
raw observation next is [-5.9, 66.0, 149.0, 0.0, 26.0, 25.5504742386505, 0.4209977725794377, 1.0, 1.0, 32526.60044782868], 
processed observation next is [1.0, 0.5652173913043478, 0.2991689750692521, 0.66, 0.49666666666666665, 0.0, 0.6666666666666666, 0.6292061865542085, 0.6403325908598125, 1.0, 1.0, 0.15488857356108895], 
reward next is 0.8451, 
noisyNet noise sample is [array([-0.2577158], dtype=float32), -0.6227154]. 
=============================================
[2019-04-06 23:17:04,166] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2421885e-21 4.0513107e-22 1.0188006e-17 6.7090826e-21 1.0000000e+00
 5.7273795e-23 4.4609324e-22], sum to 1.0000
[2019-04-06 23:17:04,166] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4243
[2019-04-06 23:17:04,218] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 46.0, 0.0, 0.0, 26.0, 25.20681335425375, 0.2692319005114968, 0.0, 1.0, 38391.58919244509], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4942800.0000, 
sim time next is 4944600.0000, 
raw observation next is [-2.5, 48.0, 0.0, 0.0, 26.0, 25.17288512144859, 0.2507514745141295, 0.0, 1.0, 38519.2423224004], 
processed observation next is [1.0, 0.21739130434782608, 0.39335180055401664, 0.48, 0.0, 0.0, 0.6666666666666666, 0.5977404267873826, 0.5835838248380432, 0.0, 1.0, 0.18342496344000192], 
reward next is 0.8166, 
noisyNet noise sample is [array([1.1564608], dtype=float32), -0.9871901]. 
=============================================
[2019-04-06 23:17:11,683] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:17:11,683] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:17:11,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run41
[2019-04-06 23:17:12,105] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9826381e-20 9.1986122e-20 6.8169589e-17 5.7549421e-19 1.0000000e+00
 8.4003128e-23 4.4758174e-20], sum to 1.0000
[2019-04-06 23:17:12,105] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4007
[2019-04-06 23:17:12,171] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 43.0, 74.5, 607.0, 26.0, 25.33869809021173, 0.4605521517329501, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3600000.0000, 
sim time next is 3601800.0000, 
raw observation next is [0.0, 41.0, 63.0, 515.0, 26.0, 25.2809736415907, 0.439677494061915, 0.0, 1.0, 9342.141211298913], 
processed observation next is [0.0, 0.6956521739130435, 0.46260387811634357, 0.41, 0.21, 0.569060773480663, 0.6666666666666666, 0.6067478034658915, 0.646559164687305, 0.0, 1.0, 0.04448638672047101], 
reward next is 0.9555, 
noisyNet noise sample is [array([-0.61937773], dtype=float32), 0.7331716]. 
=============================================
[2019-04-06 23:17:46,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:17:46,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:17:46,620] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run41
[2019-04-06 23:17:54,646] A3C_AGENT_WORKER-Thread-14 INFO:Local step 113500, global step 1799855: loss 0.0791
[2019-04-06 23:17:54,647] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 113500, global step 1799855: learning rate 0.0000
[2019-04-06 23:17:55,574] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-06 23:17:55,575] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:17:55,575] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:17:55,579] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run91
[2019-04-06 23:17:55,601] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:17:55,604] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:17:55,613] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run91
[2019-04-06 23:17:55,638] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:17:55,640] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:17:55,645] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run91
[2019-04-06 23:20:13,780] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 23:20:53,760] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 23:20:56,382] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 23:20:57,421] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1800000, evaluation results [1800000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 23:21:02,315] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0672082e-21 1.2016935e-21 2.0837931e-19 1.2624664e-21 1.0000000e+00
 9.0685659e-24 4.4912232e-22], sum to 1.0000
[2019-04-06 23:21:02,315] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8377
[2019-04-06 23:21:02,486] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 26.0, 25.263567310698, 0.4026476036416369, 0.0, 1.0, 57275.41386126934], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3895200.0000, 
sim time next is 3897000.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 26.0, 25.69648502107536, 0.4425268767404825, 0.0, 1.0, 20529.822548014385], 
processed observation next is [1.0, 0.08695652173913043, 0.40720221606648205, 0.65, 0.0, 0.0, 0.6666666666666666, 0.6413737517562801, 0.6475089589134941, 0.0, 1.0, 0.09776105975244945], 
reward next is 0.9022, 
noisyNet noise sample is [array([0.01152075], dtype=float32), 0.5915668]. 
=============================================
[2019-04-06 23:21:02,498] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[84.00293 ]
 [83.71332 ]
 [83.620705]
 [83.54782 ]
 [83.37114 ]], R is [[84.10890198]
 [83.99507141]
 [84.08638   ]
 [84.05554199]
 [84.00849152]].
[2019-04-06 23:21:04,275] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.5787625e-20 2.7843510e-20 3.2540617e-17 2.6617879e-19 1.0000000e+00
 8.7525498e-24 4.3104289e-21], sum to 1.0000
[2019-04-06 23:21:04,275] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4266
[2019-04-06 23:21:04,402] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.65, 89.0, 0.0, 0.0, 26.0, 23.97367864384918, 0.04358177531632262, 0.0, 1.0, 43571.82641221059], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2262600.0000, 
sim time next is 2264400.0000, 
raw observation next is [-8.9, 91.0, 0.0, 0.0, 26.0, 23.81046515723298, 0.008857092594477584, 0.0, 1.0, 43463.68065322928], 
processed observation next is [1.0, 0.21739130434782608, 0.21606648199445982, 0.91, 0.0, 0.0, 0.6666666666666666, 0.48420542976941494, 0.5029523641981591, 0.0, 1.0, 0.2069699078725204], 
reward next is 0.7930, 
noisyNet noise sample is [array([-0.2986643], dtype=float32), -0.6106325]. 
=============================================
[2019-04-06 23:21:08,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0996981e-19 5.0937555e-19 1.5684450e-15 2.1812333e-18 1.0000000e+00
 1.3167748e-21 1.7830767e-19], sum to 1.0000
[2019-04-06 23:21:08,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4835
[2019-04-06 23:21:08,959] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-14.0, 69.0, 0.0, 0.0, 26.0, 23.38220890658136, -0.06558030102277444, 0.0, 1.0, 43098.79182524671], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3999600.0000, 
sim time next is 4001400.0000, 
raw observation next is [-13.5, 66.0, 0.0, 0.0, 26.0, 23.55064138380428, 0.07120909027452445, 1.0, 1.0, 149412.7952224986], 
processed observation next is [1.0, 0.30434782608695654, 0.0886426592797784, 0.66, 0.0, 0.0, 0.6666666666666666, 0.46255344865035664, 0.5237363634248414, 1.0, 1.0, 0.7114895010595171], 
reward next is 0.2885, 
noisyNet noise sample is [array([1.5360142], dtype=float32), -1.0044928]. 
=============================================
[2019-04-06 23:21:29,600] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:21:29,600] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:21:29,603] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run41
[2019-04-06 23:21:36,872] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9830943e-20 1.1012190e-20 3.0506871e-17 2.3305261e-19 1.0000000e+00
 5.9309333e-23 3.3918346e-22], sum to 1.0000
[2019-04-06 23:21:36,872] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6774
[2019-04-06 23:21:36,943] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.0, 78.5, 0.0, 0.0, 26.0, 23.80996064101288, 0.02041208611355655, 0.0, 1.0, 44369.605947051874], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2615400.0000, 
sim time next is 2617200.0000, 
raw observation next is [-7.3, 79.0, 0.0, 0.0, 26.0, 23.84304267738632, 0.01035980034161933, 0.0, 1.0, 44727.07788283945], 
processed observation next is [1.0, 0.30434782608695654, 0.26038781163434904, 0.79, 0.0, 0.0, 0.6666666666666666, 0.4869202231155268, 0.5034532667805398, 0.0, 1.0, 0.21298608515637832], 
reward next is 0.7870, 
noisyNet noise sample is [array([-2.3938596], dtype=float32), -0.029897012]. 
=============================================
[2019-04-06 23:21:37,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:21:37,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:21:37,196] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run41
[2019-04-06 23:21:37,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:21:37,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:21:37,952] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run41
[2019-04-06 23:21:41,800] A3C_AGENT_WORKER-Thread-17 INFO:Local step 113500, global step 1805142: loss 0.0682
[2019-04-06 23:21:41,800] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 113500, global step 1805142: learning rate 0.0000
[2019-04-06 23:21:47,469] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:21:47,469] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:21:47,472] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run41
[2019-04-06 23:21:53,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:21:53,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:21:53,380] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run41
[2019-04-06 23:21:59,715] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:21:59,716] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:21:59,719] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run41
[2019-04-06 23:22:00,941] A3C_AGENT_WORKER-Thread-14 INFO:Local step 114000, global step 1807703: loss 1.5450
[2019-04-06 23:22:00,943] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 114000, global step 1807703: learning rate 0.0000
[2019-04-06 23:22:09,257] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.4774593e-22 8.8946276e-23 7.3009542e-18 1.0382711e-20 1.0000000e+00
 1.8914218e-23 4.1198689e-22], sum to 1.0000
[2019-04-06 23:22:09,257] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7540
[2019-04-06 23:22:09,317] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 75.0, 0.0, 0.0, 26.0, 24.51361027993676, 0.1729733655265017, 0.0, 1.0, 44223.856913932446], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 252000.0000, 
sim time next is 253800.0000, 
raw observation next is [-3.9, 78.5, 0.0, 0.0, 26.0, 24.42786263726914, 0.1522204880386202, 0.0, 1.0, 44183.19433111101], 
processed observation next is [1.0, 0.9565217391304348, 0.3545706371191136, 0.785, 0.0, 0.0, 0.6666666666666666, 0.5356552197724284, 0.5507401626795401, 0.0, 1.0, 0.210396163481481], 
reward next is 0.7896, 
noisyNet noise sample is [array([1.3864871], dtype=float32), 0.55857944]. 
=============================================
[2019-04-06 23:22:10,519] A3C_AGENT_WORKER-Thread-19 INFO:Local step 113500, global step 1808951: loss 0.0606
[2019-04-06 23:22:10,523] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 113500, global step 1808951: learning rate 0.0000
[2019-04-06 23:22:10,737] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:22:10,737] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:22:10,752] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run41
[2019-04-06 23:22:11,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:22:11,282] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:22:11,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run41
[2019-04-06 23:22:15,270] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2789550e-24 4.3350747e-24 1.0476526e-20 1.7532140e-23 1.0000000e+00
 8.7673695e-28 4.0528019e-26], sum to 1.0000
[2019-04-06 23:22:15,270] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8736
[2019-04-06 23:22:15,341] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.15, 75.0, 0.0, 0.0, 26.0, 26.14491046590222, 0.7150195205368436, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1546200.0000, 
sim time next is 1548000.0000, 
raw observation next is [6.6, 76.0, 0.0, 0.0, 26.0, 26.11665889759926, 0.6917403030957777, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.6454293628808865, 0.76, 0.0, 0.0, 0.6666666666666666, 0.6763882414666051, 0.7305801010319258, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.0408223], dtype=float32), 0.8530823]. 
=============================================
[2019-04-06 23:22:15,373] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[94.19442 ]
 [94.19889 ]
 [92.92869 ]
 [91.47347 ]
 [91.826866]], R is [[94.02368164]
 [94.08344269]
 [93.4847641 ]
 [92.92630005]
 [92.99703979]].
[2019-04-06 23:22:21,765] A3C_AGENT_WORKER-Thread-18 INFO:Local step 113500, global step 1810336: loss 0.0710
[2019-04-06 23:22:21,766] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 113500, global step 1810336: learning rate 0.0000
[2019-04-06 23:22:22,911] A3C_AGENT_WORKER-Thread-15 INFO:Local step 113500, global step 1810489: loss 0.0669
[2019-04-06 23:22:22,912] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 113500, global step 1810489: learning rate 0.0000
[2019-04-06 23:22:26,882] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.1140978e-20 1.9165476e-20 2.4841964e-17 3.6594577e-20 1.0000000e+00
 2.2310468e-23 1.5443476e-21], sum to 1.0000
[2019-04-06 23:22:26,882] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8487
[2019-04-06 23:22:26,961] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 35.0, 109.0, 724.0, 26.0, 26.428237598231, 0.5617649915253362, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4096800.0000, 
sim time next is 4098600.0000, 
raw observation next is [-1.5, 33.5, 114.0, 769.0, 26.0, 26.57618558269218, 0.595093255952643, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4210526315789474, 0.335, 0.38, 0.8497237569060774, 0.6666666666666666, 0.7146821318910149, 0.698364418650881, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.26147893], dtype=float32), -0.88847476]. 
=============================================
[2019-04-06 23:22:31,837] A3C_AGENT_WORKER-Thread-8 INFO:Local step 113500, global step 1811643: loss 0.0664
[2019-04-06 23:22:31,837] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 113500, global step 1811643: learning rate 0.0000
[2019-04-06 23:22:36,349] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3760892e-20 8.8828365e-21 3.3943800e-17 2.2235988e-20 1.0000000e+00
 5.8183938e-23 2.8504545e-21], sum to 1.0000
[2019-04-06 23:22:36,350] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1820
[2019-04-06 23:22:36,422] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 33.0, 118.0, 841.0, 26.0, 26.45736741539072, 0.4345178392532218, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4019400.0000, 
sim time next is 4021200.0000, 
raw observation next is [-4.0, 29.0, 116.0, 835.5, 26.0, 25.96920914963087, 0.5382414498666795, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3518005540166205, 0.29, 0.38666666666666666, 0.9232044198895027, 0.6666666666666666, 0.6641007624692392, 0.6794138166222266, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6899178], dtype=float32), -1.2855644]. 
=============================================
[2019-04-06 23:22:36,764] A3C_AGENT_WORKER-Thread-7 INFO:Local step 113500, global step 1812346: loss 0.0622
[2019-04-06 23:22:36,765] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 113500, global step 1812346: learning rate 0.0000
[2019-04-06 23:22:38,336] A3C_AGENT_WORKER-Thread-17 INFO:Local step 114000, global step 1812550: loss 1.4946
[2019-04-06 23:22:38,336] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 114000, global step 1812550: learning rate 0.0000
[2019-04-06 23:22:40,459] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.9270555e-23 3.2636704e-25 8.8632726e-21 5.7626851e-23 1.0000000e+00
 6.6644995e-27 1.3015163e-24], sum to 1.0000
[2019-04-06 23:22:40,459] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2582
[2019-04-06 23:22:40,542] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.8, 68.0, 0.0, 0.0, 26.0, 25.5523728136746, 0.5255179436570855, 0.0, 1.0, 68035.73384457623], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4424400.0000, 
sim time next is 4426200.0000, 
raw observation next is [3.4, 68.0, 0.0, 0.0, 26.0, 25.73638379480764, 0.5386468822720436, 0.0, 1.0, 19819.423231123237], 
processed observation next is [1.0, 0.21739130434782608, 0.556786703601108, 0.68, 0.0, 0.0, 0.6666666666666666, 0.6446986495673034, 0.6795489607573479, 0.0, 1.0, 0.09437820586249161], 
reward next is 0.9056, 
noisyNet noise sample is [array([0.908049], dtype=float32), 0.016961249]. 
=============================================
[2019-04-06 23:22:42,562] A3C_AGENT_WORKER-Thread-6 INFO:Local step 113500, global step 1813169: loss 0.0682
[2019-04-06 23:22:42,582] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 113500, global step 1813169: learning rate 0.0000
[2019-04-06 23:22:47,057] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.1286206e-22 5.9121876e-22 1.7429225e-18 3.7865958e-21 1.0000000e+00
 1.3510570e-24 1.4044444e-22], sum to 1.0000
[2019-04-06 23:22:47,058] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7079
[2019-04-06 23:22:47,181] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.65, 88.5, 0.0, 0.0, 26.0, 25.02973844973089, 0.2586517493135633, 0.0, 1.0, 39547.2578415889], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 523800.0000, 
sim time next is 525600.0000, 
raw observation next is [4.3, 88.0, 0.0, 0.0, 26.0, 24.92799094464333, 0.243854622593601, 0.0, 1.0, 39594.0473381753], 
processed observation next is [0.0, 0.08695652173913043, 0.5817174515235458, 0.88, 0.0, 0.0, 0.6666666666666666, 0.5773325787202775, 0.581284874197867, 0.0, 1.0, 0.18854308256273955], 
reward next is 0.8115, 
noisyNet noise sample is [array([-0.7474093], dtype=float32), -0.92340535]. 
=============================================
[2019-04-06 23:22:51,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1227265e-22 7.1132322e-21 4.3178414e-18 3.1087522e-20 1.0000000e+00
 5.6502517e-24 3.2035672e-22], sum to 1.0000
[2019-04-06 23:22:51,699] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8675
[2019-04-06 23:22:51,877] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 77.0, 5.0, 149.0, 26.0, 24.88220072516021, 0.3390885459498185, 1.0, 1.0, 86001.96276234959], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3828600.0000, 
sim time next is 3830400.0000, 
raw observation next is [-5.0, 77.0, 48.0, 298.0, 26.0, 25.3924302335743, 0.376724376484267, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.32409972299168976, 0.77, 0.16, 0.3292817679558011, 0.6666666666666666, 0.6160358527978582, 0.6255747921614223, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.01103921], dtype=float32), -1.1355758]. 
=============================================
[2019-04-06 23:22:55,122] A3C_AGENT_WORKER-Thread-12 INFO:Local step 113500, global step 1814954: loss 0.0682
[2019-04-06 23:22:55,123] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 113500, global step 1814954: learning rate 0.0000
[2019-04-06 23:22:55,172] A3C_AGENT_WORKER-Thread-16 INFO:Local step 113500, global step 1814961: loss 0.0583
[2019-04-06 23:22:55,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 113500, global step 1814961: learning rate 0.0000
[2019-04-06 23:22:56,666] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.9325462e-21 4.4061888e-21 5.2429737e-19 2.7080375e-21 1.0000000e+00
 1.9629448e-23 1.4201759e-22], sum to 1.0000
[2019-04-06 23:22:56,666] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7169
[2019-04-06 23:22:56,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:22:56,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:22:56,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run41
[2019-04-06 23:22:56,918] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 59.0, 147.0, 96.5, 26.0, 24.89957619796551, 0.2384969290424512, 0.0, 1.0, 39441.830635911756], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 651600.0000, 
sim time next is 653400.0000, 
raw observation next is [-1.75, 59.5, 182.0, 93.0, 26.0, 24.91700825499426, 0.246111184464696, 0.0, 1.0, 29000.118837127025], 
processed observation next is [0.0, 0.5652173913043478, 0.4141274238227147, 0.595, 0.6066666666666667, 0.10276243093922652, 0.6666666666666666, 0.5764173545828551, 0.582037061488232, 0.0, 1.0, 0.13809580398631918], 
reward next is 0.8619, 
noisyNet noise sample is [array([0.78992134], dtype=float32), 1.3114343]. 
=============================================
[2019-04-06 23:22:59,081] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0090781e-20 1.9655994e-21 3.9780115e-17 5.1190369e-20 1.0000000e+00
 1.3596358e-22 3.0598768e-21], sum to 1.0000
[2019-04-06 23:22:59,081] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3854
[2019-04-06 23:22:59,262] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 41.0, 0.0, 0.0, 26.0, 25.63608288819043, 0.5440384311939499, 1.0, 1.0, 72605.02527619693], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3956400.0000, 
sim time next is 3958200.0000, 
raw observation next is [-6.5, 43.0, 0.0, 0.0, 26.0, 25.68005644303, 0.5506332030648556, 1.0, 1.0, 49303.429784331376], 
processed observation next is [1.0, 0.8260869565217391, 0.28254847645429365, 0.43, 0.0, 0.0, 0.6666666666666666, 0.6400047035858334, 0.6835444010216185, 1.0, 1.0, 0.23477823706824466], 
reward next is 0.7652, 
noisyNet noise sample is [array([1.0849922], dtype=float32), 0.68233824]. 
=============================================
[2019-04-06 23:23:02,579] A3C_AGENT_WORKER-Thread-14 INFO:Local step 114500, global step 1815920: loss 1.2200
[2019-04-06 23:23:02,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 114500, global step 1815920: learning rate 0.0000
[2019-04-06 23:23:06,212] A3C_AGENT_WORKER-Thread-19 INFO:Local step 114000, global step 1816401: loss 1.4631
[2019-04-06 23:23:06,216] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 114000, global step 1816401: learning rate 0.0000
[2019-04-06 23:23:13,869] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.3936365e-23 3.0070157e-23 2.6548808e-20 1.0376954e-23 1.0000000e+00
 1.1050203e-25 7.6075640e-25], sum to 1.0000
[2019-04-06 23:23:13,869] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9260
[2019-04-06 23:23:13,933] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.7, 79.0, 0.0, 0.0, 26.0, 24.69163129951781, 0.2088569878031471, 0.0, 1.0, 39401.362483276316], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 871200.0000, 
sim time next is 873000.0000, 
raw observation next is [-1.7, 79.0, 0.0, 0.0, 26.0, 24.73796027695566, 0.1989819529289752, 0.0, 1.0, 39365.93383576605], 
processed observation next is [1.0, 0.08695652173913043, 0.4155124653739613, 0.79, 0.0, 0.0, 0.6666666666666666, 0.5614966897463051, 0.5663273176429917, 0.0, 1.0, 0.18745682778936215], 
reward next is 0.8125, 
noisyNet noise sample is [array([-0.75655544], dtype=float32), -0.2919656]. 
=============================================
[2019-04-06 23:23:13,953] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[85.848076]
 [85.59472 ]
 [85.173004]
 [84.89655 ]
 [84.68902 ]], R is [[86.07872772]
 [86.03031921]
 [85.98220062]
 [85.93396759]
 [85.88457489]].
[2019-04-06 23:23:15,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:23:15,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:23:15,704] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run41
[2019-04-06 23:23:17,476] A3C_AGENT_WORKER-Thread-18 INFO:Local step 114000, global step 1818199: loss 1.4569
[2019-04-06 23:23:17,481] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 114000, global step 1818199: learning rate 0.0000
[2019-04-06 23:23:18,567] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4897540e-20 2.1241851e-21 1.5777206e-17 1.6776850e-21 1.0000000e+00
 3.5213268e-24 1.5921310e-21], sum to 1.0000
[2019-04-06 23:23:18,599] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7125
[2019-04-06 23:23:18,698] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 72.0, 0.0, 0.0, 26.0, 24.39131181741818, 0.09194226345585521, 0.0, 1.0, 40947.197792850246], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 694800.0000, 
sim time next is 696600.0000, 
raw observation next is [-3.4, 73.5, 0.0, 0.0, 26.0, 24.40040511163608, 0.08525935795207212, 0.0, 1.0, 41012.191861170526], 
processed observation next is [1.0, 0.043478260869565216, 0.368421052631579, 0.735, 0.0, 0.0, 0.6666666666666666, 0.53336709263634, 0.5284197859840241, 0.0, 1.0, 0.19529615171985965], 
reward next is 0.8047, 
noisyNet noise sample is [array([-1.9294987], dtype=float32), -3.384521]. 
=============================================
[2019-04-06 23:23:19,197] A3C_AGENT_WORKER-Thread-15 INFO:Local step 114000, global step 1818454: loss 1.4749
[2019-04-06 23:23:19,197] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 114000, global step 1818454: learning rate 0.0000
[2019-04-06 23:23:24,324] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.2706104e-24 3.0897216e-25 1.5064229e-20 5.9851824e-24 1.0000000e+00
 1.7808680e-26 6.5827651e-26], sum to 1.0000
[2019-04-06 23:23:24,324] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2348
[2019-04-06 23:23:24,364] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.6, 65.0, 217.5, 266.0, 26.0, 27.17988971747023, 0.6307766065387382, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1080000.0000, 
sim time next is 1081800.0000, 
raw observation next is [17.45, 60.5, 181.0, 317.0, 26.0, 27.00662362253207, 0.7245839329470888, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.9459833795013851, 0.605, 0.6033333333333334, 0.35027624309392263, 0.6666666666666666, 0.7505519685443393, 0.7415279776490297, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.72812027], dtype=float32), -0.960898]. 
=============================================
[2019-04-06 23:23:26,203] A3C_AGENT_WORKER-Thread-8 INFO:Local step 114000, global step 1819593: loss 1.4477
[2019-04-06 23:23:26,210] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 114000, global step 1819593: learning rate 0.0000
[2019-04-06 23:23:28,662] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 23:23:28,672] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:23:28,672] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:23:28,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run92
[2019-04-06 23:23:28,695] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:23:28,698] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:23:28,704] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:23:28,706] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:23:28,709] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run92
[2019-04-06 23:23:28,735] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run92
[2019-04-06 23:23:29,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:23:29,484] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:23:29,488] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run41
[2019-04-06 23:24:45,173] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15266348]
[2019-04-06 23:24:45,174] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-4.051535999, 47.64366093, 27.20613423, 477.8753765, 26.0, 24.96574771517906, 0.1982120760181936, 0.0, 1.0, 52873.792537851725]
[2019-04-06 23:24:45,174] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 23:24:45,174] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [4.0676077e-19 7.8523383e-20 1.2967738e-16 8.3213925e-19 1.0000000e+00
 1.4146129e-21 2.3256491e-20], sampled 0.6582568925574768
[2019-04-06 23:25:45,180] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 23:26:25,428] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 23:26:30,269] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 23:26:31,308] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 1820000, evaluation results [1820000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 23:26:34,660] A3C_AGENT_WORKER-Thread-7 INFO:Local step 114000, global step 1820339: loss 1.4339
[2019-04-06 23:26:34,660] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 114000, global step 1820339: learning rate 0.0000
[2019-04-06 23:26:41,747] A3C_AGENT_WORKER-Thread-6 INFO:Local step 114000, global step 1821010: loss 1.4529
[2019-04-06 23:26:41,747] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 114000, global step 1821010: learning rate 0.0000
[2019-04-06 23:26:48,074] A3C_AGENT_WORKER-Thread-20 INFO:Local step 113500, global step 1821588: loss 0.0723
[2019-04-06 23:26:48,074] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 113500, global step 1821588: learning rate 0.0000
[2019-04-06 23:26:49,388] A3C_AGENT_WORKER-Thread-17 INFO:Local step 114500, global step 1821698: loss 1.1746
[2019-04-06 23:26:49,388] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 114500, global step 1821698: learning rate 0.0000
[2019-04-06 23:26:51,743] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4376204e-20 2.5472117e-19 1.5436683e-16 5.5153369e-19 1.0000000e+00
 2.7487529e-21 6.2225728e-20], sum to 1.0000
[2019-04-06 23:26:51,743] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6597
[2019-04-06 23:26:52,123] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.5, 40.0, 0.0, 0.0, 26.0, 25.52946289734129, 0.3412655952082284, 1.0, 1.0, 40504.40978481236], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 412200.0000, 
sim time next is 414000.0000, 
raw observation next is [-9.5, 40.0, 0.0, 0.0, 26.0, 25.24601991071001, 0.2857158019702646, 1.0, 1.0, 46892.69931542745], 
processed observation next is [1.0, 0.8260869565217391, 0.1994459833795014, 0.4, 0.0, 0.0, 0.6666666666666666, 0.6038349925591676, 0.5952386006567548, 1.0, 1.0, 0.22329856816870217], 
reward next is 0.7767, 
noisyNet noise sample is [array([0.5381026], dtype=float32), -0.9184024]. 
=============================================
[2019-04-06 23:26:52,161] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.64871 ]
 [73.89548 ]
 [73.26803 ]
 [73.665184]
 [74.71162 ]], R is [[73.87360382]
 [73.94198608]
 [73.74061584]
 [73.70979309]
 [73.9726944 ]].
[2019-04-06 23:27:01,446] A3C_AGENT_WORKER-Thread-16 INFO:Local step 114000, global step 1822901: loss 1.5010
[2019-04-06 23:27:01,457] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 114000, global step 1822901: learning rate 0.0000
[2019-04-06 23:27:01,466] A3C_AGENT_WORKER-Thread-12 INFO:Local step 114000, global step 1822904: loss 1.4803
[2019-04-06 23:27:01,466] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 114000, global step 1822904: learning rate 0.0000
[2019-04-06 23:27:05,559] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:27:05,559] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:27:05,567] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run41
[2019-04-06 23:27:07,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:27:07,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:27:07,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run41
[2019-04-06 23:27:07,946] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.9042578e-23 2.8173075e-23 3.9758493e-21 1.3443083e-22 1.0000000e+00
 4.0407918e-26 1.9203262e-25], sum to 1.0000
[2019-04-06 23:27:07,946] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9300
[2019-04-06 23:27:08,013] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.85, 92.0, 53.0, 0.0, 26.0, 25.88313892950406, 0.5534484616135978, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1675800.0000, 
sim time next is 1677600.0000, 
raw observation next is [1.5, 92.0, 59.5, 0.0, 26.0, 26.00486467298683, 0.5608533137245221, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.5041551246537397, 0.92, 0.19833333333333333, 0.0, 0.6666666666666666, 0.6670720560822359, 0.6869511045748408, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.95858145], dtype=float32), -0.09285322]. 
=============================================
[2019-04-06 23:27:10,802] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:27:10,803] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:27:10,806] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run41
[2019-04-06 23:27:12,662] A3C_AGENT_WORKER-Thread-5 INFO:Local step 113500, global step 1824185: loss 0.0738
[2019-04-06 23:27:12,664] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 113500, global step 1824185: learning rate 0.0000
[2019-04-06 23:27:17,134] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [9.6197166e-19 9.3417893e-21 5.7185089e-18 7.9030082e-19 1.0000000e+00
 5.8057783e-23 6.3923585e-21], sum to 1.0000
[2019-04-06 23:27:17,135] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.9922
[2019-04-06 23:27:17,212] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.55, 76.5, 0.0, 0.0, 26.0, 24.05536724972026, 0.02238013934827341, 0.0, 1.0, 45191.02294401869], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1906200.0000, 
sim time next is 1908000.0000, 
raw observation next is [-7.8, 78.0, 0.0, 0.0, 26.0, 24.02638410624683, 0.009412502321475011, 0.0, 1.0, 45071.51952957284], 
processed observation next is [1.0, 0.08695652173913043, 0.24653739612188366, 0.78, 0.0, 0.0, 0.6666666666666666, 0.5021986755205692, 0.503137500773825, 0.0, 1.0, 0.21462628347415638], 
reward next is 0.7854, 
noisyNet noise sample is [array([-0.10605755], dtype=float32), 0.11784158]. 
=============================================
[2019-04-06 23:27:17,218] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[78.89543]
 [78.90839]
 [78.56896]
 [77.93828]
 [76.7968 ]], R is [[78.92471313]
 [78.92027283]
 [78.91616058]
 [78.91236877]
 [78.90904236]].
[2019-04-06 23:27:17,927] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.8292918e-20 5.7040579e-20 1.6487007e-17 1.8207714e-19 1.0000000e+00
 4.0725544e-22 9.0730784e-21], sum to 1.0000
[2019-04-06 23:27:17,927] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2254
[2019-04-06 23:27:18,301] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.5, 91.0, 0.0, 0.0, 26.0, 23.11919144320184, -0.193361869069363, 0.0, 1.0, 44542.00452495085], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1926000.0000, 
sim time next is 1927800.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 26.0, 23.62478035044371, 0.009829222835690885, 1.0, 1.0, 150047.45305300364], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.6666666666666666, 0.4687316958703092, 0.503276407611897, 1.0, 1.0, 0.7145116812047793], 
reward next is 0.2855, 
noisyNet noise sample is [array([-0.17586322], dtype=float32), -0.53514296]. 
=============================================
[2019-04-06 23:27:19,980] A3C_AGENT_WORKER-Thread-2 INFO:Local step 113500, global step 1824981: loss 0.0734
[2019-04-06 23:27:19,981] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 113500, global step 1824981: learning rate 0.0000
[2019-04-06 23:27:20,558] A3C_AGENT_WORKER-Thread-14 INFO:Local step 115000, global step 1825047: loss 17.7663
[2019-04-06 23:27:20,558] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 115000, global step 1825047: learning rate 0.0000
[2019-04-06 23:27:23,535] A3C_AGENT_WORKER-Thread-19 INFO:Local step 114500, global step 1825378: loss 1.2067
[2019-04-06 23:27:23,536] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 114500, global step 1825378: learning rate 0.0000
[2019-04-06 23:27:27,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3383960e-21 2.9636419e-21 1.8300274e-17 1.5057097e-21 1.0000000e+00
 8.5200114e-23 7.7375542e-22], sum to 1.0000
[2019-04-06 23:27:27,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7194
[2019-04-06 23:27:27,526] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.0, 71.5, 0.0, 0.0, 26.0, 23.23702773187975, -0.09009006090948857, 0.0, 1.0, 45438.6349209477], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 109800.0000, 
sim time next is 111600.0000, 
raw observation next is [-7.3, 68.0, 0.0, 0.0, 26.0, 23.16379544660384, -0.1151345343567202, 0.0, 1.0, 45767.85630946591], 
processed observation next is [1.0, 0.30434782608695654, 0.26038781163434904, 0.68, 0.0, 0.0, 0.6666666666666666, 0.43031628721698656, 0.46162182188109324, 0.0, 1.0, 0.21794217290221862], 
reward next is 0.7821, 
noisyNet noise sample is [array([0.8222948], dtype=float32), -0.54981494]. 
=============================================
[2019-04-06 23:27:34,309] A3C_AGENT_WORKER-Thread-15 INFO:Local step 114500, global step 1826552: loss 1.1874
[2019-04-06 23:27:34,310] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 114500, global step 1826552: learning rate 0.0000
[2019-04-06 23:27:35,101] A3C_AGENT_WORKER-Thread-18 INFO:Local step 114500, global step 1826613: loss 1.2390
[2019-04-06 23:27:35,102] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 114500, global step 1826613: learning rate 0.0000
[2019-04-06 23:27:42,733] A3C_AGENT_WORKER-Thread-8 INFO:Local step 114500, global step 1827466: loss 1.2223
[2019-04-06 23:27:42,734] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 114500, global step 1827466: learning rate 0.0000
[2019-04-06 23:27:46,228] A3C_AGENT_WORKER-Thread-7 INFO:Local step 114500, global step 1827911: loss 1.1936
[2019-04-06 23:27:46,228] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 114500, global step 1827911: learning rate 0.0000
[2019-04-06 23:27:49,663] A3C_AGENT_WORKER-Thread-20 INFO:Local step 114000, global step 1828337: loss 1.5903
[2019-04-06 23:27:49,664] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 114000, global step 1828337: learning rate 0.0000
[2019-04-06 23:27:50,048] A3C_AGENT_WORKER-Thread-4 INFO:Local step 113500, global step 1828382: loss 0.0991
[2019-04-06 23:27:50,048] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 113500, global step 1828382: learning rate 0.0000
[2019-04-06 23:27:51,379] A3C_AGENT_WORKER-Thread-6 INFO:Local step 114500, global step 1828511: loss 1.1755
[2019-04-06 23:27:51,380] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 114500, global step 1828511: learning rate 0.0000
[2019-04-06 23:27:52,550] A3C_AGENT_WORKER-Thread-13 INFO:Local step 113500, global step 1828671: loss 0.0923
[2019-04-06 23:27:52,551] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 113500, global step 1828671: learning rate 0.0000
[2019-04-06 23:27:56,025] A3C_AGENT_WORKER-Thread-3 INFO:Local step 113500, global step 1829091: loss 0.0870
[2019-04-06 23:27:56,025] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 113500, global step 1829091: learning rate 0.0000
[2019-04-06 23:28:00,037] A3C_AGENT_WORKER-Thread-17 INFO:Local step 115000, global step 1829530: loss 17.4903
[2019-04-06 23:28:00,038] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 115000, global step 1829530: learning rate 0.0000
[2019-04-06 23:28:03,911] A3C_AGENT_WORKER-Thread-16 INFO:Local step 114500, global step 1830120: loss 1.2121
[2019-04-06 23:28:03,916] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 114500, global step 1830120: learning rate 0.0000
[2019-04-06 23:28:05,778] A3C_AGENT_WORKER-Thread-12 INFO:Local step 114500, global step 1830388: loss 1.2017
[2019-04-06 23:28:05,779] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 114500, global step 1830388: learning rate 0.0000
[2019-04-06 23:28:07,951] A3C_AGENT_WORKER-Thread-14 INFO:Local step 115500, global step 1830703: loss 1.1763
[2019-04-06 23:28:07,952] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 115500, global step 1830703: learning rate 0.0000
[2019-04-06 23:28:09,338] A3C_AGENT_WORKER-Thread-5 INFO:Local step 114000, global step 1830889: loss 1.6125
[2019-04-06 23:28:09,339] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 114000, global step 1830889: learning rate 0.0000
[2019-04-06 23:28:17,602] A3C_AGENT_WORKER-Thread-2 INFO:Local step 114000, global step 1832079: loss 1.6525
[2019-04-06 23:28:17,603] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 114000, global step 1832079: learning rate 0.0000
[2019-04-06 23:28:23,510] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3256883e-17 1.4934247e-18 7.6842194e-16 7.9846487e-18 1.0000000e+00
 3.1722306e-21 1.1643049e-19], sum to 1.0000
[2019-04-06 23:28:23,510] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2660
[2019-04-06 23:28:23,576] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.4, 61.0, 0.0, 0.0, 26.0, 23.46627685086091, -0.09369919310647558, 0.0, 1.0, 44396.86589295681], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2435400.0000, 
sim time next is 2437200.0000, 
raw observation next is [-8.4, 61.0, 0.0, 0.0, 26.0, 23.35830513081865, -0.1140877975191054, 0.0, 1.0, 44402.08674206197], 
processed observation next is [0.0, 0.21739130434782608, 0.2299168975069252, 0.61, 0.0, 0.0, 0.6666666666666666, 0.44652542756822083, 0.46197073416029816, 0.0, 1.0, 0.21143850829553318], 
reward next is 0.7886, 
noisyNet noise sample is [array([0.07023667], dtype=float32), 0.8622894]. 
=============================================
[2019-04-06 23:28:24,095] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0983785e-23 6.2207535e-25 1.8716580e-20 3.1755567e-23 1.0000000e+00
 3.5578455e-27 3.8602704e-25], sum to 1.0000
[2019-04-06 23:28:24,095] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5682
[2019-04-06 23:28:24,139] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 100.0, 131.0, 0.0, 26.0, 25.40512871382575, 0.3216095845062352, 1.0, 1.0, 18680.41167023054], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2894400.0000, 
sim time next is 2896200.0000, 
raw observation next is [1.5, 100.0, 175.0, 0.0, 26.0, 25.24690767303524, 0.303003489422583, 1.0, 1.0, 15567.009725192116], 
processed observation next is [1.0, 0.5217391304347826, 0.5041551246537397, 1.0, 0.5833333333333334, 0.0, 0.6666666666666666, 0.6039089727529365, 0.601001163140861, 1.0, 1.0, 0.07412861773901008], 
reward next is 0.9259, 
noisyNet noise sample is [array([0.69434106], dtype=float32), 0.42544872]. 
=============================================
[2019-04-06 23:28:28,760] A3C_AGENT_WORKER-Thread-19 INFO:Local step 115000, global step 1833654: loss 17.5973
[2019-04-06 23:28:28,786] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 115000, global step 1833654: learning rate 0.0000
[2019-04-06 23:28:31,737] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2767644e-24 7.0635458e-25 5.5732845e-20 2.5675875e-22 1.0000000e+00
 1.0135088e-26 4.3142840e-26], sum to 1.0000
[2019-04-06 23:28:31,737] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7618
[2019-04-06 23:28:31,856] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 84.0, 62.5, 0.0, 26.0, 25.44065731080764, 0.2949559790614668, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 900000.0000, 
sim time next is 901800.0000, 
raw observation next is [1.1, 84.0, 77.0, 0.0, 26.0, 25.53273131400929, 0.2943090058262671, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.49307479224376743, 0.84, 0.25666666666666665, 0.0, 0.6666666666666666, 0.6277276095007741, 0.5981030019420891, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24109614], dtype=float32), 0.8138752]. 
=============================================
[2019-04-06 23:28:35,620] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.1100904e-20 2.2843402e-21 6.4162857e-18 1.8497608e-20 1.0000000e+00
 1.9726057e-23 5.5028872e-22], sum to 1.0000
[2019-04-06 23:28:35,620] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2000
[2019-04-06 23:28:35,843] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 87.0, 47.0, 0.0, 26.0, 24.99773790339846, 0.3288490125141655, 0.0, 1.0, 44116.52107658869], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1785600.0000, 
sim time next is 1787400.0000, 
raw observation next is [-3.65, 84.5, 28.0, 0.0, 26.0, 24.98691472173229, 0.3342825152569738, 0.0, 1.0, 55964.1043243423], 
processed observation next is [0.0, 0.6956521739130435, 0.3614958448753463, 0.845, 0.09333333333333334, 0.0, 0.6666666666666666, 0.5822428934776909, 0.6114275050856579, 0.0, 1.0, 0.26649573487782047], 
reward next is 0.7335, 
noisyNet noise sample is [array([0.65579164], dtype=float32), 0.76188576]. 
=============================================
[2019-04-06 23:28:38,053] A3C_AGENT_WORKER-Thread-15 INFO:Local step 115000, global step 1835024: loss 17.7308
[2019-04-06 23:28:38,054] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 115000, global step 1835024: learning rate 0.0000
[2019-04-06 23:28:38,870] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3219876e-23 6.4054539e-25 7.6882496e-20 2.0277370e-23 1.0000000e+00
 5.1598594e-26 1.3074722e-25], sum to 1.0000
[2019-04-06 23:28:38,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9610
[2019-04-06 23:28:38,931] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 26.0, 25.4570274800953, 0.5458569449579186, 0.0, 1.0, 80382.17310848816], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1717200.0000, 
sim time next is 1719000.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 26.0, 25.53639108611935, 0.5508344314308832, 0.0, 1.0, 21361.78816159224], 
processed observation next is [1.0, 0.9130434782608695, 0.4764542936288089, 0.92, 0.0, 0.0, 0.6666666666666666, 0.628032590509946, 0.6836114771436277, 0.0, 1.0, 0.10172280076948687], 
reward next is 0.8983, 
noisyNet noise sample is [array([1.3205458], dtype=float32), 1.1194874]. 
=============================================
[2019-04-06 23:28:38,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[88.82076 ]
 [88.46491 ]
 [88.767784]
 [89.83863 ]
 [89.671005]], R is [[88.73513794]
 [88.4650116 ]
 [88.39078522]
 [88.50688171]
 [88.49666595]].
[2019-04-06 23:28:39,650] A3C_AGENT_WORKER-Thread-18 INFO:Local step 115000, global step 1835303: loss 17.6898
[2019-04-06 23:28:39,650] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 115000, global step 1835303: learning rate 0.0000
[2019-04-06 23:28:45,206] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.7848833e-23 8.2726571e-25 9.0098920e-21 3.3427268e-23 1.0000000e+00
 1.3925815e-27 9.0043369e-26], sum to 1.0000
[2019-04-06 23:28:45,207] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0653
[2019-04-06 23:28:45,281] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.1, 96.0, 0.0, 0.0, 26.0, 25.0815605584149, 0.5647033383834766, 0.0, 1.0, 64752.39531341789], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1281600.0000, 
sim time next is 1283400.0000, 
raw observation next is [5.8, 98.0, 0.0, 0.0, 26.0, 25.40365502951709, 0.6049126764226388, 0.0, 1.0, 35209.50484412345], 
processed observation next is [0.0, 0.8695652173913043, 0.6232686980609419, 0.98, 0.0, 0.0, 0.6666666666666666, 0.6169712524597575, 0.7016375588075463, 0.0, 1.0, 0.16766430878154023], 
reward next is 0.8323, 
noisyNet noise sample is [array([1.3976706], dtype=float32), 0.36164662]. 
=============================================
[2019-04-06 23:28:45,334] A3C_AGENT_WORKER-Thread-8 INFO:Local step 115000, global step 1836255: loss 17.8849
[2019-04-06 23:28:45,336] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 115000, global step 1836255: learning rate 0.0000
[2019-04-06 23:28:45,725] A3C_AGENT_WORKER-Thread-17 INFO:Local step 115500, global step 1836306: loss 1.1404
[2019-04-06 23:28:45,727] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 115500, global step 1836306: learning rate 0.0000
[2019-04-06 23:28:45,871] A3C_AGENT_WORKER-Thread-4 INFO:Local step 114000, global step 1836328: loss 1.6130
[2019-04-06 23:28:45,872] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 114000, global step 1836328: learning rate 0.0000
[2019-04-06 23:28:46,239] A3C_AGENT_WORKER-Thread-13 INFO:Local step 114000, global step 1836394: loss 1.6447
[2019-04-06 23:28:46,240] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 114000, global step 1836394: learning rate 0.0000
[2019-04-06 23:28:49,658] A3C_AGENT_WORKER-Thread-7 INFO:Local step 115000, global step 1836920: loss 17.5901
[2019-04-06 23:28:49,658] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 115000, global step 1836920: learning rate 0.0000
[2019-04-06 23:28:49,886] A3C_AGENT_WORKER-Thread-20 INFO:Local step 114500, global step 1836956: loss 1.1842
[2019-04-06 23:28:49,917] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 114500, global step 1836960: learning rate 0.0000
[2019-04-06 23:28:50,116] A3C_AGENT_WORKER-Thread-3 INFO:Local step 114000, global step 1836999: loss 1.6252
[2019-04-06 23:28:50,117] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 114000, global step 1836999: learning rate 0.0000
[2019-04-06 23:28:54,944] A3C_AGENT_WORKER-Thread-6 INFO:Local step 115000, global step 1837724: loss 17.5930
[2019-04-06 23:28:54,945] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 115000, global step 1837724: learning rate 0.0000
[2019-04-06 23:28:55,092] A3C_AGENT_WORKER-Thread-14 INFO:Local step 116000, global step 1837746: loss 0.2287
[2019-04-06 23:28:55,092] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 116000, global step 1837746: learning rate 0.0000
[2019-04-06 23:28:57,218] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.9678905e-23 8.9773539e-24 1.3913226e-20 1.5495745e-23 1.0000000e+00
 3.6709393e-26 5.0304797e-25], sum to 1.0000
[2019-04-06 23:28:57,218] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4011
[2019-04-06 23:28:57,249] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 95.0, 81.0, 0.0, 26.0, 25.86656648465155, 0.4873875621119479, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1422000.0000, 
sim time next is 1423800.0000, 
raw observation next is [0.0, 95.0, 90.0, 0.0, 26.0, 25.66431522769575, 0.4647950026439044, 1.0, 1.0, 10510.866238402165], 
processed observation next is [1.0, 0.4782608695652174, 0.46260387811634357, 0.95, 0.3, 0.0, 0.6666666666666666, 0.6386929356413124, 0.654931667547968, 1.0, 1.0, 0.05005174399239126], 
reward next is 0.9499, 
noisyNet noise sample is [array([0.14769232], dtype=float32), -0.94259995]. 
=============================================
[2019-04-06 23:28:58,942] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.2522989e-21 5.9990406e-22 7.5795221e-18 1.4779053e-21 1.0000000e+00
 3.3038078e-23 2.2960710e-23], sum to 1.0000
[2019-04-06 23:28:58,942] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6961
[2019-04-06 23:28:58,992] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-10.0, 76.0, 0.0, 0.0, 26.0, 24.4819548895889, 0.2210385648824891, 0.0, 1.0, 43747.17150909654], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3301200.0000, 
sim time next is 3303000.0000, 
raw observation next is [-10.5, 76.0, 0.0, 0.0, 26.0, 24.39939248348501, 0.1884926052570038, 0.0, 1.0, 43630.48782022227], 
processed observation next is [1.0, 0.21739130434782608, 0.17174515235457063, 0.76, 0.0, 0.0, 0.6666666666666666, 0.5332827069570841, 0.5628308684190012, 0.0, 1.0, 0.20776422771534414], 
reward next is 0.7922, 
noisyNet noise sample is [array([0.02464237], dtype=float32), 0.08011366]. 
=============================================
[2019-04-06 23:28:59,038] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[78.94061 ]
 [79.43755 ]
 [79.81532 ]
 [80.25702 ]
 [80.761856]], R is [[78.34292603]
 [78.3511734 ]
 [78.3589325 ]
 [78.3658371 ]
 [78.37295532]].
[2019-04-06 23:29:05,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:29:05,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:29:05,066] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run42
[2019-04-06 23:29:06,158] A3C_AGENT_WORKER-Thread-16 INFO:Local step 115000, global step 1839524: loss 17.7138
[2019-04-06 23:29:06,161] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 115000, global step 1839524: learning rate 0.0000
[2019-04-06 23:29:06,432] A3C_AGENT_WORKER-Thread-5 INFO:Local step 114500, global step 1839565: loss 1.1824
[2019-04-06 23:29:06,432] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 114500, global step 1839565: learning rate 0.0000
[2019-04-06 23:29:08,779] A3C_AGENT_WORKER-Thread-12 INFO:Local step 115000, global step 1839955: loss 17.6300
[2019-04-06 23:29:08,780] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 115000, global step 1839955: learning rate 0.0000
[2019-04-06 23:29:09,095] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 23:29:09,122] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:29:09,122] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:29:09,127] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run93
[2019-04-06 23:29:09,150] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:29:09,152] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:29:09,152] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:29:09,153] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:29:09,157] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run93
[2019-04-06 23:29:09,184] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run93
[2019-04-06 23:30:32,123] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15242377]
[2019-04-06 23:30:32,124] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-5.050000000000001, 51.0, 117.0, 688.0, 26.0, 25.14764370817394, 0.2943133776922306, 0.0, 1.0, 0.0]
[2019-04-06 23:30:32,124] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 23:30:32,125] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [3.2317414e-19 6.3054647e-20 1.3926370e-16 8.7800610e-19 1.0000000e+00
 1.5167783e-21 2.5894559e-20], sampled 0.8093894493257855
[2019-04-06 23:30:56,003] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15242377]
[2019-04-06 23:30:56,003] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-4.0, 65.0, 0.0, 0.0, 26.0, 24.99817834062199, 0.2839641923943002, 0.0, 1.0, 38374.46042431109]
[2019-04-06 23:30:56,003] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-06 23:30:56,029] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [3.8074700e-20 5.6467485e-21 1.4105474e-17 7.9540576e-20 1.0000000e+00
 1.0899172e-22 2.0207816e-21], sampled 0.9803362158004133
[2019-04-06 23:31:29,838] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 23:32:05,123] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 23:32:06,855] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 23:32:07,919] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1840000, evaluation results [1840000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 23:32:15,738] A3C_AGENT_WORKER-Thread-19 INFO:Local step 115500, global step 1840715: loss 1.0246
[2019-04-06 23:32:15,738] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 115500, global step 1840715: learning rate 0.0000
[2019-04-06 23:32:16,569] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.0430805e-24 1.3812563e-24 2.9899429e-20 2.0039678e-23 1.0000000e+00
 4.5907973e-26 1.6329210e-25], sum to 1.0000
[2019-04-06 23:32:16,569] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1514
[2019-04-06 23:32:16,668] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 72.0, 0.0, 0.0, 26.0, 25.3366352419543, 0.4287390689780953, 0.0, 1.0, 50940.19286284551], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3466800.0000, 
sim time next is 3468600.0000, 
raw observation next is [1.0, 69.5, 0.0, 0.0, 26.0, 25.44511846418782, 0.439821317075017, 0.0, 1.0, 24956.888992000706], 
processed observation next is [1.0, 0.13043478260869565, 0.4903047091412743, 0.695, 0.0, 0.0, 0.6666666666666666, 0.6204265386823185, 0.6466071056916723, 0.0, 1.0, 0.11884232853333669], 
reward next is 0.8812, 
noisyNet noise sample is [array([0.6767073], dtype=float32), 0.635224]. 
=============================================
[2019-04-06 23:32:18,335] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.66060250e-20 7.20078818e-21 1.28279525e-17 7.12858032e-21
 1.00000000e+00 5.52337131e-22 1.62886257e-20], sum to 1.0000
[2019-04-06 23:32:18,335] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9145
[2019-04-06 23:32:18,380] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 42.0, 108.0, 800.0, 26.0, 25.19535697653536, 0.4508386609174075, 0.0, 1.0, 12463.334805436016], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3592800.0000, 
sim time next is 3594600.0000, 
raw observation next is [-1.0, 42.0, 102.0, 788.0, 26.0, 25.19150781630024, 0.456436369183663, 0.0, 1.0, 18696.125592578643], 
processed observation next is [0.0, 0.6086956521739131, 0.4349030470914128, 0.42, 0.34, 0.8707182320441988, 0.6666666666666666, 0.5992923180250201, 0.6521454563945543, 0.0, 1.0, 0.08902916948846973], 
reward next is 0.9110, 
noisyNet noise sample is [array([0.35257298], dtype=float32), -0.42559847]. 
=============================================
[2019-04-06 23:32:20,260] A3C_AGENT_WORKER-Thread-2 INFO:Local step 114500, global step 1841150: loss 1.1942
[2019-04-06 23:32:20,261] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 114500, global step 1841150: learning rate 0.0000
[2019-04-06 23:32:28,476] A3C_AGENT_WORKER-Thread-15 INFO:Local step 115500, global step 1841856: loss 1.3276
[2019-04-06 23:32:28,477] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 115500, global step 1841856: learning rate 0.0000
[2019-04-06 23:32:32,496] A3C_AGENT_WORKER-Thread-18 INFO:Local step 115500, global step 1842400: loss 1.1994
[2019-04-06 23:32:32,496] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 115500, global step 1842400: learning rate 0.0000
[2019-04-06 23:32:36,103] A3C_AGENT_WORKER-Thread-17 INFO:Local step 116000, global step 1842905: loss 0.2502
[2019-04-06 23:32:36,104] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 116000, global step 1842905: learning rate 0.0000
[2019-04-06 23:32:36,695] A3C_AGENT_WORKER-Thread-8 INFO:Local step 115500, global step 1842979: loss 1.1792
[2019-04-06 23:32:36,695] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 115500, global step 1842979: learning rate 0.0000
[2019-04-06 23:32:41,743] A3C_AGENT_WORKER-Thread-7 INFO:Local step 115500, global step 1843759: loss 1.2693
[2019-04-06 23:32:41,744] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 115500, global step 1843759: learning rate 0.0000
[2019-04-06 23:32:46,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:32:46,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:32:46,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run42
[2019-04-06 23:32:48,010] A3C_AGENT_WORKER-Thread-6 INFO:Local step 115500, global step 1844690: loss 1.2650
[2019-04-06 23:32:48,011] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 115500, global step 1844690: learning rate 0.0000
[2019-04-06 23:32:53,136] A3C_AGENT_WORKER-Thread-13 INFO:Local step 114500, global step 1845403: loss 1.2643
[2019-04-06 23:32:53,146] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 114500, global step 1845403: learning rate 0.0000
[2019-04-06 23:32:53,808] A3C_AGENT_WORKER-Thread-4 INFO:Local step 114500, global step 1845488: loss 1.2464
[2019-04-06 23:32:53,808] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 114500, global step 1845488: learning rate 0.0000
[2019-04-06 23:32:57,228] A3C_AGENT_WORKER-Thread-3 INFO:Local step 114500, global step 1845995: loss 1.2488
[2019-04-06 23:32:57,228] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 114500, global step 1845995: learning rate 0.0000
[2019-04-06 23:32:58,624] A3C_AGENT_WORKER-Thread-16 INFO:Local step 115500, global step 1846218: loss 1.2550
[2019-04-06 23:32:58,625] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 115500, global step 1846218: learning rate 0.0000
[2019-04-06 23:32:59,574] A3C_AGENT_WORKER-Thread-20 INFO:Local step 115000, global step 1846343: loss 17.6629
[2019-04-06 23:32:59,574] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 115000, global step 1846343: learning rate 0.0000
[2019-04-06 23:33:01,160] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.1477841e-24 4.6237706e-25 4.3945918e-20 5.0736323e-24 1.0000000e+00
 1.3501798e-26 9.2006850e-27], sum to 1.0000
[2019-04-06 23:33:01,180] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9419
[2019-04-06 23:33:01,249] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.0, 100.0, 0.0, 0.0, 26.0, 25.35513002920484, 0.3150572689071003, 0.0, 1.0, 60262.569910425205], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3133800.0000, 
sim time next is 3135600.0000, 
raw observation next is [6.0, 100.0, 0.0, 0.0, 26.0, 25.3955822753187, 0.3355047942273415, 0.0, 1.0, 46178.84094290538], 
processed observation next is [1.0, 0.30434782608695654, 0.6288088642659281, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6162985229432248, 0.6118349314091138, 0.0, 1.0, 0.21989924258526372], 
reward next is 0.7801, 
noisyNet noise sample is [array([-0.22037067], dtype=float32), 1.2261144]. 
=============================================
[2019-04-06 23:33:01,503] A3C_AGENT_WORKER-Thread-12 INFO:Local step 115500, global step 1846615: loss 1.2502
[2019-04-06 23:33:01,522] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 115500, global step 1846615: learning rate 0.0000
[2019-04-06 23:33:06,843] A3C_AGENT_WORKER-Thread-19 INFO:Local step 116000, global step 1847456: loss 0.2280
[2019-04-06 23:33:06,844] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 116000, global step 1847456: learning rate 0.0000
[2019-04-06 23:33:15,290] A3C_AGENT_WORKER-Thread-15 INFO:Local step 116000, global step 1848732: loss 0.1840
[2019-04-06 23:33:15,290] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 116000, global step 1848732: learning rate 0.0000
[2019-04-06 23:33:17,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:33:17,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:33:17,124] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run42
[2019-04-06 23:33:17,841] A3C_AGENT_WORKER-Thread-5 INFO:Local step 115000, global step 1849147: loss 17.2767
[2019-04-06 23:33:17,842] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 115000, global step 1849147: learning rate 0.0000
[2019-04-06 23:33:18,060] A3C_AGENT_WORKER-Thread-18 INFO:Local step 116000, global step 1849184: loss 0.2280
[2019-04-06 23:33:18,073] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 116000, global step 1849184: learning rate 0.0000
[2019-04-06 23:33:21,891] A3C_AGENT_WORKER-Thread-8 INFO:Local step 116000, global step 1849792: loss 0.2025
[2019-04-06 23:33:21,892] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 116000, global step 1849792: learning rate 0.0000
[2019-04-06 23:33:25,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:33:25,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:33:25,192] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run42
[2019-04-06 23:33:26,950] A3C_AGENT_WORKER-Thread-2 INFO:Local step 115000, global step 1850523: loss 17.4503
[2019-04-06 23:33:26,950] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 115000, global step 1850523: learning rate 0.0000
[2019-04-06 23:33:27,783] A3C_AGENT_WORKER-Thread-7 INFO:Local step 116000, global step 1850642: loss 0.1983
[2019-04-06 23:33:27,786] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 116000, global step 1850642: learning rate 0.0000
[2019-04-06 23:33:28,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:33:28,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:33:28,076] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run42
[2019-04-06 23:33:32,108] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:33:32,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:33:32,112] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run42
[2019-04-06 23:33:32,781] A3C_AGENT_WORKER-Thread-6 INFO:Local step 116000, global step 1851290: loss 0.2056
[2019-04-06 23:33:32,782] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 116000, global step 1851290: learning rate 0.0000
[2019-04-06 23:33:38,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:33:38,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:33:38,686] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run42
[2019-04-06 23:33:43,294] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:33:43,294] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:33:43,299] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run42
[2019-04-06 23:33:43,402] A3C_AGENT_WORKER-Thread-16 INFO:Local step 116000, global step 1852689: loss 0.1780
[2019-04-06 23:33:43,403] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 116000, global step 1852689: learning rate 0.0000
[2019-04-06 23:33:44,054] A3C_AGENT_WORKER-Thread-20 INFO:Local step 115500, global step 1852782: loss 1.1918
[2019-04-06 23:33:44,055] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 115500, global step 1852782: learning rate 0.0000
[2019-04-06 23:33:45,189] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6230330e-25 4.5028688e-23 1.2381149e-20 1.2290598e-22 1.0000000e+00
 1.9800901e-25 1.2568096e-23], sum to 1.0000
[2019-04-06 23:33:45,189] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9111
[2019-04-06 23:33:45,330] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 79.0, 0.0, 0.0, 26.0, 25.05324694122368, 0.4154200967050698, 1.0, 1.0, 41943.780787533244], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3439800.0000, 
sim time next is 3441600.0000, 
raw observation next is [1.0, 79.0, 0.0, 0.0, 26.0, 25.00572148376305, 0.4390396422250539, 0.0, 1.0, 60744.45318148113], 
processed observation next is [1.0, 0.8695652173913043, 0.4903047091412743, 0.79, 0.0, 0.0, 0.6666666666666666, 0.5838101236469209, 0.6463465474083513, 0.0, 1.0, 0.2892593008641958], 
reward next is 0.7107, 
noisyNet noise sample is [array([0.76571214], dtype=float32), -0.12251947]. 
=============================================
[2019-04-06 23:33:45,357] A3C_AGENT_WORKER-Thread-12 INFO:Local step 116000, global step 1852940: loss 0.1619
[2019-04-06 23:33:45,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 116000, global step 1852940: learning rate 0.0000
[2019-04-06 23:33:48,337] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4835637e-23 1.4058320e-23 1.4503557e-19 6.5240520e-23 1.0000000e+00
 8.2898379e-26 3.5987874e-24], sum to 1.0000
[2019-04-06 23:33:48,337] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4963
[2019-04-06 23:33:48,422] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 26.0, 25.08415735584337, 0.3831019446535138, 0.0, 1.0, 43810.23096505302], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2934000.0000, 
sim time next is 2935800.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 26.0, 24.9983244092356, 0.3656405343622842, 0.0, 1.0, 43522.33160970469], 
processed observation next is [1.0, 1.0, 0.40720221606648205, 0.85, 0.0, 0.0, 0.6666666666666666, 0.5831937007696334, 0.6218801781207614, 0.0, 1.0, 0.2072491981414509], 
reward next is 0.7928, 
noisyNet noise sample is [array([0.81728655], dtype=float32), -0.99925774]. 
=============================================
[2019-04-06 23:33:52,234] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6657712e-21 2.6504661e-22 5.2702220e-20 3.6454373e-22 1.0000000e+00
 3.5783902e-24 6.8007566e-23], sum to 1.0000
[2019-04-06 23:33:52,234] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5778
[2019-04-06 23:33:52,364] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 65.0, 78.0, 317.0, 26.0, 25.5847796240099, 0.4291944958027455, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5040000.0000, 
sim time next is 5041800.0000, 
raw observation next is [-0.5, 56.0, 97.0, 533.0, 26.0, 25.84071754661051, 0.5218694718073725, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.44875346260387816, 0.56, 0.3233333333333333, 0.5889502762430939, 0.6666666666666666, 0.6533931288842091, 0.6739564906024574, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6433802], dtype=float32), -0.22916785]. 
=============================================
[2019-04-06 23:33:52,897] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9734910e-23 9.9244855e-24 1.9280833e-19 3.5418348e-22 1.0000000e+00
 6.7585652e-26 8.7401386e-24], sum to 1.0000
[2019-04-06 23:33:52,897] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8656
[2019-04-06 23:33:52,947] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.5, 31.0, 123.0, 845.0, 26.0, 27.33913313909142, 0.8294039909983626, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5052600.0000, 
sim time next is 5054400.0000, 
raw observation next is [8.0, 26.0, 123.5, 855.0, 26.0, 27.36486379245746, 0.8535006671313328, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6842105263157896, 0.26, 0.4116666666666667, 0.9447513812154696, 0.6666666666666666, 0.7804053160381216, 0.7845002223771109, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4794221], dtype=float32), 0.73849225]. 
=============================================
[2019-04-06 23:33:53,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:33:53,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:33:53,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run42
[2019-04-06 23:33:55,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:33:55,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:33:55,388] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run42
[2019-04-06 23:33:56,846] A3C_AGENT_WORKER-Thread-13 INFO:Local step 115000, global step 1854388: loss 17.2485
[2019-04-06 23:33:56,858] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 115000, global step 1854388: learning rate 0.0000
[2019-04-06 23:33:58,172] A3C_AGENT_WORKER-Thread-4 INFO:Local step 115000, global step 1854553: loss 17.4729
[2019-04-06 23:33:58,172] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 115000, global step 1854553: learning rate 0.0000
[2019-04-06 23:33:59,488] A3C_AGENT_WORKER-Thread-3 INFO:Local step 115000, global step 1854701: loss 17.6048
[2019-04-06 23:33:59,517] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 115000, global step 1854701: learning rate 0.0000
[2019-04-06 23:34:03,260] A3C_AGENT_WORKER-Thread-5 INFO:Local step 115500, global step 1855186: loss 1.2221
[2019-04-06 23:34:03,277] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 115500, global step 1855186: learning rate 0.0000
[2019-04-06 23:34:13,991] A3C_AGENT_WORKER-Thread-2 INFO:Local step 115500, global step 1856536: loss 1.1929
[2019-04-06 23:34:13,992] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 115500, global step 1856536: learning rate 0.0000
[2019-04-06 23:34:27,294] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3511473e-19 8.6025806e-21 2.7861508e-17 2.4330432e-19 1.0000000e+00
 8.4293996e-22 3.0052312e-20], sum to 1.0000
[2019-04-06 23:34:27,295] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1355
[2019-04-06 23:34:27,340] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 50.0, 0.0, 0.0, 26.0, 25.41380337055323, 0.3905340970297651, 0.0, 1.0, 44901.81330009162], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3621600.0000, 
sim time next is 3623400.0000, 
raw observation next is [-2.5, 55.0, 0.0, 0.0, 26.0, 25.36772617515599, 0.3777518989620463, 0.0, 1.0, 44000.24294687613], 
processed observation next is [0.0, 0.9565217391304348, 0.39335180055401664, 0.55, 0.0, 0.0, 0.6666666666666666, 0.6139771812629992, 0.6259172996540154, 0.0, 1.0, 0.20952496641369586], 
reward next is 0.7905, 
noisyNet noise sample is [array([-0.6097996], dtype=float32), -0.81814706]. 
=============================================
[2019-04-06 23:34:27,606] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1650730e-21 8.5341283e-23 5.3397809e-18 4.6358758e-22 1.0000000e+00
 6.0883442e-25 1.8915662e-23], sum to 1.0000
[2019-04-06 23:34:27,608] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4075
[2019-04-06 23:34:27,647] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.36672027880483, 0.3782015860181364, 0.0, 1.0, 40072.44332460019], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3717000.0000, 
sim time next is 3718800.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 26.0, 25.58347775246068, 0.3874633398611517, 0.0, 1.0, 13911.417753597625], 
processed observation next is [1.0, 0.043478260869565216, 0.3795013850415513, 0.71, 0.0, 0.0, 0.6666666666666666, 0.6319564793717234, 0.6291544466203839, 0.0, 1.0, 0.06624484644570297], 
reward next is 0.9338, 
noisyNet noise sample is [array([-1.178432], dtype=float32), -0.997242]. 
=============================================
[2019-04-06 23:34:29,096] A3C_AGENT_WORKER-Thread-20 INFO:Local step 116000, global step 1858659: loss 0.2598
[2019-04-06 23:34:29,097] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 116000, global step 1858659: learning rate 0.0000
[2019-04-06 23:34:38,891] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-06 23:34:38,896] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:34:38,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:34:38,900] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run94
[2019-04-06 23:34:38,928] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:34:38,930] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:34:38,935] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run94
[2019-04-06 23:34:38,951] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:34:38,973] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:34:38,978] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run94
[2019-04-06 23:34:39,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:34:39,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:34:39,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run42
[2019-04-06 23:36:59,296] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 23:37:35,469] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 23:37:43,462] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 23:37:44,500] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 1860000, evaluation results [1860000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 23:37:46,683] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.9132270e-19 3.7165310e-21 2.0395349e-17 5.5957806e-20 1.0000000e+00
 4.8759763e-22 2.1557038e-20], sum to 1.0000
[2019-04-06 23:37:46,684] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9310
[2019-04-06 23:37:46,783] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 68.0, 0.0, 0.0, 26.0, 23.80191799134563, 0.006293694812410502, 0.0, 1.0, 44427.01635046806], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 622800.0000, 
sim time next is 624600.0000, 
raw observation next is [-4.5, 66.5, 0.0, 0.0, 26.0, 23.75424586139581, -0.005780995441867345, 0.0, 1.0, 44232.600920331], 
processed observation next is [0.0, 0.21739130434782608, 0.3379501385041552, 0.665, 0.0, 0.0, 0.6666666666666666, 0.47952048844965073, 0.49807300151937756, 0.0, 1.0, 0.21063143295395714], 
reward next is 0.7894, 
noisyNet noise sample is [array([0.1650577], dtype=float32), 0.5130264]. 
=============================================
[2019-04-06 23:37:50,370] A3C_AGENT_WORKER-Thread-13 INFO:Local step 115500, global step 1860520: loss 1.2880
[2019-04-06 23:37:50,370] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 115500, global step 1860520: learning rate 0.0000
[2019-04-06 23:37:51,065] A3C_AGENT_WORKER-Thread-4 INFO:Local step 115500, global step 1860591: loss 1.1943
[2019-04-06 23:37:51,065] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 115500, global step 1860591: learning rate 0.0000
[2019-04-06 23:37:55,797] A3C_AGENT_WORKER-Thread-3 INFO:Local step 115500, global step 1860968: loss 1.2337
[2019-04-06 23:37:55,798] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 115500, global step 1860968: learning rate 0.0000
[2019-04-06 23:37:58,017] A3C_AGENT_WORKER-Thread-5 INFO:Local step 116000, global step 1861157: loss 0.1756
[2019-04-06 23:37:58,067] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 116000, global step 1861162: learning rate 0.0000
[2019-04-06 23:38:05,968] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.6681843e-19 2.0109098e-19 1.5919285e-16 8.6201308e-19 1.0000000e+00
 3.7850632e-22 1.0534279e-19], sum to 1.0000
[2019-04-06 23:38:05,968] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3942
[2019-04-06 23:38:06,086] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.0, 49.0, 0.0, 0.0, 26.0, 24.54940263321029, 0.2015945947558548, 0.0, 1.0, 40084.16511505266], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4172400.0000, 
sim time next is 4174200.0000, 
raw observation next is [-5.0, 51.5, 0.0, 0.0, 26.0, 24.6161634878569, 0.2018308455997309, 0.0, 1.0, 40435.18734076601], 
processed observation next is [0.0, 0.30434782608695654, 0.32409972299168976, 0.515, 0.0, 0.0, 0.6666666666666666, 0.5513469573214081, 0.5672769485332436, 0.0, 1.0, 0.1925485111465048], 
reward next is 0.8075, 
noisyNet noise sample is [array([0.62839705], dtype=float32), -0.44664967]. 
=============================================
[2019-04-06 23:38:12,803] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:38:12,803] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:38:12,806] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run42
[2019-04-06 23:38:13,931] A3C_AGENT_WORKER-Thread-2 INFO:Local step 116000, global step 1862727: loss 0.1583
[2019-04-06 23:38:13,932] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 116000, global step 1862727: learning rate 0.0000
[2019-04-06 23:38:22,956] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5276459e-24 2.1323724e-25 6.3245406e-21 7.0875676e-25 1.0000000e+00
 6.6614715e-28 4.3563419e-25], sum to 1.0000
[2019-04-06 23:38:22,957] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5521
[2019-04-06 23:38:23,006] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.6, 63.0, 0.0, 0.0, 26.0, 25.67485812974403, 0.6357356061087603, 0.0, 1.0, 88696.50000560253], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4406400.0000, 
sim time next is 4408200.0000, 
raw observation next is [7.199999999999999, 64.0, 0.0, 0.0, 26.0, 25.83010407582568, 0.6333124405736558, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.0, 0.662049861495845, 0.64, 0.0, 0.0, 0.6666666666666666, 0.6525086729854733, 0.7111041468578853, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2970055], dtype=float32), 1.0031844]. 
=============================================
[2019-04-06 23:38:24,511] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:38:24,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:38:24,538] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run42
[2019-04-06 23:38:27,803] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3593837e-19 1.5943919e-21 2.0683047e-17 9.6471676e-19 1.0000000e+00
 1.5124558e-22 1.0518568e-21], sum to 1.0000
[2019-04-06 23:38:27,804] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8056
[2019-04-06 23:38:27,854] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 57.0, 0.0, 0.0, 26.0, 24.78565992342572, 0.129575060328652, 0.0, 1.0, 38471.821142210734], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2527200.0000, 
sim time next is 2529000.0000, 
raw observation next is [-2.55, 55.5, 0.0, 0.0, 26.0, 24.69988590356493, 0.1124501230432527, 0.0, 1.0, 38691.73239418286], 
processed observation next is [1.0, 0.2608695652173913, 0.3919667590027701, 0.555, 0.0, 0.0, 0.6666666666666666, 0.5583238252970775, 0.5374833743477508, 0.0, 1.0, 0.1842463447342041], 
reward next is 0.8158, 
noisyNet noise sample is [array([-0.5528128], dtype=float32), -0.41912475]. 
=============================================
[2019-04-06 23:38:27,889] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[81.36379 ]
 [81.172874]
 [80.87693 ]
 [80.63129 ]
 [80.459145]], R is [[81.3549881 ]
 [81.35823822]
 [81.36196136]
 [81.36560822]
 [81.36909485]].
[2019-04-06 23:38:43,075] A3C_AGENT_WORKER-Thread-4 INFO:Local step 116000, global step 1867298: loss 0.2085
[2019-04-06 23:38:43,095] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 116000, global step 1867298: learning rate 0.0000
[2019-04-06 23:38:43,220] A3C_AGENT_WORKER-Thread-13 INFO:Local step 116000, global step 1867320: loss 0.2186
[2019-04-06 23:38:43,221] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 116000, global step 1867320: learning rate 0.0000
[2019-04-06 23:38:49,001] A3C_AGENT_WORKER-Thread-3 INFO:Local step 116000, global step 1868242: loss 0.1939
[2019-04-06 23:38:49,024] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 116000, global step 1868242: learning rate 0.0000
[2019-04-06 23:38:51,413] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.2853558e-23 7.4704161e-25 2.4192048e-21 1.7967436e-22 1.0000000e+00
 5.8594157e-25 1.9966558e-25], sum to 1.0000
[2019-04-06 23:38:51,413] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6876
[2019-04-06 23:38:51,454] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.35, 91.5, 0.0, 0.0, 26.0, 25.32574409262612, 0.4565547133547499, 0.0, 1.0, 43216.566553009565], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1733400.0000, 
sim time next is 1735200.0000, 
raw observation next is [0.2, 91.0, 0.0, 0.0, 26.0, 25.30837274779071, 0.4435379954455684, 0.0, 1.0, 42908.56836661287], 
processed observation next is [0.0, 0.08695652173913043, 0.46814404432132967, 0.91, 0.0, 0.0, 0.6666666666666666, 0.6090310623158924, 0.6478459984818561, 0.0, 1.0, 0.20432651603148985], 
reward next is 0.7957, 
noisyNet noise sample is [array([1.3724483], dtype=float32), -0.9243325]. 
=============================================
[2019-04-06 23:38:53,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:38:53,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:38:53,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run42
[2019-04-06 23:38:53,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:38:53,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:38:53,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run42
[2019-04-06 23:38:54,959] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9635438e-20 2.6592277e-21 2.3620589e-18 6.1730886e-20 1.0000000e+00
 6.5548352e-23 2.4874710e-22], sum to 1.0000
[2019-04-06 23:38:54,959] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4111
[2019-04-06 23:38:55,234] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 78.0, 134.0, 72.5, 26.0, 25.01957800783478, 0.2180394905388855, 0.0, 1.0, 6252.4497852414725], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1850400.0000, 
sim time next is 1852200.0000, 
raw observation next is [-5.6, 76.5, 120.0, 51.0, 26.0, 24.87668353875297, 0.2338302958050861, 0.0, 1.0, 85548.34340377703], 
processed observation next is [0.0, 0.43478260869565216, 0.30747922437673136, 0.765, 0.4, 0.056353591160221, 0.6666666666666666, 0.5730569615627475, 0.5779434319350287, 0.0, 1.0, 0.4073730638275097], 
reward next is 0.5926, 
noisyNet noise sample is [array([0.38170135], dtype=float32), -0.71957153]. 
=============================================
[2019-04-06 23:38:57,622] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3753930e-25 1.0454945e-24 1.8128211e-20 7.1165327e-24 1.0000000e+00
 2.7354703e-27 4.4233215e-26], sum to 1.0000
[2019-04-06 23:38:57,623] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7284
[2019-04-06 23:38:57,673] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [11.5, 19.5, 111.0, 819.0, 26.0, 28.29849286833861, 1.057296531562915, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5063400.0000, 
sim time next is 5065200.0000, 
raw observation next is [12.0, 19.0, 103.5, 782.0, 26.0, 28.55271196738633, 1.108532372492501, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.7950138504155125, 0.19, 0.345, 0.8640883977900552, 0.6666666666666666, 0.8793926639488608, 0.8695107908308337, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3713978], dtype=float32), -2.1350627]. 
=============================================
[2019-04-06 23:38:59,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:38:59,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:38:59,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run42
[2019-04-06 23:39:11,010] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.0108568e-23 2.6126188e-24 1.7201799e-19 6.0868406e-23 1.0000000e+00
 1.3680412e-25 2.8685905e-24], sum to 1.0000
[2019-04-06 23:39:11,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1979
[2019-04-06 23:39:11,183] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 82.0, 48.0, 0.0, 26.0, 25.44419509413319, 0.2931972066239109, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 898200.0000, 
sim time next is 900000.0000, 
raw observation next is [1.1, 84.0, 62.5, 0.0, 26.0, 25.44065731080764, 0.2949559790614668, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.49307479224376743, 0.84, 0.20833333333333334, 0.0, 0.6666666666666666, 0.6200547759006367, 0.5983186596871556, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47679237], dtype=float32), 1.4389113]. 
=============================================
[2019-04-06 23:39:11,190] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[85.217834]
 [85.08711 ]
 [85.00457 ]
 [85.01023 ]
 [84.98463 ]], R is [[85.53970337]
 [85.68431091]
 [85.82746887]
 [85.9691925 ]
 [86.1095047 ]].
[2019-04-06 23:39:13,809] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3708153e-24 4.2109411e-24 1.3528817e-18 3.0610162e-24 1.0000000e+00
 2.9896584e-27 8.4241194e-24], sum to 1.0000
[2019-04-06 23:39:13,809] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9986
[2019-04-06 23:39:13,986] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.7, 100.0, 0.0, 0.0, 26.0, 24.94653487869422, 0.3005363684322062, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 934200.0000, 
sim time next is 936000.0000, 
raw observation next is [5.0, 100.0, 0.0, 0.0, 26.0, 24.63071413250159, 0.2873212440066567, 1.0, 1.0, 59729.84606312608], 
processed observation next is [1.0, 0.8695652173913043, 0.6011080332409973, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5525595110417992, 0.5957737480022188, 1.0, 1.0, 0.28442783839583846], 
reward next is 0.7156, 
noisyNet noise sample is [array([-0.7437231], dtype=float32), 0.51574725]. 
=============================================
[2019-04-06 23:39:13,996] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[91.42217]
 [92.69278]
 [92.35752]
 [91.4748 ]
 [91.49961]], R is [[92.49855042]
 [92.57356262]
 [92.37892151]
 [92.01950836]
 [92.09931183]].
[2019-04-06 23:39:48,163] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.6511818e-23 6.5441637e-24 3.8474607e-20 8.2813522e-22 1.0000000e+00
 4.1610882e-24 2.3099341e-23], sum to 1.0000
[2019-04-06 23:39:48,163] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4264
[2019-04-06 23:39:48,416] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.8, 90.0, 0.0, 0.0, 26.0, 24.85322715447998, 0.2327582160971542, 1.0, 1.0, 100859.78108135762], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 498600.0000, 
sim time next is 500400.0000, 
raw observation next is [1.1, 96.0, 0.0, 0.0, 26.0, 25.03083892954923, 0.2156821832117034, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.96, 0.0, 0.0, 0.6666666666666666, 0.5859032441291024, 0.5718940610705677, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05442854], dtype=float32), -0.45294458]. 
=============================================
[2019-04-06 23:40:04,506] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1748487e-22 7.1022511e-21 2.6653354e-18 3.0114971e-20 1.0000000e+00
 6.1496226e-23 9.1763128e-22], sum to 1.0000
[2019-04-06 23:40:04,506] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4966
[2019-04-06 23:40:04,576] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 71.0, 0.0, 0.0, 26.0, 24.44114727006653, 0.1078568670768287, 0.0, 1.0, 41221.40352701094], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 691200.0000, 
sim time next is 693000.0000, 
raw observation next is [-3.65, 71.5, 0.0, 0.0, 26.0, 24.39742115971362, 0.09159336392485422, 0.0, 1.0, 41002.028367138206], 
processed observation next is [1.0, 0.0, 0.3614958448753463, 0.715, 0.0, 0.0, 0.6666666666666666, 0.533118429976135, 0.5305311213082847, 0.0, 1.0, 0.19524775412922954], 
reward next is 0.8048, 
noisyNet noise sample is [array([-2.753936], dtype=float32), 1.0118641]. 
=============================================
[2019-04-06 23:40:04,581] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[78.42363]
 [76.98306]
 [77.15886]
 [77.32532]
 [77.51953]], R is [[79.5062561 ]
 [79.51490784]
 [79.52239227]
 [79.52891541]
 [79.53437042]].
[2019-04-06 23:40:20,110] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.6169474e-24 9.0340676e-25 2.3776601e-20 5.2083601e-22 1.0000000e+00
 2.4678071e-26 1.4298123e-24], sum to 1.0000
[2019-04-06 23:40:20,110] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9273
[2019-04-06 23:40:20,177] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.5, 100.0, 0.0, 0.0, 26.0, 25.41558372863479, 0.3462186673446704, 0.0, 1.0, 33094.87110412374], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3119400.0000, 
sim time next is 3121200.0000, 
raw observation next is [2.0, 100.0, 0.0, 0.0, 26.0, 25.48355041989964, 0.2995299376441649, 0.0, 1.0, 14182.801608467847], 
processed observation next is [1.0, 0.13043478260869565, 0.518005540166205, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6236292016583033, 0.599843312548055, 0.0, 1.0, 0.06753715051651356], 
reward next is 0.9325, 
noisyNet noise sample is [array([0.26823094], dtype=float32), 0.046696663]. 
=============================================
[2019-04-06 23:40:22,848] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-06 23:40:22,850] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:40:22,851] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:40:22,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run95
[2019-04-06 23:40:22,884] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:40:22,887] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:40:22,887] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:40:22,887] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:40:22,893] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run95
[2019-04-06 23:40:22,918] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run95
[2019-04-06 23:42:22,488] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15288548]
[2019-04-06 23:42:22,488] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-9.112389405, 71.68150074, 130.58972745, 515.21019885, 26.0, 25.82538552825266, 0.4707605327239615, 1.0, 1.0, 0.0]
[2019-04-06 23:42:22,488] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 23:42:22,490] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [4.3011838e-20 1.1802824e-20 2.8187136e-17 1.1385753e-19 1.0000000e+00
 2.2512755e-22 4.1419163e-21], sampled 0.5384250486334199
[2019-04-06 23:42:41,826] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 23:43:18,970] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 23:43:22,292] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 23:43:23,363] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 1880000, evaluation results [1880000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 23:43:30,947] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.5849090e-23 1.0578231e-23 7.7427582e-20 2.0687798e-23 1.0000000e+00
 1.3813669e-24 1.7403603e-23], sum to 1.0000
[2019-04-06 23:43:30,948] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3631
[2019-04-06 23:43:31,226] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.5, 93.0, 6.0, 41.0, 26.0, 25.77956628169697, 0.257666434531138, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2914200.0000, 
sim time next is 2916000.0000, 
raw observation next is [1.0, 93.0, 0.0, 0.0, 26.0, 25.02661824831825, 0.3829214729497305, 1.0, 1.0, 62780.22824518571], 
processed observation next is [1.0, 0.782608695652174, 0.4903047091412743, 0.93, 0.0, 0.0, 0.6666666666666666, 0.5855515206931875, 0.6276404909832435, 1.0, 1.0, 0.29895346783421767], 
reward next is 0.7010, 
noisyNet noise sample is [array([0.06462396], dtype=float32), -0.93839025]. 
=============================================
[2019-04-06 23:43:31,233] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[90.5806  ]
 [91.18001 ]
 [91.591385]
 [91.30133 ]
 [91.29936 ]], R is [[90.3243866 ]
 [90.42114258]
 [90.51692963]
 [90.29907227]
 [90.39608002]].
[2019-04-06 23:43:52,737] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6084600e-22 2.2679882e-23 4.5054357e-20 1.8217976e-21 1.0000000e+00
 2.7182680e-25 1.6725265e-23], sum to 1.0000
[2019-04-06 23:43:52,738] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4422
[2019-04-06 23:43:52,765] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [11.5, 26.0, 111.0, 763.0, 26.0, 25.63131266286761, 0.4817481620312781, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3666600.0000, 
sim time next is 3668400.0000, 
raw observation next is [12.0, 24.0, 113.5, 789.5, 26.0, 25.69033241817115, 0.4994997046240477, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.7950138504155125, 0.24, 0.37833333333333335, 0.8723756906077348, 0.6666666666666666, 0.6408610348475957, 0.6664999015413492, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2098384], dtype=float32), -0.48654127]. 
=============================================
[2019-04-06 23:43:54,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:43:54,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:43:54,196] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run43
[2019-04-06 23:43:56,406] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5311819e-24 3.1858064e-25 2.2025501e-22 8.1682346e-25 1.0000000e+00
 4.2674173e-28 1.8775314e-25], sum to 1.0000
[2019-04-06 23:43:56,406] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5166
[2019-04-06 23:43:56,469] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.9, 84.0, 0.0, 0.0, 26.0, 25.8298723484888, 0.6095916266512215, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1636200.0000, 
sim time next is 1638000.0000, 
raw observation next is [7.2, 82.0, 0.0, 0.0, 26.0, 25.58996484007565, 0.5836003853296645, 0.0, 1.0, 54701.620567768674], 
processed observation next is [1.0, 1.0, 0.662049861495845, 0.82, 0.0, 0.0, 0.6666666666666666, 0.6324970700063041, 0.694533461776555, 0.0, 1.0, 0.2604839074655651], 
reward next is 0.7395, 
noisyNet noise sample is [array([-0.0532123], dtype=float32), 0.849129]. 
=============================================
[2019-04-06 23:43:56,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[92.550575]
 [92.86079 ]
 [93.099915]
 [92.98595 ]
 [92.17779 ]], R is [[92.23554993]
 [92.31319427]
 [92.39006042]
 [92.46616364]
 [91.83049011]].
[2019-04-06 23:44:09,905] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7376000e-20 1.1017400e-20 2.4705972e-17 1.4094587e-20 1.0000000e+00
 4.6507195e-22 4.0103812e-21], sum to 1.0000
[2019-04-06 23:44:09,905] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0733
[2019-04-06 23:44:10,159] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-12.0, 58.0, 93.0, 444.0, 26.0, 25.8249195683773, 0.4420903672542753, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4005000.0000, 
sim time next is 4006800.0000, 
raw observation next is [-11.0, 53.0, 97.0, 571.0, 26.0, 26.28445842978498, 0.5033165553371864, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.15789473684210528, 0.53, 0.3233333333333333, 0.630939226519337, 0.6666666666666666, 0.690371535815415, 0.6677721851123954, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8022077], dtype=float32), 0.065172665]. 
=============================================
[2019-04-06 23:44:22,579] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.8794188e-22 2.7209708e-21 2.5907628e-18 6.3552795e-21 1.0000000e+00
 1.6991307e-23 4.4768889e-22], sum to 1.0000
[2019-04-06 23:44:22,580] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1008
[2019-04-06 23:44:22,667] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.69274091532301, 0.2316467671265064, 0.0, 1.0, 42974.35413932679], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1983600.0000, 
sim time next is 1985400.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 26.0, 24.55896156975153, 0.2056281803015261, 0.0, 1.0, 42951.154941222114], 
processed observation next is [1.0, 1.0, 0.30747922437673136, 0.83, 0.0, 0.0, 0.6666666666666666, 0.5465801308126276, 0.5685427267671753, 0.0, 1.0, 0.20452930924391483], 
reward next is 0.7955, 
noisyNet noise sample is [array([-1.4123374], dtype=float32), -1.3296854]. 
=============================================
[2019-04-06 23:44:25,857] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7307490e-21 2.5787676e-22 2.3649339e-19 3.5359099e-21 1.0000000e+00
 3.6883487e-24 8.6671327e-23], sum to 1.0000
[2019-04-06 23:44:25,857] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3903
[2019-04-06 23:44:25,933] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.5, 42.5, 0.0, 0.0, 26.0, 25.3324145968968, 0.4152996154112376, 0.0, 1.0, 45725.79447979031], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4152600.0000, 
sim time next is 4154400.0000, 
raw observation next is [-2.0, 46.0, 0.0, 0.0, 26.0, 25.32728418931422, 0.4001531562246245, 0.0, 1.0, 39310.8965873961], 
processed observation next is [0.0, 0.08695652173913043, 0.40720221606648205, 0.46, 0.0, 0.0, 0.6666666666666666, 0.610607015776185, 0.6333843854082082, 0.0, 1.0, 0.18719474565426714], 
reward next is 0.8128, 
noisyNet noise sample is [array([-0.1419752], dtype=float32), -0.32148504]. 
=============================================
[2019-04-06 23:44:27,037] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0580656e-21 1.3880239e-22 3.9421319e-18 3.7436514e-21 1.0000000e+00
 3.1578459e-24 7.9536200e-23], sum to 1.0000
[2019-04-06 23:44:27,038] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9718
[2019-04-06 23:44:27,133] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.5, 40.0, 0.0, 0.0, 26.0, 25.54191233258457, 0.4685603954636762, 0.0, 1.0, 40948.913998387834], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 5013000.0000, 
sim time next is 5014800.0000, 
raw observation next is [1.0, 40.0, 0.0, 0.0, 26.0, 25.61258654943094, 0.4561953321392395, 0.0, 1.0, 12495.989580853347], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 0.4, 0.0, 0.0, 0.6666666666666666, 0.6343822124525783, 0.6520651107130798, 0.0, 1.0, 0.05950471228977784], 
reward next is 0.9405, 
noisyNet noise sample is [array([-0.395277], dtype=float32), 0.98281765]. 
=============================================
[2019-04-06 23:44:31,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:44:31,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:44:31,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run43
[2019-04-06 23:44:56,566] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.4993606e-23 2.2832077e-21 1.9623874e-19 1.4830728e-21 1.0000000e+00
 7.9444851e-25 1.0360940e-22], sum to 1.0000
[2019-04-06 23:44:56,566] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9349
[2019-04-06 23:44:56,642] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 26.0, 25.5186387788191, 0.5351388753789487, 0.0, 1.0, 33362.061189631866], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4485600.0000, 
sim time next is 4487400.0000, 
raw observation next is [-0.15, 72.0, 0.0, 0.0, 26.0, 25.39534303405642, 0.4832651935409708, 0.0, 1.0, 75033.52357328392], 
processed observation next is [1.0, 0.9565217391304348, 0.458448753462604, 0.72, 0.0, 0.0, 0.6666666666666666, 0.6162785861713683, 0.6610883978469902, 0.0, 1.0, 0.3573024932061139], 
reward next is 0.6427, 
noisyNet noise sample is [array([-1.5744611], dtype=float32), -0.88641626]. 
=============================================
[2019-04-06 23:45:03,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:45:03,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:45:03,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run43
[2019-04-06 23:45:07,090] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9754315e-25 1.6123216e-25 1.8517287e-22 7.0415689e-24 1.0000000e+00
 3.0785066e-27 1.4774562e-26], sum to 1.0000
[2019-04-06 23:45:07,090] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5884
[2019-04-06 23:45:07,198] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.65, 82.0, 120.0, 232.0, 26.0, 25.61999181166874, 0.5553347827208021, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4437000.0000, 
sim time next is 4438800.0000, 
raw observation next is [1.3, 84.0, 142.5, 131.5, 26.0, 26.16852640830941, 0.5928273681868251, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49861495844875353, 0.84, 0.475, 0.1453038674033149, 0.6666666666666666, 0.6807105340257843, 0.6976091227289417, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.973775], dtype=float32), -2.1131558]. 
=============================================
[2019-04-06 23:45:08,286] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.7821747e-23 1.7792682e-23 1.5191425e-19 8.1023588e-23 1.0000000e+00
 6.8192721e-25 6.3692981e-24], sum to 1.0000
[2019-04-06 23:45:08,286] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9629
[2019-04-06 23:45:08,354] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 72.0, 123.5, 5.5, 26.0, 26.16205739521197, 0.5469138966606706, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4723200.0000, 
sim time next is 4725000.0000, 
raw observation next is [1.0, 72.0, 100.0, 11.0, 26.0, 26.14237390963439, 0.4325731362465395, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4903047091412743, 0.72, 0.3333333333333333, 0.012154696132596685, 0.6666666666666666, 0.6785311591361992, 0.6441910454155132, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.26914892], dtype=float32), -0.6133771]. 
=============================================
[2019-04-06 23:45:08,360] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[87.38632 ]
 [88.22727 ]
 [89.26497 ]
 [90.15097 ]
 [90.287895]], R is [[86.87706757]
 [87.00830078]
 [87.11845398]
 [87.21390533]
 [87.34176636]].
[2019-04-06 23:45:12,898] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:45:12,898] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:45:12,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run43
[2019-04-06 23:45:16,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:45:16,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:45:16,123] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run43
[2019-04-06 23:45:18,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:45:18,070] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:45:18,239] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run43
[2019-04-06 23:45:21,599] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.2775546e-22 1.1656147e-21 6.6242079e-17 2.1415732e-20 1.0000000e+00
 2.7429171e-22 2.9116687e-21], sum to 1.0000
[2019-04-06 23:45:21,599] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4328
[2019-04-06 23:45:21,947] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.0, 61.5, 113.0, 799.0, 26.0, 25.86481673930652, 0.3619474276986732, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2723400.0000, 
sim time next is 2725200.0000, 
raw observation next is [-6.0, 59.0, 111.0, 793.5, 26.0, 25.36187789317043, 0.4880518870085745, 1.0, 1.0, 121803.56992693285], 
processed observation next is [1.0, 0.5652173913043478, 0.296398891966759, 0.59, 0.37, 0.8767955801104972, 0.6666666666666666, 0.6134898244308692, 0.6626839623361915, 1.0, 1.0, 0.5800169996520612], 
reward next is 0.4200, 
noisyNet noise sample is [array([1.6565099], dtype=float32), 0.14398655]. 
=============================================
[2019-04-06 23:45:27,962] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:45:27,962] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:45:27,984] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run43
[2019-04-06 23:45:28,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:45:28,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:45:28,904] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run43
[2019-04-06 23:45:35,236] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1087434e-21 7.3627257e-21 2.4550661e-18 7.5326136e-21 1.0000000e+00
 2.1654838e-23 4.9690150e-23], sum to 1.0000
[2019-04-06 23:45:35,237] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9360
[2019-04-06 23:45:35,436] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-2.0, 46.0, 46.5, 280.0, 26.0, 25.22750975104328, 0.2751123051350244, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4953600.0000, 
sim time next is 4955400.0000, 
raw observation next is [-1.5, 42.5, 93.0, 560.0, 26.0, 25.23826871659252, 0.3290622630828317, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4210526315789474, 0.425, 0.31, 0.6187845303867403, 0.6666666666666666, 0.6031890597160432, 0.6096874210276105, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8536723], dtype=float32), -0.9650609]. 
=============================================
[2019-04-06 23:45:37,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:45:37,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:45:37,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run43
[2019-04-06 23:45:42,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:45:42,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:45:42,233] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run43
[2019-04-06 23:45:43,551] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-06 23:45:43,571] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:45:43,571] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:45:43,573] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:45:43,573] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:45:43,588] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:45:43,589] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run96
[2019-04-06 23:45:43,589] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:45:43,615] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run96
[2019-04-06 23:45:43,640] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run96
[2019-04-06 23:48:02,012] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 23:48:43,015] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 23:48:45,667] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 23:48:46,706] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1900000, evaluation results [1900000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 23:49:33,178] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:49:33,178] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:49:33,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run43
[2019-04-06 23:49:45,617] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1369493e-20 2.8393107e-20 4.6225199e-17 8.2524470e-19 1.0000000e+00
 7.1963088e-22 5.9900306e-22], sum to 1.0000
[2019-04-06 23:49:45,618] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3994
[2019-04-06 23:49:45,861] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.45, 26.5, 129.0, 0.0, 26.0, 25.16614446715232, 0.1541813295975249, 1.0, 1.0, 6598.571179839553], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 477000.0000, 
sim time next is 478800.0000, 
raw observation next is [-1.2, 28.0, 124.0, 0.0, 26.0, 24.98724069567509, 0.1569603197840842, 1.0, 1.0, 71522.9033566122], 
processed observation next is [1.0, 0.5652173913043478, 0.42936288088642666, 0.28, 0.41333333333333333, 0.0, 0.6666666666666666, 0.5822700579729242, 0.5523201065946948, 1.0, 1.0, 0.34058525407910567], 
reward next is 0.6594, 
noisyNet noise sample is [array([-1.7309505], dtype=float32), -0.087546274]. 
=============================================
[2019-04-06 23:49:56,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:49:56,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:49:56,469] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run43
[2019-04-06 23:50:02,715] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:50:02,715] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:50:02,719] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run43
[2019-04-06 23:50:08,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8006853e-24 3.9449329e-24 2.8310030e-21 2.1973891e-22 1.0000000e+00
 8.6709511e-27 2.8252377e-24], sum to 1.0000
[2019-04-06 23:50:08,426] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9241
[2019-04-06 23:50:08,510] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.0, 88.5, 85.0, 0.0, 26.0, 26.28505399019848, 0.629437876970835, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4458600.0000, 
sim time next is 4460400.0000, 
raw observation next is [0.0, 85.0, 78.0, 0.0, 26.0, 25.90327241951212, 0.5676023000925212, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.46260387811634357, 0.85, 0.26, 0.0, 0.6666666666666666, 0.6586060349593433, 0.6892007666975072, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8432823], dtype=float32), -0.89502287]. 
=============================================
[2019-04-06 23:50:10,898] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3768119e-23 4.8072139e-23 5.4325203e-20 5.0814990e-23 1.0000000e+00
 1.1725120e-24 1.4888361e-23], sum to 1.0000
[2019-04-06 23:50:10,899] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1664
[2019-04-06 23:50:10,960] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 73.0, 0.0, 0.0, 26.0, 25.59239965185429, 0.4800988696707294, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4496400.0000, 
sim time next is 4498200.0000, 
raw observation next is [-0.6, 73.0, 0.0, 0.0, 26.0, 25.39553364138508, 0.4304229172473928, 0.0, 1.0, 48526.03721492811], 
processed observation next is [1.0, 0.043478260869565216, 0.44598337950138506, 0.73, 0.0, 0.0, 0.6666666666666666, 0.6162944701154233, 0.6434743057491309, 0.0, 1.0, 0.23107636769013387], 
reward next is 0.7689, 
noisyNet noise sample is [array([-2.5964997], dtype=float32), 1.5529565]. 
=============================================
[2019-04-06 23:50:24,604] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.3388738e-22 3.4393129e-22 2.7560738e-19 6.7897473e-21 1.0000000e+00
 1.0556544e-23 2.2021048e-22], sum to 1.0000
[2019-04-06 23:50:24,604] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2184
[2019-04-06 23:50:24,655] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 26.0, 23.60911483366082, 0.1767236726517522, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1229400.0000, 
sim time next is 1231200.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 26.0, 23.58357639551268, 0.1641455987682474, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.8781163434903049, 0.96, 0.0, 0.0, 0.6666666666666666, 0.46529803295938993, 0.5547151995894158, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03787223], dtype=float32), 0.08557409]. 
=============================================
[2019-04-06 23:50:26,132] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4822736e-21 7.4079145e-21 1.0618005e-17 1.1544469e-19 1.0000000e+00
 2.6512839e-23 2.8442308e-21], sum to 1.0000
[2019-04-06 23:50:26,132] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7580
[2019-04-06 23:50:26,285] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-8.4, 78.0, 56.5, 148.0, 26.0, 25.30918009777394, 0.2201754597472716, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 205200.0000, 
sim time next is 207000.0000, 
raw observation next is [-7.85, 76.5, 79.0, 0.0, 26.0, 25.40574658411297, 0.220877628338937, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.24515235457063714, 0.765, 0.2633333333333333, 0.0, 0.6666666666666666, 0.6171455486760807, 0.573625876112979, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7773317], dtype=float32), 1.297433]. 
=============================================
[2019-04-06 23:50:26,295] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[80.43514]
 [80.62351]
 [79.49376]
 [76.48969]
 [75.49824]], R is [[80.23160553]
 [80.42929077]
 [80.5290451 ]
 [80.15644073]
 [79.63922882]].
[2019-04-06 23:50:28,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4724663e-25 7.7204452e-24 8.3859816e-20 4.4510199e-23 1.0000000e+00
 3.0010749e-26 1.4776881e-25], sum to 1.0000
[2019-04-06 23:50:28,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7067
[2019-04-06 23:50:28,225] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.75, 66.0, 130.0, 0.0, 26.0, 25.32675724113466, 0.5228115629610044, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1161000.0000, 
sim time next is 1162800.0000, 
raw observation next is [18.3, 65.0, 145.0, 0.0, 26.0, 25.23950041227705, 0.5149509512098637, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.9695290858725764, 0.65, 0.48333333333333334, 0.0, 0.6666666666666666, 0.6032917010230875, 0.6716503170699545, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3059532], dtype=float32), -0.5963306]. 
=============================================
[2019-04-06 23:50:40,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:50:40,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:50:40,720] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run43
[2019-04-06 23:50:42,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:50:42,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:50:42,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run43
[2019-04-06 23:50:45,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:50:45,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:50:45,835] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run43
[2019-04-06 23:51:20,517] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.2102981e-18 1.0686428e-18 1.1083822e-15 1.1182893e-17 1.0000000e+00
 1.0670165e-20 1.0175922e-18], sum to 1.0000
[2019-04-06 23:51:20,517] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1736
[2019-04-06 23:51:20,701] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-9.5, 42.0, 47.0, 358.5, 26.0, 26.28631226630839, 0.4862436823783554, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 316800.0000, 
sim time next is 318600.0000, 
raw observation next is [-10.05, 45.5, 24.0, 240.0, 26.0, 25.7611928634913, 0.3822726842110293, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.18421052631578946, 0.455, 0.08, 0.26519337016574585, 0.6666666666666666, 0.6467660719576083, 0.6274242280703431, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24845415], dtype=float32), -0.29356718]. 
=============================================
[2019-04-06 23:51:30,209] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-06 23:51:30,210] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:51:30,210] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:51:30,210] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:51:30,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run97
[2019-04-06 23:51:30,211] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:51:30,257] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:51:30,257] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:51:30,261] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run97
[2019-04-06 23:51:30,281] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run97
[2019-04-06 23:52:06,014] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15333804]
[2019-04-06 23:52:06,015] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [15.50813595, 64.68363443999999, 0.0, 0.0, 26.0, 25.65587003313256, 0.5645378026007241, 0.0, 1.0, 18729.100924338607]
[2019-04-06 23:52:06,015] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 23:52:06,016] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.0578589e-24 1.4009376e-25 1.4899627e-21 1.8998453e-24 1.0000000e+00
 8.6544570e-28 2.8961417e-26], sampled 0.4751679742724294
[2019-04-06 23:53:50,140] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 23:54:01,110] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15333804]
[2019-04-06 23:54:01,110] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [0.747627499, 40.05525283, 0.0, 0.0, 26.0, 25.86195895299167, 0.5329983489247104, 1.0, 1.0, 0.0]
[2019-04-06 23:54:01,110] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-06 23:54:01,111] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [8.6539264e-21 2.4889531e-21 5.3056084e-18 2.2341077e-20 1.0000000e+00
 3.5054467e-23 1.0591324e-21], sampled 0.8857183528700582
[2019-04-06 23:54:25,286] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 23:54:30,511] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 23:54:31,559] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1920000, evaluation results [1920000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-06 23:54:32,846] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0405772e-26 1.3766095e-27 2.8112125e-21 3.5213252e-25 1.0000000e+00
 3.6688077e-28 3.9979831e-26], sum to 1.0000
[2019-04-06 23:54:32,846] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1155
[2019-04-06 23:54:32,897] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.4, 75.0, 0.0, 0.0, 26.0, 25.96175515602514, 0.6162942231875347, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1031400.0000, 
sim time next is 1033200.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 26.0, 25.85214320487536, 0.5937934309086293, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.8614958448753465, 0.75, 0.0, 0.0, 0.6666666666666666, 0.6543452670729467, 0.6979311436362098, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4452249], dtype=float32), 0.75919735]. 
=============================================
[2019-04-06 23:54:47,665] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.0256716e-24 4.5422358e-24 1.0950156e-19 7.5055578e-23 1.0000000e+00
 4.3691376e-26 4.9970286e-25], sum to 1.0000
[2019-04-06 23:54:47,665] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3155
[2019-04-06 23:54:47,797] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 59.0, 0.0, 26.0, 26.01518199974294, 0.5397480944120818, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1436400.0000, 
sim time next is 1438200.0000, 
raw observation next is [1.1, 92.0, 46.0, 0.0, 26.0, 25.91053852511479, 0.51570699518312, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.92, 0.15333333333333332, 0.0, 0.6666666666666666, 0.6592115437595659, 0.6719023317277067, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9481466], dtype=float32), -1.0126437]. 
=============================================
[2019-04-06 23:55:34,042] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.8267578e-24 4.0741467e-26 1.1070942e-21 4.2393748e-23 1.0000000e+00
 7.1497154e-28 6.8739330e-26], sum to 1.0000
[2019-04-06 23:55:34,042] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4158
[2019-04-06 23:55:34,226] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 85.0, 0.0, 0.0, 26.0, 25.04196745769413, 0.377775664922633, 1.0, 1.0, 20701.752233295563], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2921400.0000, 
sim time next is 2923200.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 26.0, 24.91720594726637, 0.4025110198617031, 0.0, 1.0, 85612.4058522579], 
processed observation next is [1.0, 0.8695652173913043, 0.4349030470914128, 0.78, 0.0, 0.0, 0.6666666666666666, 0.5764338289388643, 0.634170339953901, 0.0, 1.0, 0.40767812310599], 
reward next is 0.5923, 
noisyNet noise sample is [array([0.6690941], dtype=float32), 1.4383056]. 
=============================================
[2019-04-06 23:55:34,494] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4341704e-25 9.6397077e-25 5.1927495e-21 3.2527111e-23 1.0000000e+00
 5.2001476e-27 4.6482315e-24], sum to 1.0000
[2019-04-06 23:55:34,494] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2691
[2019-04-06 23:55:34,543] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.1, 92.0, 114.5, 0.0, 26.0, 26.11374377096437, 0.5918316091378905, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1335600.0000, 
sim time next is 1337400.0000, 
raw observation next is [1.1, 92.0, 127.0, 0.0, 26.0, 26.11745283631738, 0.5915116964705637, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.49307479224376743, 0.92, 0.42333333333333334, 0.0, 0.6666666666666666, 0.6764544030264483, 0.6971705654901879, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.078892], dtype=float32), 0.12111071]. 
=============================================
[2019-04-06 23:55:36,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:55:36,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:55:36,579] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run44
[2019-04-06 23:56:05,859] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5344570e-23 1.9235247e-23 9.5916019e-21 1.2130738e-22 1.0000000e+00
 1.3314911e-25 6.2489853e-25], sum to 1.0000
[2019-04-06 23:56:05,859] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0914
[2019-04-06 23:56:05,939] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [1.0, 79.0, 0.0, 0.0, 26.0, 25.52300508649019, 0.4316665049181447, 0.0, 1.0, 8695.547372833877], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3463200.0000, 
sim time next is 3465000.0000, 
raw observation next is [1.0, 75.5, 0.0, 0.0, 26.0, 25.40349068231395, 0.4295600885067115, 0.0, 1.0, 69408.68730333533], 
processed observation next is [1.0, 0.08695652173913043, 0.4903047091412743, 0.755, 0.0, 0.0, 0.6666666666666666, 0.6169575568594959, 0.6431866961689038, 0.0, 1.0, 0.33051755858731113], 
reward next is 0.6695, 
noisyNet noise sample is [array([0.6812379], dtype=float32), -1.0673448]. 
=============================================
[2019-04-06 23:56:05,943] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[88.27236 ]
 [88.561424]
 [88.425995]
 [88.41667 ]
 [88.32016 ]], R is [[88.27368927]
 [88.34954834]
 [88.28611755]
 [88.22859955]
 [88.20980835]].
[2019-04-06 23:56:12,199] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8778585e-20 3.1377616e-21 9.9062852e-18 2.6892076e-22 1.0000000e+00
 4.8663668e-23 2.7919421e-22], sum to 1.0000
[2019-04-06 23:56:12,199] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8309
[2019-04-06 23:56:12,417] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 70.0, 94.0, 550.5, 26.0, 25.90853678100685, 0.5277696931283878, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3574800.0000, 
sim time next is 3576600.0000, 
raw observation next is [-5.5, 67.5, 100.0, 676.0, 26.0, 25.89881593359816, 0.5269323333789293, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3102493074792244, 0.675, 0.3333333333333333, 0.7469613259668508, 0.6666666666666666, 0.6582346611331801, 0.6756441111263097, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2076541], dtype=float32), 0.13403004]. 
=============================================
[2019-04-06 23:56:18,375] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-06 23:56:18,375] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:56:18,378] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run44
[2019-04-06 23:56:34,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9025653e-22 1.5573561e-22 1.5434843e-18 3.1104944e-21 1.0000000e+00
 8.8484958e-24 9.7200677e-23], sum to 1.0000
[2019-04-06 23:56:34,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0442
[2019-04-06 23:56:34,462] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 54.0, 117.0, 804.5, 26.0, 26.35715974279543, 0.6054870652257306, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3326400.0000, 
sim time next is 3328200.0000, 
raw observation next is [-5.5, 54.0, 118.0, 811.0, 26.0, 26.24678663858172, 0.5773403726079762, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.3102493074792244, 0.54, 0.3933333333333333, 0.8961325966850828, 0.6666666666666666, 0.68723221988181, 0.6924467908693254, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2687152], dtype=float32), 0.9187701]. 
=============================================
[2019-04-06 23:56:52,836] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.3300553e-20 2.2581501e-20 3.2652045e-16 4.4888639e-20 1.0000000e+00
 8.4179279e-22 2.2327178e-21], sum to 1.0000
[2019-04-06 23:56:52,836] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3293
[2019-04-06 23:56:52,877] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [2.75, 27.0, 78.0, 784.0, 26.0, 24.97476857504204, 0.2791669270795707, 0.0, 1.0, 6234.173358265753], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2471400.0000, 
sim time next is 2473200.0000, 
raw observation next is [3.3, 27.0, 70.0, 732.0, 26.0, 24.96741106508444, 0.2829623266605146, 0.0, 1.0, 12468.001640961505], 
processed observation next is [0.0, 0.6521739130434783, 0.554016620498615, 0.27, 0.23333333333333334, 0.8088397790055248, 0.6666666666666666, 0.5806175887570367, 0.5943207755535048, 0.0, 1.0, 0.05937143638553098], 
reward next is 0.9406, 
noisyNet noise sample is [array([-0.86254543], dtype=float32), 0.99744797]. 
=============================================
[2019-04-06 23:56:54,886] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-06 23:56:54,886] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:56:54,886] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:56:54,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run98
[2019-04-06 23:56:54,916] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-06 23:56:54,920] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:56:54,918] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-06 23:56:54,921] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-06 23:56:54,925] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run98
[2019-04-06 23:56:54,954] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run98
[2019-04-06 23:59:07,407] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-06 23:59:47,634] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-06 23:59:52,209] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-06 23:59:53,247] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1940000, evaluation results [1940000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-07 00:00:03,011] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:00:03,011] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:00:03,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run44
[2019-04-07 00:00:03,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:00:03,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:00:03,164] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run44
[2019-04-07 00:00:18,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:00:18,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:00:18,171] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run44
[2019-04-07 00:00:30,157] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:00:30,157] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:00:30,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run44
[2019-04-07 00:00:33,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:00:33,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:00:33,323] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run44
[2019-04-07 00:00:36,973] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:00:36,973] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:00:36,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run44
[2019-04-07 00:00:40,197] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5432077e-25 9.1118673e-26 5.7547577e-22 3.2935256e-24 1.0000000e+00
 5.5351877e-28 4.2716749e-25], sum to 1.0000
[2019-04-07 00:00:40,197] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9911
[2019-04-07 00:00:40,266] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [5.5, 97.0, 0.0, 0.0, 26.0, 25.47897807552574, 0.5520929335269019, 0.0, 1.0, 64235.633984899294], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1663200.0000, 
sim time next is 1665000.0000, 
raw observation next is [5.25, 94.5, 0.0, 0.0, 26.0, 25.65576717553571, 0.5483615465806211, 0.0, 1.0, 6249.018166820733], 
processed observation next is [1.0, 0.2608695652173913, 0.60803324099723, 0.945, 0.0, 0.0, 0.6666666666666666, 0.6379805979613092, 0.6827871821935404, 0.0, 1.0, 0.029757229365813015], 
reward next is 0.9702, 
noisyNet noise sample is [array([-0.73725134], dtype=float32), 0.17842725]. 
=============================================
[2019-04-07 00:00:40,302] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[98.8044  ]
 [98.689644]
 [98.9108  ]
 [98.85879 ]
 [99.076965]], R is [[98.25532532]
 [97.96688843]
 [97.88076782]
 [97.65900421]
 [97.68241882]].
[2019-04-07 00:00:41,136] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:00:41,136] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:00:41,140] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run44
[2019-04-07 00:00:41,969] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:00:41,969] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:00:41,973] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run44
[2019-04-07 00:00:54,009] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.2901470e-24 1.4814979e-25 9.2122283e-22 8.4559568e-25 1.0000000e+00
 4.0504796e-28 1.6036237e-25], sum to 1.0000
[2019-04-07 00:00:54,009] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2229
[2019-04-07 00:00:54,223] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [7.2, 86.0, 64.5, 0.0, 26.0, 24.47161442805653, 0.1615151389058745, 0.0, 1.0, 29927.54599159672], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 54000.0000, 
sim time next is 55800.0000, 
raw observation next is [6.9, 84.0, 50.0, 0.0, 26.0, 24.46403510472185, 0.178858205317101, 0.0, 1.0, 47597.94832786437], 
processed observation next is [0.0, 0.6521739130434783, 0.6537396121883658, 0.84, 0.16666666666666666, 0.0, 0.6666666666666666, 0.5386695920601543, 0.559619401772367, 0.0, 1.0, 0.22665689679935414], 
reward next is 0.7733, 
noisyNet noise sample is [array([0.51902306], dtype=float32), 0.031563476]. 
=============================================
[2019-04-07 00:01:00,973] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0662184e-23 1.0520679e-24 8.4415672e-21 4.7411392e-24 1.0000000e+00
 1.4777444e-25 8.0141544e-26], sum to 1.0000
[2019-04-07 00:01:00,974] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3631
[2019-04-07 00:01:01,048] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.0, 71.0, 0.0, 0.0, 26.0, 25.42597305867709, 0.3864769071404976, 0.0, 1.0, 73609.13301311833], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4330800.0000, 
sim time next is 4332600.0000, 
raw observation next is [3.95, 70.5, 0.0, 0.0, 26.0, 25.66520258531298, 0.4037992180740356, 0.0, 1.0, 13799.68524048654], 
processed observation next is [1.0, 0.13043478260869565, 0.57202216066482, 0.705, 0.0, 0.0, 0.6666666666666666, 0.6387668821094149, 0.6345997393580118, 0.0, 1.0, 0.06571278685945972], 
reward next is 0.9343, 
noisyNet noise sample is [array([-0.5013416], dtype=float32), -0.3347751]. 
=============================================
[2019-04-07 00:01:18,380] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [3.0353266e-19 8.4994107e-20 2.8201237e-16 1.1950440e-18 1.0000000e+00
 9.7603540e-21 2.2403132e-19], sum to 1.0000
[2019-04-07 00:01:18,380] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2654
[2019-04-07 00:01:18,513] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-11.15, 51.5, 0.0, 0.0, 26.0, 24.20545605198257, 0.08112858723500828, 0.0, 1.0, 44796.734031779604], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 426600.0000, 
sim time next is 428400.0000, 
raw observation next is [-11.7, 54.0, 0.0, 0.0, 26.0, 24.03389210952702, 0.04214468549334138, 0.0, 1.0, 44754.32526544369], 
processed observation next is [1.0, 1.0, 0.13850415512465375, 0.54, 0.0, 0.0, 0.6666666666666666, 0.502824342460585, 0.5140482284977804, 0.0, 1.0, 0.2131158345973509], 
reward next is 0.7869, 
noisyNet noise sample is [array([0.5377431], dtype=float32), 0.17468864]. 
=============================================
[2019-04-07 00:01:18,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:01:18,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:01:18,716] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run44
[2019-04-07 00:01:31,144] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.6059242e-19 2.8449391e-19 4.9699074e-15 9.1482999e-18 1.0000000e+00
 4.5714112e-21 1.6423771e-20], sum to 1.0000
[2019-04-07 00:01:31,144] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2242
[2019-04-07 00:01:31,366] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 32.0, 80.0, 0.0, 26.0, 25.54762069955776, 0.1979925940151861, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 468000.0000, 
sim time next is 469800.0000, 
raw observation next is [-3.4, 30.0, 98.0, 0.0, 26.0, 25.47246915676806, 0.1736126650857671, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.368421052631579, 0.3, 0.32666666666666666, 0.0, 0.6666666666666666, 0.622705763064005, 0.5578708883619223, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.64384955], dtype=float32), -0.1773383]. 
=============================================
[2019-04-07 00:01:37,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:01:37,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:01:37,412] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run44
[2019-04-07 00:01:39,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:01:39,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:01:39,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run44
[2019-04-07 00:02:12,655] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0497920e-24 1.3654604e-25 2.3315717e-22 1.3154968e-25 1.0000000e+00
 2.8972106e-28 3.5472767e-26], sum to 1.0000
[2019-04-07 00:02:12,683] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3381
[2019-04-07 00:02:12,724] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [6.9, 96.5, 0.0, 0.0, 26.0, 25.71778124231296, 0.5715246421622472, 0.0, 1.0, 11519.577271787666], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1650600.0000, 
sim time next is 1652400.0000, 
raw observation next is [6.6, 97.0, 0.0, 0.0, 26.0, 25.6032470540022, 0.5358863647742547, 0.0, 1.0, 35526.7385192295], 
processed observation next is [1.0, 0.13043478260869565, 0.6454293628808865, 0.97, 0.0, 0.0, 0.6666666666666666, 0.6336039211668499, 0.6786287882580849, 0.0, 1.0, 0.16917494532966426], 
reward next is 0.8308, 
noisyNet noise sample is [array([-2.1800501], dtype=float32), 0.75706327]. 
=============================================
[2019-04-07 00:02:17,706] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.0580926e-21 5.3746338e-22 2.0695033e-18 4.4479715e-20 1.0000000e+00
 3.8989898e-23 2.3663664e-21], sum to 1.0000
[2019-04-07 00:02:17,706] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7497
[2019-04-07 00:02:17,784] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [15.8, 88.0, 0.0, 0.0, 26.0, 24.0049826441485, 0.2456462007426482, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1218600.0000, 
sim time next is 1220400.0000, 
raw observation next is [15.5, 93.0, 0.0, 0.0, 26.0, 23.92211593293877, 0.2303064331286534, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.8919667590027703, 0.93, 0.0, 0.0, 0.6666666666666666, 0.4935096610782308, 0.5767688110428845, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09870782], dtype=float32), 0.31772104]. 
=============================================
[2019-04-07 00:02:28,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:02:28,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:02:28,364] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run44
[2019-04-07 00:02:28,792] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9239485e-19 8.7582416e-21 2.0870877e-18 3.3232932e-19 1.0000000e+00
 2.2714267e-22 2.3413771e-21], sum to 1.0000
[2019-04-07 00:02:28,792] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9700
[2019-04-07 00:02:28,877] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.55, 35.5, 56.0, 0.0, 26.0, 25.73356785272627, 0.2852151510116198, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 487800.0000, 
sim time next is 489600.0000, 
raw observation next is [1.1, 34.0, 38.0, 0.0, 26.0, 25.64909377965871, 0.2701799787876037, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.49307479224376743, 0.34, 0.12666666666666668, 0.0, 0.6666666666666666, 0.6374244816382258, 0.5900599929292012, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.40354663], dtype=float32), 1.2327352]. 
=============================================
[2019-04-07 00:02:29,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:02:29,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:02:29,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run44
[2019-04-07 00:02:31,227] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-07 00:02:31,229] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 00:02:31,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:02:31,233] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run99
[2019-04-07 00:02:31,309] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 00:02:31,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:02:31,314] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run99
[2019-04-07 00:02:31,357] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 00:02:31,357] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:02:31,362] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run99
[2019-04-07 00:04:49,338] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-07 00:05:29,599] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-07 00:05:33,506] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-07 00:05:34,545] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 1960000, evaluation results [1960000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-07 00:05:39,004] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.1692597e-25 9.8381085e-28 3.0009435e-22 2.7245486e-25 1.0000000e+00
 1.7054522e-27 1.0074602e-27], sum to 1.0000
[2019-04-07 00:05:39,005] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7380
[2019-04-07 00:05:39,058] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [11.6, 52.0, 76.0, 570.5, 26.0, 26.59950283703584, 0.749277622391841, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1522800.0000, 
sim time next is 1524600.0000, 
raw observation next is [11.9, 51.0, 77.0, 478.0, 26.0, 26.64582023098835, 0.7563002044828387, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.7922437673130196, 0.51, 0.25666666666666665, 0.5281767955801105, 0.6666666666666666, 0.7204850192490291, 0.7521000681609462, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4309148], dtype=float32), -0.6408516]. 
=============================================
[2019-04-07 00:05:39,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:05:39,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:05:39,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run44
[2019-04-07 00:06:02,033] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1750155e-21 3.7677042e-22 4.9398063e-19 5.3293105e-22 1.0000000e+00
 2.8174363e-23 3.3313463e-23], sum to 1.0000
[2019-04-07 00:06:02,033] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1660
[2019-04-07 00:06:02,108] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [0.5, 50.0, 110.0, 611.0, 26.0, 25.58459613956564, 0.3591375272923165, 1.0, 1.0, 24820.805173622783], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 738000.0000, 
sim time next is 739800.0000, 
raw observation next is [0.5, 47.5, 89.0, 773.0, 26.0, 25.3588383679842, 0.3820715348137063, 1.0, 1.0, 18680.59799159462], 
processed observation next is [1.0, 0.5652173913043478, 0.4764542936288089, 0.475, 0.2966666666666667, 0.8541436464088398, 0.6666666666666666, 0.6132365306653501, 0.6273571782712354, 1.0, 1.0, 0.08895522853140295], 
reward next is 0.9110, 
noisyNet noise sample is [array([0.61841935], dtype=float32), -0.67422473]. 
=============================================
[2019-04-07 00:07:21,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:07:21,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:07:21,179] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run45
[2019-04-07 00:07:27,123] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9488233e-21 1.6102342e-22 6.7752389e-19 3.3191216e-21 1.0000000e+00
 3.5543374e-24 2.0014315e-23], sum to 1.0000
[2019-04-07 00:07:27,123] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7143
[2019-04-07 00:07:27,165] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 45.0, 0.0, 0.0, 26.0, 25.35066282910596, 0.3337373132257537, 0.0, 1.0, 46081.05292346344], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4251600.0000, 
sim time next is 4253400.0000, 
raw observation next is [3.0, 47.0, 0.0, 0.0, 26.0, 25.38555445029439, 0.3276472557412934, 0.0, 1.0, 34610.775833855216], 
processed observation next is [0.0, 0.21739130434782608, 0.5457063711911359, 0.47, 0.0, 0.0, 0.6666666666666666, 0.6154628708578658, 0.6092157519137644, 0.0, 1.0, 0.1648132182564534], 
reward next is 0.8352, 
noisyNet noise sample is [array([0.73968536], dtype=float32), -0.28623062]. 
=============================================
[2019-04-07 00:07:30,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.96913528e-20 1.06601964e-20 2.94946964e-18 3.58144261e-20
 1.00000000e+00 3.42047185e-22 1.33424950e-21], sum to 1.0000
[2019-04-07 00:07:30,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5449
[2019-04-07 00:07:30,521] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.3, 25.0, 27.0, 161.0, 26.0, 25.05000717142949, 0.2350673859056064, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2480400.0000, 
sim time next is 2482200.0000, 
raw observation next is [2.2, 26.5, 0.0, 0.0, 26.0, 24.8586684332525, 0.2065327802736677, 0.0, 1.0, 65926.17935867504], 
processed observation next is [0.0, 0.7391304347826086, 0.5235457063711911, 0.265, 0.0, 0.0, 0.6666666666666666, 0.5715557027710417, 0.5688442600912226, 0.0, 1.0, 0.3139341874222621], 
reward next is 0.6861, 
noisyNet noise sample is [array([-0.727198], dtype=float32), -0.30873737]. 
=============================================
[2019-04-07 00:07:55,456] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.9547951e-20 1.4568156e-19 7.6551628e-17 2.2289428e-18 1.0000000e+00
 2.4624440e-21 1.7761515e-20], sum to 1.0000
[2019-04-07 00:07:55,456] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1436
[2019-04-07 00:07:55,757] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-10.05, 45.5, 24.0, 240.0, 26.0, 25.7611928634913, 0.3822726842110293, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 318600.0000, 
sim time next is 320400.0000, 
raw observation next is [-10.6, 49.0, 12.0, 123.0, 26.0, 25.73770581043334, 0.3034602691692624, 1.0, 1.0, 123946.38004885237], 
processed observation next is [1.0, 0.7391304347826086, 0.1689750692520776, 0.49, 0.04, 0.13591160220994475, 0.6666666666666666, 0.6448088175361116, 0.6011534230564207, 1.0, 1.0, 0.5902208573754875], 
reward next is 0.4098, 
noisyNet noise sample is [array([1.6386379], dtype=float32), 0.34904358]. 
=============================================
[2019-04-07 00:08:02,094] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.2945673e-21 9.3871116e-23 2.6402894e-18 1.3634488e-21 1.0000000e+00
 1.7158042e-24 2.5692334e-22], sum to 1.0000
[2019-04-07 00:08:02,094] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1275
[2019-04-07 00:08:02,192] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.5, 61.0, 0.0, 0.0, 26.0, 24.94581945848122, 0.3543763719363094, 0.0, 1.0, 143168.81837086185], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 3699000.0000, 
sim time next is 3700800.0000, 
raw observation next is [3.0, 63.0, 0.0, 0.0, 26.0, 25.41452532660796, 0.4590483879111076, 0.0, 1.0, 81265.2018848229], 
processed observation next is [0.0, 0.8695652173913043, 0.5457063711911359, 0.63, 0.0, 0.0, 0.6666666666666666, 0.6178771105506634, 0.6530161293037026, 0.0, 1.0, 0.38697715183249004], 
reward next is 0.6130, 
noisyNet noise sample is [array([0.1673595], dtype=float32), -0.38358176]. 
=============================================
[2019-04-07 00:08:09,893] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:08:09,893] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:08:09,896] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run45
[2019-04-07 00:08:10,765] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-07 00:08:10,777] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 00:08:10,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:08:10,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run100
[2019-04-07 00:08:10,818] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 00:08:10,820] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:08:10,820] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 00:08:10,825] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:08:10,825] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run100
[2019-04-07 00:08:10,845] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run100
[2019-04-07 00:10:28,174] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-07 00:11:06,408] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-07 00:11:07,249] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-07 00:11:08,287] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1980000, evaluation results [1980000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
[2019-04-07 00:11:47,943] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3204968e-23 2.2103263e-23 8.6977452e-21 9.7960785e-23 1.0000000e+00
 7.4321532e-26 2.7070831e-24], sum to 1.0000
[2019-04-07 00:11:47,943] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7920
[2019-04-07 00:11:48,036] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 78.0, 0.0, 0.0, 26.0, 25.29511005883371, 0.4572716084176529, 1.0, 1.0, 8695.923612667613], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4735800.0000, 
sim time next is 4737600.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 26.0, 25.04114547564375, 0.4173462058120625, 0.0, 1.0, 36313.03841583816], 
processed observation next is [1.0, 0.8695652173913043, 0.4349030470914128, 0.78, 0.0, 0.0, 0.6666666666666666, 0.5867621229703124, 0.6391154019373542, 0.0, 1.0, 0.17291923055161026], 
reward next is 0.8271, 
noisyNet noise sample is [array([0.46671256], dtype=float32), 0.055057637]. 
=============================================
[2019-04-07 00:11:52,098] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0370520e-20 3.1350097e-21 1.1370921e-17 9.7846277e-20 1.0000000e+00
 7.1611743e-22 2.5848754e-21], sum to 1.0000
[2019-04-07 00:11:52,118] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6073
[2019-04-07 00:11:52,151] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 37.0, 97.0, 727.0, 26.0, 25.1866778991961, 0.4436124419076233, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4807800.0000, 
sim time next is 4809600.0000, 
raw observation next is [3.0, 37.0, 89.5, 638.0, 26.0, 25.19619606924905, 0.4382142390343596, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.37, 0.29833333333333334, 0.7049723756906078, 0.6666666666666666, 0.5996830057707543, 0.6460714130114532, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2630164], dtype=float32), 0.041652422]. 
=============================================
[2019-04-07 00:11:53,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5382080e-21 3.2111529e-22 1.6715039e-18 1.3369658e-20 1.0000000e+00
 3.5515760e-22 2.6645573e-22], sum to 1.0000
[2019-04-07 00:11:53,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8306
[2019-04-07 00:11:53,539] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [3.0, 28.0, 171.0, 482.0, 26.0, 25.41841486332736, 0.3428289143284406, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 2554200.0000, 
sim time next is 2556000.0000, 
raw observation next is [3.8, 26.0, 165.0, 378.5, 26.0, 25.72790539894842, 0.3669857544353481, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5678670360110805, 0.26, 0.55, 0.41823204419889504, 0.6666666666666666, 0.6439921165790349, 0.6223285848117827, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0871495], dtype=float32), 0.85809004]. 
=============================================
[2019-04-07 00:11:53,592] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[80.59288 ]
 [80.4407  ]
 [80.30363 ]
 [80.56325 ]
 [80.706505]], R is [[80.41649628]
 [80.61233521]
 [80.80621338]
 [80.99815369]
 [81.18817139]].
[2019-04-07 00:12:03,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:12:03,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:12:03,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run45
[2019-04-07 00:12:06,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:12:06,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:12:06,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run45
[2019-04-07 00:12:08,700] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4672980e-23 1.8082727e-24 6.6052694e-21 3.8778487e-25 1.0000000e+00
 1.5805636e-25 2.3447969e-24], sum to 1.0000
[2019-04-07 00:12:08,701] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6252
[2019-04-07 00:12:08,718] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [8.0, 26.0, 113.0, 839.5, 26.0, 27.22106162682649, 0.8000215266522908, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 4975200.0000, 
sim time next is 4977000.0000, 
raw observation next is [8.0, 26.0, 109.0, 819.0, 26.0, 27.55096537183788, 0.8557738198630905, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.6842105263157896, 0.26, 0.36333333333333334, 0.9049723756906077, 0.6666666666666666, 0.7959137809864899, 0.7852579399543634, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5834244], dtype=float32), 0.48405042]. 
=============================================
[2019-04-07 00:12:08,723] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[88.57136]
 [87.86587]
 [87.25991]
 [86.54746]
 [85.57282]], R is [[89.37973022]
 [89.4859314 ]
 [89.59107208]
 [89.69515991]
 [89.79821014]].
[2019-04-07 00:12:14,558] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:12:14,558] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:12:14,562] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run45
[2019-04-07 00:12:15,341] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:12:15,341] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:12:15,360] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run45
[2019-04-07 00:12:21,393] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:12:21,393] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:12:21,396] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run45
[2019-04-07 00:12:28,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:12:28,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:12:28,568] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run45
[2019-04-07 00:12:29,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:12:29,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:12:29,706] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run45
[2019-04-07 00:12:30,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:12:30,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:12:30,178] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run45
[2019-04-07 00:12:35,389] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.9963980e-22 7.9143393e-22 4.9715114e-18 6.7279935e-22 1.0000000e+00
 2.4704765e-23 1.2794249e-22], sum to 1.0000
[2019-04-07 00:12:35,389] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8296
[2019-04-07 00:12:35,569] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 26.0, 25.22744107577471, 0.2587622646609418, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 237600.0000, 
sim time next is 239400.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 26.0, 24.98570963297718, 0.2129605513808907, 1.0, 1.0, 56706.10281531004], 
processed observation next is [1.0, 0.782608695652174, 0.368421052631579, 0.65, 0.0, 0.0, 0.6666666666666666, 0.582142469414765, 0.570986850460297, 1.0, 1.0, 0.2700290610252859], 
reward next is 0.7300, 
noisyNet noise sample is [array([0.13850516], dtype=float32), 0.68357813]. 
=============================================
[2019-04-07 00:13:01,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:13:01,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:13:01,664] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run45
[2019-04-07 00:13:17,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:13:17,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:13:17,667] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run45
[2019-04-07 00:13:23,797] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 00:13:23,797] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:13:23,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run45
[2019-04-07 00:13:38,902] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1643006e-22 2.8832722e-22 2.0475230e-19 4.6048555e-22 1.0000000e+00
 2.9131210e-23 1.2075059e-22], sum to 1.0000
[2019-04-07 00:13:38,902] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2262
[2019-04-07 00:13:38,997] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.0, 65.0, 0.0, 0.0, 26.0, 24.79346678968571, 0.4237684345952058, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1189800.0000, 
sim time next is 1191600.0000, 
raw observation next is [17.7, 67.0, 0.0, 0.0, 26.0, 24.73285832577455, 0.4084158947322918, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.9529085872576178, 0.67, 0.0, 0.0, 0.6666666666666666, 0.5610715271478792, 0.6361386315774306, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1732692], dtype=float32), -1.1290425]. 
=============================================
[2019-04-07 00:13:44,814] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-07 00:13:44,820] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 00:13:44,820] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:13:44,824] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run101
[2019-04-07 00:13:44,854] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 00:13:44,880] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 00:13:44,890] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:13:44,891] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 00:13:46,502] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run101
[2019-04-07 00:13:46,528] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/45/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run101
[2019-04-07 00:14:28,263] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15531954]
[2019-04-07 00:14:28,263] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [4.65, 84.5, 0.0, 0.0, 26.0, 25.55192344997032, 0.5013054664577342, 0.0, 1.0, 16673.123116000712]
[2019-04-07 00:14:28,263] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 00:14:28,264] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.9742269e-24 4.1954660e-25 2.5966559e-21 5.3778277e-24 1.0000000e+00
 3.7937846e-27 9.9832930e-26], sampled 0.7757358376584208
[2019-04-07 00:16:13,167] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2454.7988 79953378.9028 535.2730
[2019-04-07 00:16:17,743] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.00756029], dtype=float32), 0.15531954]
[2019-04-07 00:16:17,744] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-1.5, 21.0, 89.0, 712.0, 26.0, 26.84906144013901, 0.5872047710938159, 1.0, 1.0, 0.0]
[2019-04-07 00:16:17,744] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 00:16:17,745] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.8869731e-20 1.3883167e-20 2.0519194e-17 9.4554467e-20 1.0000000e+00
 2.6517606e-22 6.1775145e-21], sampled 0.055904606814949576
[2019-04-07 00:16:54,167] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2416.9920 87788194.3572 515.3379
[2019-04-07 00:16:58,028] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2397.3903 91930456.6128 409.3872
[2019-04-07 00:16:59,068] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 2000000, evaluation results [2000000.0, 2416.991962528224, 87788194.35718836, 515.3379063860621, 2454.7988308773406, 79953378.90284702, 535.2729564010272, 2397.390291572798, 91930456.61283225, 409.38716111533705]
Traceback (most recent call last):
  File "../../../a3c_eplus_rlParametric_v0.1.py", line 48, in <module>
    main()
  File "../../../a3c_eplus_rlParametric_v0.1.py", line 44, in main
    eval_action_limits, raw_state_process_func, raw_stateLimit_process_func);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/main_args.py", line 195, in effective_main
    args.debug_log_prob, args.is_greedy_policy, args.action_repeat_n, args.eval_env_res_max_keep);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 850, in fit
    coordinator.join(threads);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py", line 397, in join
    " ".join(stragglers))
RuntimeError: Coordinator stopped with threads still running: Thread-18 Thread-19 Thread-15 Thread-6 Thread-12 Thread-2 Thread-8 Thread-16 Thread-20 Thread-5 Thread-17 Thread-7
