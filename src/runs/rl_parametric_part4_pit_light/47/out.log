Using TensorFlow backend.
[2019-04-07 10:48:13,016] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part4_v2', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part4-Light-Pit-Train-Repeat-v1', eval_act_func='part4_v3', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=20000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=5e-06, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2000000, metric_func='part4_v1', model_dir='None', model_param=[64, 2], model_type='nn', num_threads=16, output='./Part4-Light-Pit-Train-Repeat-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part4_heuri_v4', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=5.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=10, test_env=['Part4-Light-Pit-Test-Repeat-v1', 'Part4-Light-Pit-Test-Repeat-v2'], test_mode='Multiple', train_act_func='part4_v3', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=10.0, weight_initer='glorot_uniform', window_len=7)
[2019-04-07 10:48:13,016] A3C_AGENT_MAIN INFO:Start compiling...
2019-04-07 10:48:13.054829: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-04-07 10:48:36,035] A3C_AGENT_MAIN INFO:Start the learning...
[2019-04-07 10:48:36,036] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part4-Light-Pit-Train-Repeat-v1', 'Part4-Light-Pit-Test-Repeat-v1', 'Part4-Light-Pit-Test-Repeat-v2'] ...
[2019-04-07 10:48:36,059] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation worker starts!
[2019-04-07 10:48:36,083] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation worker starts!
[2019-04-07 10:48:36,106] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation worker starts!
[2019-04-07 10:48:36,107] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:36,107] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-04-07 10:48:36,178] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:36,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run1
[2019-04-07 10:48:37,108] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:37,110] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-04-07 10:48:37,186] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:37,187] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run1
[2019-04-07 10:48:38,111] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:38,112] A3C_AGENT_WORKER-Thread-4 INFO:Local worker starts!
[2019-04-07 10:48:38,187] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:38,188] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run1
[2019-04-07 10:48:39,112] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:39,113] A3C_AGENT_WORKER-Thread-5 INFO:Local worker starts!
[2019-04-07 10:48:39,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:39,194] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run1
[2019-04-07 10:48:40,114] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:40,115] A3C_AGENT_WORKER-Thread-6 INFO:Local worker starts!
[2019-04-07 10:48:40,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:40,198] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run1
[2019-04-07 10:48:40,727] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-07 10:48:40,728] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 10:48:40,728] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 10:48:40,728] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:40,729] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 10:48:40,729] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:40,729] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:40,733] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run1
[2019-04-07 10:48:40,733] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run1
[2019-04-07 10:48:40,754] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run1
[2019-04-07 10:48:41,116] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:41,117] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-04-07 10:48:41,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:41,231] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run1
[2019-04-07 10:48:42,118] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:42,119] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-04-07 10:48:42,236] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:42,238] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run1
[2019-04-07 10:48:43,120] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:43,125] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-04-07 10:48:43,254] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:43,255] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run1
[2019-04-07 10:48:44,126] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:44,127] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-04-07 10:48:44,246] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:44,248] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run1
[2019-04-07 10:48:45,128] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:45,129] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-04-07 10:48:45,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:45,266] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run1
[2019-04-07 10:48:46,129] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:46,130] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-04-07 10:48:46,336] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:46,338] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run1
[2019-04-07 10:48:47,137] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:47,148] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-04-07 10:48:47,339] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:47,341] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run1
[2019-04-07 10:48:48,146] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:48,147] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-04-07 10:48:48,243] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:48,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run1
[2019-04-07 10:48:49,148] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:49,149] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-04-07 10:48:49,306] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:49,307] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run1
[2019-04-07 10:48:50,149] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:50,150] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-04-07 10:48:50,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:50,367] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run1
[2019-04-07 10:48:51,150] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-07 10:48:51,151] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-04-07 10:48:51,299] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:48:51,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run1
[2019-04-07 10:50:13,684] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-04-07 10:50:13,685] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [2.99226723, 88.28059462, 0.0, 0.0, 19.0, 24.50056749654371, 0.2873941085163345, 0.0, 1.0, 0.0]
[2019-04-07 10:50:13,685] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 10:50:13,686] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [0.09853152 0.0837788  0.13821264 0.12560573 0.10624515 0.12497117
 0.18010789 0.14254707], sampled 0.08100776407588939
[2019-04-07 10:50:24,365] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2557.7371 72429101.5803 394.5217
[2019-04-07 10:50:56,264] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2534.7306 80403447.1232 285.1462
[2019-04-07 10:51:04,606] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2521.6179 84378954.3869 230.6965
[2019-04-07 10:51:05,643] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2534.7305764465495, 80403447.12316306, 285.14624743108, 2557.737117868729, 72429101.58027297, 394.5216526369033, 2521.6179013495275, 84378954.38686205, 230.69647787760562]
[2019-04-07 10:52:00,213] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.13824122 0.08187266 0.10870343 0.13389292 0.1000268  0.1297285
 0.17540918 0.13212529], sum to 1.0000
[2019-04-07 10:52:00,213] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8565
[2019-04-07 10:52:00,722] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [-15.0, 69.0, 0.0, 0.0, 19.0, 21.10057341161735, -0.6752562227396234, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.0], 
sim time this is 352800.0000, 
sim time next is 354600.0000, 
raw observation next is [-15.0, 69.0, 0.0, 0.0, 25.0, 20.80445676256992, -0.7045952447917538, 0.0, 1.0, 89103.08251555142], 
processed observation next is [1.0, 0.08695652173913043, 0.04709141274238226, 0.69, 0.0, 0.0, 0.5833333333333334, 0.23370473021416002, 0.2651349184027487, 0.0, 1.0, 0.4243003929311972], 
reward next is 0.7186, 
noisyNet noise sample is [array([0.5420542], dtype=float32), 0.8193869]. 
=============================================
[2019-04-07 10:52:21,788] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.09106431 0.08564217 0.12133487 0.1242929  0.12034566 0.12950884
 0.19655518 0.13125604], sum to 1.0000
[2019-04-07 10:52:21,788] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5615
[2019-04-07 10:52:21,999] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 25.0, 23.37533420519161, -0.1083466856795967, 0.0, 1.0, 42700.81296329275], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 545400.0000, 
sim time next is 547200.0000, 
raw observation next is [0.5, 92.0, 17.5, 54.5, 24.0, 23.36252930853832, -0.09747289606507155, 0.0, 1.0, 42396.24374458779], 
processed observation next is [0.0, 0.34782608695652173, 0.4764542936288089, 0.92, 0.058333333333333334, 0.06022099447513812, 0.5, 0.4468774423781934, 0.4675090346449762, 0.0, 1.0, 0.20188687497422755], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.49553296], dtype=float32), 0.21476012]. 
=============================================
[2019-04-07 10:52:31,924] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.11012004 0.08968984 0.14110716 0.11344731 0.0995395  0.1620774
 0.17287058 0.11114821], sum to 1.0000
[2019-04-07 10:52:31,924] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6392
[2019-04-07 10:52:32,332] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 76.0, 65.0, 24.5, 20.0, 23.46214570212728, -0.2083643551308272, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 723600.0000, 
sim time next is 725400.0000, 
raw observation next is [-2.0, 72.0, 101.0, 49.0, 24.0, 23.66924427346257, -0.161560742251103, 1.0, 1.0, 18697.8933673682], 
processed observation next is [1.0, 0.391304347826087, 0.40720221606648205, 0.72, 0.33666666666666667, 0.05414364640883978, 0.5, 0.47243702278854754, 0.44614641924963233, 1.0, 1.0, 0.0890375874636581], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.19792], dtype=float32), 0.36237413]. 
=============================================
[2019-04-07 10:52:40,311] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0940341  0.0875854  0.11091365 0.14990987 0.12904178 0.17498122
 0.1312254  0.12230863], sum to 1.0000
[2019-04-07 10:52:40,311] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8354
[2019-04-07 10:52:40,551] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [-2.8, 54.0, 34.0, 2.5, 24.0, 24.41553580697811, 0.1438706663610074, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.0], 
sim time this is 752400.0000, 
sim time next is 754200.0000, 
raw observation next is [-3.35, 55.0, 0.0, 0.0, 25.0, 24.72435187544462, 0.1030426023662509, 1.0, 1.0, 11138.496676226468], 
processed observation next is [1.0, 0.7391304347826086, 0.3698060941828255, 0.55, 0.0, 0.0, 0.5833333333333334, 0.5603626562870515, 0.5343475341220837, 1.0, 1.0, 0.05304046036298318], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16612467], dtype=float32), -1.1917304]. 
=============================================
[2019-04-07 10:52:40,553] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.10079934 0.08877392 0.12244174 0.13406877 0.12395205 0.17447282
 0.13177012 0.12372122], sum to 1.0000
[2019-04-07 10:52:40,553] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9208
[2019-04-07 10:52:41,140] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.35, 55.0, 0.0, 0.0, 25.0, 24.72435187544462, 0.1030426023662509, 1.0, 1.0, 11138.496676226468], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 754200.0000, 
sim time next is 756000.0000, 
raw observation next is [-3.9, 56.0, 0.0, 0.0, 26.0, 24.33595373455942, 0.1990244790345622, 1.0, 1.0, 198999.04750204747], 
processed observation next is [1.0, 0.782608695652174, 0.3545706371191136, 0.56, 0.0, 0.0, 0.6666666666666666, 0.5279961445466185, 0.5663414930115207, 1.0, 1.0, 0.9476145119145117], 
reward next is 0.0524, 
noisyNet noise sample is [array([-0.16612467], dtype=float32), -1.1917304]. 
=============================================
[2019-04-07 10:52:41,144] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[0.96690434]
 [1.0136874 ]
 [0.86249006]
 [0.91915774]
 [1.0221057 ]], R is [[1.09459496]
 [2.08364916]
 [3.06281281]
 [4.0321846 ]
 [4.99186277]].
[2019-04-07 10:52:50,657] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7592: loss 42.1106
[2019-04-07 10:52:50,801] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7592: learning rate 0.0000
[2019-04-07 10:52:51,232] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7625: loss 35.7776
[2019-04-07 10:52:51,232] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7625: learning rate 0.0000
[2019-04-07 10:52:51,676] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7657: loss 39.4973
[2019-04-07 10:52:51,732] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7657: learning rate 0.0000
[2019-04-07 10:52:52,439] A3C_AGENT_WORKER-Thread-6 INFO:Local step 500, global step 7728: loss 45.3391
[2019-04-07 10:52:52,439] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 500, global step 7728: learning rate 0.0000
[2019-04-07 10:52:54,083] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7888: loss 43.5607
[2019-04-07 10:52:54,088] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7888: learning rate 0.0000
[2019-04-07 10:52:54,687] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7953: loss 33.2994
[2019-04-07 10:52:54,688] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7953: learning rate 0.0000
[2019-04-07 10:52:54,835] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7969: loss 45.0328
[2019-04-07 10:52:54,837] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7969: learning rate 0.0000
[2019-04-07 10:52:55,195] A3C_AGENT_WORKER-Thread-5 INFO:Local step 500, global step 8011: loss 42.8087
[2019-04-07 10:52:55,195] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 500, global step 8011: learning rate 0.0000
[2019-04-07 10:52:55,379] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 8036: loss 34.4900
[2019-04-07 10:52:55,381] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 8036: learning rate 0.0000
[2019-04-07 10:52:55,685] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8081: loss 38.8483
[2019-04-07 10:52:55,685] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8081: learning rate 0.0000
[2019-04-07 10:52:55,974] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 8123: loss 46.0980
[2019-04-07 10:52:55,975] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 8123: learning rate 0.0000
[2019-04-07 10:52:56,136] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 8144: loss 44.7149
[2019-04-07 10:52:56,136] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 8144: learning rate 0.0000
[2019-04-07 10:52:56,713] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 8232: loss 43.2594
[2019-04-07 10:52:56,717] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 8232: learning rate 0.0000
[2019-04-07 10:52:57,186] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.08458628 0.08806618 0.11695674 0.12506658 0.11909905 0.19288489
 0.14850666 0.12483361], sum to 1.0000
[2019-04-07 10:52:57,186] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4993
[2019-04-07 10:52:57,420] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [4.4, 93.0, 36.0, 0.0, 20.0, 24.77267030737883, 0.189277242933697, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [23.0], 
sim time this is 921600.0000, 
sim time next is 923400.0000, 
raw observation next is [4.7, 92.5, 18.0, 0.0, 23.0, 24.87418102174643, 0.1950566665714768, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.592797783933518, 0.925, 0.06, 0.0, 0.4166666666666667, 0.5728484184788692, 0.5650188888571589, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.18606539], dtype=float32), -2.567913]. 
=============================================
[2019-04-07 10:52:57,563] A3C_AGENT_WORKER-Thread-4 INFO:Local step 500, global step 8323: loss 42.2305
[2019-04-07 10:52:57,564] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 500, global step 8323: learning rate 0.0000
[2019-04-07 10:52:57,925] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8363: loss 47.0477
[2019-04-07 10:52:57,925] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8363: learning rate 0.0000
[2019-04-07 10:52:58,428] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8439: loss 46.0003
[2019-04-07 10:52:58,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8439: learning rate 0.0000
[2019-04-07 10:52:59,556] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.13154876 0.0791429  0.12830077 0.1202874  0.10574695 0.13503402
 0.17281161 0.12712762], sum to 1.0000
[2019-04-07 10:52:59,557] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2806
[2019-04-07 10:52:59,877] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [7.7, 80.0, 0.0, 0.0, 20.0, 23.81300604293119, 0.04349308686076079, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [21.0], 
sim time this is 961200.0000, 
sim time next is 963000.0000, 
raw observation next is [7.7, 81.5, 0.0, 0.0, 21.0, 23.66608501743877, 0.006932275588351559, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.6759002770083103, 0.815, 0.0, 0.0, 0.25, 0.4721737514532309, 0.5023107585294505, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6449277], dtype=float32), -1.3325936]. 
=============================================
[2019-04-07 10:52:59,896] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[0.95905536]
 [0.9189039 ]
 [1.0090648 ]
 [1.0541486 ]
 [1.3039314 ]], R is [[1.92425108]
 [2.90500855]
 [3.87595844]
 [4.83719921]
 [5.78882742]].
[2019-04-07 10:53:19,558] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.08842861 0.08047899 0.13806883 0.11533421 0.12506464 0.10673503
 0.1866942  0.15919548], sum to 1.0000
[2019-04-07 10:53:19,563] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4157
[2019-04-07 10:53:20,061] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 23.0, 23.79686967261651, 0.1880597875351791, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [22.0], 
sim time this is 1233000.0000, 
sim time next is 1234800.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 22.0, 23.74329547829801, 0.1775300185519692, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.8781163434903049, 0.96, 0.0, 0.0, 0.3333333333333333, 0.47860795652483407, 0.5591766728506564, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8214122], dtype=float32), -1.0921006]. 
=============================================
[2019-04-07 10:53:29,458] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.11944185 0.07409194 0.11480244 0.11745398 0.10030279 0.16337755
 0.17847706 0.13205242], sum to 1.0000
[2019-04-07 10:53:29,458] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9307
[2019-04-07 10:53:30,122] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.2, 92.0, 0.0, 0.0, 24.0, 24.06936914119931, 0.2219334005442457, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1310400.0000, 
sim time next is 1312200.0000, 
raw observation next is [1.9, 92.0, 0.0, 0.0, 26.0, 23.96575849120427, 0.2865153337595889, 0.0, 1.0, 170073.16066493784], 
processed observation next is [1.0, 0.17391304347826086, 0.515235457063712, 0.92, 0.0, 0.0, 0.6666666666666666, 0.4971465409336891, 0.5955051112531963, 0.0, 1.0, 0.8098721936425611], 
reward next is 0.1901, 
noisyNet noise sample is [array([-0.39957395], dtype=float32), -0.51855177]. 
=============================================
[2019-04-07 10:53:48,539] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0786068  0.1187223  0.10758219 0.1585457  0.07682066 0.23917511
 0.10915451 0.11139275], sum to 1.0000
[2019-04-07 10:53:48,539] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7110
[2019-04-07 10:53:49,065] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 49.0, 145.0, 0.0, 24.0, 26.01278648830341, 0.6643386655243955, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1607400.0000, 
sim time next is 1609200.0000, 
raw observation next is [13.8, 49.0, 111.5, 0.0, 24.0, 26.83062903522093, 0.7362289841472885, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.844875346260388, 0.49, 0.37166666666666665, 0.0, 0.5, 0.7358857529350775, 0.7454096613824296, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3591553], dtype=float32), 0.6894631]. 
=============================================
[2019-04-07 10:53:51,737] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.10348427 0.08317924 0.11234733 0.1086321  0.1140609  0.1697047
 0.17268899 0.13590246], sum to 1.0000
[2019-04-07 10:53:51,737] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5775
[2019-04-07 10:53:51,839] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.9, 84.0, 0.0, 0.0, 20.0, 24.66521984999562, 0.3708658632881185, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1636200.0000, 
sim time next is 1638000.0000, 
raw observation next is [7.2, 82.0, 0.0, 0.0, 24.0, 24.66197217113368, 0.3440997214515583, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.662049861495845, 0.82, 0.0, 0.0, 0.5, 0.5551643475944733, 0.6146999071505195, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3733369], dtype=float32), -2.010652]. 
=============================================
[2019-04-07 10:53:52,133] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[1.6460189]
 [1.9919862]
 [1.8739016]
 [1.7596972]
 [2.0004394]], R is [[2.70562887]
 [3.67857265]
 [3.70540524]
 [4.66835117]
 [5.62166786]].
[2019-04-07 10:53:53,989] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.09796341 0.07786651 0.10656996 0.14291593 0.09594727 0.2114826
 0.14745589 0.1197985 ], sum to 1.0000
[2019-04-07 10:53:53,989] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1769
[2019-04-07 10:53:54,097] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [5.0, 82.0, 19.0, 20.0, 22.0, 23.8399647098846, 0.09920278229598682, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [21.0], 
sim time this is 1584000.0000, 
sim time next is 1585800.0000, 
raw observation next is [5.8, 79.0, 37.0, 35.0, 21.0, 23.89671879795829, 0.1492561399764521, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.6232686980609419, 0.79, 0.12333333333333334, 0.03867403314917127, 0.25, 0.4913932331631908, 0.5497520466588174, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.08180535], dtype=float32), -1.3749664]. 
=============================================
[2019-04-07 10:54:01,300] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15467: loss 28.7362
[2019-04-07 10:54:01,301] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15467: learning rate 0.0000
[2019-04-07 10:54:03,605] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15754: loss 29.5859
[2019-04-07 10:54:03,605] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15754: learning rate 0.0000
[2019-04-07 10:54:04,135] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15801: loss 34.2458
[2019-04-07 10:54:04,136] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15801: learning rate 0.0000
[2019-04-07 10:54:05,687] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15947: loss 28.3443
[2019-04-07 10:54:05,687] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15947: learning rate 0.0000
[2019-04-07 10:54:05,975] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1000, global step 15973: loss 30.8406
[2019-04-07 10:54:05,975] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 1000, global step 15973: learning rate 0.0000
[2019-04-07 10:54:07,263] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16087: loss 37.3383
[2019-04-07 10:54:07,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16087: learning rate 0.0000
[2019-04-07 10:54:07,289] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16093: loss 27.8039
[2019-04-07 10:54:07,305] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16093: learning rate 0.0000
[2019-04-07 10:54:07,417] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16103: loss 31.4573
[2019-04-07 10:54:07,417] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16103: learning rate 0.0000
[2019-04-07 10:54:07,423] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1000, global step 16104: loss 34.8718
[2019-04-07 10:54:07,424] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 1000, global step 16104: learning rate 0.0000
[2019-04-07 10:54:07,448] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16108: loss 27.9982
[2019-04-07 10:54:07,448] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16108: learning rate 0.0000
[2019-04-07 10:54:07,635] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16129: loss 29.6434
[2019-04-07 10:54:07,636] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 16129: learning rate 0.0000
[2019-04-07 10:54:07,797] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16154: loss 37.8295
[2019-04-07 10:54:07,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16154: learning rate 0.0000
[2019-04-07 10:54:07,989] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1000, global step 16176: loss 27.7190
[2019-04-07 10:54:07,997] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 1000, global step 16176: learning rate 0.0000
[2019-04-07 10:54:08,040] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16181: loss 30.5966
[2019-04-07 10:54:08,041] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16181: learning rate 0.0000
[2019-04-07 10:54:09,012] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16335: loss 32.2888
[2019-04-07 10:54:09,013] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 16335: learning rate 0.0000
[2019-04-07 10:54:10,732] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16518: loss 33.3515
[2019-04-07 10:54:10,749] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16518: learning rate 0.0000
[2019-04-07 10:54:13,782] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.07290548 0.06440817 0.11306281 0.12593053 0.10786579 0.22409122
 0.18232886 0.10940716], sum to 1.0000
[2019-04-07 10:54:13,782] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5320
[2019-04-07 10:54:14,093] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 79.0, 29.0, 0.0, 24.0, 23.49523458978624, -0.08543906457675206, 0.0, 1.0, 34261.359402799135], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1873800.0000, 
sim time next is 1875600.0000, 
raw observation next is [-4.5, 83.0, 15.0, 0.0, 24.0, 23.43491728933673, -0.1060089931425484, 0.0, 1.0, 32545.997586277637], 
processed observation next is [0.0, 0.7391304347826086, 0.3379501385041552, 0.83, 0.05, 0.0, 0.5, 0.45290977411139427, 0.4646636689524839, 0.0, 1.0, 0.15498094088703637], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.183924], dtype=float32), 1.5300248]. 
=============================================
[2019-04-07 10:54:16,577] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.1050595  0.07128258 0.07000913 0.14669113 0.10173047 0.22384821
 0.15228412 0.1290949 ], sum to 1.0000
[2019-04-07 10:54:16,577] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5885
[2019-04-07 10:54:16,778] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.2, 86.5, 0.0, 0.0, 22.0, 21.39900327504691, -0.5441577103609117, 0.0, 1.0, 122030.86673695907], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1924200.0000, 
sim time next is 1926000.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 24.0, 21.65034723491046, -0.4931357675888114, 0.0, 1.0, 68334.43914448819], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.5, 0.30419560290920494, 0.3356214108037296, 0.0, 1.0, 0.32540209116422947], 
reward next is 0.9603, 
noisyNet noise sample is [array([1.2655587], dtype=float32), 0.24294052]. 
=============================================
[2019-04-07 10:54:16,805] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[2.0232646]
 [1.888864 ]
 [1.9656725]
 [1.9900846]
 [1.8401783]], R is [[2.85598326]
 [3.8177526 ]
 [4.77957535]
 [5.73177958]
 [6.67446184]].
[2019-04-07 10:54:26,034] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.09781981 0.07882672 0.10417538 0.13490884 0.09184809 0.19573586
 0.16351336 0.13317187], sum to 1.0000
[2019-04-07 10:54:26,034] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1906
[2019-04-07 10:54:26,315] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-7.3, 79.0, 36.5, 18.5, 19.0, 23.50004007265423, -0.09746664419306315, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [21.0], 
sim time this is 2102400.0000, 
sim time next is 2104200.0000, 
raw observation next is [-7.55, 80.5, 72.0, 37.0, 21.0, 23.59354129105298, -0.08197224216057551, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.25346260387811637, 0.805, 0.24, 0.04088397790055249, 0.25, 0.4661284409210816, 0.4726759192798082, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.39624986], dtype=float32), -0.16531919]. 
=============================================
[2019-04-07 10:54:27,553] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.07017404 0.08441038 0.08242389 0.144094   0.11941394 0.227708
 0.15578404 0.11599167], sum to 1.0000
[2019-04-07 10:54:27,553] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6252
[2019-04-07 10:54:27,959] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 32.0, 0.0, 24.0, 23.68726056720707, -0.067870920699856, 1.0, 1.0, 56892.4926350369], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2046600.0000, 
sim time next is 2048400.0000, 
raw observation next is [-3.9, 82.0, 17.0, 0.0, 24.0, 23.10117792522247, -0.05899045682412124, 1.0, 1.0, 85306.58096912054], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.82, 0.056666666666666664, 0.0, 0.5, 0.42509816043520576, 0.48033651439195957, 1.0, 1.0, 0.4062218141386692], 
reward next is 0.8795, 
noisyNet noise sample is [array([3.3120236], dtype=float32), 0.9139886]. 
=============================================
[2019-04-07 10:54:43,295] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-07 10:54:43,298] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 10:54:43,298] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:54:43,299] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run2
[2019-04-07 10:54:43,328] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 10:54:43,329] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:54:43,330] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run2
[2019-04-07 10:54:43,344] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 10:54:43,344] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:54:43,347] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run2
[2019-04-07 10:55:29,100] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.01391002], dtype=float32), 0.015886022]
[2019-04-07 10:55:29,100] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [8.75, 73.5, 0.0, 0.0, 22.0, 23.46256382588067, 0.06719768418082886, 0.0, 1.0, 0.0]
[2019-04-07 10:55:29,100] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 10:55:29,101] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [0.08443961 0.07590505 0.12665601 0.13550973 0.09602118 0.20650718
 0.15398733 0.12097396], sampled 0.37690430704720523
[2019-04-07 10:56:19,392] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2568.6958 71552653.3429 367.9877
[2019-04-07 10:56:51,042] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2548.1530 80325411.4558 290.6416
[2019-04-07 10:57:02,659] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2542.8411 83795615.2770 218.7129
[2019-04-07 10:57:03,697] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 20000, evaluation results [20000.0, 2548.1529938871436, 80325411.45583081, 290.6416454235983, 2568.695802076723, 71552653.34291162, 367.9876587511935, 2542.8411250941103, 83795615.27703317, 218.7129091439985]
[2019-04-07 10:57:30,334] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.08567675 0.08290737 0.12238798 0.17784773 0.08797123 0.1588598
 0.16214553 0.12220361], sum to 1.0000
[2019-04-07 10:57:30,335] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2809
[2019-04-07 10:57:30,604] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.6, 31.0, 88.0, 837.0, 26.0, 24.902795963721, 0.1901480515364518, 0.0, 1.0, 67714.14249693036], 
current ob forecast is [], 
actual action is [21.0], 
sim time this is 2462400.0000, 
sim time next is 2464200.0000, 
raw observation next is [0.5, 29.5, 90.0, 845.0, 21.0, 25.06504377586948, 0.2008333068730021, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.4764542936288089, 0.295, 0.3, 0.9337016574585635, 0.25, 0.5887536479891233, 0.566944435624334, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06421845], dtype=float32), -0.0567676]. 
=============================================
[2019-04-07 10:57:38,059] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23071: loss 37.7391
[2019-04-07 10:57:38,059] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23071: learning rate 0.0000
[2019-04-07 10:57:40,480] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23301: loss 36.5813
[2019-04-07 10:57:40,480] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23301: learning rate 0.0000
[2019-04-07 10:57:41,474] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23396: loss 40.6121
[2019-04-07 10:57:41,475] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23396: learning rate 0.0000
[2019-04-07 10:57:43,005] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1500, global step 23527: loss 34.9184
[2019-04-07 10:57:43,025] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 1500, global step 23527: learning rate 0.0000
[2019-04-07 10:57:44,703] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1500, global step 23673: loss 36.9330
[2019-04-07 10:57:44,704] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 1500, global step 23673: learning rate 0.0000
[2019-04-07 10:57:45,713] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23759: loss 39.3336
[2019-04-07 10:57:45,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23759: learning rate 0.0000
[2019-04-07 10:57:46,900] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23862: loss 32.7235
[2019-04-07 10:57:46,901] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23862: learning rate 0.0000
[2019-04-07 10:57:47,153] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23882: loss 38.1968
[2019-04-07 10:57:47,154] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23882: learning rate 0.0000
[2019-04-07 10:57:48,497] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24021: loss 38.2827
[2019-04-07 10:57:48,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 24021: learning rate 0.0000
[2019-04-07 10:57:49,203] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 24090: loss 32.6303
[2019-04-07 10:57:49,204] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 24090: learning rate 0.0000
[2019-04-07 10:57:49,384] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24108: loss 37.3079
[2019-04-07 10:57:49,387] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24108: learning rate 0.0000
[2019-04-07 10:57:49,388] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24109: loss 39.7486
[2019-04-07 10:57:49,389] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 24109: learning rate 0.0000
[2019-04-07 10:57:50,880] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1500, global step 24243: loss 32.3570
[2019-04-07 10:57:50,880] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 1500, global step 24243: learning rate 0.0000
[2019-04-07 10:57:51,610] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24308: loss 34.3211
[2019-04-07 10:57:51,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24308: learning rate 0.0000
[2019-04-07 10:57:51,921] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24336: loss 37.8717
[2019-04-07 10:57:51,922] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24336: learning rate 0.0000
[2019-04-07 10:57:52,478] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.05873782 0.07826807 0.08489273 0.16171883 0.08649301 0.2940066
 0.13347924 0.10240371], sum to 1.0000
[2019-04-07 10:57:52,478] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4116
[2019-04-07 10:57:52,523] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 54.0, 0.0, 0.0, 23.0, 24.10535725514657, 0.1246436077434371, 1.0, 1.0, 9340.205835115268], 
current ob forecast is [], 
actual action is [23.0], 
sim time this is 2743200.0000, 
sim time next is 2745000.0000, 
raw observation next is [-4.5, 56.5, 0.0, 0.0, 23.0, 23.84722795247211, 0.009149663933285304, 1.0, 1.0, 15567.00972519211], 
processed observation next is [1.0, 0.782608695652174, 0.3379501385041552, 0.565, 0.0, 0.0, 0.4166666666666667, 0.48726899603934254, 0.5030498879777617, 1.0, 1.0, 0.07412861773901006], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.47428593], dtype=float32), -2.1276858]. 
=============================================
[2019-04-07 10:57:52,562] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[3.7922826]
 [3.8108163]
 [3.7991521]
 [3.8357472]
 [3.8057294]], R is [[4.72404099]
 [5.67680073]
 [6.62003279]
 [7.55383253]
 [8.47829437]].
[2019-04-07 10:57:52,871] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24426: loss 36.6956
[2019-04-07 10:57:52,871] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24426: learning rate 0.0000
[2019-04-07 10:58:12,406] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.05326599 0.05324226 0.04493995 0.15223409 0.08163248 0.34533277
 0.1439978  0.12535466], sum to 1.0000
[2019-04-07 10:58:12,407] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1354
[2019-04-07 10:58:12,877] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.0, 81.5, 0.0, 0.0, 26.0, 22.57777948206846, -0.08444654358627852, 0.0, 1.0, 197130.5769198189], 
current ob forecast is [], 
actual action is [21.0], 
sim time this is 2925000.0000, 
sim time next is 2926800.0000, 
raw observation next is [-1.0, 85.0, 0.0, 0.0, 21.0, 22.89703569964606, -0.05029834469615215, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.85, 0.0, 0.0, 0.25, 0.4080863083038384, 0.48323388510128257, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8461492], dtype=float32), -1.0396861]. 
=============================================
[2019-04-07 10:58:30,347] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.07253671 0.06612215 0.05790098 0.17299086 0.09538557 0.2843847
 0.14406118 0.10661782], sum to 1.0000
[2019-04-07 10:58:30,347] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4877
[2019-04-07 10:58:30,455] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 100.0, 0.0, 0.0, 24.0, 24.31478468275242, 0.2032114627830903, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3213000.0000, 
sim time next is 3214800.0000, 
raw observation next is [-2.0, 100.0, 0.0, 0.0, 24.0, 23.95904922239896, 0.1404691483624375, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.40720221606648205, 1.0, 0.0, 0.0, 0.5, 0.49658743519991333, 0.5468230494541458, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6644796], dtype=float32), 0.64178926]. 
=============================================
[2019-04-07 10:58:52,341] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.03979718 0.06127657 0.03576249 0.14746751 0.04642515 0.40795878
 0.17885906 0.08245329], sum to 1.0000
[2019-04-07 10:58:52,341] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6974
[2019-04-07 10:58:52,680] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 60.0, 93.0, 540.0, 26.0, 24.46370683038745, 0.2228960608615158, 1.0, 1.0, 199558.27617531977], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3402000.0000, 
sim time next is 3403800.0000, 
raw observation next is [0.5, 54.0, 99.0, 658.0, 24.0, 25.76967900349958, 0.4099465691618622, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4764542936288089, 0.54, 0.33, 0.7270718232044199, 0.5, 0.6474732502916316, 0.6366488563872874, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.12282599], dtype=float32), -0.8935712]. 
=============================================
[2019-04-07 10:58:52,897] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 30847: loss 38.3299
[2019-04-07 10:58:52,898] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 30847: learning rate 0.0000
[2019-04-07 10:58:56,293] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31371: loss 32.3323
[2019-04-07 10:58:56,294] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31371: learning rate 0.0000
[2019-04-07 10:58:57,266] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.04896018 0.0602912  0.08686636 0.1776193  0.061496   0.27033362
 0.16759914 0.1268342 ], sum to 1.0000
[2019-04-07 10:58:57,266] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2897
[2019-04-07 10:58:57,442] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-4.0, 54.0, 112.5, 787.0, 19.0, 24.03479349755067, 0.1421792292559955, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [22.0], 
sim time this is 3582000.0000, 
sim time next is 3583800.0000, 
raw observation next is [-3.5, 54.5, 114.0, 816.0, 22.0, 23.8822131267997, 0.1196883029236319, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.36565096952908593, 0.545, 0.38, 0.901657458563536, 0.3333333333333333, 0.49018442723330846, 0.539896100974544, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7510624], dtype=float32), 2.151564]. 
=============================================
[2019-04-07 10:58:58,251] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31599: loss 33.8478
[2019-04-07 10:58:58,252] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31599: learning rate 0.0000
[2019-04-07 10:58:58,865] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31711: loss 26.4470
[2019-04-07 10:58:58,866] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31711: learning rate 0.0000
[2019-04-07 10:58:58,928] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2000, global step 31720: loss 40.8649
[2019-04-07 10:58:58,928] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 2000, global step 31720: learning rate 0.0000
[2019-04-07 10:58:58,934] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31720: loss 46.0857
[2019-04-07 10:58:58,936] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31720: learning rate 0.0000
[2019-04-07 10:58:59,332] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2000, global step 31780: loss 47.1856
[2019-04-07 10:58:59,333] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 2000, global step 31780: learning rate 0.0000
[2019-04-07 10:59:00,052] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31880: loss 36.4949
[2019-04-07 10:59:00,052] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31880: learning rate 0.0000
[2019-04-07 10:59:03,391] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32354: loss 46.2521
[2019-04-07 10:59:03,421] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32354: learning rate 0.0000
[2019-04-07 10:59:04,270] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2000, global step 32498: loss 39.8478
[2019-04-07 10:59:04,270] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 2000, global step 32498: learning rate 0.0000
[2019-04-07 10:59:04,419] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32519: loss 38.8156
[2019-04-07 10:59:04,422] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 32520: loss 36.0813
[2019-04-07 10:59:04,423] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 32520: learning rate 0.0000
[2019-04-07 10:59:04,424] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32519: learning rate 0.0000
[2019-04-07 10:59:04,506] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32532: loss 39.6728
[2019-04-07 10:59:04,521] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 32532: learning rate 0.0000
[2019-04-07 10:59:04,571] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32540: loss 29.6058
[2019-04-07 10:59:04,574] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32540: learning rate 0.0000
[2019-04-07 10:59:05,357] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32673: loss 37.2630
[2019-04-07 10:59:05,358] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32673: learning rate 0.0000
[2019-04-07 10:59:07,618] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 33126: loss 33.9376
[2019-04-07 10:59:07,619] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 33126: learning rate 0.0000
[2019-04-07 10:59:25,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.04097852 0.06002714 0.061602   0.16360779 0.0637571  0.36619335
 0.14182414 0.10200997], sum to 1.0000
[2019-04-07 10:59:25,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7825
[2019-04-07 10:59:25,936] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [1.0, 43.0, 0.0, 0.0, 20.0, 24.54493216279144, 0.1506851749960377, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.0], 
sim time this is 4221000.0000, 
sim time next is 4222800.0000, 
raw observation next is [1.0, 43.0, 0.0, 0.0, 25.0, 24.40649977630713, 0.2060092127755112, 0.0, 1.0, 177302.10413612289], 
processed observation next is [0.0, 0.9130434782608695, 0.4903047091412743, 0.43, 0.0, 0.0, 0.5833333333333334, 0.5338749813589274, 0.5686697375918371, 0.0, 1.0, 0.8442957339815376], 
reward next is 0.2986, 
noisyNet noise sample is [array([2.2864127], dtype=float32), -1.2677008]. 
=============================================
[2019-04-07 10:59:36,502] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 38367: loss 18.0053
[2019-04-07 10:59:36,503] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 38367: learning rate 0.0000
[2019-04-07 10:59:38,660] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 38871: loss 22.2715
[2019-04-07 10:59:38,660] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 38871: learning rate 0.0000
[2019-04-07 10:59:40,994] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39415: loss 18.3425
[2019-04-07 10:59:41,002] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39416: learning rate 0.0000
[2019-04-07 10:59:41,119] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2500, global step 39439: loss 15.2414
[2019-04-07 10:59:41,122] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 2500, global step 39439: learning rate 0.0000
[2019-04-07 10:59:41,473] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2500, global step 39520: loss 23.7825
[2019-04-07 10:59:41,492] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 2500, global step 39523: learning rate 0.0000
[2019-04-07 10:59:41,649] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39559: loss 22.6312
[2019-04-07 10:59:41,649] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39559: learning rate 0.0000
[2019-04-07 10:59:41,858] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39608: loss 24.5728
[2019-04-07 10:59:41,865] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39609: learning rate 0.0000
[2019-04-07 10:59:43,171] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39901: loss 25.8517
[2019-04-07 10:59:43,172] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39901: learning rate 0.0000
[2019-04-07 10:59:43,282] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39932: loss 19.0622
[2019-04-07 10:59:43,282] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39932: learning rate 0.0000
[2019-04-07 10:59:43,535] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-07 10:59:43,545] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 10:59:43,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:59:43,547] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run3
[2019-04-07 10:59:43,565] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 10:59:43,565] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:59:43,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run3
[2019-04-07 10:59:43,580] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 10:59:43,581] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 10:59:43,583] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run3
[2019-04-07 11:00:42,886] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.03375829], dtype=float32), 0.03533478]
[2019-04-07 11:00:42,887] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-8.081808869, 67.55221144000001, 352.9557389, 360.2058406, 25.0, 25.67187089866467, 0.3873089251807088, 1.0, 1.0, 0.0]
[2019-04-07 11:00:42,887] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 11:00:42,887] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [0.02292497 0.04442264 0.02520492 0.13453108 0.04278909 0.4734876
 0.16606757 0.0905721 ], sampled 0.8092780990357198
[2019-04-07 11:01:17,000] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2604.1795 72009114.4103 362.4386
[2019-04-07 11:01:55,727] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2581.8354 80668881.8663 279.2909
[2019-04-07 11:02:03,206] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2560.0851 84957714.0084 212.7178
[2019-04-07 11:02:04,292] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 40000, evaluation results [40000.0, 2581.8354111677004, 80668881.86631323, 279.29085554975103, 2604.1794758502288, 72009114.41026053, 362.43858060116474, 2560.0850767157935, 84957714.00844072, 212.71783004170075]
[2019-04-07 11:02:05,027] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.02329578 0.05620607 0.01414865 0.21326691 0.02020578 0.4988506
 0.08668725 0.08733899], sum to 1.0000
[2019-04-07 11:02:05,027] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8873
[2019-04-07 11:02:05,813] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [3.0, 47.0, 264.0, 113.0, 23.0, 25.3672388186646, 0.2649461399118425, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.0], 
sim time this is 4545000.0000, 
sim time next is 4546800.0000, 
raw observation next is [3.0, 45.0, 208.5, 62.5, 25.0, 24.97548333848477, 0.3044236000441578, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.45, 0.695, 0.06906077348066299, 0.5833333333333334, 0.5812902782070642, 0.6014745333480526, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8727695], dtype=float32), 0.01828182]. 
=============================================
[2019-04-07 11:02:05,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.01455327 0.05854738 0.02380097 0.1699367  0.02537295 0.5130663
 0.11594468 0.07877773], sum to 1.0000
[2019-04-07 11:02:05,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3425
[2019-04-07 11:02:05,970] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 50.5, 122.0, 833.0, 24.0, 25.80203059646007, 0.5237493409385748, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4620600.0000, 
sim time next is 4622400.0000, 
raw observation next is [3.0, 49.0, 121.0, 846.0, 24.0, 25.88857502546661, 0.5471255462683496, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5457063711911359, 0.49, 0.4033333333333333, 0.9348066298342541, 0.5, 0.6573812521222177, 0.6823751820894498, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0328196], dtype=float32), 0.6884442]. 
=============================================
[2019-04-07 11:02:08,134] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40372: loss 12.9453
[2019-04-07 11:02:08,163] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40372: learning rate 0.0000
[2019-04-07 11:02:08,180] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40377: loss 28.8958
[2019-04-07 11:02:08,181] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40377: learning rate 0.0000
[2019-04-07 11:02:10,179] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40594: loss 21.2966
[2019-04-07 11:02:10,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40594: learning rate 0.0000
[2019-04-07 11:02:10,353] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2500, global step 40607: loss 17.8969
[2019-04-07 11:02:10,354] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 2500, global step 40607: learning rate 0.0000
[2019-04-07 11:02:10,797] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40658: loss 26.4263
[2019-04-07 11:02:10,797] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40658: learning rate 0.0000
[2019-04-07 11:02:11,066] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40676: loss 19.7890
[2019-04-07 11:02:11,067] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40676: learning rate 0.0000
[2019-04-07 11:02:11,389] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40712: loss 22.9533
[2019-04-07 11:02:11,390] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40712: learning rate 0.0000
[2019-04-07 11:02:16,314] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.02591524 0.0460277  0.02843948 0.21629526 0.05264057 0.420449
 0.11719261 0.09304019], sum to 1.0000
[2019-04-07 11:02:16,315] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4808
[2019-04-07 11:02:16,339] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 57.0, 0.0, 0.0, 24.0, 24.29141782970328, 0.1956218719894033, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4660200.0000, 
sim time next is 4662000.0000, 
raw observation next is [2.0, 57.0, 0.0, 0.0, 24.0, 23.96902622645808, 0.1365295274880307, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.518005540166205, 0.57, 0.0, 0.0, 0.5, 0.49741885220484, 0.5455098424960102, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.200004], dtype=float32), -0.5638585]. 
=============================================
[2019-04-07 11:02:16,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[8.487326]
 [8.60091 ]
 [8.797789]
 [9.072387]
 [9.039678]], R is [[ 9.28534317]
 [10.19248962]
 [11.09056473]
 [11.97965908]
 [12.85986233]].
[2019-04-07 11:02:44,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:02:44,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:02:44,439] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run2
[2019-04-07 11:02:47,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:02:47,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:02:47,195] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run2
[2019-04-07 11:02:50,221] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:02:50,221] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:02:50,223] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run2
[2019-04-07 11:02:50,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:02:50,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:02:50,655] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run2
[2019-04-07 11:02:51,511] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:02:51,511] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:02:51,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run2
[2019-04-07 11:02:51,763] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:02:51,763] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:02:51,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run2
[2019-04-07 11:02:54,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:02:54,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:02:54,459] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run2
[2019-04-07 11:02:54,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:02:54,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:02:54,687] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run2
[2019-04-07 11:02:57,038] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:02:57,038] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:02:57,234] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run2
[2019-04-07 11:02:58,114] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:02:58,114] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:02:58,116] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run2
[2019-04-07 11:02:58,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:02:58,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:02:58,815] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run2
[2019-04-07 11:02:59,580] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:02:59,580] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:02:59,582] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run2
[2019-04-07 11:03:00,266] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:03:00,266] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:03:00,268] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run2
[2019-04-07 11:03:00,702] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.0081743  0.01735324 0.01503147 0.1315377  0.01090195 0.697534
 0.07004454 0.04942263], sum to 1.0000
[2019-04-07 11:03:00,702] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5058
[2019-04-07 11:03:00,736] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.0, 19.0, 0.0, 0.0, 25.0, 25.67758794968623, 0.5161407056090984, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5083200.0000, 
sim time next is 5085000.0000, 
raw observation next is [9.5, 19.0, 0.0, 0.0, 24.0, 25.56360644489343, 0.4876056615852322, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.7257617728531857, 0.19, 0.0, 0.0, 0.5, 0.6303005370744525, 0.6625352205284107, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.04929929], dtype=float32), -0.7355353]. 
=============================================
[2019-04-07 11:03:00,740] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[10.619774]
 [11.03065 ]
 [11.113215]
 [11.206976]
 [11.335501]], R is [[11.50632858]
 [12.39126587]
 [13.26735306]
 [14.13467979]
 [14.99333286]].
[2019-04-07 11:03:00,814] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:03:00,814] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:03:00,816] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run2
[2019-04-07 11:03:01,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:03:01,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:03:01,999] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run2
[2019-04-07 11:03:02,130] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:03:02,131] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:03:02,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run2
[2019-04-07 11:03:12,550] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [0.01940325 0.06328221 0.03205231 0.15057623 0.03242227 0.4716663
 0.15168233 0.07891507], sum to 1.0000
[2019-04-07 11:03:12,550] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8486
[2019-04-07 11:03:13,521] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [7.7, 93.0, 49.0, 0.0, 25.0, 22.73338546250651, -0.1990737987578428, 0.0, 1.0, 133448.11455843816], 
current ob forecast is [], 
actual action is [25.0], 
sim time this is 36000.0000, 
sim time next is 37800.0000, 
raw observation next is [7.7, 93.0, 60.0, 0.0, 25.0, 23.401202642123, -0.09472167886844295, 0.0, 1.0, 37205.58146937824], 
processed observation next is [0.0, 0.43478260869565216, 0.6759002770083103, 0.93, 0.2, 0.0, 0.5833333333333334, 0.45010022017691664, 0.4684261070438524, 0.0, 1.0, 0.1771694355684678], 
reward next is 0.9657, 
noisyNet noise sample is [array([0.87153345], dtype=float32), -0.17278086]. 
=============================================
[2019-04-07 11:03:41,158] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.01818874 0.04864281 0.00825416 0.0907753  0.02894764 0.55458564
 0.17248413 0.07812158], sum to 1.0000
[2019-04-07 11:03:41,159] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9485
[2019-04-07 11:03:41,227] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-8.1, 69.0, 0.0, 0.0, 24.0, 22.94550905878534, -0.2098859258655713, 0.0, 1.0, 46563.91461172479], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 268200.0000, 
sim time next is 270000.0000, 
raw observation next is [-8.9, 67.0, 0.0, 0.0, 26.0, 22.87511472026958, -0.2399735186534302, 0.0, 1.0, 46602.96129436628], 
processed observation next is [1.0, 0.13043478260869565, 0.21606648199445982, 0.67, 0.0, 0.0, 0.6666666666666666, 0.40625956002246494, 0.4200088271155233, 0.0, 1.0, 0.2219188633065061], 
reward next is 0.7781, 
noisyNet noise sample is [array([0.5973627], dtype=float32), -0.36134094]. 
=============================================
[2019-04-07 11:03:41,231] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[ 9.06751 ]
 [ 9.403266]
 [ 9.753527]
 [ 9.967364]
 [10.410777]], R is [[ 9.80601025]
 [10.70795059]
 [11.37919426]
 [12.18692493]
 [13.06505585]].
[2019-04-07 11:04:17,954] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.01466021 0.03672467 0.01584594 0.11429721 0.03884597 0.47680327
 0.23570749 0.06711516], sum to 1.0000
[2019-04-07 11:04:17,954] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8176
[2019-04-07 11:04:18,048] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [-2.8, 85.0, 0.0, 0.0, 26.0, 23.9037999593035, 0.03403349033117264, 0.0, 1.0, 46737.42094653022], 
current ob forecast is [], 
actual action is [25.0], 
sim time this is 592200.0000, 
sim time next is 594000.0000, 
raw observation next is [-2.8, 83.0, 0.0, 0.0, 25.0, 23.97638390383246, 0.02992577523791125, 0.0, 1.0, 44430.516012868706], 
processed observation next is [0.0, 0.9130434782608695, 0.38504155124653744, 0.83, 0.0, 0.0, 0.5833333333333334, 0.4980319919860383, 0.509975258412637, 0.0, 1.0, 0.21157388577556527], 
reward next is 0.9313, 
noisyNet noise sample is [array([-2.3580422], dtype=float32), -1.3279202]. 
=============================================
[2019-04-07 11:04:18,051] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[10.5769  ]
 [10.739455]
 [10.792543]
 [10.435035]
 [10.533988]], R is [[11.31454849]
 [11.97884369]
 [12.49238777]
 [13.29973984]
 [14.16674232]].
[2019-04-07 11:04:35,845] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.00897485 0.02126127 0.00360943 0.06928542 0.01655195 0.72051567
 0.10720893 0.05259249], sum to 1.0000
[2019-04-07 11:04:35,846] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1119
[2019-04-07 11:04:35,953] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-7.8, 71.0, 0.0, 0.0, 26.0, 22.67260483438577, -0.2679035264330417, 0.0, 1.0, 43228.899651544525], 
current ob forecast is [], 
actual action is [23.0], 
sim time this is 784800.0000, 
sim time next is 786600.0000, 
raw observation next is [-7.8, 72.5, 0.0, 0.0, 23.0, 22.56327629708611, -0.3101656742700342, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.24653739612188366, 0.725, 0.0, 0.0, 0.4166666666666667, 0.3802730247571757, 0.3966114419099886, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1215326], dtype=float32), -0.01085483]. 
=============================================
[2019-04-07 11:04:44,400] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.00504622 0.01544631 0.00509234 0.06199827 0.00708806 0.7608168
 0.09770916 0.0468028 ], sum to 1.0000
[2019-04-07 11:04:44,400] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9727
[2019-04-07 11:04:44,579] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 24.0, 23.23254665067618, -0.1403980726493825, 0.0, 1.0, 58900.40062613828], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 885600.0000, 
sim time next is 887400.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 26.0, 23.2296324488093, -0.1374862098987359, 0.0, 1.0, 41329.04155407048], 
processed observation next is [1.0, 0.2608695652173913, 0.46260387811634357, 0.72, 0.0, 0.0, 0.6666666666666666, 0.43580270406744176, 0.454171263367088, 0.0, 1.0, 0.19680495978128798], 
reward next is 0.8032, 
noisyNet noise sample is [array([1.3964984], dtype=float32), 1.6506124]. 
=============================================
[2019-04-07 11:04:46,824] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.00465399 0.01596136 0.00402803 0.10333435 0.01690486 0.7062073
 0.09220001 0.05671016], sum to 1.0000
[2019-04-07 11:04:46,824] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6144
[2019-04-07 11:04:46,884] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.3, 72.0, 0.0, 0.0, 24.0, 23.48283151410191, -0.1100632633517469, 0.0, 1.0, 20042.17151610554], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 883800.0000, 
sim time next is 885600.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 24.0, 23.25480275497391, -0.1190710920716518, 0.0, 1.0, 66148.8307595785], 
processed observation next is [1.0, 0.2608695652173913, 0.46260387811634357, 0.72, 0.0, 0.0, 0.5, 0.4379002295811591, 0.46030963597611607, 0.0, 1.0, 0.31499443218846906], 
reward next is 0.9707, 
noisyNet noise sample is [array([-1.4576724], dtype=float32), 0.47577068]. 
=============================================
[2019-04-07 11:04:51,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.00580507 0.03061302 0.01083289 0.13466214 0.01412237 0.5970431
 0.14891931 0.05800201], sum to 1.0000
[2019-04-07 11:04:51,127] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9959
[2019-04-07 11:04:51,156] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [18.3, 65.0, 14.5, 0.0, 24.0, 24.23139522426152, 0.2773995466216723, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [26.0], 
sim time this is 1184400.0000, 
sim time next is 1186200.0000, 
raw observation next is [18.3, 64.0, 0.0, 0.0, 26.0, 24.18072342891841, 0.2655565014347248, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.9695290858725764, 0.64, 0.0, 0.0, 0.6666666666666666, 0.5150602857432007, 0.5885188338115749, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0654019], dtype=float32), 0.18747635]. 
=============================================
[2019-04-07 11:04:51,688] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.00137026 0.01421898 0.00101619 0.05871999 0.00306909 0.835993
 0.04795758 0.03765477], sum to 1.0000
[2019-04-07 11:04:51,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5143
[2019-04-07 11:04:51,715] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 106.0, 0.0, 24.0, 24.29084525968259, 0.1771083772135807, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1344600.0000, 
sim time next is 1346400.0000, 
raw observation next is [1.1, 92.0, 88.5, 0.0, 24.0, 24.33654331989984, 0.1875137683985262, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.92, 0.295, 0.0, 0.5, 0.5280452766583199, 0.5625045894661754, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3453138], dtype=float32), -0.64807194]. 
=============================================
[2019-04-07 11:04:55,413] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.00863221 0.04689363 0.01134332 0.12268212 0.01389626 0.5688041
 0.13213357 0.09561481], sum to 1.0000
[2019-04-07 11:04:55,414] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0231
[2019-04-07 11:04:55,435] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 65.0, 14.5, 0.0, 24.0, 24.14954903773828, 0.2640304778050049, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [20.0], 
sim time this is 1184400.0000, 
sim time next is 1186200.0000, 
raw observation next is [18.3, 64.0, 0.0, 0.0, 20.0, 24.09085606294072, 0.2506512931293934, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.9695290858725764, 0.64, 0.0, 0.0, 0.16666666666666666, 0.5075713385783933, 0.5835504310431311, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8305286], dtype=float32), -0.0818254]. 
=============================================
[2019-04-07 11:05:03,492] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.2271384e-04 6.9563533e-03 8.1163360e-04 2.6619110e-02 1.5160268e-03
 9.2259294e-01 2.5932681e-02 1.4648538e-02], sum to 1.0000
[2019-04-07 11:05:03,493] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6441
[2019-04-07 11:05:03,599] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.3, 97.5, 46.0, 0.0, 24.0, 24.30094657449049, 0.1276691648738658, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1416600.0000, 
sim time next is 1418400.0000, 
raw observation next is [0.0, 95.0, 59.0, 0.0, 24.0, 24.41053259111553, 0.1376189739406588, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.46260387811634357, 0.95, 0.19666666666666666, 0.0, 0.5, 0.5342110492596275, 0.5458729913135529, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.44032595], dtype=float32), 0.16843647]. 
=============================================
[2019-04-07 11:05:06,347] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.4008089e-04 8.1891762e-03 5.6014786e-04 3.9870214e-02 2.9572805e-03
 8.9663678e-01 3.8837984e-02 1.2308355e-02], sum to 1.0000
[2019-04-07 11:05:06,348] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8625
[2019-04-07 11:05:06,376] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.2, 73.0, 0.0, 0.0, 24.0, 24.9344602510073, 0.401246856411159, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1540800.0000, 
sim time next is 1542600.0000, 
raw observation next is [7.45, 73.5, 0.0, 0.0, 24.0, 24.7848530295558, 0.3677979397918067, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.6689750692520776, 0.735, 0.0, 0.0, 0.5, 0.5654044191296501, 0.6225993132639356, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.138221], dtype=float32), 0.69236755]. 
=============================================
[2019-04-07 11:05:08,397] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2039502e-04 3.5841479e-03 2.1688644e-04 2.8674304e-02 5.0361262e-04
 9.0950072e-01 4.7415230e-02 9.6847424e-03], sum to 1.0000
[2019-04-07 11:05:08,397] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9826
[2019-04-07 11:05:08,466] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [3.85, 94.5, 88.0, 708.0, 24.0, 25.63012591963788, 0.4616570023641776, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [25.0], 
sim time this is 1510200.0000, 
sim time next is 1512000.0000, 
raw observation next is [4.4, 93.0, 94.0, 704.0, 25.0, 25.72867175041335, 0.4750388127200293, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5844875346260389, 0.93, 0.31333333333333335, 0.7779005524861878, 0.5833333333333334, 0.6440559792011126, 0.6583462709066764, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3125781], dtype=float32), -2.127875]. 
=============================================
[2019-04-07 11:05:08,473] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[18.834692]
 [18.454086]
 [18.492052]
 [17.79263 ]
 [17.36068 ]], R is [[20.14354134]
 [20.94210625]
 [21.73268509]
 [21.88780212]
 [22.66892433]].
[2019-04-07 11:05:09,875] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.00142313 0.00646178 0.00096265 0.05574566 0.00200138 0.66418916
 0.24399424 0.02522209], sum to 1.0000
[2019-04-07 11:05:09,875] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5057
[2019-04-07 11:05:09,917] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.4, 61.0, 208.0, 168.5, 24.0, 25.12855515973481, 0.3436476901597592, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1594800.0000, 
sim time next is 1596600.0000, 
raw observation next is [10.5, 59.0, 216.0, 249.0, 24.0, 25.30816151387713, 0.3933220898669489, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.7534626038781165, 0.59, 0.72, 0.2751381215469613, 0.5, 0.6090134594897609, 0.631107363288983, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7184555], dtype=float32), -0.22412252]. 
=============================================
[2019-04-07 11:05:10,189] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1247260e-04 7.2699878e-03 7.2100002e-04 3.1827159e-02 2.2841608e-03
 8.4144866e-01 8.3482802e-02 3.2153770e-02], sum to 1.0000
[2019-04-07 11:05:10,190] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6135
[2019-04-07 11:05:10,254] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.65, 84.5, 0.0, 0.0, 25.0, 23.78642619985658, 0.159789840758993, 0.0, 1.0, 155060.1522957119], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1571400.0000, 
sim time next is 1573200.0000, 
raw observation next is [4.7, 84.0, 0.0, 0.0, 24.0, 24.09309359924866, 0.193644958593949, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.592797783933518, 0.84, 0.0, 0.0, 0.5, 0.5077577999373885, 0.5645483195313163, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0392923], dtype=float32), -1.1192658]. 
=============================================
[2019-04-07 11:05:10,541] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-07 11:05:10,542] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:05:10,542] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:05:10,543] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:05:10,543] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:05:10,543] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 11:05:10,544] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run4
[2019-04-07 11:05:10,545] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:05:10,546] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run4
[2019-04-07 11:05:10,586] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run4
[2019-04-07 11:06:20,555] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.05366372], dtype=float32), 0.054630082]
[2019-04-07 11:06:20,556] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-6.351039879, 55.25065752, 163.877062, 378.044979, 24.0, 23.88106322264267, -0.05254402326941025, 1.0, 1.0, 0.0]
[2019-04-07 11:06:20,556] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 11:06:20,557] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [0.00264888 0.01255463 0.00195357 0.04749413 0.00622454 0.7679743
 0.12459433 0.03655557], sampled 0.5054631086479275
[2019-04-07 11:06:34,210] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.05366372], dtype=float32), 0.054630082]
[2019-04-07 11:06:34,210] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [0.5, 54.0, 99.0, 658.0, 24.0, 26.27892900159946, 0.5041776615931605, 1.0, 1.0, 0.0]
[2019-04-07 11:06:34,210] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 11:06:34,211] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [0.00293946 0.01417178 0.00220811 0.05859277 0.00543391 0.7379574
 0.14648817 0.03220839], sampled 0.36221691838666825
[2019-04-07 11:06:42,219] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2676.5968 71468826.0045 282.4666
[2019-04-07 11:07:18,736] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2661.8025 80395366.3302 233.7635
[2019-04-07 11:07:25,313] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2656.8112 84254631.9961 158.4983
[2019-04-07 11:07:26,350] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 60000, evaluation results [60000.0, 2661.8025058769335, 80395366.33021802, 233.7634544097357, 2676.59683583598, 71468826.00451244, 282.46656801964474, 2656.8111671412817, 84254631.99608439, 158.49826696126738]
[2019-04-07 11:08:09,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.00124382 0.00859591 0.00089966 0.0242561  0.00149584 0.8516489
 0.09238423 0.0194756 ], sum to 1.0000
[2019-04-07 11:08:09,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6930
[2019-04-07 11:08:09,386] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 82.0, 123.0, 77.5, 24.0, 24.08347879612719, 0.0089046090675991, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2106000.0000, 
sim time next is 2107800.0000, 
raw observation next is [-7.8, 82.0, 174.0, 118.0, 24.0, 24.25761600402419, 0.03982723526117229, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.82, 0.58, 0.13038674033149172, 0.5, 0.5214680003353491, 0.5132757450870574, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6561731], dtype=float32), 0.28812665]. 
=============================================
[2019-04-07 11:08:12,789] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4932134e-04 4.4566002e-03 2.6223061e-04 1.8492097e-02 2.0761655e-03
 8.8127500e-01 8.1925005e-02 1.1163555e-02], sum to 1.0000
[2019-04-07 11:08:12,789] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2057
[2019-04-07 11:08:13,065] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 83.0, 85.5, 0.0, 24.0, 24.53053805590569, 0.02478416675576314, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2023200.0000, 
sim time next is 2025000.0000, 
raw observation next is [-5.6, 83.0, 102.0, 0.0, 24.0, 24.43000405517317, 0.01027738569199926, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.30747922437673136, 0.83, 0.34, 0.0, 0.5, 0.5358336712644309, 0.5034257952306664, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8845783], dtype=float32), -0.22218661]. 
=============================================
[2019-04-07 11:08:13,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[20.39037 ]
 [20.079185]
 [19.094738]
 [18.478405]
 [18.820097]], R is [[21.77017212]
 [22.55247116]
 [23.12778282]
 [23.89650536]
 [24.65754128]].
[2019-04-07 11:08:34,038] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8142959e-04 2.2955474e-03 9.2360999e-05 1.0236173e-02 4.8675542e-04
 9.4354290e-01 3.9039843e-02 3.9249943e-03], sum to 1.0000
[2019-04-07 11:08:34,039] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4936
[2019-04-07 11:08:34,167] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 24.0, 23.41847902096202, -0.05225767631772346, 0.0, 1.0, 31461.517659906705], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2331000.0000, 
sim time next is 2332800.0000, 
raw observation next is [-2.3, 65.0, 0.0, 0.0, 24.0, 23.42350179539037, -0.05612473113964534, 0.0, 1.0, 31406.415391158993], 
processed observation next is [0.0, 0.0, 0.3988919667590028, 0.65, 0.0, 0.0, 0.5, 0.4519584829491974, 0.4812917562867849, 0.0, 1.0, 0.149554359005519], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8154218], dtype=float32), 0.8215968]. 
=============================================
[2019-04-07 11:09:29,115] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1715703e-05 1.2078930e-03 4.5101129e-05 9.0048751e-03 1.8795364e-04
 9.7180068e-01 1.4733789e-02 2.9780008e-03], sum to 1.0000
[2019-04-07 11:09:29,116] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4694
[2019-04-07 11:09:29,328] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.5, 61.5, 0.0, 0.0, 26.0, 23.58398307590866, 0.07755647479717907, 0.0, 1.0, 159103.99096628226], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2752200.0000, 
sim time next is 2754000.0000, 
raw observation next is [-6.0, 64.0, 0.0, 0.0, 24.0, 23.89652938746462, 0.07042750651020589, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.296398891966759, 0.64, 0.0, 0.0, 0.5, 0.4913774489553851, 0.5234758355034019, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6456522], dtype=float32), 0.36898413]. 
=============================================
[2019-04-07 11:09:29,349] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[27.195496]
 [26.456034]
 [27.194778]
 [27.87738 ]
 [27.266594]], R is [[27.38494873]
 [27.35346031]
 [28.07992554]
 [28.79912567]
 [28.71815491]].
[2019-04-07 11:09:42,702] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.54829671e-04 5.91411907e-03 6.80302677e-04 1.88208651e-02
 3.92798893e-03 8.36181581e-01 1.05269864e-01 2.84504108e-02], sum to 1.0000
[2019-04-07 11:09:42,702] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8427
[2019-04-07 11:09:42,739] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 73.5, 0.0, 0.0, 24.0, 22.69475159698565, -0.2737394826506951, 0.0, 1.0, 41093.7139876315], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3047400.0000, 
sim time next is 3049200.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 24.0, 22.72534323008794, -0.2767332713310871, 0.0, 1.0, 41230.36400645947], 
processed observation next is [0.0, 0.30434782608695654, 0.296398891966759, 0.77, 0.0, 0.0, 0.5, 0.3937786025073284, 0.407755576222971, 0.0, 1.0, 0.19633506669742606], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7566186], dtype=float32), 1.508283]. 
=============================================
[2019-04-07 11:09:43,166] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8653252e-04 3.7939115e-03 7.0804171e-04 4.0330291e-02 1.3846373e-03
 8.7314790e-01 7.2960258e-02 7.0884535e-03], sum to 1.0000
[2019-04-07 11:09:43,166] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8902
[2019-04-07 11:09:43,234] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 42.0, 104.0, 790.5, 24.0, 23.31783072634146, -0.04615754956581764, 0.0, 1.0, 12461.05781003106], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3074400.0000, 
sim time next is 3076200.0000, 
raw observation next is [-0.5, 40.5, 99.0, 775.0, 24.0, 23.32022681076176, -0.04463804823851585, 0.0, 1.0, 6229.639923573406], 
processed observation next is [0.0, 0.6086956521739131, 0.44875346260387816, 0.405, 0.33, 0.856353591160221, 0.5, 0.44335223423014664, 0.4851206505871614, 0.0, 1.0, 0.02966495201701622], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.092412], dtype=float32), -0.43846637]. 
=============================================
[2019-04-07 11:09:55,783] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.8005366e-06 8.2829720e-05 4.8384441e-06 2.0904583e-03 3.0341847e-05
 9.8797834e-01 8.7339040e-03 1.0694641e-03], sum to 1.0000
[2019-04-07 11:09:55,783] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9379
[2019-04-07 11:09:55,804] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 85.0, 113.0, 817.5, 24.0, 24.07610563549185, 0.2485564414609871, 1.0, 1.0, 42947.8268546635], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3243600.0000, 
sim time next is 3245400.0000, 
raw observation next is [-3.0, 92.5, 111.0, 812.0, 24.0, 24.56340231572837, 0.3110685224601727, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3795013850415513, 0.925, 0.37, 0.8972375690607735, 0.5, 0.5469501929773642, 0.6036895074867242, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1636848], dtype=float32), -0.36077225]. 
=============================================
[2019-04-07 11:10:23,492] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-07 11:10:23,501] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:10:23,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:10:23,509] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:10:23,509] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:10:23,511] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run5
[2019-04-07 11:10:23,527] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 11:10:23,528] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:10:23,530] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run5
[2019-04-07 11:10:23,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run5
[2019-04-07 11:10:35,119] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.07263695], dtype=float32), 0.073228896]
[2019-04-07 11:10:35,120] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-5.7, 54.0, 0.0, 0.0, 24.0, 23.22654830960031, -0.09143960413815867, 0.0, 1.0, 52293.22337069074]
[2019-04-07 11:10:35,120] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 11:10:35,121] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [4.6020781e-05 8.7584206e-04 1.9417843e-05 6.3128620e-03 2.7514005e-04
 9.5722294e-01 3.1126337e-02 4.1214586e-03], sampled 0.6233649839109298
[2019-04-07 11:10:41,339] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.07263695], dtype=float32), 0.073228896]
[2019-04-07 11:10:41,339] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-6.216534368, 46.20037447, 51.733092855, 593.1499327500001, 24.0, 24.04536144773813, -0.04361950388292857, 1.0, 1.0, 0.0]
[2019-04-07 11:10:41,340] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 11:10:41,340] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.5891195e-05 5.7890610e-04 9.5683436e-06 5.3924844e-03 1.3405315e-04
 9.6866423e-01 2.2818318e-02 2.3866398e-03], sampled 0.2603349044032268
[2019-04-07 11:10:59,119] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.07263695], dtype=float32), 0.073228896]
[2019-04-07 11:10:59,119] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.6, 92.0, 0.0, 0.0, 24.0, 23.62720869017093, 0.1398308605820618, 0.0, 1.0, 16903.020741118748]
[2019-04-07 11:10:59,120] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 11:10:59,120] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [5.2660551e-05 9.7611058e-04 2.5693846e-05 6.6134268e-03 2.9184954e-04
 9.5436102e-01 3.3274084e-02 4.4051455e-03], sampled 0.7907411105866299
[2019-04-07 11:11:51,395] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2760.6811 71073834.1420 204.7707
[2019-04-07 11:12:23,137] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2756.1257 79711762.2512 126.0778
[2019-04-07 11:12:26,790] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2758.8668 83986594.2075 53.4399
[2019-04-07 11:12:27,828] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 80000, evaluation results [80000.0, 2756.1257085179373, 79711762.25120857, 126.07778742967267, 2760.681134272557, 71073834.14196014, 204.77068776799123, 2758.866807421369, 83986594.20753896, 53.43991905727681]
[2019-04-07 11:12:34,783] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8921961e-05 7.8595831e-04 2.3342261e-06 3.3176597e-03 1.2395243e-04
 9.6547800e-01 2.5642022e-02 4.6310425e-03], sum to 1.0000
[2019-04-07 11:12:34,783] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2730
[2019-04-07 11:12:35,076] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 38.0, 98.0, 574.0, 24.0, 24.42839295409468, 0.0692574538897213, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4093200.0000, 
sim time next is 4095000.0000, 
raw observation next is [-2.5, 36.5, 104.0, 679.0, 24.0, 24.56276967755563, 0.1254076572899068, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.39335180055401664, 0.365, 0.3466666666666667, 0.7502762430939226, 0.5, 0.5468974731296358, 0.5418025524299689, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9344344], dtype=float32), 0.58321625]. 
=============================================
[2019-04-07 11:12:35,080] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[31.457943]
 [30.05004 ]
 [29.331282]
 [28.934092]
 [28.222525]], R is [[33.29243469]
 [33.9595108 ]
 [34.61991501]
 [35.27371597]
 [35.92097855]].
[2019-04-07 11:12:35,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3789468e-06 1.2836882e-04 8.4038753e-08 3.3435374e-04 2.3026170e-05
 9.9240780e-01 6.6957502e-03 4.0918298e-04], sum to 1.0000
[2019-04-07 11:12:35,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8839
[2019-04-07 11:12:35,350] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 47.0, 119.0, 835.0, 24.0, 24.84249655513512, 0.2414955062734743, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3933000.0000, 
sim time next is 3934800.0000, 
raw observation next is [-6.0, 45.0, 117.5, 829.5, 24.0, 24.77599244957319, 0.1525349612844138, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.296398891966759, 0.45, 0.39166666666666666, 0.9165745856353591, 0.5, 0.5646660374644327, 0.5508449870948046, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.65973896], dtype=float32), -1.087354]. 
=============================================
[2019-04-07 11:12:40,085] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.4215757e-04 1.4971286e-03 2.0367142e-05 1.3337445e-02 2.0157339e-04
 9.5750606e-01 1.7890273e-02 9.4049815e-03], sum to 1.0000
[2019-04-07 11:12:40,085] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6177
[2019-04-07 11:12:40,192] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 39.5, 0.0, 0.0, 24.0, 23.39196339880494, -0.1106836591168002, 0.0, 1.0, 48044.07827454071], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4073400.0000, 
sim time next is 4075200.0000, 
raw observation next is [-5.0, 41.0, 0.0, 0.0, 24.0, 23.39088673564511, -0.1050614209937171, 0.0, 1.0, 48084.69976374967], 
processed observation next is [1.0, 0.17391304347826086, 0.32409972299168976, 0.41, 0.0, 0.0, 0.5, 0.4492405613037593, 0.46497952633542766, 0.0, 1.0, 0.2289747607797603], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.22793925], dtype=float32), 1.6620243]. 
=============================================
[2019-04-07 11:12:43,859] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.7571468e-06 2.9037448e-04 8.3441427e-07 9.9409116e-04 3.1150390e-05
 9.9358094e-01 4.3163793e-03 7.8452349e-04], sum to 1.0000
[2019-04-07 11:12:43,860] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5581
[2019-04-07 11:12:44,201] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 31.0, 0.0, 0.0, 24.0, 23.519634417646, 0.02281736468238301, 0.0, 1.0, 119078.41130736792], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4044600.0000, 
sim time next is 4046400.0000, 
raw observation next is [-4.0, 31.0, 0.0, 0.0, 24.0, 23.60342669708063, 0.07116427905324144, 0.0, 1.0, 56571.16200210916], 
processed observation next is [1.0, 0.8695652173913043, 0.3518005540166205, 0.31, 0.0, 0.0, 0.5, 0.46695222475671905, 0.5237214263510804, 0.0, 1.0, 0.2693864857243293], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.01631039], dtype=float32), 0.8939456]. 
=============================================
[2019-04-07 11:13:55,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:13:55,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:13:55,063] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run3
[2019-04-07 11:13:58,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:13:58,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:13:58,279] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run3
[2019-04-07 11:13:59,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:13:59,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:13:59,507] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run3
[2019-04-07 11:14:03,582] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:03,582] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:03,584] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run3
[2019-04-07 11:14:07,940] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:07,940] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:07,942] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run3
[2019-04-07 11:14:08,386] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:08,386] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:08,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run3
[2019-04-07 11:14:09,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:09,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:09,587] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run3
[2019-04-07 11:14:09,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:09,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:09,879] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run3
[2019-04-07 11:14:10,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:10,320] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:10,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run3
[2019-04-07 11:14:14,132] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:14,132] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:14,134] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run3
[2019-04-07 11:14:14,182] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:14,183] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:14,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run3
[2019-04-07 11:14:14,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:14,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:14,260] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run3
[2019-04-07 11:14:14,676] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:14,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:14,679] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run3
[2019-04-07 11:14:15,016] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:15,016] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:15,019] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run3
[2019-04-07 11:14:16,250] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:16,250] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:16,252] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run3
[2019-04-07 11:14:17,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:14:17,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:14:17,051] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run3
[2019-04-07 11:14:42,051] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1213149e-08 5.2345058e-06 5.3454818e-09 8.0705759e-05 5.0233524e-08
 9.9932516e-01 5.4156967e-04 4.7186590e-05], sum to 1.0000
[2019-04-07 11:14:42,052] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5794
[2019-04-07 11:14:42,235] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 24.0, 23.08826082254061, -0.169050151874667, 1.0, 1.0, 70982.15802363808], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 237600.0000, 
sim time next is 239400.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 24.0, 23.36080055589168, -0.1896076223470836, 1.0, 1.0, 6235.62150145766], 
processed observation next is [1.0, 0.782608695652174, 0.368421052631579, 0.65, 0.0, 0.0, 0.5, 0.4467333796576399, 0.43679745921763885, 1.0, 1.0, 0.029693435721226954], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.48060435], dtype=float32), 1.2075244]. 
=============================================
[2019-04-07 11:14:54,572] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.8202788e-07 1.7071647e-05 2.8810463e-08 2.8886841e-04 2.9035764e-06
 9.9276567e-01 6.8733753e-03 5.1699662e-05], sum to 1.0000
[2019-04-07 11:14:54,573] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9739
[2019-04-07 11:14:54,654] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 24.0, 22.97516044366187, -0.2021468363049578, 0.0, 1.0, 45538.29563654048], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 255600.0000, 
sim time next is 257400.0000, 
raw observation next is [-4.2, 80.5, 0.0, 0.0, 24.0, 22.90145311575379, -0.2195777912178583, 0.0, 1.0, 45521.26660076403], 
processed observation next is [1.0, 1.0, 0.34626038781163443, 0.805, 0.0, 0.0, 0.5, 0.40845442631281575, 0.42680740292738056, 0.0, 1.0, 0.2167679361941144], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5571855], dtype=float32), -1.9252498]. 
=============================================
[2019-04-07 11:14:55,670] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.98261406e-08 6.19092407e-06 3.33988170e-09 1.18590826e-04
 1.37359177e-06 9.95166779e-01 4.55272617e-03 1.54406313e-04], sum to 1.0000
[2019-04-07 11:14:55,670] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5765
[2019-04-07 11:14:55,917] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 44.0, 89.0, 694.5, 24.0, 22.81790200072304, -0.05431374934344232, 1.0, 1.0, 198634.86969889817], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 306000.0000, 
sim time next is 307800.0000, 
raw observation next is [-9.5, 44.0, 95.0, 631.0, 24.0, 24.45594724805908, 0.1185199009211939, 1.0, 1.0, 6811.793014638751], 
processed observation next is [1.0, 0.5652173913043478, 0.1994459833795014, 0.44, 0.31666666666666665, 0.6972375690607735, 0.5, 0.5379956040049233, 0.539506633640398, 1.0, 1.0, 0.03243710959351786], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8866656], dtype=float32), -0.23175718]. 
=============================================
[2019-04-07 11:14:57,950] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0617073e-05 2.0156092e-04 5.4036184e-07 5.7910369e-03 1.2338281e-04
 9.7442663e-01 1.6258186e-02 3.1780689e-03], sum to 1.0000
[2019-04-07 11:14:57,950] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2610
[2019-04-07 11:14:58,369] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.55, 68.5, 0.0, 0.0, 24.0, 21.77277088535455, -0.3839536292147405, 1.0, 1.0, 151452.0606518516], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 286200.0000, 
sim time next is 288000.0000, 
raw observation next is [-12.8, 70.0, 15.0, 205.5, 24.0, 23.43183395731166, -0.1542775617135916, 1.0, 1.0, 79946.16966319013], 
processed observation next is [1.0, 0.34782608695652173, 0.1080332409972299, 0.7, 0.05, 0.22707182320441988, 0.5, 0.4526528297759717, 0.4485741460954695, 1.0, 1.0, 0.3806960460151911], 
reward next is 0.9050, 
noisyNet noise sample is [array([-0.6322121], dtype=float32), -0.77428323]. 
=============================================
[2019-04-07 11:14:58,373] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[36.725178]
 [35.30541 ]
 [35.375954]
 [35.529034]
 [35.632652]], R is [[37.89291   ]
 [38.07849503]
 [38.69771194]
 [39.3107338 ]
 [39.91762543]].
[2019-04-07 11:15:19,763] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4366225e-06 7.0449853e-05 2.9555747e-07 1.2458516e-03 5.0613094e-06
 9.7585773e-01 2.1765847e-02 1.0522585e-03], sum to 1.0000
[2019-04-07 11:15:19,763] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2944
[2019-04-07 11:15:19,830] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.1, 83.0, 0.0, 0.0, 24.0, 23.36971373543114, -0.1136803647715013, 0.0, 1.0, 45728.20115869468], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 599400.0000, 
sim time next is 601200.0000, 
raw observation next is [-3.4, 83.0, 0.0, 0.0, 24.0, 23.36035950870217, -0.1193994160612781, 0.0, 1.0, 43556.941247071554], 
processed observation next is [0.0, 1.0, 0.368421052631579, 0.83, 0.0, 0.0, 0.5, 0.44669662572518093, 0.4602001946462406, 0.0, 1.0, 0.20741400593843598], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.35625368], dtype=float32), 1.1108147]. 
=============================================
[2019-04-07 11:15:36,519] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.72463518e-08 1.12603038e-05 3.08191161e-08 1.24301718e-04
 7.39294251e-07 9.94312406e-01 5.45043964e-03 1.00769794e-04], sum to 1.0000
[2019-04-07 11:15:36,519] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4547
[2019-04-07 11:15:36,559] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 79.0, 0.0, 0.0, 24.0, 23.29775799340278, -0.1266574329671573, 0.0, 1.0, 42650.89521685469], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 860400.0000, 
sim time next is 862200.0000, 
raw observation next is [-2.55, 79.5, 0.0, 0.0, 24.0, 23.24070381463972, -0.1368127708407877, 0.0, 1.0, 42168.3110073152], 
processed observation next is [1.0, 1.0, 0.3919667590027701, 0.795, 0.0, 0.0, 0.5, 0.43672531788664326, 0.4543957430530708, 0.0, 1.0, 0.20080148098721523], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.622936], dtype=float32), -0.9247363]. 
=============================================
[2019-04-07 11:15:37,542] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.30504745e-07 1.68467941e-05 1.62944733e-08 3.22325242e-04
 1.24088274e-06 9.97572958e-01 1.98379043e-03 1.02729166e-04], sum to 1.0000
[2019-04-07 11:15:37,542] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9947
[2019-04-07 11:15:37,601] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.15, 81.0, 0.0, 0.0, 24.0, 23.64682690300351, -0.006664571834079082, 0.0, 1.0, 6371.080318870337], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 959400.0000, 
sim time next is 961200.0000, 
raw observation next is [7.7, 80.0, 0.0, 0.0, 24.0, 23.50739994168859, -0.005579376221930471, 0.0, 1.0, 59445.652126567904], 
processed observation next is [1.0, 0.13043478260869565, 0.6759002770083103, 0.8, 0.0, 0.0, 0.5, 0.4589499951407158, 0.49814020792602315, 0.0, 1.0, 0.28307453393603765], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1889259], dtype=float32), -0.14091735]. 
=============================================
[2019-04-07 11:15:46,505] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-07 11:15:46,506] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:15:46,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:15:46,515] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:15:46,516] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:15:46,516] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 11:15:46,516] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:15:46,518] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run6
[2019-04-07 11:15:46,519] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run6
[2019-04-07 11:15:46,549] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run6
[2019-04-07 11:15:50,886] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.08702681], dtype=float32), 0.08755082]
[2019-04-07 11:15:50,886] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [10.11873186, 94.54385323, 0.0, 0.0, 24.0, 21.32007544517972, -0.5412536970812515, 0.0, 1.0, 40038.491584054704]
[2019-04-07 11:15:50,886] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 11:15:50,887] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.6861542e-06 4.6648544e-05 4.0332270e-07 6.5687817e-04 1.2822222e-05
 9.8829597e-01 1.0400993e-02 5.8452855e-04], sampled 0.022206564325920497
[2019-04-07 11:16:25,177] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.08702681], dtype=float32), 0.08755082]
[2019-04-07 11:16:25,178] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [0.320910018, 100.0, 52.795998418, 0.0, 24.0, 23.74621704226681, -0.0126938999367422, 1.0, 1.0, 0.0]
[2019-04-07 11:16:25,178] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 11:16:25,178] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.7428590e-08 1.8707549e-06 2.0850450e-09 5.0907540e-05 2.9059760e-07
 9.9782842e-01 2.0728703e-03 4.5504501e-05], sampled 0.1605155419273676
[2019-04-07 11:17:18,219] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2785.2541 70878801.1192 168.2801
[2019-04-07 11:17:54,518] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2776.2060 79362946.5439 107.3083
[2019-04-07 11:18:00,037] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2778.0524 83887673.9571 38.1258
[2019-04-07 11:18:01,075] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 100000, evaluation results [100000.0, 2776.206013296976, 79362946.54388085, 107.30826105775418, 2785.2540740713043, 70878801.1191668, 168.2801171826146, 2778.0524445148176, 83887673.95708157, 38.12575189512098]
[2019-04-07 11:18:29,133] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.3788638e-09 1.0925744e-06 4.3642019e-09 1.6258235e-05 3.2537392e-07
 9.9528450e-01 4.6661701e-03 3.1714208e-05], sum to 1.0000
[2019-04-07 11:18:29,133] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3256
[2019-04-07 11:18:29,260] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.25, 80.5, 0.0, 0.0, 24.0, 23.76049135294642, 0.0489985744375935, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1578600.0000, 
sim time next is 1580400.0000, 
raw observation next is [5.5, 79.0, 0.0, 0.0, 24.0, 23.5683427067725, 0.03982984447650664, 0.0, 1.0, 72220.14688292833], 
processed observation next is [1.0, 0.30434782608695654, 0.6149584487534627, 0.79, 0.0, 0.0, 0.5, 0.46402855889770844, 0.5132766148255022, 0.0, 1.0, 0.34390546134727773], 
reward next is 0.9418, 
noisyNet noise sample is [array([-0.4915106], dtype=float32), 0.30324122]. 
=============================================
[2019-04-07 11:18:34,704] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5189940e-10 1.9875454e-08 2.7712745e-12 8.7109692e-07 5.5202984e-09
 9.9966586e-01 3.3060575e-04 2.6827042e-06], sum to 1.0000
[2019-04-07 11:18:34,705] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9993
[2019-04-07 11:18:35,099] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 24.0, 23.12377792061409, 0.001294962879517136, 0.0, 1.0, 35807.70400474599], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1366200.0000, 
sim time next is 1368000.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 24.0, 23.00297553385485, 0.03337985594382752, 1.0, 1.0, 78271.67521343612], 
processed observation next is [1.0, 0.8695652173913043, 0.4764542936288089, 0.96, 0.0, 0.0, 0.5, 0.4169146278212376, 0.5111266186479425, 1.0, 1.0, 0.37272226292112437], 
reward next is 0.9130, 
noisyNet noise sample is [array([-0.69383574], dtype=float32), -0.7404226]. 
=============================================
[2019-04-07 11:18:35,147] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[60.034637]
 [60.78793 ]
 [60.753574]
 [61.034325]
 [61.011112]], R is [[61.22319412]
 [61.61096191]
 [61.99485397]
 [62.37490463]
 [62.66984558]].
[2019-04-07 11:18:40,438] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.5217425e-09 5.8120884e-07 5.5861371e-11 1.8622919e-05 8.8672927e-08
 9.9963629e-01 3.2239707e-04 2.2063525e-05], sum to 1.0000
[2019-04-07 11:18:40,438] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5453
[2019-04-07 11:18:40,505] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 24.0, 23.38427786221136, 0.08092737572811982, 0.0, 1.0, 74292.55160438536], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1378800.0000, 
sim time next is 1380600.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 24.0, 23.5427095426235, 0.06912765162942532, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.5, 0.46189246188529154, 0.5230425505431417, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0278182], dtype=float32), 0.094908565]. 
=============================================
[2019-04-07 11:18:42,865] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.24036326e-09 1.49739279e-07 6.23007410e-11 3.18345628e-05
 7.90583030e-08 9.98430073e-01 1.52780022e-03 1.00502875e-05], sum to 1.0000
[2019-04-07 11:18:42,865] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0203
[2019-04-07 11:18:42,931] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.15, 72.0, 115.0, 136.0, 24.0, 24.38152214543462, 0.1963681139182489, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1589400.0000, 
sim time next is 1591200.0000, 
raw observation next is [7.7, 68.0, 157.5, 112.0, 24.0, 24.74993274248515, 0.2498610325947141, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.6759002770083103, 0.68, 0.525, 0.12375690607734807, 0.5, 0.5624943952070959, 0.5832870108649048, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3376402], dtype=float32), 0.72215486]. 
=============================================
[2019-04-07 11:18:51,737] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.3380463e-08 2.1589569e-06 5.2642370e-09 1.8263994e-05 5.7843084e-07
 9.9705243e-01 2.8966526e-03 2.9881146e-05], sum to 1.0000
[2019-04-07 11:18:51,744] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7667
[2019-04-07 11:18:51,825] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.2, 91.0, 0.0, 0.0, 24.0, 23.42992627196924, 0.0141597157530711, 0.0, 1.0, 38892.04955370437], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1735200.0000, 
sim time next is 1737000.0000, 
raw observation next is [0.1, 91.0, 0.0, 0.0, 24.0, 23.42587960739178, 0.01641705739785595, 0.0, 1.0, 44891.84538310938], 
processed observation next is [0.0, 0.08695652173913043, 0.4653739612188367, 0.91, 0.0, 0.0, 0.5, 0.4521566339493151, 0.505472352465952, 0.0, 1.0, 0.21377069230052084], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2070378], dtype=float32), 2.2695606]. 
=============================================
[2019-04-07 11:18:51,833] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[45.37116 ]
 [48.238827]
 [49.81342 ]
 [51.33643 ]
 [53.40043 ]], R is [[43.71595764]
 [44.27879715]
 [44.83600998]
 [45.38764954]
 [45.93377304]].
[2019-04-07 11:19:09,694] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3468291e-07 2.7707354e-06 1.8288665e-09 4.6938130e-05 1.4981717e-06
 9.9142563e-01 8.4259240e-03 9.7079122e-05], sum to 1.0000
[2019-04-07 11:19:09,694] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0190
[2019-04-07 11:19:09,810] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 24.0, 23.34289973387752, -0.1492960964498378, 0.0, 1.0, 57220.71586586955], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1890000.0000, 
sim time next is 1891800.0000, 
raw observation next is [-5.9, 79.0, 0.0, 0.0, 24.0, 23.30077590539123, -0.1591885904422948, 0.0, 1.0, 47542.81433531822], 
processed observation next is [0.0, 0.9130434782608695, 0.2991689750692521, 0.79, 0.0, 0.0, 0.5, 0.4417313254492692, 0.4469371365192351, 0.0, 1.0, 0.2263943539777058], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.45514938], dtype=float32), 0.9506341]. 
=============================================
[2019-04-07 11:19:25,779] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3774695e-09 3.0427057e-07 9.4196748e-11 1.3964841e-05 9.3421960e-08
 9.9954683e-01 4.3655699e-04 2.0891450e-06], sum to 1.0000
[2019-04-07 11:19:25,779] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1716
[2019-04-07 11:19:26,189] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 15.0, 0.0, 24.0, 23.2199179952521, -0.2015485733237623, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2016000.0000, 
sim time next is 2017800.0000, 
raw observation next is [-6.1, 86.5, 29.0, 0.0, 24.0, 23.40500338564278, -0.1537246026455754, 1.0, 1.0, 20515.318041750495], 
processed observation next is [1.0, 0.34782608695652173, 0.29362880886426596, 0.865, 0.09666666666666666, 0.0, 0.5, 0.4504169488035649, 0.4487584657848082, 1.0, 1.0, 0.09769199067500237], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.15344265], dtype=float32), 0.70599544]. 
=============================================
[2019-04-07 11:19:27,030] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2058352e-08 1.2096569e-07 7.3110257e-10 2.2825161e-04 7.7544165e-08
 9.9765790e-01 2.0947573e-03 1.8939034e-05], sum to 1.0000
[2019-04-07 11:19:27,030] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0885
[2019-04-07 11:19:27,414] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 24.0, 23.08128231126017, -0.1892371247670213, 1.0, 1.0, 41336.950153225764], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2014200.0000, 
sim time next is 2016000.0000, 
raw observation next is [-6.2, 87.0, 15.0, 0.0, 24.0, 23.22361994155337, -0.2011851971356116, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.2908587257617729, 0.87, 0.05, 0.0, 0.5, 0.4353016617961141, 0.4329382676214628, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.49977812], dtype=float32), 1.5632156]. 
=============================================
[2019-04-07 11:19:27,420] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[51.36417 ]
 [50.037453]
 [49.85555 ]
 [49.761677]
 [49.558697]], R is [[52.50444794]
 [52.97940445]
 [53.44961166]
 [53.91511536]
 [54.37596512]].
[2019-04-07 11:20:01,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8746873e-08 2.9299842e-06 1.7062094e-08 1.0707860e-04 7.6087173e-07
 9.9810338e-01 1.6933461e-03 9.2302158e-05], sum to 1.0000
[2019-04-07 11:20:01,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3427
[2019-04-07 11:20:01,290] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 39.0, 0.0, 0.0, 24.0, 23.61140675636778, -0.1165783938404751, 0.0, 1.0, 30184.71319821796], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2507400.0000, 
sim time next is 2509200.0000, 
raw observation next is [-1.7, 40.0, 0.0, 0.0, 24.0, 23.55917874075661, -0.166731960484259, 0.0, 1.0, 6247.433324609953], 
processed observation next is [1.0, 0.043478260869565216, 0.4155124653739613, 0.4, 0.0, 0.0, 0.5, 0.4632648950630509, 0.44442267983858036, 0.0, 1.0, 0.029749682498142634], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.97756875], dtype=float32), 1.5872649]. 
=============================================
[2019-04-07 11:20:10,083] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.2719462e-10 1.1060487e-08 1.9733928e-12 8.0148237e-07 1.2793214e-09
 9.9988019e-01 1.1870371e-04 2.8880919e-07], sum to 1.0000
[2019-04-07 11:20:10,083] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8696
[2019-04-07 11:20:10,201] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 64.0, 0.0, 0.0, 24.0, 23.0989063386839, -0.04945730133960386, 0.0, 1.0, 143826.75265402335], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2665800.0000, 
sim time next is 2667600.0000, 
raw observation next is [-1.2, 65.0, 0.0, 0.0, 24.0, 23.43205654275963, 0.02172337170423441, 0.0, 1.0, 61011.45133605707], 
processed observation next is [1.0, 0.9130434782608695, 0.42936288088642666, 0.65, 0.0, 0.0, 0.5, 0.45267137856330236, 0.5072411239014115, 0.0, 1.0, 0.2905307206478908], 
reward next is 0.9952, 
noisyNet noise sample is [array([1.2992079], dtype=float32), -1.2022892]. 
=============================================
[2019-04-07 11:20:10,831] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.9075696e-09 1.8531446e-07 1.8952804e-09 1.3153541e-05 9.4080796e-08
 9.9917018e-01 7.6972379e-04 4.6664136e-05], sum to 1.0000
[2019-04-07 11:20:10,831] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0975
[2019-04-07 11:20:10,917] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.0, 69.0, 0.0, 0.0, 24.0, 23.12849396626364, -0.1287888838580651, 0.0, 1.0, 45735.147280267316], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2682000.0000, 
sim time next is 2683800.0000, 
raw observation next is [-10.0, 72.5, 0.0, 0.0, 24.0, 23.01611011037672, -0.1702662262919672, 0.0, 1.0, 45645.88264966209], 
processed observation next is [1.0, 0.043478260869565216, 0.18559556786703602, 0.725, 0.0, 0.0, 0.5, 0.4180091758647266, 0.44324459123601095, 0.0, 1.0, 0.21736134595077186], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4542418], dtype=float32), 0.18951248]. 
=============================================
[2019-04-07 11:20:11,468] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2648449e-08 6.0891620e-07 9.7973885e-10 3.5408597e-05 1.9790703e-07
 9.9848598e-01 1.4332327e-03 4.4569024e-05], sum to 1.0000
[2019-04-07 11:20:11,468] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5974
[2019-04-07 11:20:11,538] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 24.0, 23.27144051448235, -0.1300884886596236, 0.0, 1.0, 50438.39145861494], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2773800.0000, 
sim time next is 2775600.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 24.0, 23.28243237274389, -0.1380238628933896, 0.0, 1.0, 42673.3592465679], 
processed observation next is [1.0, 0.13043478260869565, 0.296398891966759, 0.59, 0.0, 0.0, 0.5, 0.44020269772865755, 0.4539920457022035, 0.0, 1.0, 0.2032064726027043], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.95565134], dtype=float32), 0.14530632]. 
=============================================
[2019-04-07 11:20:12,469] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6003673e-10 5.2451532e-09 5.5689104e-12 1.0622880e-06 3.2001515e-09
 9.9995852e-01 3.9915245e-05 4.6932450e-07], sum to 1.0000
[2019-04-07 11:20:12,470] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7499
[2019-04-07 11:20:12,498] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.2500000000000001, 43.0, 232.0, 71.0, 24.0, 24.10631487379989, -0.06189549559663288, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2547000.0000, 
sim time next is 2548800.0000, 
raw observation next is [1.1, 39.0, 225.0, 46.5, 24.0, 24.18061687107562, -0.04879269356608115, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.49307479224376743, 0.39, 0.75, 0.05138121546961326, 0.5, 0.5150514059229684, 0.48373576881130625, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.515182], dtype=float32), 0.33220208]. 
=============================================
[2019-04-07 11:20:31,261] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8181110e-08 1.3236220e-07 1.1834675e-09 2.8762282e-05 5.7070206e-08
 9.9816304e-01 1.7958770e-03 1.2211281e-05], sum to 1.0000
[2019-04-07 11:20:31,261] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1356
[2019-04-07 11:20:31,354] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 24.0, 23.41499154520585, -0.08050480803548472, 0.0, 1.0, 44157.42343651238], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3016800.0000, 
sim time next is 3018600.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 24.0, 23.43409528942221, -0.08966596305446224, 0.0, 1.0, 31881.789386442248], 
processed observation next is [0.0, 0.9565217391304348, 0.3518005540166205, 0.65, 0.0, 0.0, 0.5, 0.4528412741185175, 0.4701113456485126, 0.0, 1.0, 0.15181804469734403], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0774568], dtype=float32), 0.6892628]. 
=============================================
[2019-04-07 11:20:31,437] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.4659960e-08 1.8753291e-06 3.9395083e-09 2.1093028e-05 5.3227694e-07
 9.9739718e-01 2.5591520e-03 2.0047835e-05], sum to 1.0000
[2019-04-07 11:20:31,440] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9743
[2019-04-07 11:20:31,520] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.75, 65.0, 0.0, 0.0, 24.0, 23.43564980349518, -0.07220658775005141, 0.0, 1.0, 36928.98439796904], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3015000.0000, 
sim time next is 3016800.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 24.0, 23.41972287660076, -0.07870009495040621, 0.0, 1.0, 42533.244177372086], 
processed observation next is [0.0, 0.9565217391304348, 0.3518005540166205, 0.65, 0.0, 0.0, 0.5, 0.4516435730500632, 0.47376663501653127, 0.0, 1.0, 0.20253925798748612], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.43712813], dtype=float32), 0.98813593]. 
=============================================
[2019-04-07 11:20:45,752] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-07 11:20:45,752] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:20:45,752] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:20:45,754] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run7
[2019-04-07 11:20:45,770] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:20:45,771] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:20:45,772] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 11:20:45,775] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run7
[2019-04-07 11:20:45,794] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:20:45,800] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run7
[2019-04-07 11:21:06,353] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.09659122], dtype=float32), 0.09754469]
[2019-04-07 11:21:06,353] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-1.835108703, 97.5705104, 0.0, 0.0, 24.0, 23.08411325587616, -0.2111503056755648, 0.0, 1.0, 53312.242886608794]
[2019-04-07 11:21:06,353] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 11:21:06,354] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [5.6802890e-10 3.6350624e-08 2.3175080e-11 1.1897249e-06 1.0166720e-08
 9.9957293e-01 4.2278608e-04 3.0839790e-06], sampled 0.5504422050852404
[2019-04-07 11:21:21,222] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.09659122], dtype=float32), 0.09754469]
[2019-04-07 11:21:21,222] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-2.8, 71.0, 0.0, 0.0, 24.0, 23.13230922157138, -0.1921783299720307, 0.0, 1.0, 38208.88145745012]
[2019-04-07 11:21:21,222] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 11:21:21,223] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [6.4815303e-08 1.5411071e-06 6.1589600e-09 2.8162383e-05 5.4305070e-07
 9.9732131e-01 2.6019458e-03 4.6454286e-05], sampled 0.3977558113642834
[2019-04-07 11:22:26,630] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2788.8653 70926442.4630 167.1368
[2019-04-07 11:22:45,442] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.09659122], dtype=float32), 0.09754469]
[2019-04-07 11:22:45,442] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [3.426974551, 72.913187025, 0.0, 0.0, 24.0, 23.58026506114705, 0.05819914208349325, 0.0, 1.0, 37572.20814137741]
[2019-04-07 11:22:45,442] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 11:22:45,443] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.6165418e-08 8.3125343e-07 2.5603588e-09 1.7143893e-05 2.3288536e-07
 9.9821138e-01 1.7423955e-03 2.7934653e-05], sampled 0.36102844711158744
[2019-04-07 11:22:54,372] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.5135 79428246.9220 94.9407
[2019-04-07 11:23:01,877] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.5065 83781558.7530 32.8203
[2019-04-07 11:23:02,926] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 120000, evaluation results [120000.0, 2782.5135466930037, 79428246.9219517, 94.94073539821291, 2788.8653204663647, 70926442.46302046, 167.13683530328345, 2784.506540812139, 83781558.75295287, 32.820302227313114]
[2019-04-07 11:23:12,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2423857e-08 1.1684191e-07 7.6600372e-11 4.1426524e-06 6.8802812e-08
 9.9979812e-01 1.9656451e-04 9.4806131e-07], sum to 1.0000
[2019-04-07 11:23:12,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7728
[2019-04-07 11:23:13,258] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.0, 76.0, 0.0, 0.0, 24.0, 22.64776655989825, -0.2085127886981218, 0.0, 1.0, 44986.40608750565], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3308400.0000, 
sim time next is 3310200.0000, 
raw observation next is [-11.0, 80.0, 2.0, 94.0, 24.0, 22.98962004992976, -0.05007845189967172, 1.0, 1.0, 121344.24022817724], 
processed observation next is [1.0, 0.30434782608695654, 0.15789473684210528, 0.8, 0.006666666666666667, 0.10386740331491713, 0.5, 0.4158016708274799, 0.4833071827001094, 1.0, 1.0, 0.5778297153722726], 
reward next is 0.7079, 
noisyNet noise sample is [array([-0.09273335], dtype=float32), -0.186326]. 
=============================================
[2019-04-07 11:23:13,365] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.3143035e-11 3.1246469e-08 3.3618611e-12 2.6057668e-07 1.8666404e-09
 9.9973232e-01 2.6552271e-04 1.8706636e-06], sum to 1.0000
[2019-04-07 11:23:13,366] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7133
[2019-04-07 11:23:13,531] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 24.0, 23.63152374954851, 0.05380298659817511, 0.0, 1.0, 29122.72480885984], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3454200.0000, 
sim time next is 3456000.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 24.0, 23.58522181996937, 0.0241561113451771, 0.0, 1.0, 12411.453572574772], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.86, 0.0, 0.0, 0.5, 0.46543515166411414, 0.5080520371150591, 0.0, 1.0, 0.059102159869403675], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.41810355], dtype=float32), 0.10289828]. 
=============================================
[2019-04-07 11:23:13,641] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[68.180405]
 [68.574524]
 [68.22425 ]
 [68.918526]
 [69.20561 ]], R is [[66.80488586]
 [67.13684082]
 [67.22917175]
 [67.55687714]
 [67.88130951]].
[2019-04-07 11:23:23,637] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.5226821e-12 3.4828487e-10 1.5971583e-13 5.9729572e-08 1.5694837e-10
 9.9996519e-01 3.4731096e-05 3.2866041e-08], sum to 1.0000
[2019-04-07 11:23:23,638] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4478
[2019-04-07 11:23:23,794] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 49.0, 112.0, 784.0, 24.0, 25.0180883108607, 0.2289135832141599, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3409200.0000, 
sim time next is 3411000.0000, 
raw observation next is [3.0, 47.0, 115.0, 804.0, 24.0, 24.89276236585063, 0.2327978955730714, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.5457063711911359, 0.47, 0.38333333333333336, 0.8883977900552487, 0.5, 0.5743968638208857, 0.5775992985243571, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.20840356], dtype=float32), 0.2567768]. 
=============================================
[2019-04-07 11:23:23,803] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.62645 ]
 [69.24848 ]
 [67.24225 ]
 [65.252075]
 [63.142925]], R is [[71.85998535]
 [72.14138794]
 [72.41997528]
 [72.69577789]
 [72.96881866]].
[2019-04-07 11:23:27,726] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.4639894e-09 5.1015115e-07 8.4213758e-10 9.7446455e-06 5.1263845e-07
 9.9799263e-01 1.9757058e-03 2.0955080e-05], sum to 1.0000
[2019-04-07 11:23:27,741] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6410
[2019-04-07 11:23:27,966] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 50.0, 0.0, 0.0, 24.0, 23.51819506466105, -0.04685682594110518, 0.0, 1.0, 72386.710176609], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3621600.0000, 
sim time next is 3623400.0000, 
raw observation next is [-2.5, 55.0, 0.0, 0.0, 24.0, 23.50199904690986, -0.05100321707796197, 0.0, 1.0, 41189.10362535601], 
processed observation next is [0.0, 0.9565217391304348, 0.39335180055401664, 0.55, 0.0, 0.0, 0.5, 0.45849992057582156, 0.48299892764067937, 0.0, 1.0, 0.19613858869217146], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.41760924], dtype=float32), 0.24871475]. 
=============================================
[2019-04-07 11:23:49,760] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.66155617e-09 1.00302344e-07 9.03600458e-11 1.09323787e-06
 5.21942933e-09 9.99831438e-01 1.65366437e-04 1.93436040e-06], sum to 1.0000
[2019-04-07 11:23:49,760] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4603
[2019-04-07 11:23:49,891] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 24.0, 23.44927227014506, -0.06203846831270907, 0.0, 1.0, 41498.523578268745], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3717000.0000, 
sim time next is 3718800.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 24.0, 23.72098844178352, -0.0400707949980439, 0.0, 1.0, 15337.74687875752], 
processed observation next is [1.0, 0.043478260869565216, 0.3795013850415513, 0.71, 0.0, 0.0, 0.5, 0.4767490368152932, 0.48664306833398535, 0.0, 1.0, 0.07303688989884534], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24980824], dtype=float32), 0.2488634]. 
=============================================
[2019-04-07 11:24:21,018] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.1694757e-09 2.1071443e-08 2.4553167e-11 1.9214774e-06 1.9637149e-08
 9.9901938e-01 9.7698183e-04 1.7099723e-06], sum to 1.0000
[2019-04-07 11:24:21,018] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3583
[2019-04-07 11:24:21,088] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.7, 71.0, 0.0, 0.0, 24.0, 23.24113002566115, -0.08879496402429093, 0.0, 1.0, 130811.93961286407], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4303800.0000, 
sim time next is 4305600.0000, 
raw observation next is [5.4, 73.0, 0.0, 0.0, 24.0, 23.43831581623428, 0.03367989074436631, 0.0, 1.0, 157960.17254312205], 
processed observation next is [0.0, 0.8695652173913043, 0.6121883656509697, 0.73, 0.0, 0.0, 0.5, 0.45319298468618996, 0.5112266302481221, 0.0, 1.0, 0.7521912978243908], 
reward next is 0.5335, 
noisyNet noise sample is [array([-0.12439776], dtype=float32), 0.47034925]. 
=============================================
[2019-04-07 11:24:26,038] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.4873792e-13 2.1853093e-10 6.5650805e-15 3.0214384e-08 5.6764267e-11
 9.9998605e-01 1.3849569e-05 3.9249684e-08], sum to 1.0000
[2019-04-07 11:24:26,039] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0675
[2019-04-07 11:24:26,052] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.2, 47.0, 0.0, 0.0, 24.0, 26.1757763840309, 0.6080321756906386, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4386600.0000, 
sim time next is 4388400.0000, 
raw observation next is [12.0, 50.0, 0.0, 0.0, 24.0, 26.1535040319316, 0.6024327934144221, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.7950138504155125, 0.5, 0.0, 0.0, 0.5, 0.6794586693276333, 0.7008109311381406, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.42608166], dtype=float32), 0.4161726]. 
=============================================
[2019-04-07 11:24:37,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:37,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:37,564] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run4
[2019-04-07 11:24:41,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:41,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:41,455] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run4
[2019-04-07 11:24:42,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:42,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:42,823] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run4
[2019-04-07 11:24:44,956] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9766821e-08 4.5240603e-07 9.3176822e-10 1.2574334e-05 2.0141393e-08
 9.9897885e-01 9.6018409e-04 4.7954156e-05], sum to 1.0000
[2019-04-07 11:24:44,956] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8135
[2019-04-07 11:24:45,021] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 39.5, 0.0, 0.0, 24.0, 23.49297332822312, -0.08797467824687877, 0.0, 1.0, 49454.5552046583], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4923000.0000, 
sim time next is 4924800.0000, 
raw observation next is [1.0, 40.0, 0.0, 0.0, 24.0, 23.52420782933448, -0.08733168742331221, 0.0, 1.0, 30157.499882454358], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.4, 0.0, 0.0, 0.5, 0.46035065244453993, 0.47088943752556256, 0.0, 1.0, 0.1436071422974017], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3016175], dtype=float32), -0.6490708]. 
=============================================
[2019-04-07 11:24:49,264] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.6940050e-09 5.1415647e-08 2.3456535e-11 1.1011639e-06 1.6350358e-08
 9.9978262e-01 2.1568792e-04 5.1408517e-07], sum to 1.0000
[2019-04-07 11:24:49,264] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3020
[2019-04-07 11:24:49,339] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 50.0, 0.0, 0.0, 24.0, 23.44768978946048, -0.1511922901658095, 0.0, 1.0, 17234.93656652364], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4948200.0000, 
sim time next is 4950000.0000, 
raw observation next is [-3.0, 50.0, 0.0, 0.0, 24.0, 23.31278970701014, -0.1687169028882538, 0.0, 1.0, 55883.37094201691], 
processed observation next is [1.0, 0.30434782608695654, 0.3795013850415513, 0.5, 0.0, 0.0, 0.5, 0.44273247558417833, 0.44376103237058206, 0.0, 1.0, 0.2661112902000805], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.07188713], dtype=float32), 1.9021502]. 
=============================================
[2019-04-07 11:24:49,348] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[60.025047]
 [60.378693]
 [60.2065  ]
 [59.928383]
 [60.056526]], R is [[60.82601929]
 [61.21775818]
 [61.60557938]
 [61.98952484]
 [62.36962891]].
[2019-04-07 11:24:51,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:51,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:51,095] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run4
[2019-04-07 11:24:52,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:52,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:52,446] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run4
[2019-04-07 11:24:52,659] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:52,659] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:52,662] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run4
[2019-04-07 11:24:53,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:53,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:53,266] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run4
[2019-04-07 11:24:53,609] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4279340e-11 7.2783429e-10 7.9778848e-14 2.2904837e-08 1.1608524e-10
 9.9986768e-01 1.3194175e-04 3.1910298e-07], sum to 1.0000
[2019-04-07 11:24:53,610] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4451
[2019-04-07 11:24:53,712] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 61.0, 143.5, 295.0, 24.0, 24.25678749909929, 0.06260807862181582, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 136800.0000, 
sim time next is 138600.0000, 
raw observation next is [-6.7, 61.0, 148.0, 106.0, 24.0, 24.1626087405617, 0.03331220044317897, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.2770083102493075, 0.61, 0.49333333333333335, 0.11712707182320442, 0.5, 0.5135507283801418, 0.511104066814393, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.14826453], dtype=float32), -1.1318922]. 
=============================================
[2019-04-07 11:24:53,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:53,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:53,855] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run4
[2019-04-07 11:24:53,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:53,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:53,914] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run4
[2019-04-07 11:24:54,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:54,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:54,923] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run4
[2019-04-07 11:24:55,727] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:55,727] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:55,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run4
[2019-04-07 11:24:57,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:57,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:57,275] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run4
[2019-04-07 11:24:58,016] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:58,016] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:58,018] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run4
[2019-04-07 11:24:58,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:58,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:58,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run4
[2019-04-07 11:24:58,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:58,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:58,650] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run4
[2019-04-07 11:24:58,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:24:58,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:24:58,803] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run4
[2019-04-07 11:25:20,795] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.8492213e-08 7.8466762e-08 7.4726586e-11 1.1346127e-06 3.4347917e-08
 9.9972850e-01 2.6701481e-04 3.2092146e-06], sum to 1.0000
[2019-04-07 11:25:20,796] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3967
[2019-04-07 11:25:20,875] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 24.0, 22.32076404809455, -0.3549962237800166, 0.0, 1.0, 45075.52045408633], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 183600.0000, 
sim time next is 185400.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 24.0, 22.22996072903443, -0.3805283462806794, 0.0, 1.0, 44928.98113527224], 
processed observation next is [1.0, 0.13043478260869565, 0.21606648199445982, 0.78, 0.0, 0.0, 0.5, 0.3524967274195359, 0.3731572179064402, 0.0, 1.0, 0.21394752921558208], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.94027025], dtype=float32), -0.74018246]. 
=============================================
[2019-04-07 11:25:40,815] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-07 11:25:40,815] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:25:40,815] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:25:40,833] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:25:40,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:25:40,834] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run8
[2019-04-07 11:25:40,861] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 11:25:40,861] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:25:40,863] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run8
[2019-04-07 11:25:40,881] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run8
[2019-04-07 11:27:26,130] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.2739 70888331.5517 169.5054
[2019-04-07 11:27:46,723] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.10190248], dtype=float32), 0.10375161]
[2019-04-07 11:27:46,723] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.5, 59.0, 221.0, 18.0, 24.0, 24.53948797679122, 0.1434231064112514, 1.0, 1.0, 0.0]
[2019-04-07 11:27:46,723] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 11:27:46,724] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [5.8204705e-11 4.3869948e-09 1.4124327e-12 9.9484829e-08 1.0169274e-09
 9.9988163e-01 1.1796200e-04 2.3944324e-07], sampled 0.32158226260662015
[2019-04-07 11:28:01,702] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.8546 79463814.5229 95.0531
[2019-04-07 11:28:09,311] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.2832 83804173.5951 33.3083
[2019-04-07 11:28:10,349] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 140000, evaluation results [140000.0, 2782.8545779888245, 79463814.52292724, 95.05306144070829, 2789.273879401112, 70888331.5516578, 169.50536880853943, 2784.2832285043078, 83804173.59513025, 33.30829457382416]
[2019-04-07 11:28:48,164] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5079371e-08 3.8102800e-07 4.1838658e-10 2.5002385e-06 1.0788794e-07
 9.9837118e-01 1.6193013e-03 6.5846698e-06], sum to 1.0000
[2019-04-07 11:28:48,164] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8535
[2019-04-07 11:28:48,491] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 57.0, 0.0, 0.0, 24.0, 23.0339079715505, -0.2263942137467721, 0.0, 1.0, 26101.84446937838], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 667800.0000, 
sim time next is 669600.0000, 
raw observation next is [-1.2, 57.0, 0.0, 0.0, 24.0, 22.9778079759016, -0.2317619867593579, 0.0, 1.0, 47632.84683696717], 
processed observation next is [0.0, 0.782608695652174, 0.42936288088642666, 0.57, 0.0, 0.0, 0.5, 0.4148173313251335, 0.42274600441354737, 0.0, 1.0, 0.22682308017603414], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1730407], dtype=float32), -0.19101529]. 
=============================================
[2019-04-07 11:29:14,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.1885969e-12 2.5577394e-09 5.6729800e-13 3.6891016e-08 9.4198305e-10
 9.9997473e-01 2.4556080e-05 6.6091570e-07], sum to 1.0000
[2019-04-07 11:29:14,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9723
[2019-04-07 11:29:14,213] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.2, 96.0, 0.0, 0.0, 24.0, 23.47756895588048, 0.0117459113855116, 0.0, 1.0, 39793.11133033759], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1486800.0000, 
sim time next is 1488600.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 24.0, 23.51178038574739, 0.01470209440169076, 0.0, 1.0, 31432.510792231482], 
processed observation next is [1.0, 0.21739130434782608, 0.5235457063711911, 0.96, 0.0, 0.0, 0.5, 0.4593150321456158, 0.5049006981338969, 0.0, 1.0, 0.1496786228201499], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2589818], dtype=float32), -1.7394918]. 
=============================================
[2019-04-07 11:29:16,502] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.71898284e-14 2.97998466e-11 2.25476094e-16 5.21731491e-10
 1.31571013e-12 9.99987602e-01 1.23955269e-05 1.28421735e-08], sum to 1.0000
[2019-04-07 11:29:16,504] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1177
[2019-04-07 11:29:16,628] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 100.0, 0.0, 0.0, 24.0, 22.73011724498593, -0.1575067648734629, 1.0, 1.0, 68320.98823345162], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 936000.0000, 
sim time next is 937800.0000, 
raw observation next is [5.0, 100.0, 0.0, 0.0, 24.0, 22.83459740710754, -0.09531690678848788, 0.0, 1.0, 128565.36855286657], 
processed observation next is [1.0, 0.8695652173913043, 0.6011080332409973, 1.0, 0.0, 0.0, 0.5, 0.40288311725896175, 0.4682276977371707, 0.0, 1.0, 0.612216040727936], 
reward next is 0.6735, 
noisyNet noise sample is [array([1.6214052], dtype=float32), 0.0008604074]. 
=============================================
[2019-04-07 11:29:24,631] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.9957983e-13 2.1080497e-11 1.1919348e-16 5.1416243e-10 4.0067702e-13
 9.9999928e-01 7.1308222e-07 7.7954271e-10], sum to 1.0000
[2019-04-07 11:29:24,631] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7187
[2019-04-07 11:29:24,653] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.1121501e-13 1.7475259e-10 1.8011178e-14 1.7354006e-08 1.7671533e-11
 9.9998808e-01 1.1759786e-05 1.2107489e-07], sum to 1.0000
[2019-04-07 11:29:24,653] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2885
[2019-04-07 11:29:24,718] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 24.0, 23.49652608631182, 0.06485692652543042, 0.0, 1.0, 11396.294387386455], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1380600.0000, 
sim time next is 1382400.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 24.0, 23.43672946815675, 0.06657635145173278, 0.0, 1.0, 56641.03253506609], 
processed observation next is [1.0, 0.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.5, 0.4530607890130624, 0.5221921171505776, 0.0, 1.0, 0.2697192025479338], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1460338], dtype=float32), -0.96934366]. 
=============================================
[2019-04-07 11:29:24,731] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.25, 93.5, 96.0, 0.0, 24.0, 24.14350892456662, 0.06073258223151867, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1427400.0000, 
sim time next is 1429200.0000, 
raw observation next is [0.5, 92.0, 93.0, 0.0, 24.0, 23.47587307060972, -0.002456704381510558, 1.0, 1.0, 26843.434755986993], 
processed observation next is [1.0, 0.5652173913043478, 0.4764542936288089, 0.92, 0.31, 0.0, 0.5, 0.4563227558841432, 0.4991810985394965, 1.0, 1.0, 0.12782587979041427], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4390161], dtype=float32), -0.30892494]. 
=============================================
[2019-04-07 11:29:33,216] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9939815e-11 3.9216991e-10 1.1349131e-13 8.0617447e-08 1.4579525e-09
 9.9995863e-01 4.0474326e-05 8.0539024e-07], sum to 1.0000
[2019-04-07 11:29:33,216] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1628
[2019-04-07 11:29:33,252] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 24.0, 23.82725699887907, 0.05631585970358837, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1472400.0000, 
sim time next is 1474200.0000, 
raw observation next is [1.9, 92.0, 0.0, 0.0, 24.0, 23.67871914153418, 0.03124834020339055, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.515235457063712, 0.92, 0.0, 0.0, 0.5, 0.4732265951278484, 0.5104161134011301, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.29958642], dtype=float32), 1.9501449]. 
=============================================
[2019-04-07 11:30:15,707] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0287773e-11 1.1279517e-10 3.9622572e-14 1.1809059e-08 1.0854256e-10
 9.9997270e-01 2.7266413e-05 9.4861665e-09], sum to 1.0000
[2019-04-07 11:30:15,707] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1898
[2019-04-07 11:30:15,738] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 55.0, 0.0, 0.0, 24.0, 23.67006825184838, -0.0129708958845025, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2323800.0000, 
sim time next is 2325600.0000, 
raw observation next is [-1.7, 56.0, 0.0, 0.0, 24.0, 23.50577696336126, -0.03184334695194659, 0.0, 1.0, 43820.65236498433], 
processed observation next is [1.0, 0.9565217391304348, 0.4155124653739613, 0.56, 0.0, 0.0, 0.5, 0.45881474694677166, 0.48938555101601783, 0.0, 1.0, 0.20866977316659205], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.353301], dtype=float32), -0.3824276]. 
=============================================
[2019-04-07 11:30:25,660] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8179242e-15 1.5487639e-12 1.2722591e-16 2.6341356e-11 1.4007370e-13
 9.9999952e-01 4.5225795e-07 8.9382191e-10], sum to 1.0000
[2019-04-07 11:30:25,661] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2438
[2019-04-07 11:30:25,731] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.4, 57.5, 109.0, 788.0, 24.0, 24.41810657620169, 0.1806729097256539, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2727000.0000, 
sim time next is 2728800.0000, 
raw observation next is [-4.8, 56.0, 105.5, 760.5, 24.0, 24.96112281906756, 0.2423863703864429, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3296398891966759, 0.56, 0.3516666666666667, 0.8403314917127072, 0.5, 0.5800935682556299, 0.580795456795481, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.559546], dtype=float32), 0.74064153]. 
=============================================
[2019-04-07 11:30:40,110] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.9279687e-11 7.1426296e-09 1.0293883e-12 1.1750566e-07 9.9663904e-09
 9.9991810e-01 8.1649465e-05 6.1866594e-08], sum to 1.0000
[2019-04-07 11:30:40,110] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4629
[2019-04-07 11:30:40,175] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 49.0, 0.0, 0.0, 24.0, 23.37729605097395, -0.199589585100304, 0.0, 1.0, 55059.0287396408], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2520000.0000, 
sim time next is 2521800.0000, 
raw observation next is [-2.0, 53.0, 0.0, 0.0, 24.0, 23.31347335838865, -0.1946680226622844, 0.0, 1.0, 49885.21368208135], 
processed observation next is [1.0, 0.17391304347826086, 0.40720221606648205, 0.53, 0.0, 0.0, 0.5, 0.4427894465323874, 0.4351106591125719, 0.0, 1.0, 0.23754863658133973], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.11402246], dtype=float32), 0.49718606]. 
=============================================
[2019-04-07 11:30:44,540] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-07 11:30:44,565] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:30:44,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:30:44,567] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run9
[2019-04-07 11:30:44,586] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:30:44,588] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:30:44,591] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run9
[2019-04-07 11:30:44,604] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 11:30:44,605] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:30:44,607] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run9
[2019-04-07 11:31:26,036] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.10615513], dtype=float32), 0.10897658]
[2019-04-07 11:31:26,037] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.1, 88.0, 0.0, 0.0, 24.0, 22.73698565607281, -0.04149020907115184, 1.0, 1.0, 101782.37808794303]
[2019-04-07 11:31:26,037] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 11:31:26,038] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.0270969e-12 1.1020898e-10 9.8436689e-15 2.6223428e-09 3.3928093e-11
 9.9999380e-01 6.2338167e-06 9.8754054e-09], sampled 0.9834702708678008
[2019-04-07 11:32:25,394] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 11:33:00,615] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.4863 79463814.5229 95.0531
[2019-04-07 11:33:07,314] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 11:33:08,349] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 160000, evaluation results [160000.0, 2782.4863413368403, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 11:33:13,569] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.6819864e-09 2.5446630e-07 3.7851451e-11 2.9096780e-06 6.3323611e-08
 9.9936587e-01 6.2168221e-04 9.2588853e-06], sum to 1.0000
[2019-04-07 11:33:13,569] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0231
[2019-04-07 11:33:13,701] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 24.0, 22.80984628504025, -0.246421312806239, 0.0, 1.0, 41141.02059032392], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3040200.0000, 
sim time next is 3042000.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 24.0, 22.74655898721855, -0.2608616401502608, 0.0, 1.0, 41157.08811715681], 
processed observation next is [0.0, 0.21739130434782608, 0.296398891966759, 0.77, 0.0, 0.0, 0.5, 0.39554658226821243, 0.4130461199499131, 0.0, 1.0, 0.1959861338912229], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.99850637], dtype=float32), 0.6381404]. 
=============================================
[2019-04-07 11:33:13,726] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[58.07026 ]
 [57.990326]
 [57.741   ]
 [57.577545]
 [58.38396 ]], R is [[58.64280319]
 [59.05637741]
 [59.46581268]
 [59.87115479]
 [60.27244568]].
[2019-04-07 11:33:15,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0518970e-14 6.6521363e-12 1.2291474e-15 2.1106463e-09 7.2833371e-11
 9.9999905e-01 9.5614041e-07 1.3082456e-08], sum to 1.0000
[2019-04-07 11:33:15,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9969
[2019-04-07 11:33:15,790] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 52.0, 86.0, 614.0, 24.0, 25.03449637919768, 0.2635085583028803, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2734200.0000, 
sim time next is 2736000.0000, 
raw observation next is [-3.0, 50.0, 70.0, 534.0, 24.0, 25.08630672957888, 0.08956933585928291, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.3795013850415513, 0.5, 0.23333333333333334, 0.5900552486187846, 0.5, 0.5905255607982399, 0.5298564452864276, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.20410556], dtype=float32), 0.7617191]. 
=============================================
[2019-04-07 11:33:15,795] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[89.43517 ]
 [89.250946]
 [88.95053 ]
 [88.532814]
 [88.18556 ]], R is [[89.13320923]
 [89.24187469]
 [89.34945679]
 [89.45596313]
 [89.56140137]].
[2019-04-07 11:33:53,245] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.1915908e-11 4.2631898e-11 5.6779867e-15 3.8840078e-09 1.5000555e-11
 9.9999774e-01 2.2407055e-06 3.7306216e-09], sum to 1.0000
[2019-04-07 11:33:53,245] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8124
[2019-04-07 11:33:53,442] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.0, 80.5, 86.0, 396.0, 24.0, 24.08007756870574, 0.07933496541458518, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3313800.0000, 
sim time next is 3315600.0000, 
raw observation next is [-9.0, 77.0, 95.0, 505.5, 24.0, 24.39042097126757, 0.1284478171720626, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.21329639889196678, 0.77, 0.31666666666666665, 0.5585635359116022, 0.5, 0.5325350809389642, 0.5428159390573543, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.68341804], dtype=float32), -0.17562231]. 
=============================================
[2019-04-07 11:34:07,650] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4698713e-12 8.0162699e-10 1.7733890e-13 2.3178785e-08 8.4995316e-11
 9.9999249e-01 7.4375830e-06 4.0460037e-08], sum to 1.0000
[2019-04-07 11:34:07,650] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1515
[2019-04-07 11:34:07,701] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 37.0, 0.0, 0.0, 24.0, 23.38524152206955, -0.02491077256068735, 0.0, 1.0, 83075.10204594785], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4057200.0000, 
sim time next is 4059000.0000, 
raw observation next is [-6.0, 37.0, 0.0, 0.0, 24.0, 23.46292959641927, -0.03505167248577363, 0.0, 1.0, 21925.364399927133], 
processed observation next is [1.0, 1.0, 0.296398891966759, 0.37, 0.0, 0.0, 0.5, 0.45524413303493905, 0.4883161091714088, 0.0, 1.0, 0.10440649714251016], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.0558267], dtype=float32), 0.57379866]. 
=============================================
[2019-04-07 11:34:07,715] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[76.393036]
 [75.70144 ]
 [76.28556 ]
 [76.79757 ]
 [78.22604 ]], R is [[76.17884064]
 [76.30717468]
 [76.54410553]
 [76.77866364]
 [77.01087952]].
[2019-04-07 11:34:44,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:34:44,634] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:34:44,635] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run5
[2019-04-07 11:34:48,794] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:34:48,795] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:34:48,810] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run5
[2019-04-07 11:34:50,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:34:50,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:34:50,367] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run5
[2019-04-07 11:34:51,409] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3185866e-15 1.2826171e-12 1.2261358e-17 4.3535869e-12 6.9088317e-14
 9.9999976e-01 2.7576360e-07 3.3868925e-12], sum to 1.0000
[2019-04-07 11:34:51,409] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3817
[2019-04-07 11:34:51,447] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 121.5, 0.0, 24.0, 24.10357313415678, 0.02889693002651241, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4712400.0000, 
sim time next is 4714200.0000, 
raw observation next is [1.5, 79.5, 135.0, 0.0, 24.0, 23.93862057837835, 0.01975403775979472, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5041551246537397, 0.795, 0.45, 0.0, 0.5, 0.49488504819819595, 0.5065846792532649, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5082497], dtype=float32), 1.5163343]. 
=============================================
[2019-04-07 11:34:57,911] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:34:57,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:34:57,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run5
[2019-04-07 11:35:00,688] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-07 11:35:00,692] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:35:00,693] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:35:00,694] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:35:00,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run10
[2019-04-07 11:35:00,725] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:35:00,725] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 11:35:00,736] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run10
[2019-04-07 11:35:00,737] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:35:00,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run10
[2019-04-07 11:36:03,235] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.1094401], dtype=float32), 0.11302868]
[2019-04-07 11:36:03,235] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [0.04863348700000003, 30.166539, 116.9866238, 862.7253357, 24.0, 23.04811014508664, -0.1768844775838295, 0.0, 1.0, 20409.44221203908]
[2019-04-07 11:36:03,235] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 11:36:03,236] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [3.7514443e-11 1.8031052e-09 1.0978565e-12 3.2335329e-08 6.1124245e-10
 9.9999154e-01 8.3765071e-06 7.1058018e-08], sampled 0.6584845535790803
[2019-04-07 11:36:53,312] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2788.9052 70927233.8163 166.2180
[2019-04-07 11:37:23,940] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.6292 79463814.5229 95.0531
[2019-04-07 11:37:33,244] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 11:37:34,282] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 180000, evaluation results [180000.0, 2782.629198479697, 79463814.52292724, 95.05306144070829, 2788.9051760082016, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 11:37:39,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:37:39,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:37:39,854] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run5
[2019-04-07 11:37:42,976] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:37:42,976] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:37:42,979] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run5
[2019-04-07 11:37:43,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:37:43,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:37:43,035] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run5
[2019-04-07 11:37:43,241] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:37:43,241] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:37:43,243] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run5
[2019-04-07 11:37:43,323] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:37:43,323] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:37:43,325] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run5
[2019-04-07 11:37:44,141] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:37:44,141] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:37:44,143] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run5
[2019-04-07 11:37:45,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:37:45,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:37:45,519] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run5
[2019-04-07 11:37:45,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:37:45,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:37:45,775] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run5
[2019-04-07 11:37:47,346] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:37:47,346] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:37:47,348] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run5
[2019-04-07 11:37:47,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:37:47,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:37:47,551] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run5
[2019-04-07 11:37:47,727] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:37:47,727] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:37:47,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run5
[2019-04-07 11:37:47,846] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:37:47,846] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:37:47,848] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run5
[2019-04-07 11:39:15,817] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2998663e-15 3.1314068e-13 1.8870890e-17 1.4817685e-11 4.7647270e-13
 1.0000000e+00 2.8674377e-08 1.0132290e-10], sum to 1.0000
[2019-04-07 11:39:15,818] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2650
[2019-04-07 11:39:15,886] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 24.0, 23.4335079854061, 0.0860163532119503, 0.0, 1.0, 60162.07599041669], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1378800.0000, 
sim time next is 1380600.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 24.0, 23.49652608631182, 0.06485692652543042, 0.0, 1.0, 11396.294387386455], 
processed observation next is [1.0, 1.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.5, 0.45804384052598507, 0.5216189755084768, 0.0, 1.0, 0.05426806851136407], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0840874], dtype=float32), 0.72053045]. 
=============================================
[2019-04-07 11:39:22,120] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0784531e-13 2.5812802e-10 1.4688878e-14 2.5433038e-09 3.1575621e-11
 9.9999690e-01 3.0637041e-06 6.1422387e-09], sum to 1.0000
[2019-04-07 11:39:22,121] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5008
[2019-04-07 11:39:22,167] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 71.0, 0.0, 0.0, 24.0, 22.67159406372972, -0.2977738578943607, 0.0, 1.0, 42483.32072613529], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 795600.0000, 
sim time next is 797400.0000, 
raw observation next is [-7.3, 71.0, 0.0, 0.0, 24.0, 22.51950450585866, -0.3225540759891898, 0.0, 1.0, 42742.88449407965], 
processed observation next is [1.0, 0.21739130434782608, 0.26038781163434904, 0.71, 0.0, 0.0, 0.5, 0.3766253754882216, 0.3924819746702701, 0.0, 1.0, 0.20353754520990308], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.53225535], dtype=float32), -0.22672038]. 
=============================================
[2019-04-07 11:39:28,536] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3229544e-13 1.5168177e-11 6.5352091e-16 6.3519939e-10 2.1475580e-12
 9.9999988e-01 1.7720144e-07 9.2757563e-10], sum to 1.0000
[2019-04-07 11:39:28,537] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3221
[2019-04-07 11:39:28,574] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 24.0, 23.25101253116775, -0.1514069037190368, 0.0, 1.0, 45173.72189828326], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 885600.0000, 
sim time next is 887400.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 24.0, 23.19858989429019, -0.1560094068806831, 0.0, 1.0, 39978.3287552522], 
processed observation next is [1.0, 0.2608695652173913, 0.46260387811634357, 0.72, 0.0, 0.0, 0.5, 0.43321582452418256, 0.44799686437310565, 0.0, 1.0, 0.19037299407262953], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.193754], dtype=float32), 2.4238715]. 
=============================================
[2019-04-07 11:39:35,115] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.2965066e-11 2.7094538e-09 3.1959665e-12 2.1977062e-08 1.0035301e-09
 9.9999797e-01 1.7960915e-06 2.6670918e-07], sum to 1.0000
[2019-04-07 11:39:35,116] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5381
[2019-04-07 11:39:35,124] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [16.6, 75.0, 0.0, 0.0, 24.0, 23.0878431384686, 0.0145436986425681, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1206000.0000, 
sim time next is 1207800.0000, 
raw observation next is [16.35, 76.5, 0.0, 0.0, 24.0, 23.03955161474578, 0.00529849782492008, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 1.0, 0.9155124653739612, 0.765, 0.0, 0.0, 0.5, 0.4199626345621483, 0.50176616594164, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.7080424], dtype=float32), -0.5361407]. 
=============================================
[2019-04-07 11:39:38,668] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7294783e-12 1.2253229e-10 2.5228937e-14 3.4755347e-09 1.2157225e-10
 9.9999869e-01 1.2681277e-06 2.9433873e-09], sum to 1.0000
[2019-04-07 11:39:38,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4686
[2019-04-07 11:39:38,715] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.55, 78.0, 0.0, 0.0, 24.0, 23.84684638893285, 0.197030920981495, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1132200.0000, 
sim time next is 1134000.0000, 
raw observation next is [11.1, 77.0, 0.0, 0.0, 24.0, 23.79556541978057, 0.1762687790304919, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.7700831024930749, 0.77, 0.0, 0.0, 0.5, 0.4829637849817141, 0.5587562596768306, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.80319846], dtype=float32), 0.4339045]. 
=============================================
[2019-04-07 11:39:38,721] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[76.273636]
 [79.10687 ]
 [83.33709 ]
 [85.16137 ]
 [87.35965 ]], R is [[74.09164429]
 [74.3507309 ]
 [74.60722351]
 [74.71914673]
 [74.97195435]].
[2019-04-07 11:39:41,748] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.0130714e-15 2.0832045e-12 1.2378807e-17 1.8473998e-11 2.2039009e-13
 1.0000000e+00 4.6533255e-08 3.8259781e-11], sum to 1.0000
[2019-04-07 11:39:41,749] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0705
[2019-04-07 11:39:41,956] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 100.0, 9.0, 0.0, 24.0, 23.4460059981482, -0.01539189130537208, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1411200.0000, 
sim time next is 1413000.0000, 
raw observation next is [-0.6, 100.0, 18.0, 0.0, 24.0, 23.8561069348982, 0.07484587918608497, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.44598337950138506, 1.0, 0.06, 0.0, 0.5, 0.4880089112415167, 0.5249486263953617, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.23134215], dtype=float32), -1.0516262]. 
=============================================
[2019-04-07 11:39:41,960] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[88.0518  ]
 [86.022194]
 [86.350204]
 [86.214714]
 [85.51816 ]], R is [[89.43579102]
 [89.54143524]
 [89.64601898]
 [89.7495575 ]
 [89.83366394]].
[2019-04-07 11:39:45,702] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2590971e-14 9.3593590e-13 2.8241379e-17 1.3188986e-10 2.5283482e-12
 1.0000000e+00 4.6155257e-09 1.0656714e-10], sum to 1.0000
[2019-04-07 11:39:45,704] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8841
[2019-04-07 11:39:45,794] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.9, 92.0, 0.0, 0.0, 24.0, 23.58047851845539, 0.123432919502212, 0.0, 1.0, 31107.671156484837], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1312200.0000, 
sim time next is 1314000.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 24.0, 23.59543107418499, 0.1349201538127369, 0.0, 1.0, 26593.224101621327], 
processed observation next is [1.0, 0.21739130434782608, 0.5069252077562327, 0.92, 0.0, 0.0, 0.5, 0.4662859228487492, 0.5449733846042456, 0.0, 1.0, 0.12663440048391109], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.00460712], dtype=float32), 0.5660076]. 
=============================================
[2019-04-07 11:39:45,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[89.03729 ]
 [89.07612 ]
 [88.7731  ]
 [88.704575]
 [88.056786]], R is [[89.07810974]
 [89.18733215]
 [89.29545593]
 [89.40250397]
 [89.50847626]].
[2019-04-07 11:39:53,675] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6671167e-13 4.3022101e-12 4.1124836e-17 1.1488775e-09 3.5540535e-12
 9.9999988e-01 8.0255774e-08 3.5141003e-09], sum to 1.0000
[2019-04-07 11:39:53,676] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6958
[2019-04-07 11:39:53,731] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.7, 82.5, 0.0, 0.0, 24.0, 23.6534160971379, 0.1188763796276876, 0.0, 1.0, 50200.796774438], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1564200.0000, 
sim time next is 1566000.0000, 
raw observation next is [4.4, 86.0, 0.0, 0.0, 24.0, 23.77742234946776, 0.09459578222548515, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.5844875346260389, 0.86, 0.0, 0.0, 0.5, 0.4814518624556466, 0.5315319274084951, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9034948], dtype=float32), 2.3016977]. 
=============================================
[2019-04-07 11:39:53,780] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[88.31183 ]
 [89.360756]
 [91.02498 ]
 [92.363716]
 [94.529724]], R is [[87.25582886]
 [87.38327026]
 [87.50943756]
 [87.63434601]
 [87.75800323]].
[2019-04-07 11:39:58,493] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.4438109e-16 2.8573682e-13 7.5151205e-17 4.4645315e-11 2.8270900e-14
 9.9999988e-01 1.6624737e-07 6.9328945e-11], sum to 1.0000
[2019-04-07 11:39:58,493] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5420
[2019-04-07 11:39:58,590] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.8, 79.0, 37.0, 35.0, 24.0, 23.78439324195352, 0.0900395925626497, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1585800.0000, 
sim time next is 1587600.0000, 
raw observation next is [6.6, 76.0, 76.0, 85.5, 24.0, 24.10894674592164, 0.1240426264540922, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6454293628808865, 0.76, 0.25333333333333335, 0.09447513812154697, 0.5, 0.5090788954934699, 0.541347542151364, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.366347], dtype=float32), -0.08434928]. 
=============================================
[2019-04-07 11:39:58,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8348231e-16 3.1209424e-13 1.1958922e-18 4.5495552e-12 2.9000936e-15
 1.0000000e+00 8.1659017e-09 1.1284833e-11], sum to 1.0000
[2019-04-07 11:39:58,863] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0234
[2019-04-07 11:39:58,909] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.55, 64.5, 200.0, 88.0, 24.0, 24.95292014975103, 0.2826435163520918, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1593000.0000, 
sim time next is 1594800.0000, 
raw observation next is [9.4, 61.0, 208.0, 168.5, 24.0, 24.99984499040062, 0.316233839204403, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.7229916897506927, 0.61, 0.6933333333333334, 0.1861878453038674, 0.5, 0.5833204158667185, 0.605411279734801, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0657345], dtype=float32), -0.1491379]. 
=============================================
[2019-04-07 11:39:59,314] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.4587260e-15 2.9923010e-15 1.0513679e-20 3.6335715e-12 1.7560592e-15
 1.0000000e+00 6.2436956e-10 4.6135118e-12], sum to 1.0000
[2019-04-07 11:39:59,332] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6868
[2019-04-07 11:39:59,351] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.55, 50.0, 78.0, 0.0, 24.0, 25.45071355040008, 0.4049172099433776, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1611000.0000, 
sim time next is 1612800.0000, 
raw observation next is [13.3, 51.0, 64.0, 18.5, 24.0, 25.64017510440906, 0.4318469442563406, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.8310249307479226, 0.51, 0.21333333333333335, 0.020441988950276244, 0.5, 0.636681258700755, 0.6439489814187802, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2981431], dtype=float32), -0.17939138]. 
=============================================
[2019-04-07 11:40:05,843] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8582079e-14 3.2971016e-13 1.7315713e-17 2.1710222e-11 5.1027173e-13
 1.0000000e+00 4.9791094e-08 3.3419694e-11], sum to 1.0000
[2019-04-07 11:40:05,844] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6665
[2019-04-07 11:40:05,883] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 84.0, 0.0, 0.0, 24.0, 23.52185488338913, -0.03422053534332296, 0.0, 1.0, 11756.42799378083], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2064600.0000, 
sim time next is 2066400.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 24.0, 23.38194438091849, -0.02832878907878534, 0.0, 1.0, 77008.84729064966], 
processed observation next is [1.0, 0.9565217391304348, 0.3545706371191136, 0.82, 0.0, 0.0, 0.5, 0.44849536507654086, 0.4905570703070716, 0.0, 1.0, 0.36670879662214123], 
reward next is 0.9190, 
noisyNet noise sample is [array([-0.72482276], dtype=float32), 0.07372957]. 
=============================================
[2019-04-07 11:40:23,588] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-07 11:40:23,589] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:40:23,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:40:23,593] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:40:23,594] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:40:23,596] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run11
[2019-04-07 11:40:23,609] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 11:40:23,643] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:40:23,645] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run11
[2019-04-07 11:40:23,643] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run11
[2019-04-07 11:42:11,565] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.3337 70927233.8163 166.2180
[2019-04-07 11:42:41,010] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 11:42:49,079] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 11:42:50,119] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 200000, evaluation results [200000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.333747436773, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 11:43:25,328] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9997536e-11 6.6753458e-10 1.5342865e-13 3.1692202e-09 1.6206526e-10
 9.9999821e-01 1.7658077e-06 2.6946132e-08], sum to 1.0000
[2019-04-07 11:43:25,328] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3184
[2019-04-07 11:43:25,430] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.1, 67.0, 0.0, 0.0, 24.0, 22.9529455269741, -0.1988154919649829, 0.0, 1.0, 42008.078437491], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2352600.0000, 
sim time next is 2354400.0000, 
raw observation next is [-2.8, 65.0, 0.0, 0.0, 24.0, 22.90510373190674, -0.2052380926932525, 0.0, 1.0, 42117.03361158205], 
processed observation next is [0.0, 0.2608695652173913, 0.38504155124653744, 0.65, 0.0, 0.0, 0.5, 0.4087586443255615, 0.4315873024355825, 0.0, 1.0, 0.20055730291229545], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8190443], dtype=float32), 0.7473075]. 
=============================================
[2019-04-07 11:43:26,639] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.22787890e-14 8.24155522e-13 8.34537411e-16 1.97196426e-10
 7.31025321e-13 1.00000000e+00 4.90957888e-08 1.04798566e-10], sum to 1.0000
[2019-04-07 11:43:26,639] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6353
[2019-04-07 11:43:26,797] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 57.5, 0.0, 0.0, 24.0, 23.39656957073589, -0.08210968124495428, 0.0, 1.0, 68121.67849410117], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2327400.0000, 
sim time next is 2329200.0000, 
raw observation next is [-2.3, 59.0, 0.0, 0.0, 24.0, 23.33758607788711, -0.08221827061733565, 0.0, 1.0, 55307.75234768897], 
processed observation next is [1.0, 1.0, 0.3988919667590028, 0.59, 0.0, 0.0, 0.5, 0.4447988398239258, 0.4725939097942215, 0.0, 1.0, 0.26337024927470937], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3525647], dtype=float32), -0.08490209]. 
=============================================
[2019-04-07 11:44:35,412] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7098483e-12 8.5882542e-12 1.6177383e-15 8.9376057e-10 8.5472688e-12
 9.9999952e-01 4.3742267e-07 9.2645608e-10], sum to 1.0000
[2019-04-07 11:44:35,413] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6085
[2019-04-07 11:44:35,533] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 24.0, 23.55895990808847, 0.01634602596011092, 0.0, 1.0, 28048.37105189668], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4147200.0000, 
sim time next is 4149000.0000, 
raw observation next is [-1.0, 40.5, 0.0, 0.0, 24.0, 23.50813627772776, 0.01148645493347068, 0.0, 1.0, 48038.63227495891], 
processed observation next is [0.0, 0.0, 0.4349030470914128, 0.405, 0.0, 0.0, 0.5, 0.45901135647731345, 0.5038288183111569, 0.0, 1.0, 0.22875539178551862], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8302381], dtype=float32), 1.0326681]. 
=============================================
[2019-04-07 11:44:35,551] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[81.99692 ]
 [86.710464]
 [86.93604 ]
 [86.23551 ]
 [86.8766  ]], R is [[78.80071259]
 [79.01270294]
 [79.22257996]
 [79.19132996]
 [79.39941406]].
[2019-04-07 11:44:37,067] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0747473e-15 8.1052748e-13 1.2971839e-17 1.0013462e-10 3.3046929e-14
 1.0000000e+00 2.6052789e-09 3.3411791e-11], sum to 1.0000
[2019-04-07 11:44:37,067] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5684
[2019-04-07 11:44:37,126] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 78.0, 0.0, 0.0, 24.0, 24.0415160044497, 0.1580811775646742, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3535200.0000, 
sim time next is 3537000.0000, 
raw observation next is [-1.0, 72.0, 0.0, 0.0, 24.0, 23.76922733751539, 0.03011184072505957, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4349030470914128, 0.72, 0.0, 0.0, 0.5, 0.48076894479294907, 0.5100372802416865, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9992831], dtype=float32), 1.1254405]. 
=============================================
[2019-04-07 11:44:37,149] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[94.04607 ]
 [93.812645]
 [94.3337  ]
 [95.466255]
 [95.75247 ]], R is [[94.12892914]
 [94.18763733]
 [94.24575806]
 [94.2660141 ]
 [93.92615509]].
[2019-04-07 11:44:57,091] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7482615e-12 5.5948763e-11 3.3977770e-15 5.5784799e-10 3.3761750e-11
 9.9999976e-01 2.4479462e-07 8.1023526e-09], sum to 1.0000
[2019-04-07 11:44:57,091] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1381
[2019-04-07 11:44:57,153] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.0, 63.0, 0.0, 0.0, 24.0, 22.9169200914617, -0.1692924089380843, 0.0, 1.0, 44922.84719724075], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3985200.0000, 
sim time next is 3987000.0000, 
raw observation next is [-12.0, 63.0, 0.0, 0.0, 24.0, 22.9709018750254, -0.1841881567170127, 0.0, 1.0, 44734.57644045848], 
processed observation next is [1.0, 0.13043478260869565, 0.13019390581717452, 0.63, 0.0, 0.0, 0.5, 0.4142418229187834, 0.43860394776099576, 0.0, 1.0, 0.21302179257361178], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.39168254], dtype=float32), 1.4211423]. 
=============================================
[2019-04-07 11:44:57,196] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[76.57716]
 [77.18478]
 [78.596  ]
 [80.34849]
 [81.23537]], R is [[76.81096649]
 [77.04285431]
 [77.27242279]
 [77.49970245]
 [77.72470856]].
[2019-04-07 11:45:02,884] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-07 11:45:02,888] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:45:02,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:45:02,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run12
[2019-04-07 11:45:02,905] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:45:02,908] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:45:02,909] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 11:45:02,909] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:45:02,910] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run12
[2019-04-07 11:45:02,933] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run12
[2019-04-07 11:45:03,253] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:45:03,254] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:45:03,282] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run6
[2019-04-07 11:46:42,658] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.4766 70927233.8163 166.2180
[2019-04-07 11:47:16,055] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.4863 79463814.5229 95.0531
[2019-04-07 11:47:24,210] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.5330 83805026.4189 32.8860
[2019-04-07 11:47:25,247] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 220000, evaluation results [220000.0, 2782.4863413368403, 79463814.52292724, 95.05306144070829, 2789.47660457963, 70927233.8162715, 166.21801628696863, 2784.5329620425596, 83805026.41892925, 32.88598103848735]
[2019-04-07 11:47:49,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:47:49,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:47:49,632] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run6
[2019-04-07 11:47:57,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:47:57,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:47:57,650] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run6
[2019-04-07 11:47:58,534] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:47:58,534] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:47:58,559] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run6
[2019-04-07 11:48:23,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:48:23,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:48:23,616] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run6
[2019-04-07 11:48:25,172] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:48:25,172] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:48:25,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run6
[2019-04-07 11:48:28,428] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:48:28,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:48:28,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run6
[2019-04-07 11:48:29,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:48:29,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:48:29,111] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run6
[2019-04-07 11:48:30,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:48:30,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:48:30,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run6
[2019-04-07 11:48:30,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:48:30,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:48:30,900] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run6
[2019-04-07 11:48:31,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:48:31,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:48:31,094] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run6
[2019-04-07 11:48:31,975] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:48:31,975] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:48:31,979] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run6
[2019-04-07 11:48:32,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:48:32,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:48:32,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run6
[2019-04-07 11:48:32,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:48:32,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:48:32,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run6
[2019-04-07 11:48:34,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:48:34,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:48:34,184] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run6
[2019-04-07 11:48:35,883] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:48:35,884] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:48:35,887] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run6
[2019-04-07 11:48:36,273] A3C_AGENT_WORKER-Thread-3 INFO:Local step 14500, global step 227390: loss 16.4665
[2019-04-07 11:48:36,274] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 14500, global step 227390: learning rate 0.0000
[2019-04-07 11:48:49,102] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3635431e-13 3.4481865e-11 6.6151706e-16 4.9433824e-10 9.4547634e-12
 1.0000000e+00 2.8043011e-08 3.5028116e-09], sum to 1.0000
[2019-04-07 11:48:49,102] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3273
[2019-04-07 11:48:49,195] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.7, 89.0, 0.0, 0.0, 24.0, 23.18787988676286, -0.09648446149017476, 0.0, 1.0, 55590.12784409861], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 72000.0000, 
sim time next is 73800.0000, 
raw observation next is [2.15, 87.0, 0.0, 0.0, 24.0, 23.2941165069031, -0.08596509248126638, 0.0, 1.0, 43093.48934102088], 
processed observation next is [0.0, 0.8695652173913043, 0.5221606648199446, 0.87, 0.0, 0.0, 0.5, 0.44117637557525846, 0.4713449691729112, 0.0, 1.0, 0.20520709210009944], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2236396], dtype=float32), 0.13969395]. 
=============================================
[2019-04-07 11:49:03,090] A3C_AGENT_WORKER-Thread-18 INFO:Local step 14500, global step 229500: loss 18.4424
[2019-04-07 11:49:03,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 14500, global step 229500: learning rate 0.0000
[2019-04-07 11:49:11,343] A3C_AGENT_WORKER-Thread-19 INFO:Local step 14500, global step 230445: loss 17.7977
[2019-04-07 11:49:11,344] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 14500, global step 230445: learning rate 0.0000
[2019-04-07 11:49:13,184] A3C_AGENT_WORKER-Thread-14 INFO:Local step 14500, global step 230667: loss 17.0686
[2019-04-07 11:49:13,184] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 14500, global step 230667: learning rate 0.0000
[2019-04-07 11:49:15,698] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5506157e-15 7.8209134e-14 2.2097070e-19 6.8694469e-12 5.5836009e-14
 1.0000000e+00 6.0915384e-10 9.3836553e-12], sum to 1.0000
[2019-04-07 11:49:15,698] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8895
[2019-04-07 11:49:15,886] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.0, 60.0, 0.0, 0.0, 24.0, 23.90391967683573, -0.0727189760550133, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 325800.0000, 
sim time next is 327600.0000, 
raw observation next is [-12.3, 63.0, 0.0, 0.0, 24.0, 23.53817242865539, -0.05492541571601447, 1.0, 1.0, 117325.07598684635], 
processed observation next is [1.0, 0.8260869565217391, 0.12188365650969527, 0.63, 0.0, 0.0, 0.5, 0.4615143690546158, 0.48169152809466187, 1.0, 1.0, 0.5586908380326017], 
reward next is 0.7270, 
noisyNet noise sample is [array([1.7874267], dtype=float32), -1.4634687]. 
=============================================
[2019-04-07 11:49:24,200] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15000, global step 231854: loss 41.4101
[2019-04-07 11:49:24,200] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 15000, global step 231854: learning rate 0.0000
[2019-04-07 11:49:25,570] A3C_AGENT_WORKER-Thread-6 INFO:Local step 14500, global step 232032: loss 17.2212
[2019-04-07 11:49:25,570] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 14500, global step 232032: learning rate 0.0000
[2019-04-07 11:49:29,329] A3C_AGENT_WORKER-Thread-10 INFO:Local step 14500, global step 232528: loss 16.5206
[2019-04-07 11:49:29,330] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 14500, global step 232528: learning rate 0.0000
[2019-04-07 11:49:29,707] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7467914e-15 4.1857581e-12 2.1722900e-18 1.5068528e-10 6.8018676e-13
 9.9999988e-01 1.4670188e-07 1.8969545e-10], sum to 1.0000
[2019-04-07 11:49:29,707] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3017
[2019-04-07 11:49:29,771] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 34.0, 38.0, 0.0, 24.0, 23.33785756780119, -0.200341587335089, 1.0, 1.0, 33155.78388715678], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 489600.0000, 
sim time next is 491400.0000, 
raw observation next is [1.1, 38.5, 20.0, 0.0, 24.0, 23.68904657348991, -0.1825798815829008, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.49307479224376743, 0.385, 0.06666666666666667, 0.0, 0.5, 0.4740872144574926, 0.4391400394723664, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2992687], dtype=float32), -0.14268576]. 
=============================================
[2019-04-07 11:49:31,926] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9832639e-14 3.2458936e-12 2.9781901e-16 2.0188887e-11 6.6623194e-14
 1.0000000e+00 9.0527879e-09 1.1089094e-10], sum to 1.0000
[2019-04-07 11:49:31,926] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2520
[2019-04-07 11:49:32,052] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 83.0, 83.0, 138.0, 24.0, 23.02532461567612, -0.1517494678702062, 0.0, 1.0, 6492.1976095057435], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 558000.0000, 
sim time next is 559800.0000, 
raw observation next is [-0.7, 82.0, 89.0, 135.0, 24.0, 23.00637868253989, -0.1571241932313671, 0.0, 1.0, 33341.06517302192], 
processed observation next is [0.0, 0.4782608695652174, 0.443213296398892, 0.82, 0.2966666666666667, 0.14917127071823205, 0.5, 0.41719822354499075, 0.44762526892287763, 0.0, 1.0, 0.15876697701439008], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.75014985], dtype=float32), -0.5932614]. 
=============================================
[2019-04-07 11:49:32,988] A3C_AGENT_WORKER-Thread-12 INFO:Local step 14500, global step 233025: loss 17.5734
[2019-04-07 11:49:32,990] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 14500, global step 233025: learning rate 0.0000
[2019-04-07 11:49:34,038] A3C_AGENT_WORKER-Thread-16 INFO:Local step 14500, global step 233172: loss 18.4947
[2019-04-07 11:49:34,040] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 14500, global step 233172: learning rate 0.0000
[2019-04-07 11:49:34,942] A3C_AGENT_WORKER-Thread-2 INFO:Local step 14500, global step 233304: loss 17.1962
[2019-04-07 11:49:34,942] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 14500, global step 233304: learning rate 0.0000
[2019-04-07 11:49:35,835] A3C_AGENT_WORKER-Thread-13 INFO:Local step 14500, global step 233423: loss 18.3218
[2019-04-07 11:49:35,837] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 14500, global step 233423: learning rate 0.0000
[2019-04-07 11:49:36,406] A3C_AGENT_WORKER-Thread-11 INFO:Local step 14500, global step 233502: loss 17.8138
[2019-04-07 11:49:36,406] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 14500, global step 233502: learning rate 0.0000
[2019-04-07 11:49:37,168] A3C_AGENT_WORKER-Thread-5 INFO:Local step 14500, global step 233600: loss 17.1261
[2019-04-07 11:49:37,171] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 14500, global step 233600: learning rate 0.0000
[2019-04-07 11:49:37,830] A3C_AGENT_WORKER-Thread-4 INFO:Local step 14500, global step 233705: loss 18.6022
[2019-04-07 11:49:37,831] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 14500, global step 233705: learning rate 0.0000
[2019-04-07 11:49:37,987] A3C_AGENT_WORKER-Thread-20 INFO:Local step 14500, global step 233728: loss 17.2376
[2019-04-07 11:49:38,004] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 14500, global step 233728: learning rate 0.0000
[2019-04-07 11:49:38,191] A3C_AGENT_WORKER-Thread-15 INFO:Local step 14500, global step 233764: loss 17.4000
[2019-04-07 11:49:38,191] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 14500, global step 233764: learning rate 0.0000
[2019-04-07 11:49:40,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8918779e-14 1.6949453e-12 1.7527380e-17 7.1822936e-11 1.4787290e-13
 1.0000000e+00 1.8971919e-08 1.3291465e-10], sum to 1.0000
[2019-04-07 11:49:40,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9913
[2019-04-07 11:49:40,116] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.45, 65.5, 0.0, 0.0, 24.0, 23.19855953815041, -0.1327071903705387, 0.0, 1.0, 44696.11064118278], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 772200.0000, 
sim time next is 774000.0000, 
raw observation next is [-6.7, 67.0, 0.0, 0.0, 24.0, 23.13099031041837, -0.1474002184267185, 0.0, 1.0, 44168.583821340355], 
processed observation next is [1.0, 1.0, 0.2770083102493075, 0.67, 0.0, 0.0, 0.5, 0.4275825258681974, 0.4508665938577605, 0.0, 1.0, 0.21032658962543027], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8438032], dtype=float32), -0.5809985]. 
=============================================
[2019-04-07 11:49:40,119] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[93.17823 ]
 [93.77837 ]
 [95.01551 ]
 [95.52629 ]
 [96.795525]], R is [[92.96569824]
 [93.03604126]
 [93.10568237]
 [93.17462921]
 [93.24288177]].
[2019-04-07 11:49:40,413] A3C_AGENT_WORKER-Thread-17 INFO:Local step 14500, global step 234082: loss 17.9955
[2019-04-07 11:49:40,414] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 14500, global step 234082: learning rate 0.0000
[2019-04-07 11:49:48,557] A3C_AGENT_WORKER-Thread-18 INFO:Local step 15000, global step 235337: loss 41.4702
[2019-04-07 11:49:48,557] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 15000, global step 235337: learning rate 0.0000
[2019-04-07 11:49:56,000] A3C_AGENT_WORKER-Thread-19 INFO:Local step 15000, global step 236456: loss 40.7983
[2019-04-07 11:49:56,021] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 15000, global step 236456: learning rate 0.0000
[2019-04-07 11:49:58,832] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15000, global step 237044: loss 39.4805
[2019-04-07 11:49:58,833] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 15000, global step 237044: learning rate 0.0000
[2019-04-07 11:50:08,128] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15000, global step 239650: loss 41.2610
[2019-04-07 11:50:08,129] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 15000, global step 239650: learning rate 0.0000
[2019-04-07 11:50:09,721] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-07 11:50:09,721] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:50:09,722] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:50:09,724] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run13
[2019-04-07 11:50:09,738] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:50:09,742] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 11:50:09,743] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:50:09,743] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:50:09,753] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run13
[2019-04-07 11:50:09,771] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run13
[2019-04-07 11:50:22,642] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.11590585], dtype=float32), 0.1219483]
[2019-04-07 11:50:22,642] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-11.15, 68.5, 0.0, 0.0, 24.0, 21.88680674104263, -0.4480505105183565, 0.0, 1.0, 48462.61455799263]
[2019-04-07 11:50:22,642] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 11:50:22,643] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [8.9204078e-12 3.1439884e-10 9.2665696e-14 5.0832463e-09 1.6128060e-10
 9.9999905e-01 9.5206491e-07 1.3196486e-08], sampled 0.5530140464311973
[2019-04-07 11:51:08,892] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.11590585], dtype=float32), 0.1219483]
[2019-04-07 11:51:08,892] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-2.3, 63.5, 0.0, 0.0, 24.0, 23.37369396525079, -0.1030718567552442, 0.0, 1.0, 37822.204799585794]
[2019-04-07 11:51:08,892] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 11:51:08,893] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.2695011e-13 2.4088063e-11 2.7827542e-15 6.1596644e-10 9.5811857e-12
 9.9999988e-01 1.7615342e-07 1.5735104e-09], sampled 0.38218664614060316
[2019-04-07 11:51:49,063] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 11:52:23,922] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.6999 79463814.5229 95.0531
[2019-04-07 11:52:31,181] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.3901 83805026.4189 32.8860
[2019-04-07 11:52:32,219] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 240000, evaluation results [240000.0, 2782.699874979815, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.390104899702, 83805026.41892925, 32.88598103848735]
[2019-04-07 11:52:34,399] A3C_AGENT_WORKER-Thread-10 INFO:Local step 15000, global step 240226: loss 40.4518
[2019-04-07 11:52:34,400] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 15000, global step 240226: learning rate 0.0000
[2019-04-07 11:52:41,021] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15000, global step 240934: loss 40.4856
[2019-04-07 11:52:41,023] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 15000, global step 240934: learning rate 0.0000
[2019-04-07 11:52:42,334] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15000, global step 241045: loss 40.2891
[2019-04-07 11:52:42,335] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 15000, global step 241045: learning rate 0.0000
[2019-04-07 11:52:45,812] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15000, global step 241393: loss 39.4543
[2019-04-07 11:52:45,857] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 15000, global step 241393: learning rate 0.0000
[2019-04-07 11:52:46,083] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15000, global step 241409: loss 40.3479
[2019-04-07 11:52:46,084] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 15000, global step 241409: learning rate 0.0000
[2019-04-07 11:52:47,232] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15500, global step 241492: loss 1.6827
[2019-04-07 11:52:47,232] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 15500, global step 241492: learning rate 0.0000
[2019-04-07 11:52:47,323] A3C_AGENT_WORKER-Thread-11 INFO:Local step 15000, global step 241500: loss 40.0769
[2019-04-07 11:52:47,327] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 15000, global step 241500: learning rate 0.0000
[2019-04-07 11:52:48,645] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15000, global step 241628: loss 38.6663
[2019-04-07 11:52:48,647] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 15000, global step 241628: learning rate 0.0000
[2019-04-07 11:52:49,384] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15000, global step 241682: loss 40.2222
[2019-04-07 11:52:49,384] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 15000, global step 241682: learning rate 0.0000
[2019-04-07 11:52:49,778] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0210784e-14 7.8283051e-13 1.5388464e-17 2.7481116e-11 4.1404698e-14
 1.0000000e+00 2.6003293e-09 4.9149187e-12], sum to 1.0000
[2019-04-07 11:52:49,779] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9192
[2019-04-07 11:52:49,887] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.2, 91.0, 0.0, 0.0, 24.0, 23.43792590604729, 0.006463962865032665, 0.0, 1.0, 38784.5105817791], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1735200.0000, 
sim time next is 1737000.0000, 
raw observation next is [0.1, 91.0, 0.0, 0.0, 24.0, 23.43257574929972, 0.009068318565211711, 0.0, 1.0, 45040.82411364272], 
processed observation next is [0.0, 0.08695652173913043, 0.4653739612188367, 0.91, 0.0, 0.0, 0.5, 0.4527146457749766, 0.5030227728550706, 0.0, 1.0, 0.21448011482687007], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7801036], dtype=float32), -0.10993297]. 
=============================================
[2019-04-07 11:52:49,904] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[87.897   ]
 [91.74732 ]
 [93.932816]
 [96.374695]
 [99.84565 ]], R is [[85.2453537 ]
 [85.39289856]
 [85.53897095]
 [85.68357849]
 [85.82674408]].
[2019-04-07 11:52:50,392] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15000, global step 241772: loss 40.6136
[2019-04-07 11:52:50,406] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 15000, global step 241772: learning rate 0.0000
[2019-04-07 11:52:50,845] A3C_AGENT_WORKER-Thread-20 INFO:Local step 15000, global step 241794: loss 39.1749
[2019-04-07 11:52:50,857] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 15000, global step 241794: learning rate 0.0000
[2019-04-07 11:52:56,575] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15000, global step 242378: loss 39.4018
[2019-04-07 11:52:56,575] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 15000, global step 242378: learning rate 0.0000
[2019-04-07 11:53:04,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5547222e-19 2.4010909e-15 4.5607883e-20 1.6291604e-13 3.8498029e-16
 1.0000000e+00 2.2575513e-09 2.9107352e-14], sum to 1.0000
[2019-04-07 11:53:04,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4445
[2019-04-07 11:53:04,442] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 24.0, 23.2734976500363, 0.04253672442824993, 1.0, 1.0, 40650.958148603866], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1710000.0000, 
sim time next is 1711800.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 24.0, 23.44085565046959, 0.03388537478527513, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.88, 0.0, 0.0, 0.5, 0.4534046375391325, 0.5112951249284251, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.01647], dtype=float32), 1.3016727]. 
=============================================
[2019-04-07 11:53:19,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.1814603e-12 9.2773389e-10 6.1479311e-14 4.5042099e-09 4.6351714e-11
 9.9999881e-01 1.1909563e-06 1.0743593e-08], sum to 1.0000
[2019-04-07 11:53:19,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4953
[2019-04-07 11:53:19,948] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 78.0, 27.0, 0.0, 24.0, 22.47101116445162, -0.2010821323696802, 0.0, 1.0, 151175.32087082686], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1845000.0000, 
sim time next is 1846800.0000, 
raw observation next is [-6.7, 78.0, 87.5, 47.0, 24.0, 23.58377210967739, -0.1086152674523499, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.2770083102493075, 0.78, 0.2916666666666667, 0.051933701657458566, 0.5, 0.46531434247311587, 0.4637949108492167, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4019586], dtype=float32), -0.780381]. 
=============================================
[2019-04-07 11:53:25,983] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.3822294e-12 6.1040034e-11 1.6717807e-15 5.1642923e-10 3.0593479e-12
 1.0000000e+00 1.5433891e-08 7.6582862e-10], sum to 1.0000
[2019-04-07 11:53:25,983] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3970
[2019-04-07 11:53:26,268] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.05, 84.5, 0.0, 0.0, 24.0, 23.10545734434969, -0.166474366645841, 0.0, 1.0, 108330.14487676551], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1884600.0000, 
sim time next is 1886400.0000, 
raw observation next is [-5.6, 86.0, 0.0, 0.0, 24.0, 23.33262021354145, -0.1487387014740344, 0.0, 1.0, 54744.61810216985], 
processed observation next is [0.0, 0.8695652173913043, 0.30747922437673136, 0.86, 0.0, 0.0, 0.5, 0.4443850177951208, 0.4504204328419885, 0.0, 1.0, 0.26068865762938026], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1594837], dtype=float32), 1.3229544]. 
=============================================
[2019-04-07 11:53:29,749] A3C_AGENT_WORKER-Thread-18 INFO:Local step 15500, global step 245198: loss 1.6387
[2019-04-07 11:53:29,749] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 15500, global step 245198: learning rate 0.0000
[2019-04-07 11:53:35,466] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9608275e-15 2.3992930e-14 6.8281175e-19 3.3916255e-12 1.2644477e-13
 1.0000000e+00 3.8606847e-09 3.8412802e-12], sum to 1.0000
[2019-04-07 11:53:35,466] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7854
[2019-04-07 11:53:35,507] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.9, 80.5, 0.0, 0.0, 24.0, 23.46732544372968, -0.05936681486050353, 0.0, 1.0, 21024.193425320715], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1978200.0000, 
sim time next is 1980000.0000, 
raw observation next is [-6.2, 83.0, 0.0, 0.0, 24.0, 23.36533669968679, -0.05179912033791129, 0.0, 1.0, 73577.79250213182], 
processed observation next is [1.0, 0.9565217391304348, 0.2908587257617729, 0.83, 0.0, 0.0, 0.5, 0.4471113916405658, 0.48273362655402957, 0.0, 1.0, 0.350370440486342], 
reward next is 0.9353, 
noisyNet noise sample is [array([-0.04955855], dtype=float32), -1.3239825]. 
=============================================
[2019-04-07 11:53:35,528] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[ 98.001076]
 [ 99.669685]
 [100.8056  ]
 [101.28454 ]
 [102.831314]], R is [[98.03780365]
 [98.05742645]
 [98.07685089]
 [97.82967377]
 [97.85137939]].
[2019-04-07 11:53:40,170] A3C_AGENT_WORKER-Thread-19 INFO:Local step 15500, global step 246136: loss 1.6715
[2019-04-07 11:53:40,170] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 15500, global step 246136: learning rate 0.0000
[2019-04-07 11:53:44,504] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15500, global step 246506: loss 1.6025
[2019-04-07 11:53:44,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 15500, global step 246506: learning rate 0.0000
[2019-04-07 11:53:58,720] A3C_AGENT_WORKER-Thread-3 INFO:Local step 16000, global step 247824: loss 19.1275
[2019-04-07 11:53:58,721] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 16000, global step 247824: learning rate 0.0000
[2019-04-07 11:53:59,410] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15500, global step 247889: loss 1.7085
[2019-04-07 11:53:59,411] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 15500, global step 247889: learning rate 0.0000
[2019-04-07 11:54:03,375] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5898366e-16 4.0222078e-14 4.2743963e-18 5.5144942e-12 3.5316361e-14
 1.0000000e+00 4.2307375e-09 1.0356611e-11], sum to 1.0000
[2019-04-07 11:54:03,375] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1294
[2019-04-07 11:54:03,542] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.8, 70.5, 0.0, 0.0, 24.0, 23.59163409967162, -0.03919801824988153, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2230200.0000, 
sim time next is 2232000.0000, 
raw observation next is [-5.0, 71.0, 0.0, 0.0, 24.0, 23.32036078481785, -0.08076892115365959, 1.0, 1.0, 27917.160567874624], 
processed observation next is [1.0, 0.8695652173913043, 0.32409972299168976, 0.71, 0.0, 0.0, 0.5, 0.4433633987348209, 0.4730770262821135, 1.0, 1.0, 0.13293885984702203], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.37966534], dtype=float32), -1.1517156]. 
=============================================
[2019-04-07 11:54:03,566] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[102.376755]
 [102.26413 ]
 [104.43822 ]
 [105.23335 ]
 [105.86938 ]], R is [[102.8287735 ]
 [102.8004837 ]
 [102.61238098]
 [102.58625793]
 [102.56039429]].
[2019-04-07 11:54:04,697] A3C_AGENT_WORKER-Thread-10 INFO:Local step 15500, global step 248494: loss 1.6689
[2019-04-07 11:54:04,697] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 15500, global step 248494: learning rate 0.0000
[2019-04-07 11:54:09,233] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15500, global step 249120: loss 1.6004
[2019-04-07 11:54:09,245] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 15500, global step 249120: learning rate 0.0000
[2019-04-07 11:54:10,408] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15500, global step 249305: loss 1.5917
[2019-04-07 11:54:10,409] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 15500, global step 249305: learning rate 0.0000
[2019-04-07 11:54:12,264] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15500, global step 249542: loss 1.7719
[2019-04-07 11:54:12,281] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 15500, global step 249542: learning rate 0.0000
[2019-04-07 11:54:12,706] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15500, global step 249593: loss 1.5832
[2019-04-07 11:54:12,706] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 15500, global step 249593: learning rate 0.0000
[2019-04-07 11:54:13,812] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15500, global step 249743: loss 1.6833
[2019-04-07 11:54:13,812] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 15500, global step 249743: learning rate 0.0000
[2019-04-07 11:54:14,319] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15500, global step 249814: loss 1.6322
[2019-04-07 11:54:14,319] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 15500, global step 249814: learning rate 0.0000
[2019-04-07 11:54:14,455] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15500, global step 249835: loss 1.7398
[2019-04-07 11:54:14,455] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 15500, global step 249835: learning rate 0.0000
[2019-04-07 11:54:15,274] A3C_AGENT_WORKER-Thread-11 INFO:Local step 15500, global step 249965: loss 1.6781
[2019-04-07 11:54:15,275] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 15500, global step 249965: learning rate 0.0000
[2019-04-07 11:54:16,064] A3C_AGENT_WORKER-Thread-20 INFO:Local step 15500, global step 250108: loss 1.7569
[2019-04-07 11:54:16,065] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 15500, global step 250108: learning rate 0.0000
[2019-04-07 11:54:17,630] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15500, global step 250313: loss 1.7391
[2019-04-07 11:54:17,631] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 15500, global step 250313: learning rate 0.0000
[2019-04-07 11:54:25,114] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8874202e-17 2.7402913e-15 7.2182519e-21 7.9861268e-14 3.4568304e-16
 1.0000000e+00 1.8699396e-11 4.6721477e-14], sum to 1.0000
[2019-04-07 11:54:25,114] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0595
[2019-04-07 11:54:25,173] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 92.0, 101.0, 653.0, 24.0, 24.3019114941413, 0.2144291179993056, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3231000.0000, 
sim time next is 3232800.0000, 
raw observation next is [-3.0, 92.0, 105.0, 702.5, 24.0, 24.5409891689949, 0.2505646736630376, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.92, 0.35, 0.7762430939226519, 0.5, 0.5450824307495751, 0.5835215578876792, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0307598], dtype=float32), -0.9539888]. 
=============================================
[2019-04-07 11:54:29,349] A3C_AGENT_WORKER-Thread-18 INFO:Local step 16000, global step 252279: loss 19.5810
[2019-04-07 11:54:29,349] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 16000, global step 252279: learning rate 0.0000
[2019-04-07 11:54:31,067] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5213849e-14 2.6736160e-13 3.8978120e-17 3.1958847e-10 2.0574467e-12
 1.0000000e+00 2.8329772e-08 3.3076697e-10], sum to 1.0000
[2019-04-07 11:54:31,068] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7229
[2019-04-07 11:54:31,121] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 100.0, 0.0, 0.0, 24.0, 23.57839183507092, -0.07851037784059875, 0.0, 1.0, 27469.754228095117], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3114000.0000, 
sim time next is 3115800.0000, 
raw observation next is [1.0, 100.0, 0.0, 0.0, 24.0, 23.6605979420596, -0.1006842854875028, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 1.0, 0.0, 0.0, 0.5, 0.4717164951716333, 0.46643857150416573, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.10434918], dtype=float32), 0.9736789]. 
=============================================
[2019-04-07 11:54:34,390] A3C_AGENT_WORKER-Thread-19 INFO:Local step 16000, global step 253008: loss 19.5235
[2019-04-07 11:54:34,391] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 16000, global step 253008: learning rate 0.0000
[2019-04-07 11:54:39,418] A3C_AGENT_WORKER-Thread-14 INFO:Local step 16000, global step 253822: loss 19.5673
[2019-04-07 11:54:39,419] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 16000, global step 253822: learning rate 0.0000
[2019-04-07 11:54:42,079] A3C_AGENT_WORKER-Thread-3 INFO:Local step 16500, global step 254295: loss 6.4166
[2019-04-07 11:54:42,084] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 16500, global step 254295: learning rate 0.0000
[2019-04-07 11:54:48,760] A3C_AGENT_WORKER-Thread-6 INFO:Local step 16000, global step 255428: loss 19.3346
[2019-04-07 11:54:48,761] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 16000, global step 255428: learning rate 0.0000
[2019-04-07 11:54:53,032] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7662926e-13 2.7743589e-11 1.3908328e-14 9.9101194e-10 3.5752328e-11
 9.9999952e-01 4.8316429e-07 3.4670364e-09], sum to 1.0000
[2019-04-07 11:54:53,032] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0826
[2019-04-07 11:54:53,076] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.5, 74.0, 0.0, 0.0, 24.0, 23.11096445565462, -0.1804546697317577, 0.0, 1.0, 39952.95220567385], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3033000.0000, 
sim time next is 3034800.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 24.0, 23.01755094446171, -0.2005295473985785, 0.0, 1.0, 40312.220762523786], 
processed observation next is [0.0, 0.13043478260869565, 0.296398891966759, 0.77, 0.0, 0.0, 0.5, 0.41812924537180923, 0.4331568175338072, 0.0, 1.0, 0.19196295601201802], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3696375], dtype=float32), -0.17587098]. 
=============================================
[2019-04-07 11:54:53,788] A3C_AGENT_WORKER-Thread-10 INFO:Local step 16000, global step 256407: loss 19.4272
[2019-04-07 11:54:53,789] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 16000, global step 256407: learning rate 0.0000
[2019-04-07 11:54:56,737] A3C_AGENT_WORKER-Thread-12 INFO:Local step 16000, global step 257086: loss 19.7641
[2019-04-07 11:54:56,737] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 16000, global step 257086: learning rate 0.0000
[2019-04-07 11:54:57,375] A3C_AGENT_WORKER-Thread-16 INFO:Local step 16000, global step 257221: loss 19.8494
[2019-04-07 11:54:57,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 16000, global step 257221: learning rate 0.0000
[2019-04-07 11:54:59,505] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9154709e-18 5.2199120e-16 1.6986797e-20 3.0059299e-13 2.7749711e-17
 1.0000000e+00 4.4717931e-11 2.0678908e-13], sum to 1.0000
[2019-04-07 11:54:59,505] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9978
[2019-04-07 11:54:59,552] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 71.0, 85.0, 686.0, 24.0, 24.8461883486916, 0.339939102060808, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3252600.0000, 
sim time next is 3254400.0000, 
raw observation next is [-3.0, 71.0, 72.0, 598.5, 24.0, 25.09800567947746, 0.3606935534990055, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.3795013850415513, 0.71, 0.24, 0.6613259668508288, 0.5, 0.5915004732897883, 0.6202311844996685, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.448148], dtype=float32), 0.3843545]. 
=============================================
[2019-04-07 11:54:59,992] A3C_AGENT_WORKER-Thread-13 INFO:Local step 16000, global step 257799: loss 19.3937
[2019-04-07 11:54:59,992] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 16000, global step 257799: learning rate 0.0000
[2019-04-07 11:55:01,208] A3C_AGENT_WORKER-Thread-2 INFO:Local step 16000, global step 258008: loss 19.4748
[2019-04-07 11:55:01,209] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 16000, global step 258008: learning rate 0.0000
[2019-04-07 11:55:01,684] A3C_AGENT_WORKER-Thread-4 INFO:Local step 16000, global step 258081: loss 19.6791
[2019-04-07 11:55:01,691] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 16000, global step 258081: learning rate 0.0000
[2019-04-07 11:55:02,914] A3C_AGENT_WORKER-Thread-5 INFO:Local step 16000, global step 258311: loss 19.7701
[2019-04-07 11:55:02,915] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 16000, global step 258311: learning rate 0.0000
[2019-04-07 11:55:02,923] A3C_AGENT_WORKER-Thread-15 INFO:Local step 16000, global step 258315: loss 19.5555
[2019-04-07 11:55:02,923] A3C_AGENT_WORKER-Thread-11 INFO:Local step 16000, global step 258315: loss 19.4915
[2019-04-07 11:55:02,923] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 16000, global step 258315: learning rate 0.0000
[2019-04-07 11:55:02,925] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 16000, global step 258315: learning rate 0.0000
[2019-04-07 11:55:03,204] A3C_AGENT_WORKER-Thread-20 INFO:Local step 16000, global step 258364: loss 19.1462
[2019-04-07 11:55:03,204] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 16000, global step 258364: learning rate 0.0000
[2019-04-07 11:55:04,499] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7549457e-14 4.8494628e-13 4.1226778e-17 1.9196294e-11 2.4675284e-12
 1.0000000e+00 2.9616839e-08 6.3311900e-10], sum to 1.0000
[2019-04-07 11:55:04,499] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1126
[2019-04-07 11:55:04,566] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 24.0, 23.36624137152024, -0.07089552089262756, 0.0, 1.0, 43330.70380132997], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3378600.0000, 
sim time next is 3380400.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 24.0, 23.44792122695434, -0.07165269114308791, 0.0, 1.0, 26763.39826418497], 
processed observation next is [1.0, 0.13043478260869565, 0.296398891966759, 0.77, 0.0, 0.0, 0.5, 0.45399343557952826, 0.4761157696189707, 0.0, 1.0, 0.12744475363897603], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.741541], dtype=float32), 0.27357352]. 
=============================================
[2019-04-07 11:55:04,894] A3C_AGENT_WORKER-Thread-17 INFO:Local step 16000, global step 258694: loss 19.5931
[2019-04-07 11:55:04,895] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 16000, global step 258694: learning rate 0.0000
[2019-04-07 11:55:08,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.4444419e-18 4.6057328e-15 1.3055623e-19 1.2684333e-13 1.0099714e-15
 1.0000000e+00 3.4316541e-10 3.0510674e-12], sum to 1.0000
[2019-04-07 11:55:08,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0837
[2019-04-07 11:55:08,070] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 48.0, 104.0, 711.0, 24.0, 24.86723922850283, 0.1955272550496857, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3405600.0000, 
sim time next is 3407400.0000, 
raw observation next is [2.5, 48.5, 109.0, 764.0, 24.0, 24.88230762084509, 0.2208015222862647, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.5318559556786704, 0.485, 0.36333333333333334, 0.8441988950276244, 0.5, 0.5735256350704242, 0.5736005074287549, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.27897578], dtype=float32), 0.8833764]. 
=============================================
[2019-04-07 11:55:10,599] A3C_AGENT_WORKER-Thread-18 INFO:Local step 16500, global step 259830: loss 7.2922
[2019-04-07 11:55:10,600] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 16500, global step 259830: learning rate 0.0000
[2019-04-07 11:55:11,437] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-07 11:55:11,438] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:55:11,439] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:55:11,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run14
[2019-04-07 11:55:11,459] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 11:55:11,459] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:55:11,463] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 11:55:11,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run14
[2019-04-07 11:55:11,478] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:55:11,482] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run14
[2019-04-07 11:56:47,551] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2788.9052 70927233.8163 166.2180
[2019-04-07 11:57:18,402] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 11:57:27,043] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 11:57:28,081] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 260000, evaluation results [260000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2788.9051760082016, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 11:57:38,947] A3C_AGENT_WORKER-Thread-19 INFO:Local step 16500, global step 261034: loss 6.8804
[2019-04-07 11:57:38,948] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 16500, global step 261034: learning rate 0.0000
[2019-04-07 11:57:42,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:57:42,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:57:42,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run7
[2019-04-07 11:57:44,971] A3C_AGENT_WORKER-Thread-14 INFO:Local step 16500, global step 261644: loss 6.9472
[2019-04-07 11:57:45,037] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 16500, global step 261644: learning rate 0.0000
[2019-04-07 11:57:48,251] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3243014e-14 6.0619986e-12 6.3152251e-16 3.0351427e-10 1.9641914e-12
 9.9999976e-01 2.4590722e-07 1.3786181e-10], sum to 1.0000
[2019-04-07 11:57:48,251] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4125
[2019-04-07 11:57:48,392] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 24.0, 23.44883910015352, -0.06074352497192955, 0.0, 1.0, 41515.914045654514], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3717000.0000, 
sim time next is 3718800.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 24.0, 23.72052585988768, -0.0388211753719036, 0.0, 1.0, 15351.302672514663], 
processed observation next is [1.0, 0.043478260869565216, 0.3795013850415513, 0.71, 0.0, 0.0, 0.5, 0.4767104883239733, 0.48705960820936545, 0.0, 1.0, 0.07310144129768888], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.35474628], dtype=float32), 0.38015777]. 
=============================================
[2019-04-07 11:58:02,856] A3C_AGENT_WORKER-Thread-6 INFO:Local step 16500, global step 263430: loss 6.3724
[2019-04-07 11:58:02,857] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 16500, global step 263430: learning rate 0.0000
[2019-04-07 11:58:11,505] A3C_AGENT_WORKER-Thread-10 INFO:Local step 16500, global step 264338: loss 7.0696
[2019-04-07 11:58:11,516] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 16500, global step 264338: learning rate 0.0000
[2019-04-07 11:58:17,987] A3C_AGENT_WORKER-Thread-12 INFO:Local step 16500, global step 265002: loss 7.3677
[2019-04-07 11:58:17,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 16500, global step 265002: learning rate 0.0000
[2019-04-07 11:58:20,301] A3C_AGENT_WORKER-Thread-16 INFO:Local step 16500, global step 265269: loss 6.8308
[2019-04-07 11:58:20,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 16500, global step 265269: learning rate 0.0000
[2019-04-07 11:58:22,333] A3C_AGENT_WORKER-Thread-13 INFO:Local step 16500, global step 265466: loss 7.5255
[2019-04-07 11:58:22,335] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 16500, global step 265466: learning rate 0.0000
[2019-04-07 11:58:27,489] A3C_AGENT_WORKER-Thread-4 INFO:Local step 16500, global step 265990: loss 7.3689
[2019-04-07 11:58:27,496] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 16500, global step 265990: learning rate 0.0000
[2019-04-07 11:58:28,768] A3C_AGENT_WORKER-Thread-2 INFO:Local step 16500, global step 266128: loss 6.8675
[2019-04-07 11:58:28,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 16500, global step 266128: learning rate 0.0000
[2019-04-07 11:58:30,208] A3C_AGENT_WORKER-Thread-15 INFO:Local step 16500, global step 266277: loss 7.0145
[2019-04-07 11:58:30,209] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 16500, global step 266277: learning rate 0.0000
[2019-04-07 11:58:31,575] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.4880866e-12 6.3107722e-12 4.7454830e-16 3.7030986e-11 2.1603557e-12
 1.0000000e+00 3.8916177e-09 1.8001436e-10], sum to 1.0000
[2019-04-07 11:58:31,575] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3502
[2019-04-07 11:58:31,679] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 51.0, 110.0, 53.0, 24.0, 23.47684112625282, -0.09091967730516308, 0.0, 1.0, 12356.981929702177], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4264200.0000, 
sim time next is 4266000.0000, 
raw observation next is [3.0, 53.0, 146.0, 92.0, 24.0, 23.44594371358033, -0.1023566589497121, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.5457063711911359, 0.53, 0.4866666666666667, 0.10165745856353592, 0.5, 0.4538286427983609, 0.4658811136834293, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.9722507], dtype=float32), -0.55835146]. 
=============================================
[2019-04-07 11:58:31,693] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[80.56037]
 [79.47872]
 [78.58542]
 [78.29032]
 [77.95585]], R is [[82.19025421]
 [82.3683548 ]
 [82.5446701 ]
 [82.71922302]
 [82.89202881]].
[2019-04-07 11:58:32,534] A3C_AGENT_WORKER-Thread-20 INFO:Local step 16500, global step 266525: loss 6.9492
[2019-04-07 11:58:32,570] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 16500, global step 266525: learning rate 0.0000
[2019-04-07 11:58:33,053] A3C_AGENT_WORKER-Thread-5 INFO:Local step 16500, global step 266585: loss 6.5514
[2019-04-07 11:58:33,097] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 16500, global step 266585: learning rate 0.0000
[2019-04-07 11:58:33,380] A3C_AGENT_WORKER-Thread-11 INFO:Local step 16500, global step 266621: loss 7.1563
[2019-04-07 11:58:33,409] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 16500, global step 266621: learning rate 0.0000
[2019-04-07 11:58:38,048] A3C_AGENT_WORKER-Thread-17 INFO:Local step 16500, global step 267104: loss 7.3357
[2019-04-07 11:58:38,049] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 16500, global step 267104: learning rate 0.0000
[2019-04-07 11:58:38,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:58:38,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:58:38,177] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run7
[2019-04-07 11:58:51,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:58:51,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:58:51,940] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run7
[2019-04-07 11:58:52,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:58:52,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:58:52,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run7
[2019-04-07 11:59:02,332] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1601397e-14 2.6620194e-13 1.6481906e-18 7.8542318e-11 1.3567698e-12
 1.0000000e+00 3.3536198e-09 1.3602122e-10], sum to 1.0000
[2019-04-07 11:59:02,333] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2563
[2019-04-07 11:59:02,465] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 46.0, 46.5, 280.0, 24.0, 23.81070303907723, -0.06927915644661746, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4953600.0000, 
sim time next is 4955400.0000, 
raw observation next is [-1.5, 42.5, 93.0, 560.0, 24.0, 23.84434108628028, -0.01083477910610232, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4210526315789474, 0.425, 0.31, 0.6187845303867403, 0.5, 0.48702842385669004, 0.49638840696463254, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.29692617], dtype=float32), -1.1694144]. 
=============================================
[2019-04-07 11:59:02,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:59:02,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:59:02,590] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run7
[2019-04-07 11:59:08,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:59:08,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:59:08,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run7
[2019-04-07 11:59:13,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:59:13,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:59:13,319] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run7
[2019-04-07 11:59:13,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:59:13,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:59:13,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run7
[2019-04-07 11:59:14,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:59:14,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:59:14,660] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run7
[2019-04-07 11:59:16,111] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.4073034e-15 6.6378265e-14 1.7236432e-17 2.3208255e-11 6.1147959e-14
 1.0000000e+00 7.6651583e-09 2.9402234e-11], sum to 1.0000
[2019-04-07 11:59:16,111] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6117
[2019-04-07 11:59:16,149] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.1, 83.0, 0.0, 0.0, 24.0, 23.16094535528575, -0.1436456704988258, 0.0, 1.0, 43862.881867454416], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 99000.0000, 
sim time next is 100800.0000, 
raw observation next is [-3.4, 79.0, 0.0, 0.0, 24.0, 23.03403383529524, -0.1584486690841523, 0.0, 1.0, 44170.00328607749], 
processed observation next is [1.0, 0.17391304347826086, 0.368421052631579, 0.79, 0.0, 0.0, 0.5, 0.41950281960793667, 0.4471837769719493, 0.0, 1.0, 0.21033334898132136], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2384535], dtype=float32), -0.43831548]. 
=============================================
[2019-04-07 11:59:17,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:59:17,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:59:17,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run7
[2019-04-07 11:59:18,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:59:18,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:59:18,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run7
[2019-04-07 11:59:18,595] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:59:18,595] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:59:18,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run7
[2019-04-07 11:59:19,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:59:19,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:59:19,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run7
[2019-04-07 11:59:20,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:59:20,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:59:20,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run7
[2019-04-07 11:59:21,475] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:59:21,475] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:59:21,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run7
[2019-04-07 11:59:21,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 11:59:21,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 11:59:21,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run7
[2019-04-07 11:59:35,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.9815317e-16 8.4364431e-15 3.2455041e-19 3.7927262e-13 2.0255351e-14
 1.0000000e+00 4.5144244e-09 7.7750809e-12], sum to 1.0000
[2019-04-07 11:59:35,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5430
[2019-04-07 11:59:36,189] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 80.0, 190.0, 36.0, 24.0, 23.70128749196848, -0.09203181175802273, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 124200.0000, 
sim time next is 126000.0000, 
raw observation next is [-7.8, 86.0, 187.0, 24.5, 24.0, 23.78003166849918, -0.02303123493919927, 1.0, 1.0, 112474.13123757202], 
processed observation next is [1.0, 0.4782608695652174, 0.24653739612188366, 0.86, 0.6233333333333333, 0.02707182320441989, 0.5, 0.48166930570826505, 0.4923229216869336, 1.0, 1.0, 0.5355911011312953], 
reward next is 0.7501, 
noisyNet noise sample is [array([0.5550528], dtype=float32), 0.003187383]. 
=============================================
[2019-04-07 11:59:36,193] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[102.33557 ]
 [100.52324 ]
 [ 98.7106  ]
 [ 97.754005]
 [ 95.91912 ]], R is [[104.4489212 ]
 [104.4044342 ]
 [104.36038971]
 [104.31678772]
 [104.27362061]].
[2019-04-07 11:59:48,472] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5083890e-13 2.8052686e-12 8.2847176e-18 2.7950067e-10 2.1519657e-12
 9.9999988e-01 8.7895934e-08 1.9691160e-09], sum to 1.0000
[2019-04-07 11:59:48,473] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3984
[2019-04-07 11:59:48,670] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 40.0, 11.5, 0.0, 24.0, 23.38630728955123, -0.2361761451083405, 1.0, 1.0, 54272.084338194334], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 460800.0000, 
sim time next is 462600.0000, 
raw observation next is [-7.0, 36.5, 23.0, 0.0, 24.0, 23.62028033218026, -0.2004094399310748, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.2686980609418283, 0.365, 0.07666666666666666, 0.0, 0.5, 0.4683566943483551, 0.4331968533563084, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.94593686], dtype=float32), -1.6091509]. 
=============================================
[2019-04-07 11:59:50,429] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.7052856e-12 7.8486904e-11 7.8065114e-15 4.8428611e-10 4.2655580e-11
 9.9999988e-01 1.6187995e-07 7.9091050e-10], sum to 1.0000
[2019-04-07 11:59:50,430] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5289
[2019-04-07 11:59:50,521] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 68.0, 0.0, 0.0, 24.0, 22.69544187351494, -0.2697332712196517, 0.0, 1.0, 45250.3684891916], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 622800.0000, 
sim time next is 624600.0000, 
raw observation next is [-4.5, 66.5, 0.0, 0.0, 24.0, 22.66411686433644, -0.2777885543760037, 0.0, 1.0, 45040.637063349226], 
processed observation next is [0.0, 0.21739130434782608, 0.3379501385041552, 0.665, 0.0, 0.0, 0.5, 0.3886764053613699, 0.4074038152079988, 0.0, 1.0, 0.21447922411118678], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.19907859], dtype=float32), 0.73446923]. 
=============================================
[2019-04-07 12:00:13,339] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1608376e-15 3.0465590e-13 5.0145790e-17 4.1040314e-12 2.6159207e-12
 1.0000000e+00 8.8461167e-09 8.7121135e-12], sum to 1.0000
[2019-04-07 12:00:13,340] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6832
[2019-04-07 12:00:13,466] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 83.0, 83.0, 138.0, 24.0, 23.02532461567612, -0.1517494678702062, 0.0, 1.0, 6492.1976095057435], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 558000.0000, 
sim time next is 559800.0000, 
raw observation next is [-0.7, 82.0, 89.0, 135.0, 24.0, 23.00637868253989, -0.1571241932313671, 0.0, 1.0, 33341.06517302192], 
processed observation next is [0.0, 0.4782608695652174, 0.443213296398892, 0.82, 0.2966666666666667, 0.14917127071823205, 0.5, 0.41719822354499075, 0.44762526892287763, 0.0, 1.0, 0.15876697701439008], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5896688], dtype=float32), -0.10090066]. 
=============================================
[2019-04-07 12:00:15,635] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.8073708e-18 2.4964811e-16 1.7031039e-21 2.7921627e-13 9.3764091e-16
 1.0000000e+00 7.5267310e-12 4.0074099e-12], sum to 1.0000
[2019-04-07 12:00:15,635] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0328
[2019-04-07 12:00:15,699] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 77.0, 0.0, 0.0, 24.0, 23.31160806004768, 0.136052086102556, 0.0, 1.0, 166587.36477429254], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1026000.0000, 
sim time next is 1027800.0000, 
raw observation next is [14.4, 76.0, 0.0, 0.0, 24.0, 24.03562843607061, 0.2002088173843076, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.8614958448753465, 0.76, 0.0, 0.0, 0.5, 0.5029690363392175, 0.5667362724614359, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3389134], dtype=float32), -1.2801067]. 
=============================================
[2019-04-07 12:00:22,474] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-07 12:00:22,474] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:00:22,475] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:00:22,476] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:00:22,477] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:00:22,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run15
[2019-04-07 12:00:22,499] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run15
[2019-04-07 12:00:22,516] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:00:22,520] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:00:22,522] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run15
[2019-04-07 12:00:31,438] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.11818699], dtype=float32), 0.12572645]
[2019-04-07 12:00:31,439] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-8.9, 74.0, 0.0, 0.0, 24.0, 22.39507998022345, -0.3280842889735918, 0.0, 1.0, 45247.19476169648]
[2019-04-07 12:00:31,439] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 12:00:31,440] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [8.8006073e-13 3.9249038e-11 5.0341709e-15 8.1613333e-10 1.6864518e-11
 9.9999976e-01 2.3714296e-07 2.6397420e-09], sampled 0.44453465261482683
[2019-04-07 12:02:04,398] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 12:02:40,369] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 12:02:48,250] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 12:02:49,288] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 280000, evaluation results [280000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 12:03:07,006] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.7019253e-17 2.2958594e-13 7.5798611e-20 1.4191217e-12 9.7864768e-16
 1.0000000e+00 3.2100842e-09 1.6662640e-11], sum to 1.0000
[2019-04-07 12:03:07,006] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9404
[2019-04-07 12:03:07,248] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 79.0, 95.0, 0.0, 24.0, 23.69747045181288, -0.1010582376586873, 1.0, 1.0, 43477.06093211695], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 824400.0000, 
sim time next is 826200.0000, 
raw observation next is [-4.2, 79.0, 91.0, 0.0, 24.0, 23.9113745436435, -0.05742622731871446, 1.0, 1.0, 9742.822258738643], 
processed observation next is [1.0, 0.5652173913043478, 0.34626038781163443, 0.79, 0.30333333333333334, 0.0, 0.5, 0.49261454530362503, 0.48085792422709517, 1.0, 1.0, 0.04639439170827925], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16096665], dtype=float32), -1.4547809]. 
=============================================
[2019-04-07 12:03:23,891] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3910961e-14 8.5773841e-13 6.3599244e-17 3.0409890e-11 1.4582991e-13
 1.0000000e+00 8.3797289e-09 6.7879335e-10], sum to 1.0000
[2019-04-07 12:03:23,891] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1677
[2019-04-07 12:03:24,086] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 83.0, 122.5, 0.0, 24.0, 23.06239128483891, -0.08776843207845207, 0.0, 1.0, 27867.70213127749], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1771200.0000, 
sim time next is 1773000.0000, 
raw observation next is [-2.55, 83.0, 126.0, 0.0, 24.0, 23.05572354281031, -0.08598751575729306, 0.0, 1.0, 40485.92297825631], 
processed observation next is [0.0, 0.5217391304347826, 0.3919667590027701, 0.83, 0.42, 0.0, 0.5, 0.42131029523419244, 0.471337494747569, 0.0, 1.0, 0.19279010942026814], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.41086733], dtype=float32), 2.144698]. 
=============================================
[2019-04-07 12:03:24,262] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[90.80729 ]
 [90.27969 ]
 [89.58969 ]
 [89.150604]
 [88.6635  ]], R is [[91.61479187]
 [91.69864655]
 [91.78166199]
 [91.86384583]
 [91.94520569]].
[2019-04-07 12:03:51,380] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0320431e-17 6.4015256e-16 3.6873430e-20 9.1054005e-12 2.3691194e-15
 1.0000000e+00 8.6717206e-10 1.3207393e-13], sum to 1.0000
[2019-04-07 12:03:51,380] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5541
[2019-04-07 12:03:51,433] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 92.0, 0.0, 0.0, 24.0, 23.74505391876795, 0.09456555702512341, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1666800.0000, 
sim time next is 1668600.0000, 
raw observation next is [4.15, 92.0, 0.0, 0.0, 24.0, 23.65731737772341, 0.0728713839711132, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.5775623268698062, 0.92, 0.0, 0.0, 0.5, 0.47144311481028406, 0.5242904613237044, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0014274], dtype=float32), -0.5585029]. 
=============================================
[2019-04-07 12:04:21,142] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8604225e-15 2.2954008e-12 9.7945340e-18 2.6866542e-11 1.7493916e-13
 1.0000000e+00 1.4119428e-08 9.2873261e-12], sum to 1.0000
[2019-04-07 12:04:21,142] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9768
[2019-04-07 12:04:21,184] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 80.5, 0.0, 0.0, 24.0, 22.66073220190565, -0.2688667600537725, 0.0, 1.0, 44533.70291541475], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2097000.0000, 
sim time next is 2098800.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 24.0, 22.56324460869979, -0.2850901873391244, 0.0, 1.0, 44420.921525638376], 
processed observation next is [1.0, 0.30434782608695654, 0.2770083102493075, 0.78, 0.0, 0.0, 0.5, 0.38027038405831587, 0.40496993755362515, 0.0, 1.0, 0.21152819774113513], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2705667], dtype=float32), -0.6430653]. 
=============================================
[2019-04-07 12:04:38,372] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0714928e-17 1.0214134e-14 2.3695461e-21 3.6843824e-13 9.3446691e-15
 1.0000000e+00 1.5773111e-10 6.7170997e-13], sum to 1.0000
[2019-04-07 12:04:38,373] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5895
[2019-04-07 12:04:38,532] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 24.0, 23.80292491138037, 0.004936996817531088, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2142000.0000, 
sim time next is 2143800.0000, 
raw observation next is [-5.3, 78.5, 0.0, 0.0, 24.0, 23.6407455228466, -0.05241824291897721, 0.0, 1.0, 29507.098361029242], 
processed observation next is [1.0, 0.8260869565217391, 0.31578947368421056, 0.785, 0.0, 0.0, 0.5, 0.4700621269038834, 0.48252725236034094, 0.0, 1.0, 0.14050999219537735], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02437574], dtype=float32), 0.8274023]. 
=============================================
[2019-04-07 12:04:40,522] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.0667363e-16 2.3751065e-14 6.8506820e-20 7.9063451e-14 1.9242223e-15
 1.0000000e+00 5.0950835e-09 2.1531483e-12], sum to 1.0000
[2019-04-07 12:04:40,522] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1939
[2019-04-07 12:04:40,549] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 62.0, 188.0, 223.0, 24.0, 24.04807995789442, -0.03644783183256826, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2631600.0000, 
sim time next is 2633400.0000, 
raw observation next is [-3.1, 58.0, 224.0, 171.0, 24.0, 24.02539004409099, -0.04170633549726566, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.37673130193905824, 0.58, 0.7466666666666667, 0.18895027624309393, 0.5, 0.5021158370075826, 0.4860978881675781, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.01660699], dtype=float32), 1.9005184]. 
=============================================
[2019-04-07 12:04:45,007] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.5469813e-16 2.0425210e-13 9.8371782e-19 1.9788789e-13 6.7800875e-15
 1.0000000e+00 1.6616638e-09 9.7531046e-12], sum to 1.0000
[2019-04-07 12:04:45,007] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1054
[2019-04-07 12:04:45,086] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.45, 76.5, 0.0, 0.0, 24.0, 23.07234521930419, -0.1487172872259057, 0.0, 1.0, 45781.85661876141], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2244600.0000, 
sim time next is 2246400.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 24.0, 22.96461909966193, -0.1719392002098655, 0.0, 1.0, 45648.04400637979], 
processed observation next is [1.0, 0.0, 0.2770083102493075, 0.78, 0.0, 0.0, 0.5, 0.4137182583051609, 0.4426869332633782, 0.0, 1.0, 0.21737163812561802], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.88958997], dtype=float32), 0.16330846]. 
=============================================
[2019-04-07 12:05:12,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8296682e-15 1.8860647e-12 1.6624178e-17 3.3401769e-12 6.3838400e-14
 1.0000000e+00 8.1073015e-09 8.3545488e-12], sum to 1.0000
[2019-04-07 12:05:12,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9272
[2019-04-07 12:05:12,373] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.40280958341459, -0.09988408310007478, 0.0, 1.0, 57281.614356173064], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3726000.0000, 
sim time next is 3727800.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.58545346129764, -0.06814201127278852, 0.0, 1.0, 25645.57637128237], 
processed observation next is [1.0, 0.13043478260869565, 0.3795013850415513, 0.65, 0.0, 0.0, 0.5, 0.4654544551081366, 0.47728599624240386, 0.0, 1.0, 0.12212179224420175], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0895927], dtype=float32), -0.8933028]. 
=============================================
[2019-04-07 12:05:18,025] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-07 12:05:18,025] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:05:18,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:05:18,027] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:05:18,028] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run16
[2019-04-07 12:05:18,045] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:05:18,047] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run16
[2019-04-07 12:05:18,060] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:05:18,066] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:05:18,067] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run16
[2019-04-07 12:06:04,005] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.11864109], dtype=float32), 0.12680744]
[2019-04-07 12:06:04,005] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-0.9, 70.0, 0.0, 0.0, 24.0, 23.40639860614899, -0.01021267326171825, 0.0, 1.0, 46237.3157524152]
[2019-04-07 12:06:04,006] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 12:06:04,006] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [5.1130321e-14 3.7368060e-12 2.3509058e-16 9.6405481e-11 1.5287078e-12
 1.0000000e+00 3.7710311e-08 3.4331665e-10], sampled 0.5170768768267661
[2019-04-07 12:07:04,091] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 12:07:34,936] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.4863 79463814.5229 95.0531
[2019-04-07 12:07:41,378] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 12:07:42,413] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 300000, evaluation results [300000.0, 2782.4863413368403, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 12:08:25,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3483030e-16 6.7420136e-13 3.2354948e-17 3.5115609e-13 1.2936575e-14
 1.0000000e+00 1.9566753e-09 4.2737917e-11], sum to 1.0000
[2019-04-07 12:08:25,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2576
[2019-04-07 12:08:25,106] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.45, 77.0, 0.0, 0.0, 24.0, 23.22007954852882, -0.05770009091748019, 0.0, 1.0, 48307.35493595419], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3295800.0000, 
sim time next is 3297600.0000, 
raw observation next is [-8.9, 77.0, 0.0, 0.0, 24.0, 23.33805654973057, -0.06384760224833493, 0.0, 1.0, 45301.38711919588], 
processed observation next is [1.0, 0.17391304347826086, 0.21606648199445982, 0.77, 0.0, 0.0, 0.5, 0.4448380458108809, 0.4787174659172217, 0.0, 1.0, 0.21572089104378991], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1008308], dtype=float32), -0.4641127]. 
=============================================
[2019-04-07 12:08:25,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:08:25,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:08:25,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run8
[2019-04-07 12:08:34,344] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6263468e-14 4.7188371e-13 2.3103641e-17 9.9837118e-11 2.6201090e-13
 1.0000000e+00 1.1231039e-08 1.1311210e-11], sum to 1.0000
[2019-04-07 12:08:34,344] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3100
[2019-04-07 12:08:34,432] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 24.0, 23.49151510538731, 0.01703500952706579, 0.0, 1.0, 34862.09011888018], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3546000.0000, 
sim time next is 3547800.0000, 
raw observation next is [-2.5, 65.5, 0.0, 0.0, 24.0, 23.44884269487106, 0.0130093272047655, 0.0, 1.0, 53880.91300912498], 
processed observation next is [0.0, 0.043478260869565216, 0.39335180055401664, 0.655, 0.0, 0.0, 0.5, 0.45407022457258844, 0.5043364424015885, 0.0, 1.0, 0.25657577623392847], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.41403568], dtype=float32), -1.9993225]. 
=============================================
[2019-04-07 12:08:39,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5137647e-12 7.4266210e-12 1.5465207e-16 1.6332445e-10 3.4905872e-12
 9.9999976e-01 1.8368853e-07 2.9698783e-09], sum to 1.0000
[2019-04-07 12:08:39,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3015
[2019-04-07 12:08:39,340] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 38.0, 0.0, 0.0, 24.0, 23.41164699875709, -0.1002984677350818, 0.0, 1.0, 40634.77161168002], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4071600.0000, 
sim time next is 4073400.0000, 
raw observation next is [-5.0, 39.5, 0.0, 0.0, 24.0, 23.39198343972285, -0.1119853067340847, 0.0, 1.0, 48067.672123567296], 
processed observation next is [1.0, 0.13043478260869565, 0.32409972299168976, 0.395, 0.0, 0.0, 0.5, 0.4493319533102375, 0.4626715644219717, 0.0, 1.0, 0.22889367677889189], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7785447], dtype=float32), 0.9896241]. 
=============================================
[2019-04-07 12:08:47,779] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.0398016e-15 6.1535965e-13 2.0609162e-18 2.5196550e-11 1.4069309e-13
 1.0000000e+00 2.4844731e-08 2.7294157e-11], sum to 1.0000
[2019-04-07 12:08:47,780] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8517
[2019-04-07 12:08:47,830] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 30.0, 0.0, 0.0, 24.0, 23.67318257788159, 0.04870576809890508, 0.0, 1.0, 21831.867855197648], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4051800.0000, 
sim time next is 4053600.0000, 
raw observation next is [-5.0, 31.0, 0.0, 0.0, 24.0, 23.61537980526701, 0.04410177257726635, 0.0, 1.0, 46883.77344818757], 
processed observation next is [1.0, 0.9565217391304348, 0.32409972299168976, 0.31, 0.0, 0.0, 0.5, 0.46794831710558427, 0.5147005908590888, 0.0, 1.0, 0.2232560640389884], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8653516], dtype=float32), -0.07894352]. 
=============================================
[2019-04-07 12:08:54,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:08:54,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:08:54,056] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run8
[2019-04-07 12:08:58,227] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2809774e-15 2.6299711e-14 2.2306282e-17 6.4915798e-12 3.1519709e-14
 1.0000000e+00 2.9518130e-09 1.8744282e-11], sum to 1.0000
[2019-04-07 12:08:58,227] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0234
[2019-04-07 12:08:58,290] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.0, 52.0, 120.0, 847.0, 24.0, 23.43353035662959, -0.008151356939906559, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4278600.0000, 
sim time next is 4280400.0000, 
raw observation next is [7.0, 52.0, 154.0, 782.0, 24.0, 23.53322699109939, 0.01306674280160782, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.6565096952908588, 0.52, 0.5133333333333333, 0.8640883977900552, 0.5, 0.4611022492582825, 0.5043555809338692, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4874825], dtype=float32), -0.09515854]. 
=============================================
[2019-04-07 12:09:02,556] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3406905e-14 1.3819439e-13 1.8736021e-19 1.6403926e-12 1.9084735e-14
 1.0000000e+00 9.3743269e-10 6.5065045e-12], sum to 1.0000
[2019-04-07 12:09:02,556] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6230
[2019-04-07 12:09:02,593] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 62.0, 0.0, 0.0, 24.0, 23.78471134079275, 0.07604956943646696, 0.0, 1.0, 26504.466154760576], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4674600.0000, 
sim time next is 4676400.0000, 
raw observation next is [2.0, 62.0, 0.0, 0.0, 24.0, 23.84013048852363, 0.06989004499406089, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.518005540166205, 0.62, 0.0, 0.0, 0.5, 0.48667754071030256, 0.523296681664687, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.29407007], dtype=float32), -0.13959695]. 
=============================================
[2019-04-07 12:09:03,358] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2278833e-15 2.1547055e-12 3.2554878e-18 4.2656968e-11 1.5904014e-13
 1.0000000e+00 3.2353105e-09 1.4888851e-11], sum to 1.0000
[2019-04-07 12:09:03,358] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8545
[2019-04-07 12:09:03,433] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 55.5, 0.0, 0.0, 24.0, 23.44785154090694, -0.06555951871758785, 0.0, 1.0, 66211.72687635172], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5034600.0000, 
sim time next is 5036400.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.5167866987965, -0.05582574656619604, 0.0, 1.0, 33357.715582477445], 
processed observation next is [1.0, 0.30434782608695654, 0.3795013850415513, 0.65, 0.0, 0.0, 0.5, 0.45973222489970844, 0.481391417811268, 0.0, 1.0, 0.15884626467846402], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.141651], dtype=float32), 2.021367]. 
=============================================
[2019-04-07 12:09:04,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:04,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:04,344] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run8
[2019-04-07 12:09:06,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:06,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:06,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run8
[2019-04-07 12:09:10,258] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.68698995e-13 1.89202855e-11 3.16531342e-15 1.07610046e-10
 3.15327842e-12 9.99999881e-01 1.24266421e-07 1.81817061e-09], sum to 1.0000
[2019-04-07 12:09:10,259] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2183
[2019-04-07 12:09:10,342] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 60.0, 0.0, 0.0, 24.0, 23.38721722175472, -0.1115770525954131, 0.0, 1.0, 38973.199604171656], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4852800.0000, 
sim time next is 4854600.0000, 
raw observation next is [-3.5, 65.5, 0.0, 0.0, 24.0, 23.35919876219894, -0.110368827870151, 0.0, 1.0, 45870.47408460979], 
processed observation next is [0.0, 0.17391304347826086, 0.36565096952908593, 0.655, 0.0, 0.0, 0.5, 0.44659989684991164, 0.4632103907099497, 0.0, 1.0, 0.21843082897433233], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.26332703], dtype=float32), 0.49906167]. 
=============================================
[2019-04-07 12:09:12,705] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3192196e-18 4.5744256e-15 6.8680532e-21 8.9265812e-15 3.5985274e-16
 1.0000000e+00 1.8772495e-09 1.7136257e-13], sum to 1.0000
[2019-04-07 12:09:12,705] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9443
[2019-04-07 12:09:12,721] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.2, 59.0, 0.0, 0.0, 24.0, 25.21552819521877, 0.4489996960315516, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4395600.0000, 
sim time next is 4397400.0000, 
raw observation next is [9.8, 60.0, 0.0, 0.0, 24.0, 25.06080741463829, 0.4164205080910472, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.7340720221606649, 0.6, 0.0, 0.0, 0.5, 0.5884006178865242, 0.638806836030349, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7677317], dtype=float32), -0.27216938]. 
=============================================
[2019-04-07 12:09:16,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:16,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:16,184] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run8
[2019-04-07 12:09:21,712] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:21,712] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:21,718] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run8
[2019-04-07 12:09:30,192] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.74665447e-15 5.30930714e-13 1.05663654e-17 2.98716329e-11
 9.83964294e-14 1.00000000e+00 3.44044437e-09 5.06765047e-11], sum to 1.0000
[2019-04-07 12:09:30,192] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1348
[2019-04-07 12:09:30,244] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 24.0, 23.04812773493906, -0.110592632344479, 0.0, 1.0, 42214.62870109883], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4768200.0000, 
sim time next is 4770000.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 24.0, 23.06205781270497, -0.1293042489503869, 0.0, 1.0, 42290.73269206967], 
processed observation next is [0.0, 0.21739130434782608, 0.296398891966759, 0.92, 0.0, 0.0, 0.5, 0.4218381510587476, 0.4568985836832044, 0.0, 1.0, 0.20138444139080797], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2726153], dtype=float32), 0.7020362]. 
=============================================
[2019-04-07 12:09:30,295] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[85.202225]
 [84.77925 ]
 [84.428474]
 [84.37671 ]
 [86.03009 ]], R is [[85.85544586]
 [85.99689484]
 [86.13692474]
 [86.27555847]
 [86.41280365]].
[2019-04-07 12:09:32,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:32,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:32,534] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run8
[2019-04-07 12:09:32,833] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.9221777e-13 6.9851881e-11 4.0185517e-16 6.0625927e-10 3.6345471e-12
 9.9999952e-01 5.1453077e-07 1.2116291e-09], sum to 1.0000
[2019-04-07 12:09:32,858] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1119
[2019-04-07 12:09:32,911] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 37.0, 33.0, 185.0, 24.0, 23.45669397637472, -0.02577545843756971, 0.0, 1.0, 18680.41167023054], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4815000.0000, 
sim time next is 4816800.0000, 
raw observation next is [2.0, 40.0, 16.5, 92.5, 24.0, 23.34474321623599, -0.07395053532933285, 0.0, 1.0, 12453.607780153694], 
processed observation next is [0.0, 0.782608695652174, 0.518005540166205, 0.4, 0.055, 0.10220994475138122, 0.5, 0.44539526801966584, 0.47534982155688904, 0.0, 1.0, 0.059302894191208065], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.0140257], dtype=float32), 0.9094152]. 
=============================================
[2019-04-07 12:09:33,101] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.7640208e-13 1.2568095e-10 9.7413998e-16 9.3362229e-10 8.0415058e-12
 9.9999917e-01 8.0318614e-07 2.1752256e-09], sum to 1.0000
[2019-04-07 12:09:33,101] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7392
[2019-04-07 12:09:33,206] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 43.0, 0.0, 0.0, 24.0, 23.07153507125205, -0.1126077564239715, 0.0, 1.0, 58067.9945000218], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4820400.0000, 
sim time next is 4822200.0000, 
raw observation next is [1.0, 45.0, 0.0, 0.0, 24.0, 23.18432387544205, -0.0518837748524126, 0.0, 1.0, 145302.92592218707], 
processed observation next is [0.0, 0.8260869565217391, 0.4903047091412743, 0.45, 0.0, 0.0, 0.5, 0.4320269896201709, 0.4827054083825291, 0.0, 1.0, 0.6919186948675575], 
reward next is 0.5938, 
noisyNet noise sample is [array([2.0140257], dtype=float32), 0.9094152]. 
=============================================
[2019-04-07 12:09:34,410] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:34,411] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:34,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run8
[2019-04-07 12:09:35,104] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:35,104] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:35,108] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run8
[2019-04-07 12:09:37,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:37,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:37,390] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run8
[2019-04-07 12:09:40,071] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:40,071] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:40,075] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run8
[2019-04-07 12:09:42,435] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:42,435] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:42,439] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run8
[2019-04-07 12:09:43,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:43,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:43,575] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run8
[2019-04-07 12:09:45,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:45,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:45,030] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run8
[2019-04-07 12:09:45,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:45,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:45,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run8
[2019-04-07 12:09:45,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:09:45,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:45,850] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run8
[2019-04-07 12:09:56,879] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-07 12:09:56,889] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:09:56,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:56,891] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run17
[2019-04-07 12:09:56,909] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:09:56,910] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:56,912] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run17
[2019-04-07 12:09:56,924] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:09:56,925] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:09:56,939] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run17
[2019-04-07 12:11:51,314] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 12:12:20,136] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 12:12:26,340] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 12:12:27,378] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 320000, evaluation results [320000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 12:13:06,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7986870e-18 5.3742021e-15 5.0050514e-21 4.7034598e-14 2.5191428e-17
 1.0000000e+00 1.5582519e-09 4.5468613e-14], sum to 1.0000
[2019-04-07 12:13:06,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5837
[2019-04-07 12:13:06,596] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 84.0, 87.0, 0.0, 24.0, 24.07971912619485, -0.04930785880700634, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 903600.0000, 
sim time next is 905400.0000, 
raw observation next is [1.9, 90.5, 97.0, 0.0, 24.0, 24.0121643777363, -0.0477049715568332, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.515235457063712, 0.905, 0.3233333333333333, 0.0, 0.5, 0.5010136981446918, 0.48409834281438896, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.588733], dtype=float32), -0.13700211]. 
=============================================
[2019-04-07 12:13:40,597] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2752528e-14 3.4389826e-12 7.2361633e-16 3.0840677e-11 3.6364627e-12
 1.0000000e+00 5.8090537e-09 1.7365850e-10], sum to 1.0000
[2019-04-07 12:13:40,598] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9107
[2019-04-07 12:13:40,760] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.05, 84.5, 0.0, 0.0, 24.0, 23.10545734434969, -0.166474366645841, 0.0, 1.0, 108330.14487676551], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1884600.0000, 
sim time next is 1886400.0000, 
raw observation next is [-5.6, 86.0, 0.0, 0.0, 24.0, 23.33262021354145, -0.1487387014740344, 0.0, 1.0, 54744.61810216985], 
processed observation next is [0.0, 0.8695652173913043, 0.30747922437673136, 0.86, 0.0, 0.0, 0.5, 0.4443850177951208, 0.4504204328419885, 0.0, 1.0, 0.26068865762938026], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.32765022], dtype=float32), 0.2381113]. 
=============================================
[2019-04-07 12:13:49,439] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.8189071e-17 4.2258474e-14 6.0683262e-20 1.6601280e-12 5.0498859e-15
 1.0000000e+00 1.5673604e-10 1.0747047e-12], sum to 1.0000
[2019-04-07 12:13:49,439] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5794
[2019-04-07 12:13:49,484] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 24.0, 23.34397309481487, 0.001818177349085566, 0.0, 1.0, 63869.87732797572], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1405800.0000, 
sim time next is 1407600.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 24.0, 23.4256579421614, 0.03145178370199312, 0.0, 1.0, 39612.315057159874], 
processed observation next is [1.0, 0.30434782608695654, 0.44598337950138506, 1.0, 0.0, 0.0, 0.5, 0.4521381618467834, 0.5104839279006644, 0.0, 1.0, 0.18863007170076132], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.232287], dtype=float32), 1.0174296]. 
=============================================
[2019-04-07 12:14:03,583] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2034025e-18 6.4204581e-15 3.0957344e-20 1.7649863e-13 4.7025198e-17
 1.0000000e+00 6.0611821e-11 4.5449626e-14], sum to 1.0000
[2019-04-07 12:14:03,583] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6179
[2019-04-07 12:14:03,604] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 62.0, 74.0, 0.0, 24.0, 23.89652084507836, -0.1179575648649945, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1956600.0000, 
sim time next is 1958400.0000, 
raw observation next is [-2.8, 62.0, 52.0, 0.0, 24.0, 23.68130879924261, -0.1367859325714658, 1.0, 1.0, 55544.68722143257], 
processed observation next is [1.0, 0.6956521739130435, 0.38504155124653744, 0.62, 0.17333333333333334, 0.0, 0.5, 0.47344239993688425, 0.45440468914284476, 1.0, 1.0, 0.26449851057825036], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.88798386], dtype=float32), -0.25899807]. 
=============================================
[2019-04-07 12:14:05,206] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2019795e-14 2.1105203e-12 1.9351749e-16 2.7494222e-11 1.3161423e-13
 1.0000000e+00 1.9478910e-09 1.0206930e-10], sum to 1.0000
[2019-04-07 12:14:05,206] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1181
[2019-04-07 12:14:05,243] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [18.3, 65.0, 104.0, 0.0, 24.0, 23.59164762655909, 0.1423501710101056, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1177200.0000, 
sim time next is 1179000.0000, 
raw observation next is [18.55, 64.0, 80.0, 0.0, 24.0, 23.61156634778599, 0.1382054957379753, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.976454293628809, 0.64, 0.26666666666666666, 0.0, 0.5, 0.46763052898216567, 0.546068498579325, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1599416], dtype=float32), -0.27521068]. 
=============================================
[2019-04-07 12:14:05,295] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[77.37004 ]
 [77.656586]
 [77.81226 ]
 [77.772255]
 [77.631966]], R is [[77.11267853]
 [77.34155273]
 [77.56813812]
 [77.79245758]
 [78.014534  ]].
[2019-04-07 12:14:12,252] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.20880395e-17 1.08322758e-14 1.06200136e-20 3.19292032e-12
 2.62333515e-16 1.00000000e+00 2.06979989e-10 1.81872399e-11], sum to 1.0000
[2019-04-07 12:14:12,253] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9754
[2019-04-07 12:14:12,391] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 24.0, 23.44535051683347, -0.006592188555268256, 1.0, 1.0, 69683.46936116897], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1359000.0000, 
sim time next is 1360800.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 24.0, 23.19364287383047, 0.03981324230975087, 1.0, 1.0, 33774.747092015714], 
processed observation next is [1.0, 0.782608695652174, 0.4764542936288089, 0.96, 0.0, 0.0, 0.5, 0.43280357281920584, 0.5132710807699169, 1.0, 1.0, 0.16083212900959865], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.29384702], dtype=float32), 0.29338434]. 
=============================================
[2019-04-07 12:14:18,059] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8592575e-17 1.2654163e-15 3.1046058e-19 2.8585227e-14 4.1753701e-15
 1.0000000e+00 1.0269634e-10 2.9876633e-12], sum to 1.0000
[2019-04-07 12:14:18,059] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0594
[2019-04-07 12:14:18,107] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.2, 96.0, 0.0, 0.0, 24.0, 23.47598714787343, 0.00750651284925891, 0.0, 1.0, 51183.11739328469], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1485000.0000, 
sim time next is 1486800.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 24.0, 23.4774743629754, 0.01168818779231323, 0.0, 1.0, 39783.76068118694], 
processed observation next is [1.0, 0.21739130434782608, 0.5235457063711911, 0.96, 0.0, 0.0, 0.5, 0.45645619691461664, 0.5038960625974377, 0.0, 1.0, 0.18944647943422352], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5795706], dtype=float32), -0.5481911]. 
=============================================
[2019-04-07 12:15:06,508] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-07 12:15:06,508] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:15:06,508] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:15:06,510] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run18
[2019-04-07 12:15:06,526] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:15:06,527] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:15:06,535] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:15:06,536] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:15:06,546] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run18
[2019-04-07 12:15:06,570] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run18
[2019-04-07 12:15:44,403] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.11901487], dtype=float32), 0.12851222]
[2019-04-07 12:15:44,403] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [14.6, 74.0, 0.0, 0.0, 24.0, 25.15831149548703, 0.3140005402843013, 1.0, 1.0, 0.0]
[2019-04-07 12:15:44,403] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 12:15:44,403] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [2.0908682e-15 3.3367878e-13 5.0178099e-18 9.3300263e-12 8.8129509e-14
 1.0000000e+00 5.5001954e-09 3.4232978e-11], sampled 0.04055140491100806
[2019-04-07 12:16:58,615] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.3337 70927233.8163 166.2180
[2019-04-07 12:17:28,686] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 12:17:37,766] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2785.1044 83805026.4189 32.8860
[2019-04-07 12:17:38,800] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 340000, evaluation results [340000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.333747436773, 70927233.8162715, 166.21801628696863, 2785.104390613988, 83805026.41892925, 32.88598103848735]
[2019-04-07 12:17:44,950] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.15628195e-14 4.15760525e-13 2.23598805e-16 1.49747471e-11
 1.86578007e-13 1.00000000e+00 7.69065434e-09 1.05006455e-10], sum to 1.0000
[2019-04-07 12:17:44,950] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2243
[2019-04-07 12:17:45,099] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 47.0, 82.5, 199.5, 24.0, 23.11971074776517, -0.1446723803263576, 0.0, 1.0, 12465.515629789768], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2390400.0000, 
sim time next is 2392200.0000, 
raw observation next is [-0.3, 46.0, 79.0, 58.0, 24.0, 23.0574881759484, -0.1571896080946062, 0.0, 1.0, 42566.816847692324], 
processed observation next is [0.0, 0.6956521739130435, 0.4542936288088643, 0.46, 0.2633333333333333, 0.06408839779005525, 0.5, 0.4214573479957, 0.44760346396846457, 0.0, 1.0, 0.20269912784615393], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.03910581], dtype=float32), -0.3857748]. 
=============================================
[2019-04-07 12:18:13,620] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7560833e-18 1.2916098e-16 6.4284030e-21 6.7018290e-14 8.3698959e-15
 1.0000000e+00 4.6672562e-11 1.8235060e-12], sum to 1.0000
[2019-04-07 12:18:13,620] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0208
[2019-04-07 12:18:13,704] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 24.0, 23.89342025026931, 0.1111022976596665, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4665600.0000, 
sim time next is 4667400.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 24.0, 23.75524481396849, 0.07077199314276715, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.0, 0.518005540166205, 0.52, 0.0, 0.0, 0.5, 0.47960373449737403, 0.5235906643809224, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9109953], dtype=float32), -0.419993]. 
=============================================
[2019-04-07 12:18:19,572] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8035515e-19 5.5594510e-16 1.9690205e-22 1.9824328e-14 1.6411958e-17
 1.0000000e+00 3.6957620e-10 5.6808189e-14], sum to 1.0000
[2019-04-07 12:18:19,574] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8082
[2019-04-07 12:18:19,640] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.2, 75.5, 113.0, 811.0, 24.0, 24.52651398189222, 0.1338181423062676, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3238200.0000, 
sim time next is 3240000.0000, 
raw observation next is [-2.0, 71.0, 114.0, 817.0, 24.0, 24.43016855014988, 0.2680136266170396, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.40720221606648205, 0.71, 0.38, 0.9027624309392265, 0.5, 0.5358473791791566, 0.5893378755390132, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2597972], dtype=float32), -1.0166254]. 
=============================================
[2019-04-07 12:18:19,649] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[112.24627]
 [112.19323]
 [111.78185]
 [111.49899]
 [110.53563]], R is [[112.03475189]
 [111.91440582]
 [111.7952652 ]
 [111.67731476]
 [111.56053925]].
[2019-04-07 12:18:21,817] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6631646e-16 3.2402135e-13 1.9866645e-18 1.4685893e-11 6.8333333e-14
 1.0000000e+00 6.5637900e-09 4.6195790e-12], sum to 1.0000
[2019-04-07 12:18:21,817] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4129
[2019-04-07 12:18:22,044] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 64.0, 0.0, 0.0, 24.0, 22.57725668918288, -0.3212893539362942, 0.0, 1.0, 62795.296892784594], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2790000.0000, 
sim time next is 2791800.0000, 
raw observation next is [-6.5, 64.0, 0.0, 0.0, 24.0, 22.63212769654566, -0.1696026111630373, 1.0, 1.0, 156338.90801240606], 
processed observation next is [1.0, 0.30434782608695654, 0.28254847645429365, 0.64, 0.0, 0.0, 0.5, 0.3860106413788049, 0.4434657962789876, 1.0, 1.0, 0.7444709905352669], 
reward next is 0.5412, 
noisyNet noise sample is [array([-1.9061003], dtype=float32), 0.65968615]. 
=============================================
[2019-04-07 12:18:33,401] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:18:33,401] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:18:33,411] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run9
[2019-04-07 12:18:34,372] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6624138e-15 4.1422809e-13 4.1987655e-17 1.6085917e-11 9.8877915e-13
 1.0000000e+00 3.8748196e-09 8.3207913e-11], sum to 1.0000
[2019-04-07 12:18:34,383] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0743
[2019-04-07 12:18:34,445] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 65.0, 0.0, 0.0, 24.0, 23.40571844460761, -0.06965827597148914, 0.0, 1.0, 72248.38818350075], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3013200.0000, 
sim time next is 3015000.0000, 
raw observation next is [-3.75, 65.0, 0.0, 0.0, 24.0, 23.43690126162169, -0.07442679232062639, 0.0, 1.0, 33872.499877905524], 
processed observation next is [0.0, 0.9130434782608695, 0.3587257617728532, 0.65, 0.0, 0.0, 0.5, 0.4530751051351407, 0.4751910692264579, 0.0, 1.0, 0.1612976184662168], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2937503], dtype=float32), -0.03842168]. 
=============================================
[2019-04-07 12:18:34,464] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[82.070465]
 [81.03366 ]
 [80.58945 ]
 [80.30324 ]
 [79.25357 ]], R is [[82.16827393]
 [82.28826904]
 [82.46538544]
 [82.64073181]
 [82.47916412]].
[2019-04-07 12:18:34,599] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.7852446e-14 3.0735120e-13 1.5667938e-16 6.0533634e-10 1.7282267e-12
 1.0000000e+00 1.9422789e-08 7.6076472e-11], sum to 1.0000
[2019-04-07 12:18:34,600] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6617
[2019-04-07 12:18:34,669] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 24.0, 23.49151510538731, 0.01703500952706579, 0.0, 1.0, 34862.09011888018], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3546000.0000, 
sim time next is 3547800.0000, 
raw observation next is [-2.5, 65.5, 0.0, 0.0, 24.0, 23.44884269487106, 0.0130093272047655, 0.0, 1.0, 53880.91300912498], 
processed observation next is [0.0, 0.043478260869565216, 0.39335180055401664, 0.655, 0.0, 0.0, 0.5, 0.45407022457258844, 0.5043364424015885, 0.0, 1.0, 0.25657577623392847], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.65429974], dtype=float32), 0.28077507]. 
=============================================
[2019-04-07 12:18:43,998] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7778836e-17 5.5685593e-15 1.4090233e-20 1.9508605e-14 9.5552211e-15
 1.0000000e+00 5.3014426e-10 9.2564433e-13], sum to 1.0000
[2019-04-07 12:18:43,998] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4482
[2019-04-07 12:18:44,045] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 92.0, 101.0, 653.0, 24.0, 24.3019114941413, 0.2144291179993056, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3231000.0000, 
sim time next is 3232800.0000, 
raw observation next is [-3.0, 92.0, 105.0, 702.5, 24.0, 24.5409891689949, 0.2505646736630376, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.92, 0.35, 0.7762430939226519, 0.5, 0.5450824307495751, 0.5835215578876792, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09189964], dtype=float32), 1.4110756]. 
=============================================
[2019-04-07 12:19:00,469] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:19:00,469] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:19:00,472] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run9
[2019-04-07 12:19:12,291] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:19:12,291] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:19:12,295] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run9
[2019-04-07 12:19:15,114] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8668190e-13 2.1756727e-11 6.0805751e-15 1.1415071e-10 5.1190371e-12
 9.9999976e-01 2.4689345e-07 4.2842747e-09], sum to 1.0000
[2019-04-07 12:19:15,114] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0658
[2019-04-07 12:19:15,171] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 36.0, 0.0, 0.0, 24.0, 23.58221507264819, -0.07896775855367655, 0.0, 1.0, 36939.952854753115], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4915800.0000, 
sim time next is 4917600.0000, 
raw observation next is [1.0, 36.0, 0.0, 0.0, 24.0, 23.54180992298794, -0.07073883615279608, 0.0, 1.0, 53140.78956435351], 
processed observation next is [0.0, 0.9565217391304348, 0.4903047091412743, 0.36, 0.0, 0.0, 0.5, 0.46181749358232843, 0.476420387949068, 0.0, 1.0, 0.2530513788778738], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1211528], dtype=float32), -0.0742766]. 
=============================================
[2019-04-07 12:19:23,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:19:23,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:19:23,420] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run9
[2019-04-07 12:19:34,774] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-07 12:19:34,775] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:19:34,775] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:19:34,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run19
[2019-04-07 12:19:34,794] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:19:34,795] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:19:34,798] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:19:34,798] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:19:34,799] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run19
[2019-04-07 12:19:34,834] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run19
[2019-04-07 12:19:34,968] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:19:34,968] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:19:34,972] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run9
[2019-04-07 12:20:26,634] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.11938271], dtype=float32), 0.12948586]
[2019-04-07 12:20:26,634] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-3.029410671, 75.86526302, 0.0, 0.0, 24.0, 23.42202225961771, -0.05442853674829782, 0.0, 1.0, 59370.631218854025]
[2019-04-07 12:20:26,634] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 12:20:26,635] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [4.2614105e-15 4.6845893e-13 1.2150034e-17 1.5203082e-11 2.0249954e-13
 1.0000000e+00 8.4426333e-09 5.5377064e-11], sampled 0.38187915384866844
[2019-04-07 12:21:32,509] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 12:22:06,569] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.11938271], dtype=float32), 0.12948586]
[2019-04-07 12:22:06,569] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [1.352770084, 49.274673775, 0.0, 0.0, 24.0, 23.94507267671209, 0.03082892764726587, 0.0, 1.0, 0.0]
[2019-04-07 12:22:06,569] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 12:22:06,570] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.1711059e-13 8.4679876e-12 7.4367846e-16 1.6922108e-10 2.9902112e-12
 9.9999988e-01 6.2554307e-08 5.6390409e-10], sampled 0.15492612698889352
[2019-04-07 12:22:09,569] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 12:22:13,091] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 12:22:14,129] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 360000, evaluation results [360000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 12:22:16,227] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.3825766e-17 1.1879785e-14 5.2463494e-21 2.5668207e-13 3.7316291e-15
 1.0000000e+00 9.4649677e-10 3.8436624e-12], sum to 1.0000
[2019-04-07 12:22:16,227] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9569
[2019-04-07 12:22:16,360] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.35, 49.0, 139.0, 813.0, 24.0, 25.72333956081928, 0.483529082516235, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4627800.0000, 
sim time next is 4629600.0000, 
raw observation next is [4.7, 49.0, 171.0, 706.0, 24.0, 24.9094957767478, 0.4222584446461985, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.592797783933518, 0.49, 0.57, 0.7801104972375691, 0.5, 0.5757913147289834, 0.6407528148820661, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.94517845], dtype=float32), 0.095842905]. 
=============================================
[2019-04-07 12:22:20,274] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8643587e-15 6.6961946e-14 1.2278152e-19 1.6477272e-12 2.6848930e-14
 1.0000000e+00 2.7940490e-09 2.1695154e-11], sum to 1.0000
[2019-04-07 12:22:20,274] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7388
[2019-04-07 12:22:20,323] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 61.0, 172.0, 9.0, 24.0, 24.47507118068014, 0.1222875585693908, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4528800.0000, 
sim time next is 4530600.0000, 
raw observation next is [1.5, 59.0, 221.0, 18.0, 24.0, 24.53948797679122, 0.1434231064112514, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.5041551246537397, 0.59, 0.7366666666666667, 0.019889502762430938, 0.5, 0.5449573313992685, 0.5478077021370839, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3017601], dtype=float32), 0.86704546]. 
=============================================
[2019-04-07 12:22:22,370] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0982343e-16 5.8756873e-14 7.0772721e-18 3.3453095e-12 8.1774458e-14
 1.0000000e+00 1.3910924e-08 8.8540411e-11], sum to 1.0000
[2019-04-07 12:22:22,370] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6861
[2019-04-07 12:22:22,421] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 54.5, 0.0, 0.0, 24.0, 23.1333628205273, 0.01242713945565701, 0.0, 1.0, 151217.02992129704], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4566600.0000, 
sim time next is 4568400.0000, 
raw observation next is [2.0, 57.0, 0.0, 0.0, 24.0, 23.71388905783028, 0.1360078894060998, 0.0, 1.0, 77414.47968257799], 
processed observation next is [1.0, 0.9130434782608695, 0.518005540166205, 0.57, 0.0, 0.0, 0.5, 0.4761574214858566, 0.5453359631353666, 0.0, 1.0, 0.3686403794408476], 
reward next is 0.9171, 
noisyNet noise sample is [array([0.5154289], dtype=float32), -0.1203091]. 
=============================================
[2019-04-07 12:22:22,748] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:22:22,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:22:22,754] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run9
[2019-04-07 12:22:42,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:22:42,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:22:42,428] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run9
[2019-04-07 12:22:42,858] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:22:42,858] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:22:42,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run9
[2019-04-07 12:22:43,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:22:43,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:22:43,577] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run9
[2019-04-07 12:22:45,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:22:45,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:22:45,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run9
[2019-04-07 12:22:49,099] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:22:49,099] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:22:49,102] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run9
[2019-04-07 12:22:54,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:22:54,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:22:54,076] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run9
[2019-04-07 12:22:56,682] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:22:56,682] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:22:56,686] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run9
[2019-04-07 12:22:56,780] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:22:56,780] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:22:56,781] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:22:56,790] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:22:56,786] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run9
[2019-04-07 12:22:56,878] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run9
[2019-04-07 12:22:58,538] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:22:58,538] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:22:58,542] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run9
[2019-04-07 12:23:19,116] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.1295197e-17 2.8398338e-14 1.7865355e-19 1.0712966e-13 1.4575746e-15
 1.0000000e+00 6.1090377e-10 6.2686761e-12], sum to 1.0000
[2019-04-07 12:23:19,117] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1524
[2019-04-07 12:23:19,271] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 59.0, 86.5, 0.0, 24.0, 24.26261156346024, -0.0338705532412921, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 226800.0000, 
sim time next is 228600.0000, 
raw observation next is [-3.1, 60.5, 56.0, 0.0, 24.0, 23.7452468400721, -0.1159206941342354, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.37673130193905824, 0.605, 0.18666666666666668, 0.0, 0.5, 0.47877057000600826, 0.4613597686219215, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3083769], dtype=float32), -0.5637123]. 
=============================================
[2019-04-07 12:23:22,988] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2855146e-16 4.9390464e-14 3.5212283e-19 2.2225095e-12 3.2558422e-14
 1.0000000e+00 6.0426009e-10 4.8855711e-12], sum to 1.0000
[2019-04-07 12:23:22,989] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8487
[2019-04-07 12:23:23,207] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.3, 59.5, 0.0, 0.0, 24.0, 23.15749448532006, -0.1059590102945887, 0.0, 1.0, 85819.98732647924], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 765000.0000, 
sim time next is 766800.0000, 
raw observation next is [-5.6, 61.0, 0.0, 0.0, 24.0, 23.29382603210841, -0.09755012647713439, 0.0, 1.0, 53535.74897241354], 
processed observation next is [1.0, 0.9130434782608695, 0.30747922437673136, 0.61, 0.0, 0.0, 0.5, 0.44115216934236745, 0.46748329117428855, 0.0, 1.0, 0.254932137963874], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47097003], dtype=float32), -0.9557292]. 
=============================================
[2019-04-07 12:23:24,143] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1936795e-17 3.4031239e-14 2.2866891e-18 7.2590146e-12 4.3638985e-15
 1.0000000e+00 1.8794734e-10 6.4338633e-13], sum to 1.0000
[2019-04-07 12:23:24,143] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3823
[2019-04-07 12:23:24,207] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.9, 85.0, 0.0, 0.0, 24.0, 22.98608395398526, -0.1776876820047835, 0.0, 1.0, 43771.07920615668], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1989000.0000, 
sim time next is 1990800.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 24.0, 22.99209384573037, -0.186456608075525, 0.0, 1.0, 43362.298651584155], 
processed observation next is [1.0, 0.043478260869565216, 0.2908587257617729, 0.87, 0.0, 0.0, 0.5, 0.4160078204775308, 0.4378477973081583, 0.0, 1.0, 0.20648713643611502], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05011349], dtype=float32), -2.5326064]. 
=============================================
[2019-04-07 12:23:52,089] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.5885081e-15 1.0046811e-13 1.1997173e-17 2.8621987e-11 5.8048638e-14
 1.0000000e+00 1.0348531e-08 3.5449768e-11], sum to 1.0000
[2019-04-07 12:23:52,089] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2029
[2019-04-07 12:23:52,221] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 80.0, 132.5, 531.0, 24.0, 23.12349837600605, -0.08580170502769409, 0.0, 1.0, 18708.03034560342], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 568800.0000, 
sim time next is 570600.0000, 
raw observation next is [-1.2, 81.5, 127.0, 467.0, 24.0, 23.12083209370496, -0.08288043091897622, 0.0, 1.0, 21330.345031704743], 
processed observation next is [0.0, 0.6086956521739131, 0.42936288088642666, 0.815, 0.42333333333333334, 0.5160220994475138, 0.5, 0.42673600780874654, 0.47237318969367464, 0.0, 1.0, 0.1015730715795464], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5601627], dtype=float32), -1.0216442]. 
=============================================
[2019-04-07 12:24:33,417] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4212406e-15 8.2556473e-14 3.0146492e-18 1.1481162e-11 5.0765837e-13
 9.9999988e-01 9.8208844e-08 3.9820921e-11], sum to 1.0000
[2019-04-07 12:24:33,417] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1714
[2019-04-07 12:24:33,496] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.9, 80.5, 0.0, 0.0, 24.0, 23.07855635013314, -0.1866765146357185, 0.0, 1.0, 43827.527847416], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2608200.0000, 
sim time next is 2610000.0000, 
raw observation next is [-6.2, 83.0, 0.0, 0.0, 24.0, 23.0412529247003, -0.2132912357690787, 0.0, 1.0, 44007.77004249004], 
processed observation next is [1.0, 0.21739130434782608, 0.2908587257617729, 0.83, 0.0, 0.0, 0.5, 0.42010441039169155, 0.42890292141030706, 0.0, 1.0, 0.20956080972614305], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8152213], dtype=float32), -0.49534866]. 
=============================================
[2019-04-07 12:24:33,526] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[94.73838]
 [94.37748]
 [93.85144]
 [93.38875]
 [92.57588]], R is [[95.17133331]
 [95.21961975]
 [95.26742554]
 [95.31475067]
 [95.36160278]].
[2019-04-07 12:24:39,933] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5991103e-16 2.0184901e-13 2.9570389e-19 6.2530324e-12 7.1234099e-15
 1.0000000e+00 3.9882688e-09 2.9215970e-11], sum to 1.0000
[2019-04-07 12:24:39,934] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6408
[2019-04-07 12:24:40,118] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 68.0, 0.0, 0.0, 24.0, 23.52667645626747, -0.03720493695608579, 1.0, 1.0, 32971.897379841714], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2224800.0000, 
sim time next is 2226600.0000, 
raw observation next is [-4.55, 69.0, 0.0, 0.0, 24.0, 23.60461251670856, -0.1245740577996566, 1.0, 1.0, 37262.70052916998], 
processed observation next is [1.0, 0.782608695652174, 0.3365650969529086, 0.69, 0.0, 0.0, 0.5, 0.46705104305904666, 0.45847531406678116, 1.0, 1.0, 0.17744143109128563], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0575799], dtype=float32), 0.60841376]. 
=============================================
[2019-04-07 12:24:41,688] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-07 12:24:41,696] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:24:41,696] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:24:41,697] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:24:41,697] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:24:41,697] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:24:41,698] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:24:41,701] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run20
[2019-04-07 12:24:41,721] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run20
[2019-04-07 12:24:41,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run20
[2019-04-07 12:25:59,899] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.11901127], dtype=float32), 0.12967306]
[2019-04-07 12:25:59,900] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-4.5, 59.5, 152.0, 233.0, 24.0, 24.28757902515088, 0.01963097616992186, 1.0, 1.0, 0.0]
[2019-04-07 12:25:59,900] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 12:25:59,901] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [6.2202631e-15 4.8912372e-13 1.3324720e-17 1.1689736e-11 2.3453735e-13
 1.0000000e+00 1.0965936e-08 5.2523135e-11], sampled 0.505594177660002
[2019-04-07 12:26:37,194] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2788.9052 70927233.8163 166.2180
[2019-04-07 12:27:08,004] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 12:27:13,987] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 12:27:15,034] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 380000, evaluation results [380000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2788.9051760082016, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 12:27:48,161] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.6260034e-17 6.7608882e-14 2.3337820e-19 4.5202245e-12 7.2661827e-14
 1.0000000e+00 6.9479900e-10 3.7381604e-12], sum to 1.0000
[2019-04-07 12:27:48,162] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3685
[2019-04-07 12:27:48,216] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 62.0, 93.0, 0.0, 24.0, 24.00305743191608, -0.09222161783234918, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1954800.0000, 
sim time next is 1956600.0000, 
raw observation next is [-2.8, 62.0, 74.0, 0.0, 24.0, 23.89652084507836, -0.1179575648649945, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.38504155124653744, 0.62, 0.24666666666666667, 0.0, 0.5, 0.49137673708986335, 0.4606808117116685, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.22139677], dtype=float32), 0.1509362]. 
=============================================
[2019-04-07 12:28:03,595] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.2533774e-17 2.8691974e-13 4.9168679e-20 2.9260457e-12 2.8356337e-14
 1.0000000e+00 1.5892213e-10 3.1788971e-11], sum to 1.0000
[2019-04-07 12:28:03,596] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8311
[2019-04-07 12:28:03,656] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 30.0, 116.0, 830.0, 24.0, 24.45378068219987, 0.233025848342336, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4109400.0000, 
sim time next is 4111200.0000, 
raw observation next is [3.0, 31.0, 111.0, 812.0, 24.0, 25.33777082025347, 0.3453693409070701, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5457063711911359, 0.31, 0.37, 0.8972375690607735, 0.5, 0.6114809016877892, 0.61512311363569, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.98850685], dtype=float32), 1.7956462]. 
=============================================
[2019-04-07 12:28:05,946] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.8451791e-18 2.1078770e-16 4.1756122e-21 8.0830281e-13 3.3946280e-16
 1.0000000e+00 1.3357052e-11 1.1296155e-12], sum to 1.0000
[2019-04-07 12:28:05,946] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4934
[2019-04-07 12:28:06,024] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 93.0, 0.0, 0.0, 24.0, 23.33158078168603, -0.1177424042005908, 0.0, 1.0, 59462.73110687543], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2867400.0000, 
sim time next is 2869200.0000, 
raw observation next is [1.0, 93.0, 0.0, 0.0, 24.0, 23.41475660335237, -0.1042007194062623, 0.0, 1.0, 45613.02953718263], 
processed observation next is [1.0, 0.21739130434782608, 0.4903047091412743, 0.93, 0.0, 0.0, 0.5, 0.4512297169460308, 0.46526642686457925, 0.0, 1.0, 0.21720490255801253], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0082712], dtype=float32), -0.73875237]. 
=============================================
[2019-04-07 12:28:15,200] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1006697e-15 8.3921238e-13 3.7056641e-18 2.0034556e-12 3.3457351e-13
 1.0000000e+00 1.4516924e-08 7.8257789e-10], sum to 1.0000
[2019-04-07 12:28:15,200] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4642
[2019-04-07 12:28:15,267] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 82.0, 0.0, 0.0, 24.0, 22.84885637252431, -0.2213984326095102, 0.0, 1.0, 45122.77069256839], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2253600.0000, 
sim time next is 2255400.0000, 
raw observation next is [-7.55, 84.0, 0.0, 0.0, 24.0, 22.95123621652442, -0.1992238757109153, 0.0, 1.0, 45174.899155563704], 
processed observation next is [1.0, 0.08695652173913043, 0.25346260387811637, 0.84, 0.0, 0.0, 0.5, 0.41260301804370175, 0.43359204142969493, 0.0, 1.0, 0.2151185674074462], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.48333892], dtype=float32), -0.17968805]. 
=============================================
[2019-04-07 12:28:39,818] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.6158534e-15 6.0823341e-13 7.2079724e-18 2.7959012e-11 8.3623524e-14
 1.0000000e+00 6.1676744e-09 9.1452450e-11], sum to 1.0000
[2019-04-07 12:28:39,818] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6168
[2019-04-07 12:28:39,901] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 55.0, 116.0, 819.5, 24.0, 23.39603666220753, 0.02749921385375594, 0.0, 1.0, 18704.633052294335], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3585600.0000, 
sim time next is 3587400.0000, 
raw observation next is [-2.5, 52.5, 118.0, 823.0, 24.0, 23.43134786387991, 0.03665044513661635, 0.0, 1.0, 18702.24721808585], 
processed observation next is [0.0, 0.5217391304347826, 0.39335180055401664, 0.525, 0.3933333333333333, 0.9093922651933701, 0.5, 0.4526123219899925, 0.5122168150455387, 0.0, 1.0, 0.08905832008612309], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.15561184], dtype=float32), 0.5488713]. 
=============================================
[2019-04-07 12:28:45,828] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:28:45,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:28:45,834] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run10
[2019-04-07 12:28:50,414] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.2826008e-15 3.3857465e-14 1.7603137e-20 4.8736393e-12 5.8414604e-14
 1.0000000e+00 3.5773784e-10 3.3455135e-12], sum to 1.0000
[2019-04-07 12:28:50,415] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3286
[2019-04-07 12:28:50,481] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 93.0, 0.0, 0.0, 24.0, 23.27211185647654, -0.118855387341479, 0.0, 1.0, 88467.27213702495], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2865600.0000, 
sim time next is 2867400.0000, 
raw observation next is [1.0, 93.0, 0.0, 0.0, 24.0, 23.33158078168603, -0.1177424042005908, 0.0, 1.0, 59462.73110687543], 
processed observation next is [1.0, 0.17391304347826086, 0.4903047091412743, 0.93, 0.0, 0.0, 0.5, 0.44429839847383573, 0.4607525319331364, 0.0, 1.0, 0.2831558624136925], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05082888], dtype=float32), 0.44976893]. 
=============================================
[2019-04-07 12:29:10,341] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.2493814e-15 6.3886911e-13 1.5349352e-18 1.5653371e-11 3.5248374e-15
 1.0000000e+00 8.6395486e-09 2.1917160e-12], sum to 1.0000
[2019-04-07 12:29:10,342] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2529
[2019-04-07 12:29:10,416] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.5, 73.5, 0.0, 0.0, 24.0, 23.41380684075408, -0.01592669152576223, 0.0, 1.0, 46904.77143358478], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3288600.0000, 
sim time next is 3290400.0000, 
raw observation next is [-8.0, 77.0, 0.0, 0.0, 24.0, 23.36805844962743, -0.007191952175503123, 0.0, 1.0, 58996.74590085954], 
processed observation next is [1.0, 0.08695652173913043, 0.24099722991689754, 0.77, 0.0, 0.0, 0.5, 0.44733820413561914, 0.49760268260816565, 0.0, 1.0, 0.2809368852421883], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.3375983], dtype=float32), 1.5342364]. 
=============================================
[2019-04-07 12:29:17,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:29:17,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:29:17,184] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run10
[2019-04-07 12:29:18,029] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.861879e-16 6.443894e-14 4.341275e-19 9.226584e-13 5.646464e-15
 1.000000e+00 3.564594e-10 8.798201e-11], sum to 1.0000
[2019-04-07 12:29:18,029] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3333
[2019-04-07 12:29:18,065] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.55, 73.0, 0.0, 0.0, 24.0, 23.43989072903774, 0.04946517128123575, 0.0, 1.0, 67805.22609667761], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4494600.0000, 
sim time next is 4496400.0000, 
raw observation next is [-0.6, 73.0, 0.0, 0.0, 24.0, 23.77433260471673, 0.05728754581223572, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.44598337950138506, 0.73, 0.0, 0.0, 0.5, 0.4811943837263941, 0.5190958486040785, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5478197], dtype=float32), 0.44844505]. 
=============================================
[2019-04-07 12:29:23,903] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1671183e-14 1.4491221e-12 1.6489452e-18 1.8025709e-12 1.6887036e-13
 1.0000000e+00 7.8459443e-09 1.5114499e-10], sum to 1.0000
[2019-04-07 12:29:23,904] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4072
[2019-04-07 12:29:23,966] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 24.0, 23.29926359311625, -0.05216985317372739, 0.0, 1.0, 88494.22130036833], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3812400.0000, 
sim time next is 3814200.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 24.0, 23.47173175328187, -0.04150546559550296, 0.0, 1.0, 32083.054899188177], 
processed observation next is [1.0, 0.13043478260869565, 0.3518005540166205, 0.71, 0.0, 0.0, 0.5, 0.4559776461068224, 0.486164844801499, 0.0, 1.0, 0.1527764519008961], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.03273367], dtype=float32), 0.49512872]. 
=============================================
[2019-04-07 12:29:29,941] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-07 12:29:29,952] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:29:29,953] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:29:29,958] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:29:29,960] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run21
[2019-04-07 12:29:29,954] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:29:29,954] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:29:29,977] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:29:29,979] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run21
[2019-04-07 12:29:29,996] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run21
[2019-04-07 12:31:18,656] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.5307 70927233.8163 166.2180
[2019-04-07 12:31:56,348] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 12:31:59,380] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.5330 83805026.4189 32.8860
[2019-04-07 12:32:00,418] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 400000, evaluation results [400000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.5306997291827, 70927233.8162715, 166.21801628696863, 2784.5329620425596, 83805026.41892925, 32.88598103848735]
[2019-04-07 12:32:05,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:32:05,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:32:05,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run10
[2019-04-07 12:32:09,652] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1554204e-16 1.5917177e-14 7.3511386e-20 2.5761851e-12 1.3974486e-15
 1.0000000e+00 1.3699160e-10 6.6505156e-13], sum to 1.0000
[2019-04-07 12:32:09,652] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8852
[2019-04-07 12:32:09,688] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 80.0, 0.0, 0.0, 24.0, 23.84651606009406, 0.08152096451433599, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4431600.0000, 
sim time next is 4433400.0000, 
raw observation next is [2.0, 80.0, 0.0, 0.0, 24.0, 23.75133747826289, 0.06179791958475173, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.518005540166205, 0.8, 0.0, 0.0, 0.5, 0.47927812318857416, 0.5205993065282506, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2227447], dtype=float32), 0.94563675]. 
=============================================
[2019-04-07 12:32:18,594] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7023441e-14 9.0234677e-12 4.1766424e-16 2.1838387e-11 8.0638214e-14
 1.0000000e+00 2.1099691e-08 2.2023704e-10], sum to 1.0000
[2019-04-07 12:32:18,594] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0935
[2019-04-07 12:32:18,789] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 42.5, 0.0, 0.0, 24.0, 23.47912885047186, -0.007356715435244386, 0.0, 1.0, 45814.34745460638], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4152600.0000, 
sim time next is 4154400.0000, 
raw observation next is [-2.0, 46.0, 0.0, 0.0, 24.0, 23.46362925116072, -0.01964925917011498, 0.0, 1.0, 41042.78615656982], 
processed observation next is [0.0, 0.08695652173913043, 0.40720221606648205, 0.46, 0.0, 0.0, 0.5, 0.4553024375967268, 0.49345024694329503, 0.0, 1.0, 0.19544183884080865], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4614607], dtype=float32), -0.42254457]. 
=============================================
[2019-04-07 12:32:23,491] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:32:23,491] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:32:23,494] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run10
[2019-04-07 12:32:23,941] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2204877e-15 3.1120796e-13 1.0207341e-17 1.3767414e-11 2.2111820e-12
 1.0000000e+00 5.8986429e-09 4.3449459e-11], sum to 1.0000
[2019-04-07 12:32:23,941] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5523
[2019-04-07 12:32:24,372] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.5, 66.0, 0.0, 0.0, 24.0, 22.4295418528422, -0.2168694434277868, 1.0, 1.0, 149811.35813692477], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4001400.0000, 
sim time next is 4003200.0000, 
raw observation next is [-13.0, 63.0, 46.5, 222.0, 24.0, 23.87748233552614, -0.02116269018468491, 1.0, 1.0, 37375.41009068823], 
processed observation next is [1.0, 0.34782608695652173, 0.10249307479224376, 0.63, 0.155, 0.24530386740331492, 0.5, 0.48979019462717827, 0.49294576993843836, 1.0, 1.0, 0.17797814328899159], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9158338], dtype=float32), 0.54717463]. 
=============================================
[2019-04-07 12:32:31,274] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:32:31,274] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:32:31,294] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run10
[2019-04-07 12:32:32,788] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3650020e-13 1.3708348e-11 7.7095261e-16 7.9302664e-10 3.5621305e-11
 9.9999964e-01 3.4601632e-07 2.0693187e-09], sum to 1.0000
[2019-04-07 12:32:32,788] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4787
[2019-04-07 12:32:32,926] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 49.0, 0.0, 0.0, 24.0, 23.470481716833, -0.1063014611674857, 0.0, 1.0, 36219.020163349014], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4258800.0000, 
sim time next is 4260600.0000, 
raw observation next is [3.0, 49.0, 0.0, 0.0, 24.0, 23.46553807756678, -0.1065416492988902, 0.0, 1.0, 37201.58341066076], 
processed observation next is [0.0, 0.30434782608695654, 0.5457063711911359, 0.49, 0.0, 0.0, 0.5, 0.4554615064638983, 0.46448611690036995, 0.0, 1.0, 0.17715039719362266], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.49546036], dtype=float32), 0.6589914]. 
=============================================
[2019-04-07 12:32:49,443] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.3580325e-17 1.6257194e-15 2.7888702e-19 1.2259001e-13 7.3042489e-16
 1.0000000e+00 1.5134866e-10 5.9679345e-13], sum to 1.0000
[2019-04-07 12:32:49,443] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5534
[2019-04-07 12:32:49,559] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.45, 33.5, 103.0, 0.0, 24.0, 26.70967376445037, 0.6898723166674725, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4375800.0000, 
sim time next is 4377600.0000, 
raw observation next is [13.0, 35.0, 71.0, 0.0, 24.0, 27.0772891328497, 0.6072929109725386, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.8227146814404434, 0.35, 0.23666666666666666, 0.0, 0.5, 0.7564407610708083, 0.7024309703241794, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.11891855], dtype=float32), -1.7945495]. 
=============================================
[2019-04-07 12:32:52,473] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4861973e-16 1.1891347e-14 1.7669346e-19 1.2132558e-12 4.4601316e-15
 1.0000000e+00 1.1849960e-10 6.7617851e-12], sum to 1.0000
[2019-04-07 12:32:52,473] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2495
[2019-04-07 12:32:52,568] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.9, 32.0, 149.0, 314.5, 24.0, 26.56112087855076, 0.6582731559141878, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4374000.0000, 
sim time next is 4375800.0000, 
raw observation next is [13.45, 33.5, 103.0, 0.0, 24.0, 26.70967376445037, 0.6898723166674725, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.8351800554016622, 0.335, 0.3433333333333333, 0.0, 0.5, 0.7258061470375307, 0.7299574388891575, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05989246], dtype=float32), 1.0759999]. 
=============================================
[2019-04-07 12:32:58,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:32:58,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:32:58,253] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run10
[2019-04-07 12:33:16,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:33:16,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:33:16,971] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run10
[2019-04-07 12:33:17,452] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:33:17,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:33:17,456] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run10
[2019-04-07 12:33:17,802] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.1130876e-16 1.7904621e-15 5.8286661e-20 6.5225887e-14 5.2757014e-17
 1.0000000e+00 7.9729737e-11 8.8626827e-13], sum to 1.0000
[2019-04-07 12:33:17,802] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1425
[2019-04-07 12:33:17,890] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 47.0, 104.5, 615.5, 24.0, 24.45510059295397, 0.1331378834420426, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5043600.0000, 
sim time next is 5045400.0000, 
raw observation next is [2.0, 44.0, 112.0, 698.0, 24.0, 24.66969494848518, 0.2004939973055495, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.518005540166205, 0.44, 0.37333333333333335, 0.7712707182320442, 0.5, 0.555807912373765, 0.5668313324351831, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.32287315], dtype=float32), -0.05852625]. 
=============================================
[2019-04-07 12:33:20,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:33:20,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:33:20,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run10
[2019-04-07 12:33:21,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:33:21,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:33:21,029] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run10
[2019-04-07 12:33:25,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:33:25,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:33:25,341] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run10
[2019-04-07 12:33:25,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:33:25,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:33:25,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run10
[2019-04-07 12:33:25,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:33:25,950] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:33:25,962] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run10
[2019-04-07 12:33:26,546] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:33:26,546] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:33:26,550] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run10
[2019-04-07 12:33:27,141] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:33:27,141] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:33:27,144] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run10
[2019-04-07 12:33:28,646] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:33:28,646] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:33:28,650] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run10
[2019-04-07 12:34:17,099] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.6373675e-15 1.2628449e-13 5.6891539e-19 4.6114623e-12 2.2183103e-14
 1.0000000e+00 3.1010765e-09 1.7217863e-10], sum to 1.0000
[2019-04-07 12:34:17,099] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1352
[2019-04-07 12:34:17,331] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 24.0, 23.08123692412476, -0.1895042037622409, 1.0, 1.0, 41351.7755679591], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2014200.0000, 
sim time next is 2016000.0000, 
raw observation next is [-6.2, 87.0, 15.0, 0.0, 24.0, 23.22366489891439, -0.2014414853704705, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.2908587257617729, 0.87, 0.05, 0.0, 0.5, 0.4353054082428658, 0.43285283820984316, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2802484], dtype=float32), -0.020618068]. 
=============================================
[2019-04-07 12:34:17,335] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[99.181015]
 [97.43776 ]
 [97.390335]
 [97.433395]
 [97.34516 ]], R is [[100.11967468]
 [100.11847687]
 [100.11729431]
 [100.11611938]
 [100.11495972]].
[2019-04-07 12:34:29,500] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3266104e-15 4.3062556e-13 9.6733685e-19 2.6780540e-11 2.9434807e-13
 1.0000000e+00 4.1855892e-09 7.7364608e-11], sum to 1.0000
[2019-04-07 12:34:29,500] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1141
[2019-04-07 12:34:29,622] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 47.0, 204.5, 179.0, 24.0, 23.67909252526408, -0.01538467984130173, 1.0, 1.0, 65499.4212603725], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2638800.0000, 
sim time next is 2640600.0000, 
raw observation next is [-0.04999999999999999, 45.0, 164.0, 211.0, 24.0, 24.18013384126765, 0.04240738872275782, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.461218836565097, 0.45, 0.5466666666666666, 0.23314917127071824, 0.5, 0.5150111534389709, 0.5141357962409193, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.44732714], dtype=float32), -0.57240236]. 
=============================================
[2019-04-07 12:34:29,987] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1957468e-17 3.3463270e-14 1.4390566e-21 4.4134716e-14 2.2364060e-16
 1.0000000e+00 4.6988403e-11 5.4951798e-14], sum to 1.0000
[2019-04-07 12:34:29,987] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1999
[2019-04-07 12:34:30,027] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 100.0, 95.0, 0.0, 24.0, 23.22929860563525, 0.09203890067655063, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1258200.0000, 
sim time next is 1260000.0000, 
raw observation next is [13.8, 100.0, 86.0, 0.0, 24.0, 23.23393831025533, 0.09031052328664896, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.844875346260388, 1.0, 0.2866666666666667, 0.0, 0.5, 0.43616152585461077, 0.5301035077622164, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4180817], dtype=float32), -0.7720294]. 
=============================================
[2019-04-07 12:34:30,038] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[103.50738 ]
 [100.86201 ]
 [ 97.051704]
 [ 92.010895]
 [ 88.37744 ]], R is [[103.15681458]
 [103.12524414]
 [103.09399414]
 [103.06305695]
 [103.03242493]].
[2019-04-07 12:34:43,386] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-07 12:34:43,386] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:34:43,386] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:34:43,388] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run22
[2019-04-07 12:34:43,403] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:34:43,407] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:34:43,410] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run22
[2019-04-07 12:34:43,445] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:34:43,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:34:43,448] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run22
[2019-04-07 12:35:17,724] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.12026848], dtype=float32), 0.13193119]
[2019-04-07 12:35:17,724] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [14.92199605, 86.88608993, 0.0, 0.0, 24.0, 23.62776923531906, 0.1479476106199552, 0.0, 1.0, 0.0]
[2019-04-07 12:35:17,724] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 12:35:17,725] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [4.6861013e-16 8.3576165e-14 1.2127385e-18 2.4252959e-12 2.8407766e-14
 1.0000000e+00 2.5810580e-09 1.1255427e-11], sampled 0.16112497329392172
[2019-04-07 12:36:04,576] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12026848], dtype=float32), 0.13193119]
[2019-04-07 12:36:04,576] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [9.5, 66.0, 0.0, 0.0, 24.0, 23.7006838129829, -0.006879480807802606, 0.0, 1.0, 0.0]
[2019-04-07 12:36:04,576] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 12:36:04,578] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [2.0478788e-15 3.0790217e-13 7.2054429e-18 7.8305192e-12 8.7332336e-14
 1.0000000e+00 5.9174390e-09 3.4285904e-11], sampled 0.3544584388234344
[2019-04-07 12:36:34,450] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 12:37:08,401] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 12:37:13,537] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 12:37:14,582] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 420000, evaluation results [420000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 12:38:04,287] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.4645904e-18 1.2754755e-14 2.4805766e-19 6.4345596e-14 2.5035204e-15
 1.0000000e+00 1.8367900e-10 5.8972840e-12], sum to 1.0000
[2019-04-07 12:38:04,288] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5292
[2019-04-07 12:38:04,428] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 88.0, 80.0, 0.0, 24.0, 24.34004056685248, 0.05639749236054133, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1693800.0000, 
sim time next is 1695600.0000, 
raw observation next is [1.1, 88.0, 66.5, 0.0, 24.0, 23.62009751846091, 0.05321254951392802, 1.0, 1.0, 12453.607780153683], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.88, 0.22166666666666668, 0.0, 0.5, 0.4683414598717424, 0.5177375165046426, 1.0, 1.0, 0.059302894191208017], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.48734647], dtype=float32), -0.76618177]. 
=============================================
[2019-04-07 12:38:20,054] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5970074e-16 1.4985067e-14 2.3978262e-20 2.7964477e-13 4.3459212e-16
 1.0000000e+00 6.6581030e-10 1.4283934e-11], sum to 1.0000
[2019-04-07 12:38:20,054] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1500
[2019-04-07 12:38:20,199] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 61.5, 113.0, 799.0, 24.0, 24.33389516667464, -8.807402004478344e-05, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2723400.0000, 
sim time next is 2725200.0000, 
raw observation next is [-6.0, 59.0, 111.0, 793.5, 24.0, 23.62489910904625, 0.06570767437130122, 1.0, 1.0, 100136.10214338783], 
processed observation next is [1.0, 0.5652173913043478, 0.296398891966759, 0.59, 0.37, 0.8767955801104972, 0.5, 0.4687415924205209, 0.5219025581237671, 1.0, 1.0, 0.47683858163518017], 
reward next is 0.8089, 
noisyNet noise sample is [array([-1.1326783], dtype=float32), -2.4325833]. 
=============================================
[2019-04-07 12:38:20,537] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6524223e-16 5.4343119e-13 2.6091693e-19 1.6062309e-11 1.0440616e-13
 1.0000000e+00 8.3265111e-10 7.1833761e-11], sum to 1.0000
[2019-04-07 12:38:20,538] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0996
[2019-04-07 12:38:20,615] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 82.0, 0.0, 0.0, 24.0, 22.26834370621, -0.4191334817690786, 0.0, 1.0, 45729.42892574455], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1922400.0000, 
sim time next is 1924200.0000, 
raw observation next is [-9.2, 86.5, 0.0, 0.0, 24.0, 22.1222960665837, -0.4422977197331925, 0.0, 1.0, 45486.07893552239], 
processed observation next is [1.0, 0.2608695652173913, 0.20775623268698065, 0.865, 0.0, 0.0, 0.5, 0.3435246722153084, 0.3525674267556025, 0.0, 1.0, 0.21660037588343994], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5897324], dtype=float32), -2.401009]. 
=============================================
[2019-04-07 12:38:23,510] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6199440e-12 1.0408864e-10 4.0972173e-14 4.9687759e-10 2.8952210e-11
 9.9999869e-01 1.3507353e-06 1.0780724e-08], sum to 1.0000
[2019-04-07 12:38:23,512] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1299
[2019-04-07 12:38:23,572] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 60.0, 0.0, 0.0, 24.0, 22.08889564366193, -0.4313412988888818, 0.0, 1.0, 44998.93868334571], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2440800.0000, 
sim time next is 2442600.0000, 
raw observation next is [-9.2, 60.5, 0.0, 0.0, 24.0, 22.01711986152374, -0.4534257165944902, 0.0, 1.0, 44864.44699967937], 
processed observation next is [0.0, 0.2608695652173913, 0.20775623268698065, 0.605, 0.0, 0.0, 0.5, 0.3347599884603116, 0.3488580944685033, 0.0, 1.0, 0.213640223807997], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.26832616], dtype=float32), -0.21068546]. 
=============================================
[2019-04-07 12:38:27,265] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0264865e-13 4.7017980e-11 1.1224403e-15 7.3452322e-10 4.0408298e-11
 9.9999988e-01 1.2563176e-07 2.0886979e-09], sum to 1.0000
[2019-04-07 12:38:27,265] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4295
[2019-04-07 12:38:27,392] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.35, 29.5, 0.0, 0.0, 24.0, 23.04770072513502, -0.1730278788771231, 0.0, 1.0, 131026.23995899833], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2489400.0000, 
sim time next is 2491200.0000, 
raw observation next is [-0.7, 29.0, 0.0, 0.0, 24.0, 23.48504060337155, -0.1135419686095763, 0.0, 1.0, 46579.575175931765], 
processed observation next is [0.0, 0.8695652173913043, 0.443213296398892, 0.29, 0.0, 0.0, 0.5, 0.4570867169476293, 0.46215267713014124, 0.0, 1.0, 0.22180750083777032], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.00274331], dtype=float32), 0.19832008]. 
=============================================
[2019-04-07 12:38:58,704] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7637740e-14 3.3270342e-12 3.3070714e-17 2.1875323e-11 2.0249887e-12
 1.0000000e+00 2.9523946e-08 2.8266378e-10], sum to 1.0000
[2019-04-07 12:38:58,704] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9873
[2019-04-07 12:38:58,814] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 56.0, 300.0, 164.0, 24.0, 23.27620407974743, -0.09692797689758663, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4876200.0000, 
sim time next is 4878000.0000, 
raw observation next is [-0.4, 52.0, 291.5, 236.0, 24.0, 23.14202978843655, -0.1031981819114652, 0.0, 1.0, 14478.987122096902], 
processed observation next is [0.0, 0.4782608695652174, 0.45152354570637127, 0.52, 0.9716666666666667, 0.26077348066298345, 0.5, 0.4285024823697124, 0.46560060602951164, 0.0, 1.0, 0.06894755772427096], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5308502], dtype=float32), 0.54631305]. 
=============================================
[2019-04-07 12:38:58,818] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[87.79733 ]
 [87.40187 ]
 [87.06167 ]
 [86.46246 ]
 [85.410225]], R is [[87.8522644 ]
 [87.97373962]
 [88.09400177]
 [88.2130661 ]
 [88.33093262]].
[2019-04-07 12:39:08,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:39:08,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:39:08,440] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run11
[2019-04-07 12:39:15,938] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.0834237e-17 6.2103317e-14 8.0959139e-20 6.7279981e-13 2.5525181e-15
 1.0000000e+00 3.9030112e-10 1.0022547e-12], sum to 1.0000
[2019-04-07 12:39:15,938] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6953
[2019-04-07 12:39:16,045] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 51.0, 0.0, 0.0, 24.0, 24.12818031961127, 0.05763450749296162, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3870000.0000, 
sim time next is 3871800.0000, 
raw observation next is [1.0, 51.0, 0.0, 0.0, 24.0, 23.25839585974052, 0.02938494085684133, 0.0, 1.0, 68735.66647820566], 
processed observation next is [1.0, 0.8260869565217391, 0.4903047091412743, 0.51, 0.0, 0.0, 0.5, 0.4381996549783767, 0.5097949802856138, 0.0, 1.0, 0.32731269751526504], 
reward next is 0.9584, 
noisyNet noise sample is [array([0.70829254], dtype=float32), 0.28615025]. 
=============================================
[2019-04-07 12:39:30,597] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-07 12:39:30,601] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:39:30,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:39:30,604] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run23
[2019-04-07 12:39:30,602] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:39:30,620] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:39:30,632] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:39:30,633] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:39:30,635] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run23
[2019-04-07 12:39:30,654] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run23
[2019-04-07 12:40:31,362] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12045313], dtype=float32), 0.13266943]
[2019-04-07 12:40:31,362] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-5.45, 53.0, 179.0, 334.0, 24.0, 23.9913905578298, -0.007519407124714254, 1.0, 1.0, 0.0]
[2019-04-07 12:40:31,362] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 12:40:31,363] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.14216718e-14 9.56246909e-13 2.94604147e-17 2.05194143e-11
 3.49024656e-13 1.00000000e+00 1.29660105e-08 8.95670135e-11], sampled 0.8729054243783987
[2019-04-07 12:41:22,339] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 12:41:52,789] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 12:42:03,615] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.5330 83805026.4189 32.8860
[2019-04-07 12:42:04,652] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 440000, evaluation results [440000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.5329620425596, 83805026.41892925, 32.88598103848735]
[2019-04-07 12:42:20,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:42:20,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:42:20,096] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run11
[2019-04-07 12:42:22,417] A3C_AGENT_WORKER-Thread-3 INFO:Local step 28500, global step 441792: loss 1.7644
[2019-04-07 12:42:22,424] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 28500, global step 441792: learning rate 0.0000
[2019-04-07 12:42:42,740] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.6721710e-15 3.0646435e-13 8.8696443e-18 1.3407182e-11 1.8399895e-12
 1.0000000e+00 3.9384993e-08 4.3699794e-11], sum to 1.0000
[2019-04-07 12:42:42,740] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4649
[2019-04-07 12:42:43,015] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 70.0, 45.5, 273.0, 24.0, 22.9866805940757, -0.1067377949563188, 0.0, 1.0, 42619.90208597912], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3571200.0000, 
sim time next is 3573000.0000, 
raw observation next is [-6.5, 70.0, 88.0, 425.0, 24.0, 23.28516169331595, -0.01135301936246198, 0.0, 1.0, 29903.4668461913], 
processed observation next is [0.0, 0.34782608695652173, 0.28254847645429365, 0.7, 0.29333333333333333, 0.4696132596685083, 0.5, 0.44043014110966244, 0.4962156602125127, 0.0, 1.0, 0.1423974611723395], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4001878], dtype=float32), 1.6728563]. 
=============================================
[2019-04-07 12:42:43,019] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[84.67831]
 [83.96355]
 [84.25452]
 [84.30465]
 [84.60558]], R is [[85.99171448]
 [86.13179779]
 [86.27047729]
 [86.40777588]
 [86.54370117]].
[2019-04-07 12:42:45,893] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:42:45,893] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:42:45,896] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run11
[2019-04-07 12:42:47,573] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.64885351e-16 1.06239616e-13 1.06836973e-18 1.55057065e-12
 2.39216910e-14 1.00000000e+00 3.35850392e-09 1.60275439e-11], sum to 1.0000
[2019-04-07 12:42:47,574] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3456
[2019-04-07 12:42:47,636] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 24.0, 22.22996072903443, -0.3805283462806794, 0.0, 1.0, 44928.98113527224], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 185400.0000, 
sim time next is 187200.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 24.0, 22.05595623601171, -0.4032687297377799, 0.0, 1.0, 45012.99443205605], 
processed observation next is [1.0, 0.17391304347826086, 0.21606648199445982, 0.78, 0.0, 0.0, 0.5, 0.3379963530009758, 0.3655770900874067, 0.0, 1.0, 0.21434759253360025], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0093372], dtype=float32), -0.74284524]. 
=============================================
[2019-04-07 12:42:55,048] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:42:55,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:42:55,066] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run11
[2019-04-07 12:42:57,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:42:57,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:42:57,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run11
[2019-04-07 12:42:59,280] A3C_AGENT_WORKER-Thread-18 INFO:Local step 28500, global step 447468: loss 1.6495
[2019-04-07 12:42:59,281] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 28500, global step 447468: learning rate 0.0000
[2019-04-07 12:43:18,248] A3C_AGENT_WORKER-Thread-19 INFO:Local step 28500, global step 450853: loss 1.7679
[2019-04-07 12:43:18,248] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 28500, global step 450853: learning rate 0.0000
[2019-04-07 12:43:19,346] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:43:19,346] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:43:19,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run11
[2019-04-07 12:43:19,428] A3C_AGENT_WORKER-Thread-3 INFO:Local step 29000, global step 451110: loss 6.8768
[2019-04-07 12:43:19,428] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 29000, global step 451110: learning rate 0.0000
[2019-04-07 12:43:22,148] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.0456504e-16 3.2623923e-15 2.3871924e-21 5.4823995e-13 1.1651509e-16
 1.0000000e+00 1.2312024e-10 2.5434231e-13], sum to 1.0000
[2019-04-07 12:43:22,148] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8582
[2019-04-07 12:43:22,173] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.4, 61.0, 0.0, 0.0, 24.0, 24.88886742673593, 0.3838910216827396, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4399200.0000, 
sim time next is 4401000.0000, 
raw observation next is [8.95, 61.5, 0.0, 0.0, 24.0, 24.57281854994812, 0.2700056712947128, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.7105263157894738, 0.615, 0.0, 0.0, 0.5, 0.5477348791623434, 0.5900018904315709, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.48629886], dtype=float32), 0.69679177]. 
=============================================
[2019-04-07 12:43:22,179] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[109.16352 ]
 [109.01373 ]
 [109.231705]
 [109.12671 ]
 [109.815094]], R is [[109.13490295]
 [109.04355621]
 [108.953125  ]
 [108.86359406]
 [108.77495575]].
[2019-04-07 12:43:25,980] A3C_AGENT_WORKER-Thread-14 INFO:Local step 28500, global step 452265: loss 1.8201
[2019-04-07 12:43:25,981] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 28500, global step 452265: learning rate 0.0000
[2019-04-07 12:43:27,940] A3C_AGENT_WORKER-Thread-6 INFO:Local step 28500, global step 452633: loss 1.6359
[2019-04-07 12:43:27,942] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 28500, global step 452633: learning rate 0.0000
[2019-04-07 12:43:36,386] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.4417788e-14 1.2965514e-12 8.3976426e-18 9.3838756e-11 1.1934554e-12
 1.0000000e+00 1.1434545e-08 2.1487526e-10], sum to 1.0000
[2019-04-07 12:43:36,386] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7199
[2019-04-07 12:43:36,426] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 44.5, 33.0, 187.0, 24.0, 23.2773774207347, -0.1022004600250471, 0.0, 1.0, 12453.607780153694], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4901400.0000, 
sim time next is 4903200.0000, 
raw observation next is [2.0, 44.0, 16.5, 93.5, 24.0, 23.18478954664035, -0.1402185983305223, 0.0, 1.0, 23240.48265095132], 
processed observation next is [0.0, 0.782608695652174, 0.518005540166205, 0.44, 0.055, 0.10331491712707182, 0.5, 0.43206579555336244, 0.4532604672231592, 0.0, 1.0, 0.11066896500453009], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.12439521], dtype=float32), 0.3747023]. 
=============================================
[2019-04-07 12:43:38,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:43:38,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:43:38,640] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run11
[2019-04-07 12:43:39,674] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4312464e-18 8.4712670e-16 4.3749504e-22 1.1347063e-14 1.4433320e-16
 1.0000000e+00 2.0210771e-11 6.5586418e-14], sum to 1.0000
[2019-04-07 12:43:39,674] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3963
[2019-04-07 12:43:39,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:43:39,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:43:39,797] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run11
[2019-04-07 12:43:39,876] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.8, 93.0, 96.0, 0.0, 24.0, 23.39837603957764, -0.1263566565093768, 1.0, 1.0, 6226.803890076843], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 912600.0000, 
sim time next is 914400.0000, 
raw observation next is [3.8, 93.0, 93.0, 0.0, 24.0, 23.77094848798967, -0.02698300615497301, 1.0, 1.0, 62482.265252503705], 
processed observation next is [1.0, 0.6086956521739131, 0.5678670360110805, 0.93, 0.31, 0.0, 0.5, 0.4809123739991392, 0.491005664615009, 1.0, 1.0, 0.29753459644049385], 
reward next is 0.9882, 
noisyNet noise sample is [array([-0.4118672], dtype=float32), -1.1675593]. 
=============================================
[2019-04-07 12:43:40,052] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:43:40,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:43:40,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run11
[2019-04-07 12:43:45,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:43:45,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:43:45,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run11
[2019-04-07 12:43:48,827] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:43:48,827] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:43:48,831] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run11
[2019-04-07 12:43:49,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:43:49,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:43:49,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run11
[2019-04-07 12:43:49,722] A3C_AGENT_WORKER-Thread-18 INFO:Local step 29000, global step 456148: loss 6.7948
[2019-04-07 12:43:49,723] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 29000, global step 456148: learning rate 0.0000
[2019-04-07 12:43:49,807] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:43:49,807] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:43:49,811] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run11
[2019-04-07 12:43:50,830] A3C_AGENT_WORKER-Thread-10 INFO:Local step 28500, global step 456261: loss 1.7672
[2019-04-07 12:43:50,830] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 28500, global step 456261: learning rate 0.0000
[2019-04-07 12:43:51,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:43:51,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:43:51,157] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run11
[2019-04-07 12:43:51,402] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9830124e-15 1.5558461e-13 4.8732899e-18 5.6054601e-12 1.4615396e-14
 1.0000000e+00 4.8185762e-09 1.2011038e-11], sum to 1.0000
[2019-04-07 12:43:51,402] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7321
[2019-04-07 12:43:51,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:43:51,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:43:51,440] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run11
[2019-04-07 12:43:51,646] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.8, 86.0, 0.0, 0.0, 24.0, 22.76415128936222, -0.1960315733194058, 0.0, 1.0, 35215.74422032802], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 68400.0000, 
sim time next is 70200.0000, 
raw observation next is [3.25, 87.5, 0.0, 0.0, 24.0, 22.80635172331223, -0.1474747695574802, 0.0, 1.0, 120458.79355315254], 
processed observation next is [0.0, 0.8260869565217391, 0.5526315789473685, 0.875, 0.0, 0.0, 0.5, 0.40052931027601907, 0.4508417434808399, 0.0, 1.0, 0.5736133026340597], 
reward next is 0.7121, 
noisyNet noise sample is [array([1.1675109], dtype=float32), -0.3357525]. 
=============================================
[2019-04-07 12:43:53,764] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:43:53,764] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:43:53,769] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run11
[2019-04-07 12:44:08,929] A3C_AGENT_WORKER-Thread-19 INFO:Local step 29000, global step 458158: loss 6.8572
[2019-04-07 12:44:08,929] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 29000, global step 458158: learning rate 0.0000
[2019-04-07 12:44:08,968] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.7637321e-19 5.3262752e-17 3.7038476e-22 1.5554003e-14 3.1296630e-17
 1.0000000e+00 1.5831152e-11 4.2179398e-14], sum to 1.0000
[2019-04-07 12:44:08,968] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5415
[2019-04-07 12:44:09,002] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.1, 93.0, 90.0, 0.0, 24.0, 24.13097835336167, 0.008812935976521765, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 916200.0000, 
sim time next is 918000.0000, 
raw observation next is [4.4, 93.0, 72.0, 0.0, 24.0, 24.14526967815019, 0.0075928328877026, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5844875346260389, 0.93, 0.24, 0.0, 0.5, 0.5121058065125158, 0.5025309442959008, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5555997], dtype=float32), -0.20854291]. 
=============================================
[2019-04-07 12:44:09,021] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[109.99259 ]
 [109.51387 ]
 [108.35036 ]
 [108.037506]
 [107.350395]], R is [[110.32204437]
 [110.21882629]
 [110.10482025]
 [110.00377655]
 [109.90373993]].
[2019-04-07 12:44:09,482] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.30117972e-15 4.60510265e-14 1.64406412e-19 2.72360043e-12
 4.05232971e-15 1.00000000e+00 1.42707215e-08 6.00269921e-12], sum to 1.0000
[2019-04-07 12:44:09,482] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6522
[2019-04-07 12:44:09,590] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.1, 73.5, 184.0, 13.0, 24.0, 24.01438407538299, -0.03072627086813747, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 127800.0000, 
sim time next is 129600.0000, 
raw observation next is [-8.4, 61.0, 157.0, 308.0, 24.0, 23.89580114178438, -0.02197865691218433, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.2299168975069252, 0.61, 0.5233333333333333, 0.34033149171270716, 0.5, 0.4913167618153649, 0.4926737810292719, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4625396], dtype=float32), 0.36522767]. 
=============================================
[2019-04-07 12:44:11,330] A3C_AGENT_WORKER-Thread-3 INFO:Local step 29500, global step 458436: loss 6.1323
[2019-04-07 12:44:11,333] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 29500, global step 458436: learning rate 0.0000
[2019-04-07 12:44:13,962] A3C_AGENT_WORKER-Thread-13 INFO:Local step 28500, global step 458752: loss 1.7712
[2019-04-07 12:44:13,985] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 28500, global step 458752: learning rate 0.0000
[2019-04-07 12:44:14,327] A3C_AGENT_WORKER-Thread-12 INFO:Local step 28500, global step 458796: loss 1.7271
[2019-04-07 12:44:14,330] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 28500, global step 458796: learning rate 0.0000
[2019-04-07 12:44:14,741] A3C_AGENT_WORKER-Thread-16 INFO:Local step 28500, global step 458859: loss 1.8102
[2019-04-07 12:44:14,742] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 28500, global step 458859: learning rate 0.0000
[2019-04-07 12:44:18,378] A3C_AGENT_WORKER-Thread-14 INFO:Local step 29000, global step 459368: loss 6.7918
[2019-04-07 12:44:18,378] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 29000, global step 459368: learning rate 0.0000
[2019-04-07 12:44:20,918] A3C_AGENT_WORKER-Thread-4 INFO:Local step 28500, global step 459680: loss 1.8528
[2019-04-07 12:44:20,919] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 28500, global step 459680: learning rate 0.0000
[2019-04-07 12:44:21,208] A3C_AGENT_WORKER-Thread-6 INFO:Local step 29000, global step 459719: loss 6.8059
[2019-04-07 12:44:21,208] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 29000, global step 459719: learning rate 0.0000
[2019-04-07 12:44:23,128] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-07 12:44:23,151] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:44:23,151] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:44:23,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run24
[2019-04-07 12:44:23,179] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:44:23,180] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:44:23,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run24
[2019-04-07 12:44:23,238] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:44:23,243] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:44:23,245] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run24
[2019-04-07 12:44:56,069] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.1213083], dtype=float32), 0.13408506]
[2019-04-07 12:44:56,069] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [12.15373034, 72.183354105, 0.0, 0.0, 24.0, 23.85119991233622, 0.1168043626976235, 0.0, 1.0, 0.0]
[2019-04-07 12:44:56,069] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 12:44:56,070] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.6098688e-17 6.8173040e-15 3.8218471e-20 2.5847971e-13 1.7024076e-15
 1.0000000e+00 3.8330361e-10 1.3102519e-12], sampled 0.15350212444190803
[2019-04-07 12:45:41,248] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.1213083], dtype=float32), 0.13408506]
[2019-04-07 12:45:41,248] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [17.3, 53.0, 82.0, 171.0, 24.0, 25.99893167130698, 0.5468481339434215, 1.0, 0.0, 0.0]
[2019-04-07 12:45:41,248] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 12:45:41,249] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [4.8029282e-14 6.2328493e-12 2.7880979e-16 1.1527557e-10 1.2270165e-12
 1.0000000e+00 2.3971458e-08 2.7404551e-10], sampled 0.5443204936585883
[2019-04-07 12:46:18,008] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 12:46:55,723] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 12:46:59,954] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 12:47:00,998] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 460000, evaluation results [460000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 12:47:04,533] A3C_AGENT_WORKER-Thread-17 INFO:Local step 28500, global step 460328: loss 1.8408
[2019-04-07 12:47:04,533] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 28500, global step 460328: learning rate 0.0000
[2019-04-07 12:47:04,848] A3C_AGENT_WORKER-Thread-11 INFO:Local step 28500, global step 460354: loss 1.7721
[2019-04-07 12:47:04,848] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 28500, global step 460354: learning rate 0.0000
[2019-04-07 12:47:07,654] A3C_AGENT_WORKER-Thread-15 INFO:Local step 28500, global step 460551: loss 1.8255
[2019-04-07 12:47:07,655] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 28500, global step 460551: learning rate 0.0000
[2019-04-07 12:47:08,619] A3C_AGENT_WORKER-Thread-2 INFO:Local step 28500, global step 460627: loss 1.8439
[2019-04-07 12:47:08,619] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 28500, global step 460627: learning rate 0.0000
[2019-04-07 12:47:09,400] A3C_AGENT_WORKER-Thread-20 INFO:Local step 28500, global step 460687: loss 1.8732
[2019-04-07 12:47:09,400] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 28500, global step 460687: learning rate 0.0000
[2019-04-07 12:47:11,278] A3C_AGENT_WORKER-Thread-5 INFO:Local step 28500, global step 460809: loss 1.8448
[2019-04-07 12:47:11,279] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 28500, global step 460809: learning rate 0.0000
[2019-04-07 12:47:28,025] A3C_AGENT_WORKER-Thread-18 INFO:Local step 29500, global step 462240: loss 5.3574
[2019-04-07 12:47:28,027] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 29500, global step 462241: learning rate 0.0000
[2019-04-07 12:47:32,854] A3C_AGENT_WORKER-Thread-10 INFO:Local step 29000, global step 462748: loss 6.9071
[2019-04-07 12:47:32,854] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 29000, global step 462748: learning rate 0.0000
[2019-04-07 12:47:44,683] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9128776e-15 1.8797035e-13 2.1904566e-17 3.4537796e-12 4.7426852e-13
 1.0000000e+00 3.0337213e-09 1.1650078e-10], sum to 1.0000
[2019-04-07 12:47:44,683] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3864
[2019-04-07 12:47:44,741] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 71.0, 0.0, 0.0, 24.0, 23.16053909063046, -0.2087458999618189, 0.0, 1.0, 42644.40980501642], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 689400.0000, 
sim time next is 691200.0000, 
raw observation next is [-3.9, 71.0, 0.0, 0.0, 24.0, 23.09852817569197, -0.2149365941226256, 0.0, 1.0, 42355.761860824576], 
processed observation next is [1.0, 0.0, 0.3545706371191136, 0.71, 0.0, 0.0, 0.5, 0.4248773479743309, 0.42835446862579146, 0.0, 1.0, 0.20169410409916463], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.37329367], dtype=float32), 1.8868043]. 
=============================================
[2019-04-07 12:47:48,739] A3C_AGENT_WORKER-Thread-19 INFO:Local step 29500, global step 464811: loss 6.2281
[2019-04-07 12:47:48,753] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 29500, global step 464811: learning rate 0.0000
[2019-04-07 12:47:51,444] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8698522e-17 5.5851452e-14 7.4670692e-21 4.1597785e-13 4.8893833e-16
 1.0000000e+00 2.1609389e-10 1.2359893e-12], sum to 1.0000
[2019-04-07 12:47:51,445] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7164
[2019-04-07 12:47:51,513] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.15, 83.0, 0.0, 0.0, 24.0, 23.50600617236743, -0.03610234385589972, 0.0, 1.0, 13818.922295799422], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2151000.0000, 
sim time next is 2152800.0000, 
raw observation next is [-6.7, 83.0, 0.0, 0.0, 24.0, 23.39403293601793, -0.03125891220351576, 0.0, 1.0, 74893.49440322955], 
processed observation next is [1.0, 0.9565217391304348, 0.2770083102493075, 0.83, 0.0, 0.0, 0.5, 0.44950274466816076, 0.48958036259882803, 0.0, 1.0, 0.35663568763442643], 
reward next is 0.9291, 
noisyNet noise sample is [array([0.19799604], dtype=float32), -1.5072017]. 
=============================================
[2019-04-07 12:47:56,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7316391e-15 2.7553240e-14 5.9585413e-20 3.6820733e-12 8.8466128e-15
 1.0000000e+00 2.0546212e-10 2.9274508e-13], sum to 1.0000
[2019-04-07 12:47:56,251] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0223
[2019-04-07 12:47:56,321] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 79.0, 0.0, 0.0, 24.0, 23.27427593485051, -0.1454946104449931, 0.0, 1.0, 45578.06195997237], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 874800.0000, 
sim time next is 876600.0000, 
raw observation next is [-1.45, 77.5, 0.0, 0.0, 24.0, 23.31312212718883, -0.1374010805637478, 0.0, 1.0, 40542.53344684385], 
processed observation next is [1.0, 0.13043478260869565, 0.422437673130194, 0.775, 0.0, 0.0, 0.5, 0.44276017726573585, 0.45419963981208406, 0.0, 1.0, 0.19305968308020882], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3361293], dtype=float32), 1.20079]. 
=============================================
[2019-04-07 12:47:56,863] A3C_AGENT_WORKER-Thread-6 INFO:Local step 29500, global step 466084: loss 5.2904
[2019-04-07 12:47:56,863] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 29500, global step 466084: learning rate 0.0000
[2019-04-07 12:47:56,897] A3C_AGENT_WORKER-Thread-16 INFO:Local step 29000, global step 466092: loss 6.9275
[2019-04-07 12:47:56,913] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 29000, global step 466092: learning rate 0.0000
[2019-04-07 12:47:57,285] A3C_AGENT_WORKER-Thread-14 INFO:Local step 29500, global step 466146: loss 5.0247
[2019-04-07 12:47:57,286] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 29500, global step 466146: learning rate 0.0000
[2019-04-07 12:47:57,941] A3C_AGENT_WORKER-Thread-3 INFO:Local step 30000, global step 466244: loss 1.8126
[2019-04-07 12:47:57,942] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 30000, global step 466244: learning rate 0.0000
[2019-04-07 12:47:59,165] A3C_AGENT_WORKER-Thread-12 INFO:Local step 29000, global step 466458: loss 7.0360
[2019-04-07 12:47:59,180] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 29000, global step 466458: learning rate 0.0000
[2019-04-07 12:47:59,713] A3C_AGENT_WORKER-Thread-13 INFO:Local step 29000, global step 466575: loss 6.8457
[2019-04-07 12:47:59,714] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 29000, global step 466575: learning rate 0.0000
[2019-04-07 12:48:00,923] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.1386087e-15 1.0381595e-14 5.7777749e-19 7.9735975e-11 2.6695839e-14
 1.0000000e+00 9.9494613e-10 2.1044517e-11], sum to 1.0000
[2019-04-07 12:48:00,923] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7208
[2019-04-07 12:48:01,194] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 79.0, 0.0, 0.0, 24.0, 22.94703750222608, -0.1507221885707087, 1.0, 1.0, 95296.73941840604], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2619000.0000, 
sim time next is 2620800.0000, 
raw observation next is [-7.3, 79.0, 42.0, 4.0, 24.0, 23.619706097726, -0.1219287896730282, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.26038781163434904, 0.79, 0.14, 0.004419889502762431, 0.5, 0.46830884147716656, 0.45935707010899063, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.9027263], dtype=float32), 0.8737713]. 
=============================================
[2019-04-07 12:48:04,578] A3C_AGENT_WORKER-Thread-4 INFO:Local step 29000, global step 467542: loss 6.9033
[2019-04-07 12:48:04,578] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 29000, global step 467542: learning rate 0.0000
[2019-04-07 12:48:06,011] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6093811e-17 4.9112753e-15 3.8218891e-21 3.5327071e-14 6.5984330e-17
 1.0000000e+00 5.8415807e-11 5.9968252e-13], sum to 1.0000
[2019-04-07 12:48:06,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0348
[2019-04-07 12:48:06,085] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.3, 97.5, 0.0, 0.0, 24.0, 23.60105340988039, 0.02183606225787756, 0.0, 1.0, 18737.517297374692], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1395000.0000, 
sim time next is 1396800.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 24.0, 23.37039672893909, 0.03179881482048166, 0.0, 1.0, 87493.88422331754], 
processed observation next is [1.0, 0.17391304347826086, 0.44598337950138506, 1.0, 0.0, 0.0, 0.5, 0.4475330607449243, 0.5105996049401605, 0.0, 1.0, 0.4166375439205597], 
reward next is 0.8691, 
noisyNet noise sample is [array([1.4653891], dtype=float32), 2.6203961]. 
=============================================
[2019-04-07 12:48:08,057] A3C_AGENT_WORKER-Thread-17 INFO:Local step 29000, global step 468369: loss 6.9766
[2019-04-07 12:48:08,059] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 29000, global step 468369: learning rate 0.0000
[2019-04-07 12:48:08,560] A3C_AGENT_WORKER-Thread-11 INFO:Local step 29000, global step 468488: loss 6.9638
[2019-04-07 12:48:08,560] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 29000, global step 468488: learning rate 0.0000
[2019-04-07 12:48:09,660] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.0953768e-15 2.8461730e-14 2.5425338e-18 4.7694123e-12 6.7672227e-14
 1.0000000e+00 7.0842465e-09 1.3238453e-11], sum to 1.0000
[2019-04-07 12:48:09,661] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7821
[2019-04-07 12:48:09,838] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 56.0, 0.0, 0.0, 24.0, 23.02499256228163, -0.1051369122115528, 0.0, 1.0, 92555.27150315768], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2318400.0000, 
sim time next is 2320200.0000, 
raw observation next is [-1.7, 55.0, 0.0, 0.0, 24.0, 23.15398892945359, -0.04753512880400423, 0.0, 1.0, 119406.06583105536], 
processed observation next is [1.0, 0.8695652173913043, 0.4155124653739613, 0.55, 0.0, 0.0, 0.5, 0.4294990774544658, 0.4841549570653319, 0.0, 1.0, 0.568600313481216], 
reward next is 0.7171, 
noisyNet noise sample is [array([0.80933565], dtype=float32), 1.1581498]. 
=============================================
[2019-04-07 12:48:10,566] A3C_AGENT_WORKER-Thread-2 INFO:Local step 29000, global step 468996: loss 6.9767
[2019-04-07 12:48:10,567] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 29000, global step 468996: learning rate 0.0000
[2019-04-07 12:48:10,642] A3C_AGENT_WORKER-Thread-15 INFO:Local step 29000, global step 469018: loss 7.0253
[2019-04-07 12:48:10,642] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 29000, global step 469018: learning rate 0.0000
[2019-04-07 12:48:10,926] A3C_AGENT_WORKER-Thread-20 INFO:Local step 29000, global step 469084: loss 6.9972
[2019-04-07 12:48:10,926] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 29000, global step 469084: learning rate 0.0000
[2019-04-07 12:48:11,681] A3C_AGENT_WORKER-Thread-5 INFO:Local step 29000, global step 469248: loss 7.0575
[2019-04-07 12:48:11,682] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 29000, global step 469248: learning rate 0.0000
[2019-04-07 12:48:20,475] A3C_AGENT_WORKER-Thread-10 INFO:Local step 29500, global step 470874: loss 6.4239
[2019-04-07 12:48:20,482] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 29500, global step 470874: learning rate 0.0000
[2019-04-07 12:48:22,103] A3C_AGENT_WORKER-Thread-18 INFO:Local step 30000, global step 471172: loss 1.6270
[2019-04-07 12:48:22,103] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 30000, global step 471172: learning rate 0.0000
[2019-04-07 12:48:38,265] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7792066e-16 1.2095761e-14 1.8299837e-19 4.0970059e-13 6.9277525e-15
 1.0000000e+00 4.7280451e-09 2.2156866e-12], sum to 1.0000
[2019-04-07 12:48:38,265] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1490
[2019-04-07 12:48:38,538] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 24.0, 22.826326204159, -0.2469806373779633, 0.0, 1.0, 41974.62844758422], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2012400.0000, 
sim time next is 2014200.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 24.0, 23.08123692412476, -0.1895042037622409, 1.0, 1.0, 41351.7755679591], 
processed observation next is [1.0, 0.30434782608695654, 0.2908587257617729, 0.87, 0.0, 0.0, 0.5, 0.42343641034373, 0.436831932079253, 1.0, 1.0, 0.19691321699028141], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5987741], dtype=float32), 0.06467211]. 
=============================================
[2019-04-07 12:48:39,831] A3C_AGENT_WORKER-Thread-3 INFO:Local step 30500, global step 473945: loss 1.0436
[2019-04-07 12:48:39,831] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 30500, global step 473945: learning rate 0.0000
[2019-04-07 12:48:40,973] A3C_AGENT_WORKER-Thread-19 INFO:Local step 30000, global step 474101: loss 1.5551
[2019-04-07 12:48:40,973] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 30000, global step 474101: learning rate 0.0000
[2019-04-07 12:48:45,812] A3C_AGENT_WORKER-Thread-16 INFO:Local step 29500, global step 474753: loss 4.8057
[2019-04-07 12:48:45,812] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 29500, global step 474753: learning rate 0.0000
[2019-04-07 12:48:46,019] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1916279e-16 7.1797901e-14 2.3219715e-19 5.8693393e-13 6.8714544e-15
 1.0000000e+00 1.2335372e-09 2.1395498e-11], sum to 1.0000
[2019-04-07 12:48:46,019] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0973
[2019-04-07 12:48:46,087] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.3, 88.5, 0.0, 0.0, 24.0, 23.08757610523422, -0.1799898961783381, 0.0, 1.0, 44366.29697888405], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2086200.0000, 
sim time next is 2088000.0000, 
raw observation next is [-5.6, 91.0, 0.0, 0.0, 24.0, 23.06206772599649, -0.1672994363810815, 0.0, 1.0, 44654.81668902221], 
processed observation next is [1.0, 0.17391304347826086, 0.30747922437673136, 0.91, 0.0, 0.0, 0.5, 0.42183897716637403, 0.44423352120630616, 0.0, 1.0, 0.2126419842334391], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4015126], dtype=float32), 1.7994107]. 
=============================================
[2019-04-07 12:48:46,100] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[100.18306]
 [100.41655]
 [100.04329]
 [ 99.93475]
 [100.14153]], R is [[100.13220978]
 [100.13088989]
 [100.12958527]
 [100.12828827]
 [100.12700653]].
[2019-04-07 12:48:47,244] A3C_AGENT_WORKER-Thread-13 INFO:Local step 29500, global step 474956: loss 4.7871
[2019-04-07 12:48:47,246] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 29500, global step 474957: learning rate 0.0000
[2019-04-07 12:48:49,190] A3C_AGENT_WORKER-Thread-12 INFO:Local step 29500, global step 475215: loss 4.8986
[2019-04-07 12:48:49,191] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 29500, global step 475215: learning rate 0.0000
[2019-04-07 12:48:49,486] A3C_AGENT_WORKER-Thread-14 INFO:Local step 30000, global step 475257: loss 1.5659
[2019-04-07 12:48:49,488] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 30000, global step 475257: learning rate 0.0000
[2019-04-07 12:48:50,744] A3C_AGENT_WORKER-Thread-6 INFO:Local step 30000, global step 475462: loss 1.5208
[2019-04-07 12:48:50,747] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 30000, global step 475462: learning rate 0.0000
[2019-04-07 12:48:54,069] A3C_AGENT_WORKER-Thread-4 INFO:Local step 29500, global step 475935: loss 5.3391
[2019-04-07 12:48:54,070] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 29500, global step 475935: learning rate 0.0000
[2019-04-07 12:48:54,112] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2809763e-16 9.1071881e-16 2.6961246e-19 1.3098446e-12 8.1356905e-14
 1.0000000e+00 5.5433764e-09 4.2268676e-12], sum to 1.0000
[2019-04-07 12:48:54,112] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7736
[2019-04-07 12:48:54,368] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 47.0, 282.5, 24.0, 23.37483419688408, -0.1111589449638971, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3744000.0000, 
sim time next is 3745800.0000, 
raw observation next is [-4.0, 74.0, 89.0, 429.0, 24.0, 23.83229579778955, -0.00209212145300935, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3518005540166205, 0.74, 0.2966666666666667, 0.4740331491712707, 0.5, 0.4860246498157957, 0.4993026261823302, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5030121], dtype=float32), -1.2215551]. 
=============================================
[2019-04-07 12:48:59,319] A3C_AGENT_WORKER-Thread-11 INFO:Local step 29500, global step 476712: loss 4.7796
[2019-04-07 12:48:59,319] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 29500, global step 476712: learning rate 0.0000
[2019-04-07 12:49:00,205] A3C_AGENT_WORKER-Thread-17 INFO:Local step 29500, global step 476841: loss 4.9514
[2019-04-07 12:49:00,206] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 29500, global step 476841: learning rate 0.0000
[2019-04-07 12:49:00,727] A3C_AGENT_WORKER-Thread-15 INFO:Local step 29500, global step 476918: loss 5.4898
[2019-04-07 12:49:00,728] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 29500, global step 476918: learning rate 0.0000
[2019-04-07 12:49:01,537] A3C_AGENT_WORKER-Thread-2 INFO:Local step 29500, global step 477035: loss 4.4570
[2019-04-07 12:49:01,537] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 29500, global step 477035: learning rate 0.0000
[2019-04-07 12:49:02,300] A3C_AGENT_WORKER-Thread-5 INFO:Local step 29500, global step 477152: loss 4.6433
[2019-04-07 12:49:02,300] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 29500, global step 477152: learning rate 0.0000
[2019-04-07 12:49:03,267] A3C_AGENT_WORKER-Thread-20 INFO:Local step 29500, global step 477294: loss 6.0947
[2019-04-07 12:49:03,267] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 29500, global step 477294: learning rate 0.0000
[2019-04-07 12:49:04,015] A3C_AGENT_WORKER-Thread-18 INFO:Local step 30500, global step 477393: loss 1.3077
[2019-04-07 12:49:04,016] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 30500, global step 477393: learning rate 0.0000
[2019-04-07 12:49:07,815] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.4125925e-16 3.7386272e-14 1.7984076e-17 6.0199319e-12 4.6581066e-14
 1.0000000e+00 2.9176905e-09 2.1856846e-11], sum to 1.0000
[2019-04-07 12:49:07,815] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8896
[2019-04-07 12:49:07,955] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 65.0, 105.5, 717.0, 24.0, 23.38006656181794, -0.008741118428782169, 0.0, 1.0, 19004.779707585076], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3578400.0000, 
sim time next is 3580200.0000, 
raw observation next is [-4.5, 59.5, 111.0, 758.0, 24.0, 23.29167691929877, -0.006675867229089041, 0.0, 1.0, 20338.236285409854], 
processed observation next is [0.0, 0.43478260869565216, 0.3379501385041552, 0.595, 0.37, 0.8375690607734807, 0.5, 0.44097307660823076, 0.497774710923637, 0.0, 1.0, 0.0968487442162374], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.3465903], dtype=float32), -0.18576199]. 
=============================================
[2019-04-07 12:49:13,709] A3C_AGENT_WORKER-Thread-10 INFO:Local step 30000, global step 478826: loss 1.7681
[2019-04-07 12:49:13,713] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 30000, global step 478826: learning rate 0.0000
[2019-04-07 12:49:16,955] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7596932e-14 1.0164778e-12 4.6312225e-16 2.5657862e-10 1.2770777e-13
 9.9999976e-01 2.3632839e-07 5.4093241e-10], sum to 1.0000
[2019-04-07 12:49:16,962] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1273
[2019-04-07 12:49:17,059] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 54.0, 221.5, 212.0, 24.0, 23.1523505747131, -0.111982115301626, 0.0, 1.0, 3116.6169384998016], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2379600.0000, 
sim time next is 2381400.0000, 
raw observation next is [-0.3, 53.0, 191.0, 0.0, 24.0, 23.05475151587113, -0.15071564506976, 0.0, 1.0, 32580.661099915902], 
processed observation next is [0.0, 0.5652173913043478, 0.4542936288088643, 0.53, 0.6366666666666667, 0.0, 0.5, 0.4212292929892607, 0.44976145164341336, 0.0, 1.0, 0.15514600523769478], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.49034145], dtype=float32), 0.74644554]. 
=============================================
[2019-04-07 12:49:19,317] A3C_AGENT_WORKER-Thread-3 INFO:Local step 31000, global step 479742: loss 13.9956
[2019-04-07 12:49:19,319] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 31000, global step 479742: learning rate 0.0000
[2019-04-07 12:49:20,791] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-07 12:49:20,801] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:49:20,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:49:20,803] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run25
[2019-04-07 12:49:20,818] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:49:20,819] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:49:20,830] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:49:20,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:49:20,831] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run25
[2019-04-07 12:49:20,848] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run25
[2019-04-07 12:51:16,398] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 12:51:45,525] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 12:51:54,110] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.3901 83805026.4189 32.8860
[2019-04-07 12:51:55,148] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 480000, evaluation results [480000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.390104899702, 83805026.41892925, 32.88598103848735]
[2019-04-07 12:51:55,510] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.02719855e-13 1.42959440e-12 9.58924623e-16 5.32553862e-11
 7.37013402e-12 9.99999762e-01 2.51597129e-07 2.63959465e-10], sum to 1.0000
[2019-04-07 12:51:55,511] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3837
[2019-04-07 12:51:55,609] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 49.0, 0.0, 0.0, 24.0, 23.46553807756678, -0.1065416492988902, 0.0, 1.0, 37201.58341066076], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4260600.0000, 
sim time next is 4262400.0000, 
raw observation next is [3.0, 49.0, 55.0, 26.5, 24.0, 23.50433140870412, -0.09601019021714341, 0.0, 1.0, 26854.01669651658], 
processed observation next is [0.0, 0.34782608695652173, 0.5457063711911359, 0.49, 0.18333333333333332, 0.029281767955801105, 0.5, 0.4586942840586768, 0.46799660326095216, 0.0, 1.0, 0.12787626998341228], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1972241], dtype=float32), 1.7039512]. 
=============================================
[2019-04-07 12:51:58,256] A3C_AGENT_WORKER-Thread-19 INFO:Local step 30500, global step 480385: loss 1.3767
[2019-04-07 12:51:58,257] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 30500, global step 480385: learning rate 0.0000
[2019-04-07 12:52:09,681] A3C_AGENT_WORKER-Thread-14 INFO:Local step 30500, global step 481936: loss 1.9125
[2019-04-07 12:52:09,682] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 30500, global step 481936: learning rate 0.0000
[2019-04-07 12:52:09,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:52:09,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:52:09,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run12
[2019-04-07 12:52:11,167] A3C_AGENT_WORKER-Thread-6 INFO:Local step 30500, global step 482173: loss 1.5240
[2019-04-07 12:52:11,168] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 30500, global step 482173: learning rate 0.0000
[2019-04-07 12:52:20,357] A3C_AGENT_WORKER-Thread-16 INFO:Local step 30000, global step 483565: loss 1.7036
[2019-04-07 12:52:20,357] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 30000, global step 483565: learning rate 0.0000
[2019-04-07 12:52:20,734] A3C_AGENT_WORKER-Thread-13 INFO:Local step 30000, global step 483623: loss 1.4548
[2019-04-07 12:52:20,735] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 30000, global step 483623: learning rate 0.0000
[2019-04-07 12:52:21,324] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.40851637e-15 8.74067095e-13 1.01889395e-17 2.75710513e-11
 2.75525181e-13 1.00000000e+00 1.40425627e-08 1.40988540e-10], sum to 1.0000
[2019-04-07 12:52:21,325] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1857
[2019-04-07 12:52:21,461] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.6, 82.0, 34.0, 0.0, 24.0, 22.72953989368218, -0.2087257255689516, 0.0, 1.0, 19094.411111014455], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 57600.0000, 
sim time next is 59400.0000, 
raw observation next is [6.05, 84.0, 18.0, 0.0, 24.0, 22.68334363562841, -0.2106612744813418, 0.0, 1.0, 36462.84582435909], 
processed observation next is [0.0, 0.6956521739130435, 0.6301939058171746, 0.84, 0.06, 0.0, 0.5, 0.3902786363023676, 0.42977957517288606, 0.0, 1.0, 0.1736325991636147], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5088218], dtype=float32), -0.117081486]. 
=============================================
[2019-04-07 12:52:21,465] A3C_AGENT_WORKER-Thread-12 INFO:Local step 30000, global step 483747: loss 1.8433
[2019-04-07 12:52:21,469] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 30000, global step 483747: learning rate 0.0000
[2019-04-07 12:52:21,795] A3C_AGENT_WORKER-Thread-18 INFO:Local step 31000, global step 483801: loss 14.7343
[2019-04-07 12:52:21,796] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 31000, global step 483801: learning rate 0.0000
[2019-04-07 12:52:24,161] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7816561e-15 1.3871940e-13 1.3497953e-16 1.5081087e-11 3.2880064e-14
 1.0000000e+00 2.7011828e-09 3.8811839e-11], sum to 1.0000
[2019-04-07 12:52:24,161] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2196
[2019-04-07 12:52:24,231] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 46.5, 0.0, 0.0, 24.0, 23.50365517959596, -0.08256014465507468, 0.0, 1.0, 40258.28904043821], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4239000.0000, 
sim time next is 4240800.0000, 
raw observation next is [3.0, 45.0, 0.0, 0.0, 24.0, 23.52032588553945, -0.08372726427035088, 0.0, 1.0, 31858.20749051478], 
processed observation next is [0.0, 0.08695652173913043, 0.5457063711911359, 0.45, 0.0, 0.0, 0.5, 0.46002715712828746, 0.47209091190988306, 0.0, 1.0, 0.15170574995483227], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9494349], dtype=float32), 0.8970072]. 
=============================================
[2019-04-07 12:52:26,209] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8135967e-17 5.0255570e-15 3.5975319e-20 6.2574166e-14 1.0682823e-14
 1.0000000e+00 7.7704787e-10 6.7045016e-14], sum to 1.0000
[2019-04-07 12:52:26,210] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7602
[2019-04-07 12:52:26,234] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 100.0, 131.0, 0.0, 24.0, 23.76280372878666, -0.0933838118916248, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2894400.0000, 
sim time next is 2896200.0000, 
raw observation next is [1.5, 100.0, 175.0, 0.0, 24.0, 23.56777415263708, -0.1054751558583821, 1.0, 1.0, 41049.1050208023], 
processed observation next is [1.0, 0.5217391304347826, 0.5041551246537397, 1.0, 0.5833333333333334, 0.0, 0.5, 0.46398117938642347, 0.4648416147138726, 1.0, 1.0, 0.19547192867048716], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.9021455], dtype=float32), -0.0602144]. 
=============================================
[2019-04-07 12:52:27,323] A3C_AGENT_WORKER-Thread-4 INFO:Local step 30000, global step 484800: loss 1.6701
[2019-04-07 12:52:27,326] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 30000, global step 484801: learning rate 0.0000
[2019-04-07 12:52:29,243] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2142838e-16 7.1007289e-15 8.1530597e-21 1.2638287e-12 7.3491950e-15
 1.0000000e+00 1.8090731e-09 8.1944380e-13], sum to 1.0000
[2019-04-07 12:52:29,243] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1283
[2019-04-07 12:52:29,298] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 41.0, 41.0, 365.0, 24.0, 25.39564040622295, 0.2246051556924296, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3862800.0000, 
sim time next is 3864600.0000, 
raw observation next is [2.5, 44.5, 18.0, 179.0, 24.0, 25.06769606851252, 0.2514775599784929, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5318559556786704, 0.445, 0.06, 0.19779005524861878, 0.5, 0.5889746723760435, 0.5838258533261643, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8222777], dtype=float32), 0.82583964]. 
=============================================
[2019-04-07 12:52:31,614] A3C_AGENT_WORKER-Thread-11 INFO:Local step 30000, global step 485616: loss 1.7776
[2019-04-07 12:52:31,615] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 30000, global step 485616: learning rate 0.0000
[2019-04-07 12:52:32,112] A3C_AGENT_WORKER-Thread-10 INFO:Local step 30500, global step 485709: loss 2.4197
[2019-04-07 12:52:32,114] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 30500, global step 485711: learning rate 0.0000
[2019-04-07 12:52:33,708] A3C_AGENT_WORKER-Thread-15 INFO:Local step 30000, global step 485979: loss 1.4963
[2019-04-07 12:52:33,708] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 30000, global step 485979: learning rate 0.0000
[2019-04-07 12:52:33,842] A3C_AGENT_WORKER-Thread-17 INFO:Local step 30000, global step 485999: loss 1.7000
[2019-04-07 12:52:33,847] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 30000, global step 485999: learning rate 0.0000
[2019-04-07 12:52:34,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:52:34,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:52:34,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run12
[2019-04-07 12:52:34,748] A3C_AGENT_WORKER-Thread-5 INFO:Local step 30000, global step 486157: loss 1.5204
[2019-04-07 12:52:34,760] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 30000, global step 486157: learning rate 0.0000
[2019-04-07 12:52:35,032] A3C_AGENT_WORKER-Thread-2 INFO:Local step 30000, global step 486205: loss 1.8916
[2019-04-07 12:52:35,033] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 30000, global step 486205: learning rate 0.0000
[2019-04-07 12:52:36,712] A3C_AGENT_WORKER-Thread-20 INFO:Local step 30000, global step 486467: loss 1.8106
[2019-04-07 12:52:36,712] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 30000, global step 486467: learning rate 0.0000
[2019-04-07 12:52:40,257] A3C_AGENT_WORKER-Thread-19 INFO:Local step 31000, global step 487060: loss 15.1571
[2019-04-07 12:52:40,260] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 31000, global step 487060: learning rate 0.0000
[2019-04-07 12:52:48,813] A3C_AGENT_WORKER-Thread-14 INFO:Local step 31000, global step 488698: loss 15.9450
[2019-04-07 12:52:48,814] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 31000, global step 488698: learning rate 0.0000
[2019-04-07 12:52:51,884] A3C_AGENT_WORKER-Thread-6 INFO:Local step 31000, global step 489317: loss 15.7380
[2019-04-07 12:52:51,885] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 31000, global step 489317: learning rate 0.0000
[2019-04-07 12:52:52,338] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:52:52,338] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:52:52,342] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run12
[2019-04-07 12:53:00,428] A3C_AGENT_WORKER-Thread-13 INFO:Local step 30500, global step 490857: loss 3.3760
[2019-04-07 12:53:00,429] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 30500, global step 490857: learning rate 0.0000
[2019-04-07 12:53:00,836] A3C_AGENT_WORKER-Thread-16 INFO:Local step 30500, global step 490944: loss 2.9622
[2019-04-07 12:53:00,836] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 30500, global step 490944: learning rate 0.0000
[2019-04-07 12:53:01,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:53:01,298] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:53:01,302] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run12
[2019-04-07 12:53:01,572] A3C_AGENT_WORKER-Thread-12 INFO:Local step 30500, global step 491085: loss 2.8533
[2019-04-07 12:53:01,573] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 30500, global step 491085: learning rate 0.0000
[2019-04-07 12:53:03,118] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.2116043e-16 8.9372123e-15 1.2516257e-19 2.1547642e-11 2.6323046e-14
 1.0000000e+00 4.5348580e-10 1.0891295e-11], sum to 1.0000
[2019-04-07 12:53:03,119] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4085
[2019-04-07 12:53:03,178] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 57.0, 0.0, 0.0, 24.0, 23.82108279538539, 0.1274061843666454, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4658400.0000, 
sim time next is 4660200.0000, 
raw observation next is [2.0, 57.0, 0.0, 0.0, 24.0, 23.54298610295409, 0.0623293956486722, 0.0, 1.0, 130811.93961286407], 
processed observation next is [1.0, 0.9565217391304348, 0.518005540166205, 0.57, 0.0, 0.0, 0.5, 0.4619155085795074, 0.520776465216224, 0.0, 1.0, 0.6229139981564955], 
reward next is 0.6628, 
noisyNet noise sample is [array([0.18950365], dtype=float32), -1.6552672]. 
=============================================
[2019-04-07 12:53:03,625] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1110667e-14 8.5879058e-14 7.1290568e-17 3.5885434e-11 6.3310204e-14
 1.0000000e+00 1.2099161e-09 5.2036895e-12], sum to 1.0000
[2019-04-07 12:53:03,625] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7614
[2019-04-07 12:53:03,690] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.0, 49.0, 0.0, 0.0, 24.0, 23.52915584877078, 0.0445292234357762, 0.0, 1.0, 44567.51191756401], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3967200.0000, 
sim time next is 3969000.0000, 
raw observation next is [-8.5, 51.0, 0.0, 0.0, 24.0, 23.38867630216296, -0.03037281153773276, 0.0, 1.0, 69646.61460833746], 
processed observation next is [1.0, 0.9565217391304348, 0.22714681440443216, 0.51, 0.0, 0.0, 0.5, 0.44905635851358, 0.48987572948742236, 0.0, 1.0, 0.3316505457539879], 
reward next is 0.9541, 
noisyNet noise sample is [array([0.9793232], dtype=float32), -0.31557196]. 
=============================================
[2019-04-07 12:53:03,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[91.39809]
 [91.52051]
 [91.41734]
 [91.09557]
 [91.12282]], R is [[92.35413361]
 [92.4305954 ]
 [92.50628662]
 [92.58122253]
 [92.60347748]].
[2019-04-07 12:53:04,054] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:53:04,054] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:53:04,060] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run12
[2019-04-07 12:53:07,754] A3C_AGENT_WORKER-Thread-4 INFO:Local step 30500, global step 492116: loss 3.2201
[2019-04-07 12:53:07,754] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 30500, global step 492116: learning rate 0.0000
[2019-04-07 12:53:10,575] A3C_AGENT_WORKER-Thread-10 INFO:Local step 31000, global step 492547: loss 16.8120
[2019-04-07 12:53:10,586] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 31000, global step 492549: learning rate 0.0000
[2019-04-07 12:53:12,462] A3C_AGENT_WORKER-Thread-11 INFO:Local step 30500, global step 492879: loss 3.3433
[2019-04-07 12:53:12,462] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 30500, global step 492879: learning rate 0.0000
[2019-04-07 12:53:13,459] A3C_AGENT_WORKER-Thread-15 INFO:Local step 30500, global step 493051: loss 3.4890
[2019-04-07 12:53:13,464] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 30500, global step 493051: learning rate 0.0000
[2019-04-07 12:53:14,132] A3C_AGENT_WORKER-Thread-5 INFO:Local step 30500, global step 493160: loss 3.5187
[2019-04-07 12:53:14,135] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 30500, global step 493160: learning rate 0.0000
[2019-04-07 12:53:15,835] A3C_AGENT_WORKER-Thread-2 INFO:Local step 30500, global step 493447: loss 3.3691
[2019-04-07 12:53:15,836] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 30500, global step 493447: learning rate 0.0000
[2019-04-07 12:53:15,985] A3C_AGENT_WORKER-Thread-17 INFO:Local step 30500, global step 493469: loss 3.4351
[2019-04-07 12:53:15,988] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 30500, global step 493469: learning rate 0.0000
[2019-04-07 12:53:17,940] A3C_AGENT_WORKER-Thread-20 INFO:Local step 30500, global step 493777: loss 3.6912
[2019-04-07 12:53:17,940] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 30500, global step 493777: learning rate 0.0000
[2019-04-07 12:53:22,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:53:22,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:53:22,883] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run12
[2019-04-07 12:53:27,781] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1946058e-19 1.1861485e-15 2.0450163e-20 3.6677651e-13 4.8339713e-15
 1.0000000e+00 3.9597969e-10 9.1385222e-13], sum to 1.0000
[2019-04-07 12:53:27,781] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1839
[2019-04-07 12:53:27,962] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8, 73.0, 55.5, 33.0, 24.0, 23.4932473773906, -0.03744910280446483, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4521600.0000, 
sim time next is 4523400.0000, 
raw observation next is [-0.4, 72.5, 111.0, 66.0, 24.0, 23.73709916165909, 0.04007817017201808, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.45152354570637127, 0.725, 0.37, 0.07292817679558011, 0.5, 0.478091596804924, 0.5133593900573393, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9848863], dtype=float32), 0.23871692]. 
=============================================
[2019-04-07 12:53:36,021] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.9086080e-18 5.1204148e-16 2.5494547e-21 2.2216566e-13 3.3742807e-16
 1.0000000e+00 1.2229734e-10 9.1604716e-14], sum to 1.0000
[2019-04-07 12:53:36,022] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2152
[2019-04-07 12:53:36,073] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.15, 67.5, 0.0, 0.0, 24.0, 24.05968748486412, 0.1405066071968682, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4422600.0000, 
sim time next is 4424400.0000, 
raw observation next is [3.8, 68.0, 0.0, 0.0, 24.0, 23.88832172575364, 0.09200764322055865, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.5678670360110805, 0.68, 0.0, 0.0, 0.5, 0.4906934771461368, 0.5306692144068529, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.52396953], dtype=float32), -0.07598255]. 
=============================================
[2019-04-07 12:53:38,698] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1731386e-16 8.7787054e-15 4.5349018e-21 5.6954218e-14 3.0600129e-16
 1.0000000e+00 1.8714677e-10 2.0400291e-13], sum to 1.0000
[2019-04-07 12:53:38,699] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6998
[2019-04-07 12:53:38,787] A3C_AGENT_WORKER-Thread-13 INFO:Local step 31000, global step 497667: loss 16.6577
[2019-04-07 12:53:38,792] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 31000, global step 497667: learning rate 0.0000
[2019-04-07 12:53:38,796] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 52.0, 187.0, 24.0, 24.0, 23.84718552320427, 0.04042400531621271, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4539600.0000, 
sim time next is 4541400.0000, 
raw observation next is [2.5, 50.5, 247.0, 48.0, 24.0, 24.12067224577518, 0.01028944742754967, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5318559556786704, 0.505, 0.8233333333333334, 0.05303867403314917, 0.5, 0.5100560204812649, 0.5034298158091832, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2085036], dtype=float32), 0.26821655]. 
=============================================
[2019-04-07 12:53:40,844] A3C_AGENT_WORKER-Thread-16 INFO:Local step 31000, global step 498009: loss 16.7189
[2019-04-07 12:53:40,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 31000, global step 498009: learning rate 0.0000
[2019-04-07 12:53:41,284] A3C_AGENT_WORKER-Thread-12 INFO:Local step 31000, global step 498091: loss 16.4546
[2019-04-07 12:53:41,284] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 31000, global step 498091: learning rate 0.0000
[2019-04-07 12:53:44,485] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.07069636e-16 9.33735104e-14 8.87694690e-20 1.11507236e-11
 1.00447748e-14 1.00000000e+00 1.15434484e-09 4.27940149e-12], sum to 1.0000
[2019-04-07 12:53:44,485] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9706
[2019-04-07 12:53:44,567] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.3, 68.0, 0.0, 0.0, 24.0, 23.60667150532292, -0.01243628613277693, 0.0, 1.0, 20524.28136731242], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4591800.0000, 
sim time next is 4593600.0000, 
raw observation next is [-1.5, 69.0, 0.0, 0.0, 24.0, 23.55930655297082, -0.04427800697548803, 0.0, 1.0, 19187.662812931958], 
processed observation next is [1.0, 0.17391304347826086, 0.4210526315789474, 0.69, 0.0, 0.0, 0.5, 0.4632755460809017, 0.485240664341504, 0.0, 1.0, 0.09136982291872361], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9230304], dtype=float32), -1.2457732]. 
=============================================
[2019-04-07 12:53:45,851] A3C_AGENT_WORKER-Thread-4 INFO:Local step 31000, global step 498897: loss 16.4620
[2019-04-07 12:53:45,851] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 31000, global step 498897: learning rate 0.0000
[2019-04-07 12:53:51,201] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-07 12:53:51,218] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:53:51,219] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:53:51,220] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:53:51,220] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:53:51,221] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:53:51,221] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:53:51,223] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run26
[2019-04-07 12:53:51,238] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run26
[2019-04-07 12:53:51,251] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run26
[2019-04-07 12:53:51,646] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:53:51,651] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:53:52,187] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:53:52,187] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:53:52,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run12
[2019-04-07 12:53:52,399] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run12
[2019-04-07 12:55:58,718] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2788.9052 70927233.8163 166.2180
[2019-04-07 12:56:26,855] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 12:56:35,763] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 12:56:36,798] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 500000, evaluation results [500000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2788.9051760082016, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 12:56:36,902] A3C_AGENT_WORKER-Thread-11 INFO:Local step 31000, global step 500019: loss 17.3123
[2019-04-07 12:56:36,904] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 31000, global step 500019: learning rate 0.0000
[2019-04-07 12:56:39,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:56:39,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:56:39,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run12
[2019-04-07 12:56:40,323] A3C_AGENT_WORKER-Thread-5 INFO:Local step 31000, global step 500376: loss 16.7897
[2019-04-07 12:56:40,324] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 31000, global step 500376: learning rate 0.0000
[2019-04-07 12:56:40,979] A3C_AGENT_WORKER-Thread-15 INFO:Local step 31000, global step 500431: loss 16.9355
[2019-04-07 12:56:40,980] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 31000, global step 500431: learning rate 0.0000
[2019-04-07 12:56:41,783] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8293432e-15 2.9031958e-13 6.5537768e-18 7.8334318e-12 7.2788509e-13
 1.0000000e+00 1.8871912e-08 2.6784217e-11], sum to 1.0000
[2019-04-07 12:56:41,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2487
[2019-04-07 12:56:41,902] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 93.0, 0.0, 0.0, 24.0, 22.72893032850049, -0.1995005228263301, 0.0, 1.0, 42745.656292017025], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4777200.0000, 
sim time next is 4779000.0000, 
raw observation next is [-6.1, 92.5, 0.0, 0.0, 24.0, 22.65759597462569, -0.215130332564336, 0.0, 1.0, 42823.46385682845], 
processed observation next is [0.0, 0.30434782608695654, 0.29362880886426596, 0.925, 0.0, 0.0, 0.5, 0.3881329978854741, 0.42828988914522137, 0.0, 1.0, 0.20392125646108786], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.51847297], dtype=float32), 0.74976367]. 
=============================================
[2019-04-07 12:56:41,941] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[91.45587 ]
 [91.554924]
 [91.784935]
 [91.56032 ]
 [91.22679 ]], R is [[91.33527374]
 [91.42192078]
 [91.50770569]
 [91.59262848]
 [91.67670441]].
[2019-04-07 12:56:42,992] A3C_AGENT_WORKER-Thread-17 INFO:Local step 31000, global step 500633: loss 17.0557
[2019-04-07 12:56:42,994] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 31000, global step 500633: learning rate 0.0000
[2019-04-07 12:56:43,195] A3C_AGENT_WORKER-Thread-2 INFO:Local step 31000, global step 500651: loss 17.6860
[2019-04-07 12:56:43,196] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 31000, global step 500651: learning rate 0.0000
[2019-04-07 12:56:46,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:56:46,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:56:46,016] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run12
[2019-04-07 12:56:46,191] A3C_AGENT_WORKER-Thread-20 INFO:Local step 31000, global step 500920: loss 17.0564
[2019-04-07 12:56:46,191] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 31000, global step 500920: learning rate 0.0000
[2019-04-07 12:56:55,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:56:55,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:56:55,272] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run12
[2019-04-07 12:56:58,431] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:56:58,431] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:56:58,434] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run12
[2019-04-07 12:56:58,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:56:58,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:56:58,616] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run12
[2019-04-07 12:57:01,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:57:01,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:57:01,192] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run12
[2019-04-07 12:57:01,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:57:01,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:57:01,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run12
[2019-04-07 12:57:02,839] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9660812e-16 8.4375412e-14 1.4881869e-18 9.7513369e-12 3.8647547e-15
 1.0000000e+00 5.1168794e-09 4.3017121e-11], sum to 1.0000
[2019-04-07 12:57:02,839] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8478
[2019-04-07 12:57:02,929] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 78.0, 0.0, 0.0, 24.0, 22.65014087727736, -0.3422169733817035, 0.0, 1.0, 45798.172495578474], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1915200.0000, 
sim time next is 1917000.0000, 
raw observation next is [-8.65, 80.0, 0.0, 0.0, 24.0, 22.5307700814985, -0.3573082232864966, 0.0, 1.0, 46066.07857935884], 
processed observation next is [1.0, 0.17391304347826086, 0.22299168975069253, 0.8, 0.0, 0.0, 0.5, 0.37756417345820825, 0.38089725890450116, 0.0, 1.0, 0.2193622789493278], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5992229], dtype=float32), -0.018068306]. 
=============================================
[2019-04-07 12:57:02,942] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[97.7835  ]
 [98.00189 ]
 [98.357285]
 [96.5704  ]
 [95.61987 ]], R is [[97.6854248 ]
 [97.70857239]
 [97.73149109]
 [97.75418091]
 [97.77664185]].
[2019-04-07 12:57:04,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 12:57:04,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:57:04,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run12
[2019-04-07 12:57:10,096] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2516226e-19 5.0739433e-16 2.4088528e-22 3.2222571e-15 3.2788937e-18
 1.0000000e+00 1.2149979e-11 8.5391987e-14], sum to 1.0000
[2019-04-07 12:57:10,096] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1095
[2019-04-07 12:57:10,150] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.8, 93.0, 93.0, 0.0, 24.0, 23.77094848798967, -0.02698300615497301, 1.0, 1.0, 62482.265252503705], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 914400.0000, 
sim time next is 916200.0000, 
raw observation next is [4.1, 93.0, 90.0, 0.0, 24.0, 24.13097835336167, 0.008812935976521765, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5761772853185596, 0.93, 0.3, 0.0, 0.5, 0.5109148627801391, 0.5029376453255072, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.19571085], dtype=float32), 0.51396716]. 
=============================================
[2019-04-07 12:57:21,878] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0438609e-16 9.3893704e-15 2.7800632e-20 3.8851501e-13 1.7016171e-13
 1.0000000e+00 1.5112135e-10 1.0186148e-12], sum to 1.0000
[2019-04-07 12:57:21,878] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0413
[2019-04-07 12:57:21,974] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 75.0, 0.0, 0.0, 24.0, 23.06872532880417, -0.1803640923363517, 0.0, 1.0, 45822.50607586724], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 252000.0000, 
sim time next is 253800.0000, 
raw observation next is [-3.9, 78.5, 0.0, 0.0, 24.0, 23.01831547096532, -0.1930354737767235, 0.0, 1.0, 45617.72343514537], 
processed observation next is [1.0, 0.9565217391304348, 0.3545706371191136, 0.785, 0.0, 0.0, 0.5, 0.41819295591377664, 0.4356548420744255, 0.0, 1.0, 0.2172272544530732], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.64660007], dtype=float32), -2.0975938]. 
=============================================
[2019-04-07 12:57:22,402] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2649572e-16 6.2499376e-14 1.4300839e-18 1.0785241e-12 5.5404840e-15
 1.0000000e+00 5.4260652e-10 2.5759147e-12], sum to 1.0000
[2019-04-07 12:57:22,402] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8665
[2019-04-07 12:57:22,448] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.95, 98.0, 0.0, 0.0, 24.0, 23.60936490905709, 0.1550359278754434, 0.0, 1.0, 35209.016279207404], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1294200.0000, 
sim time next is 1296000.0000, 
raw observation next is [4.4, 96.0, 0.0, 0.0, 24.0, 23.55732925641994, 0.1535636735095673, 0.0, 1.0, 46226.44643479217], 
processed observation next is [1.0, 0.0, 0.5844875346260389, 0.96, 0.0, 0.0, 0.5, 0.4631107713683284, 0.5511878911698558, 0.0, 1.0, 0.22012593540377223], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.56821257], dtype=float32), -1.6078424]. 
=============================================
[2019-04-07 12:57:22,460] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[104.94869]
 [105.00781]
 [105.40363]
 [105.6921 ]
 [105.53783]], R is [[106.7675705 ]
 [106.69989777]
 [106.63289642]
 [106.56656647]
 [106.47731781]].
[2019-04-07 12:57:31,716] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.57013909e-19 1.26342486e-14 3.82252864e-22 2.83751108e-14
 3.61006104e-17 1.00000000e+00 9.54465743e-11 3.01008201e-14], sum to 1.0000
[2019-04-07 12:57:31,717] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5035
[2019-04-07 12:57:31,782] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 24.0, 23.4788210567762, 0.01716324585431959, 0.0, 1.0, 13686.877985134417], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1404000.0000, 
sim time next is 1405800.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 24.0, 23.34397309481487, 0.001818177349085566, 0.0, 1.0, 63869.87732797572], 
processed observation next is [1.0, 0.2608695652173913, 0.44598337950138506, 1.0, 0.0, 0.0, 0.5, 0.44533109123457254, 0.5006060591163618, 0.0, 1.0, 0.30414227299036056], 
reward next is 0.9816, 
noisyNet noise sample is [array([-1.2145343], dtype=float32), -1.8523915]. 
=============================================
[2019-04-07 12:57:42,619] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0315811e-13 6.2202099e-13 2.9074902e-17 1.1268444e-11 3.1309650e-13
 1.0000000e+00 4.8896641e-08 8.5655932e-10], sum to 1.0000
[2019-04-07 12:57:42,620] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0741
[2019-04-07 12:57:42,840] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.75, 84.5, 0.0, 0.0, 24.0, 23.14072141314107, -0.1816702529490344, 0.0, 1.0, 43308.26801166913], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1877400.0000, 
sim time next is 1879200.0000, 
raw observation next is [-5.0, 86.0, 0.0, 0.0, 24.0, 23.11800231915709, -0.1892267690860999, 0.0, 1.0, 44685.30450227655], 
processed observation next is [0.0, 0.782608695652174, 0.32409972299168976, 0.86, 0.0, 0.0, 0.5, 0.42650019326309074, 0.4369244103046334, 0.0, 1.0, 0.212787164296555], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.92122996], dtype=float32), 1.3020161]. 
=============================================
[2019-04-07 12:57:47,636] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3370719e-14 1.4290004e-12 2.2929981e-16 1.1421100e-11 3.1188971e-12
 1.0000000e+00 9.5470156e-09 5.7396407e-11], sum to 1.0000
[2019-04-07 12:57:47,637] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6122
[2019-04-07 12:57:48,028] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.1, 41.5, 0.0, 0.0, 24.0, 21.89998148665128, -0.4180434174210474, 1.0, 1.0, 150827.02974595397], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 459000.0000, 
sim time next is 460800.0000, 
raw observation next is [-7.8, 40.0, 11.5, 0.0, 24.0, 23.38630728955123, -0.2361761451083405, 1.0, 1.0, 54272.084338194334], 
processed observation next is [1.0, 0.34782608695652173, 0.24653739612188366, 0.4, 0.03833333333333333, 0.0, 0.5, 0.4488589407959358, 0.42127461829721985, 1.0, 1.0, 0.2584384968485445], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.77912474], dtype=float32), 0.60244596]. 
=============================================
[2019-04-07 12:57:52,573] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5735275e-14 1.1929295e-12 3.4749017e-17 5.3947524e-11 1.1019335e-12
 9.9999988e-01 6.1987528e-08 9.8166419e-10], sum to 1.0000
[2019-04-07 12:57:52,574] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1634
[2019-04-07 12:57:52,665] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 82.0, 0.0, 0.0, 24.0, 23.2322171369994, -0.1210802817726213, 0.0, 1.0, 47004.570876707345], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1810800.0000, 
sim time next is 1812600.0000, 
raw observation next is [-5.0, 80.5, 0.0, 0.0, 24.0, 23.17601349009997, -0.13374640764551, 0.0, 1.0, 46712.428196090164], 
processed observation next is [0.0, 1.0, 0.32409972299168976, 0.805, 0.0, 0.0, 0.5, 0.4313344575083307, 0.4554178641181634, 0.0, 1.0, 0.22244013426709602], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8892847], dtype=float32), -2.2515023]. 
=============================================
[2019-04-07 12:57:54,508] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0824266e-15 1.2286107e-13 1.4940237e-17 7.0151766e-12 4.2818895e-13
 1.0000000e+00 4.8447511e-08 3.1217435e-11], sum to 1.0000
[2019-04-07 12:57:54,509] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7760
[2019-04-07 12:57:54,688] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 96.0, 0.0, 0.0, 24.0, 23.12329228578083, -0.2412788551868757, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 500400.0000, 
sim time next is 502200.0000, 
raw observation next is [1.1, 96.0, 0.0, 0.0, 24.0, 22.81153751287397, -0.2713941340895499, 1.0, 1.0, 56953.897376764304], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.96, 0.0, 0.0, 0.5, 0.40096145940616407, 0.4095352886368167, 1.0, 1.0, 0.27120903512744904], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.26602498], dtype=float32), 0.6363521]. 
=============================================
[2019-04-07 12:58:17,919] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.95930347e-15 3.91945482e-13 1.20077955e-17 8.63525640e-11
 1.13354733e-13 1.00000000e+00 2.33053896e-08 2.02147413e-11], sum to 1.0000
[2019-04-07 12:58:17,919] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0974
[2019-04-07 12:58:17,969] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 24.0, 23.17563605861469, -0.1619398054971332, 0.0, 1.0, 39695.240770442055], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3031200.0000, 
sim time next is 3033000.0000, 
raw observation next is [-5.5, 74.0, 0.0, 0.0, 24.0, 23.11096445565462, -0.1804546697317577, 0.0, 1.0, 39952.95220567385], 
processed observation next is [0.0, 0.08695652173913043, 0.3102493074792244, 0.74, 0.0, 0.0, 0.5, 0.4259137046378851, 0.4398484434227474, 0.0, 1.0, 0.19025215336035167], 
reward next is 1.0000, 
noisyNet noise sample is [array([3.154102], dtype=float32), 0.45943832]. 
=============================================
[2019-04-07 12:58:17,973] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[90.3588  ]
 [90.55152 ]
 [90.200516]
 [90.72971 ]
 [91.00487 ]], R is [[90.62363434]
 [90.7173996 ]
 [90.81022644]
 [90.9021225 ]
 [90.99310303]].
[2019-04-07 12:58:26,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6409088e-16 1.0822606e-15 1.4120157e-19 2.3608218e-13 2.8941811e-15
 1.0000000e+00 9.0964003e-10 8.0961897e-13], sum to 1.0000
[2019-04-07 12:58:26,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7180
[2019-04-07 12:58:26,991] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 92.5, 111.0, 812.0, 24.0, 24.52393788229463, 0.3010322829191049, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3245400.0000, 
sim time next is 3247200.0000, 
raw observation next is [-4.0, 100.0, 106.0, 790.5, 24.0, 24.85297921560971, 0.3415637316636987, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3518005540166205, 1.0, 0.35333333333333333, 0.8734806629834254, 0.5, 0.5710816013008092, 0.6138545772212329, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4381609], dtype=float32), 0.9526972]. 
=============================================
[2019-04-07 12:58:27,800] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2248800e-20 5.4921669e-16 1.4135925e-22 1.2630394e-14 5.3082810e-18
 1.0000000e+00 1.2860960e-12 3.7669649e-14], sum to 1.0000
[2019-04-07 12:58:27,804] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3074
[2019-04-07 12:58:27,849] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 76.0, 0.0, 0.0, 24.0, 24.03562843607061, 0.2002088173843076, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1027800.0000, 
sim time next is 1029600.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 24.0, 24.15487653527964, 0.2136864601211811, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.8614958448753465, 0.75, 0.0, 0.0, 0.5, 0.5129063779399701, 0.5712288200403938, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7141003], dtype=float32), -0.6537239]. 
=============================================
[2019-04-07 12:58:37,740] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5695755e-16 3.4167806e-15 1.3760218e-19 7.2047507e-12 1.3843017e-14
 1.0000000e+00 6.9233319e-10 4.6491221e-11], sum to 1.0000
[2019-04-07 12:58:37,747] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2038
[2019-04-07 12:58:37,898] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 54.0, 0.0, 0.0, 24.0, 23.53096849782335, -0.1725200737478372, 1.0, 1.0, 8363.130217674343], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2532600.0000, 
sim time next is 2534400.0000, 
raw observation next is [-2.8, 54.0, 28.5, 9.0, 24.0, 23.4564511393652, -0.2122177102708979, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.38504155124653744, 0.54, 0.095, 0.009944751381215469, 0.5, 0.45470426161376665, 0.429260763243034, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.038095], dtype=float32), 0.5538276]. 
=============================================
[2019-04-07 12:58:51,919] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3611563e-16 3.0596673e-13 1.6355326e-18 2.6722765e-12 5.8794651e-14
 1.0000000e+00 9.3536268e-10 2.5605336e-12], sum to 1.0000
[2019-04-07 12:58:51,919] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3859
[2019-04-07 12:58:52,010] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 62.5, 84.0, 704.0, 24.0, 25.18259042109601, 0.2160165984372022, 1.0, 1.0, 1245.360778015369], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3425400.0000, 
sim time next is 3427200.0000, 
raw observation next is [2.0, 67.0, 72.5, 608.5, 24.0, 24.61183829890578, 0.2336783938818884, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.518005540166205, 0.67, 0.24166666666666667, 0.6723756906077348, 0.5, 0.5509865249088151, 0.5778927979606295, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.93708616], dtype=float32), 1.338284]. 
=============================================
[2019-04-07 12:58:53,866] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5237348e-17 2.2609811e-13 3.5672879e-21 1.1469180e-13 1.5306516e-15
 1.0000000e+00 8.3670121e-10 1.3496075e-12], sum to 1.0000
[2019-04-07 12:58:53,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8411
[2019-04-07 12:58:53,939] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 24.0, 23.45382567430192, -0.02842721075777599, 0.0, 1.0, 37787.95731980281], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3474000.0000, 
sim time next is 3475800.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 24.0, 23.49660606939261, -0.02037916139342633, 0.0, 1.0, 29649.821757389447], 
processed observation next is [1.0, 0.21739130434782608, 0.46260387811634357, 0.72, 0.0, 0.0, 0.5, 0.4580505057827174, 0.49320694620219124, 0.0, 1.0, 0.14118962741614022], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8823743], dtype=float32), -1.4433409]. 
=============================================
[2019-04-07 12:59:02,796] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-07 12:59:02,798] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:59:02,798] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:59:02,800] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run27
[2019-04-07 12:59:02,839] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 12:59:02,840] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:59:02,845] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run27
[2019-04-07 12:59:02,862] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 12:59:02,865] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 12:59:02,867] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run27
[2019-04-07 13:01:04,174] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 13:01:34,373] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 13:01:39,672] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 13:01:40,710] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 520000, evaluation results [520000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 13:01:41,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.86106251e-14 6.80257109e-12 9.05321586e-17 1.08473279e-10
 3.56475309e-12 9.99999881e-01 8.58901288e-08 1.09764066e-10], sum to 1.0000
[2019-04-07 13:01:41,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0490
[2019-04-07 13:01:41,229] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 26.0, 109.0, 812.0, 24.0, 24.90834530396637, 0.2542554725678174, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4024800.0000, 
sim time next is 4026600.0000, 
raw observation next is [-2.5, 23.0, 104.0, 794.0, 24.0, 25.09720901663884, 0.2846581979768957, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.39335180055401664, 0.23, 0.3466666666666667, 0.8773480662983425, 0.5, 0.5914340847199032, 0.5948860659922985, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.387873], dtype=float32), 0.023142172]. 
=============================================
[2019-04-07 13:01:53,715] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9650582e-17 3.7635232e-15 1.5530810e-19 1.6682085e-13 2.4863890e-15
 1.0000000e+00 2.6772484e-10 3.5136195e-12], sum to 1.0000
[2019-04-07 13:01:53,716] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5247
[2019-04-07 13:01:53,748] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 53.5, 103.0, 775.0, 24.0, 24.66056079000534, 0.2285344379805802, 1.0, 1.0, 6226.803890076847], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3421800.0000, 
sim time next is 3423600.0000, 
raw observation next is [3.0, 58.0, 93.5, 739.5, 24.0, 24.93139202759396, 0.277638060078241, 1.0, 1.0, 6226.803890076847], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.58, 0.31166666666666665, 0.8171270718232044, 0.5, 0.5776160022994968, 0.5925460200260804, 1.0, 1.0, 0.029651447095604033], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.08192261], dtype=float32), -0.13560517]. 
=============================================
[2019-04-07 13:02:13,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2557085e-17 1.1170034e-14 6.0009493e-19 2.5785434e-13 2.1205643e-15
 1.0000000e+00 5.1493421e-10 5.7788946e-13], sum to 1.0000
[2019-04-07 13:02:13,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2916
[2019-04-07 13:02:13,711] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 79.0, 42.0, 4.0, 24.0, 23.619706097726, -0.1219287896730282, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2620800.0000, 
sim time next is 2622600.0000, 
raw observation next is [-7.0, 77.0, 77.0, 0.0, 24.0, 23.62300240263027, -0.09291784366162507, 1.0, 1.0, 6244.912833860156], 
processed observation next is [1.0, 0.34782608695652173, 0.2686980609418283, 0.77, 0.25666666666666665, 0.0, 0.5, 0.4685835335525225, 0.46902738544612493, 1.0, 1.0, 0.029737680161238837], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.948922], dtype=float32), 0.8074523]. 
=============================================
[2019-04-07 13:02:31,064] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:02:31,064] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:02:31,068] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run13
[2019-04-07 13:02:31,133] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.4972797e-14 4.1875173e-11 1.8321877e-15 2.6395397e-10 2.3344939e-12
 1.0000000e+00 4.2652310e-08 1.5407697e-10], sum to 1.0000
[2019-04-07 13:02:31,133] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5634
[2019-04-07 13:02:31,214] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.85, 40.5, 24.0, 163.0, 24.0, 23.39645587308951, -0.0690948293348136, 0.0, 1.0, 9340.205835115268], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4210200.0000, 
sim time next is 4212000.0000, 
raw observation next is [1.7, 41.0, 0.0, 0.0, 24.0, 23.26340533914072, -0.1078410694756041, 0.0, 1.0, 12453.607780153694], 
processed observation next is [0.0, 0.782608695652174, 0.5096952908587258, 0.41, 0.0, 0.0, 0.5, 0.4386171115950601, 0.46405297684146535, 0.0, 1.0, 0.059302894191208065], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3970407], dtype=float32), -0.47319344]. 
=============================================
[2019-04-07 13:02:31,229] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[82.9616  ]
 [83.461945]
 [83.48773 ]
 [83.414764]
 [82.61897 ]], R is [[82.18664551]
 [82.36477661]
 [82.54113007]
 [82.71572113]
 [82.88856506]].
[2019-04-07 13:02:35,424] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1904451e-16 2.1465526e-14 7.5900174e-20 3.3948791e-13 8.8524144e-16
 1.0000000e+00 2.2634516e-11 7.1112539e-13], sum to 1.0000
[2019-04-07 13:02:35,424] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1416
[2019-04-07 13:02:35,543] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 24.0, 23.35278977074544, -0.1411344079138925, 0.0, 1.0, 58255.88148368284], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2601000.0000, 
sim time next is 2602800.0000, 
raw observation next is [-5.0, 74.0, 0.0, 0.0, 24.0, 23.30594840140484, -0.1418838346608865, 0.0, 1.0, 48672.562643661164], 
processed observation next is [1.0, 0.13043478260869565, 0.32409972299168976, 0.74, 0.0, 0.0, 0.5, 0.4421623667837367, 0.45270538844637115, 0.0, 1.0, 0.23177410782695793], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.58121103], dtype=float32), 2.2704213]. 
=============================================
[2019-04-07 13:02:42,451] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.7465866e-14 2.5860103e-13 1.4892156e-17 3.7198599e-12 1.2670254e-14
 1.0000000e+00 7.9434698e-10 9.6483113e-11], sum to 1.0000
[2019-04-07 13:02:42,452] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5343
[2019-04-07 13:02:42,515] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 68.0, 0.0, 0.0, 24.0, 23.44679541580899, -0.05189349713517141, 0.0, 1.0, 51543.31594299463], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3713400.0000, 
sim time next is 3715200.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 24.0, 23.48312984005842, -0.04939493607186513, 0.0, 1.0, 34893.78883648934], 
processed observation next is [1.0, 0.0, 0.3795013850415513, 0.71, 0.0, 0.0, 0.5, 0.4569274866715351, 0.4835350213093783, 0.0, 1.0, 0.1661608992213778], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.49491516], dtype=float32), 0.0062836506]. 
=============================================
[2019-04-07 13:02:48,083] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:02:48,083] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:02:48,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run13
[2019-04-07 13:02:51,181] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6450955e-16 8.8928871e-14 4.9905883e-18 5.1903273e-12 4.9582615e-15
 1.0000000e+00 6.8825461e-09 1.7329511e-11], sum to 1.0000
[2019-04-07 13:02:51,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1033
[2019-04-07 13:02:51,292] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 68.0, 0.0, 0.0, 24.0, 23.50803723974853, -0.04563269164476012, 0.0, 1.0, 50654.89941136085], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3900600.0000, 
sim time next is 3902400.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 24.0, 23.40814395420414, -0.02752462483799502, 0.0, 1.0, 71103.43700463157], 
processed observation next is [1.0, 0.17391304347826086, 0.3795013850415513, 0.71, 0.0, 0.0, 0.5, 0.4506786628503449, 0.49082512505400167, 0.0, 1.0, 0.33858779526015037], 
reward next is 0.9471, 
noisyNet noise sample is [array([-0.4396201], dtype=float32), -0.50112265]. 
=============================================
[2019-04-07 13:02:55,917] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5855395e-19 3.7716865e-15 1.9312688e-21 1.0396303e-13 2.3703203e-16
 1.0000000e+00 8.5371273e-11 1.9472408e-13], sum to 1.0000
[2019-04-07 13:02:55,917] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4999
[2019-04-07 13:02:55,970] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 24.0, 23.49660606939261, -0.02037916139342633, 0.0, 1.0, 29649.821757389447], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3475800.0000, 
sim time next is 3477600.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 24.0, 23.50033444703433, -0.04073032250920102, 0.0, 1.0, 32691.562655644], 
processed observation next is [1.0, 0.2608695652173913, 0.46260387811634357, 0.72, 0.0, 0.0, 0.5, 0.4583612039195275, 0.4864232258302663, 0.0, 1.0, 0.15567410788401906], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09279239], dtype=float32), -0.9537405]. 
=============================================
[2019-04-07 13:02:58,649] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.0421419e-14 1.7670586e-12 7.6777724e-16 5.3366225e-11 2.3282060e-12
 9.9999988e-01 1.5267040e-07 8.6701037e-09], sum to 1.0000
[2019-04-07 13:02:58,654] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0654
[2019-04-07 13:02:58,922] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 59.0, 91.0, 497.0, 24.0, 23.76947646577556, -0.05952160558738397, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3056400.0000, 
sim time next is 3058200.0000, 
raw observation next is [-5.0, 56.5, 99.0, 635.0, 24.0, 23.6136885062966, -0.06617148965678225, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.32409972299168976, 0.565, 0.33, 0.7016574585635359, 0.5, 0.46780737552471674, 0.4779428367810726, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7334744], dtype=float32), 1.9051766]. 
=============================================
[2019-04-07 13:03:03,871] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.0067578e-19 6.1802880e-16 4.1891397e-22 1.1489537e-14 1.5508922e-17
 1.0000000e+00 6.3421306e-13 1.1160670e-13], sum to 1.0000
[2019-04-07 13:03:03,871] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4996
[2019-04-07 13:03:03,914] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.0, 100.0, 0.0, 0.0, 24.0, 25.37346871122616, 0.4634096987707134, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3175200.0000, 
sim time next is 3177000.0000, 
raw observation next is [5.0, 100.0, 0.0, 0.0, 24.0, 25.17501157286611, 0.4096807497364996, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6011080332409973, 1.0, 0.0, 0.0, 0.5, 0.597917631072176, 0.6365602499121665, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.10234205], dtype=float32), 0.097414464]. 
=============================================
[2019-04-07 13:03:03,932] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[119.919365]
 [120.25988 ]
 [120.84251 ]
 [121.05912 ]
 [121.054405]], R is [[118.41397095]
 [118.22983551]
 [118.04753876]
 [117.86706543]
 [117.68839264]].
[2019-04-07 13:03:07,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:03:07,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:03:07,320] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run13
[2019-04-07 13:03:20,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:03:20,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:03:20,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run13
[2019-04-07 13:03:22,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:03:22,898] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:03:22,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run13
[2019-04-07 13:03:31,394] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.7246127e-17 2.8923282e-14 6.6139462e-20 5.0111564e-13 2.3053922e-15
 1.0000000e+00 7.5521385e-09 1.0432739e-12], sum to 1.0000
[2019-04-07 13:03:31,394] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8704
[2019-04-07 13:03:31,549] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 96.0, 563.5, 24.0, 24.32905846205117, 0.09754188196446052, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3834000.0000, 
sim time next is 3835800.0000, 
raw observation next is [-3.0, 65.5, 101.0, 680.0, 24.0, 24.49957368329931, 0.1442801067465937, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.655, 0.33666666666666667, 0.7513812154696132, 0.5, 0.5416311402749425, 0.5480933689155313, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.22917786], dtype=float32), -0.81296015]. 
=============================================
[2019-04-07 13:03:44,222] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:03:44,222] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:03:44,237] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run13
[2019-04-07 13:03:44,822] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-07 13:03:44,822] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:03:44,823] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:03:44,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run28
[2019-04-07 13:03:44,849] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:03:44,850] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:03:44,852] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run28
[2019-04-07 13:03:44,871] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 13:03:44,873] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:03:44,876] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run28
[2019-04-07 13:05:48,265] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 13:06:24,077] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 13:06:31,067] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.5330 83805026.4189 32.8860
[2019-04-07 13:06:32,106] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 540000, evaluation results [540000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.5329620425596, 83805026.41892925, 32.88598103848735]
[2019-04-07 13:06:35,333] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1818252e-17 1.1521533e-14 5.9481395e-20 7.1233086e-13 2.5508063e-14
 1.0000000e+00 5.8235583e-11 2.7097329e-13], sum to 1.0000
[2019-04-07 13:06:35,333] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4389
[2019-04-07 13:06:35,496] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.15, 81.0, 0.0, 0.0, 24.0, 23.64693547121273, -0.006627228555247384, 0.0, 1.0, 6364.220790626364], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 959400.0000, 
sim time next is 961200.0000, 
raw observation next is [7.7, 80.0, 0.0, 0.0, 24.0, 23.50750071384315, -0.005550045009981209, 0.0, 1.0, 59436.42077483015], 
processed observation next is [1.0, 0.13043478260869565, 0.6759002770083103, 0.8, 0.0, 0.0, 0.5, 0.4589583928202625, 0.4981499849966729, 0.0, 1.0, 0.2830305751182388], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8565833], dtype=float32), 1.6067424]. 
=============================================
[2019-04-07 13:06:43,359] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.6251485e-15 7.3999097e-13 1.9708602e-16 8.4908738e-12 1.5218528e-13
 1.0000000e+00 2.2661116e-08 1.7968299e-10], sum to 1.0000
[2019-04-07 13:06:43,359] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1299
[2019-04-07 13:06:43,420] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 53.0, 146.0, 92.0, 24.0, 23.44594371358033, -0.1023566589497121, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4266000.0000, 
sim time next is 4267800.0000, 
raw observation next is [3.5, 53.5, 182.0, 131.0, 24.0, 23.44884709542089, -0.08956345496523656, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.5595567867036012, 0.535, 0.6066666666666667, 0.14475138121546963, 0.5, 0.45407059128507427, 0.4701455150115878, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5113344], dtype=float32), 0.32818893]. 
=============================================
[2019-04-07 13:06:56,612] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7259496e-18 1.1979161e-16 2.2151315e-21 4.9231677e-15 1.9723343e-16
 1.0000000e+00 2.2702786e-11 2.5476361e-14], sum to 1.0000
[2019-04-07 13:06:56,612] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5682
[2019-04-07 13:06:56,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:06:56,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:06:56,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run13
[2019-04-07 13:06:56,720] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.7, 92.0, 0.0, 0.0, 24.0, 23.34195971914093, -0.1386444461369805, 0.0, 1.0, 42945.58772004904], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 511200.0000, 
sim time next is 513000.0000, 
raw observation next is [3.0, 94.0, 0.0, 0.0, 24.0, 23.3786391141081, -0.1308737825482239, 0.0, 1.0, 41189.344687752244], 
processed observation next is [1.0, 0.9565217391304348, 0.5457063711911359, 0.94, 0.0, 0.0, 0.5, 0.448219926175675, 0.4563754058172587, 0.0, 1.0, 0.19613973660834402], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6845397], dtype=float32), 0.6116482]. 
=============================================
[2019-04-07 13:06:56,736] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[110.80257 ]
 [110.04473 ]
 [109.04643 ]
 [107.278465]
 [105.93853 ]], R is [[110.75403595]
 [110.64649963]
 [110.54003906]
 [110.43463898]
 [110.11342621]].
[2019-04-07 13:06:59,872] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:06:59,872] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:06:59,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run13
[2019-04-07 13:07:11,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:07:11,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:07:11,771] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run13
[2019-04-07 13:07:14,688] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:07:14,688] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:07:14,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run13
[2019-04-07 13:07:17,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:07:17,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:07:17,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run13
[2019-04-07 13:07:18,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:07:18,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:07:18,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run13
[2019-04-07 13:07:19,092] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:07:19,092] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:07:19,096] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run13
[2019-04-07 13:07:21,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:07:21,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:07:21,900] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run13
[2019-04-07 13:07:22,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:07:22,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:07:22,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run13
[2019-04-07 13:07:25,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:07:25,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:07:25,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run13
[2019-04-07 13:07:34,405] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.6365553e-18 4.0822749e-15 2.4279589e-22 1.3712583e-12 1.3895440e-15
 1.0000000e+00 1.1095426e-09 1.5873769e-13], sum to 1.0000
[2019-04-07 13:07:34,414] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3568
[2019-04-07 13:07:34,476] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.35, 92.0, 0.0, 0.0, 24.0, 23.44589407447208, 0.09417920724804009, 0.0, 1.0, 88374.46255984646], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1319400.0000, 
sim time next is 1321200.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 24.0, 23.58753399128562, 0.09080964538450836, 0.0, 1.0, 12210.221543341808], 
processed observation next is [1.0, 0.30434782608695654, 0.49307479224376743, 0.92, 0.0, 0.0, 0.5, 0.4656278326071351, 0.5302698817948361, 0.0, 1.0, 0.05814391211115147], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.650681], dtype=float32), 0.33045405]. 
=============================================
[2019-04-07 13:07:55,516] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.50454380e-14 6.82761681e-13 1.17830025e-17 5.16608284e-11
 8.37552575e-13 1.00000000e+00 1.80501991e-09 1.07071140e-11], sum to 1.0000
[2019-04-07 13:07:55,517] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1653
[2019-04-07 13:07:55,760] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.6, 54.5, 106.0, 658.0, 24.0, 23.68225611433198, -0.08343167409417136, 1.0, 1.0, 65674.4865351123], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 300600.0000, 
sim time next is 302400.0000, 
raw observation next is [-10.6, 49.0, 94.5, 708.0, 24.0, 23.81732224080217, -0.06059233582031864, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.1689750692520776, 0.49, 0.315, 0.7823204419889502, 0.5, 0.48477685340018084, 0.47980255472656047, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2189475], dtype=float32), 1.1545068]. 
=============================================
[2019-04-07 13:08:07,156] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0557548e-16 3.5919205e-14 1.7891468e-20 3.8208038e-13 7.3338931e-14
 1.0000000e+00 2.1106271e-10 4.4612356e-12], sum to 1.0000
[2019-04-07 13:08:07,156] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8796
[2019-04-07 13:08:07,276] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 83.0, 100.0, 73.0, 24.0, 23.07966411690581, -0.1145209109019648, 0.0, 1.0, 41268.961855148664], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 574200.0000, 
sim time next is 576000.0000, 
raw observation next is [-1.2, 83.0, 70.5, 59.0, 24.0, 23.08559074199562, -0.1246402451061642, 0.0, 1.0, 27453.06912209262], 
processed observation next is [0.0, 0.6956521739130435, 0.42936288088642666, 0.83, 0.235, 0.06519337016574586, 0.5, 0.42379922849963503, 0.45845325163127865, 0.0, 1.0, 0.13072890058139344], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3242044], dtype=float32), -0.41830024]. 
=============================================
[2019-04-07 13:08:07,283] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[95.16042 ]
 [95.79516 ]
 [96.636894]
 [97.07183 ]
 [97.7205  ]], R is [[94.85596466]
 [94.90740967]
 [94.95833588]
 [95.00875092]
 [95.05866241]].
[2019-04-07 13:08:12,817] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.88840378e-18 1.42954068e-15 3.73036743e-20 2.47801030e-14
 4.96353631e-17 1.00000000e+00 2.25427021e-11 1.01494313e-13], sum to 1.0000
[2019-04-07 13:08:12,818] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6705
[2019-04-07 13:08:12,859] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 24.0, 23.03010752678428, -0.1660194503418123, 0.0, 1.0, 44197.92237568359], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1987200.0000, 
sim time next is 1989000.0000, 
raw observation next is [-5.9, 85.0, 0.0, 0.0, 24.0, 22.98608395398526, -0.1776876820047835, 0.0, 1.0, 43771.07920615668], 
processed observation next is [1.0, 0.0, 0.2991689750692521, 0.85, 0.0, 0.0, 0.5, 0.41550699616543846, 0.4407707726650722, 0.0, 1.0, 0.20843371050550802], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.26953226], dtype=float32), -1.8711826]. 
=============================================
[2019-04-07 13:08:12,864] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[103.11339]
 [104.81909]
 [105.16322]
 [104.42117]
 [103.92465]], R is [[102.9475708 ]
 [102.91809845]
 [102.88891602]
 [102.86003113]
 [102.83142853]].
[2019-04-07 13:08:27,737] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9018470e-16 5.5019337e-14 4.1878836e-19 1.0295472e-12 1.9990437e-15
 1.0000000e+00 1.6800383e-10 1.6542299e-12], sum to 1.0000
[2019-04-07 13:08:27,737] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1159
[2019-04-07 13:08:27,837] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 47.0, 82.5, 372.5, 24.0, 24.35715332384419, 0.03727645282521467, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 745200.0000, 
sim time next is 747000.0000, 
raw observation next is [-0.3, 46.0, 85.0, 31.0, 24.0, 23.8392591105524, -0.04319015492636274, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.4542936288088643, 0.46, 0.2833333333333333, 0.03425414364640884, 0.5, 0.48660492587936677, 0.4856032816912124, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5483231], dtype=float32), -0.23210423]. 
=============================================
[2019-04-07 13:08:27,843] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[101.21525 ]
 [101.84659 ]
 [102.571205]
 [103.1986  ]
 [103.65553 ]], R is [[100.08591461]
 [100.08506012]
 [100.08421326]
 [100.08337402]
 [100.08254242]].
[2019-04-07 13:08:40,033] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6239009e-18 2.9091781e-16 2.3741877e-21 5.6931192e-14 6.5867924e-16
 1.0000000e+00 1.1868259e-10 1.0372218e-13], sum to 1.0000
[2019-04-07 13:08:40,033] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9641
[2019-04-07 13:08:40,061] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 49.0, 111.5, 0.0, 24.0, 24.88434976144732, 0.3335624882800312, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1609200.0000, 
sim time next is 1611000.0000, 
raw observation next is [13.55, 50.0, 78.0, 0.0, 24.0, 25.45071355040008, 0.4049172099433776, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.8379501385041552, 0.5, 0.26, 0.0, 0.5, 0.6208927958666735, 0.6349724033144591, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.35637507], dtype=float32), -0.60069793]. 
=============================================
[2019-04-07 13:08:40,078] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[110.423   ]
 [110.74547 ]
 [110.90076 ]
 [110.745415]
 [110.7166  ]], R is [[110.23912048]
 [110.13673401]
 [110.03536987]
 [109.93502045]
 [109.83567047]].
[2019-04-07 13:08:40,724] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.02595050e-19 1.10449013e-16 2.12238467e-23 5.09281154e-16
 3.52449748e-17 1.00000000e+00 8.26506641e-11 1.16991767e-14], sum to 1.0000
[2019-04-07 13:08:40,724] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1507
[2019-04-07 13:08:40,793] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 98.0, 0.0, 0.0, 24.0, 23.50479992538629, -0.0134246568362757, 0.0, 1.0, 9276.638920575127], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 941400.0000, 
sim time next is 943200.0000, 
raw observation next is [5.0, 96.0, 0.0, 0.0, 24.0, 23.45540337693306, -0.02207025708469001, 0.0, 1.0, 36396.79803868414], 
processed observation next is [1.0, 0.9565217391304348, 0.6011080332409973, 0.96, 0.0, 0.0, 0.5, 0.45461694807775493, 0.49264324763843664, 0.0, 1.0, 0.1733180858984959], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.840642], dtype=float32), 0.45944968]. 
=============================================
[2019-04-07 13:08:48,189] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-07 13:08:48,190] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:08:48,191] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:08:48,191] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:08:48,192] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:08:48,194] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run29
[2019-04-07 13:08:48,209] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 13:08:48,213] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run29
[2019-04-07 13:08:48,226] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:08:48,231] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run29
[2019-04-07 13:10:51,576] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 13:11:23,971] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 13:11:34,063] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.5330 83805026.4189 32.8860
[2019-04-07 13:11:35,190] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 560000, evaluation results [560000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.5329620425596, 83805026.41892925, 32.88598103848735]
[2019-04-07 13:12:04,285] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.20982933e-15 2.47905646e-13 1.22767591e-17 6.72543618e-12
 1.11433554e-13 1.00000000e+00 2.60412136e-09 2.00247839e-11], sum to 1.0000
[2019-04-07 13:12:04,287] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0513
[2019-04-07 13:12:04,336] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.0, 43.0, 108.5, 797.0, 24.0, 23.63185135995489, 0.06346938321811309, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3679200.0000, 
sim time next is 3681000.0000, 
raw observation next is [6.0, 45.0, 104.0, 776.0, 24.0, 23.74552976978524, 0.08257796505562301, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.6288088642659281, 0.45, 0.3466666666666667, 0.8574585635359117, 0.5, 0.4787941474821033, 0.5275259883518744, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.94407415], dtype=float32), -1.7115035]. 
=============================================
[2019-04-07 13:12:04,373] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[84.14696 ]
 [84.32963 ]
 [84.53672 ]
 [84.75371 ]
 [85.021255]], R is [[84.36878967]
 [84.52510071]
 [84.67984772]
 [84.83305359]
 [84.98472595]].
[2019-04-07 13:12:33,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4048666e-16 3.1792924e-14 2.3863311e-18 4.4420611e-13 2.2002907e-15
 1.0000000e+00 2.1809397e-09 1.7380422e-11], sum to 1.0000
[2019-04-07 13:12:33,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4095
[2019-04-07 13:12:33,586] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 71.0, 109.5, 225.5, 24.0, 24.26580105822482, 0.004496619828989097, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2196000.0000, 
sim time next is 2197800.0000, 
raw observation next is [-4.75, 71.0, 117.0, 0.0, 24.0, 24.24917619645569, -0.02285680332911795, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3310249307479225, 0.71, 0.39, 0.0, 0.5, 0.5207646830379741, 0.4923810655569607, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.94019103], dtype=float32), -0.18065259]. 
=============================================
[2019-04-07 13:12:45,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6447073e-15 1.2762883e-14 1.5418600e-18 7.0013145e-12 1.0092696e-13
 1.0000000e+00 8.0314200e-10 2.5419465e-11], sum to 1.0000
[2019-04-07 13:12:45,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2562
[2019-04-07 13:12:45,801] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8999999999999999, 50.5, 252.0, 424.0, 24.0, 23.10656042095279, -0.09272347942562455, 0.0, 1.0, 21307.35378544351], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2377800.0000, 
sim time next is 2379600.0000, 
raw observation next is [-0.6, 54.0, 221.5, 212.0, 24.0, 23.1523505747131, -0.111982115301626, 0.0, 1.0, 3116.6169384998016], 
processed observation next is [0.0, 0.5652173913043478, 0.44598337950138506, 0.54, 0.7383333333333333, 0.23425414364640884, 0.5, 0.42936254789275835, 0.4626726282327913, 0.0, 1.0, 0.014841033040475245], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.38713264], dtype=float32), -0.045498863]. 
=============================================
[2019-04-07 13:12:50,292] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5411940e-20 2.1247891e-17 1.4095172e-21 6.9521877e-15 7.4880178e-18
 1.0000000e+00 7.7404234e-13 4.2138047e-15], sum to 1.0000
[2019-04-07 13:12:50,292] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0266
[2019-04-07 13:12:50,338] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 92.0, 208.0, 6.0, 24.0, 24.56960669817781, 0.1451443139625295, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4703400.0000, 
sim time next is 4705200.0000, 
raw observation next is [0.0, 92.0, 210.5, 6.0, 24.0, 24.65841360944879, 0.1535820992264459, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.46260387811634357, 0.92, 0.7016666666666667, 0.0066298342541436465, 0.5, 0.5548678007873992, 0.551194033075482, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.44408858], dtype=float32), -0.7809655]. 
=============================================
[2019-04-07 13:12:56,973] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.1929202e-18 2.0566912e-14 1.7840634e-19 3.0147952e-13 9.0911167e-16
 1.0000000e+00 4.6916555e-12 1.4634539e-13], sum to 1.0000
[2019-04-07 13:12:56,973] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2990
[2019-04-07 13:12:57,128] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 64.0, 108.0, 207.0, 24.0, 24.18199753867144, 0.008717532087352495, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2795400.0000, 
sim time next is 2797200.0000, 
raw observation next is [-6.0, 64.0, 130.0, 220.0, 24.0, 24.33361087577882, 0.002874464869297438, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.296398891966759, 0.64, 0.43333333333333335, 0.2430939226519337, 0.5, 0.5278009063149017, 0.5009581549564325, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.55391943], dtype=float32), 0.21264383]. 
=============================================
[2019-04-07 13:12:57,973] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:12:57,973] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:12:57,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run14
[2019-04-07 13:12:59,000] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2955193e-16 3.9746045e-14 8.7562502e-18 4.0582377e-12 4.6846313e-14
 1.0000000e+00 4.9045668e-10 1.0388702e-11], sum to 1.0000
[2019-04-07 13:12:59,001] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7157
[2019-04-07 13:12:59,207] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 54.0, 0.0, 0.0, 24.0, 23.50186297427817, -0.1934232367130971, 0.0, 1.0, 13577.579051821262], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2530800.0000, 
sim time next is 2532600.0000, 
raw observation next is [-2.8, 54.0, 0.0, 0.0, 24.0, 23.53096849782335, -0.1725200737478372, 1.0, 1.0, 8363.130217674343], 
processed observation next is [1.0, 0.30434782608695654, 0.38504155124653744, 0.54, 0.0, 0.0, 0.5, 0.46091404148527904, 0.44249330875072096, 1.0, 1.0, 0.03982442960797306], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5745647], dtype=float32), -1.9157511]. 
=============================================
[2019-04-07 13:13:06,856] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4362513e-16 1.2286429e-14 1.6102981e-19 1.0101700e-11 6.2315680e-15
 1.0000000e+00 1.3621568e-10 3.2211972e-13], sum to 1.0000
[2019-04-07 13:13:06,857] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0200
[2019-04-07 13:13:07,012] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 52.0, 3.0, 53.0, 24.0, 23.58228308138341, -0.06231851437128694, 1.0, 1.0, 65405.969806432], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2741400.0000, 
sim time next is 2743200.0000, 
raw observation next is [-4.0, 54.0, 0.0, 0.0, 24.0, 23.72825611869406, 0.08613407806725781, 1.0, 1.0, 98800.78685577621], 
processed observation next is [1.0, 0.782608695652174, 0.3518005540166205, 0.54, 0.0, 0.0, 0.5, 0.47735467655783825, 0.5287113593557526, 1.0, 1.0, 0.47047993740845817], 
reward next is 0.8152, 
noisyNet noise sample is [array([0.2712016], dtype=float32), 0.93209046]. 
=============================================
[2019-04-07 13:13:08,562] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:13:08,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:13:08,566] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run14
[2019-04-07 13:13:14,080] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7204276e-16 5.1492700e-15 2.8185815e-19 1.3562439e-13 6.9585290e-15
 1.0000000e+00 9.6903978e-11 7.5714933e-13], sum to 1.0000
[2019-04-07 13:13:14,080] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6276
[2019-04-07 13:13:14,399] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.5, 64.0, 0.0, 0.0, 24.0, 22.63212769654566, -0.1696026111630373, 1.0, 1.0, 156338.90801240606], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2791800.0000, 
sim time next is 2793600.0000, 
raw observation next is [-6.0, 64.0, 54.0, 103.5, 24.0, 23.90141823706366, -0.03930300189751184, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.296398891966759, 0.64, 0.18, 0.1143646408839779, 0.5, 0.49178485308863823, 0.4868989993674961, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.22195067], dtype=float32), 1.382938]. 
=============================================
[2019-04-07 13:13:25,062] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:13:25,062] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:13:25,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run14
[2019-04-07 13:13:35,205] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-07 13:13:35,205] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:13:35,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:13:35,207] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run30
[2019-04-07 13:13:35,239] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:13:35,240] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:13:35,242] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run30
[2019-04-07 13:13:35,256] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 13:13:35,259] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:13:35,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run30
[2019-04-07 13:13:36,186] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:13:36,187] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:13:36,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run14
[2019-04-07 13:15:41,795] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 13:16:12,408] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.6292 79463814.5229 95.0531
[2019-04-07 13:16:19,043] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 13:16:20,102] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 580000, evaluation results [580000.0, 2782.629198479697, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 13:16:25,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:16:25,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:16:25,540] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run14
[2019-04-07 13:16:36,226] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4839934e-19 6.8397322e-15 9.0187979e-21 8.9704164e-14 1.6310243e-15
 1.0000000e+00 4.9709604e-11 4.5940161e-13], sum to 1.0000
[2019-04-07 13:16:36,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2207
[2019-04-07 13:16:36,294] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 24.0, 23.43631120261812, -0.03317273056525726, 0.0, 1.0, 59134.10932852127], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3479400.0000, 
sim time next is 3481200.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 24.0, 23.48856566667449, -0.06142277884649333, 0.0, 1.0, 26965.30023515012], 
processed observation next is [1.0, 0.30434782608695654, 0.46260387811634357, 0.72, 0.0, 0.0, 0.5, 0.4573804722228741, 0.4795257403845022, 0.0, 1.0, 0.12840619159595296], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.20797093], dtype=float32), 2.2937677]. 
=============================================
[2019-04-07 13:16:38,027] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4839595e-16 1.4969440e-14 6.9352710e-20 1.2122305e-13 2.0643972e-15
 1.0000000e+00 5.4136806e-10 1.0889919e-12], sum to 1.0000
[2019-04-07 13:16:38,038] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7803
[2019-04-07 13:16:38,069] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 73.0, 0.0, 0.0, 24.0, 24.04049215623903, 0.08250182313696763, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3436200.0000, 
sim time next is 3438000.0000, 
raw observation next is [1.0, 79.0, 0.0, 0.0, 24.0, 23.78268328960183, 0.03803775618193655, 1.0, 1.0, 3113.4019450384226], 
processed observation next is [1.0, 0.8260869565217391, 0.4903047091412743, 0.79, 0.0, 0.0, 0.5, 0.4818902741334859, 0.5126792520606455, 1.0, 1.0, 0.014825723547802013], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.45183185], dtype=float32), 1.0515022]. 
=============================================
[2019-04-07 13:16:38,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[100.59732]
 [100.38934]
 [100.24874]
 [100.26053]
 [ 99.96203]], R is [[101.31716919]
 [101.30400085]
 [101.29096222]
 [101.27805328]
 [101.26527405]].
[2019-04-07 13:16:44,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:16:44,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:16:44,010] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run14
[2019-04-07 13:16:45,863] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.7464836e-14 1.1488546e-11 7.3407257e-17 2.3452284e-11 3.1782164e-12
 1.0000000e+00 9.6094590e-09 1.3072005e-10], sum to 1.0000
[2019-04-07 13:16:45,863] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2054
[2019-04-07 13:16:45,939] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 24.0, 23.45861450755944, -0.03178151531956986, 0.0, 1.0, 23825.51052141793], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3607200.0000, 
sim time next is 3609000.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 24.0, 23.39197107620093, -0.05966738675658704, 0.0, 1.0, 19546.901569054105], 
processed observation next is [0.0, 0.782608695652174, 0.4349030470914128, 0.42, 0.0, 0.0, 0.5, 0.4493309230167443, 0.48011087108113765, 0.0, 1.0, 0.09308048366216241], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1057496], dtype=float32), 0.40628418]. 
=============================================
[2019-04-07 13:16:45,943] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[83.37428 ]
 [83.46966 ]
 [83.63286 ]
 [84.27923 ]
 [84.709755]], R is [[83.75731659]
 [83.9197464 ]
 [84.08055115]
 [84.23974609]
 [84.3973465 ]].
[2019-04-07 13:16:46,459] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7872285e-14 4.7135928e-13 8.4360114e-18 9.3035666e-12 7.6250387e-14
 1.0000000e+00 5.1253868e-09 1.3620314e-11], sum to 1.0000
[2019-04-07 13:16:46,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8427
[2019-04-07 13:16:46,502] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.5, 48.5, 87.0, 705.0, 24.0, 23.8267145034328, 0.08697864747780258, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3684600.0000, 
sim time next is 3686400.0000, 
raw observation next is [5.0, 50.0, 75.5, 613.5, 24.0, 23.80784248428448, 0.07897184860114098, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.6011080332409973, 0.5, 0.25166666666666665, 0.6779005524861879, 0.5, 0.4839868736903732, 0.5263239495337136, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2796191], dtype=float32), 0.8599107]. 
=============================================
[2019-04-07 13:16:54,926] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3960023e-19 3.1132680e-16 1.2747049e-21 2.8052556e-14 8.3547029e-17
 1.0000000e+00 6.1281240e-12 3.0320303e-14], sum to 1.0000
[2019-04-07 13:16:54,926] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0633
[2019-04-07 13:16:54,994] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 24.0, 23.95950461009096, 0.03958337337646554, 0.0, 1.0, 19735.223687145193], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3897000.0000, 
sim time next is 3898800.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 24.0, 23.74269281110327, -0.02503065756962558, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.40720221606648205, 0.65, 0.0, 0.0, 0.5, 0.478557734258606, 0.4916564474767915, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3291686], dtype=float32), -0.5726365]. 
=============================================
[2019-04-07 13:17:17,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:17:17,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:17:17,460] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run14
[2019-04-07 13:17:24,788] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:17:24,788] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:17:24,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run14
[2019-04-07 13:17:34,024] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:17:34,024] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:17:34,039] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run14
[2019-04-07 13:17:41,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:17:41,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:17:41,672] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run14
[2019-04-07 13:17:44,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:17:44,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:17:44,160] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run14
[2019-04-07 13:17:47,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:17:47,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:17:47,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run14
[2019-04-07 13:17:47,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:17:47,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:17:47,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run14
[2019-04-07 13:17:48,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:17:48,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:17:48,184] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run14
[2019-04-07 13:17:50,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:17:50,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:17:50,728] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run14
[2019-04-07 13:17:52,016] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:17:52,016] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:17:52,020] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run14
[2019-04-07 13:17:57,164] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.4389788e-18 4.0145872e-15 2.5184720e-23 4.2032590e-14 1.7368315e-16
 1.0000000e+00 1.1153063e-11 2.3245654e-14], sum to 1.0000
[2019-04-07 13:17:57,165] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9233
[2019-04-07 13:17:57,249] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 24.0, 23.4335079854061, 0.0860163532119503, 0.0, 1.0, 60162.07599041669], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1378800.0000, 
sim time next is 1380600.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 24.0, 23.49652608631182, 0.06485692652543042, 0.0, 1.0, 11396.294387386455], 
processed observation next is [1.0, 1.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.5, 0.45804384052598507, 0.5216189755084768, 0.0, 1.0, 0.05426806851136407], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8478867], dtype=float32), -0.30789182]. 
=============================================
[2019-04-07 13:18:00,016] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.0529012e-20 6.1739457e-17 1.7539709e-22 6.5865193e-15 2.7907978e-18
 1.0000000e+00 6.2026200e-12 2.7305140e-15], sum to 1.0000
[2019-04-07 13:18:00,017] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2783
[2019-04-07 13:18:00,072] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.9, 96.5, 0.0, 0.0, 24.0, 23.88965194367151, 0.1340522034406381, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1650600.0000, 
sim time next is 1652400.0000, 
raw observation next is [6.6, 97.0, 0.0, 0.0, 24.0, 23.75748268672869, 0.08438198848479143, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.6454293628808865, 0.97, 0.0, 0.0, 0.5, 0.47979022389405745, 0.5281273294949305, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.14945573], dtype=float32), 1.872168]. 
=============================================
[2019-04-07 13:18:09,876] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.4131481e-20 2.3744292e-16 1.9290137e-23 8.7024843e-15 8.4819656e-17
 1.0000000e+00 4.9289885e-13 2.0257526e-13], sum to 1.0000
[2019-04-07 13:18:09,877] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0791
[2019-04-07 13:18:09,921] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 24.0, 23.49652608631182, 0.06485692652543042, 0.0, 1.0, 11396.294387386455], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1380600.0000, 
sim time next is 1382400.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 24.0, 23.43672946815675, 0.06657635145173278, 0.0, 1.0, 56641.03253506609], 
processed observation next is [1.0, 0.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.5, 0.4530607890130624, 0.5221921171505776, 0.0, 1.0, 0.2697192025479338], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4519826], dtype=float32), -2.1176481]. 
=============================================
[2019-04-07 13:18:38,992] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-07 13:18:38,998] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:18:38,998] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:18:39,000] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run31
[2019-04-07 13:18:39,019] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:18:39,019] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:18:39,025] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run31
[2019-04-07 13:18:39,043] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 13:18:39,044] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:18:39,046] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run31
[2019-04-07 13:20:39,622] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 13:21:13,450] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 13:21:22,100] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 13:21:23,122] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 600000, evaluation results [600000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 13:21:23,375] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7670551e-20 3.6151168e-18 2.3266827e-24 8.1021708e-16 4.5950735e-18
 1.0000000e+00 1.2271248e-11 1.0502482e-15], sum to 1.0000
[2019-04-07 13:21:23,375] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9059
[2019-04-07 13:21:23,418] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 75.0, 0.0, 0.0, 24.0, 23.93045652169253, 0.149154173106618, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1038600.0000, 
sim time next is 1040400.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 24.0, 23.86766537404801, 0.134152428621878, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.8614958448753465, 0.75, 0.0, 0.0, 0.5, 0.48897211450400074, 0.5447174762072927, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.27557108], dtype=float32), 0.26422828]. 
=============================================
[2019-04-07 13:21:24,042] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.1410147e-17 6.1350266e-15 3.2292030e-19 2.7717908e-14 5.0125306e-14
 1.0000000e+00 1.8155086e-10 1.6987449e-12], sum to 1.0000
[2019-04-07 13:21:24,042] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3170
[2019-04-07 13:21:24,165] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.3, 73.0, 102.0, 451.0, 24.0, 24.20071164786634, 0.01447106240484688, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2194200.0000, 
sim time next is 2196000.0000, 
raw observation next is [-5.0, 71.0, 109.5, 225.5, 24.0, 24.26580105822482, 0.004496619828989097, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.32409972299168976, 0.71, 0.365, 0.24917127071823206, 0.5, 0.5221500881854017, 0.5014988732763297, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.64613193], dtype=float32), -0.2054502]. 
=============================================
[2019-04-07 13:21:24,180] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[100.88275]
 [101.14033]
 [100.61664]
 [100.63597]
 [100.20922]], R is [[100.03981018]
 [100.03941345]
 [100.03901672]
 [100.03862762]
 [100.03823853]].
[2019-04-07 13:22:00,663] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.86574949e-19 6.40269144e-18 1.15675439e-23 1.06463656e-15
 1.24196735e-17 1.00000000e+00 1.13833240e-11 8.94437925e-14], sum to 1.0000
[2019-04-07 13:22:00,667] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2844
[2019-04-07 13:22:00,716] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 78.0, 0.0, 0.0, 24.0, 23.69167111814352, 0.1117869546597689, 0.0, 1.0, 55171.79594043067], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1044000.0000, 
sim time next is 1045800.0000, 
raw observation next is [14.1, 77.5, 0.0, 0.0, 24.0, 23.8516501155399, 0.1213994822486622, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.8531855955678671, 0.775, 0.0, 0.0, 0.5, 0.487637509628325, 0.5404664940828874, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.01232274], dtype=float32), -0.412043]. 
=============================================
[2019-04-07 13:22:02,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4414097e-20 2.5988001e-18 4.7631491e-23 1.8127694e-16 2.1439224e-17
 1.0000000e+00 1.6365206e-12 4.1114369e-15], sum to 1.0000
[2019-04-07 13:22:02,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9845
[2019-04-07 13:22:02,284] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.35, 92.0, 0.0, 0.0, 24.0, 23.44589407447208, 0.09417920724804009, 0.0, 1.0, 88374.46255984646], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1319400.0000, 
sim time next is 1321200.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 24.0, 23.58753399128562, 0.09080964538450836, 0.0, 1.0, 12210.221543341808], 
processed observation next is [1.0, 0.30434782608695654, 0.49307479224376743, 0.92, 0.0, 0.0, 0.5, 0.4656278326071351, 0.5302698817948361, 0.0, 1.0, 0.05814391211115147], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1015621], dtype=float32), -1.5066979]. 
=============================================
[2019-04-07 13:22:18,675] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.8437752e-14 6.1053623e-12 5.3530199e-17 9.4588809e-11 4.0042367e-13
 1.0000000e+00 1.7255591e-08 4.8857157e-10], sum to 1.0000
[2019-04-07 13:22:18,675] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8647
[2019-04-07 13:22:18,743] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 55.0, 56.0, 474.0, 24.0, 23.32794733765231, -0.03341957962355759, 0.0, 1.0, 18691.078768987965], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2997000.0000, 
sim time next is 2998800.0000, 
raw observation next is [-1.0, 55.0, 31.0, 286.5, 24.0, 23.29919853190098, -0.06186572792643539, 0.0, 1.0, 18690.549946119885], 
processed observation next is [0.0, 0.7391304347826086, 0.4349030470914128, 0.55, 0.10333333333333333, 0.3165745856353591, 0.5, 0.4415998776584151, 0.4793780906911882, 0.0, 1.0, 0.08900261879104707], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06951588], dtype=float32), -1.4652234]. 
=============================================
[2019-04-07 13:22:29,151] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9245455e-15 1.1744428e-14 3.9364497e-19 8.3861351e-14 1.6380202e-15
 1.0000000e+00 1.4332034e-09 9.9593955e-13], sum to 1.0000
[2019-04-07 13:22:29,152] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5680
[2019-04-07 13:22:29,225] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 60.0, 117.0, 828.5, 24.0, 24.76092826504495, 0.1071125314151607, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3844800.0000, 
sim time next is 3846600.0000, 
raw observation next is [0.0, 55.5, 117.0, 835.0, 24.0, 24.75352381043262, 0.2439718401687331, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.46260387811634357, 0.555, 0.39, 0.9226519337016574, 0.5, 0.5627936508693848, 0.5813239467229111, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6141281], dtype=float32), -1.1425034]. 
=============================================
[2019-04-07 13:22:51,692] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0830188e-18 2.6751677e-16 8.7884959e-21 6.3259901e-13 5.2745970e-16
 1.0000000e+00 1.2130135e-11 2.6166030e-13], sum to 1.0000
[2019-04-07 13:22:51,722] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6628
[2019-04-07 13:22:51,792] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 74.0, 0.0, 0.0, 24.0, 23.45324517773091, -0.0783710838954887, 0.0, 1.0, 21639.8790121152], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3821400.0000, 
sim time next is 3823200.0000, 
raw observation next is [-5.0, 77.0, 0.0, 0.0, 24.0, 23.42312766303703, -0.0773742745829732, 0.0, 1.0, 47039.49179977988], 
processed observation next is [1.0, 0.2608695652173913, 0.32409972299168976, 0.77, 0.0, 0.0, 0.5, 0.4519273052530857, 0.4742085751390089, 0.0, 1.0, 0.22399757999895178], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.68115824], dtype=float32), -0.6776254]. 
=============================================
[2019-04-07 13:22:59,713] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4981916e-17 1.4963539e-13 2.0385750e-20 1.1927733e-11 6.8723717e-15
 1.0000000e+00 6.9821620e-09 5.5474930e-12], sum to 1.0000
[2019-04-07 13:22:59,713] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0075
[2019-04-07 13:22:59,762] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 62.0, 0.0, 0.0, 24.0, 23.44623688185668, -0.06074654321544273, 0.0, 1.0, 54538.324706780964], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2847600.0000, 
sim time next is 2849400.0000, 
raw observation next is [1.5, 67.0, 0.0, 0.0, 24.0, 23.47162610772796, -0.07150078434411722, 0.0, 1.0, 29582.33486118872], 
processed observation next is [1.0, 1.0, 0.5041551246537397, 0.67, 0.0, 0.0, 0.5, 0.45596884231066337, 0.47616640521862763, 0.0, 1.0, 0.14086826124375582], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.39557657], dtype=float32), 0.4936033]. 
=============================================
[2019-04-07 13:23:03,507] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7566487e-17 1.6288925e-14 7.1557981e-21 5.0196994e-13 9.7405493e-17
 1.0000000e+00 1.9085383e-11 1.4899346e-13], sum to 1.0000
[2019-04-07 13:23:03,507] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7041
[2019-04-07 13:23:03,617] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 55.0, 0.0, 0.0, 24.0, 23.67006825184838, -0.0129708958845025, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2323800.0000, 
sim time next is 2325600.0000, 
raw observation next is [-1.7, 56.0, 0.0, 0.0, 24.0, 23.50577696336126, -0.03184334695194659, 0.0, 1.0, 43820.65236498433], 
processed observation next is [1.0, 0.9565217391304348, 0.4155124653739613, 0.56, 0.0, 0.0, 0.5, 0.45881474694677166, 0.48938555101601783, 0.0, 1.0, 0.20866977316659205], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47694096], dtype=float32), 2.057545]. 
=============================================
[2019-04-07 13:23:17,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:23:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:23:17,595] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run15
[2019-04-07 13:23:20,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9498736e-19 5.9126089e-17 1.6891541e-21 4.1725304e-14 9.2106394e-16
 1.0000000e+00 3.2280154e-11 2.9877530e-13], sum to 1.0000
[2019-04-07 13:23:20,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0747
[2019-04-07 13:23:20,152] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 80.0, 60.0, 116.0, 24.0, 23.69918060336527, 0.05030024471767986, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4435200.0000, 
sim time next is 4437000.0000, 
raw observation next is [1.65, 82.0, 120.0, 232.0, 24.0, 23.77323401000677, 0.1224541515645922, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.5083102493074793, 0.82, 0.4, 0.256353591160221, 0.5, 0.48110283416723093, 0.5408180505215308, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02047253], dtype=float32), -0.55906105]. 
=============================================
[2019-04-07 13:23:20,156] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[108.99666 ]
 [108.311554]
 [107.68287 ]
 [107.636375]
 [108.25207 ]], R is [[108.72031403]
 [108.63311005]
 [108.54678345]
 [108.46131897]
 [108.37670898]].
[2019-04-07 13:23:23,427] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-07 13:23:23,431] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:23:23,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:23:23,434] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run32
[2019-04-07 13:23:23,453] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:23:23,454] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:23:23,454] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 13:23:23,455] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:23:23,458] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run32
[2019-04-07 13:23:23,479] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run32
[2019-04-07 13:24:37,216] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12259902], dtype=float32), 0.13989064]
[2019-04-07 13:24:37,217] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-8.65, 60.5, 0.0, 0.0, 24.0, 22.16221212341234, -0.4165802607071889, 0.0, 1.0, 45141.47511770477]
[2019-04-07 13:24:37,217] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 13:24:37,218] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.5214492e-14 1.5065956e-12 1.2795313e-16 3.6845901e-11 8.5825715e-13
 1.0000000e+00 1.5704831e-08 1.1325334e-10], sampled 0.7059519721789069
[2019-04-07 13:25:25,023] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2788.9052 70927233.8163 166.2180
[2019-04-07 13:25:33,947] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12259902], dtype=float32), 0.13989064]
[2019-04-07 13:25:33,947] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [2.0, 44.0, 173.5, 313.5, 24.0, 23.16226209406786, -0.05134242630778572, 0.0, 1.0, 27225.882072209923]
[2019-04-07 13:25:33,947] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 13:25:33,948] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.6544522e-14 1.7379318e-12 1.4112855e-16 4.5427856e-11 3.4612824e-13
 1.0000000e+00 1.1777507e-08 8.1897274e-11], sampled 0.3461602883069531
[2019-04-07 13:25:56,489] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.6292 79463814.5229 95.0531
[2019-04-07 13:26:03,400] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.9615 83805026.4189 32.8860
[2019-04-07 13:26:04,422] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 620000, evaluation results [620000.0, 2782.629198479697, 79463814.52292724, 95.05306144070829, 2788.9051760082016, 70927233.8162715, 166.21801628696863, 2784.961533471131, 83805026.41892925, 32.88598103848735]
[2019-04-07 13:26:05,786] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:26:05,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:26:05,798] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run15
[2019-04-07 13:26:25,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:26:25,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:26:25,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run15
[2019-04-07 13:26:30,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:26:30,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:26:30,508] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run15
[2019-04-07 13:26:36,742] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:26:36,743] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:26:36,752] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run15
[2019-04-07 13:26:38,068] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.96950738e-16 3.01166698e-14 2.73665178e-18 2.22223824e-12
 6.85195402e-15 1.00000000e+00 6.02970562e-10 1.45350485e-11], sum to 1.0000
[2019-04-07 13:26:38,068] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2464
[2019-04-07 13:26:38,230] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.1, 87.5, 0.0, 0.0, 24.0, 22.75608941333962, -0.197900456247739, 0.0, 1.0, 32655.397033876827], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 66600.0000, 
sim time next is 68400.0000, 
raw observation next is [3.8, 86.0, 0.0, 0.0, 24.0, 22.76415128936222, -0.1960315733194058, 0.0, 1.0, 35215.74422032802], 
processed observation next is [0.0, 0.8260869565217391, 0.5678670360110805, 0.86, 0.0, 0.0, 0.5, 0.3970126074468518, 0.4346561422268647, 0.0, 1.0, 0.1676940200968001], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5952708], dtype=float32), 0.7793077]. 
=============================================
[2019-04-07 13:26:46,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:26:46,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:26:46,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run15
[2019-04-07 13:26:54,242] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5893966e-16 4.7020784e-14 1.9297179e-18 3.2741292e-12 4.2140560e-14
 1.0000000e+00 1.7851242e-09 1.0135049e-11], sum to 1.0000
[2019-04-07 13:26:54,245] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0578
[2019-04-07 13:26:54,312] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.0, 27.0, 101.0, 663.0, 24.0, 23.92217369051003, 0.04054986319247422, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3663000.0000, 
sim time next is 3664800.0000, 
raw observation next is [11.0, 28.0, 106.0, 713.0, 24.0, 23.90044161560645, 0.05045746977104254, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.7673130193905818, 0.28, 0.35333333333333333, 0.7878453038674034, 0.5, 0.49170346796720416, 0.5168191565903475, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2054545], dtype=float32), -1.6030684]. 
=============================================
[2019-04-07 13:27:02,494] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0160832e-18 7.9505892e-15 2.4427859e-22 3.5065614e-13 5.6680014e-15
 1.0000000e+00 1.3394376e-11 1.9217963e-13], sum to 1.0000
[2019-04-07 13:27:02,494] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8838
[2019-04-07 13:27:02,518] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 78.0, 60.0, 0.0, 24.0, 24.45717286818766, 0.1639006623861849, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4464000.0000, 
sim time next is 4465800.0000, 
raw observation next is [0.0, 78.0, 49.0, 0.0, 24.0, 24.46563997668365, 0.1555410036802132, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.46260387811634357, 0.78, 0.16333333333333333, 0.0, 0.5, 0.5388033313903042, 0.5518470012267377, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4606453], dtype=float32), -0.22231777]. 
=============================================
[2019-04-07 13:27:13,006] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4522229e-17 1.4898515e-14 7.6532204e-21 3.3182615e-13 1.2360835e-16
 1.0000000e+00 6.6623429e-11 4.0514762e-13], sum to 1.0000
[2019-04-07 13:27:13,006] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7328
[2019-04-07 13:27:13,076] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 79.5, 135.0, 0.0, 24.0, 23.93862057837835, 0.01975403775979472, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4714200.0000, 
sim time next is 4716000.0000, 
raw observation next is [2.0, 73.0, 165.5, 3.0, 24.0, 23.52184897871008, 0.03316491400379574, 1.0, 1.0, 73945.92767145095], 
processed observation next is [1.0, 0.6086956521739131, 0.518005540166205, 0.73, 0.5516666666666666, 0.0033149171270718232, 0.5, 0.4601540815591732, 0.5110549713345985, 1.0, 1.0, 0.35212346510214737], 
reward next is 0.9336, 
noisyNet noise sample is [array([-1.0954533], dtype=float32), 0.7491533]. 
=============================================
[2019-04-07 13:27:13,080] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[111.29608 ]
 [111.803314]
 [112.00799 ]
 [112.61766 ]
 [113.10264 ]], R is [[111.74320984]
 [111.6257782 ]
 [111.50952148]
 [111.39442444]
 [111.28047943]].
[2019-04-07 13:27:25,758] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:27:25,758] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:27:25,762] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run15
[2019-04-07 13:27:30,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:27:30,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:27:30,052] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run15
[2019-04-07 13:27:42,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:27:42,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:27:42,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run15
[2019-04-07 13:27:55,119] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.6862734e-16 8.8169862e-14 2.8582536e-19 4.3293646e-13 2.3730359e-15
 1.0000000e+00 5.0202431e-10 1.5610369e-12], sum to 1.0000
[2019-04-07 13:27:55,119] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3785
[2019-04-07 13:27:55,170] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 47.5, 0.0, 0.0, 24.0, 23.72193094734392, 0.02394858838552872, 0.0, 1.0, 13780.932114551315], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5020200.0000, 
sim time next is 5022000.0000, 
raw observation next is [-1.0, 55.0, 0.0, 0.0, 24.0, 23.59064672093353, 0.000891876713436171, 0.0, 1.0, 37035.57988488432], 
processed observation next is [1.0, 0.13043478260869565, 0.4349030470914128, 0.55, 0.0, 0.0, 0.5, 0.4658872267444609, 0.500297292237812, 0.0, 1.0, 0.17635990421373485], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1497375], dtype=float32), 0.46435225]. 
=============================================
[2019-04-07 13:27:55,186] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[ 98.92206]
 [ 99.09251]
 [100.02484]
 [ 99.68742]
 [100.77163]], R is [[99.77681732]
 [99.77905273]
 [99.78126526]
 [99.62565613]
 [99.62940216]].
[2019-04-07 13:27:57,438] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:27:57,438] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:27:57,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run15
[2019-04-07 13:27:58,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:27:58,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:27:58,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run15
[2019-04-07 13:27:58,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:27:58,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:27:58,818] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run15
[2019-04-07 13:27:58,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:27:58,842] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:27:58,850] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run15
[2019-04-07 13:28:00,474] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:28:00,475] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:28:00,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run15
[2019-04-07 13:28:01,716] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-07 13:28:01,717] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:28:01,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:28:01,719] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run33
[2019-04-07 13:28:01,765] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:28:01,765] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:28:01,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run33
[2019-04-07 13:28:01,790] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 13:28:01,790] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:28:01,793] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run33
[2019-04-07 13:30:08,484] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 13:30:40,932] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 13:30:48,688] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 13:30:49,726] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 640000, evaluation results [640000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 13:30:52,708] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:30:52,708] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:30:52,711] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run15
[2019-04-07 13:30:53,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:30:53,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:30:53,029] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run15
[2019-04-07 13:30:57,401] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3173294e-16 1.2471060e-14 1.8279813e-19 1.0525680e-12 1.3691302e-13
 1.0000000e+00 5.2575109e-09 7.1043297e-12], sum to 1.0000
[2019-04-07 13:30:57,401] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4401
[2019-04-07 13:30:57,596] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-14.5, 66.0, 55.0, 733.5, 24.0, 23.96587580860119, -0.1074447046277416, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 381600.0000, 
sim time next is 383400.0000, 
raw observation next is [-13.95, 63.0, 71.0, 729.0, 24.0, 23.91509600848795, -0.1052254865608452, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.07617728531855956, 0.63, 0.23666666666666666, 0.8055248618784531, 0.5, 0.4929246673739958, 0.46492483781305155, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.44461054], dtype=float32), 1.0669154]. 
=============================================
[2019-04-07 13:31:31,380] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7441557e-15 8.7850289e-13 1.8196622e-17 4.4936277e-12 5.2556626e-14
 1.0000000e+00 1.4644063e-09 5.5071260e-12], sum to 1.0000
[2019-04-07 13:31:31,380] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3226
[2019-04-07 13:31:31,418] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.2, 52.0, 0.0, 0.0, 24.0, 21.79497053098871, -0.5170511157971706, 0.0, 1.0, 47121.488907581945], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 446400.0000, 
sim time next is 448200.0000, 
raw observation next is [-10.9, 52.0, 0.0, 0.0, 24.0, 21.62944502485522, -0.5296514573794894, 0.0, 1.0, 47414.619374710914], 
processed observation next is [1.0, 0.17391304347826086, 0.16066481994459833, 0.52, 0.0, 0.0, 0.5, 0.30245375207126823, 0.3234495142068369, 0.0, 1.0, 0.2257839017843377], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.9572504], dtype=float32), -0.8560708]. 
=============================================
[2019-04-07 13:32:26,289] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.5668969e-18 3.3199057e-14 6.1690806e-22 2.8115135e-13 2.9751453e-17
 1.0000000e+00 3.7964649e-11 3.5560710e-14], sum to 1.0000
[2019-04-07 13:32:26,290] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9553
[2019-04-07 13:32:26,346] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 86.0, 0.0, 0.0, 24.0, 23.23206646878747, -0.1061129369464013, 0.0, 1.0, 51352.27556075033], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2070000.0000, 
sim time next is 2071800.0000, 
raw observation next is [-4.5, 88.5, 0.0, 0.0, 24.0, 23.16753319918368, -0.1203147038651999, 0.0, 1.0, 44551.9750077741], 
processed observation next is [1.0, 1.0, 0.3379501385041552, 0.885, 0.0, 0.0, 0.5, 0.43062776659864, 0.4598950987116, 0.0, 1.0, 0.2121522619417814], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3065003], dtype=float32), 0.27009746]. 
=============================================
[2019-04-07 13:32:54,498] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3980637e-17 1.2481660e-16 1.4894576e-20 2.1244004e-13 4.7446143e-16
 1.0000000e+00 3.2408225e-11 1.8928029e-13], sum to 1.0000
[2019-04-07 13:32:54,498] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0434
[2019-04-07 13:32:54,591] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 24.0, 23.1256989250085, -0.1935268740615446, 0.0, 1.0, 42339.918985846685], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1999800.0000, 
sim time next is 2001600.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 24.0, 23.0171266439678, -0.2195087345935919, 0.0, 1.0, 42216.87445635761], 
processed observation next is [1.0, 0.17391304347826086, 0.30747922437673136, 0.83, 0.0, 0.0, 0.5, 0.4180938869973166, 0.426830421802136, 0.0, 1.0, 0.2010327355064648], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.07071245], dtype=float32), 0.7132637]. 
=============================================
[2019-04-07 13:33:04,677] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-07 13:33:04,678] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:33:04,678] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:33:04,680] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:33:04,680] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:33:04,683] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run34
[2019-04-07 13:33:04,712] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run34
[2019-04-07 13:33:04,730] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 13:33:04,732] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:33:04,740] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run34
[2019-04-07 13:35:09,318] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2788.9052 70927233.8163 166.2180
[2019-04-07 13:35:37,031] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 13:35:42,288] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 13:35:43,311] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 660000, evaluation results [660000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2788.9051760082016, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 13:35:44,288] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0170254e-18 7.9100741e-17 4.3760710e-21 5.4824835e-13 1.7024789e-15
 1.0000000e+00 1.2005548e-10 3.7824968e-13], sum to 1.0000
[2019-04-07 13:35:44,304] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6029
[2019-04-07 13:35:44,378] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 24.0, 23.04278585536452, -0.2205445335672655, 0.0, 1.0, 41964.5878340914], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2007000.0000, 
sim time next is 2008800.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 24.0, 22.95464763466078, -0.2329373862185663, 0.0, 1.0, 41976.644796071596], 
processed observation next is [1.0, 0.2608695652173913, 0.2908587257617729, 0.87, 0.0, 0.0, 0.5, 0.41288730288839837, 0.4223542045938113, 0.0, 1.0, 0.19988878474319807], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4084589], dtype=float32), 1.1434642]. 
=============================================
[2019-04-07 13:36:09,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:36:09,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:36:09,213] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run16
[2019-04-07 13:36:15,359] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7821242e-18 8.6214269e-16 3.0025024e-21 1.5665241e-13 3.3320953e-16
 1.0000000e+00 1.0345714e-11 7.9752889e-14], sum to 1.0000
[2019-04-07 13:36:15,359] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8893
[2019-04-07 13:36:15,482] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 44.0, 0.0, 0.0, 24.0, 23.07621893907267, -0.05869204770246252, 0.0, 1.0, 140171.84078219786], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2838600.0000, 
sim time next is 2840400.0000, 
raw observation next is [2.0, 44.0, 0.0, 0.0, 24.0, 23.62255726993746, 0.00888665754169008, 0.0, 1.0, 39099.47955661431], 
processed observation next is [1.0, 0.9130434782608695, 0.518005540166205, 0.44, 0.0, 0.0, 0.5, 0.46854643916145494, 0.5029622191805634, 0.0, 1.0, 0.18618799788863957], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2296886], dtype=float32), -0.67373466]. 
=============================================
[2019-04-07 13:36:16,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:36:16,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:36:16,695] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run16
[2019-04-07 13:36:18,625] A3C_AGENT_WORKER-Thread-3 INFO:Local step 42500, global step 665724: loss 3.6488
[2019-04-07 13:36:18,628] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 42500, global step 665724: learning rate 0.0000
[2019-04-07 13:36:26,273] A3C_AGENT_WORKER-Thread-18 INFO:Local step 42500, global step 666918: loss 3.4062
[2019-04-07 13:36:26,274] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 42500, global step 666918: learning rate 0.0000
[2019-04-07 13:36:30,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6443666e-18 4.2706843e-16 5.4493710e-21 5.9803060e-14 5.6678012e-17
 1.0000000e+00 8.6524191e-11 3.5723887e-13], sum to 1.0000
[2019-04-07 13:36:30,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2210
[2019-04-07 13:36:30,178] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 93.0, 0.0, 0.0, 24.0, 23.33158078168603, -0.1177424042005908, 0.0, 1.0, 59462.73110687543], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2867400.0000, 
sim time next is 2869200.0000, 
raw observation next is [1.0, 93.0, 0.0, 0.0, 24.0, 23.41475660335237, -0.1042007194062623, 0.0, 1.0, 45613.02953718263], 
processed observation next is [1.0, 0.21739130434782608, 0.4903047091412743, 0.93, 0.0, 0.0, 0.5, 0.4512297169460308, 0.46526642686457925, 0.0, 1.0, 0.21720490255801253], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.08335341], dtype=float32), -1.5070506]. 
=============================================
[2019-04-07 13:36:33,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:36:33,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:36:33,660] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run16
[2019-04-07 13:36:35,267] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.7881298e-16 7.4576169e-14 4.8242005e-18 1.7109397e-11 2.3366610e-14
 1.0000000e+00 2.1451418e-09 3.1173165e-11], sum to 1.0000
[2019-04-07 13:36:35,267] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3896
[2019-04-07 13:36:35,330] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 68.0, 0.0, 0.0, 24.0, 23.17151619290582, -0.1698363847453054, 0.0, 1.0, 40707.46048937175], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4865400.0000, 
sim time next is 4867200.0000, 
raw observation next is [-4.0, 71.0, 70.5, 156.5, 24.0, 23.13664198399083, -0.1466871093072463, 0.0, 1.0, 40520.40784252108], 
processed observation next is [0.0, 0.34782608695652173, 0.3518005540166205, 0.71, 0.235, 0.17292817679558012, 0.5, 0.4280534986659026, 0.4511042968975845, 0.0, 1.0, 0.1929543230596242], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.32168117], dtype=float32), 1.1584214]. 
=============================================
[2019-04-07 13:36:37,705] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.8118359e-16 1.0103148e-14 2.7066976e-19 2.4888826e-13 2.0901554e-14
 1.0000000e+00 1.5969544e-10 1.4282265e-12], sum to 1.0000
[2019-04-07 13:36:37,705] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5289
[2019-04-07 13:36:37,888] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.55, 68.5, 30.0, 386.0, 24.0, 23.84345829796423, -0.08247579914918828, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 289800.0000, 
sim time next is 291600.0000, 
raw observation next is [-12.3, 67.0, 62.5, 384.5, 24.0, 23.9912551385333, -0.09008332035230737, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.12188365650969527, 0.67, 0.20833333333333334, 0.4248618784530387, 0.5, 0.49927126154444174, 0.46997222654923093, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.03519391], dtype=float32), -0.1822657]. 
=============================================
[2019-04-07 13:36:40,213] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:36:40,213] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:36:40,216] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run16
[2019-04-07 13:36:41,878] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0432134e-17 3.3444191e-14 6.9954794e-20 1.6852680e-12 2.8214689e-16
 1.0000000e+00 1.4326186e-09 7.1649094e-13], sum to 1.0000
[2019-04-07 13:36:41,879] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6102
[2019-04-07 13:36:41,978] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 24.0, 23.72052585988768, -0.0388211753719036, 0.0, 1.0, 15351.302672514663], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3718800.0000, 
sim time next is 3720600.0000, 
raw observation next is [-3.0, 68.0, 0.0, 0.0, 24.0, 23.63085306048654, -0.08049401270685748, 0.0, 1.0, 6243.840204095463], 
processed observation next is [1.0, 0.043478260869565216, 0.3795013850415513, 0.68, 0.0, 0.0, 0.5, 0.46923775504054505, 0.47316866243104755, 0.0, 1.0, 0.02973257240045459], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9127794], dtype=float32), 0.19790909]. 
=============================================
[2019-04-07 13:36:42,710] A3C_AGENT_WORKER-Thread-19 INFO:Local step 42500, global step 669590: loss 3.3871
[2019-04-07 13:36:42,754] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 42500, global step 669590: learning rate 0.0000
[2019-04-07 13:36:46,603] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:36:46,603] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:36:46,607] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run16
[2019-04-07 13:36:48,560] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3138103e-19 4.5326798e-17 1.9611271e-22 1.3487306e-15 2.5315603e-17
 1.0000000e+00 5.7945787e-13 9.1475120e-15], sum to 1.0000
[2019-04-07 13:36:48,560] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4415
[2019-04-07 13:36:48,638] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 92.0, 0.0, 0.0, 24.0, 23.35617025862022, 0.02680888946446774, 0.0, 1.0, 67010.42601095363], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3222000.0000, 
sim time next is 3223800.0000, 
raw observation next is [-3.0, 92.0, 1.0, 82.0, 24.0, 23.73777745171573, 0.07302103074397426, 1.0, 1.0, 15178.217435802313], 
processed observation next is [1.0, 0.30434782608695654, 0.3795013850415513, 0.92, 0.0033333333333333335, 0.09060773480662983, 0.5, 0.47814812097631076, 0.5243403435813248, 1.0, 1.0, 0.07227722588477292], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5117172], dtype=float32), 0.83318275]. 
=============================================
[2019-04-07 13:36:48,958] A3C_AGENT_WORKER-Thread-14 INFO:Local step 42500, global step 670625: loss 3.4100
[2019-04-07 13:36:48,959] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 42500, global step 670625: learning rate 0.0000
[2019-04-07 13:36:54,075] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6944147e-20 9.2368129e-17 8.8739544e-23 2.6047989e-15 2.2029412e-18
 1.0000000e+00 6.8208425e-11 6.3586607e-14], sum to 1.0000
[2019-04-07 13:36:54,075] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8418
[2019-04-07 13:36:54,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:36:54,078] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:36:54,082] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run16
[2019-04-07 13:36:54,168] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 100.0, 0.0, 0.0, 24.0, 23.48883630173475, 0.08045552234600417, 0.0, 1.0, 82330.59380453083], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3204000.0000, 
sim time next is 3205800.0000, 
raw observation next is [-0.5, 100.0, 0.0, 0.0, 24.0, 23.59478663175226, 0.132306906706659, 0.0, 1.0, 51939.21377177449], 
processed observation next is [1.0, 0.08695652173913043, 0.44875346260387816, 1.0, 0.0, 0.0, 0.5, 0.4662322193126884, 0.544102302235553, 0.0, 1.0, 0.24732958938940233], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.41082692], dtype=float32), 1.5676603]. 
=============================================
[2019-04-07 13:36:56,216] A3C_AGENT_WORKER-Thread-6 INFO:Local step 42500, global step 671733: loss 3.4139
[2019-04-07 13:36:56,217] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 42500, global step 671733: learning rate 0.0000
[2019-04-07 13:37:04,503] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2752043e-19 2.2129073e-16 3.2774007e-21 1.3533620e-14 1.7590427e-15
 1.0000000e+00 2.8894009e-10 2.0328579e-14], sum to 1.0000
[2019-04-07 13:37:04,504] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1165
[2019-04-07 13:37:04,542] A3C_AGENT_WORKER-Thread-10 INFO:Local step 42500, global step 673053: loss 3.3252
[2019-04-07 13:37:04,543] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 42500, global step 673053: learning rate 0.0000
[2019-04-07 13:37:04,553] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.7, 82.0, 0.0, 0.0, 24.0, 23.36124787497026, -0.1166228471705437, 0.0, 1.0, 42181.00580123942], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 532800.0000, 
sim time next is 534600.0000, 
raw observation next is [2.15, 83.5, 0.0, 0.0, 24.0, 23.37009295614787, -0.1166939659115815, 0.0, 1.0, 41350.98969925474], 
processed observation next is [0.0, 0.17391304347826086, 0.5221606648199446, 0.835, 0.0, 0.0, 0.5, 0.447507746345656, 0.46110201136280615, 0.0, 1.0, 0.19690947475835588], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.28434375], dtype=float32), -0.14788803]. 
=============================================
[2019-04-07 13:37:22,617] A3C_AGENT_WORKER-Thread-3 INFO:Local step 43000, global step 676149: loss 1.6276
[2019-04-07 13:37:22,618] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 43000, global step 676149: learning rate 0.0000
[2019-04-07 13:37:24,113] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1298496e-17 4.4757606e-15 2.3135167e-21 4.1654929e-14 1.3101050e-15
 1.0000000e+00 3.5743503e-10 7.4753043e-14], sum to 1.0000
[2019-04-07 13:37:24,113] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4444
[2019-04-07 13:37:24,190] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 68.0, 0.0, 0.0, 24.0, 23.45711355278931, 0.1096064000975583, 0.0, 1.0, 135041.4655344532], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3789000.0000, 
sim time next is 3790800.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 24.0, 23.80008123014208, 0.132989430748256, 0.0, 1.0, 12132.513909604786], 
processed observation next is [1.0, 0.9130434782608695, 0.3795013850415513, 0.71, 0.0, 0.0, 0.5, 0.48334010251184, 0.5443298102494186, 0.0, 1.0, 0.05777387576002279], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47801918], dtype=float32), 0.40917665]. 
=============================================
[2019-04-07 13:37:29,379] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.18985615e-14 2.14196079e-13 7.94802540e-19 6.26422959e-12
 9.21850487e-14 1.00000000e+00 1.26869237e-09 2.48250830e-11], sum to 1.0000
[2019-04-07 13:37:29,380] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1860
[2019-04-07 13:37:29,431] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 28.5, 120.0, 841.0, 24.0, 24.83699302439769, 0.2461043901204678, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4105800.0000, 
sim time next is 4107600.0000, 
raw observation next is [3.0, 29.0, 118.0, 835.5, 24.0, 24.65016753086673, 0.1878355955802693, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.29, 0.3933333333333333, 0.9232044198895027, 0.5, 0.5541806275722276, 0.5626118651934231, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.30795985], dtype=float32), -0.89065945]. 
=============================================
[2019-04-07 13:37:31,959] A3C_AGENT_WORKER-Thread-18 INFO:Local step 43000, global step 677788: loss 1.7043
[2019-04-07 13:37:31,960] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 43000, global step 677788: learning rate 0.0000
[2019-04-07 13:37:38,254] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:37:38,254] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:37:38,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run16
[2019-04-07 13:37:40,019] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0107369e-18 6.5382235e-17 1.7225608e-22 2.5510678e-15 5.8505499e-17
 1.0000000e+00 2.0802634e-11 6.2243965e-14], sum to 1.0000
[2019-04-07 13:37:40,019] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7129
[2019-04-07 13:37:40,064] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.3, 84.0, 142.5, 131.5, 24.0, 24.37876688552415, 0.1591773162295694, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4438800.0000, 
sim time next is 4440600.0000, 
raw observation next is [1.15, 85.0, 165.0, 31.0, 24.0, 24.44742969302773, 0.1907269515282792, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49445983379501385, 0.85, 0.55, 0.03425414364640884, 0.5, 0.5372858077523107, 0.5635756505094264, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9289686], dtype=float32), 0.19250491]. 
=============================================
[2019-04-07 13:37:41,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:37:41,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:37:41,136] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run16
[2019-04-07 13:37:43,283] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-07 13:37:43,284] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:37:43,284] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:37:43,286] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run35
[2019-04-07 13:37:43,307] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:37:43,315] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:37:43,318] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run35
[2019-04-07 13:37:43,336] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 13:37:43,339] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:37:43,341] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run35
[2019-04-07 13:38:54,599] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12321701], dtype=float32), 0.14219402]
[2019-04-07 13:38:54,599] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-1.5, 36.0, 0.0, 0.0, 24.0, 23.28904981108532, -0.03971958534418441, 0.0, 1.0, 24834.3622094757]
[2019-04-07 13:38:54,600] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 13:38:54,601] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [2.8207171e-15 3.5837585e-13 1.3997893e-17 7.6723428e-12 1.0559114e-13
 1.0000000e+00 2.8817739e-09 1.8581924e-11], sampled 0.7064858349430577
[2019-04-07 13:39:55,486] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 13:40:29,091] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 13:40:33,663] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 13:40:34,716] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 680000, evaluation results [680000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 13:40:36,527] A3C_AGENT_WORKER-Thread-13 INFO:Local step 42500, global step 680347: loss 3.3901
[2019-04-07 13:40:36,528] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 42500, global step 680347: learning rate 0.0000
[2019-04-07 13:40:36,532] A3C_AGENT_WORKER-Thread-12 INFO:Local step 42500, global step 680349: loss 3.4820
[2019-04-07 13:40:36,533] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 42500, global step 680349: learning rate 0.0000
[2019-04-07 13:40:36,970] A3C_AGENT_WORKER-Thread-19 INFO:Local step 43000, global step 680409: loss 1.6896
[2019-04-07 13:40:36,974] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 43000, global step 680409: learning rate 0.0000
[2019-04-07 13:40:42,357] A3C_AGENT_WORKER-Thread-14 INFO:Local step 43000, global step 681461: loss 1.5533
[2019-04-07 13:40:42,357] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 43000, global step 681461: learning rate 0.0000
[2019-04-07 13:40:45,577] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1299001e-16 1.0974487e-13 6.5156804e-20 1.3149493e-11 7.6193358e-15
 1.0000000e+00 1.2836186e-08 5.1053557e-13], sum to 1.0000
[2019-04-07 13:40:45,577] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8871
[2019-04-07 13:40:45,734] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 68.0, 0.0, 0.0, 24.0, 23.09112701207183, -0.1409866267338252, 0.0, 1.0, 51241.54797238888], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 162000.0000, 
sim time next is 163800.0000, 
raw observation next is [-8.4, 69.5, 0.0, 0.0, 24.0, 22.97169766204649, -0.1681505151701038, 0.0, 1.0, 47867.40296404795], 
processed observation next is [1.0, 0.9130434782608695, 0.2299168975069252, 0.695, 0.0, 0.0, 0.5, 0.41430813850387427, 0.4439498282766321, 0.0, 1.0, 0.22794001411451403], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0509174], dtype=float32), 0.71042496]. 
=============================================
[2019-04-07 13:40:49,899] A3C_AGENT_WORKER-Thread-6 INFO:Local step 43000, global step 682963: loss 1.5566
[2019-04-07 13:40:49,899] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 43000, global step 682963: learning rate 0.0000
[2019-04-07 13:40:50,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:40:50,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:40:50,558] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run16
[2019-04-07 13:40:50,699] A3C_AGENT_WORKER-Thread-3 INFO:Local step 43500, global step 683113: loss 0.6177
[2019-04-07 13:40:50,700] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 43500, global step 683113: learning rate 0.0000
[2019-04-07 13:40:51,210] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.85041093e-15 2.91357650e-12 4.87288087e-18 1.30524645e-11
 2.17397634e-15 1.00000000e+00 1.40503325e-08 1.53666021e-11], sum to 1.0000
[2019-04-07 13:40:51,218] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2607
[2019-04-07 13:40:51,286] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 44.5, 236.0, 374.0, 24.0, 23.23724139735202, -0.06597872801498898, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4890600.0000, 
sim time next is 4892400.0000, 
raw observation next is [3.0, 45.0, 199.5, 398.0, 24.0, 23.24774868052636, -0.06259398550421101, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.5457063711911359, 0.45, 0.665, 0.4397790055248619, 0.5, 0.43731239004386335, 0.479135338165263, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1464422], dtype=float32), 2.2981043]. 
=============================================
[2019-04-07 13:40:58,272] A3C_AGENT_WORKER-Thread-10 INFO:Local step 43000, global step 684371: loss 1.5400
[2019-04-07 13:40:58,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 43000, global step 684371: learning rate 0.0000
[2019-04-07 13:40:58,823] A3C_AGENT_WORKER-Thread-18 INFO:Local step 43500, global step 684491: loss 0.3769
[2019-04-07 13:40:58,823] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 43500, global step 684491: learning rate 0.0000
[2019-04-07 13:40:59,516] A3C_AGENT_WORKER-Thread-16 INFO:Local step 42500, global step 684630: loss 3.5122
[2019-04-07 13:40:59,518] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 42500, global step 684630: learning rate 0.0000
[2019-04-07 13:41:00,437] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3492025e-16 5.9697726e-15 5.1736574e-18 2.3693443e-12 2.4806585e-14
 1.0000000e+00 3.0413574e-09 1.4460904e-12], sum to 1.0000
[2019-04-07 13:41:00,437] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9517
[2019-04-07 13:41:00,606] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 62.5, 207.0, 179.0, 24.0, 23.6065196396592, -0.06242129410635069, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4872600.0000, 
sim time next is 4874400.0000, 
raw observation next is [-2.0, 60.0, 253.5, 171.5, 24.0, 23.45451592147283, -0.07916781967728537, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.40720221606648205, 0.6, 0.845, 0.18950276243093922, 0.5, 0.45454299345606913, 0.4736107267742382, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.26289088], dtype=float32), 1.1052936]. 
=============================================
[2019-04-07 13:41:00,768] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:41:00,768] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:41:00,771] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run16
[2019-04-07 13:41:00,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:41:00,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:41:00,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run16
[2019-04-07 13:41:01,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:41:01,754] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:41:01,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run16
[2019-04-07 13:41:02,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:41:02,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:41:02,184] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run16
[2019-04-07 13:41:03,291] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:41:03,291] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:41:03,294] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run16
[2019-04-07 13:41:10,436] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:41:10,436] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:41:10,440] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run16
[2019-04-07 13:41:10,917] A3C_AGENT_WORKER-Thread-4 INFO:Local step 42500, global step 686116: loss 3.3820
[2019-04-07 13:41:10,918] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 42500, global step 686116: learning rate 0.0000
[2019-04-07 13:41:11,716] A3C_AGENT_WORKER-Thread-2 INFO:Local step 42500, global step 686203: loss 3.4998
[2019-04-07 13:41:11,717] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 42500, global step 686203: learning rate 0.0000
[2019-04-07 13:41:11,851] A3C_AGENT_WORKER-Thread-11 INFO:Local step 42500, global step 686219: loss 3.4718
[2019-04-07 13:41:11,902] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 42500, global step 686219: learning rate 0.0000
[2019-04-07 13:41:12,347] A3C_AGENT_WORKER-Thread-5 INFO:Local step 42500, global step 686280: loss 3.4685
[2019-04-07 13:41:12,348] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 42500, global step 686280: learning rate 0.0000
[2019-04-07 13:41:13,697] A3C_AGENT_WORKER-Thread-20 INFO:Local step 42500, global step 686444: loss 3.4731
[2019-04-07 13:41:13,697] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 42500, global step 686444: learning rate 0.0000
[2019-04-07 13:41:14,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:41:14,866] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:41:14,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run16
[2019-04-07 13:41:15,926] A3C_AGENT_WORKER-Thread-19 INFO:Local step 43500, global step 686713: loss 0.4932
[2019-04-07 13:41:15,927] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 43500, global step 686713: learning rate 0.0000
[2019-04-07 13:41:20,661] A3C_AGENT_WORKER-Thread-17 INFO:Local step 42500, global step 687214: loss 3.3499
[2019-04-07 13:41:20,661] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 42500, global step 687214: learning rate 0.0000
[2019-04-07 13:41:20,666] A3C_AGENT_WORKER-Thread-14 INFO:Local step 43500, global step 687216: loss 0.3120
[2019-04-07 13:41:20,666] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 43500, global step 687216: learning rate 0.0000
[2019-04-07 13:41:25,550] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.1891199e-16 1.5798167e-13 1.6005675e-18 3.9357354e-12 4.0948614e-15
 1.0000000e+00 8.1861433e-09 1.1472933e-11], sum to 1.0000
[2019-04-07 13:41:25,550] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8333
[2019-04-07 13:41:25,627] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 24.0, 21.80082452385794, -0.4755655761746977, 0.0, 1.0, 45630.35592901181], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 194400.0000, 
sim time next is 196200.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 24.0, 21.72307382125382, -0.4958342363510995, 0.0, 1.0, 45637.510661595305], 
processed observation next is [1.0, 0.2608695652173913, 0.21606648199445982, 0.78, 0.0, 0.0, 0.5, 0.3102561517711517, 0.3347219212163002, 0.0, 1.0, 0.21732147934093002], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.19643404], dtype=float32), 0.2725986]. 
=============================================
[2019-04-07 13:41:25,892] A3C_AGENT_WORKER-Thread-15 INFO:Local step 42500, global step 687813: loss 3.4111
[2019-04-07 13:41:25,893] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 42500, global step 687813: learning rate 0.0000
[2019-04-07 13:41:27,473] A3C_AGENT_WORKER-Thread-6 INFO:Local step 43500, global step 688005: loss 0.3357
[2019-04-07 13:41:27,473] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 43500, global step 688005: learning rate 0.0000
[2019-04-07 13:41:31,959] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0215142e-15 2.7999955e-14 6.0709453e-19 5.8966845e-13 9.0983028e-15
 1.0000000e+00 2.7033991e-09 2.3300866e-11], sum to 1.0000
[2019-04-07 13:41:31,959] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1648
[2019-04-07 13:41:32,145] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 58.0, 0.0, 0.0, 24.0, 23.0592290493149, -0.1269728545417236, 1.0, 1.0, 97171.13545246182], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 763200.0000, 
sim time next is 765000.0000, 
raw observation next is [-5.3, 59.5, 0.0, 0.0, 24.0, 23.15749448532006, -0.1059590102945887, 0.0, 1.0, 85819.98732647924], 
processed observation next is [1.0, 0.8695652173913043, 0.31578947368421056, 0.595, 0.0, 0.0, 0.5, 0.4297912071100051, 0.4646803299018038, 0.0, 1.0, 0.4086666063165678], 
reward next is 0.8770, 
noisyNet noise sample is [array([0.9332489], dtype=float32), 1.163266]. 
=============================================
[2019-04-07 13:41:32,154] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[100.81547 ]
 [100.39935 ]
 [100.923546]
 [100.9647  ]
 [100.26566 ]], R is [[100.12138367]
 [ 99.94316864]
 [ 99.94374084]
 [ 99.94430542]
 [ 99.90664673]].
[2019-04-07 13:41:35,439] A3C_AGENT_WORKER-Thread-10 INFO:Local step 43500, global step 688899: loss 0.3936
[2019-04-07 13:41:35,439] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 43500, global step 688899: learning rate 0.0000
[2019-04-07 13:41:44,180] A3C_AGENT_WORKER-Thread-12 INFO:Local step 43000, global step 689847: loss 1.5461
[2019-04-07 13:41:44,180] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 43000, global step 689847: learning rate 0.0000
[2019-04-07 13:41:44,346] A3C_AGENT_WORKER-Thread-13 INFO:Local step 43000, global step 689858: loss 1.4087
[2019-04-07 13:41:44,346] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 43000, global step 689858: learning rate 0.0000
[2019-04-07 13:41:52,910] A3C_AGENT_WORKER-Thread-3 INFO:Local step 44000, global step 691113: loss 0.1210
[2019-04-07 13:41:52,912] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 44000, global step 691113: learning rate 0.0000
[2019-04-07 13:41:53,580] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.3287471e-16 4.6421061e-14 5.2873236e-18 3.3797287e-13 8.0288567e-15
 1.0000000e+00 8.3945384e-10 4.9473299e-12], sum to 1.0000
[2019-04-07 13:41:53,581] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1969
[2019-04-07 13:41:53,718] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 24.0, 23.02249597120933, -0.2293410157365606, 0.0, 1.0, 38669.55462629627], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 673200.0000, 
sim time next is 675000.0000, 
raw observation next is [-2.55, 63.5, 0.0, 0.0, 24.0, 23.01496994988763, -0.1979613767170623, 0.0, 1.0, 110937.76364185494], 
processed observation next is [0.0, 0.8260869565217391, 0.3919667590027701, 0.635, 0.0, 0.0, 0.5, 0.41791416249063573, 0.4340128744276459, 0.0, 1.0, 0.528275064961214], 
reward next is 0.7574, 
noisyNet noise sample is [array([1.8040811], dtype=float32), -0.34489995]. 
=============================================
[2019-04-07 13:41:53,739] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[91.20499 ]
 [90.894135]
 [90.70618 ]
 [90.418465]
 [90.64772 ]], R is [[92.20636749]
 [92.28430176]
 [92.36145782]
 [92.43784332]
 [92.51346588]].
[2019-04-07 13:42:00,355] A3C_AGENT_WORKER-Thread-18 INFO:Local step 44000, global step 692134: loss 0.1177
[2019-04-07 13:42:00,355] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 44000, global step 692134: learning rate 0.0000
[2019-04-07 13:42:00,684] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.7977186e-16 2.2843909e-15 2.5567020e-20 8.1479115e-14 3.3744499e-15
 1.0000000e+00 5.7591304e-10 3.8187276e-13], sum to 1.0000
[2019-04-07 13:42:00,684] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2971
[2019-04-07 13:42:00,802] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.550000000000001, 82.5, 101.0, 39.0, 24.0, 23.98086364396066, -0.08045110422273201, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2280600.0000, 
sim time next is 2282400.0000, 
raw observation next is [-6.7, 78.0, 139.5, 44.5, 24.0, 23.98461813382242, -0.07600179489999141, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.2770083102493075, 0.78, 0.465, 0.049171270718232046, 0.5, 0.49871817781853495, 0.4746660683666695, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3978511], dtype=float32), 1.5110153]. 
=============================================
[2019-04-07 13:42:10,402] A3C_AGENT_WORKER-Thread-16 INFO:Local step 43000, global step 693564: loss 1.5193
[2019-04-07 13:42:10,403] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 43000, global step 693564: learning rate 0.0000
[2019-04-07 13:42:13,676] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0688513e-15 1.0787113e-12 2.5442913e-17 1.1167964e-11 8.5106341e-13
 1.0000000e+00 5.2378102e-10 2.0576478e-11], sum to 1.0000
[2019-04-07 13:42:13,676] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2398
[2019-04-07 13:42:13,742] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 24.0, 22.91106768706481, -0.2189703673053253, 0.0, 1.0, 42221.24580297598], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2358000.0000, 
sim time next is 2359800.0000, 
raw observation next is [-3.4, 69.0, 0.0, 0.0, 24.0, 22.82458879728822, -0.2360299407010299, 0.0, 1.0, 42402.639583818855], 
processed observation next is [0.0, 0.30434782608695654, 0.368421052631579, 0.69, 0.0, 0.0, 0.5, 0.4020490664406851, 0.42132335309965674, 0.0, 1.0, 0.20191733135151835], 
reward next is 1.0000, 
noisyNet noise sample is [array([3.2155097], dtype=float32), 0.25309852]. 
=============================================
[2019-04-07 13:42:18,403] A3C_AGENT_WORKER-Thread-19 INFO:Local step 44000, global step 694762: loss 0.1420
[2019-04-07 13:42:18,404] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 44000, global step 694762: learning rate 0.0000
[2019-04-07 13:42:18,840] A3C_AGENT_WORKER-Thread-4 INFO:Local step 43000, global step 694828: loss 1.4668
[2019-04-07 13:42:18,841] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 43000, global step 694828: learning rate 0.0000
[2019-04-07 13:42:21,551] A3C_AGENT_WORKER-Thread-12 INFO:Local step 43500, global step 695268: loss 0.5287
[2019-04-07 13:42:21,551] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 43500, global step 695268: learning rate 0.0000
[2019-04-07 13:42:21,564] A3C_AGENT_WORKER-Thread-5 INFO:Local step 43000, global step 695270: loss 1.4519
[2019-04-07 13:42:21,564] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 43000, global step 695270: learning rate 0.0000
[2019-04-07 13:42:22,213] A3C_AGENT_WORKER-Thread-13 INFO:Local step 43500, global step 695375: loss 0.5473
[2019-04-07 13:42:22,222] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 43500, global step 695375: learning rate 0.0000
[2019-04-07 13:42:22,366] A3C_AGENT_WORKER-Thread-2 INFO:Local step 43000, global step 695399: loss 1.5662
[2019-04-07 13:42:22,366] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 43000, global step 695399: learning rate 0.0000
[2019-04-07 13:42:22,973] A3C_AGENT_WORKER-Thread-14 INFO:Local step 44000, global step 695513: loss 0.1372
[2019-04-07 13:42:22,974] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 44000, global step 695513: learning rate 0.0000
[2019-04-07 13:42:23,099] A3C_AGENT_WORKER-Thread-20 INFO:Local step 43000, global step 695535: loss 1.3705
[2019-04-07 13:42:23,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 43000, global step 695535: learning rate 0.0000
[2019-04-07 13:42:23,641] A3C_AGENT_WORKER-Thread-11 INFO:Local step 43000, global step 695631: loss 1.4427
[2019-04-07 13:42:23,642] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 43000, global step 695631: learning rate 0.0000
[2019-04-07 13:42:26,930] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9632525e-17 1.9432984e-15 2.1014166e-21 6.5207849e-14 2.2847394e-15
 1.0000000e+00 1.8563159e-10 3.5807947e-12], sum to 1.0000
[2019-04-07 13:42:26,930] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5967
[2019-04-07 13:42:26,953] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.5258056e-16 1.7704282e-13 5.1660198e-20 2.1393774e-12 3.8734923e-15
 1.0000000e+00 1.1072424e-09 4.9338164e-12], sum to 1.0000
[2019-04-07 13:42:26,957] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8666
[2019-04-07 13:42:27,001] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 68.0, 0.0, 0.0, 24.0, 23.43200633193377, -0.1030779995842715, 0.0, 1.0, 31301.48013715554], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2595600.0000, 
sim time next is 2597400.0000, 
raw observation next is [-5.0, 71.0, 0.0, 0.0, 24.0, 23.48910601112519, -0.1140551943683245, 0.0, 1.0, 20705.613077877846], 
processed observation next is [1.0, 0.043478260869565216, 0.32409972299168976, 0.71, 0.0, 0.0, 0.5, 0.45742550092709927, 0.46198160187722515, 0.0, 1.0, 0.09859815751370403], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3164544], dtype=float32), 1.3513664]. 
=============================================
[2019-04-07 13:42:27,036] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.0, 64.0, 114.5, 727.5, 24.0, 24.48118614871373, 0.09160561117466494, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2718000.0000, 
sim time next is 2719800.0000, 
raw observation next is [-8.5, 64.0, 112.0, 781.0, 24.0, 24.44529336431368, 0.09205992291160364, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.22714681440443216, 0.64, 0.37333333333333335, 0.8629834254143647, 0.5, 0.5371077803594734, 0.5306866409705345, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.0227027], dtype=float32), -2.7430146]. 
=============================================
[2019-04-07 13:42:27,769] A3C_AGENT_WORKER-Thread-6 INFO:Local step 44000, global step 696468: loss 0.1314
[2019-04-07 13:42:27,771] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 44000, global step 696469: learning rate 0.0000
[2019-04-07 13:42:32,071] A3C_AGENT_WORKER-Thread-17 INFO:Local step 43000, global step 697362: loss 1.3765
[2019-04-07 13:42:32,074] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 43000, global step 697362: learning rate 0.0000
[2019-04-07 13:42:34,466] A3C_AGENT_WORKER-Thread-15 INFO:Local step 43000, global step 697850: loss 1.4256
[2019-04-07 13:42:34,468] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 43000, global step 697850: learning rate 0.0000
[2019-04-07 13:42:34,823] A3C_AGENT_WORKER-Thread-10 INFO:Local step 44000, global step 697927: loss 0.1282
[2019-04-07 13:42:34,823] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 44000, global step 697927: learning rate 0.0000
[2019-04-07 13:42:37,905] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3934533e-19 1.2506444e-16 3.2152453e-23 1.6908492e-14 7.9395488e-17
 1.0000000e+00 1.4068224e-11 3.3015159e-15], sum to 1.0000
[2019-04-07 13:42:37,905] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7932
[2019-04-07 13:42:37,945] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 75.0, 0.0, 0.0, 24.0, 24.2472272110742, 0.2057863115107251, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1031400.0000, 
sim time next is 1033200.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 24.0, 24.16159518011719, 0.187993714229894, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.8614958448753465, 0.75, 0.0, 0.0, 0.5, 0.5134662650097658, 0.5626645714099646, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7419986], dtype=float32), -0.5413189]. 
=============================================
[2019-04-07 13:42:38,917] A3C_AGENT_WORKER-Thread-3 INFO:Local step 44500, global step 698688: loss 0.7390
[2019-04-07 13:42:38,917] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 44500, global step 698688: learning rate 0.0000
[2019-04-07 13:42:42,083] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3826916e-19 3.8641188e-16 3.6571113e-21 4.1595997e-15 1.7645057e-16
 1.0000000e+00 4.0822810e-12 3.0653668e-14], sum to 1.0000
[2019-04-07 13:42:42,086] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2205
[2019-04-07 13:42:42,213] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 72.5, 0.0, 0.0, 24.0, 24.02129427049172, 0.02841212799167518, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2140200.0000, 
sim time next is 2142000.0000, 
raw observation next is [-5.0, 74.0, 0.0, 0.0, 24.0, 23.80292491138037, 0.004936996817531088, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.32409972299168976, 0.74, 0.0, 0.0, 0.5, 0.48357707594836413, 0.5016456656058437, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09189433], dtype=float32), -0.16467701]. 
=============================================
[2019-04-07 13:42:42,216] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[102.96703]
 [103.01642]
 [101.50184]
 [101.30024]
 [101.07745]], R is [[103.07540131]
 [103.04464722]
 [102.66914368]
 [102.64245605]
 [102.61603546]].
[2019-04-07 13:42:45,384] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-07 13:42:45,385] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:42:45,386] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:42:45,388] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run36
[2019-04-07 13:42:45,407] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:42:45,411] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:42:45,417] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run36
[2019-04-07 13:42:45,417] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 13:42:45,418] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:42:45,443] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run36
[2019-04-07 13:43:33,334] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12265962], dtype=float32), 0.1422895]
[2019-04-07 13:43:33,334] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-4.5, 79.0, 29.0, 0.0, 24.0, 23.14953879948241, -0.1713639935959526, 0.0, 1.0, 38734.28900587846]
[2019-04-07 13:43:33,334] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 13:43:33,335] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.4211497e-16 3.5946276e-14 6.4757892e-19 1.0570868e-12 1.1719634e-14
 1.0000000e+00 1.0139661e-09 3.6737393e-12], sampled 0.40652650391044076
[2019-04-07 13:44:23,893] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12265962], dtype=float32), 0.1422895]
[2019-04-07 13:44:23,893] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [9.9, 64.0, 0.0, 0.0, 24.0, 23.80413995517558, 0.01829517429483921, 0.0, 1.0, 0.0]
[2019-04-07 13:44:23,893] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 13:44:23,894] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [9.4506957e-18 2.5833355e-15 1.8211525e-20 8.9674911e-14 6.2856166e-16
 1.0000000e+00 1.3447679e-10 3.9351554e-13], sampled 0.32304146623875096
[2019-04-07 13:44:51,954] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 13:45:26,624] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 13:45:30,940] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 13:45:31,963] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 700000, evaluation results [700000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 13:45:31,971] A3C_AGENT_WORKER-Thread-18 INFO:Local step 44500, global step 700006: loss 0.7580
[2019-04-07 13:45:31,976] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 44500, global step 700008: learning rate 0.0000
[2019-04-07 13:45:32,872] A3C_AGENT_WORKER-Thread-16 INFO:Local step 43500, global step 700217: loss 0.3222
[2019-04-07 13:45:32,883] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 43500, global step 700218: learning rate 0.0000
[2019-04-07 13:45:42,473] A3C_AGENT_WORKER-Thread-4 INFO:Local step 43500, global step 701862: loss 0.4110
[2019-04-07 13:45:42,474] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 43500, global step 701862: learning rate 0.0000
[2019-04-07 13:45:44,851] A3C_AGENT_WORKER-Thread-5 INFO:Local step 43500, global step 702240: loss 0.3235
[2019-04-07 13:45:44,851] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 43500, global step 702240: learning rate 0.0000
[2019-04-07 13:45:46,034] A3C_AGENT_WORKER-Thread-2 INFO:Local step 43500, global step 702443: loss 0.3936
[2019-04-07 13:45:46,035] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 43500, global step 702443: learning rate 0.0000
[2019-04-07 13:45:46,052] A3C_AGENT_WORKER-Thread-20 INFO:Local step 43500, global step 702445: loss 0.3432
[2019-04-07 13:45:46,053] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 43500, global step 702445: learning rate 0.0000
[2019-04-07 13:45:48,257] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.7589988e-16 6.6145846e-14 1.8419819e-18 7.4882409e-12 8.4714049e-14
 1.0000000e+00 2.0374502e-10 6.3696041e-12], sum to 1.0000
[2019-04-07 13:45:48,257] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8720
[2019-04-07 13:45:48,338] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.75, 77.0, 0.0, 0.0, 24.0, 23.08749661688043, -0.2100305694663042, 0.0, 1.0, 46112.849033075094], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1895400.0000, 
sim time next is 1897200.0000, 
raw observation next is [-7.3, 79.0, 0.0, 0.0, 24.0, 22.99928992485471, -0.228413327128776, 0.0, 1.0, 46079.79786444249], 
processed observation next is [0.0, 1.0, 0.26038781163434904, 0.79, 0.0, 0.0, 0.5, 0.4166074937378926, 0.423862224290408, 0.0, 1.0, 0.21942760887829757], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4356396], dtype=float32), 1.6966027]. 
=============================================
[2019-04-07 13:45:48,473] A3C_AGENT_WORKER-Thread-19 INFO:Local step 44500, global step 702830: loss 0.8153
[2019-04-07 13:45:48,473] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 44500, global step 702830: learning rate 0.0000
[2019-04-07 13:45:48,585] A3C_AGENT_WORKER-Thread-11 INFO:Local step 43500, global step 702846: loss 0.3047
[2019-04-07 13:45:48,604] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 43500, global step 702846: learning rate 0.0000
[2019-04-07 13:45:53,105] A3C_AGENT_WORKER-Thread-14 INFO:Local step 44500, global step 703534: loss 0.8120
[2019-04-07 13:45:53,105] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 44500, global step 703534: learning rate 0.0000
[2019-04-07 13:45:56,345] A3C_AGENT_WORKER-Thread-17 INFO:Local step 43500, global step 704028: loss 0.4063
[2019-04-07 13:45:56,346] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 43500, global step 704028: learning rate 0.0000
[2019-04-07 13:45:57,571] A3C_AGENT_WORKER-Thread-6 INFO:Local step 44500, global step 704249: loss 0.8015
[2019-04-07 13:45:57,571] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 44500, global step 704249: learning rate 0.0000
[2019-04-07 13:45:58,592] A3C_AGENT_WORKER-Thread-15 INFO:Local step 43500, global step 704413: loss 0.3755
[2019-04-07 13:45:58,592] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 43500, global step 704413: learning rate 0.0000
[2019-04-07 13:46:05,014] A3C_AGENT_WORKER-Thread-3 INFO:Local step 45000, global step 705389: loss 0.8796
[2019-04-07 13:46:05,015] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 45000, global step 705389: learning rate 0.0000
[2019-04-07 13:46:05,412] A3C_AGENT_WORKER-Thread-12 INFO:Local step 44000, global step 705445: loss 0.1259
[2019-04-07 13:46:05,424] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 44000, global step 705445: learning rate 0.0000
[2019-04-07 13:46:05,583] A3C_AGENT_WORKER-Thread-13 INFO:Local step 44000, global step 705471: loss 0.1277
[2019-04-07 13:46:05,586] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 44000, global step 705471: learning rate 0.0000
[2019-04-07 13:46:06,728] A3C_AGENT_WORKER-Thread-10 INFO:Local step 44500, global step 705633: loss 0.7822
[2019-04-07 13:46:06,728] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 44500, global step 705633: learning rate 0.0000
[2019-04-07 13:46:11,252] A3C_AGENT_WORKER-Thread-18 INFO:Local step 45000, global step 706344: loss 1.1192
[2019-04-07 13:46:11,252] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 45000, global step 706344: learning rate 0.0000
[2019-04-07 13:46:16,575] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4228381e-18 2.8286585e-15 2.4806132e-20 1.1803502e-12 9.9963387e-16
 1.0000000e+00 2.9873928e-10 5.9688224e-13], sum to 1.0000
[2019-04-07 13:46:16,576] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4787
[2019-04-07 13:46:16,630] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 44.5, 18.0, 179.0, 24.0, 25.06769606851252, 0.2514775599784929, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3864600.0000, 
sim time next is 3866400.0000, 
raw observation next is [2.0, 48.0, 0.0, 0.0, 24.0, 24.64612418451688, 0.2481057129874134, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.518005540166205, 0.48, 0.0, 0.0, 0.5, 0.5538436820430732, 0.5827019043291378, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3850471], dtype=float32), 0.28240353]. 
=============================================
[2019-04-07 13:46:17,411] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1055297e-19 1.4979794e-16 6.5556422e-21 1.3761362e-13 8.1672081e-17
 1.0000000e+00 2.4161274e-11 3.7813139e-13], sum to 1.0000
[2019-04-07 13:46:17,412] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3766
[2019-04-07 13:46:17,506] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 57.5, 0.0, 0.0, 24.0, 23.65546235233815, 0.0150939352694193, 0.0, 1.0, 29675.449464720794], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3882600.0000, 
sim time next is 3884400.0000, 
raw observation next is [-1.0, 60.0, 0.0, 0.0, 24.0, 23.43558703645751, 0.0425889641420506, 0.0, 1.0, 112934.20962891653], 
processed observation next is [1.0, 1.0, 0.4349030470914128, 0.6, 0.0, 0.0, 0.5, 0.45296558637145906, 0.5141963213806835, 0.0, 1.0, 0.5377819506138882], 
reward next is 0.7479, 
noisyNet noise sample is [array([-0.06930169], dtype=float32), -0.78185236]. 
=============================================
[2019-04-07 13:46:27,300] A3C_AGENT_WORKER-Thread-19 INFO:Local step 45000, global step 708933: loss 0.8937
[2019-04-07 13:46:27,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 45000, global step 708933: learning rate 0.0000
[2019-04-07 13:46:30,735] A3C_AGENT_WORKER-Thread-16 INFO:Local step 44000, global step 709576: loss 0.1349
[2019-04-07 13:46:30,736] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 44000, global step 709576: learning rate 0.0000
[2019-04-07 13:46:31,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:46:31,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:46:31,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run17
[2019-04-07 13:46:31,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0144151e-16 3.9258422e-14 1.9747940e-18 8.0291598e-12 1.2637575e-14
 1.0000000e+00 9.4243405e-11 2.5187661e-11], sum to 1.0000
[2019-04-07 13:46:31,734] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8368
[2019-04-07 13:46:31,775] A3C_AGENT_WORKER-Thread-14 INFO:Local step 45000, global step 709764: loss 1.0129
[2019-04-07 13:46:31,775] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 45000, global step 709764: learning rate 0.0000
[2019-04-07 13:46:31,815] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 24.0, 23.34159344112048, -0.1094347986063264, 0.0, 1.0, 40385.6189287251], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2338200.0000, 
sim time next is 2340000.0000, 
raw observation next is [-2.3, 62.0, 0.0, 0.0, 24.0, 23.31412983504175, -0.1142024402229177, 0.0, 1.0, 40270.387295313856], 
processed observation next is [0.0, 0.08695652173913043, 0.3988919667590028, 0.62, 0.0, 0.0, 0.5, 0.4428441529201459, 0.46193251992569406, 0.0, 1.0, 0.19176374902530408], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0042652], dtype=float32), 0.063682884]. 
=============================================
[2019-04-07 13:46:31,826] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[ 94.55212]
 [ 95.41911]
 [ 96.18055]
 [ 97.97969]
 [101.97612]], R is [[93.45014954]
 [93.51564789]
 [93.58049011]
 [93.64468384]
 [93.70823669]].
[2019-04-07 13:46:35,953] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:46:35,953] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:46:35,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run17
[2019-04-07 13:46:36,871] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7934631e-15 9.0382549e-14 1.1146601e-18 8.9931760e-12 9.5262865e-15
 1.0000000e+00 4.4955528e-10 2.9423665e-11], sum to 1.0000
[2019-04-07 13:46:36,871] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7894
[2019-04-07 13:46:36,934] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 50.0, 106.0, 752.0, 24.0, 24.42061655758008, 0.1795424589715984, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3335400.0000, 
sim time next is 3337200.0000, 
raw observation next is [-3.0, 50.0, 96.5, 713.0, 24.0, 24.37911479505959, 0.1815765533172724, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.3795013850415513, 0.5, 0.32166666666666666, 0.7878453038674034, 0.5, 0.5315928995882991, 0.5605255177724241, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.44246274], dtype=float32), -0.85616285]. 
=============================================
[2019-04-07 13:46:37,621] A3C_AGENT_WORKER-Thread-6 INFO:Local step 45000, global step 710738: loss 0.8546
[2019-04-07 13:46:37,622] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 45000, global step 710738: learning rate 0.0000
[2019-04-07 13:46:42,801] A3C_AGENT_WORKER-Thread-4 INFO:Local step 44000, global step 711562: loss 0.1253
[2019-04-07 13:46:42,806] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 44000, global step 711562: learning rate 0.0000
[2019-04-07 13:46:44,022] A3C_AGENT_WORKER-Thread-20 INFO:Local step 44000, global step 711753: loss 0.1392
[2019-04-07 13:46:44,023] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 44000, global step 711753: learning rate 0.0000
[2019-04-07 13:46:45,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8720250e-17 7.7340994e-15 1.5605691e-20 8.1832036e-14 1.0979798e-14
 1.0000000e+00 7.8839535e-10 1.0210561e-12], sum to 1.0000
[2019-04-07 13:46:45,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5500
[2019-04-07 13:46:45,399] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 36.0, 0.0, 0.0, 24.0, 23.1457229716283, -0.1032148201416763, 1.0, 1.0, 50137.53180901086], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2574000.0000, 
sim time next is 2575800.0000, 
raw observation next is [-1.15, 40.0, 0.0, 0.0, 24.0, 23.17419128817706, -0.117894522457852, 0.0, 1.0, 30638.0511160727], 
processed observation next is [1.0, 0.8260869565217391, 0.4307479224376732, 0.4, 0.0, 0.0, 0.5, 0.4311826073480883, 0.4607018258473827, 0.0, 1.0, 0.1458954815051081], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6080579], dtype=float32), -0.21830267]. 
=============================================
[2019-04-07 13:46:45,812] A3C_AGENT_WORKER-Thread-10 INFO:Local step 45000, global step 712056: loss 1.0198
[2019-04-07 13:46:45,812] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 45000, global step 712056: learning rate 0.0000
[2019-04-07 13:46:45,984] A3C_AGENT_WORKER-Thread-2 INFO:Local step 44000, global step 712083: loss 0.1265
[2019-04-07 13:46:45,984] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 44000, global step 712083: learning rate 0.0000
[2019-04-07 13:46:46,676] A3C_AGENT_WORKER-Thread-11 INFO:Local step 44000, global step 712199: loss 0.1216
[2019-04-07 13:46:46,705] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 44000, global step 712199: learning rate 0.0000
[2019-04-07 13:46:46,719] A3C_AGENT_WORKER-Thread-5 INFO:Local step 44000, global step 712209: loss 0.1191
[2019-04-07 13:46:46,719] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 44000, global step 712209: learning rate 0.0000
[2019-04-07 13:46:50,782] A3C_AGENT_WORKER-Thread-12 INFO:Local step 44500, global step 712875: loss 0.8244
[2019-04-07 13:46:50,783] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 44500, global step 712875: learning rate 0.0000
[2019-04-07 13:46:50,789] A3C_AGENT_WORKER-Thread-13 INFO:Local step 44500, global step 712875: loss 0.8167
[2019-04-07 13:46:50,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 44500, global step 712875: learning rate 0.0000
[2019-04-07 13:46:52,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:46:52,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:46:52,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run17
[2019-04-07 13:46:54,532] A3C_AGENT_WORKER-Thread-17 INFO:Local step 44000, global step 713554: loss 0.1258
[2019-04-07 13:46:54,533] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 44000, global step 713554: learning rate 0.0000
[2019-04-07 13:46:57,017] A3C_AGENT_WORKER-Thread-15 INFO:Local step 44000, global step 713950: loss 0.1169
[2019-04-07 13:46:57,021] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 44000, global step 713950: learning rate 0.0000
[2019-04-07 13:46:57,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:46:57,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:46:57,504] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run17
[2019-04-07 13:47:02,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:47:02,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:47:02,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run17
[2019-04-07 13:47:11,606] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:47:11,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:47:11,932] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run17
[2019-04-07 13:47:15,725] A3C_AGENT_WORKER-Thread-16 INFO:Local step 44500, global step 716659: loss 0.8359
[2019-04-07 13:47:15,728] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 44500, global step 716659: learning rate 0.0000
[2019-04-07 13:47:15,910] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.0279379e-17 4.8707512e-15 4.5274025e-20 4.2570907e-14 4.3771338e-16
 1.0000000e+00 1.1327386e-10 2.7424119e-13], sum to 1.0000
[2019-04-07 13:47:15,911] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2360
[2019-04-07 13:47:15,991] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 24.0, 21.97778284810968, -0.4322752498983053, 0.0, 1.0, 45091.037072850915], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 189000.0000, 
sim time next is 190800.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 24.0, 21.90437078699891, -0.4430087711446235, 0.0, 1.0, 45308.804147079645], 
processed observation next is [1.0, 0.21739130434782608, 0.21606648199445982, 0.78, 0.0, 0.0, 0.5, 0.32536423224990924, 0.3523304096184588, 0.0, 1.0, 0.21575621022418878], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3937907], dtype=float32), 0.3553002]. 
=============================================
[2019-04-07 13:47:17,895] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5860598e-16 2.9486866e-15 5.1099063e-20 8.9720759e-14 3.2883667e-16
 1.0000000e+00 1.3100583e-10 1.1323135e-13], sum to 1.0000
[2019-04-07 13:47:17,896] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0270
[2019-04-07 13:47:17,967] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 62.5, 0.0, 0.0, 24.0, 23.9805298649683, 0.05539889014823082, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3702600.0000, 
sim time next is 3704400.0000, 
raw observation next is [2.0, 62.0, 0.0, 0.0, 24.0, 23.93017951157919, 0.02843076064540667, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.518005540166205, 0.62, 0.0, 0.0, 0.5, 0.49418162596493254, 0.5094769202151356, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.33761317], dtype=float32), -1.3173386]. 
=============================================
[2019-04-07 13:47:28,710] A3C_AGENT_WORKER-Thread-4 INFO:Local step 44500, global step 718796: loss 0.8404
[2019-04-07 13:47:28,710] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 44500, global step 718796: learning rate 0.0000
[2019-04-07 13:47:29,561] A3C_AGENT_WORKER-Thread-13 INFO:Local step 45000, global step 718927: loss 0.9189
[2019-04-07 13:47:29,562] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 45000, global step 718927: learning rate 0.0000
[2019-04-07 13:47:30,585] A3C_AGENT_WORKER-Thread-12 INFO:Local step 45000, global step 719081: loss 0.8750
[2019-04-07 13:47:30,602] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 45000, global step 719081: learning rate 0.0000
[2019-04-07 13:47:31,501] A3C_AGENT_WORKER-Thread-2 INFO:Local step 44500, global step 719263: loss 0.8768
[2019-04-07 13:47:31,501] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 44500, global step 719263: learning rate 0.0000
[2019-04-07 13:47:31,535] A3C_AGENT_WORKER-Thread-20 INFO:Local step 44500, global step 719268: loss 0.8507
[2019-04-07 13:47:31,536] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 44500, global step 719268: learning rate 0.0000
[2019-04-07 13:47:32,030] A3C_AGENT_WORKER-Thread-5 INFO:Local step 44500, global step 719349: loss 0.8546
[2019-04-07 13:47:32,031] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 44500, global step 719349: learning rate 0.0000
[2019-04-07 13:47:32,651] A3C_AGENT_WORKER-Thread-11 INFO:Local step 44500, global step 719467: loss 0.8471
[2019-04-07 13:47:32,657] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 44500, global step 719467: learning rate 0.0000
[2019-04-07 13:47:35,565] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-07 13:47:35,566] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:47:35,569] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:47:35,573] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:47:35,575] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run37
[2019-04-07 13:47:35,570] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:47:35,598] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run37
[2019-04-07 13:47:35,612] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 13:47:35,613] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:47:35,615] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run37
[2019-04-07 13:49:43,337] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 13:50:19,390] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 13:50:23,645] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 13:50:24,706] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 720000, evaluation results [720000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 13:50:28,721] A3C_AGENT_WORKER-Thread-17 INFO:Local step 44500, global step 720507: loss 0.8704
[2019-04-07 13:50:28,722] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 44500, global step 720507: learning rate 0.0000
[2019-04-07 13:50:34,464] A3C_AGENT_WORKER-Thread-15 INFO:Local step 44500, global step 721437: loss 0.9065
[2019-04-07 13:50:34,464] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 44500, global step 721437: learning rate 0.0000
[2019-04-07 13:50:44,968] A3C_AGENT_WORKER-Thread-16 INFO:Local step 45000, global step 723317: loss 0.7451
[2019-04-07 13:50:44,985] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 45000, global step 723323: learning rate 0.0000
[2019-04-07 13:50:45,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:50:45,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:50:45,306] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run17
[2019-04-07 13:50:45,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:50:45,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:50:45,745] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run17
[2019-04-07 13:50:46,052] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6365150e-18 5.2547323e-17 2.3031087e-21 7.7908939e-15 3.6491317e-18
 1.0000000e+00 6.6315820e-12 2.9501453e-14], sum to 1.0000
[2019-04-07 13:50:46,052] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0161
[2019-04-07 13:50:46,088] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 50.0, 110.0, 611.0, 24.0, 23.87362216000258, -0.06487250303981476, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 738000.0000, 
sim time next is 739800.0000, 
raw observation next is [0.5, 47.5, 89.0, 773.0, 24.0, 23.67100720641179, -0.02182130122085564, 1.0, 1.0, 50555.05163234902], 
processed observation next is [1.0, 0.5652173913043478, 0.4764542936288089, 0.475, 0.2966666666666667, 0.8541436464088398, 0.5, 0.4725839338676492, 0.49272623292638146, 1.0, 1.0, 0.24073834110642392], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.4602656], dtype=float32), 0.2808103]. 
=============================================
[2019-04-07 13:50:47,885] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0000266e-16 6.9111925e-14 3.4701976e-18 3.5403313e-13 2.0069749e-15
 1.0000000e+00 6.6555925e-09 3.9345719e-12], sum to 1.0000
[2019-04-07 13:50:47,886] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1543
[2019-04-07 13:50:47,943] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 45.0, 0.0, 0.0, 24.0, 23.52032588553945, -0.08372726427035088, 0.0, 1.0, 31858.20749051478], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4240800.0000, 
sim time next is 4242600.0000, 
raw observation next is [3.0, 45.0, 0.0, 0.0, 24.0, 23.51947689050684, -0.08875334309911576, 0.0, 1.0, 33504.34842037447], 
processed observation next is [0.0, 0.08695652173913043, 0.5457063711911359, 0.45, 0.0, 0.0, 0.5, 0.4599564075422367, 0.4704155523002947, 0.0, 1.0, 0.15954451628749747], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17833036], dtype=float32), -2.438864]. 
=============================================
[2019-04-07 13:50:51,980] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9544406e-16 5.4578966e-15 2.4393243e-20 5.6812089e-14 7.1661732e-15
 1.0000000e+00 1.2618236e-10 6.8988424e-13], sum to 1.0000
[2019-04-07 13:50:51,980] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7862
[2019-04-07 13:50:52,046] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.1, 66.5, 0.0, 0.0, 24.0, 23.55404928147806, -0.06088859153318471, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4300200.0000, 
sim time next is 4302000.0000, 
raw observation next is [6.0, 69.0, 0.0, 0.0, 24.0, 23.38650017104928, -0.09754775586385474, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.6288088642659281, 0.69, 0.0, 0.0, 0.5, 0.44887501425410675, 0.4674840813787151, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9032959], dtype=float32), 0.1278633]. 
=============================================
[2019-04-07 13:50:52,082] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[96.10775 ]
 [96.04854 ]
 [96.071465]
 [96.01333 ]
 [95.87147 ]], R is [[96.39639282]
 [96.43242645]
 [96.4681015 ]
 [96.50341797]
 [96.53838348]].
[2019-04-07 13:50:55,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9278582e-16 1.3676172e-12 1.2522240e-17 3.3124267e-12 1.4516415e-13
 1.0000000e+00 1.4962913e-09 2.5872189e-13], sum to 1.0000
[2019-04-07 13:50:55,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3445
[2019-04-07 13:50:55,932] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 39.5, 0.0, 0.0, 24.0, 23.25507778704125, -0.152340572687935, 0.0, 1.0, 42353.5077720647], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4084200.0000, 
sim time next is 4086000.0000, 
raw observation next is [-5.0, 41.0, 0.0, 0.0, 24.0, 23.27183272009962, -0.1582673607237633, 0.0, 1.0, 41347.04772114514], 
processed observation next is [1.0, 0.30434782608695654, 0.32409972299168976, 0.41, 0.0, 0.0, 0.5, 0.43931939334163506, 0.4472442130920789, 0.0, 1.0, 0.19689070343402448], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.35308638], dtype=float32), 0.05205926]. 
=============================================
[2019-04-07 13:50:55,941] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[95.345375]
 [95.40219 ]
 [95.147194]
 [95.44366 ]
 [95.44761 ]], R is [[95.56803131]
 [95.61235046]
 [95.65020752]
 [95.6937027 ]
 [95.736763  ]].
[2019-04-07 13:50:56,019] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8014544e-19 7.2319097e-17 6.6487474e-22 2.1440801e-15 1.6293134e-16
 1.0000000e+00 9.1611970e-12 1.0140216e-14], sum to 1.0000
[2019-04-07 13:50:56,020] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6679
[2019-04-07 13:50:56,077] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.1, 66.0, 0.0, 0.0, 24.0, 24.11214764264484, 0.1711854819282446, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4413600.0000, 
sim time next is 4415400.0000, 
raw observation next is [5.55, 66.5, 0.0, 0.0, 24.0, 23.98279417242411, 0.1404853977869814, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.6163434903047093, 0.665, 0.0, 0.0, 0.5, 0.49856618103534256, 0.5468284659289938, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.88150537], dtype=float32), 1.5670872]. 
=============================================
[2019-04-07 13:50:57,579] A3C_AGENT_WORKER-Thread-4 INFO:Local step 45000, global step 725505: loss 0.8398
[2019-04-07 13:50:57,588] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 45000, global step 725505: learning rate 0.0000
[2019-04-07 13:50:59,977] A3C_AGENT_WORKER-Thread-20 INFO:Local step 45000, global step 725982: loss 0.8588
[2019-04-07 13:51:00,012] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 45000, global step 725986: learning rate 0.0000
[2019-04-07 13:51:01,106] A3C_AGENT_WORKER-Thread-2 INFO:Local step 45000, global step 726182: loss 1.0646
[2019-04-07 13:51:01,107] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 45000, global step 726182: learning rate 0.0000
[2019-04-07 13:51:01,783] A3C_AGENT_WORKER-Thread-11 INFO:Local step 45000, global step 726307: loss 0.6282
[2019-04-07 13:51:01,783] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 45000, global step 726307: learning rate 0.0000
[2019-04-07 13:51:02,073] A3C_AGENT_WORKER-Thread-5 INFO:Local step 45000, global step 726375: loss 0.9692
[2019-04-07 13:51:02,132] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 45000, global step 726379: learning rate 0.0000
[2019-04-07 13:51:02,472] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.7543834e-18 2.9270570e-15 1.1736203e-19 4.4076816e-15 5.4045234e-16
 1.0000000e+00 9.1199701e-11 9.7550158e-13], sum to 1.0000
[2019-04-07 13:51:02,474] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2800
[2019-04-07 13:51:02,512] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 47.0, 264.0, 113.0, 24.0, 24.27010649423183, 0.1394080558487435, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4545000.0000, 
sim time next is 4546800.0000, 
raw observation next is [3.0, 45.0, 208.5, 62.5, 24.0, 24.60125173059578, 0.1729548967838467, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.45, 0.695, 0.06906077348066299, 0.5, 0.5501043108829817, 0.5576516322612822, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.53850204], dtype=float32), -1.7982775]. 
=============================================
[2019-04-07 13:51:06,731] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8389384e-18 1.6312288e-16 1.8355049e-21 2.1085384e-14 4.9468667e-16
 1.0000000e+00 6.8404768e-11 2.6244389e-14], sum to 1.0000
[2019-04-07 13:51:06,731] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9581
[2019-04-07 13:51:06,796] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 57.0, 0.0, 0.0, 24.0, 23.79211157205026, 0.05889144810400554, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4671000.0000, 
sim time next is 4672800.0000, 
raw observation next is [2.0, 62.0, 0.0, 0.0, 24.0, 23.59871774527986, 0.03999365185018358, 0.0, 1.0, 64879.385301481896], 
processed observation next is [1.0, 0.08695652173913043, 0.518005540166205, 0.62, 0.0, 0.0, 0.5, 0.466559812106655, 0.5133312172833945, 0.0, 1.0, 0.30894945381658045], 
reward next is 0.9768, 
noisyNet noise sample is [array([0.5809924], dtype=float32), 0.12133773]. 
=============================================
[2019-04-07 13:51:07,693] A3C_AGENT_WORKER-Thread-17 INFO:Local step 45000, global step 727561: loss 0.8292
[2019-04-07 13:51:07,695] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 45000, global step 727562: learning rate 0.0000
[2019-04-07 13:51:09,635] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:51:09,647] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:51:09,651] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run17
[2019-04-07 13:51:14,187] A3C_AGENT_WORKER-Thread-15 INFO:Local step 45000, global step 728744: loss 0.8695
[2019-04-07 13:51:14,187] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 45000, global step 728744: learning rate 0.0000
[2019-04-07 13:51:22,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:51:22,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:51:22,904] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run17
[2019-04-07 13:51:24,521] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:51:24,521] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:51:24,527] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run17
[2019-04-07 13:51:25,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:51:25,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:51:25,233] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run17
[2019-04-07 13:51:25,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:51:25,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:51:25,744] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run17
[2019-04-07 13:51:27,489] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:51:27,489] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:51:27,493] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run17
[2019-04-07 13:51:28,361] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.2730856e-19 3.9334966e-17 2.9690379e-22 1.6166101e-15 3.7631460e-17
 1.0000000e+00 8.1719657e-12 3.4917896e-14], sum to 1.0000
[2019-04-07 13:51:28,361] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2719
[2019-04-07 13:51:28,387] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.5, 58.0, 44.5, 17.0, 24.0, 24.88343489590371, 0.3611964102026524, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1530000.0000, 
sim time next is 1531800.0000, 
raw observation next is [10.25, 59.0, 0.0, 0.0, 24.0, 25.38640111520151, 0.3526004111135362, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.7465373961218837, 0.59, 0.0, 0.0, 0.5, 0.6155334262667926, 0.6175334703711787, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3163614], dtype=float32), 0.5927058]. 
=============================================
[2019-04-07 13:51:29,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9839400e-16 2.2875040e-15 8.7782103e-21 1.3007964e-13 9.9026675e-16
 1.0000000e+00 9.7800223e-12 5.5021992e-13], sum to 1.0000
[2019-04-07 13:51:29,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5680
[2019-04-07 13:51:29,351] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 68.0, 0.0, 0.0, 24.0, 23.13941032818106, -0.1197508205073469, 0.0, 1.0, 71208.73109875822], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 160200.0000, 
sim time next is 162000.0000, 
raw observation next is [-8.4, 68.0, 0.0, 0.0, 24.0, 23.09112701207183, -0.1409866267338252, 0.0, 1.0, 51241.54797238888], 
processed observation next is [1.0, 0.9130434782608695, 0.2299168975069252, 0.68, 0.0, 0.0, 0.5, 0.4242605843393192, 0.4530044577553916, 0.0, 1.0, 0.2440073712970899], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4892105], dtype=float32), 0.037313137]. 
=============================================
[2019-04-07 13:51:29,356] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[ 99.11169 ]
 [ 99.50033 ]
 [100.19066 ]
 [100.476105]
 [100.39603 ]], R is [[98.95037842]
 [98.90750122]
 [98.88731384]
 [98.87259674]
 [98.88387299]].
[2019-04-07 13:51:32,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:51:32,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:51:32,519] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run17
[2019-04-07 13:51:34,450] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7602117e-17 3.0637989e-15 1.5640795e-20 1.3804897e-13 3.0947624e-15
 1.0000000e+00 3.1654790e-10 2.9070650e-12], sum to 1.0000
[2019-04-07 13:51:34,450] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0506
[2019-04-07 13:51:34,714] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 83.0, 83.0, 138.0, 24.0, 23.02532461567612, -0.1517494678702062, 0.0, 1.0, 6492.1976095057435], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 558000.0000, 
sim time next is 559800.0000, 
raw observation next is [-0.7, 82.0, 89.0, 135.0, 24.0, 23.00637868253989, -0.1571241932313671, 0.0, 1.0, 33341.06517302192], 
processed observation next is [0.0, 0.4782608695652174, 0.443213296398892, 0.82, 0.2966666666666667, 0.14917127071823205, 0.5, 0.41719822354499075, 0.44762526892287763, 0.0, 1.0, 0.15876697701439008], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9119096], dtype=float32), -0.31523973]. 
=============================================
[2019-04-07 13:51:39,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:51:39,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:51:39,980] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run17
[2019-04-07 13:51:42,746] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5675051e-16 3.3689336e-14 2.2851531e-19 1.3700393e-13 1.1947176e-15
 1.0000000e+00 5.0117088e-10 3.2060698e-13], sum to 1.0000
[2019-04-07 13:51:42,746] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8435
[2019-04-07 13:51:43,022] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.15, 53.0, 0.0, 0.0, 24.0, 24.21803916966133, -0.06379359194634687, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 322200.0000, 
sim time next is 324000.0000, 
raw observation next is [-11.7, 57.0, 0.0, 0.0, 24.0, 23.64281690501608, -0.02543424648211488, 1.0, 1.0, 152228.9442270752], 
processed observation next is [1.0, 0.782608695652174, 0.13850415512465375, 0.57, 0.0, 0.0, 0.5, 0.4702347420846733, 0.49152191783929505, 1.0, 1.0, 0.7248997344146438], 
reward next is 0.5608, 
noisyNet noise sample is [array([-0.5910832], dtype=float32), 0.61823666]. 
=============================================
[2019-04-07 13:51:43,042] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[92.78263 ]
 [93.07622 ]
 [91.386505]
 [92.09857 ]
 [92.25918 ]], R is [[94.8711319 ]
 [94.92242432]
 [94.6423645 ]
 [94.69593811]
 [94.72291565]].
[2019-04-07 13:52:07,246] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.9572913e-17 9.7409306e-15 3.7069896e-20 1.4304996e-13 1.4740735e-14
 1.0000000e+00 1.3596027e-10 6.3311444e-13], sum to 1.0000
[2019-04-07 13:52:07,246] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0391
[2019-04-07 13:52:07,456] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 72.5, 0.0, 0.0, 24.0, 24.02129427049172, 0.02841212799167518, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2140200.0000, 
sim time next is 2142000.0000, 
raw observation next is [-5.0, 74.0, 0.0, 0.0, 24.0, 23.80292491138037, 0.004936996817531088, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.32409972299168976, 0.74, 0.0, 0.0, 0.5, 0.48357707594836413, 0.5016456656058437, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7360224], dtype=float32), -0.9020781]. 
=============================================
[2019-04-07 13:52:07,463] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[101.90698 ]
 [101.991165]
 [100.51679 ]
 [100.32926 ]
 [100.1421  ]], R is [[101.96724701]
 [101.94757843]
 [101.58304596]
 [101.56721497]
 [101.55154419]].
[2019-04-07 13:52:08,556] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.07063105e-16 9.07293717e-14 4.49066677e-18 3.20339415e-12
 2.27193739e-15 1.00000000e+00 8.53867393e-11 1.76280377e-12], sum to 1.0000
[2019-04-07 13:52:08,556] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1510
[2019-04-07 13:52:08,631] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.2, 52.0, 0.0, 0.0, 24.0, 21.79497053098871, -0.5170511157971706, 0.0, 1.0, 47121.488907581945], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 446400.0000, 
sim time next is 448200.0000, 
raw observation next is [-10.9, 52.0, 0.0, 0.0, 24.0, 21.62944502485522, -0.5296514573794894, 0.0, 1.0, 47414.619374710914], 
processed observation next is [1.0, 0.17391304347826086, 0.16066481994459833, 0.52, 0.0, 0.0, 0.5, 0.30245375207126823, 0.3234495142068369, 0.0, 1.0, 0.2257839017843377], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.32630104], dtype=float32), 0.2766778]. 
=============================================
[2019-04-07 13:52:38,823] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-07 13:52:38,837] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:52:38,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:52:38,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run38
[2019-04-07 13:52:38,863] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:52:38,864] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:52:38,866] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run38
[2019-04-07 13:52:38,889] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 13:52:38,897] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:52:38,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run38
[2019-04-07 13:54:47,903] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2788.7623 70927233.8163 166.2180
[2019-04-07 13:55:19,331] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 13:55:25,663] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 13:55:26,685] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 740000, evaluation results [740000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2788.7623188653442, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 13:55:38,610] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7268169e-21 1.7609553e-16 6.6702323e-24 1.4026237e-15 2.1865651e-18
 1.0000000e+00 7.2942222e-13 2.0656586e-14], sum to 1.0000
[2019-04-07 13:55:38,610] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8223
[2019-04-07 13:55:38,630] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 75.0, 0.0, 0.0, 24.0, 24.01441955804582, 0.159885547296804, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1035000.0000, 
sim time next is 1036800.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 24.0, 23.85187331752235, 0.1326941693029464, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.0, 0.8614958448753465, 0.75, 0.0, 0.0, 0.5, 0.48765610979352925, 0.5442313897676488, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.13295458], dtype=float32), 0.331823]. 
=============================================
[2019-04-07 13:55:53,658] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.2265212e-20 1.3071533e-17 9.2330552e-22 8.2172450e-16 2.8801357e-17
 1.0000000e+00 3.4242362e-12 2.0773856e-14], sum to 1.0000
[2019-04-07 13:55:53,658] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4539
[2019-04-07 13:55:53,724] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 100.0, 0.0, 0.0, 24.0, 23.58454392103748, -0.07650929576593789, 0.0, 1.0, 20411.105702104225], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3119400.0000, 
sim time next is 3121200.0000, 
raw observation next is [2.0, 100.0, 0.0, 0.0, 24.0, 23.59435583661636, -0.1305354483414201, 0.0, 1.0, 11195.557961621169], 
processed observation next is [1.0, 0.13043478260869565, 0.518005540166205, 1.0, 0.0, 0.0, 0.5, 0.4661963197180299, 0.45648818388619333, 0.0, 1.0, 0.053312180769624615], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.14922616], dtype=float32), 0.5312819]. 
=============================================
[2019-04-07 13:56:01,742] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.08119547e-19 1.42172508e-16 5.41761144e-23 5.38491138e-16
 8.39975287e-19 1.00000000e+00 2.46284980e-12 1.23972555e-14], sum to 1.0000
[2019-04-07 13:56:01,742] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0871
[2019-04-07 13:56:01,824] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.25, 82.0, 0.0, 0.0, 24.0, 23.73415229218964, 0.103882119737941, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1553400.0000, 
sim time next is 1555200.0000, 
raw observation next is [5.0, 82.0, 0.0, 0.0, 24.0, 23.56032826239871, 0.1141233084583882, 0.0, 1.0, 99120.96523205434], 
processed observation next is [1.0, 0.0, 0.6011080332409973, 0.82, 0.0, 0.0, 0.5, 0.46336068853322576, 0.5380411028194627, 0.0, 1.0, 0.4720045963431159], 
reward next is 0.8137, 
noisyNet noise sample is [array([0.452966], dtype=float32), 0.16247386]. 
=============================================
[2019-04-07 13:56:06,374] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.8896436e-15 3.3323420e-13 7.0176713e-18 1.7479082e-12 8.3184619e-14
 1.0000000e+00 1.6012230e-08 1.5664213e-11], sum to 1.0000
[2019-04-07 13:56:06,374] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1857
[2019-04-07 13:56:06,452] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 86.0, 0.0, 0.0, 24.0, 23.36852745854031, -0.09805779653537239, 0.0, 1.0, 49573.81280286069], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1807200.0000, 
sim time next is 1809000.0000, 
raw observation next is [-5.0, 84.0, 0.0, 0.0, 24.0, 23.28238508353863, -0.1102018629325752, 0.0, 1.0, 49917.7353605314], 
processed observation next is [0.0, 0.9565217391304348, 0.32409972299168976, 0.84, 0.0, 0.0, 0.5, 0.44019875696155264, 0.4632660456891416, 0.0, 1.0, 0.23770350171681617], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05976545], dtype=float32), -1.9604172]. 
=============================================
[2019-04-07 13:56:06,456] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[95.22918 ]
 [95.25911 ]
 [95.27803 ]
 [94.995316]
 [94.80824 ]], R is [[95.1464386 ]
 [95.19497681]
 [95.24302673]
 [95.29059601]
 [95.33769226]].
[2019-04-07 13:56:18,801] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4247532e-18 4.4844551e-17 7.6772226e-22 8.2194711e-16 1.5909201e-17
 1.0000000e+00 1.0628898e-11 2.2642900e-14], sum to 1.0000
[2019-04-07 13:56:18,801] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2030
[2019-04-07 13:56:18,840] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.1, 73.0, 0.0, 0.0, 24.0, 23.65570740180183, -0.07735776424946854, 0.0, 1.0, 11438.254247948322], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4343400.0000, 
sim time next is 4345200.0000, 
raw observation next is [2.9, 75.0, 0.0, 0.0, 24.0, 23.53533558446707, -0.05843616263572774, 0.0, 1.0, 66392.2117646247], 
processed observation next is [1.0, 0.30434782608695654, 0.5429362880886427, 0.75, 0.0, 0.0, 0.5, 0.46127796537225585, 0.4805212791214241, 0.0, 1.0, 0.31615338935535575], 
reward next is 0.9696, 
noisyNet noise sample is [array([1.4881248], dtype=float32), 1.2839016]. 
=============================================
[2019-04-07 13:56:26,037] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7290720e-17 4.2321897e-13 3.3017375e-18 5.2565504e-12 2.7754198e-14
 1.0000000e+00 1.1577610e-08 6.5863565e-11], sum to 1.0000
[2019-04-07 13:56:26,037] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9586
[2019-04-07 13:56:26,136] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 54.5, 114.0, 816.0, 24.0, 23.33582879717972, 0.01393577915710843, 0.0, 1.0, 18706.862632847275], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3583800.0000, 
sim time next is 3585600.0000, 
raw observation next is [-3.0, 55.0, 116.0, 819.5, 24.0, 23.39603666220753, 0.02749921385375594, 0.0, 1.0, 18704.633052294335], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.55, 0.38666666666666666, 0.905524861878453, 0.5, 0.44966972185062737, 0.5091664046179186, 0.0, 1.0, 0.0890696812014016], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2625009], dtype=float32), -1.180483]. 
=============================================
[2019-04-07 13:56:51,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:56:51,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:56:51,740] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run18
[2019-04-07 13:56:59,740] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:56:59,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:56:59,745] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run18
[2019-04-07 13:57:11,179] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.7376717e-15 2.4560781e-14 3.0047773e-17 4.0607521e-13 1.2380437e-13
 1.0000000e+00 2.5395066e-09 2.1871496e-10], sum to 1.0000
[2019-04-07 13:57:11,179] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3312
[2019-04-07 13:57:11,234] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 35.5, 82.0, 549.0, 24.0, 23.49467085287927, 0.02258166508152306, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4811400.0000, 
sim time next is 4813200.0000, 
raw observation next is [3.0, 34.0, 57.5, 367.0, 24.0, 23.51701739436515, -0.003079339555919251, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5457063711911359, 0.34, 0.19166666666666668, 0.40552486187845305, 0.5, 0.4597514495304293, 0.49897355348136024, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2117105], dtype=float32), -1.1441716]. 
=============================================
[2019-04-07 13:57:13,426] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.6153980e-19 2.9799074e-15 6.5074052e-21 8.0332110e-14 5.4608482e-17
 1.0000000e+00 6.1511586e-12 2.2188108e-13], sum to 1.0000
[2019-04-07 13:57:13,427] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9563
[2019-04-07 13:57:13,519] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.0, 30.0, 183.5, 86.5, 24.0, 23.78157033070598, -0.03074790382488451, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2815200.0000, 
sim time next is 2817000.0000, 
raw observation next is [6.5, 27.0, 118.0, 0.0, 24.0, 23.65796786003804, -0.1023142372479352, 1.0, 1.0, 12453.607780153689], 
processed observation next is [1.0, 0.6086956521739131, 0.6426592797783934, 0.27, 0.3933333333333333, 0.0, 0.5, 0.47149732166983654, 0.46589525425068823, 1.0, 1.0, 0.05930289419120804], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.34364292], dtype=float32), 1.6953905]. 
=============================================
[2019-04-07 13:57:13,525] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[ 99.947365]
 [100.952934]
 [100.945015]
 [100.82859 ]
 [100.24704 ]], R is [[98.9621048 ]
 [98.9724884 ]
 [98.9827652 ]
 [98.99293518]
 [99.00300598]].
[2019-04-07 13:57:17,542] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:57:17,542] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:57:17,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run18
[2019-04-07 13:57:22,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:57:22,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:57:22,172] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run18
[2019-04-07 13:57:23,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 13:57:23,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:57:23,844] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run18
[2019-04-07 13:57:24,701] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-07 13:57:24,705] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:57:24,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:57:24,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run39
[2019-04-07 13:57:24,776] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 13:57:24,776] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:57:24,778] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run39
[2019-04-07 13:57:24,805] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 13:57:24,805] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 13:57:24,808] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run39
[2019-04-07 13:59:27,160] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:00:06,291] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.6292 79463814.5229 95.0531
[2019-04-07 14:00:10,617] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:00:11,639] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 760000, evaluation results [760000.0, 2782.629198479697, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:00:16,370] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.9413921e-18 3.5049931e-15 4.2033541e-22 1.8891159e-14 1.8091218e-16
 1.0000000e+00 7.4631812e-10 3.0948836e-13], sum to 1.0000
[2019-04-07 14:00:16,370] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1862
[2019-04-07 14:00:16,434] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 52.5, 0.0, 0.0, 24.0, 23.53736982102316, -0.02162967373333662, 0.0, 1.0, 50217.10726745932], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5027400.0000, 
sim time next is 5029200.0000, 
raw observation next is [-1.0, 50.0, 0.0, 0.0, 24.0, 23.54866599257852, -0.02317620695597489, 0.0, 1.0, 25028.382209305815], 
processed observation next is [1.0, 0.21739130434782608, 0.4349030470914128, 0.5, 0.0, 0.0, 0.5, 0.4623888327148767, 0.4922745976813417, 0.0, 1.0, 0.11918277242526579], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4026353], dtype=float32), -0.5424508]. 
=============================================
[2019-04-07 14:00:20,022] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:00:20,022] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:00:20,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run18
[2019-04-07 14:00:23,098] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9481628e-20 8.3357571e-18 2.2023078e-21 5.8962599e-16 3.7143540e-18
 1.0000000e+00 2.4984726e-12 1.5179986e-15], sum to 1.0000
[2019-04-07 14:00:23,098] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0875
[2019-04-07 14:00:23,185] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 100.0, 0.0, 0.0, 24.0, 23.4458566230107, 0.03967269763846477, 0.0, 1.0, 44787.04516224599], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3216600.0000, 
sim time next is 3218400.0000, 
raw observation next is [-3.0, 100.0, 0.0, 0.0, 24.0, 23.44643443083199, 0.05496638969884162, 0.0, 1.0, 53710.520769487055], 
processed observation next is [1.0, 0.2608695652173913, 0.3795013850415513, 1.0, 0.0, 0.0, 0.5, 0.4538695359026657, 0.5183221298996139, 0.0, 1.0, 0.255764384616605], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8919925], dtype=float32), 0.08571141]. 
=============================================
[2019-04-07 14:00:25,877] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.0249167e-18 6.9557922e-16 4.7967590e-21 2.3286024e-15 5.3278778e-18
 1.0000000e+00 1.9062172e-11 3.5524560e-15], sum to 1.0000
[2019-04-07 14:00:25,877] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8761
[2019-04-07 14:00:25,989] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 77.0, 34.0, 307.5, 24.0, 24.85749572836338, 0.2827603693703704, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3258000.0000, 
sim time next is 3259800.0000, 
raw observation next is [-4.0, 71.0, 9.0, 104.0, 24.0, 24.17622251784135, 0.1393556696127338, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3518005540166205, 0.71, 0.03, 0.11491712707182321, 0.5, 0.5146852098201125, 0.5464518898709113, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6774436], dtype=float32), 0.3388288]. 
=============================================
[2019-04-07 14:00:27,350] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0439889e-18 2.1066230e-16 1.5743199e-22 9.8275592e-15 3.5882446e-17
 1.0000000e+00 6.6140487e-12 8.2739967e-14], sum to 1.0000
[2019-04-07 14:00:27,350] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6170
[2019-04-07 14:00:27,409] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.0, 77.0, 0.0, 0.0, 24.0, 23.44271681049809, -0.01848809107389288, 0.0, 1.0, 26633.44634454578], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3292200.0000, 
sim time next is 3294000.0000, 
raw observation next is [-8.0, 77.0, 0.0, 0.0, 24.0, 23.25995784182003, -0.05739058111985799, 0.0, 1.0, 56726.25907539203], 
processed observation next is [1.0, 0.13043478260869565, 0.24099722991689754, 0.77, 0.0, 0.0, 0.5, 0.43832982015166905, 0.48086980629338066, 0.0, 1.0, 0.27012504321615255], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7850399], dtype=float32), 1.0807995]. 
=============================================
[2019-04-07 14:00:27,415] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[101.59843]
 [102.54109]
 [103.23134]
 [103.93071]
 [105.48046]], R is [[101.31103516]
 [101.29792786]
 [101.28495026]
 [101.27210236]
 [101.25938416]].
[2019-04-07 14:00:33,010] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4318963e-18 1.6805405e-15 3.5809901e-21 9.2503274e-15 2.4653745e-15
 1.0000000e+00 1.9121829e-10 4.8552102e-13], sum to 1.0000
[2019-04-07 14:00:33,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0816
[2019-04-07 14:00:33,158] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 60.0, 87.0, 422.0, 24.0, 23.94934902804967, 0.02557973884613797, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3400200.0000, 
sim time next is 3402000.0000, 
raw observation next is [-1.0, 60.0, 93.0, 540.0, 24.0, 24.38265281920522, 0.08815658218443136, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4349030470914128, 0.6, 0.31, 0.5966850828729282, 0.5, 0.5318877349337683, 0.5293855273948105, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7034481], dtype=float32), 2.0220268]. 
=============================================
[2019-04-07 14:00:33,161] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[101.46759]
 [101.482  ]
 [101.27936]
 [101.13821]
 [101.22189]], R is [[101.74280548]
 [101.72537994]
 [101.70812988]
 [101.69104767]
 [101.67414093]].
[2019-04-07 14:00:36,052] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.7568034e-19 6.5248151e-18 3.8612631e-22 3.3320970e-15 3.0428056e-18
 1.0000000e+00 3.2132279e-12 1.9404031e-14], sum to 1.0000
[2019-04-07 14:00:36,053] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6154
[2019-04-07 14:00:36,108] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 24.0, 23.49660606939261, -0.02037916139342633, 0.0, 1.0, 29649.821757389447], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3475800.0000, 
sim time next is 3477600.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 24.0, 23.50033444703433, -0.04073032250920102, 0.0, 1.0, 32691.562655644], 
processed observation next is [1.0, 0.2608695652173913, 0.46260387811634357, 0.72, 0.0, 0.0, 0.5, 0.4583612039195275, 0.4864232258302663, 0.0, 1.0, 0.15567410788401906], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.33215845], dtype=float32), 0.3894691]. 
=============================================
[2019-04-07 14:00:45,694] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.4933024e-16 2.0948120e-15 6.4413216e-19 2.9326875e-13 1.7926626e-15
 1.0000000e+00 3.8397094e-10 1.3931812e-13], sum to 1.0000
[2019-04-07 14:00:45,694] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2828
[2019-04-07 14:00:45,770] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 24.0, 23.45870797865874, -0.004414667091912544, 0.0, 1.0, 50075.39831976261], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3801600.0000, 
sim time next is 3803400.0000, 
raw observation next is [-3.5, 74.0, 0.0, 0.0, 24.0, 23.4465723569768, 0.01624147187025874, 0.0, 1.0, 54137.24523209431], 
processed observation next is [1.0, 0.0, 0.36565096952908593, 0.74, 0.0, 0.0, 0.5, 0.4538810297480668, 0.5054138239567529, 0.0, 1.0, 0.2577964058671158], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8944938], dtype=float32), 1.5550244]. 
=============================================
[2019-04-07 14:00:51,706] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.69497556e-18 5.53792767e-15 5.35157987e-21 8.17343833e-14
 1.04496456e-16 1.00000000e+00 1.45452548e-11 1.32353156e-12], sum to 1.0000
[2019-04-07 14:00:51,706] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8440
[2019-04-07 14:00:51,770] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 85.0, 0.0, 0.0, 24.0, 23.3204812784418, -0.1253756902385594, 0.0, 1.0, 41488.46198019994], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 536400.0000, 
sim time next is 538200.0000, 
raw observation next is [1.35, 86.5, 0.0, 0.0, 24.0, 23.2767239088998, -0.1318879287989422, 0.0, 1.0, 41653.84763509839], 
processed observation next is [0.0, 0.21739130434782608, 0.5000000000000001, 0.865, 0.0, 0.0, 0.5, 0.4397269924083167, 0.45603735706701926, 0.0, 1.0, 0.19835165540523042], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.98187], dtype=float32), 0.69927794]. 
=============================================
[2019-04-07 14:00:59,819] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:00:59,819] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:00:59,835] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run18
[2019-04-07 14:01:00,218] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:01:00,218] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:01:00,222] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run18
[2019-04-07 14:01:06,944] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4027621e-16 8.9461833e-15 6.6482760e-19 3.8511897e-13 8.5494408e-16
 1.0000000e+00 9.1265086e-12 1.5025916e-13], sum to 1.0000
[2019-04-07 14:01:06,944] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5909
[2019-04-07 14:01:07,068] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 45.0, 0.0, 0.0, 24.0, 23.64088011832577, 0.07995860454015079, 0.0, 1.0, 70905.66578338442], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3961800.0000, 
sim time next is 3963600.0000, 
raw observation next is [-7.0, 45.0, 0.0, 0.0, 24.0, 23.60016150839085, 0.0590345336281228, 0.0, 1.0, 37001.98311625476], 
processed observation next is [1.0, 0.9130434782608695, 0.2686980609418283, 0.45, 0.0, 0.0, 0.5, 0.4666801256992376, 0.519678177876041, 0.0, 1.0, 0.17619991960121317], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6260458], dtype=float32), -0.23415357]. 
=============================================
[2019-04-07 14:01:12,779] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9578934e-17 8.0363376e-14 1.5596653e-19 1.8213057e-12 3.8732801e-14
 1.0000000e+00 1.4911175e-09 1.5987914e-11], sum to 1.0000
[2019-04-07 14:01:12,780] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8388
[2019-04-07 14:01:12,811] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 51.0, 110.0, 53.0, 24.0, 23.47684112625282, -0.09091967730516308, 0.0, 1.0, 12356.981929702177], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4264200.0000, 
sim time next is 4266000.0000, 
raw observation next is [3.0, 53.0, 146.0, 92.0, 24.0, 23.44594371358033, -0.1023566589497121, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.5457063711911359, 0.53, 0.4866666666666667, 0.10165745856353592, 0.5, 0.4538286427983609, 0.4658811136834293, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.9752983], dtype=float32), 0.23420936]. 
=============================================
[2019-04-07 14:01:12,815] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[92.736435]
 [92.48462 ]
 [91.93966 ]
 [91.87685 ]
 [91.645966]], R is [[92.96012115]
 [93.03051758]
 [93.1002121 ]
 [93.16921234]
 [93.23751831]].
[2019-04-07 14:01:29,329] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:01:29,329] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:01:29,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run18
[2019-04-07 14:01:42,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:01:42,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:01:42,016] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run18
[2019-04-07 14:01:43,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.12999286e-19 2.04060784e-18 1.24079861e-23 8.16257170e-16
 1.30635575e-17 1.00000000e+00 9.45126139e-13 4.73675258e-14], sum to 1.0000
[2019-04-07 14:01:43,908] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6745
[2019-04-07 14:01:43,944] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.9, 94.5, 0.0, 0.0, 24.0, 23.72467138582176, 0.1490471021382769, 0.0, 1.0, 17794.757544186436], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1647000.0000, 
sim time next is 1648800.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 24.0, 23.90116425946696, 0.1476072244564276, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.662049861495845, 0.96, 0.0, 0.0, 0.5, 0.4917636882889133, 0.5492024081521425, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.77343917], dtype=float32), 0.048922587]. 
=============================================
[2019-04-07 14:01:47,104] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:01:47,104] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:01:47,124] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run18
[2019-04-07 14:01:47,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:01:47,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:01:47,725] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run18
[2019-04-07 14:01:48,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:01:48,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:01:48,535] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run18
[2019-04-07 14:01:48,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:01:48,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:01:48,600] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run18
[2019-04-07 14:01:51,480] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:01:51,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:01:51,484] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run18
[2019-04-07 14:01:55,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:01:55,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:01:55,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run18
[2019-04-07 14:02:18,001] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-07 14:02:18,001] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:02:18,002] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:02:18,004] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run40
[2019-04-07 14:02:18,022] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:02:18,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:02:18,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run40
[2019-04-07 14:02:18,043] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 14:02:18,046] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:02:18,049] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run40
[2019-04-07 14:03:09,090] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12325696], dtype=float32), 0.1449578]
[2019-04-07 14:03:09,090] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-9.5, 91.0, 17.5, 11.0, 24.0, 23.62909488802488, -0.1723413572741507, 1.0, 1.0, 0.0]
[2019-04-07 14:03:09,091] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 14:03:09,092] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [7.6918996e-17 9.9782463e-15 1.4455834e-19 2.7592856e-13 5.1565430e-15
 1.0000000e+00 4.1295864e-10 1.1769600e-12], sampled 0.020918643252228142
[2019-04-07 14:04:19,229] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12325696], dtype=float32), 0.1449578]
[2019-04-07 14:04:19,230] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [19.9, 42.5, 0.0, 0.0, 24.0, 28.49127976299402, 1.34347861847772, 0.0, 0.0, 0.0]
[2019-04-07 14:04:19,230] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 14:04:19,231] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.1382682e-17 3.5314995e-15 3.5187827e-20 1.1413010e-13 6.1514746e-16
 1.0000000e+00 6.9186816e-11 4.3229038e-13], sampled 0.17091697028038144
[2019-04-07 14:04:26,084] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:04:57,649] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 14:05:01,251] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:05:02,275] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 780000, evaluation results [780000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:05:02,884] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.6977811e-19 2.5454867e-16 1.9535932e-22 4.0956423e-15 2.6976218e-15
 1.0000000e+00 2.8041350e-12 2.3583961e-13], sum to 1.0000
[2019-04-07 14:05:02,884] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4647
[2019-04-07 14:05:02,946] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 91.0, 0.0, 0.0, 24.0, 23.17947872299828, -0.1224393263884614, 0.0, 1.0, 44361.92461295754], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2075400.0000, 
sim time next is 2077200.0000, 
raw observation next is [-4.5, 91.0, 0.0, 0.0, 24.0, 23.18738018180871, -0.134144984199091, 0.0, 1.0, 44032.590372976825], 
processed observation next is [1.0, 0.043478260869565216, 0.3379501385041552, 0.91, 0.0, 0.0, 0.5, 0.43228168181739246, 0.4552850052669697, 0.0, 1.0, 0.20967900177608012], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.33841857], dtype=float32), -0.02873766]. 
=============================================
[2019-04-07 14:05:15,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0513811e-18 4.8441031e-16 2.7904954e-21 1.0280814e-12 1.4657207e-15
 1.0000000e+00 1.6079330e-10 7.9897113e-13], sum to 1.0000
[2019-04-07 14:05:15,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7933
[2019-04-07 14:05:15,867] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-14.5, 66.0, 55.0, 733.5, 24.0, 23.96587580860119, -0.1074447046277416, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 381600.0000, 
sim time next is 383400.0000, 
raw observation next is [-13.95, 63.0, 71.0, 729.0, 24.0, 23.91509600848795, -0.1052254865608452, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.07617728531855956, 0.63, 0.23666666666666666, 0.8055248618784531, 0.5, 0.4929246673739958, 0.46492483781305155, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.50104237], dtype=float32), -0.22803926]. 
=============================================
[2019-04-07 14:05:22,915] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.1617390e-17 9.3648318e-15 3.0370523e-19 1.6191020e-13 7.3541586e-15
 1.0000000e+00 2.8910160e-10 1.7136528e-12], sum to 1.0000
[2019-04-07 14:05:22,915] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6641
[2019-04-07 14:05:23,074] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 47.0, 123.0, 170.5, 24.0, 23.04358022376577, -0.1386418772418502, 0.0, 1.0, 39364.4018596948], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2386800.0000, 
sim time next is 2388600.0000, 
raw observation next is [0.0, 47.0, 86.0, 341.0, 24.0, 23.08559699746303, -0.1219788510315652, 0.0, 1.0, 21512.876742780423], 
processed observation next is [0.0, 0.6521739130434783, 0.46260387811634357, 0.47, 0.2866666666666667, 0.37679558011049724, 0.5, 0.4237997497885857, 0.45934038298947827, 0.0, 1.0, 0.1024422702037163], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0627298], dtype=float32), 0.53391516]. 
=============================================
[2019-04-07 14:05:26,996] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4847177e-17 6.8884086e-15 4.3785610e-20 3.0773293e-14 1.0243510e-15
 1.0000000e+00 6.4785988e-10 1.3516059e-13], sum to 1.0000
[2019-04-07 14:05:26,996] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5056
[2019-04-07 14:05:27,082] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.2, 91.0, 0.0, 0.0, 24.0, 22.33517293846827, -0.3524032570152227, 0.0, 1.0, 44039.018434824226], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2269800.0000, 
sim time next is 2271600.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 24.0, 22.22971589038708, -0.3861411782653451, 0.0, 1.0, 43938.21351197089], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.5, 0.35247632419892333, 0.37128627391155167, 0.0, 1.0, 0.20922958815224235], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.36876008], dtype=float32), -0.33210716]. 
=============================================
[2019-04-07 14:05:34,143] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.8693918e-17 4.7270567e-15 2.6944166e-20 1.0138596e-13 1.4673761e-16
 1.0000000e+00 1.3809923e-10 5.7308646e-12], sum to 1.0000
[2019-04-07 14:05:34,144] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9594
[2019-04-07 14:05:34,239] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 72.0, 101.0, 49.0, 24.0, 23.7847689705755, -0.1331860196682433, 1.0, 1.0, 12465.98499671688], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 725400.0000, 
sim time next is 727200.0000, 
raw observation next is [-1.7, 68.0, 120.0, 58.5, 24.0, 23.90650939564675, -0.1222357789607966, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4155124653739613, 0.68, 0.4, 0.06464088397790055, 0.5, 0.4922091163038959, 0.4592547403464011, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.79816955], dtype=float32), -0.21645068]. 
=============================================
[2019-04-07 14:05:38,979] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.3803984e-17 1.5048645e-15 7.3729322e-20 8.3339894e-15 2.4141430e-14
 1.0000000e+00 3.9623355e-10 1.1949672e-13], sum to 1.0000
[2019-04-07 14:05:38,980] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5336
[2019-04-07 14:05:39,141] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.0, 69.0, 0.0, 0.0, 24.0, 23.13233893793799, -0.1261536745272148, 0.0, 1.0, 45742.969404266274], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2682000.0000, 
sim time next is 2683800.0000, 
raw observation next is [-10.0, 72.5, 0.0, 0.0, 24.0, 23.0185545019453, -0.1678581188983196, 0.0, 1.0, 45652.091169951775], 
processed observation next is [1.0, 0.043478260869565216, 0.18559556786703602, 0.725, 0.0, 0.0, 0.5, 0.4182128751621083, 0.4440472937005601, 0.0, 1.0, 0.21739091033310368], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5259488], dtype=float32), 1.1061037]. 
=============================================
[2019-04-07 14:05:57,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7640218e-20 1.8091357e-16 2.2821095e-22 8.3907348e-16 3.9704769e-17
 1.0000000e+00 1.6199408e-11 2.3502456e-13], sum to 1.0000
[2019-04-07 14:05:57,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5839
[2019-04-07 14:05:57,696] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.05, 89.5, 96.0, 0.0, 24.0, 24.71195535881979, 0.1963364487916653, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 988200.0000, 
sim time next is 990000.0000, 
raw observation next is [11.6, 86.0, 108.0, 0.0, 24.0, 24.82328961107969, 0.2155691770383143, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.7839335180055402, 0.86, 0.36, 0.0, 0.5, 0.5686074675899743, 0.5718563923461047, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5946032], dtype=float32), 1.6444767]. 
=============================================
[2019-04-07 14:05:57,722] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[118.63988 ]
 [118.232834]
 [117.48817 ]
 [117.15349 ]
 [116.225624]], R is [[119.24241638]
 [119.04999542]
 [118.85949707]
 [118.67090607]
 [118.48419952]].
[2019-04-07 14:06:07,701] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3812855e-20 1.0196910e-17 5.3367710e-24 2.9807587e-16 4.3916636e-18
 1.0000000e+00 2.5585355e-13 2.5853466e-15], sum to 1.0000
[2019-04-07 14:06:07,701] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7215
[2019-04-07 14:06:07,757] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 24.0, 23.50878257824345, 0.04005600993777392, 0.0, 1.0, 54047.39843745023], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1402200.0000, 
sim time next is 1404000.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 24.0, 23.4788210567762, 0.01716324585431959, 0.0, 1.0, 13686.877985134417], 
processed observation next is [1.0, 0.2608695652173913, 0.44598337950138506, 1.0, 0.0, 0.0, 0.5, 0.4565684213980168, 0.5057210819514398, 0.0, 1.0, 0.06517560945302103], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.51769817], dtype=float32), 1.937543]. 
=============================================
[2019-04-07 14:06:07,769] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[112.54666]
 [112.10679]
 [111.96389]
 [112.2873 ]
 [111.57543]], R is [[112.26069641]
 [112.13809204]
 [112.016716  ]
 [111.89655304]
 [111.64666748]].
[2019-04-07 14:06:08,894] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6018179e-19 1.2166227e-16 5.3310185e-22 4.2326717e-14 2.3780718e-17
 1.0000000e+00 7.8911931e-13 1.2558670e-13], sum to 1.0000
[2019-04-07 14:06:08,894] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0002
[2019-04-07 14:06:08,927] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 71.0, 93.0, 727.5, 24.0, 23.92861332214373, 0.254751921174668, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3250800.0000, 
sim time next is 3252600.0000, 
raw observation next is [-2.5, 71.0, 85.0, 686.0, 24.0, 24.8461883486916, 0.339939102060808, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.39335180055401664, 0.71, 0.2833333333333333, 0.7580110497237569, 0.5, 0.5705156957243002, 0.6133130340202694, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.10571187], dtype=float32), -0.531202]. 
=============================================
[2019-04-07 14:06:18,887] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6112698e-18 1.3681153e-16 6.0427281e-21 2.2855151e-15 1.0779913e-16
 1.0000000e+00 7.8120399e-11 7.3980535e-15], sum to 1.0000
[2019-04-07 14:06:18,888] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8046
[2019-04-07 14:06:18,923] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 92.0, 93.0, 511.5, 24.0, 24.11398368115517, 0.1623646187025821, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3229200.0000, 
sim time next is 3231000.0000, 
raw observation next is [-3.0, 92.0, 101.0, 653.0, 24.0, 24.3019114941413, 0.2144291179993056, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.92, 0.33666666666666667, 0.7215469613259669, 0.5, 0.5251592911784417, 0.5714763726664353, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.30416727], dtype=float32), 0.5293547]. 
=============================================
[2019-04-07 14:06:18,927] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[108.293015]
 [108.3857  ]
 [108.91368 ]
 [109.15824 ]
 [109.371994]], R is [[107.69073486]
 [107.61383057]
 [107.53769684]
 [107.46231842]
 [107.38769531]].
[2019-04-07 14:06:22,767] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.0493437e-19 3.6048200e-16 7.6155352e-21 1.7970285e-14 2.7204678e-17
 1.0000000e+00 7.6368070e-12 1.3637294e-14], sum to 1.0000
[2019-04-07 14:06:22,771] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0840
[2019-04-07 14:06:22,826] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 91.0, 0.0, 0.0, 24.0, 23.42379203193462, -0.002684956172197666, 0.0, 1.0, 40556.01552955867], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1738800.0000, 
sim time next is 1740600.0000, 
raw observation next is [-0.3, 89.0, 0.0, 0.0, 24.0, 23.39636559947053, -0.003930653205715516, 0.0, 1.0, 51897.519495697044], 
processed observation next is [0.0, 0.13043478260869565, 0.4542936288088643, 0.89, 0.0, 0.0, 0.5, 0.44969713328921096, 0.4986897822647615, 0.0, 1.0, 0.24713104521760498], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06637424], dtype=float32), 1.0933712]. 
=============================================
[2019-04-07 14:06:29,456] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.5796900e-17 1.6970236e-14 9.8868698e-20 3.1920175e-13 3.5160258e-16
 1.0000000e+00 7.2784040e-10 1.6600330e-12], sum to 1.0000
[2019-04-07 14:06:29,456] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9273
[2019-04-07 14:06:29,496] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 82.0, 0.0, 0.0, 24.0, 22.53475042465359, -0.3638768405011761, 0.0, 1.0, 46098.57527488144], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1918800.0000, 
sim time next is 1920600.0000, 
raw observation next is [-8.9, 82.0, 0.0, 0.0, 24.0, 22.43404184747966, -0.3832651528763155, 0.0, 1.0, 45946.08331233886], 
processed observation next is [1.0, 0.21739130434782608, 0.21606648199445982, 0.82, 0.0, 0.0, 0.5, 0.36950348728997157, 0.3722449490412281, 0.0, 1.0, 0.21879087291589933], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.12273958], dtype=float32), 0.64632386]. 
=============================================
[2019-04-07 14:06:32,728] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3309463e-17 5.3790143e-14 2.3518876e-20 7.7583000e-15 5.8398979e-15
 1.0000000e+00 3.5654965e-11 1.1147230e-12], sum to 1.0000
[2019-04-07 14:06:32,729] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8378
[2019-04-07 14:06:32,912] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 59.0, 111.0, 793.5, 24.0, 23.62489910904625, 0.06570767437130122, 1.0, 1.0, 100136.10214338783], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2725200.0000, 
sim time next is 2727000.0000, 
raw observation next is [-5.4, 57.5, 109.0, 788.0, 24.0, 24.41810657620169, 0.1806729097256539, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.31301939058171746, 0.575, 0.36333333333333334, 0.8707182320441988, 0.5, 0.5348422146834743, 0.5602243032418847, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4504306], dtype=float32), -0.03134311]. 
=============================================
[2019-04-07 14:06:32,915] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[98.806404]
 [97.717255]
 [98.04044 ]
 [97.77537 ]
 [97.677345]], R is [[98.97663116]
 [98.79573822]
 [98.80778503]
 [98.81970978]
 [98.83151245]].
[2019-04-07 14:07:00,168] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.6618800e-20 9.7184656e-17 7.5975370e-23 1.2133188e-15 4.7336383e-17
 1.0000000e+00 3.6157900e-12 2.9352267e-14], sum to 1.0000
[2019-04-07 14:07:00,168] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6495
[2019-04-07 14:07:00,221] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.6, 58.5, 0.0, 0.0, 24.0, 25.36670199100229, 0.4758310863393837, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4393800.0000, 
sim time next is 4395600.0000, 
raw observation next is [10.2, 59.0, 0.0, 0.0, 24.0, 25.21552819521877, 0.4489996960315516, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.7451523545706372, 0.59, 0.0, 0.0, 0.5, 0.6012940162682309, 0.6496665653438506, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.12875806], dtype=float32), 1.5335087]. 
=============================================
[2019-04-07 14:07:03,145] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.7236805e-15 1.1497369e-13 2.4454867e-17 5.6081658e-12 6.9431700e-13
 1.0000000e+00 5.7585070e-09 6.3630108e-12], sum to 1.0000
[2019-04-07 14:07:03,145] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7396
[2019-04-07 14:07:03,237] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 50.0, 0.0, 0.0, 24.0, 23.44976894891754, -0.03157235989581701, 0.0, 1.0, 35844.33431501126], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4158000.0000, 
sim time next is 4159800.0000, 
raw observation next is [-3.0, 50.0, 0.0, 0.0, 24.0, 23.46089055550422, -0.0378861579948712, 0.0, 1.0, 34812.72850533315], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.5, 0.0, 0.0, 0.5, 0.4550742129586851, 0.48737128066837626, 0.0, 1.0, 0.1657748976444436], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.288524], dtype=float32), -0.34985435]. 
=============================================
[2019-04-07 14:07:04,972] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:07:04,972] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:07:04,976] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run19
[2019-04-07 14:07:05,819] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-07 14:07:05,821] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:07:05,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:07:05,823] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run41
[2019-04-07 14:07:05,846] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:07:05,847] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:07:05,849] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 14:07:05,849] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:07:05,852] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run41
[2019-04-07 14:07:05,868] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run41
[2019-04-07 14:07:12,895] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.12319238], dtype=float32), 0.1453835]
[2019-04-07 14:07:12,895] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-1.1658298075, 92.625586975, 0.0, 0.0, 24.0, 23.14717060806394, -0.1143588686937633, 0.0, 1.0, 41928.14594322221]
[2019-04-07 14:07:12,896] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 14:07:12,896] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.1803736e-18 3.1609443e-16 1.2887520e-21 1.3787233e-14 7.9495498e-17
 1.0000000e+00 2.9788793e-11 5.2892003e-14], sampled 0.5858403994418178
[2019-04-07 14:09:10,535] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:09:41,465] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 14:09:44,290] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:09:45,313] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 800000, evaluation results [800000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:09:56,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:09:56,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:09:56,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run19
[2019-04-07 14:10:07,605] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7915447e-19 3.3185983e-16 1.1755053e-21 1.4693352e-14 3.5740099e-17
 1.0000000e+00 1.3930119e-12 4.3868815e-15], sum to 1.0000
[2019-04-07 14:10:07,606] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6690
[2019-04-07 14:10:07,677] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 65.0, 0.0, 0.0, 24.0, 23.48849262551323, 0.029562276525457, 0.0, 1.0, 58922.4575723258], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2667600.0000, 
sim time next is 2669400.0000, 
raw observation next is [-2.15, 67.0, 0.0, 0.0, 24.0, 23.69098678064523, 0.01778520685772056, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4030470914127424, 0.67, 0.0, 0.0, 0.5, 0.47424889838710244, 0.5059284022859069, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.79490507], dtype=float32), 0.3578473]. 
=============================================
[2019-04-07 14:10:08,081] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9448573e-21 1.7565112e-19 7.7569585e-25 1.0621529e-17 3.6377591e-20
 1.0000000e+00 4.4870138e-13 9.1517953e-17], sum to 1.0000
[2019-04-07 14:10:08,081] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1609
[2019-04-07 14:10:08,095] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 100.0, 0.0, 0.0, 24.0, 24.80909657848476, 0.3763438621271839, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3178800.0000, 
sim time next is 3180600.0000, 
raw observation next is [3.5, 100.0, 0.0, 0.0, 24.0, 24.53581111110731, 0.3125010661239083, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.5595567867036012, 1.0, 0.0, 0.0, 0.5, 0.5446509259256093, 0.6041670220413028, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9801795], dtype=float32), -1.9761176]. 
=============================================
[2019-04-07 14:10:10,993] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:10:10,993] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:10:10,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run19
[2019-04-07 14:10:11,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:10:11,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:10:11,708] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run19
[2019-04-07 14:10:15,283] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:10:15,283] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:10:15,288] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run19
[2019-04-07 14:10:22,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0376285e-18 3.7362013e-15 4.6827300e-21 5.1000972e-14 6.0118620e-17
 1.0000000e+00 5.2792983e-12 2.4024676e-13], sum to 1.0000
[2019-04-07 14:10:22,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3159
[2019-04-07 14:10:22,235] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 65.0, 139.0, 0.0, 24.0, 23.72032921916288, -0.09886490835403106, 1.0, 1.0, 7425.66659559921], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 219600.0000, 
sim time next is 221400.0000, 
raw observation next is [-3.95, 63.5, 149.0, 0.0, 24.0, 23.86359756594529, -0.08193775969088936, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3531855955678671, 0.635, 0.49666666666666665, 0.0, 0.5, 0.48863313049544094, 0.47268741343637016, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.27601844], dtype=float32), 2.9882932]. 
=============================================
[2019-04-07 14:10:22,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:10:22,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:10:22,900] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run19
[2019-04-07 14:10:35,821] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2906382e-18 2.8460614e-16 4.0631817e-22 2.4371541e-15 7.7149971e-17
 1.0000000e+00 1.2283549e-10 7.4732760e-15], sum to 1.0000
[2019-04-07 14:10:35,822] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6130
[2019-04-07 14:10:35,871] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.5, 60.0, 115.0, 818.0, 24.0, 24.85407390020132, 0.2664030356837588, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3763800.0000, 
sim time next is 3765600.0000, 
raw observation next is [0.0, 60.0, 110.5, 797.0, 24.0, 25.20445518035318, 0.3135020486411011, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.46260387811634357, 0.6, 0.36833333333333335, 0.8806629834254144, 0.5, 0.6003712650294316, 0.6045006828803671, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.91072744], dtype=float32), -0.5597738]. 
=============================================
[2019-04-07 14:10:49,382] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5331753e-16 1.9960719e-15 3.8376250e-20 3.8967625e-14 2.8290562e-16
 1.0000000e+00 1.9637518e-10 4.9436670e-13], sum to 1.0000
[2019-04-07 14:10:49,383] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8279
[2019-04-07 14:10:49,456] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 65.0, 0.0, 0.0, 24.0, 23.37024094116181, -0.05557187327100645, 0.0, 1.0, 44183.161973005954], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3560400.0000, 
sim time next is 3562200.0000, 
raw observation next is [-5.5, 67.5, 0.0, 0.0, 24.0, 23.27089569942666, -0.05824196619048146, 0.0, 1.0, 51322.71380559388], 
processed observation next is [0.0, 0.21739130434782608, 0.3102493074792244, 0.675, 0.0, 0.0, 0.5, 0.439241308285555, 0.4805860112698395, 0.0, 1.0, 0.24439387526473275], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8677679], dtype=float32), -0.4199323]. 
=============================================
[2019-04-07 14:11:03,810] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:11:03,810] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:11:03,827] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run19
[2019-04-07 14:11:03,966] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:11:03,966] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:11:03,970] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run19
[2019-04-07 14:11:25,343] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0197484e-19 1.1194466e-16 3.5591031e-22 3.3886523e-15 6.4501063e-17
 1.0000000e+00 7.8226817e-12 9.0771263e-14], sum to 1.0000
[2019-04-07 14:11:25,343] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7433
[2019-04-07 14:11:25,391] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.8, 93.0, 100.0, 0.0, 24.0, 23.89539790976526, -0.06645917285412732, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 910800.0000, 
sim time next is 912600.0000, 
raw observation next is [3.8, 93.0, 96.0, 0.0, 24.0, 23.39837603957764, -0.1263566565093768, 1.0, 1.0, 6226.803890076843], 
processed observation next is [1.0, 0.5652173913043478, 0.5678670360110805, 0.93, 0.32, 0.0, 0.5, 0.44986466996480345, 0.4578811144968744, 1.0, 1.0, 0.029651447095604015], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2013411], dtype=float32), 0.9047423]. 
=============================================
[2019-04-07 14:11:34,228] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:11:34,228] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:11:34,237] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run19
[2019-04-07 14:11:35,824] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7163266e-18 1.4667092e-17 1.5331765e-22 3.4724259e-16 3.3117406e-18
 1.0000000e+00 4.0740978e-12 4.9410391e-16], sum to 1.0000
[2019-04-07 14:11:35,824] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7055
[2019-04-07 14:11:35,868] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 59.0, 221.0, 18.0, 24.0, 24.53948797679122, 0.1434231064112514, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4530600.0000, 
sim time next is 4532400.0000, 
raw observation next is [2.0, 57.0, 169.5, 9.0, 24.0, 24.60332768458386, 0.1472280146579789, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.518005540166205, 0.57, 0.565, 0.009944751381215469, 0.5, 0.550277307048655, 0.549076004885993, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6004252], dtype=float32), -1.4598215]. 
=============================================
[2019-04-07 14:11:39,207] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.5204014e-21 7.8215876e-17 5.6730863e-22 7.2634875e-16 2.4051745e-19
 1.0000000e+00 4.5733682e-12 5.6436619e-16], sum to 1.0000
[2019-04-07 14:11:39,207] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2437
[2019-04-07 14:11:39,234] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 108.0, 0.0, 24.0, 24.48415609363064, 0.08925706047674287, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4710600.0000, 
sim time next is 4712400.0000, 
raw observation next is [1.0, 86.0, 121.5, 0.0, 24.0, 24.10357313415678, 0.02889693002651241, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.4903047091412743, 0.86, 0.405, 0.0, 0.5, 0.5086310945130649, 0.5096323100088375, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.39196682], dtype=float32), -1.3986241]. 
=============================================
[2019-04-07 14:11:44,010] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-07 14:11:44,044] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:11:44,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:11:44,047] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run42
[2019-04-07 14:11:44,065] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:11:44,066] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:11:44,071] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run42
[2019-04-07 14:11:44,072] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 14:11:44,103] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:11:44,109] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run42
[2019-04-07 14:11:51,853] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12334453], dtype=float32), 0.14602388]
[2019-04-07 14:11:51,853] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [7.8, 93.0, 131.5, 28.5, 24.0, 23.57262710164431, -0.06690436652074258, 1.0, 1.0, 0.0]
[2019-04-07 14:11:51,853] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 14:11:51,854] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [2.3130250e-19 8.8317333e-17 2.4318519e-22 3.6097342e-15 1.7404651e-17
 1.0000000e+00 7.8927923e-12 1.5515275e-14], sampled 0.9648191855804887
[2019-04-07 14:13:28,466] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12334453], dtype=float32), 0.14602388]
[2019-04-07 14:13:28,466] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [11.1, 93.0, 36.5, 25.0, 24.0, 23.69826582752518, 0.02456783611242433, 0.0, 1.0, 20295.867838143648]
[2019-04-07 14:13:28,466] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 14:13:28,467] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [9.2739768e-20 4.0650216e-17 1.1123046e-22 1.7273442e-15 1.1782103e-17
 1.0000000e+00 6.2787995e-12 9.1263548e-15], sampled 0.4145165957070801
[2019-04-07 14:13:40,761] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.12334453], dtype=float32), 0.14602388]
[2019-04-07 14:13:40,761] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [0.879747248, 50.0070141, 86.48930103, 673.3572466, 24.0, 23.32128971961641, -0.06646231773743012, 0.0, 1.0, 0.0]
[2019-04-07 14:13:40,761] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 14:13:40,763] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.3470526e-16 3.8379883e-14 1.2884197e-18 1.0900974e-12 1.0419405e-14
 1.0000000e+00 6.4883310e-10 2.5804831e-12], sampled 0.3817791949700008
[2019-04-07 14:13:54,157] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:14:29,096] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 14:14:35,522] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:14:36,546] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 820000, evaluation results [820000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:14:41,030] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7382871e-19 2.6698244e-17 1.3982427e-23 1.0686322e-15 1.8864044e-18
 1.0000000e+00 8.9045351e-13 1.7815915e-15], sum to 1.0000
[2019-04-07 14:14:41,169] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7485
[2019-04-07 14:14:41,232] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.7, 60.5, 0.0, 0.0, 24.0, 25.02133733929897, 0.3473985316511617, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1535400.0000, 
sim time next is 1537200.0000, 
raw observation next is [9.4, 61.0, 0.0, 0.0, 24.0, 24.79736102839816, 0.3173692228286731, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.7229916897506927, 0.61, 0.0, 0.0, 0.5, 0.5664467523665134, 0.6057897409428911, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7312008], dtype=float32), -0.06705535]. 
=============================================
[2019-04-07 14:14:43,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:14:43,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:14:43,384] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run19
[2019-04-07 14:14:50,401] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:14:50,401] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:14:50,408] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run19
[2019-04-07 14:14:50,823] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:14:50,823] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:14:50,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run19
[2019-04-07 14:14:51,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:14:51,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:14:51,468] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run19
[2019-04-07 14:14:53,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:14:53,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:14:53,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run19
[2019-04-07 14:14:54,393] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:14:54,393] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:14:54,397] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run19
[2019-04-07 14:14:57,262] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:14:57,262] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:14:57,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run19
[2019-04-07 14:15:16,258] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7537412e-17 4.4304707e-16 1.1665278e-19 3.7471636e-15 2.9149212e-16
 1.0000000e+00 3.1075672e-12 1.0803086e-13], sum to 1.0000
[2019-04-07 14:15:16,258] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0478
[2019-04-07 14:15:16,269] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [16.1, 53.0, 0.0, 0.0, 24.0, 25.05957370379096, 0.4313136101957747, 1.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1101600.0000, 
sim time next is 1103400.0000, 
raw observation next is [15.55, 55.0, 0.0, 0.0, 24.0, 25.11064530966774, 0.4187907258446054, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.8933518005540168, 0.55, 0.0, 0.0, 0.5, 0.5925537758056448, 0.6395969086148684, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.38212895], dtype=float32), 0.17812955]. 
=============================================
[2019-04-07 14:15:16,445] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7828190e-18 1.5230906e-16 4.4129530e-20 7.8815281e-15 1.7033291e-16
 1.0000000e+00 1.7174846e-12 3.9615263e-14], sum to 1.0000
[2019-04-07 14:15:16,445] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4153
[2019-04-07 14:15:16,555] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.3, 68.0, 125.0, 0.0, 24.0, 24.18435337837495, 0.01014853597624707, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2125800.0000, 
sim time next is 2127600.0000, 
raw observation next is [-5.0, 68.0, 105.5, 0.0, 24.0, 24.1471951436504, -0.08957231435626657, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.32409972299168976, 0.68, 0.3516666666666667, 0.0, 0.5, 0.5122662619708667, 0.4701425618812445, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2107292], dtype=float32), 1.1794229]. 
=============================================
[2019-04-07 14:15:20,753] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.1214351e-18 3.5655418e-16 3.9365655e-21 8.6529053e-13 2.2093035e-18
 1.0000000e+00 2.7742175e-11 2.8883261e-14], sum to 1.0000
[2019-04-07 14:15:20,753] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9452
[2019-04-07 14:15:20,958] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 24.0, 23.31228290284084, -0.1674809161023795, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 241200.0000, 
sim time next is 243000.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 24.0, 23.0016408419403, -0.2328284263486727, 1.0, 1.0, 58982.0398880473], 
processed observation next is [1.0, 0.8260869565217391, 0.368421052631579, 0.65, 0.0, 0.0, 0.5, 0.41680340349502504, 0.42239052455044246, 1.0, 1.0, 0.280866856609749], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.406971], dtype=float32), 0.97572356]. 
=============================================
[2019-04-07 14:15:20,970] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[101.95951 ]
 [102.20623 ]
 [102.526726]
 [100.95358 ]
 [100.77843 ]], R is [[101.88882446]
 [101.86993408]
 [101.85123444]
 [101.41397095]
 [101.39983368]].
[2019-04-07 14:15:45,483] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.6077576e-18 1.8648328e-14 6.7964170e-18 5.2343295e-12 4.8870176e-15
 1.0000000e+00 1.1874056e-10 4.8250320e-13], sum to 1.0000
[2019-04-07 14:15:45,483] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7249
[2019-04-07 14:15:45,604] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.75, 59.5, 182.0, 93.0, 24.0, 23.04429615403912, -0.1806663228822614, 0.0, 1.0, 24658.044012999744], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 653400.0000, 
sim time next is 655200.0000, 
raw observation next is [-1.2, 60.0, 131.5, 74.5, 24.0, 23.04516933755869, -0.1928349710296634, 0.0, 1.0, 22076.14599531762], 
processed observation next is [0.0, 0.6086956521739131, 0.42936288088642666, 0.6, 0.43833333333333335, 0.08232044198895028, 0.5, 0.4204307781298908, 0.43572167632344555, 0.0, 1.0, 0.10512450473960772], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0636445], dtype=float32), -0.15331775]. 
=============================================
[2019-04-07 14:15:49,674] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.9859521e-18 2.2996643e-16 1.4617797e-21 6.5339695e-14 7.0573292e-16
 1.0000000e+00 1.0065706e-09 6.0476992e-13], sum to 1.0000
[2019-04-07 14:15:49,674] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8236
[2019-04-07 14:15:49,802] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.55, 87.0, 0.0, 0.0, 24.0, 23.08873152192992, -0.1577588831951436, 0.0, 1.0, 31708.787528857098], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 585000.0000, 
sim time next is 586800.0000, 
raw observation next is [-2.8, 87.0, 0.0, 0.0, 24.0, 23.0447426051274, -0.1610066030139835, 0.0, 1.0, 50241.77019099947], 
processed observation next is [0.0, 0.8260869565217391, 0.38504155124653744, 0.87, 0.0, 0.0, 0.5, 0.42039521709395, 0.4463311323286721, 0.0, 1.0, 0.23924652471904512], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5228023], dtype=float32), 0.3608624]. 
=============================================
[2019-04-07 14:16:11,094] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4886126e-20 3.1460995e-16 2.0920713e-24 1.4351084e-15 4.1772120e-18
 1.0000000e+00 2.0391939e-12 6.1918303e-15], sum to 1.0000
[2019-04-07 14:16:11,094] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2396
[2019-04-07 14:16:11,169] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.3, 92.0, 15.5, 0.0, 24.0, 23.5822770539408, 0.04593023534347307, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1670400.0000, 
sim time next is 1672200.0000, 
raw observation next is [2.75, 92.0, 30.0, 0.0, 24.0, 23.58506757700777, 0.0466356990816589, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.5387811634349031, 0.92, 0.1, 0.0, 0.5, 0.46542229808398083, 0.5155452330272197, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.20015047], dtype=float32), 0.6522424]. 
=============================================
[2019-04-07 14:16:23,464] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.3857236e-20 2.6417414e-17 7.0832199e-24 1.0262362e-15 3.0473824e-18
 1.0000000e+00 1.4482600e-12 1.3527754e-15], sum to 1.0000
[2019-04-07 14:16:23,465] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9035
[2019-04-07 14:16:23,486] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 18.0, 0.0, 24.0, 23.77078424678018, 0.0121391584805664, 1.0, 1.0, 15253.690195705329], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1441800.0000, 
sim time next is 1443600.0000, 
raw observation next is [1.1, 92.0, 9.0, 0.0, 24.0, 23.85484735425268, 0.02521277347129117, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.49307479224376743, 0.92, 0.03, 0.0, 0.5, 0.4879039461877233, 0.5084042578237637, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1863165], dtype=float32), 0.23173037]. 
=============================================
[2019-04-07 14:16:31,301] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0323333e-19 1.1807396e-16 1.8324258e-22 6.9873860e-16 1.4212472e-17
 1.0000000e+00 1.0800522e-11 3.4746272e-15], sum to 1.0000
[2019-04-07 14:16:31,301] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1536
[2019-04-07 14:16:31,435] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 100.0, 0.0, 0.0, 24.0, 23.70154594091535, 0.04484694137394422, 0.0, 1.0, 45116.674590747396], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1495800.0000, 
sim time next is 1497600.0000, 
raw observation next is [1.1, 100.0, 9.0, 0.0, 24.0, 23.74503531698785, 0.02854831292714612, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.49307479224376743, 1.0, 0.03, 0.0, 0.5, 0.47875294308232075, 0.5095161043090487, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0726829], dtype=float32), -2.0306845]. 
=============================================
[2019-04-07 14:16:47,978] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-07 14:16:47,999] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:16:47,999] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:16:48,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run43
[2019-04-07 14:16:48,019] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:16:48,037] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:16:48,040] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run43
[2019-04-07 14:16:48,063] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 14:16:48,064] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:16:48,066] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run43
[2019-04-07 14:18:57,438] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:19:26,702] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 14:19:30,717] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:19:31,739] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 840000, evaluation results [840000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:19:43,896] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.6964593e-19 3.7395770e-17 3.0318270e-22 2.2070421e-14 3.6611370e-18
 1.0000000e+00 1.0218163e-11 1.1207173e-13], sum to 1.0000
[2019-04-07 14:19:43,897] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6380
[2019-04-07 14:19:43,959] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 88.5, 0.0, 0.0, 24.0, 23.15880714291628, -0.1376264302384556, 0.0, 1.0, 44000.38871572329], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2079000.0000, 
sim time next is 2080800.0000, 
raw observation next is [-4.5, 86.0, 0.0, 0.0, 24.0, 23.13533139492483, -0.1455271141028645, 0.0, 1.0, 43950.79951711506], 
processed observation next is [1.0, 0.08695652173913043, 0.3379501385041552, 0.86, 0.0, 0.0, 0.5, 0.4279442829104025, 0.45149096196571187, 0.0, 1.0, 0.2092895215100717], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0933558], dtype=float32), -1.079033]. 
=============================================
[2019-04-07 14:19:53,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:19:53,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:19:53,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run20
[2019-04-07 14:20:11,852] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9257831e-16 9.9808975e-14 1.7561111e-17 1.5224024e-12 6.0088187e-15
 1.0000000e+00 2.2179257e-10 5.6512564e-12], sum to 1.0000
[2019-04-07 14:20:11,852] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9336
[2019-04-07 14:20:11,912] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 41.0, 0.0, 0.0, 24.0, 23.26194561829645, -0.1699740195126907, 0.0, 1.0, 44640.93519792185], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2415600.0000, 
sim time next is 2417400.0000, 
raw observation next is [-5.3, 42.0, 0.0, 0.0, 24.0, 23.21350564629386, -0.1760111670386725, 0.0, 1.0, 44435.97132149894], 
processed observation next is [0.0, 1.0, 0.31578947368421056, 0.42, 0.0, 0.0, 0.5, 0.4344588038578217, 0.44132961098710916, 0.0, 1.0, 0.21159986343570925], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05640142], dtype=float32), 0.8740628]. 
=============================================
[2019-04-07 14:20:14,129] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2295381e-18 3.5226597e-15 4.6601340e-21 7.5197349e-14 1.5185713e-16
 1.0000000e+00 7.1284162e-10 1.6568057e-13], sum to 1.0000
[2019-04-07 14:20:14,129] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8903
[2019-04-07 14:20:14,210] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 24.0, 23.34378729541791, -0.05395433612356854, 0.0, 1.0, 44541.37667836037], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2944800.0000, 
sim time next is 2946600.0000, 
raw observation next is [-2.5, 84.5, 0.0, 0.0, 24.0, 23.29522305698011, -0.06582021486905182, 0.0, 1.0, 44212.51145692316], 
processed observation next is [0.0, 0.08695652173913043, 0.39335180055401664, 0.845, 0.0, 0.0, 0.5, 0.4412685880816758, 0.4780599283769827, 0.0, 1.0, 0.21053576884249123], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0622855], dtype=float32), -0.1588377]. 
=============================================
[2019-04-07 14:20:19,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:20:19,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:20:19,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run20
[2019-04-07 14:20:23,595] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.1641358e-19 9.5006921e-17 3.7233140e-21 1.2242451e-14 2.0967697e-16
 1.0000000e+00 1.0589399e-11 1.6290664e-14], sum to 1.0000
[2019-04-07 14:20:23,596] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0947
[2019-04-07 14:20:23,811] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 61.5, 113.0, 799.0, 24.0, 24.33389516667464, -8.807402004478344e-05, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2723400.0000, 
sim time next is 2725200.0000, 
raw observation next is [-6.0, 59.0, 111.0, 793.5, 24.0, 23.62489910904625, 0.06570767437130122, 1.0, 1.0, 100136.10214338783], 
processed observation next is [1.0, 0.5652173913043478, 0.296398891966759, 0.59, 0.37, 0.8767955801104972, 0.5, 0.4687415924205209, 0.5219025581237671, 1.0, 1.0, 0.47683858163518017], 
reward next is 0.8089, 
noisyNet noise sample is [array([0.7382767], dtype=float32), -0.4447474]. 
=============================================
[2019-04-07 14:20:26,796] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:20:26,798] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:20:26,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run20
[2019-04-07 14:20:32,951] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:20:32,951] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:20:32,955] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run20
[2019-04-07 14:20:37,341] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:20:37,341] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:20:37,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run20
[2019-04-07 14:20:41,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:20:41,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:20:41,009] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run20
[2019-04-07 14:20:50,551] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2538724e-18 7.6351312e-16 2.1868549e-20 5.2425170e-14 1.8755366e-15
 1.0000000e+00 1.9088378e-10 2.5088433e-13], sum to 1.0000
[2019-04-07 14:20:50,551] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5513
[2019-04-07 14:20:50,620] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 24.0, 21.15439888979542, -0.5988358517197008, 0.0, 1.0, 40521.57259797563], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 19800.0000, 
sim time next is 21600.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 24.0, 21.19154630656796, -0.5838038839159895, 0.0, 1.0, 40385.629733236674], 
processed observation next is [0.0, 0.2608695652173913, 0.6759002770083103, 0.93, 0.0, 0.0, 0.5, 0.26596219221399675, 0.30539870536133684, 0.0, 1.0, 0.19231252253922226], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6262368], dtype=float32), -2.5183904]. 
=============================================
[2019-04-07 14:21:07,712] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3382334e-17 6.9470712e-15 8.3572044e-21 2.0133184e-13 1.1640364e-15
 1.0000000e+00 8.9219404e-10 4.1684359e-13], sum to 1.0000
[2019-04-07 14:21:07,713] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7995
[2019-04-07 14:21:07,755] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.1, 92.5, 0.0, 0.0, 24.0, 22.81363608894983, -0.1816362151632738, 0.0, 1.0, 42625.39113358647], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4775400.0000, 
sim time next is 4777200.0000, 
raw observation next is [-6.2, 93.0, 0.0, 0.0, 24.0, 22.72893032850049, -0.1995005228263301, 0.0, 1.0, 42745.656292017025], 
processed observation next is [0.0, 0.30434782608695654, 0.2908587257617729, 0.93, 0.0, 0.0, 0.5, 0.39407752737504076, 0.43349982572455664, 0.0, 1.0, 0.20355074424770012], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.40839833], dtype=float32), 0.19367322]. 
=============================================
[2019-04-07 14:21:14,033] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.84050780e-17 8.53008256e-14 1.05788174e-19 5.70115244e-13
 3.34701490e-15 1.00000000e+00 3.50457413e-10 1.47171229e-12], sum to 1.0000
[2019-04-07 14:21:14,033] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8447
[2019-04-07 14:21:14,260] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.2, 75.0, 19.0, 0.0, 24.0, 22.72604154463039, -0.1911913060819272, 0.0, 1.0, 107481.78804773987], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 635400.0000, 
sim time next is 637200.0000, 
raw observation next is [-3.9, 71.0, 77.0, 25.5, 24.0, 23.47593143650576, -0.143900662881218, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3545706371191136, 0.71, 0.25666666666666665, 0.0281767955801105, 0.5, 0.45632761970881336, 0.4520331123729273, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.11479285], dtype=float32), -0.26418644]. 
=============================================
[2019-04-07 14:21:19,068] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1884560e-19 9.7694580e-18 1.8926995e-23 2.8219303e-17 2.8187136e-17
 1.0000000e+00 1.0243214e-12 8.9558752e-16], sum to 1.0000
[2019-04-07 14:21:19,069] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2605
[2019-04-07 14:21:19,123] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 72.0, 0.0, 0.0, 24.0, 23.76922733751539, 0.03011184072505957, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3537000.0000, 
sim time next is 3538800.0000, 
raw observation next is [-1.0, 66.0, 0.0, 0.0, 24.0, 23.31460672896235, 0.06390055814658181, 0.0, 1.0, 172826.70171012584], 
processed observation next is [1.0, 1.0, 0.4349030470914128, 0.66, 0.0, 0.0, 0.5, 0.4428838940801958, 0.5213001860488606, 0.0, 1.0, 0.8229842938577421], 
reward next is 0.4627, 
noisyNet noise sample is [array([1.2445418], dtype=float32), 1.5148423]. 
=============================================
[2019-04-07 14:21:19,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:21:19,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:21:19,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run20
[2019-04-07 14:21:20,477] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.1817530e-19 4.7490821e-18 5.1437325e-23 6.2164648e-16 7.3113181e-19
 1.0000000e+00 4.8109281e-12 1.7542514e-15], sum to 1.0000
[2019-04-07 14:21:20,477] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7950
[2019-04-07 14:21:20,525] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.1, 94.5, 0.0, 0.0, 24.0, 23.60881308049898, 0.1613592480693193, 0.0, 1.0, 31494.300110609285], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1297800.0000, 
sim time next is 1299600.0000, 
raw observation next is [3.8, 93.0, 0.0, 0.0, 24.0, 23.67604137875026, 0.1634103141778661, 0.0, 1.0, 12488.054353719315], 
processed observation next is [1.0, 0.043478260869565216, 0.5678670360110805, 0.93, 0.0, 0.0, 0.5, 0.4730034482291883, 0.5544701047259554, 0.0, 1.0, 0.0594669254939015], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.57440996], dtype=float32), 1.2445613]. 
=============================================
[2019-04-07 14:21:21,674] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.5687200e-20 6.1090014e-18 2.7254349e-23 3.7376413e-15 1.3798642e-19
 1.0000000e+00 2.3488980e-12 1.3576356e-14], sum to 1.0000
[2019-04-07 14:21:21,674] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6661
[2019-04-07 14:21:21,765] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.199999999999999, 64.0, 0.0, 0.0, 24.0, 23.64051993811492, 0.1307405756267808, 0.0, 1.0, 130811.93961286407], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4408200.0000, 
sim time next is 4410000.0000, 
raw observation next is [6.8, 65.0, 0.0, 0.0, 24.0, 23.95166324078985, 0.200763237254089, 0.0, 1.0, 49153.9185949031], 
processed observation next is [1.0, 0.043478260869565216, 0.6509695290858727, 0.65, 0.0, 0.0, 0.5, 0.49597193673248735, 0.5669210790846964, 0.0, 1.0, 0.2340662790233481], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5599034], dtype=float32), -1.417442]. 
=============================================
[2019-04-07 14:21:21,769] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[111.24675 ]
 [110.37505 ]
 [112.71019 ]
 [113.70867 ]
 [114.155594]], R is [[110.90190887]
 [110.45569611]
 [110.35114288]
 [110.24763489]
 [110.14515686]].
[2019-04-07 14:21:21,927] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.45226070e-16 1.18132644e-14 3.62102061e-20 5.85267986e-14
 3.44836345e-15 1.00000000e+00 2.00362185e-10 3.79106096e-14], sum to 1.0000
[2019-04-07 14:21:21,929] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8433
[2019-04-07 14:21:22,049] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 54.5, 114.0, 816.0, 24.0, 23.33582879717972, 0.01393577915710843, 0.0, 1.0, 18706.862632847275], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3583800.0000, 
sim time next is 3585600.0000, 
raw observation next is [-3.0, 55.0, 116.0, 819.5, 24.0, 23.39603666220753, 0.02749921385375594, 0.0, 1.0, 18704.633052294335], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.55, 0.38666666666666666, 0.905524861878453, 0.5, 0.44966972185062737, 0.5091664046179186, 0.0, 1.0, 0.0890696812014016], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3967658], dtype=float32), -1.6295527]. 
=============================================
[2019-04-07 14:21:22,686] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:21:22,687] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:21:22,690] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run20
[2019-04-07 14:21:29,908] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1826567e-18 2.6253474e-16 3.7460744e-24 5.6738206e-15 1.5670738e-17
 1.0000000e+00 4.1212966e-12 2.9760011e-14], sum to 1.0000
[2019-04-07 14:21:29,915] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1662
[2019-04-07 14:21:30,059] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 100.0, 0.0, 0.0, 24.0, 23.70154594091535, 0.04484694137394422, 0.0, 1.0, 45116.674590747396], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1495800.0000, 
sim time next is 1497600.0000, 
raw observation next is [1.1, 100.0, 9.0, 0.0, 24.0, 23.74503531698785, 0.02854831292714612, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.49307479224376743, 1.0, 0.03, 0.0, 0.5, 0.47875294308232075, 0.5095161043090487, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.1470618], dtype=float32), 0.14037423]. 
=============================================
[2019-04-07 14:21:37,479] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-07 14:21:37,481] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:21:37,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:21:37,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run44
[2019-04-07 14:21:37,505] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:21:37,505] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:21:37,508] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run44
[2019-04-07 14:21:37,526] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 14:21:37,528] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:21:37,531] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run44
[2019-04-07 14:23:40,908] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.1234163], dtype=float32), 0.14708255]
[2019-04-07 14:23:40,909] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-3.0, 50.0, 96.5, 713.0, 24.0, 24.37911479505959, 0.1815765533172724, 1.0, 1.0, 0.0]
[2019-04-07 14:23:40,909] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 14:23:40,910] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.9573675e-17 1.0068483e-14 1.7838796e-19 2.8427239e-13 2.0907884e-15
 1.0000000e+00 1.7937207e-10 6.5570569e-13], sampled 0.33848200164247955
[2019-04-07 14:23:53,121] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:24:22,850] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 14:24:27,579] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:24:28,607] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 860000, evaluation results [860000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:24:34,770] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6992353e-17 4.6213234e-16 5.0724210e-21 1.1818409e-13 1.4537480e-16
 1.0000000e+00 1.6471404e-11 9.7900388e-13], sum to 1.0000
[2019-04-07 14:24:34,770] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2293
[2019-04-07 14:24:34,885] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 72.0, 101.0, 49.0, 24.0, 23.7847689705755, -0.1331860196682433, 1.0, 1.0, 12465.98499671688], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 725400.0000, 
sim time next is 727200.0000, 
raw observation next is [-1.7, 68.0, 120.0, 58.5, 24.0, 23.90650939564675, -0.1222357789607966, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4155124653739613, 0.68, 0.4, 0.06464088397790055, 0.5, 0.4922091163038959, 0.4592547403464011, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4442125], dtype=float32), 0.53005964]. 
=============================================
[2019-04-07 14:24:38,934] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.1339635e-18 9.2981941e-15 9.6282561e-22 1.6142915e-13 5.1517993e-17
 1.0000000e+00 2.3179986e-11 2.0621905e-14], sum to 1.0000
[2019-04-07 14:24:38,934] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2529
[2019-04-07 14:24:38,989] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.55, 79.5, 0.0, 0.0, 24.0, 23.23509112385157, -0.1384699156113303, 0.0, 1.0, 42172.312671365595], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 862200.0000, 
sim time next is 864000.0000, 
raw observation next is [-2.3, 80.0, 0.0, 0.0, 24.0, 23.24330324102819, -0.1365155420337791, 0.0, 1.0, 41652.34643418782], 
processed observation next is [1.0, 0.0, 0.3988919667590028, 0.8, 0.0, 0.0, 0.5, 0.4369419367523492, 0.45449481932207364, 0.0, 1.0, 0.1983445068294658], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.01058662], dtype=float32), 0.15834798]. 
=============================================
[2019-04-07 14:24:38,998] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[104.209694]
 [104.4693  ]
 [104.334564]
 [104.61899 ]
 [104.346214]], R is [[102.6796875 ]
 [102.65289307]
 [102.62636566]
 [102.60010529]
 [102.57410431]].
[2019-04-07 14:24:44,376] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:24:44,376] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:24:44,380] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run20
[2019-04-07 14:24:47,262] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.2015750e-20 7.5098446e-18 1.4374366e-23 1.0203375e-16 4.2260830e-17
 1.0000000e+00 4.7203224e-13 3.9596660e-15], sum to 1.0000
[2019-04-07 14:24:47,262] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3909
[2019-04-07 14:24:47,365] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 73.0, 165.5, 3.0, 24.0, 23.52184897871008, 0.03316491400379574, 1.0, 1.0, 73945.92767145095], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4716000.0000, 
sim time next is 4717800.0000, 
raw observation next is [1.5, 72.5, 196.0, 6.0, 24.0, 24.24506538152679, 0.09802529492880645, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5041551246537397, 0.725, 0.6533333333333333, 0.0066298342541436465, 0.5, 0.5204221151272325, 0.5326750983096021, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.49780142], dtype=float32), 0.26347175]. 
=============================================
[2019-04-07 14:24:54,105] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3545504e-17 1.2267683e-16 5.2543180e-22 4.0650721e-15 3.6343246e-17
 1.0000000e+00 4.3175932e-11 1.7623649e-14], sum to 1.0000
[2019-04-07 14:24:54,140] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5447
[2019-04-07 14:24:54,217] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.2, 65.0, 0.0, 0.0, 24.0, 23.57257301308768, -0.002907918362704371, 0.0, 1.0, 26132.26609658479], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4586400.0000, 
sim time next is 4588200.0000, 
raw observation next is [-0.65, 66.0, 0.0, 0.0, 24.0, 23.61689545370401, -0.006811561930194767, 0.0, 1.0, 20626.457717754955], 
processed observation next is [1.0, 0.08695652173913043, 0.4445983379501386, 0.66, 0.0, 0.0, 0.5, 0.4680746211420009, 0.4977294793566018, 0.0, 1.0, 0.09822122722740455], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5996869], dtype=float32), -1.036788]. 
=============================================
[2019-04-07 14:25:00,608] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8940413e-20 4.0838416e-18 3.8138749e-23 3.6197297e-16 3.1307241e-18
 1.0000000e+00 2.6988906e-13 1.5773010e-15], sum to 1.0000
[2019-04-07 14:25:00,608] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7360
[2019-04-07 14:25:00,632] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 120.0, 0.0, 24.0, 24.39733510228491, 0.1775684207343826, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1339200.0000, 
sim time next is 1341000.0000, 
raw observation next is [1.1, 92.0, 113.0, 0.0, 24.0, 24.2911945065968, 0.1476115641348721, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.49307479224376743, 0.92, 0.37666666666666665, 0.0, 0.5, 0.5242662088830666, 0.549203854711624, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3652961], dtype=float32), 0.8419972]. 
=============================================
[2019-04-07 14:25:00,637] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[111.81887 ]
 [111.615   ]
 [111.18231 ]
 [110.72745 ]
 [110.765854]], R is [[111.69959259]
 [111.58259583]
 [111.46677399]
 [111.35210419]
 [111.23858643]].
[2019-04-07 14:25:04,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:25:04,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:25:04,242] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run20
[2019-04-07 14:25:10,464] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:25:10,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:25:10,471] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run20
[2019-04-07 14:25:11,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:25:11,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:25:11,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run20
[2019-04-07 14:25:11,746] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0149069e-19 9.9161578e-17 8.9355830e-21 2.2599915e-15 6.3996214e-16
 1.0000000e+00 3.5786508e-12 2.3128851e-14], sum to 1.0000
[2019-04-07 14:25:11,746] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5646
[2019-04-07 14:25:11,883] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 55.0, 0.0, 0.0, 24.0, 23.55546788939997, -0.0292954205006536, 0.0, 1.0, 44578.14789713463], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5025600.0000, 
sim time next is 5027400.0000, 
raw observation next is [-1.0, 52.5, 0.0, 0.0, 24.0, 23.53736982102316, -0.02162967373333662, 0.0, 1.0, 50217.10726745932], 
processed observation next is [1.0, 0.17391304347826086, 0.4349030470914128, 0.525, 0.0, 0.0, 0.5, 0.46144748508526323, 0.49279010875555446, 0.0, 1.0, 0.23912908222599677], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.46608225], dtype=float32), 0.23549207]. 
=============================================
[2019-04-07 14:25:13,519] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:25:13,519] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:25:13,530] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run20
[2019-04-07 14:25:15,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:25:15,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:25:15,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run20
[2019-04-07 14:25:15,456] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:25:15,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:25:15,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run20
[2019-04-07 14:25:17,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:25:17,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:25:17,132] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run20
[2019-04-07 14:25:23,199] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4991231e-19 4.6710535e-17 3.5606632e-23 5.4990009e-16 8.5347685e-18
 1.0000000e+00 1.0456271e-11 3.2858499e-14], sum to 1.0000
[2019-04-07 14:25:23,200] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8099
[2019-04-07 14:25:23,232] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.15, 81.0, 0.0, 0.0, 24.0, 23.64693547121273, -0.006627228555247384, 0.0, 1.0, 6364.220790626364], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 959400.0000, 
sim time next is 961200.0000, 
raw observation next is [7.7, 80.0, 0.0, 0.0, 24.0, 23.50750071384315, -0.005550045009981209, 0.0, 1.0, 59436.42077483015], 
processed observation next is [1.0, 0.13043478260869565, 0.6759002770083103, 0.8, 0.0, 0.0, 0.5, 0.4589583928202625, 0.4981499849966729, 0.0, 1.0, 0.2830305751182388], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.21753553], dtype=float32), -0.15215558]. 
=============================================
[2019-04-07 14:25:50,825] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1433988e-17 8.9038251e-16 2.7950885e-20 9.9971445e-15 7.1332812e-15
 1.0000000e+00 3.3104387e-11 6.1010637e-13], sum to 1.0000
[2019-04-07 14:25:50,825] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9439
[2019-04-07 14:25:51,134] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.7, 57.0, 0.0, 0.0, 24.0, 23.64281690501608, -0.02543424648211488, 1.0, 1.0, 152228.9442270752], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 324000.0000, 
sim time next is 325800.0000, 
raw observation next is [-12.0, 60.0, 0.0, 0.0, 24.0, 23.90391967683573, -0.0727189760550133, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.13019390581717452, 0.6, 0.0, 0.0, 0.5, 0.49199330640297756, 0.47576034131499556, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.18979563], dtype=float32), 1.2525481]. 
=============================================
[2019-04-07 14:26:15,609] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9120730e-18 2.3955625e-17 1.8237515e-21 6.4220992e-15 9.1332111e-16
 1.0000000e+00 7.8033092e-12 9.7477195e-14], sum to 1.0000
[2019-04-07 14:26:15,609] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2921
[2019-04-07 14:26:15,670] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 54.0, 0.0, 0.0, 24.0, 23.51702747357687, -0.02354286793792716, 1.0, 1.0, 56309.64096241931], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2656800.0000, 
sim time next is 2658600.0000, 
raw observation next is [-0.8999999999999999, 57.0, 0.0, 0.0, 24.0, 23.5314804522821, -0.05553804792197009, 1.0, 1.0, 27731.692851198186], 
processed observation next is [1.0, 0.782608695652174, 0.43767313019390586, 0.57, 0.0, 0.0, 0.5, 0.46095670435684166, 0.4814873173593433, 1.0, 1.0, 0.13205568024380088], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5506012], dtype=float32), 0.032312006]. 
=============================================
[2019-04-07 14:26:32,130] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6581347e-19 7.1409547e-16 1.9462293e-22 3.3420246e-16 1.1719929e-17
 1.0000000e+00 4.7310035e-13 1.6306261e-15], sum to 1.0000
[2019-04-07 14:26:32,131] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8286
[2019-04-07 14:26:32,361] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 86.0, 14.5, 0.0, 24.0, 24.04260153313161, -0.1443330617661624, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 838800.0000, 
sim time next is 840600.0000, 
raw observation next is [-3.9, 84.0, 0.0, 0.0, 24.0, 23.40328474797681, -0.1525126222991655, 1.0, 1.0, 60274.31975778006], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.84, 0.0, 0.0, 0.5, 0.4502737289980674, 0.4491624592336115, 1.0, 1.0, 0.28702057027514316], 
reward next is 0.9987, 
noisyNet noise sample is [array([-1.9977607], dtype=float32), -0.2434837]. 
=============================================
[2019-04-07 14:26:40,525] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-07 14:26:40,536] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:26:40,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:26:40,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run45
[2019-04-07 14:26:40,555] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:26:40,557] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 14:26:40,558] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:26:40,560] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:26:40,563] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run45
[2019-04-07 14:26:40,579] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run45
[2019-04-07 14:26:56,975] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12343816], dtype=float32), 0.14763674]
[2019-04-07 14:26:56,976] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-13.1, 55.5, 58.0, 764.0, 24.0, 23.67129928572353, -0.1283401515963921, 1.0, 1.0, 66008.96782495447]
[2019-04-07 14:26:56,976] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 14:26:56,976] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [5.3730106e-16 5.8686867e-14 2.0235694e-18 1.6074315e-12 2.1720337e-14
 1.0000000e+00 7.7588230e-10 3.7629045e-12], sampled 0.2169658044373567
[2019-04-07 14:28:59,429] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:29:25,914] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 14:29:27,619] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:29:28,642] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 880000, evaluation results [880000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:29:33,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3878302e-19 1.4850113e-18 1.2241935e-22 1.6021347e-14 3.8609470e-18
 1.0000000e+00 1.5461799e-11 8.4716874e-16], sum to 1.0000
[2019-04-07 14:29:33,665] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7353
[2019-04-07 14:29:33,699] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 92.0, 85.0, 370.0, 24.0, 23.7036605758409, 0.1145249372574927, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3227400.0000, 
sim time next is 3229200.0000, 
raw observation next is [-3.0, 92.0, 93.0, 511.5, 24.0, 24.11398368115517, 0.1623646187025821, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.92, 0.31, 0.5651933701657459, 0.5, 0.5094986400962641, 0.5541215395675273, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.63652104], dtype=float32), -0.3774921]. 
=============================================
[2019-04-07 14:29:36,995] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.1457626e-20 3.5494432e-18 9.5997550e-23 1.2117223e-16 2.2131161e-18
 1.0000000e+00 7.4818164e-12 2.3080950e-14], sum to 1.0000
[2019-04-07 14:29:36,996] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2375
[2019-04-07 14:29:37,060] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 100.0, 0.0, 0.0, 24.0, 23.39026181034146, 0.07338177778775697, 0.0, 1.0, 78767.00004753216], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3213000.0000, 
sim time next is 3214800.0000, 
raw observation next is [-2.0, 100.0, 0.0, 0.0, 24.0, 23.5359295705372, 0.07010003836919497, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.40720221606648205, 1.0, 0.0, 0.0, 0.5, 0.4613274642114333, 0.5233666794563984, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.35633916], dtype=float32), -0.8524664]. 
=============================================
[2019-04-07 14:30:15,640] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:30:15,640] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:30:15,652] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run21
[2019-04-07 14:30:40,933] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:30:40,933] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:30:40,936] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run21
[2019-04-07 14:30:41,571] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2349039e-17 4.3808946e-15 1.6970678e-19 8.2039735e-14 9.6677757e-16
 1.0000000e+00 1.6732141e-10 4.1214970e-14], sum to 1.0000
[2019-04-07 14:30:41,572] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4400
[2019-04-07 14:30:41,612] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 40.0, 195.0, 677.5, 24.0, 23.33493421604161, 0.009665874084013973, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4798800.0000, 
sim time next is 4800600.0000, 
raw observation next is [2.5, 38.5, 220.0, 568.0, 24.0, 23.3384023864899, 0.007036477085218105, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.5318559556786704, 0.385, 0.7333333333333333, 0.6276243093922652, 0.5, 0.444866865540825, 0.5023454923617393, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6323944], dtype=float32), -0.30314198]. 
=============================================
[2019-04-07 14:30:45,510] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6426988e-18 2.5726263e-15 4.4389711e-20 4.2962937e-14 6.0827479e-18
 1.0000000e+00 6.0960069e-12 1.3348938e-13], sum to 1.0000
[2019-04-07 14:30:45,510] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6015
[2019-04-07 14:30:45,573] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.2, 46.0, 281.0, 390.0, 24.0, 23.25516686353371, -0.06645957202749687, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4883400.0000, 
sim time next is 4885200.0000, 
raw observation next is [1.4, 45.0, 276.5, 389.0, 24.0, 23.22131085389259, -0.07054688433167812, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.5013850415512465, 0.45, 0.9216666666666666, 0.4298342541436464, 0.5, 0.43510923782438243, 0.47648437188944065, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6235556], dtype=float32), 0.4889502]. 
=============================================
[2019-04-07 14:30:48,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:30:48,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:30:48,724] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run21
[2019-04-07 14:30:55,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:30:55,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:30:55,070] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run21
[2019-04-07 14:30:57,534] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9229777e-16 2.6368388e-13 2.2020507e-18 1.4304430e-12 4.4148523e-14
 1.0000000e+00 3.9581831e-09 1.5072605e-11], sum to 1.0000
[2019-04-07 14:30:57,535] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2310
[2019-04-07 14:30:57,614] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.6, 49.0, 0.0, 0.0, 24.0, 22.93014507477613, -0.2311007902265009, 0.0, 1.0, 46610.98707762116], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 424800.0000, 
sim time next is 426600.0000, 
raw observation next is [-11.15, 51.5, 0.0, 0.0, 24.0, 22.80894090881159, -0.2605709641243657, 0.0, 1.0, 46283.667618609266], 
processed observation next is [1.0, 0.9565217391304348, 0.15373961218836565, 0.515, 0.0, 0.0, 0.5, 0.4007450757342991, 0.4131430119585448, 0.0, 1.0, 0.2203984172314727], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.43671694], dtype=float32), -0.4368827]. 
=============================================
[2019-04-07 14:31:01,399] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:31:01,399] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:31:01,427] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run21
[2019-04-07 14:31:04,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:31:04,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:31:04,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run21
[2019-04-07 14:31:10,039] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5862304e-16 2.7587473e-14 9.3418346e-19 1.2721822e-12 9.5044720e-15
 1.0000000e+00 1.0344263e-09 1.3004505e-11], sum to 1.0000
[2019-04-07 14:31:10,041] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4577
[2019-04-07 14:31:10,130] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 24.0, 21.72307382125382, -0.4958342363510995, 0.0, 1.0, 45637.510661595305], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 196200.0000, 
sim time next is 198000.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 24.0, 21.69390951502522, -0.5078483011437408, 0.0, 1.0, 45644.18380063553], 
processed observation next is [1.0, 0.30434782608695654, 0.21606648199445982, 0.78, 0.0, 0.0, 0.5, 0.3078257929187682, 0.3307172329520864, 0.0, 1.0, 0.21735325619350254], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.34544402], dtype=float32), 0.14943728]. 
=============================================
[2019-04-07 14:31:10,134] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[94.25459 ]
 [94.600624]
 [94.77813 ]
 [94.95618 ]
 [95.07077 ]], R is [[94.11042786]
 [94.16932678]
 [94.22763062]
 [94.28535461]
 [94.34249878]].
[2019-04-07 14:31:12,089] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5479063e-22 3.1493624e-18 1.3126760e-23 1.5052303e-17 1.6712043e-18
 1.0000000e+00 2.9294099e-14 2.2511020e-16], sum to 1.0000
[2019-04-07 14:31:12,089] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7358
[2019-04-07 14:31:12,277] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 92.0, 0.0, 0.0, 24.0, 23.21378210617351, -0.0681842574357777, 1.0, 1.0, 20250.245134644952], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2919600.0000, 
sim time next is 2921400.0000, 
raw observation next is [-1.0, 85.0, 0.0, 0.0, 24.0, 23.08519872300671, -0.07501495488719763, 1.0, 1.0, 58031.080910722514], 
processed observation next is [1.0, 0.8260869565217391, 0.4349030470914128, 0.85, 0.0, 0.0, 0.5, 0.4237665602505591, 0.4749950150376008, 1.0, 1.0, 0.2763384805272501], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.75096875], dtype=float32), -0.15826899]. 
=============================================
[2019-04-07 14:31:13,796] A3C_AGENT_WORKER-Thread-3 INFO:Local step 57000, global step 897589: loss 0.0502
[2019-04-07 14:31:13,796] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 57000, global step 897589: learning rate 0.0000
[2019-04-07 14:31:20,416] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2192369e-18 1.8684374e-16 1.0634365e-20 3.0223071e-14 4.8380431e-17
 1.0000000e+00 2.4456154e-11 7.7511121e-15], sum to 1.0000
[2019-04-07 14:31:20,418] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7658
[2019-04-07 14:31:20,498] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 75.0, 0.0, 0.0, 24.0, 22.52265682288885, -0.2590863703089429, 0.0, 1.0, 45460.30845589906], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 108000.0000, 
sim time next is 109800.0000, 
raw observation next is [-7.0, 71.5, 0.0, 0.0, 24.0, 22.46616368487309, -0.2748444367141281, 0.0, 1.0, 45991.329820044244], 
processed observation next is [1.0, 0.2608695652173913, 0.2686980609418283, 0.715, 0.0, 0.0, 0.5, 0.3721803070727576, 0.4083851877619573, 0.0, 1.0, 0.21900633247640117], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.76331925], dtype=float32), 1.5421555]. 
=============================================
[2019-04-07 14:31:28,626] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.9813908e-19 9.9361941e-16 8.1488574e-22 1.2287741e-14 2.8922232e-18
 1.0000000e+00 5.9479564e-13 7.0015578e-15], sum to 1.0000
[2019-04-07 14:31:28,626] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2084
[2019-04-07 14:31:28,694] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 45.0, 116.0, 810.5, 24.0, 24.9540328680798, 0.1135209380818034, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3412800.0000, 
sim time next is 3414600.0000, 
raw observation next is [3.0, 47.0, 117.0, 817.0, 24.0, 24.72032525015125, 0.207018402168078, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5457063711911359, 0.47, 0.39, 0.9027624309392265, 0.5, 0.5600271041792709, 0.5690061340560261, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.55587345], dtype=float32), -1.3226538]. 
=============================================
[2019-04-07 14:31:29,121] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-07 14:31:29,121] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:31:29,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:31:29,124] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run46
[2019-04-07 14:31:29,143] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:31:29,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:31:29,149] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 14:31:29,154] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run46
[2019-04-07 14:31:29,154] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:31:29,178] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run46
[2019-04-07 14:32:34,344] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12336727], dtype=float32), 0.14805025]
[2019-04-07 14:32:34,344] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-5.0, 86.0, 0.0, 0.0, 24.0, 23.10302353289319, -0.1660350492539037, 0.0, 1.0, 44116.837007623144]
[2019-04-07 14:32:34,344] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 14:32:34,345] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.0074969e-18 7.5671361e-16 7.6583305e-21 2.5541071e-14 3.2003036e-16
 1.0000000e+00 4.0631967e-11 1.0059639e-13], sampled 0.25849543652459983
[2019-04-07 14:33:43,675] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:34:15,569] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 14:34:20,259] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:34:21,282] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 900000, evaluation results [900000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:34:30,051] A3C_AGENT_WORKER-Thread-18 INFO:Local step 57000, global step 901526: loss 0.0528
[2019-04-07 14:34:30,051] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 57000, global step 901526: learning rate 0.0000
[2019-04-07 14:34:30,732] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.64854701e-18 9.26469603e-16 3.37544216e-22 1.06098415e-14
 1.18556313e-18 1.00000000e+00 9.04105241e-13 1.30124488e-14], sum to 1.0000
[2019-04-07 14:34:30,735] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7074
[2019-04-07 14:34:30,794] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 53.5, 103.0, 775.0, 24.0, 24.66056079000534, 0.2285344379805802, 1.0, 1.0, 6226.803890076847], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3421800.0000, 
sim time next is 3423600.0000, 
raw observation next is [3.0, 58.0, 93.5, 739.5, 24.0, 24.93139202759396, 0.277638060078241, 1.0, 1.0, 6226.803890076847], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.58, 0.31166666666666665, 0.8171270718232044, 0.5, 0.5776160022994968, 0.5925460200260804, 1.0, 1.0, 0.029651447095604033], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.57769245], dtype=float32), 1.8216777]. 
=============================================
[2019-04-07 14:34:31,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:34:31,198] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:34:31,202] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run21
[2019-04-07 14:34:32,403] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4187442e-14 2.8032942e-13 8.7565174e-18 1.8740339e-12 2.6671525e-13
 1.0000000e+00 5.1752007e-09 2.8839596e-11], sum to 1.0000
[2019-04-07 14:34:32,403] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5131
[2019-04-07 14:34:32,437] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [18.55, 64.0, 29.0, 0.0, 24.0, 23.59417794662427, 0.1277732859122716, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1182600.0000, 
sim time next is 1184400.0000, 
raw observation next is [18.3, 65.0, 14.5, 0.0, 24.0, 23.54659785985492, 0.1169992888834359, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.9695290858725764, 0.65, 0.04833333333333333, 0.0, 0.5, 0.46221648832124335, 0.5389997629611453, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.804508], dtype=float32), 0.25614008]. 
=============================================
[2019-04-07 14:34:34,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:34:34,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:34:34,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run21
[2019-04-07 14:34:37,660] A3C_AGENT_WORKER-Thread-19 INFO:Local step 57000, global step 902770: loss 0.0436
[2019-04-07 14:34:37,661] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 57000, global step 902770: learning rate 0.0000
[2019-04-07 14:34:42,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2811136e-16 1.6263188e-14 1.0467149e-18 8.1129927e-13 1.0036502e-14
 1.0000000e+00 2.0055411e-10 4.0471356e-13], sum to 1.0000
[2019-04-07 14:34:42,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2186
[2019-04-07 14:34:42,570] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 79.0, 9.5, 0.0, 24.0, 22.42194526359404, -0.3347602179570242, 0.0, 1.0, 44712.21471105993], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 633600.0000, 
sim time next is 635400.0000, 
raw observation next is [-4.2, 75.0, 19.0, 0.0, 24.0, 22.72604154463039, -0.1911913060819272, 0.0, 1.0, 107481.78804773987], 
processed observation next is [0.0, 0.34782608695652173, 0.34626038781163443, 0.75, 0.06333333333333334, 0.0, 0.5, 0.3938367953858659, 0.43626956463935757, 0.0, 1.0, 0.5118180383225708], 
reward next is 0.7739, 
noisyNet noise sample is [array([-0.9348777], dtype=float32), -0.6360494]. 
=============================================
[2019-04-07 14:34:44,069] A3C_AGENT_WORKER-Thread-14 INFO:Local step 57000, global step 903762: loss 0.0433
[2019-04-07 14:34:44,070] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 57000, global step 903762: learning rate 0.0000
[2019-04-07 14:34:46,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.09962386e-19 8.82062259e-17 1.15424195e-23 7.04815861e-15
 3.70330415e-18 1.00000000e+00 8.92805469e-13 1.74279888e-15], sum to 1.0000
[2019-04-07 14:34:46,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0164
[2019-04-07 14:34:46,573] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 65.5, 17.0, 147.0, 24.0, 24.75203233067965, 0.1844079905930008, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3778200.0000, 
sim time next is 3780000.0000, 
raw observation next is [-2.0, 71.0, 0.0, 0.0, 24.0, 24.1430696596327, 0.1567944244770281, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.40720221606648205, 0.71, 0.0, 0.0, 0.5, 0.5119224716360584, 0.5522648081590094, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.32540548], dtype=float32), -0.07270246]. 
=============================================
[2019-04-07 14:34:46,591] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[104.295715]
 [104.81994 ]
 [105.006386]
 [104.92552 ]
 [104.65028 ]], R is [[103.75300598]
 [103.71547699]
 [103.67832184]
 [103.64154053]
 [103.60512543]].
[2019-04-07 14:34:48,637] A3C_AGENT_WORKER-Thread-3 INFO:Local step 57500, global step 904523: loss 0.5655
[2019-04-07 14:34:48,640] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 57500, global step 904523: learning rate 0.0000
[2019-04-07 14:34:51,101] A3C_AGENT_WORKER-Thread-6 INFO:Local step 57000, global step 904922: loss 0.0424
[2019-04-07 14:34:51,101] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 57000, global step 904922: learning rate 0.0000
[2019-04-07 14:34:51,535] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8696604e-18 3.7004556e-16 3.1498159e-20 5.2516243e-14 1.2430723e-16
 1.0000000e+00 3.1678871e-11 1.6957269e-13], sum to 1.0000
[2019-04-07 14:34:51,535] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8509
[2019-04-07 14:34:51,602] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 61.0, 0.0, 0.0, 24.0, 23.29382603210841, -0.09755012647713439, 0.0, 1.0, 53535.74897241354], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 766800.0000, 
sim time next is 768600.0000, 
raw observation next is [-5.9, 62.5, 0.0, 0.0, 24.0, 23.35972445678616, -0.09917172476294049, 0.0, 1.0, 45997.41590648304], 
processed observation next is [1.0, 0.9130434782608695, 0.2991689750692521, 0.625, 0.0, 0.0, 0.5, 0.44664370473218007, 0.46694275841235316, 0.0, 1.0, 0.21903531384039543], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0610853], dtype=float32), -0.20583321]. 
=============================================
[2019-04-07 14:34:54,241] A3C_AGENT_WORKER-Thread-10 INFO:Local step 57000, global step 905454: loss 0.0436
[2019-04-07 14:34:54,242] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 57000, global step 905454: learning rate 0.0000
[2019-04-07 14:35:05,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:35:05,826] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:35:05,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run21
[2019-04-07 14:35:10,328] A3C_AGENT_WORKER-Thread-18 INFO:Local step 57500, global step 908498: loss 0.6316
[2019-04-07 14:35:10,341] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 57500, global step 908498: learning rate 0.0000
[2019-04-07 14:35:19,581] A3C_AGENT_WORKER-Thread-19 INFO:Local step 57500, global step 910386: loss 0.5998
[2019-04-07 14:35:19,602] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 57500, global step 910386: learning rate 0.0000
[2019-04-07 14:35:22,909] A3C_AGENT_WORKER-Thread-14 INFO:Local step 57500, global step 911024: loss 0.5601
[2019-04-07 14:35:22,910] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 57500, global step 911024: learning rate 0.0000
[2019-04-07 14:35:24,515] A3C_AGENT_WORKER-Thread-12 INFO:Local step 57000, global step 911309: loss 0.0421
[2019-04-07 14:35:24,516] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 57000, global step 911309: learning rate 0.0000
[2019-04-07 14:35:26,315] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.00129656e-18 4.28776125e-15 1.22168486e-20 7.20047055e-14
 2.78050508e-15 1.00000000e+00 4.67396677e-10 3.20950216e-13], sum to 1.0000
[2019-04-07 14:35:26,315] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9791
[2019-04-07 14:35:26,419] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 73.5, 0.0, 0.0, 24.0, 22.48592824846626, -0.3226079532643525, 0.0, 1.0, 44649.399158469285], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 631800.0000, 
sim time next is 633600.0000, 
raw observation next is [-4.5, 79.0, 9.5, 0.0, 24.0, 22.42194526359404, -0.3347602179570242, 0.0, 1.0, 44712.21471105993], 
processed observation next is [0.0, 0.34782608695652173, 0.3379501385041552, 0.79, 0.03166666666666667, 0.0, 0.5, 0.3684954386328367, 0.38841326068099197, 0.0, 1.0, 0.21291530814790444], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.25670308], dtype=float32), 1.4123497]. 
=============================================
[2019-04-07 14:35:26,656] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.03225804e-17 1.36561246e-16 3.88947368e-20 3.34951352e-14
 2.33723474e-15 1.00000000e+00 2.53193633e-10 9.55973365e-13], sum to 1.0000
[2019-04-07 14:35:26,656] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3118
[2019-04-07 14:35:26,804] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 79.0, 29.0, 0.0, 24.0, 23.14953879948241, -0.1713639935959526, 0.0, 1.0, 38734.28900587846], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1873800.0000, 
sim time next is 1875600.0000, 
raw observation next is [-4.5, 83.0, 15.0, 0.0, 24.0, 23.1202653424056, -0.1846006822009344, 0.0, 1.0, 39909.434026057264], 
processed observation next is [0.0, 0.7391304347826086, 0.3379501385041552, 0.83, 0.05, 0.0, 0.5, 0.4266887785337999, 0.43846643926635515, 0.0, 1.0, 0.19004492393360603], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4218388], dtype=float32), -0.6916668]. 
=============================================
[2019-04-07 14:35:27,734] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5316290e-16 2.7352994e-15 5.4563631e-20 1.4024432e-13 1.2134530e-15
 1.0000000e+00 5.4654731e-10 2.6033002e-14], sum to 1.0000
[2019-04-07 14:35:27,734] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6485
[2019-04-07 14:35:27,739] A3C_AGENT_WORKER-Thread-13 INFO:Local step 57000, global step 911902: loss 0.0416
[2019-04-07 14:35:27,740] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 57000, global step 911902: learning rate 0.0000
[2019-04-07 14:35:27,829] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 24.0, 23.22529171289849, -0.1587732026069295, 0.0, 1.0, 40702.842144433285], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4863600.0000, 
sim time next is 4865400.0000, 
raw observation next is [-4.0, 68.0, 0.0, 0.0, 24.0, 23.17151619290582, -0.1698363847453054, 0.0, 1.0, 40707.46048937175], 
processed observation next is [0.0, 0.30434782608695654, 0.3518005540166205, 0.68, 0.0, 0.0, 0.5, 0.43095968274215163, 0.44338787175156485, 0.0, 1.0, 0.19384504994938928], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6067364], dtype=float32), -0.33184624]. 
=============================================
[2019-04-07 14:35:28,524] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:35:28,524] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:35:28,527] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run21
[2019-04-07 14:35:31,967] A3C_AGENT_WORKER-Thread-6 INFO:Local step 57500, global step 912544: loss 0.5739
[2019-04-07 14:35:31,969] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 57500, global step 912544: learning rate 0.0000
[2019-04-07 14:35:33,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:35:33,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:35:33,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run21
[2019-04-07 14:35:35,335] A3C_AGENT_WORKER-Thread-10 INFO:Local step 57500, global step 913026: loss 0.6247
[2019-04-07 14:35:35,341] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 57500, global step 913026: learning rate 0.0000
[2019-04-07 14:35:39,062] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:35:39,062] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:35:39,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run21
[2019-04-07 14:35:39,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:35:39,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:35:39,292] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run21
[2019-04-07 14:35:40,358] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.7432983e-19 2.5957895e-17 5.8372486e-22 9.0244648e-16 5.5437344e-17
 1.0000000e+00 6.9934536e-12 1.2447636e-13], sum to 1.0000
[2019-04-07 14:35:40,358] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0685
[2019-04-07 14:35:40,530] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.6, 82.0, 34.0, 0.0, 24.0, 22.72953989368218, -0.2087257255689516, 0.0, 1.0, 19094.411111014455], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 57600.0000, 
sim time next is 59400.0000, 
raw observation next is [6.05, 84.0, 18.0, 0.0, 24.0, 22.68334363562841, -0.2106612744813418, 0.0, 1.0, 36462.84582435909], 
processed observation next is [0.0, 0.6956521739130435, 0.6301939058171746, 0.84, 0.06, 0.0, 0.5, 0.3902786363023676, 0.42977957517288606, 0.0, 1.0, 0.1736325991636147], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.83316976], dtype=float32), 0.34525076]. 
=============================================
[2019-04-07 14:35:43,890] A3C_AGENT_WORKER-Thread-3 INFO:Local step 58000, global step 914166: loss 0.1696
[2019-04-07 14:35:43,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 58000, global step 914166: learning rate 0.0000
[2019-04-07 14:35:45,159] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:35:45,159] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:35:45,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run21
[2019-04-07 14:35:45,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:35:45,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:35:45,521] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run21
[2019-04-07 14:35:45,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:35:45,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:35:45,840] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run21
[2019-04-07 14:35:53,742] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2452743e-19 1.1946487e-16 1.0275494e-21 4.8720820e-14 2.7365176e-17
 1.0000000e+00 6.2036522e-11 1.7026342e-12], sum to 1.0000
[2019-04-07 14:35:53,743] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1560
[2019-04-07 14:35:53,810] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.05, 90.5, 0.0, 0.0, 24.0, 23.30945055488577, -0.08504178926205157, 0.0, 1.0, 42103.164746337454], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 77400.0000, 
sim time next is 79200.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 24.0, 23.31143782456176, -0.08477677424581331, 0.0, 1.0, 41747.8829733676], 
processed observation next is [0.0, 0.9565217391304348, 0.4764542936288089, 0.96, 0.0, 0.0, 0.5, 0.44261981871348005, 0.4717410752513955, 0.0, 1.0, 0.1987994427303219], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.28841972], dtype=float32), 1.2963132]. 
=============================================
[2019-04-07 14:36:01,120] A3C_AGENT_WORKER-Thread-16 INFO:Local step 57000, global step 916200: loss 0.0448
[2019-04-07 14:36:01,121] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 57000, global step 916200: learning rate 0.0000
[2019-04-07 14:36:04,931] A3C_AGENT_WORKER-Thread-12 INFO:Local step 57500, global step 916694: loss 0.6256
[2019-04-07 14:36:04,939] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 57500, global step 916694: learning rate 0.0000
[2019-04-07 14:36:08,496] A3C_AGENT_WORKER-Thread-18 INFO:Local step 58000, global step 917134: loss 0.1431
[2019-04-07 14:36:08,553] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 58000, global step 917134: learning rate 0.0000
[2019-04-07 14:36:08,794] A3C_AGENT_WORKER-Thread-13 INFO:Local step 57500, global step 917186: loss 0.5680
[2019-04-07 14:36:08,794] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 57500, global step 917186: learning rate 0.0000
[2019-04-07 14:36:11,584] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3769340e-18 2.3836871e-15 3.7262144e-20 6.0813916e-14 1.4878650e-16
 1.0000000e+00 2.0920612e-11 8.0506050e-14], sum to 1.0000
[2019-04-07 14:36:11,585] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8997
[2019-04-07 14:36:11,602] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.55, 43.5, 138.0, 42.0, 24.0, 24.05906770346477, -0.01127981423011112, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2302200.0000, 
sim time next is 2304000.0000, 
raw observation next is [0.0, 44.0, 89.5, 21.0, 24.0, 24.13869164926793, -0.01931526183302877, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.46260387811634357, 0.44, 0.29833333333333334, 0.023204419889502764, 0.5, 0.5115576374389942, 0.4935615793889904, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.86861134], dtype=float32), 1.4977005]. 
=============================================
[2019-04-07 14:36:11,606] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[97.21518 ]
 [97.34246 ]
 [97.374725]
 [98.07032 ]
 [98.65838 ]], R is [[96.92861176]
 [96.9593277 ]
 [96.98973846]
 [97.01984406]
 [97.04964447]].
[2019-04-07 14:36:20,737] A3C_AGENT_WORKER-Thread-19 INFO:Local step 58000, global step 918620: loss 0.2108
[2019-04-07 14:36:20,738] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 58000, global step 918620: learning rate 0.0000
[2019-04-07 14:36:23,667] A3C_AGENT_WORKER-Thread-14 INFO:Local step 58000, global step 918972: loss 0.1921
[2019-04-07 14:36:23,668] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 58000, global step 918972: learning rate 0.0000
[2019-04-07 14:36:29,496] A3C_AGENT_WORKER-Thread-4 INFO:Local step 57000, global step 919811: loss 0.0464
[2019-04-07 14:36:29,496] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 57000, global step 919811: learning rate 0.0000
[2019-04-07 14:36:30,817] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-07 14:36:30,818] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:36:30,818] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:36:30,820] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run47
[2019-04-07 14:36:30,862] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:36:30,862] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:36:30,864] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run47
[2019-04-07 14:36:30,894] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 14:36:30,895] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:36:30,897] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run47
[2019-04-07 14:38:45,913] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:39:10,627] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 14:39:14,365] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:39:15,388] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 920000, evaluation results [920000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:39:17,659] A3C_AGENT_WORKER-Thread-6 INFO:Local step 58000, global step 920354: loss 0.2633
[2019-04-07 14:39:17,659] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 58000, global step 920354: learning rate 0.0000
[2019-04-07 14:39:18,683] A3C_AGENT_WORKER-Thread-5 INFO:Local step 57000, global step 920471: loss 0.0462
[2019-04-07 14:39:18,684] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 57000, global step 920471: learning rate 0.0000
[2019-04-07 14:39:18,851] A3C_AGENT_WORKER-Thread-3 INFO:Local step 58500, global step 920493: loss 0.7007
[2019-04-07 14:39:18,851] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 58500, global step 920493: learning rate 0.0000
[2019-04-07 14:39:21,422] A3C_AGENT_WORKER-Thread-10 INFO:Local step 58000, global step 920823: loss 0.2668
[2019-04-07 14:39:21,435] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 58000, global step 920823: learning rate 0.0000
[2019-04-07 14:39:23,823] A3C_AGENT_WORKER-Thread-17 INFO:Local step 57000, global step 921201: loss 0.0417
[2019-04-07 14:39:23,823] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 57000, global step 921201: learning rate 0.0000
[2019-04-07 14:39:25,287] A3C_AGENT_WORKER-Thread-20 INFO:Local step 57000, global step 921366: loss 0.0472
[2019-04-07 14:39:25,288] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 57000, global step 921366: learning rate 0.0000
[2019-04-07 14:39:28,933] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3428766e-17 6.3956186e-16 6.8089921e-21 1.3117965e-13 4.0685142e-16
 1.0000000e+00 1.2239254e-10 3.2967979e-14], sum to 1.0000
[2019-04-07 14:39:28,934] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8743
[2019-04-07 14:39:28,988] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 80.5, 0.0, 0.0, 24.0, 23.00802871330751, -0.1969845467339755, 0.0, 1.0, 43285.259309582754], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 613800.0000, 
sim time next is 615600.0000, 
raw observation next is [-3.9, 75.0, 0.0, 0.0, 24.0, 22.97016804615365, -0.2079501133005549, 0.0, 1.0, 43600.42974333876], 
processed observation next is [0.0, 0.13043478260869565, 0.3545706371191136, 0.75, 0.0, 0.0, 0.5, 0.4141806705128041, 0.43068329556648166, 0.0, 1.0, 0.20762109401589887], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3864095], dtype=float32), 0.40435198]. 
=============================================
[2019-04-07 14:39:29,150] A3C_AGENT_WORKER-Thread-16 INFO:Local step 57500, global step 921895: loss 0.6058
[2019-04-07 14:39:29,152] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 57500, global step 921895: learning rate 0.0000
[2019-04-07 14:39:31,512] A3C_AGENT_WORKER-Thread-11 INFO:Local step 57000, global step 922253: loss 0.0475
[2019-04-07 14:39:31,513] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 57000, global step 922253: learning rate 0.0000
[2019-04-07 14:39:31,912] A3C_AGENT_WORKER-Thread-2 INFO:Local step 57000, global step 922309: loss 0.0456
[2019-04-07 14:39:31,925] A3C_AGENT_WORKER-Thread-15 INFO:Local step 57000, global step 922311: loss 0.0427
[2019-04-07 14:39:31,925] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 57000, global step 922311: learning rate 0.0000
[2019-04-07 14:39:31,934] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 57000, global step 922309: learning rate 0.0000
[2019-04-07 14:39:35,409] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6853528e-18 3.1905153e-16 6.9053837e-21 1.7677581e-14 4.7661835e-16
 1.0000000e+00 5.0240120e-12 4.8998440e-14], sum to 1.0000
[2019-04-07 14:39:35,410] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2917
[2019-04-07 14:39:35,460] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 72.5, 0.0, 0.0, 24.0, 22.71749998735309, -0.2570510591450363, 0.0, 1.0, 42472.34601495386], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 786600.0000, 
sim time next is 788400.0000, 
raw observation next is [-7.8, 74.0, 0.0, 0.0, 24.0, 22.65825511230607, -0.2596295367045433, 0.0, 1.0, 42327.98482409425], 
processed observation next is [1.0, 0.13043478260869565, 0.24653739612188366, 0.74, 0.0, 0.0, 0.5, 0.3881879260255057, 0.4134568210984855, 0.0, 1.0, 0.2015618324956869], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24242115], dtype=float32), -0.044066224]. 
=============================================
[2019-04-07 14:39:37,742] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6575895e-19 1.9156816e-16 2.9627023e-22 3.7030273e-15 6.1440106e-18
 1.0000000e+00 2.7354078e-12 1.9735395e-15], sum to 1.0000
[2019-04-07 14:39:37,743] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6585
[2019-04-07 14:39:38,026] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 84.0, 0.0, 0.0, 24.0, 23.03300370802211, -0.1961313121532292, 1.0, 1.0, 70993.66613067372], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 844200.0000, 
sim time next is 846000.0000, 
raw observation next is [-3.9, 86.0, 0.0, 0.0, 24.0, 23.19281996927643, -0.1200100651892626, 1.0, 1.0, 74282.25426930534], 
processed observation next is [1.0, 0.8260869565217391, 0.3545706371191136, 0.86, 0.0, 0.0, 0.5, 0.4327349974397026, 0.45999664493691245, 1.0, 1.0, 0.35372502033002545], 
reward next is 0.9320, 
noisyNet noise sample is [array([-1.0489224], dtype=float32), 0.48009592]. 
=============================================
[2019-04-07 14:39:38,044] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[104.64349 ]
 [104.37958 ]
 [104.462654]
 [104.1228  ]
 [104.18248 ]], R is [[105.0091629 ]
 [104.90672302]
 [104.85765839]
 [104.8077774 ]
 [104.75969696]].
[2019-04-07 14:39:43,929] A3C_AGENT_WORKER-Thread-18 INFO:Local step 58500, global step 924215: loss 0.7196
[2019-04-07 14:39:43,930] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 58500, global step 924215: learning rate 0.0000
[2019-04-07 14:39:48,305] A3C_AGENT_WORKER-Thread-12 INFO:Local step 58000, global step 924998: loss 0.2139
[2019-04-07 14:39:48,306] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 58000, global step 924998: learning rate 0.0000
[2019-04-07 14:39:50,666] A3C_AGENT_WORKER-Thread-13 INFO:Local step 58000, global step 925453: loss 0.2026
[2019-04-07 14:39:50,667] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 58000, global step 925453: learning rate 0.0000
[2019-04-07 14:39:53,612] A3C_AGENT_WORKER-Thread-19 INFO:Local step 58500, global step 926073: loss 0.7576
[2019-04-07 14:39:53,615] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 58500, global step 926073: learning rate 0.0000
[2019-04-07 14:39:55,031] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.4969042e-21 6.9057398e-17 3.7599509e-22 1.6555603e-14 1.5646009e-17
 1.0000000e+00 7.1336383e-14 3.6077107e-15], sum to 1.0000
[2019-04-07 14:39:55,031] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9452
[2019-04-07 14:39:55,095] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 24.0, 23.5123957934067, -0.0821145206307627, 0.0, 1.0, 32130.849174090352], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3103200.0000, 
sim time next is 3105000.0000, 
raw observation next is [-0.5, 100.0, 0.0, 0.0, 24.0, 23.50000930918636, -0.08807792893597331, 0.0, 1.0, 32711.35725977499], 
processed observation next is [0.0, 0.9565217391304348, 0.44875346260387816, 1.0, 0.0, 0.0, 0.5, 0.45833410909886335, 0.4706406903546756, 0.0, 1.0, 0.15576836790369045], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5248376], dtype=float32), -0.075127944]. 
=============================================
[2019-04-07 14:39:55,103] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[103.725525]
 [103.529816]
 [102.64797 ]
 [102.00493 ]
 [101.54066 ]], R is [[103.94288635]
 [103.90345764]
 [103.79826355]
 [103.76028442]
 [103.72267914]].
[2019-04-07 14:39:55,964] A3C_AGENT_WORKER-Thread-4 INFO:Local step 57500, global step 926645: loss 0.6368
[2019-04-07 14:39:55,981] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 57500, global step 926645: learning rate 0.0000
[2019-04-07 14:39:58,212] A3C_AGENT_WORKER-Thread-14 INFO:Local step 58500, global step 927164: loss 0.7359
[2019-04-07 14:39:58,214] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 58500, global step 927164: learning rate 0.0000
[2019-04-07 14:39:59,145] A3C_AGENT_WORKER-Thread-3 INFO:Local step 59000, global step 927409: loss 0.1337
[2019-04-07 14:39:59,146] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 59000, global step 927409: learning rate 0.0000
[2019-04-07 14:40:00,801] A3C_AGENT_WORKER-Thread-5 INFO:Local step 57500, global step 927804: loss 0.5920
[2019-04-07 14:40:00,802] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 57500, global step 927804: learning rate 0.0000
[2019-04-07 14:40:04,841] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0201382e-17 1.3492811e-15 5.0987325e-19 4.8056773e-14 1.7166697e-15
 1.0000000e+00 1.6521598e-10 2.0894640e-12], sum to 1.0000
[2019-04-07 14:40:04,841] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5190
[2019-04-07 14:40:04,882] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.0, 25.0, 0.0, 0.0, 24.0, 23.73618961661888, -0.06372592638987572, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3632400.0000, 
sim time next is 3634200.0000, 
raw observation next is [9.0, 25.0, 0.0, 0.0, 24.0, 23.63017698370287, -0.0686938011343653, 0.0, 1.0, 50495.68318261334], 
processed observation next is [0.0, 0.043478260869565216, 0.7119113573407203, 0.25, 0.0, 0.0, 0.5, 0.46918141530857255, 0.47710206628854496, 0.0, 1.0, 0.24045563420292068], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5989792], dtype=float32), -1.1423098]. 
=============================================
[2019-04-07 14:40:05,302] A3C_AGENT_WORKER-Thread-6 INFO:Local step 58500, global step 928689: loss 0.7226
[2019-04-07 14:40:05,302] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 58500, global step 928689: learning rate 0.0000
[2019-04-07 14:40:05,888] A3C_AGENT_WORKER-Thread-17 INFO:Local step 57500, global step 928797: loss 0.6426
[2019-04-07 14:40:05,888] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 57500, global step 928797: learning rate 0.0000
[2019-04-07 14:40:07,707] A3C_AGENT_WORKER-Thread-20 INFO:Local step 57500, global step 929122: loss 0.5307
[2019-04-07 14:40:07,708] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 57500, global step 929122: learning rate 0.0000
[2019-04-07 14:40:08,595] A3C_AGENT_WORKER-Thread-10 INFO:Local step 58500, global step 929282: loss 0.7641
[2019-04-07 14:40:08,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 58500, global step 929282: learning rate 0.0000
[2019-04-07 14:40:12,429] A3C_AGENT_WORKER-Thread-11 INFO:Local step 57500, global step 929983: loss 0.6772
[2019-04-07 14:40:12,443] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 57500, global step 929983: learning rate 0.0000
[2019-04-07 14:40:12,986] A3C_AGENT_WORKER-Thread-15 INFO:Local step 57500, global step 930092: loss 0.5122
[2019-04-07 14:40:12,988] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 57500, global step 930092: learning rate 0.0000
[2019-04-07 14:40:13,128] A3C_AGENT_WORKER-Thread-2 INFO:Local step 57500, global step 930117: loss 0.5974
[2019-04-07 14:40:13,154] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 57500, global step 930117: learning rate 0.0000
[2019-04-07 14:40:21,558] A3C_AGENT_WORKER-Thread-16 INFO:Local step 58000, global step 931601: loss 0.3134
[2019-04-07 14:40:21,559] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 58000, global step 931601: learning rate 0.0000
[2019-04-07 14:40:22,708] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.0023689e-17 3.2461301e-15 1.4551050e-19 1.1863969e-12 1.7764202e-15
 1.0000000e+00 6.8307894e-11 1.7071892e-13], sum to 1.0000
[2019-04-07 14:40:22,708] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2750
[2019-04-07 14:40:22,769] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 45.0, 0.0, 0.0, 24.0, 23.61591179902994, -0.06386490474380559, 0.0, 1.0, 29366.591555302282], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4224600.0000, 
sim time next is 4226400.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 24.0, 23.5531708547421, -0.05558905249916202, 0.0, 1.0, 56418.75614158335], 
processed observation next is [0.0, 0.9565217391304348, 0.4903047091412743, 0.47, 0.0, 0.0, 0.5, 0.4627642378951749, 0.48147031583361266, 0.0, 1.0, 0.2686607435313493], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.47587836], dtype=float32), 0.23378712]. 
=============================================
[2019-04-07 14:40:23,602] A3C_AGENT_WORKER-Thread-18 INFO:Local step 59000, global step 931884: loss 0.2737
[2019-04-07 14:40:23,603] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 59000, global step 931884: learning rate 0.0000
[2019-04-07 14:40:31,335] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7214401e-19 3.8962196e-18 3.3737041e-22 1.5518525e-15 6.3432789e-17
 1.0000000e+00 2.4341102e-12 9.7576618e-16], sum to 1.0000
[2019-04-07 14:40:31,335] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7243
[2019-04-07 14:40:31,431] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.0, 26.0, 53.0, 472.5, 24.0, 26.39196005735602, 0.6136894331029074, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4986000.0000, 
sim time next is 4987800.0000, 
raw observation next is [7.0, 25.5, 34.0, 304.0, 24.0, 25.99657253132318, 0.5060970312919008, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.6565096952908588, 0.255, 0.11333333333333333, 0.33591160220994476, 0.5, 0.6663810442769318, 0.6686990104306335, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.77375835], dtype=float32), 0.6093887]. 
=============================================
[2019-04-07 14:40:32,491] A3C_AGENT_WORKER-Thread-19 INFO:Local step 59000, global step 933330: loss 0.2029
[2019-04-07 14:40:32,492] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 59000, global step 933330: learning rate 0.0000
[2019-04-07 14:40:34,343] A3C_AGENT_WORKER-Thread-12 INFO:Local step 58500, global step 933650: loss 0.7601
[2019-04-07 14:40:34,343] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 58500, global step 933650: learning rate 0.0000
[2019-04-07 14:40:36,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:40:36,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:40:36,213] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run22
[2019-04-07 14:40:37,304] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5277499e-16 4.2185351e-14 5.4153912e-19 1.9435200e-12 1.4876253e-14
 1.0000000e+00 1.7605249e-09 8.8497775e-13], sum to 1.0000
[2019-04-07 14:40:37,304] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1418
[2019-04-07 14:40:37,408] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 35.0, 111.0, 717.0, 24.0, 23.50714806465567, -0.01627639806146876, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4183200.0000, 
sim time next is 4185000.0000, 
raw observation next is [-1.5, 35.0, 114.0, 774.0, 24.0, 23.41088855737374, -0.01993515364389331, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.4210526315789474, 0.35, 0.38, 0.8552486187845304, 0.5, 0.45090737978114515, 0.49335494878536884, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.20212224], dtype=float32), -0.36829886]. 
=============================================
[2019-04-07 14:40:37,412] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[87.45522 ]
 [88.17843 ]
 [88.754105]
 [89.108   ]
 [89.19279 ]], R is [[87.38684845]
 [87.5129776 ]
 [87.6378479 ]
 [87.76146698]
 [87.8838501 ]].
[2019-04-07 14:40:37,871] A3C_AGENT_WORKER-Thread-13 INFO:Local step 58500, global step 934140: loss 0.7641
[2019-04-07 14:40:37,897] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 58500, global step 934143: learning rate 0.0000
[2019-04-07 14:40:39,445] A3C_AGENT_WORKER-Thread-14 INFO:Local step 59000, global step 934408: loss 0.1722
[2019-04-07 14:40:39,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 59000, global step 934408: learning rate 0.0000
[2019-04-07 14:40:47,230] A3C_AGENT_WORKER-Thread-6 INFO:Local step 59000, global step 935619: loss 0.2152
[2019-04-07 14:40:47,231] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 59000, global step 935620: learning rate 0.0000
[2019-04-07 14:40:50,674] A3C_AGENT_WORKER-Thread-10 INFO:Local step 59000, global step 936169: loss 0.1903
[2019-04-07 14:40:50,674] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 59000, global step 936169: learning rate 0.0000
[2019-04-07 14:40:51,004] A3C_AGENT_WORKER-Thread-4 INFO:Local step 58000, global step 936241: loss 0.1927
[2019-04-07 14:40:51,023] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 58000, global step 936241: learning rate 0.0000
[2019-04-07 14:40:56,540] A3C_AGENT_WORKER-Thread-5 INFO:Local step 58000, global step 937183: loss 0.2376
[2019-04-07 14:40:56,542] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 58000, global step 937183: learning rate 0.0000
[2019-04-07 14:41:00,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:41:00,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:41:00,010] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run22
[2019-04-07 14:41:03,292] A3C_AGENT_WORKER-Thread-20 INFO:Local step 58000, global step 938293: loss 0.1943
[2019-04-07 14:41:03,293] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 58000, global step 938293: learning rate 0.0000
[2019-04-07 14:41:03,615] A3C_AGENT_WORKER-Thread-17 INFO:Local step 58000, global step 938350: loss 0.2338
[2019-04-07 14:41:03,615] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 58000, global step 938350: learning rate 0.0000
[2019-04-07 14:41:08,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:41:08,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:41:08,992] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run22
[2019-04-07 14:41:09,689] A3C_AGENT_WORKER-Thread-11 INFO:Local step 58000, global step 939252: loss 0.2257
[2019-04-07 14:41:09,690] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 58000, global step 939252: learning rate 0.0000
[2019-04-07 14:41:10,460] A3C_AGENT_WORKER-Thread-2 INFO:Local step 58000, global step 939379: loss 0.2455
[2019-04-07 14:41:10,460] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 58000, global step 939379: learning rate 0.0000
[2019-04-07 14:41:10,629] A3C_AGENT_WORKER-Thread-15 INFO:Local step 58000, global step 939406: loss 0.1715
[2019-04-07 14:41:10,630] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 58000, global step 939406: learning rate 0.0000
[2019-04-07 14:41:10,867] A3C_AGENT_WORKER-Thread-16 INFO:Local step 58500, global step 939435: loss 0.6561
[2019-04-07 14:41:10,867] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 58500, global step 939435: learning rate 0.0000
[2019-04-07 14:41:14,627] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-07 14:41:14,629] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:41:14,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:41:14,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run48
[2019-04-07 14:41:14,659] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:41:14,660] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:41:14,663] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 14:41:14,663] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run48
[2019-04-07 14:41:14,663] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:41:14,682] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run48
[2019-04-07 14:41:31,424] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12349772], dtype=float32), 0.14917892]
[2019-04-07 14:41:31,424] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-12.55, 69.0, 0.0, 0.0, 24.0, 21.28551298045996, -0.6042822257362186, 0.0, 1.0, 45114.09321560762]
[2019-04-07 14:41:31,425] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 14:41:31,426] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [3.5115909e-15 2.3018181e-13 1.9714005e-17 4.4732499e-12 1.3914895e-13
 1.0000000e+00 2.2142030e-09 1.3699362e-11], sampled 0.02099424905341485
[2019-04-07 14:42:02,895] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.12349772], dtype=float32), 0.14917892]
[2019-04-07 14:42:02,896] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [10.50122794, 54.86008537, 0.0, 0.0, 24.0, 24.43702377468704, 0.2395364822478487, 1.0, 1.0, 0.0]
[2019-04-07 14:42:02,896] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 14:42:02,897] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.4468247e-19 6.1790114e-17 2.7429171e-22 2.0296877e-15 1.0125550e-17
 1.0000000e+00 2.8430288e-12 7.7010677e-15], sampled 0.8190985112536789
[2019-04-07 14:43:25,950] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:43:53,515] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 14:43:57,795] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:43:58,847] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 940000, evaluation results [940000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:44:00,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:44:00,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:44:00,684] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run22
[2019-04-07 14:44:01,206] A3C_AGENT_WORKER-Thread-12 INFO:Local step 59000, global step 940404: loss 0.1719
[2019-04-07 14:44:01,211] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 59000, global step 940404: learning rate 0.0000
[2019-04-07 14:44:03,703] A3C_AGENT_WORKER-Thread-13 INFO:Local step 59000, global step 940788: loss 0.1270
[2019-04-07 14:44:03,703] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 59000, global step 940788: learning rate 0.0000
[2019-04-07 14:44:07,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:44:07,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:44:07,550] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run22
[2019-04-07 14:44:11,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:44:11,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:44:11,070] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run22
[2019-04-07 14:44:21,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.5173709e-20 3.0464789e-16 5.5776118e-24 5.4803423e-16 1.4886128e-18
 1.0000000e+00 1.5878259e-12 9.8512058e-15], sum to 1.0000
[2019-04-07 14:44:21,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6786
[2019-04-07 14:44:21,498] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.3722452e-22 1.8558341e-18 2.2429315e-25 2.3784245e-18 1.0804021e-19
 1.0000000e+00 5.0826877e-13 5.7331458e-17], sum to 1.0000
[2019-04-07 14:44:21,498] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4258
[2019-04-07 14:44:21,506] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 100.0, 90.0, 0.0, 24.0, 23.76459396636325, -0.04947626193626644, 1.0, 1.0, 6226.803890076847], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2903400.0000, 
sim time next is 2905200.0000, 
raw observation next is [2.0, 100.0, 87.5, 0.0, 24.0, 23.42930580731208, -0.0880821962820969, 1.0, 1.0, 12523.044002333043], 
processed observation next is [1.0, 0.6521739130434783, 0.518005540166205, 1.0, 0.2916666666666667, 0.0, 0.5, 0.45244215060933995, 0.4706392679059677, 1.0, 1.0, 0.059633542868252586], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0109265], dtype=float32), -1.0200237]. 
=============================================
[2019-04-07 14:44:21,522] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.0, 100.0, 92.5, 721.0, 24.0, 25.70356070881084, 0.5139779707682876, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3164400.0000, 
sim time next is 3166200.0000, 
raw observation next is [6.8, 99.5, 84.0, 679.0, 24.0, 25.92626628653815, 0.548272234397432, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.6509695290858727, 0.995, 0.28, 0.7502762430939226, 0.5, 0.660522190544846, 0.6827574114658107, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4621515], dtype=float32), -0.50617117]. 
=============================================
[2019-04-07 14:44:25,020] A3C_AGENT_WORKER-Thread-4 INFO:Local step 58500, global step 943870: loss 0.6165
[2019-04-07 14:44:25,049] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 58500, global step 943870: learning rate 0.0000
[2019-04-07 14:44:29,507] A3C_AGENT_WORKER-Thread-5 INFO:Local step 58500, global step 944559: loss 0.6219
[2019-04-07 14:44:29,515] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 58500, global step 944559: learning rate 0.0000
[2019-04-07 14:44:35,960] A3C_AGENT_WORKER-Thread-20 INFO:Local step 58500, global step 945624: loss 0.6418
[2019-04-07 14:44:35,961] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 58500, global step 945624: learning rate 0.0000
[2019-04-07 14:44:36,484] A3C_AGENT_WORKER-Thread-16 INFO:Local step 59000, global step 945717: loss 0.1694
[2019-04-07 14:44:36,484] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 59000, global step 945717: learning rate 0.0000
[2019-04-07 14:44:36,801] A3C_AGENT_WORKER-Thread-17 INFO:Local step 58500, global step 945779: loss 0.6135
[2019-04-07 14:44:36,802] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 58500, global step 945779: learning rate 0.0000
[2019-04-07 14:44:38,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:44:38,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:44:38,252] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run22
[2019-04-07 14:44:39,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:44:39,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:44:39,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run22
[2019-04-07 14:44:42,677] A3C_AGENT_WORKER-Thread-11 INFO:Local step 58500, global step 946726: loss 0.6365
[2019-04-07 14:44:42,679] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 58500, global step 946726: learning rate 0.0000
[2019-04-07 14:44:44,564] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.3079040e-17 3.2152214e-15 2.3654302e-19 5.1635728e-14 1.4821208e-16
 1.0000000e+00 4.9190527e-09 3.5528525e-13], sum to 1.0000
[2019-04-07 14:44:44,564] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9591
[2019-04-07 14:44:44,644] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.5, 43.5, 117.0, 829.0, 24.0, 23.71533353046011, 0.05643215543522698, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3673800.0000, 
sim time next is 3675600.0000, 
raw observation next is [5.0, 42.0, 115.0, 823.5, 24.0, 23.63000440459617, 0.05187720811838953, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.6011080332409973, 0.42, 0.38333333333333336, 0.9099447513812154, 0.5, 0.4691670337163476, 0.5172924027061299, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0647835], dtype=float32), 2.0122304]. 
=============================================
[2019-04-07 14:44:44,715] A3C_AGENT_WORKER-Thread-15 INFO:Local step 58500, global step 947022: loss 0.6506
[2019-04-07 14:44:44,727] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 58500, global step 947022: learning rate 0.0000
[2019-04-07 14:44:45,700] A3C_AGENT_WORKER-Thread-2 INFO:Local step 58500, global step 947177: loss 0.6092
[2019-04-07 14:44:45,726] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 58500, global step 947177: learning rate 0.0000
[2019-04-07 14:44:59,864] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.8187753e-18 9.8919451e-16 3.3499186e-20 1.2993048e-15 4.3329764e-16
 1.0000000e+00 2.2835666e-12 1.8437783e-14], sum to 1.0000
[2019-04-07 14:44:59,865] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3553
[2019-04-07 14:44:59,913] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 45.0, 0.0, 0.0, 24.0, 23.18432387544205, -0.0518837748524126, 0.0, 1.0, 145302.92592218707], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4822200.0000, 
sim time next is 4824000.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 24.0, 23.65062803152453, 0.02834580914021587, 0.0, 1.0, 52577.6234917276], 
processed observation next is [0.0, 0.8695652173913043, 0.4903047091412743, 0.47, 0.0, 0.0, 0.5, 0.47088566929371084, 0.5094486030467386, 0.0, 1.0, 0.25036963567489334], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9563321], dtype=float32), 0.5694741]. 
=============================================
[2019-04-07 14:44:59,941] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[91.37532 ]
 [89.85373 ]
 [89.326385]
 [89.5224  ]
 [89.6865  ]], R is [[92.06581116]
 [91.73895264]
 [91.82156372]
 [91.90335083]
 [91.98432159]].
[2019-04-07 14:45:07,190] A3C_AGENT_WORKER-Thread-4 INFO:Local step 59000, global step 950796: loss 0.1266
[2019-04-07 14:45:07,191] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 59000, global step 950796: learning rate 0.0000
[2019-04-07 14:45:09,538] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.5025970e-17 3.7233129e-14 2.2734511e-18 1.3230091e-12 1.1968987e-14
 1.0000000e+00 3.3038630e-09 5.8270191e-13], sum to 1.0000
[2019-04-07 14:45:09,539] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8221
[2019-04-07 14:45:09,566] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 32.5, 119.0, 822.0, 24.0, 23.26933309097819, -0.03824509026439608, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4188600.0000, 
sim time next is 4190400.0000, 
raw observation next is [1.0, 30.0, 118.5, 834.5, 24.0, 23.20986735313155, -0.03874885138751483, 0.0, 1.0, 6228.244042576333], 
processed observation next is [0.0, 0.5217391304347826, 0.4903047091412743, 0.3, 0.395, 0.9220994475138121, 0.5, 0.4341556127609625, 0.48708371620416174, 0.0, 1.0, 0.029658304964649208], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.43221018], dtype=float32), 0.7725511]. 
=============================================
[2019-04-07 14:45:12,031] A3C_AGENT_WORKER-Thread-5 INFO:Local step 59000, global step 951619: loss 0.2139
[2019-04-07 14:45:12,032] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 59000, global step 951619: learning rate 0.0000
[2019-04-07 14:45:12,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:45:12,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:45:12,508] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run22
[2019-04-07 14:45:18,536] A3C_AGENT_WORKER-Thread-17 INFO:Local step 59000, global step 952675: loss 0.1433
[2019-04-07 14:45:18,537] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 59000, global step 952675: learning rate 0.0000
[2019-04-07 14:45:19,016] A3C_AGENT_WORKER-Thread-20 INFO:Local step 59000, global step 952748: loss 0.1668
[2019-04-07 14:45:19,021] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 59000, global step 952748: learning rate 0.0000
[2019-04-07 14:45:24,353] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4188076e-16 3.3480092e-16 1.9891118e-20 4.2254604e-14 2.4445273e-16
 1.0000000e+00 9.2277373e-11 3.3403854e-13], sum to 1.0000
[2019-04-07 14:45:24,354] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8653
[2019-04-07 14:45:24,441] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 47.0, 0.0, 0.0, 24.0, 23.5501422115201, -0.06869445947808246, 0.0, 1.0, 32609.939135147157], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4230000.0000, 
sim time next is 4231800.0000, 
raw observation next is [1.5, 47.5, 0.0, 0.0, 24.0, 23.5204042800608, -0.06962828340365944, 0.0, 1.0, 43153.47124664352], 
processed observation next is [0.0, 1.0, 0.5041551246537397, 0.475, 0.0, 0.0, 0.5, 0.46003369000506655, 0.4767905721987802, 0.0, 1.0, 0.205492720222112], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6246692], dtype=float32), 1.5510185]. 
=============================================
[2019-04-07 14:45:25,061] A3C_AGENT_WORKER-Thread-11 INFO:Local step 59000, global step 953940: loss 0.1864
[2019-04-07 14:45:25,063] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 59000, global step 953940: learning rate 0.0000
[2019-04-07 14:45:27,247] A3C_AGENT_WORKER-Thread-15 INFO:Local step 59000, global step 954462: loss 0.1606
[2019-04-07 14:45:27,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 59000, global step 954462: learning rate 0.0000
[2019-04-07 14:45:27,581] A3C_AGENT_WORKER-Thread-2 INFO:Local step 59000, global step 954526: loss 0.1873
[2019-04-07 14:45:27,582] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 59000, global step 954526: learning rate 0.0000
[2019-04-07 14:45:32,092] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.2740938e-21 3.5894219e-17 1.0005993e-22 3.3073000e-16 2.1675212e-19
 1.0000000e+00 5.2714674e-13 3.8382938e-15], sum to 1.0000
[2019-04-07 14:45:32,092] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0163
[2019-04-07 14:45:32,162] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.2, 31.5, 195.0, 629.0, 24.0, 26.86292005127353, 0.7402492300450066, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4372200.0000, 
sim time next is 4374000.0000, 
raw observation next is [13.9, 32.0, 149.0, 314.5, 24.0, 26.56112087855076, 0.6582731559141878, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.847645429362881, 0.32, 0.49666666666666665, 0.3475138121546961, 0.5, 0.71342673987923, 0.7194243853047292, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.63963926], dtype=float32), -0.24683577]. 
=============================================
[2019-04-07 14:45:32,171] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[113.19319 ]
 [112.38532 ]
 [111.316605]
 [110.77477 ]
 [110.1795  ]], R is [[112.67904663]
 [112.55225372]
 [112.42673492]
 [112.30246735]
 [112.17944336]].
[2019-04-07 14:45:36,461] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.8748913e-17 1.8353146e-15 3.4311018e-19 1.1079838e-13 1.5575755e-15
 1.0000000e+00 2.7194502e-10 1.5354435e-12], sum to 1.0000
[2019-04-07 14:45:36,461] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1974
[2019-04-07 14:45:36,525] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 65.5, 0.0, 0.0, 24.0, 23.35485556602731, -0.1305444069801985, 0.0, 1.0, 49042.197293770725], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4858200.0000, 
sim time next is 4860000.0000, 
raw observation next is [-3.0, 60.0, 0.0, 0.0, 24.0, 23.30090775903318, -0.1372393776493357, 0.0, 1.0, 42725.609425066265], 
processed observation next is [0.0, 0.2608695652173913, 0.3795013850415513, 0.6, 0.0, 0.0, 0.5, 0.441742313252765, 0.4542535407835548, 0.0, 1.0, 0.20345528297650603], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0776837], dtype=float32), 2.2049568]. 
=============================================
[2019-04-07 14:45:36,563] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[90.00162 ]
 [90.003136]
 [89.858   ]
 [89.872055]
 [90.00962 ]], R is [[89.97995758]
 [90.08016205]
 [90.17935944]
 [90.277565  ]
 [90.37479401]].
[2019-04-07 14:45:43,528] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:45:43,528] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:45:43,535] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run22
[2019-04-07 14:45:47,378] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:45:47,378] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:45:47,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run22
[2019-04-07 14:45:54,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:45:54,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:45:54,352] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run22
[2019-04-07 14:45:54,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:45:54,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:45:54,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run22
[2019-04-07 14:45:56,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2544241e-16 3.5124234e-14 5.6775113e-19 5.6262156e-13 1.2848339e-15
 1.0000000e+00 8.4866197e-11 2.0857917e-13], sum to 1.0000
[2019-04-07 14:45:56,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6125
[2019-04-07 14:45:56,265] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 36.0, 0.0, 0.0, 24.0, 23.58221507264819, -0.07896775855367655, 0.0, 1.0, 36939.952854753115], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4915800.0000, 
sim time next is 4917600.0000, 
raw observation next is [1.0, 36.0, 0.0, 0.0, 24.0, 23.54180992298794, -0.07073883615279608, 0.0, 1.0, 53140.78956435351], 
processed observation next is [0.0, 0.9565217391304348, 0.4903047091412743, 0.36, 0.0, 0.0, 0.5, 0.46181749358232843, 0.476420387949068, 0.0, 1.0, 0.2530513788778738], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8810973], dtype=float32), -1.5271124]. 
=============================================
[2019-04-07 14:45:56,915] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1354364e-22 1.8255902e-20 1.7433685e-25 1.1444994e-16 4.7119061e-19
 1.0000000e+00 2.9253368e-12 4.0454836e-17], sum to 1.0000
[2019-04-07 14:45:56,916] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5935
[2019-04-07 14:45:56,930] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.3, 80.0, 107.0, 117.0, 24.0, 25.17689373690236, 0.4026331519210018, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1072800.0000, 
sim time next is 1074600.0000, 
raw observation next is [14.4, 75.0, 114.0, 0.0, 24.0, 25.42791377561531, 0.4360699778824317, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.8614958448753465, 0.75, 0.38, 0.0, 0.5, 0.6189928146346091, 0.6453566592941439, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.553679], dtype=float32), -1.0386528]. 
=============================================
[2019-04-07 14:46:00,061] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-07 14:46:00,063] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:46:00,063] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:46:00,066] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run49
[2019-04-07 14:46:00,087] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:46:00,087] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:46:00,090] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run49
[2019-04-07 14:46:00,122] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 14:46:00,123] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:46:00,126] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run49
[2019-04-07 14:47:18,972] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.12337032], dtype=float32), 0.14955017]
[2019-04-07 14:47:18,972] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-8.4444139985, 69.43439389, 117.899226, 0.0, 24.0, 23.89563735676393, -0.00409653883366488, 1.0, 1.0, 16726.516550326563]
[2019-04-07 14:47:18,972] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 14:47:18,973] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.5682699e-17 3.8467955e-15 7.1636407e-20 1.1197579e-13 9.9207029e-16
 1.0000000e+00 6.9195524e-11 3.0065891e-13], sampled 0.7342971735153138
[2019-04-07 14:48:16,563] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:48:43,569] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 14:48:46,335] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:48:47,359] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 960000, evaluation results [960000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:48:49,489] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:48:49,489] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:48:49,492] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run22
[2019-04-07 14:48:51,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:48:51,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:48:51,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run22
[2019-04-07 14:48:52,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:48:52,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:48:52,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run22
[2019-04-07 14:49:22,493] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5121538e-17 1.7564067e-16 4.0113756e-21 2.0277848e-14 5.9641869e-18
 1.0000000e+00 6.9343728e-12 6.0182728e-14], sum to 1.0000
[2019-04-07 14:49:22,493] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6569
[2019-04-07 14:49:22,587] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 76.5, 0.0, 0.0, 24.0, 22.94023324602855, -0.167155288977619, 0.0, 1.0, 45671.84358221727], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2248200.0000, 
sim time next is 2250000.0000, 
raw observation next is [-6.7, 75.0, 0.0, 0.0, 24.0, 22.9805487000237, -0.1848159867803663, 0.0, 1.0, 45497.36284612885], 
processed observation next is [1.0, 0.043478260869565216, 0.2770083102493075, 0.75, 0.0, 0.0, 0.5, 0.415045725001975, 0.43839467107321123, 0.0, 1.0, 0.2166541087910898], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.55559564], dtype=float32), -0.9305591]. 
=============================================
[2019-04-07 14:49:22,624] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[95.38913]
 [95.38285]
 [96.67776]
 [96.52299]
 [96.63302]], R is [[95.17965698]
 [95.2278595 ]
 [95.27558136]
 [95.3228302 ]
 [95.36960602]].
[2019-04-07 14:50:17,240] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.8794140e-19 4.2930881e-19 5.1926255e-23 2.1056669e-16 1.5671567e-18
 1.0000000e+00 3.7714314e-13 1.4275135e-15], sum to 1.0000
[2019-04-07 14:50:17,240] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2026
[2019-04-07 14:50:17,340] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.5, 88.0, 0.0, 0.0, 24.0, 23.4324468317476, 0.02759547169777271, 0.0, 1.0, 36469.89874637019], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3281400.0000, 
sim time next is 3283200.0000, 
raw observation next is [-7.0, 84.0, 0.0, 0.0, 24.0, 23.36955834370434, 0.02089944729269884, 0.0, 1.0, 61457.32870780273], 
processed observation next is [1.0, 0.0, 0.2686980609418283, 0.84, 0.0, 0.0, 0.5, 0.4474631953086951, 0.5069664824308996, 0.0, 1.0, 0.292653946227632], 
reward next is 0.9931, 
noisyNet noise sample is [array([-0.04812622], dtype=float32), -0.18741381]. 
=============================================
[2019-04-07 14:50:31,814] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0215577e-17 2.7775367e-15 2.0650625e-19 4.5995309e-13 7.4648389e-16
 1.0000000e+00 1.0754440e-10 5.7805011e-14], sum to 1.0000
[2019-04-07 14:50:31,815] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5460
[2019-04-07 14:50:31,918] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 24.0, 23.35000584115166, -0.113958623754742, 0.0, 1.0, 41521.055777707574], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3024000.0000, 
sim time next is 3025800.0000, 
raw observation next is [-4.5, 68.0, 0.0, 0.0, 24.0, 23.32669051637665, -0.1203556577712895, 0.0, 1.0, 42840.92071334513], 
processed observation next is [0.0, 0.0, 0.3379501385041552, 0.68, 0.0, 0.0, 0.5, 0.4438908763647209, 0.4598814474095702, 0.0, 1.0, 0.20400438434926252], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1061186], dtype=float32), -0.25472367]. 
=============================================
[2019-04-07 14:50:40,544] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.8613262e-20 4.3905437e-17 1.0212928e-21 3.9002255e-15 1.5881974e-17
 1.0000000e+00 3.4683159e-12 2.1919769e-14], sum to 1.0000
[2019-04-07 14:50:40,544] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2466
[2019-04-07 14:50:40,582] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 24.0, 23.31291463161064, -0.1624552121360958, 0.0, 1.0, 46278.72306769151], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1890000.0000, 
sim time next is 1891800.0000, 
raw observation next is [-5.9, 79.0, 0.0, 0.0, 24.0, 23.24600573192475, -0.1765061581482829, 0.0, 1.0, 46197.105656792184], 
processed observation next is [0.0, 0.9130434782608695, 0.2991689750692521, 0.79, 0.0, 0.0, 0.5, 0.43716714432706255, 0.4411646139505723, 0.0, 1.0, 0.2199862174132961], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.53184426], dtype=float32), 0.41052336]. 
=============================================
[2019-04-07 14:50:49,392] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.7013449e-18 9.1476117e-16 5.3787826e-20 5.8207515e-14 1.6691353e-16
 1.0000000e+00 1.4342302e-11 2.0276390e-13], sum to 1.0000
[2019-04-07 14:50:49,393] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7980
[2019-04-07 14:50:49,444] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 24.0, 23.09745719061349, -0.2046534149800219, 0.0, 1.0, 43283.95749830861], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2172600.0000, 
sim time next is 2174400.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 24.0, 22.92115670034488, -0.2207622152620603, 0.0, 1.0, 43178.246740260314], 
processed observation next is [1.0, 0.17391304347826086, 0.2770083102493075, 0.78, 0.0, 0.0, 0.5, 0.41009639169540674, 0.42641259491264655, 0.0, 1.0, 0.20561069876314436], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.111259], dtype=float32), 1.5262762]. 
=============================================
[2019-04-07 14:50:49,693] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:50:49,693] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:50:49,696] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run23
[2019-04-07 14:50:53,929] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4407708e-18 6.1388861e-16 3.2025929e-20 1.7944161e-13 1.8980865e-15
 1.0000000e+00 1.3751353e-11 2.9139848e-14], sum to 1.0000
[2019-04-07 14:50:53,929] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3460
[2019-04-07 14:50:54,172] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 83.0, 0.0, 0.0, 24.0, 23.11702328104316, -0.1984116286809835, 0.0, 1.0, 34737.67198238016], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1882800.0000, 
sim time next is 1884600.0000, 
raw observation next is [-5.05, 84.5, 0.0, 0.0, 24.0, 23.10545734434969, -0.166474366645841, 0.0, 1.0, 108330.14487676551], 
processed observation next is [0.0, 0.8260869565217391, 0.32271468144044324, 0.845, 0.0, 0.0, 0.5, 0.4254547786958076, 0.4445085444513863, 0.0, 1.0, 0.5158578327465024], 
reward next is 0.7699, 
noisyNet noise sample is [array([-0.21981774], dtype=float32), 1.5920842]. 
=============================================
[2019-04-07 14:50:55,995] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-07 14:50:55,996] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:50:55,996] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:50:55,998] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run50
[2019-04-07 14:50:56,025] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:50:56,025] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:50:56,047] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run50
[2019-04-07 14:50:56,076] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 14:50:56,077] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:50:56,080] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run50
[2019-04-07 14:51:12,065] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.12317712], dtype=float32), 0.14987029]
[2019-04-07 14:51:12,066] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-12.144816335, 74.67616218500001, 0.0, 749.8556157, 24.0, 23.75014297094278, -0.1656761598559693, 1.0, 1.0, 0.0]
[2019-04-07 14:51:12,066] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 14:51:12,066] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [5.8366208e-16 4.5474685e-14 2.1040989e-18 9.9386536e-13 2.7437079e-14
 1.0000000e+00 6.9812794e-10 3.1100339e-12], sampled 0.3859285206454406
[2019-04-07 14:51:51,331] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12317712], dtype=float32), 0.14987029]
[2019-04-07 14:51:51,331] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [3.6, 85.0, 209.0, 250.0, 24.0, 24.17853905089409, 0.1209100069020243, 1.0, 1.0, 0.0]
[2019-04-07 14:51:51,331] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 14:51:51,332] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.6760363e-19 4.8469839e-17 2.4475708e-22 1.9405427e-15 1.0454265e-17
 1.0000000e+00 3.0112451e-12 7.0842520e-15], sampled 0.7449185632855259
[2019-04-07 14:53:12,026] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:53:32,400] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 14:53:34,766] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:53:35,789] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 980000, evaluation results [980000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:53:53,074] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:53:53,074] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:53:53,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run23
[2019-04-07 14:53:57,327] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5337770e-17 5.5586054e-15 2.2645951e-19 3.7846546e-13 2.7287297e-14
 1.0000000e+00 2.0171191e-10 3.4702463e-13], sum to 1.0000
[2019-04-07 14:53:57,327] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2871
[2019-04-07 14:53:57,420] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.0, 63.0, 0.0, 0.0, 24.0, 22.91738934872335, -0.169232314337156, 0.0, 1.0, 44922.91196713808], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3985200.0000, 
sim time next is 3987000.0000, 
raw observation next is [-12.0, 63.0, 0.0, 0.0, 24.0, 22.97134097991919, -0.1841321521937596, 0.0, 1.0, 44734.59085655055], 
processed observation next is [1.0, 0.13043478260869565, 0.13019390581717452, 0.63, 0.0, 0.0, 0.5, 0.4142784149932659, 0.43862261593541346, 0.0, 1.0, 0.2130218612216693], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.14482751], dtype=float32), -0.13680303]. 
=============================================
[2019-04-07 14:53:57,430] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[89.83611 ]
 [89.97056 ]
 [90.034515]
 [90.26572 ]
 [90.06916 ]], R is [[89.65802765]
 [89.76145172]
 [89.8638382 ]
 [89.96520233]
 [90.06555176]].
[2019-04-07 14:54:02,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:54:02,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:54:02,860] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run23
[2019-04-07 14:54:09,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:54:09,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:54:09,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run23
[2019-04-07 14:54:19,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:54:19,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:54:19,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run23
[2019-04-07 14:54:23,343] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:54:23,344] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:54:23,347] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run23
[2019-04-07 14:54:24,196] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.0469933e-19 1.3051119e-15 2.3939772e-21 2.3869914e-14 1.7914646e-17
 1.0000000e+00 4.2625226e-12 8.5301927e-15], sum to 1.0000
[2019-04-07 14:54:24,196] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9006
[2019-04-07 14:54:24,250] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.0, 69.0, 0.0, 0.0, 24.0, 23.13233893793799, -0.1261536745272148, 0.0, 1.0, 45742.969404266274], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2682000.0000, 
sim time next is 2683800.0000, 
raw observation next is [-10.0, 72.5, 0.0, 0.0, 24.0, 23.0185545019453, -0.1678581188983196, 0.0, 1.0, 45652.091169951775], 
processed observation next is [1.0, 0.043478260869565216, 0.18559556786703602, 0.725, 0.0, 0.0, 0.5, 0.4182128751621083, 0.4440472937005601, 0.0, 1.0, 0.21739091033310368], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.47515646], dtype=float32), 0.84906524]. 
=============================================
[2019-04-07 14:54:39,351] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5261673e-16 6.1331784e-15 4.5062310e-18 7.4442189e-13 2.7943694e-16
 1.0000000e+00 1.5448520e-09 3.4234443e-13], sum to 1.0000
[2019-04-07 14:54:39,351] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5194
[2019-04-07 14:54:39,393] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 34.0, 166.0, 758.0, 24.0, 23.24125776687294, -0.02436796574963554, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4194000.0000, 
sim time next is 4195800.0000, 
raw observation next is [2.0, 37.0, 214.0, 669.0, 24.0, 23.26945066920132, -0.02140862825455249, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.518005540166205, 0.37, 0.7133333333333334, 0.7392265193370166, 0.5, 0.43912088910010993, 0.49286379058181584, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5310407], dtype=float32), 1.5536996]. 
=============================================
[2019-04-07 14:54:40,421] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.7849551e-18 2.4805897e-16 9.5180438e-22 1.5594461e-14 7.9498224e-17
 1.0000000e+00 1.0067884e-11 2.4533157e-14], sum to 1.0000
[2019-04-07 14:54:40,421] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2985
[2019-04-07 14:54:40,517] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 69.5, 0.0, 0.0, 24.0, 22.97169766204649, -0.1681505151701038, 0.0, 1.0, 47867.40296404795], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 163800.0000, 
sim time next is 165600.0000, 
raw observation next is [-8.4, 71.0, 0.0, 0.0, 24.0, 22.87543435258983, -0.1899784575844363, 0.0, 1.0, 46978.521345671536], 
processed observation next is [1.0, 0.9565217391304348, 0.2299168975069252, 0.71, 0.0, 0.0, 0.5, 0.4062861960491526, 0.43667384747185456, 0.0, 1.0, 0.2237072445031978], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9736054], dtype=float32), -0.80322945]. 
=============================================
[2019-04-07 14:54:40,533] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7069205e-19 2.9891590e-18 1.6633588e-22 5.4752856e-16 1.7558431e-17
 1.0000000e+00 4.1214203e-13 6.7684296e-16], sum to 1.0000
[2019-04-07 14:54:40,534] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1313
[2019-04-07 14:54:40,596] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 79.0, 0.0, 0.0, 24.0, 23.31013220785421, -0.1318254842210017, 0.0, 1.0, 41582.5266378877], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 871200.0000, 
sim time next is 873000.0000, 
raw observation next is [-1.7, 79.0, 0.0, 0.0, 24.0, 23.38572384236971, -0.1380504995941051, 0.0, 1.0, 34400.70121050938], 
processed observation next is [1.0, 0.08695652173913043, 0.4155124653739613, 0.79, 0.0, 0.0, 0.5, 0.44881032019747585, 0.453983166801965, 0.0, 1.0, 0.16381286290718752], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0802312], dtype=float32), 0.8314204]. 
=============================================
[2019-04-07 14:54:40,618] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[101.775024]
 [101.66069 ]
 [101.007164]
 [100.94774 ]
 [100.65524 ]], R is [[102.02108002]
 [102.00086975]
 [101.98086548]
 [101.96105957]
 [101.94145203]].
[2019-04-07 14:54:47,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:54:47,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:54:47,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run23
[2019-04-07 14:54:47,737] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:54:47,737] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:54:47,740] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run23
[2019-04-07 14:55:00,666] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.7712226e-19 9.2132700e-17 8.6322275e-22 5.9325188e-15 7.3646189e-18
 1.0000000e+00 1.5302957e-11 8.9569397e-15], sum to 1.0000
[2019-04-07 14:55:00,670] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2641
[2019-04-07 14:55:00,762] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 77.0, 100.0, 675.0, 24.0, 24.54428334643686, 0.1108185894016948, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3749400.0000, 
sim time next is 3751200.0000, 
raw observation next is [-3.0, 77.0, 105.5, 722.0, 24.0, 24.69038272221522, 0.1503818252244234, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.77, 0.3516666666666667, 0.7977900552486188, 0.5, 0.5575318935179349, 0.5501272750748077, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2660575], dtype=float32), 1.0320197]. 
=============================================
[2019-04-07 14:55:00,781] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4495643e-21 3.8429633e-17 1.6641585e-22 1.2483382e-15 2.1438897e-17
 1.0000000e+00 1.6316936e-11 1.8040997e-14], sum to 1.0000
[2019-04-07 14:55:00,782] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3387
[2019-04-07 14:55:00,823] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.15, 87.0, 0.0, 0.0, 24.0, 23.2941165069031, -0.08596509248126638, 0.0, 1.0, 43093.48934102088], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 73800.0000, 
sim time next is 75600.0000, 
raw observation next is [1.6, 85.0, 0.0, 0.0, 24.0, 23.3150988596357, -0.08364173009662317, 0.0, 1.0, 42484.464427158004], 
processed observation next is [0.0, 0.9130434782608695, 0.5069252077562327, 0.85, 0.0, 0.0, 0.5, 0.4429249049696417, 0.4721194233011256, 0.0, 1.0, 0.20230697346265716], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.13080437], dtype=float32), 0.2351011]. 
=============================================
[2019-04-07 14:55:01,924] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6224706e-18 3.1946075e-16 2.0712841e-22 3.8155073e-14 2.5005877e-17
 1.0000000e+00 1.8771805e-10 1.3387108e-13], sum to 1.0000
[2019-04-07 14:55:01,925] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1612
[2019-04-07 14:55:01,965] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 59.0, 115.0, 810.0, 24.0, 24.72900800506283, 0.2228163665224329, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3497400.0000, 
sim time next is 3499200.0000, 
raw observation next is [2.0, 57.0, 115.5, 816.5, 24.0, 24.5868992165373, 0.226797455476688, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.518005540166205, 0.57, 0.385, 0.9022099447513812, 0.5, 0.5489082680447751, 0.5755991518255626, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.974946], dtype=float32), -0.17394082]. 
=============================================
[2019-04-07 14:55:19,182] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:55:19,183] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:55:19,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run23
[2019-04-07 14:55:19,597] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4592581e-18 1.8849244e-16 8.1138106e-21 8.7298824e-15 6.8668617e-17
 1.0000000e+00 1.7023721e-11 1.4613926e-13], sum to 1.0000
[2019-04-07 14:55:19,598] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6750
[2019-04-07 14:55:19,790] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.0, 58.0, 48.5, 314.5, 24.0, 23.71156410504513, -0.0197063992490836, 1.0, 1.0, 3123.3262232534084], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3916800.0000, 
sim time next is 3918600.0000, 
raw observation next is [-8.0, 55.5, 91.0, 466.0, 24.0, 23.86794924232102, 0.05560153817836024, 1.0, 1.0, 41599.65319035545], 
processed observation next is [1.0, 0.34782608695652173, 0.24099722991689754, 0.555, 0.30333333333333334, 0.5149171270718232, 0.5, 0.48899577019341844, 0.5185338460594534, 1.0, 1.0, 0.19809358662074023], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7399297], dtype=float32), 0.08875114]. 
=============================================
[2019-04-07 14:55:21,256] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.2658685e-19 1.0340952e-16 2.5911344e-21 2.6781264e-14 2.8481344e-17
 1.0000000e+00 7.0255537e-12 1.7694608e-15], sum to 1.0000
[2019-04-07 14:55:21,257] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9100
[2019-04-07 14:55:21,330] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 79.0, 0.0, 0.0, 24.0, 22.51876535757698, -0.2898031404646753, 0.0, 1.0, 47880.86253628895], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1832400.0000, 
sim time next is 1834200.0000, 
raw observation next is [-6.2, 79.0, 0.0, 0.0, 24.0, 22.5291524351861, -0.2879235331303679, 0.0, 1.0, 47939.577553967334], 
processed observation next is [0.0, 0.21739130434782608, 0.2908587257617729, 0.79, 0.0, 0.0, 0.5, 0.37742936959884155, 0.404025488956544, 0.0, 1.0, 0.22828370263793968], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5500892], dtype=float32), 0.8807562]. 
=============================================
[2019-04-07 14:55:33,006] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7035377e-19 1.3372171e-18 9.2022833e-23 6.9092709e-17 2.9341627e-18
 1.0000000e+00 3.2252872e-12 1.2523638e-15], sum to 1.0000
[2019-04-07 14:55:33,016] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9396
[2019-04-07 14:55:33,043] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.15, 67.5, 0.0, 0.0, 24.0, 24.05968748486412, 0.1405066071968682, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4422600.0000, 
sim time next is 4424400.0000, 
raw observation next is [3.8, 68.0, 0.0, 0.0, 24.0, 23.88832172575364, 0.09200764322055865, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.5678670360110805, 0.68, 0.0, 0.0, 0.5, 0.4906934771461368, 0.5306692144068529, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.54364973], dtype=float32), 0.27288505]. 
=============================================
[2019-04-07 14:55:33,395] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3439258e-19 7.3136655e-18 1.2603816e-23 2.1751781e-16 7.1121816e-19
 1.0000000e+00 7.4137685e-13 2.5045902e-15], sum to 1.0000
[2019-04-07 14:55:33,395] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1348
[2019-04-07 14:55:33,412] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.55, 70.0, 0.0, 0.0, 24.0, 24.21641742217381, 0.2190207874698238, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1625400.0000, 
sim time next is 1627200.0000, 
raw observation next is [7.7, 74.0, 0.0, 0.0, 24.0, 23.94439077088418, 0.1789770420408761, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.6759002770083103, 0.74, 0.0, 0.0, 0.5, 0.49536589757368166, 0.5596590140136254, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.624179], dtype=float32), 0.4114834]. 
=============================================
[2019-04-07 14:55:33,966] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.9822992e-20 2.7255578e-17 1.0422746e-21 4.3708269e-16 1.2514784e-18
 1.0000000e+00 7.1056715e-12 9.9430942e-16], sum to 1.0000
[2019-04-07 14:55:33,966] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3634
[2019-04-07 14:55:34,028] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.1, 64.0, 0.0, 0.0, 24.0, 23.55938374297265, -0.006342750981502175, 0.0, 1.0, 33824.51350030176], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4584600.0000, 
sim time next is 4586400.0000, 
raw observation next is [-0.2, 65.0, 0.0, 0.0, 24.0, 23.57257301308768, -0.002907918362704371, 0.0, 1.0, 26132.26609658479], 
processed observation next is [1.0, 0.08695652173913043, 0.4570637119113574, 0.65, 0.0, 0.0, 0.5, 0.46438108442397336, 0.49903069387909854, 0.0, 1.0, 0.12443936236468947], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17383102], dtype=float32), 0.7776924]. 
=============================================
[2019-04-07 14:55:35,253] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.3573999e-20 4.8569390e-18 1.4819573e-23 3.4608301e-15 2.4594530e-18
 1.0000000e+00 1.4463746e-12 2.9182271e-15], sum to 1.0000
[2019-04-07 14:55:35,253] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0845
[2019-04-07 14:55:35,328] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 80.0, 0.0, 0.0, 24.0, 23.50750071384315, -0.005550045009981209, 0.0, 1.0, 59436.42077483015], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 961200.0000, 
sim time next is 963000.0000, 
raw observation next is [7.7, 81.5, 0.0, 0.0, 24.0, 23.60096428468083, 0.0064833891022379, 0.0, 1.0, 24709.2401620852], 
processed observation next is [1.0, 0.13043478260869565, 0.6759002770083103, 0.815, 0.0, 0.0, 0.5, 0.4667470237234026, 0.502161129700746, 0.0, 1.0, 0.1176630483908819], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.74534434], dtype=float32), 0.44989663]. 
=============================================
[2019-04-07 14:55:35,332] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[110.026535]
 [109.79033 ]
 [110.1421  ]
 [110.66287 ]
 [110.49638 ]], R is [[109.67814636]
 [109.58136749]
 [109.48555756]
 [109.39070129]
 [109.29679871]].
[2019-04-07 14:55:39,413] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-07 14:55:39,429] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:55:39,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:55:39,449] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 14:55:39,459] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 14:55:39,465] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:55:39,471] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:55:40,310] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run51
[2019-04-07 14:55:40,325] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run51
[2019-04-07 14:55:40,325] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run51
[2019-04-07 14:58:04,856] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 14:58:26,010] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 14:58:30,683] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 14:58:31,705] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1000000, evaluation results [1000000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 14:58:46,026] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7886476e-21 2.2789475e-18 1.5205003e-25 2.8328683e-16 7.4379338e-20
 1.0000000e+00 1.6288210e-14 4.6927918e-16], sum to 1.0000
[2019-04-07 14:58:46,026] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4545
[2019-04-07 14:58:46,076] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.25, 94.5, 0.0, 0.0, 24.0, 23.80381246280891, 0.1112200837807936, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1665000.0000, 
sim time next is 1666800.0000, 
raw observation next is [5.0, 92.0, 0.0, 0.0, 24.0, 23.74505391876795, 0.09456555702512341, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.6011080332409973, 0.92, 0.0, 0.0, 0.5, 0.4787544932306626, 0.5315218523417078, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.56223494], dtype=float32), -1.1877602]. 
=============================================
[2019-04-07 14:58:48,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:58:48,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:58:48,500] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run23
[2019-04-07 14:58:52,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:58:52,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:58:52,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run23
[2019-04-07 14:58:54,334] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:58:54,334] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:58:54,354] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run23
[2019-04-07 14:58:56,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:58:56,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:58:56,440] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run23
[2019-04-07 14:59:03,290] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:59:03,290] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:59:03,294] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run23
[2019-04-07 14:59:11,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:59:11,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:59:11,312] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run23
[2019-04-07 14:59:11,618] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8998927e-17 2.8515508e-15 1.2316665e-19 5.3744918e-14 1.9994784e-15
 1.0000000e+00 5.9323955e-11 6.5126967e-13], sum to 1.0000
[2019-04-07 14:59:11,618] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1544
[2019-04-07 14:59:11,910] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 80.0, 190.0, 36.0, 24.0, 23.70128749196848, -0.09203181175802273, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 124200.0000, 
sim time next is 126000.0000, 
raw observation next is [-7.8, 86.0, 187.0, 24.5, 24.0, 23.78003166849918, -0.02303123493919927, 1.0, 1.0, 112474.13123757202], 
processed observation next is [1.0, 0.4782608695652174, 0.24653739612188366, 0.86, 0.6233333333333333, 0.02707182320441989, 0.5, 0.48166930570826505, 0.4923229216869336, 1.0, 1.0, 0.5355911011312953], 
reward next is 0.7501, 
noisyNet noise sample is [array([0.8513061], dtype=float32), 0.6390784]. 
=============================================
[2019-04-07 14:59:11,914] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[93.20086 ]
 [92.827934]
 [92.578865]
 [93.220665]
 [93.947815]], R is [[95.07241821]
 [95.12169647]
 [95.17047882]
 [95.21877289]
 [95.2665863 ]].
[2019-04-07 14:59:11,933] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 14:59:11,933] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 14:59:11,936] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run23
[2019-04-07 14:59:53,348] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.2160392e-18 1.9694107e-15 1.7209273e-20 9.0858861e-15 4.4810886e-16
 1.0000000e+00 6.1882895e-11 4.6383562e-13], sum to 1.0000
[2019-04-07 14:59:53,348] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5425
[2019-04-07 14:59:53,491] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.75, 59.5, 182.0, 93.0, 24.0, 23.04429615403912, -0.1806663228822614, 0.0, 1.0, 24658.044012999744], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 653400.0000, 
sim time next is 655200.0000, 
raw observation next is [-1.2, 60.0, 131.5, 74.5, 24.0, 23.04516933755869, -0.1928349710296634, 0.0, 1.0, 22076.14599531762], 
processed observation next is [0.0, 0.6086956521739131, 0.42936288088642666, 0.6, 0.43833333333333335, 0.08232044198895028, 0.5, 0.4204307781298908, 0.43572167632344555, 0.0, 1.0, 0.10512450473960772], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5452117], dtype=float32), 0.21963225]. 
=============================================
[2019-04-07 14:59:58,110] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.95211677e-17 1.11434350e-14 3.13549118e-19 1.02688294e-14
 8.75976262e-17 1.00000000e+00 8.41044803e-11 3.13072620e-13], sum to 1.0000
[2019-04-07 14:59:58,112] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9809
[2019-04-07 14:59:58,178] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.0, 28.0, 106.0, 713.0, 24.0, 23.90044161560645, 0.05045746977104254, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3664800.0000, 
sim time next is 3666600.0000, 
raw observation next is [11.5, 26.0, 111.0, 763.0, 24.0, 23.89561474646973, 0.0692391600053541, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.7811634349030472, 0.26, 0.37, 0.8430939226519337, 0.5, 0.4913012288724774, 0.5230797200017847, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.55228275], dtype=float32), -0.2066779]. 
=============================================
[2019-04-07 15:00:01,570] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.14158512e-19 1.41438991e-16 4.45120913e-22 4.59315508e-14
 1.07680354e-16 1.00000000e+00 5.75412851e-12 3.63065121e-14], sum to 1.0000
[2019-04-07 15:00:01,571] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3591
[2019-04-07 15:00:01,812] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 14.5, 0.0, 24.0, 23.10858624308832, -0.111984876586471, 0.0, 1.0, 37672.487729873676], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1789200.0000, 
sim time next is 1791000.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 24.0, 23.09958209542033, -0.1186082721523953, 0.0, 1.0, 42713.67300686961], 
processed observation next is [0.0, 0.7391304347826086, 0.3545706371191136, 0.82, 0.0, 0.0, 0.5, 0.4249651746183609, 0.4604639092825349, 0.0, 1.0, 0.20339844288985529], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1483314], dtype=float32), -1.5830094]. 
=============================================
[2019-04-07 15:00:01,817] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[97.0614 ]
 [97.35311]
 [97.34188]
 [97.31548]
 [97.37104]], R is [[96.80911255]
 [96.84101868]
 [96.872612  ]
 [96.90388489]
 [96.93484497]].
[2019-04-07 15:00:06,413] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4830872e-17 1.5509824e-15 1.1631235e-20 1.1906326e-14 3.9825988e-16
 1.0000000e+00 7.3745367e-12 1.5521619e-13], sum to 1.0000
[2019-04-07 15:00:06,413] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6889
[2019-04-07 15:00:06,466] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 24.0, 23.17563605861469, -0.1619398054971332, 0.0, 1.0, 39695.240770442055], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3031200.0000, 
sim time next is 3033000.0000, 
raw observation next is [-5.5, 74.0, 0.0, 0.0, 24.0, 23.11096445565462, -0.1804546697317577, 0.0, 1.0, 39952.95220567385], 
processed observation next is [0.0, 0.08695652173913043, 0.3102493074792244, 0.74, 0.0, 0.0, 0.5, 0.4259137046378851, 0.4398484434227474, 0.0, 1.0, 0.19025215336035167], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4638722], dtype=float32), -0.14438428]. 
=============================================
[2019-04-07 15:00:06,470] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[94.479034]
 [94.53339 ]
 [94.06883 ]
 [93.941505]
 [93.692635]], R is [[94.73622131]
 [94.78885651]
 [94.84096527]
 [94.89255524]
 [94.94363403]].
[2019-04-07 15:00:06,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5890459e-17 3.0612872e-15 7.7708352e-21 2.5334877e-13 3.5984980e-17
 1.0000000e+00 3.2319969e-10 4.4167896e-14], sum to 1.0000
[2019-04-07 15:00:06,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2459
[2019-04-07 15:00:07,079] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 83.0, 113.5, 270.0, 24.0, 23.13273101365264, -0.1036773107634101, 0.0, 1.0, 21293.64384140423], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 572400.0000, 
sim time next is 574200.0000, 
raw observation next is [-1.2, 83.0, 100.0, 73.0, 24.0, 23.07966411690581, -0.1145209109019648, 0.0, 1.0, 41268.961855148664], 
processed observation next is [0.0, 0.6521739130434783, 0.42936288088642666, 0.83, 0.3333333333333333, 0.08066298342541436, 0.5, 0.42330534307548423, 0.46182636303267843, 0.0, 1.0, 0.1965188659768984], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.76383334], dtype=float32), 1.4558258]. 
=============================================
[2019-04-07 15:00:31,189] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.2573773e-20 2.6929101e-17 3.7427626e-23 4.8959877e-17 2.0318914e-19
 1.0000000e+00 3.3234299e-13 2.5376625e-16], sum to 1.0000
[2019-04-07 15:00:31,190] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0189
[2019-04-07 15:00:31,266] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.5, 82.0, 0.0, 0.0, 24.0, 23.73726623292919, 0.1388353702136521, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1551600.0000, 
sim time next is 1553400.0000, 
raw observation next is [5.25, 82.0, 0.0, 0.0, 24.0, 23.73415229218964, 0.103882119737941, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.60803324099723, 0.82, 0.0, 0.0, 0.5, 0.47784602434913676, 0.5346273732459803, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.45007047], dtype=float32), -1.3558072]. 
=============================================
[2019-04-07 15:00:32,463] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4099287e-17 1.0590630e-15 4.7561319e-19 8.1502276e-14 5.5445380e-17
 1.0000000e+00 4.0182573e-11 2.2479722e-14], sum to 1.0000
[2019-04-07 15:00:32,463] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6681
[2019-04-07 15:00:32,531] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 32.0, 287.0, 24.0, 23.25817891869686, -0.1095358024971488, 0.0, 1.0, 18681.17194629402], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3085200.0000, 
sim time next is 3087000.0000, 
raw observation next is [-0.3, 77.0, 7.0, 88.0, 24.0, 23.14607163318678, -0.1379812639229286, 0.0, 1.0, 40049.25965658308], 
processed observation next is [0.0, 0.7391304347826086, 0.4542936288088643, 0.77, 0.023333333333333334, 0.09723756906077348, 0.5, 0.42883930276556487, 0.45400624535902384, 0.0, 1.0, 0.19071076026944325], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.21699345], dtype=float32), -1.1642034]. 
=============================================
[2019-04-07 15:00:32,540] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[90.16562 ]
 [89.230064]
 [88.68177 ]
 [88.87748 ]
 [89.236275]], R is [[91.45225525]
 [91.53773499]
 [91.62236023]
 [91.70613861]
 [91.78907776]].
[2019-04-07 15:00:33,116] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6604205e-18 6.8881423e-16 1.6962902e-20 1.2384541e-14 9.0627536e-17
 1.0000000e+00 2.5252456e-11 1.9335534e-14], sum to 1.0000
[2019-04-07 15:00:33,116] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0579
[2019-04-07 15:00:33,294] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.7, 100.0, 78.0, 0.0, 24.0, 22.37934695452884, 0.004148571123146219, 0.0, 1.0, 72737.69624129355], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1247400.0000, 
sim time next is 1249200.0000, 
raw observation next is [14.4, 100.0, 86.5, 0.0, 24.0, 23.11451879754863, 0.07183951664985282, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.8614958448753465, 1.0, 0.28833333333333333, 0.0, 0.5, 0.42620989979571916, 0.5239465055499509, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.74523395], dtype=float32), -0.16935791]. 
=============================================
[2019-04-07 15:00:39,911] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-07 15:00:39,914] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:00:39,914] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:00:39,914] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:00:39,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:00:39,915] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:00:39,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:00:39,922] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run52
[2019-04-07 15:00:39,944] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run52
[2019-04-07 15:00:39,962] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run52
[2019-04-07 15:03:01,409] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 15:03:21,455] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 15:03:26,554] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 15:03:27,577] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1020000, evaluation results [1020000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 15:03:43,346] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.1183390e-20 6.7117294e-18 4.8370826e-25 4.8225493e-16 6.4814209e-20
 1.0000000e+00 1.1633428e-13 5.1756169e-16], sum to 1.0000
[2019-04-07 15:03:43,349] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2181
[2019-04-07 15:03:43,422] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 24.0, 23.40698692262767, 0.03978153417993907, 0.0, 1.0, 85076.17157495763], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3211200.0000, 
sim time next is 3213000.0000, 
raw observation next is [-1.5, 100.0, 0.0, 0.0, 24.0, 23.39026181034146, 0.07338177778775697, 0.0, 1.0, 78767.00004753216], 
processed observation next is [1.0, 0.17391304347826086, 0.4210526315789474, 1.0, 0.0, 0.0, 0.5, 0.4491884841951217, 0.524460592595919, 0.0, 1.0, 0.375080952607296], 
reward next is 0.9106, 
noisyNet noise sample is [array([0.3767732], dtype=float32), 2.2257864]. 
=============================================
[2019-04-07 15:03:43,433] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[109.59041]
 [109.19377]
 [109.62883]
 [110.00829]
 [109.79153]], R is [[109.31725311]
 [109.10467529]
 [109.0136261 ]
 [108.92349243]
 [108.83425903]].
[2019-04-07 15:03:47,690] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.8499361e-19 9.0662759e-18 4.7004659e-21 1.7883733e-15 1.0895999e-17
 1.0000000e+00 9.8268997e-12 5.2716356e-14], sum to 1.0000
[2019-04-07 15:03:47,691] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1722
[2019-04-07 15:03:47,776] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.45, 87.0, 0.0, 0.0, 24.0, 23.30929909980819, -0.03475461679472395, 0.0, 1.0, 48411.4692514652], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1751400.0000, 
sim time next is 1753200.0000, 
raw observation next is [-1.7, 87.0, 0.0, 0.0, 24.0, 23.2814897905749, -0.04003206957656433, 0.0, 1.0, 45296.26042230174], 
processed observation next is [0.0, 0.30434782608695654, 0.4155124653739613, 0.87, 0.0, 0.0, 0.5, 0.4401241492145749, 0.48665597680781186, 0.0, 1.0, 0.21569647820143686], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.35261354], dtype=float32), 0.35778156]. 
=============================================
[2019-04-07 15:03:48,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:03:48,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:03:48,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run24
[2019-04-07 15:04:04,377] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.1620156e-16 6.7540154e-15 6.2909116e-18 5.3665557e-13 3.5022265e-15
 1.0000000e+00 1.0435934e-10 3.5965035e-12], sum to 1.0000
[2019-04-07 15:04:04,378] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6586
[2019-04-07 15:04:04,443] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 37.0, 0.0, 0.0, 24.0, 23.40713532087729, -0.0237425371841503, 0.0, 1.0, 79445.0420280568], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4057200.0000, 
sim time next is 4059000.0000, 
raw observation next is [-6.0, 37.0, 0.0, 0.0, 24.0, 23.45878825029294, -0.03783985355857514, 0.0, 1.0, 24821.703399372967], 
processed observation next is [1.0, 1.0, 0.296398891966759, 0.37, 0.0, 0.0, 0.5, 0.45489902085774503, 0.48738671548047496, 0.0, 1.0, 0.11819858761606175], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4911742], dtype=float32), -2.220211]. 
=============================================
[2019-04-07 15:04:04,449] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[88.78875]
 [88.58357]
 [88.22854]
 [87.91585]
 [88.13079]], R is [[88.49528503]
 [88.51773834]
 [88.63256073]
 [88.74623871]
 [88.85877991]].
[2019-04-07 15:04:14,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:04:14,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:04:14,390] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run24
[2019-04-07 15:04:23,342] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:04:23,342] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:04:23,347] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run24
[2019-04-07 15:04:34,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:04:34,350] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:04:34,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run24
[2019-04-07 15:04:44,110] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:04:44,110] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:04:44,113] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run24
[2019-04-07 15:04:49,774] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:04:49,774] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:04:49,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run24
[2019-04-07 15:05:02,707] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7598687e-20 8.3999174e-18 1.6226522e-23 1.6779077e-15 1.7933919e-18
 1.0000000e+00 7.3544151e-14 3.4639190e-16], sum to 1.0000
[2019-04-07 15:05:02,707] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1391
[2019-04-07 15:05:02,783] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 72.0, 0.0, 0.0, 24.0, 23.22819432671861, -0.1428462483963749, 0.0, 1.0, 46830.459146841284], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 882000.0000, 
sim time next is 883800.0000, 
raw observation next is [-0.3, 72.0, 0.0, 0.0, 24.0, 23.41200080181448, -0.1357251526307599, 0.0, 1.0, 33100.73068565825], 
processed observation next is [1.0, 0.21739130434782608, 0.4542936288088643, 0.72, 0.0, 0.0, 0.5, 0.45100006681787325, 0.45475828245641337, 0.0, 1.0, 0.1576225270745631], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.58798176], dtype=float32), 1.306481]. 
=============================================
[2019-04-07 15:05:05,535] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2936432e-17 1.0469401e-15 3.3508004e-20 2.2177742e-13 1.3380713e-15
 1.0000000e+00 2.6856001e-10 4.7184858e-13], sum to 1.0000
[2019-04-07 15:05:05,535] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8497
[2019-04-07 15:05:05,666] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 56.5, 99.0, 635.0, 24.0, 23.6136885062966, -0.06617148965678225, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3058200.0000, 
sim time next is 3060000.0000, 
raw observation next is [-4.0, 54.0, 102.5, 697.0, 24.0, 23.49887860237084, -0.07593976193107176, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3518005540166205, 0.54, 0.3416666666666667, 0.7701657458563536, 0.5, 0.4582398835309034, 0.47468674602297606, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.04936677], dtype=float32), 0.16100602]. 
=============================================
[2019-04-07 15:05:05,675] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[91.81106]
 [92.03073]
 [92.25317]
 [91.52298]
 [91.51791]], R is [[91.46630096]
 [91.55163574]
 [91.63612366]
 [91.6186676 ]
 [91.70248413]].
[2019-04-07 15:05:07,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:05:07,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:05:07,018] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run24
[2019-04-07 15:05:07,767] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6401396e-19 5.3350804e-17 7.3256289e-22 1.3523368e-15 2.5689264e-17
 1.0000000e+00 1.6981359e-12 7.1085377e-14], sum to 1.0000
[2019-04-07 15:05:07,768] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8861
[2019-04-07 15:05:07,846] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 48.0, 0.0, 0.0, 24.0, 23.69745646722181, -0.03432029057891978, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5031000.0000, 
sim time next is 5032800.0000, 
raw observation next is [-1.0, 46.0, 0.0, 0.0, 24.0, 23.55055592115938, -0.05953864368413472, 0.0, 1.0, 41173.514921442926], 
processed observation next is [1.0, 0.2608695652173913, 0.4349030470914128, 0.46, 0.0, 0.0, 0.5, 0.4625463267632816, 0.48015378543862175, 0.0, 1.0, 0.19606435676877584], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3705566], dtype=float32), -1.3179485]. 
=============================================
[2019-04-07 15:05:11,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:05:11,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:05:11,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run24
[2019-04-07 15:05:13,167] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1696555e-19 4.4443997e-17 1.5061061e-21 1.4888913e-14 1.7552930e-18
 1.0000000e+00 2.1377223e-11 9.8795814e-15], sum to 1.0000
[2019-04-07 15:05:13,167] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3996
[2019-04-07 15:05:13,230] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.5, 74.0, 0.0, 0.0, 24.0, 23.41076669355898, -0.09543879802822074, 0.0, 1.0, 48526.05007673744], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3385800.0000, 
sim time next is 3387600.0000, 
raw observation next is [-5.0, 71.0, 0.0, 0.0, 24.0, 23.35333801102701, -0.09309647061161619, 0.0, 1.0, 50729.94946605765], 
processed observation next is [1.0, 0.21739130434782608, 0.32409972299168976, 0.71, 0.0, 0.0, 0.5, 0.44611150091891744, 0.46896784312946127, 0.0, 1.0, 0.24157118793360788], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.27995035], dtype=float32), -1.3830215]. 
=============================================
[2019-04-07 15:05:33,616] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-07 15:05:33,622] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:05:33,623] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:05:33,626] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run53
[2019-04-07 15:05:33,652] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:05:33,654] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:05:33,658] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run53
[2019-04-07 15:05:33,675] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:05:33,676] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:05:33,680] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run53
[2019-04-07 15:07:58,494] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 15:08:18,682] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 15:08:23,710] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 15:08:24,732] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1040000, evaluation results [1040000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 15:08:25,405] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0110292e-18 6.9955439e-17 1.1731087e-21 5.7806966e-15 5.8911532e-17
 1.0000000e+00 9.3462210e-11 6.0071597e-14], sum to 1.0000
[2019-04-07 15:08:25,406] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7483
[2019-04-07 15:08:25,428] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 42.0, 115.0, 823.5, 24.0, 23.63000440459617, 0.05187720811838953, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3675600.0000, 
sim time next is 3677400.0000, 
raw observation next is [5.5, 42.5, 113.0, 818.0, 24.0, 23.6160515191607, 0.05370392505310487, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.6149584487534627, 0.425, 0.37666666666666665, 0.9038674033149171, 0.5, 0.4680042932633916, 0.517901308351035, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0985107], dtype=float32), -0.548599]. 
=============================================
[2019-04-07 15:08:26,534] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7240316e-17 3.4528636e-16 2.7603444e-20 4.4551853e-14 3.0813921e-15
 1.0000000e+00 2.6993685e-10 2.2828937e-14], sum to 1.0000
[2019-04-07 15:08:26,535] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9001
[2019-04-07 15:08:26,599] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 68.0, 0.0, 0.0, 24.0, 23.43961000491245, -0.02974631094254452, 0.0, 1.0, 26381.83626731716], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3555000.0000, 
sim time next is 3556800.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 24.0, 23.36260289893148, -0.02737608266016119, 0.0, 1.0, 66737.22215724974], 
processed observation next is [0.0, 0.17391304347826086, 0.3518005540166205, 0.71, 0.0, 0.0, 0.5, 0.44688357491095676, 0.4908746391132796, 0.0, 1.0, 0.3177962959869035], 
reward next is 0.9679, 
noisyNet noise sample is [array([-1.7696306], dtype=float32), 0.29682258]. 
=============================================
[2019-04-07 15:08:27,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:08:27,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:08:27,922] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run24
[2019-04-07 15:08:37,699] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.3496808e-17 1.4306209e-15 2.5147798e-20 2.0570453e-13 3.1026467e-15
 1.0000000e+00 7.5567996e-11 2.2624349e-13], sum to 1.0000
[2019-04-07 15:08:37,700] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8725
[2019-04-07 15:08:37,892] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 76.0, 29.0, 0.0, 24.0, 23.40379348058244, -0.2005983063478224, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 721800.0000, 
sim time next is 723600.0000, 
raw observation next is [-2.3, 76.0, 65.0, 24.5, 24.0, 23.59013744212056, -0.1759163312962928, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3988919667590028, 0.76, 0.21666666666666667, 0.02707182320441989, 0.5, 0.4658447868433801, 0.44136122290123575, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6683995], dtype=float32), -1.9107696]. 
=============================================
[2019-04-07 15:08:39,953] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.7471364e-18 2.1983431e-16 1.0258109e-20 1.6176635e-13 9.3550339e-18
 1.0000000e+00 4.3520517e-12 1.9924936e-14], sum to 1.0000
[2019-04-07 15:08:39,954] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9849
[2019-04-07 15:08:40,027] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 60.0, 117.0, 828.5, 24.0, 24.76092826504495, 0.1071125314151607, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3844800.0000, 
sim time next is 3846600.0000, 
raw observation next is [0.0, 55.5, 117.0, 835.0, 24.0, 24.75352381043262, 0.2439718401687331, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.46260387811634357, 0.555, 0.39, 0.9226519337016574, 0.5, 0.5627936508693848, 0.5813239467229111, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.96752286], dtype=float32), 0.24061264]. 
=============================================
[2019-04-07 15:08:57,789] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0662847e-18 7.2673955e-16 1.1162881e-21 1.0634235e-14 6.8837558e-16
 1.0000000e+00 2.3666222e-11 1.0869577e-13], sum to 1.0000
[2019-04-07 15:08:57,789] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2084
[2019-04-07 15:08:57,887] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 51.5, 0.0, 0.0, 24.0, 23.37907278149756, -0.103659306688145, 0.0, 1.0, 40413.06868353392], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4174200.0000, 
sim time next is 4176000.0000, 
raw observation next is [-5.0, 54.0, 46.0, 244.0, 24.0, 23.30831133420892, -0.07870354085651167, 0.0, 1.0, 42541.54802797427], 
processed observation next is [0.0, 0.34782608695652173, 0.32409972299168976, 0.54, 0.15333333333333332, 0.2696132596685083, 0.5, 0.4423592778507433, 0.4737654863811627, 0.0, 1.0, 0.2025788001332108], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6651222], dtype=float32), -0.8629196]. 
=============================================
[2019-04-07 15:08:57,904] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[89.56485 ]
 [89.9078  ]
 [90.25454 ]
 [90.578964]
 [90.61286 ]], R is [[90.215065  ]
 [90.31291199]
 [90.40978241]
 [90.5056839 ]
 [90.60063171]].
[2019-04-07 15:09:01,290] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7282192e-19 1.6478259e-18 2.7619832e-23 3.6708740e-16 1.4962302e-18
 1.0000000e+00 1.1944444e-11 2.6443921e-14], sum to 1.0000
[2019-04-07 15:09:01,291] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4451
[2019-04-07 15:09:01,335] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.2, 96.0, 0.0, 0.0, 24.0, 23.47598714787343, 0.00750651284925891, 0.0, 1.0, 51183.11739328469], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1485000.0000, 
sim time next is 1486800.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 24.0, 23.4774743629754, 0.01168818779231323, 0.0, 1.0, 39783.76068118694], 
processed observation next is [1.0, 0.21739130434782608, 0.5235457063711911, 0.96, 0.0, 0.0, 0.5, 0.45645619691461664, 0.5038960625974377, 0.0, 1.0, 0.18944647943422352], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.624688], dtype=float32), 1.1175046]. 
=============================================
[2019-04-07 15:09:02,856] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7662174e-18 2.3869423e-17 6.2792912e-23 8.1303186e-15 1.7089449e-17
 1.0000000e+00 6.9689397e-12 9.1505130e-15], sum to 1.0000
[2019-04-07 15:09:02,856] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5828
[2019-04-07 15:09:03,025] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 91.0, 24.0, 18.0, 24.0, 23.65540692874526, -0.121442135309188, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2275200.0000, 
sim time next is 2277000.0000, 
raw observation next is [-8.95, 89.0, 45.0, 16.0, 24.0, 23.76135805450556, -0.09166960434340238, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.21468144044321333, 0.89, 0.15, 0.017679558011049725, 0.5, 0.4801131712087967, 0.4694434652188659, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5346953], dtype=float32), 0.3132178]. 
=============================================
[2019-04-07 15:09:03,051] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[97.4418  ]
 [97.15182 ]
 [95.362114]
 [95.689606]
 [95.98769 ]], R is [[97.59632111]
 [97.62036133]
 [97.21630096]
 [97.24414062]
 [97.271698  ]].
[2019-04-07 15:09:10,342] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.4026596e-21 4.8926430e-18 9.7256626e-24 3.2846164e-17 5.8272238e-19
 1.0000000e+00 1.3005062e-13 6.7664380e-17], sum to 1.0000
[2019-04-07 15:09:10,342] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6281
[2019-04-07 15:09:10,414] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.35, 92.0, 0.0, 0.0, 24.0, 23.45828956030094, 0.01761432942728905, 0.0, 1.0, 63821.55021228755], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1463400.0000, 
sim time next is 1465200.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 24.0, 23.4123610726655, 0.06013614147585156, 0.0, 1.0, 81839.4625047653], 
processed observation next is [1.0, 1.0, 0.5069252077562327, 0.92, 0.0, 0.0, 0.5, 0.45103008938879174, 0.5200453804919505, 0.0, 1.0, 0.3897117262131681], 
reward next is 0.8960, 
noisyNet noise sample is [array([1.5386107], dtype=float32), 1.457698]. 
=============================================
[2019-04-07 15:09:12,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:09:12,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:09:12,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run24
[2019-04-07 15:09:15,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0091380e-18 7.4019653e-18 1.3375569e-21 2.1077896e-15 3.6612645e-17
 1.0000000e+00 3.7548389e-12 3.9246892e-14], sum to 1.0000
[2019-04-07 15:09:15,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9792
[2019-04-07 15:09:15,669] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 29.0, 0.0, 0.0, 24.0, 24.51579408555131, 0.2336742872371512, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5000400.0000, 
sim time next is 5002200.0000, 
raw observation next is [3.5, 33.0, 0.0, 0.0, 24.0, 24.31882112525057, 0.1913096110302233, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.5595567867036012, 0.33, 0.0, 0.0, 0.5, 0.526568427104214, 0.5637698703434078, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2251664], dtype=float32), 1.8426936]. 
=============================================
[2019-04-07 15:09:18,946] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:09:18,946] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:09:18,952] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run24
[2019-04-07 15:09:19,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:09:19,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:09:19,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run24
[2019-04-07 15:09:20,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:09:20,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:09:20,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run24
[2019-04-07 15:09:29,824] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:09:29,824] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:09:29,828] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run24
[2019-04-07 15:09:29,887] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6667275e-18 3.0125931e-17 7.2710610e-22 7.0500068e-17 9.0377495e-19
 1.0000000e+00 9.6231825e-12 2.1820189e-15], sum to 1.0000
[2019-04-07 15:09:29,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0589
[2019-04-07 15:09:29,955] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 75.0, 0.0, 0.0, 24.0, 23.18966138343941, -0.1243067676543076, 0.0, 1.0, 47908.84417823444], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2242800.0000, 
sim time next is 2244600.0000, 
raw observation next is [-6.45, 76.5, 0.0, 0.0, 24.0, 23.07234521930419, -0.1487172872259057, 0.0, 1.0, 45781.85661876141], 
processed observation next is [1.0, 1.0, 0.28393351800554023, 0.765, 0.0, 0.0, 0.5, 0.4226954349420158, 0.4504275709246981, 0.0, 1.0, 0.21800884104172102], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5158505], dtype=float32), 0.58476424]. 
=============================================
[2019-04-07 15:09:32,296] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0954089e-18 9.3970285e-17 7.7268508e-21 1.1185555e-14 4.1660786e-15
 1.0000000e+00 1.9461687e-12 2.6052972e-14], sum to 1.0000
[2019-04-07 15:09:32,296] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3763
[2019-04-07 15:09:32,364] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 79.0, 0.0, 0.0, 24.0, 22.57964502854515, -0.2938941219849456, 0.0, 1.0, 42792.90940094983], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2181600.0000, 
sim time next is 2183400.0000, 
raw observation next is [-5.9, 77.0, 0.0, 0.0, 24.0, 22.50763517277706, -0.3080519450468728, 0.0, 1.0, 42767.214136072864], 
processed observation next is [1.0, 0.2608695652173913, 0.2991689750692521, 0.77, 0.0, 0.0, 0.5, 0.3756362643980884, 0.3973160183177091, 0.0, 1.0, 0.20365340064796603], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1255635], dtype=float32), 0.06265789]. 
=============================================
[2019-04-07 15:09:33,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:09:33,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:09:33,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run24
[2019-04-07 15:09:33,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0872156e-19 1.8749275e-16 8.2591737e-22 9.0325845e-14 1.0650138e-16
 1.0000000e+00 3.2901867e-12 5.4323268e-15], sum to 1.0000
[2019-04-07 15:09:33,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4618
[2019-04-07 15:09:34,230] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 24.0, 24.0953166175642, -0.07186854908548154, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2050200.0000, 
sim time next is 2052000.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 24.0, 23.25616273655161, -0.08131047674451229, 1.0, 1.0, 51963.3812872353], 
processed observation next is [1.0, 0.782608695652174, 0.3545706371191136, 0.82, 0.0, 0.0, 0.5, 0.43801356137930075, 0.47289650775182923, 1.0, 1.0, 0.24744467279635857], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8187624], dtype=float32), 0.38571286]. 
=============================================
[2019-04-07 15:09:34,234] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[100.41408 ]
 [100.62526 ]
 [100.66542 ]
 [ 99.56735 ]
 [ 99.605225]], R is [[100.39907837]
 [100.3950882 ]
 [100.39113617]
 [100.23052979]
 [100.22822571]].
[2019-04-07 15:09:39,125] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:09:39,125] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:09:39,140] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run24
[2019-04-07 15:10:34,678] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6721065e-16 6.4998618e-14 3.3005001e-20 2.5386540e-13 1.9714027e-15
 1.0000000e+00 4.1299943e-11 1.7608883e-12], sum to 1.0000
[2019-04-07 15:10:34,678] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8887
[2019-04-07 15:10:34,784] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 65.0, 0.0, 0.0, 24.0, 23.27486582566013, -0.1649615760466335, 0.0, 1.0, 55539.53133739789], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 676800.0000, 
sim time next is 678600.0000, 
raw observation next is [-3.1, 67.0, 0.0, 0.0, 24.0, 23.44579172865834, -0.1580748617135473, 0.0, 1.0, 28088.498083954084], 
processed observation next is [0.0, 0.8695652173913043, 0.37673130193905824, 0.67, 0.0, 0.0, 0.5, 0.4538159773881949, 0.44730837942881757, 0.0, 1.0, 0.13375475278073373], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.358076], dtype=float32), -0.6902707]. 
=============================================
[2019-04-07 15:10:37,211] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-07 15:10:37,212] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:10:37,212] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:10:37,213] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:10:37,216] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run54
[2019-04-07 15:10:37,237] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:10:37,249] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run54
[2019-04-07 15:10:37,269] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:10:37,270] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:10:37,277] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run54
[2019-04-07 15:13:03,280] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 15:13:18,369] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 15:13:24,015] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 15:13:25,038] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 1060000, evaluation results [1060000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 15:13:47,953] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0185499e-21 3.3693750e-19 1.3319285e-24 3.0735571e-18 1.2275623e-19
 1.0000000e+00 4.0480213e-14 2.2262429e-16], sum to 1.0000
[2019-04-07 15:13:47,954] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5429
[2019-04-07 15:13:48,004] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.0, 100.0, 103.5, 696.5, 24.0, 24.75520054655412, 0.1862628073286657, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3146400.0000, 
sim time next is 3148200.0000, 
raw observation next is [7.0, 100.0, 108.0, 746.0, 24.0, 25.008828146498, 0.251008187061988, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.6565096952908588, 1.0, 0.36, 0.8243093922651934, 0.5, 0.5840690122081668, 0.5836693956873293, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1335423], dtype=float32), 1.3883113]. 
=============================================
[2019-04-07 15:14:08,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:14:08,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:14:08,272] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run25
[2019-04-07 15:14:23,964] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.35173158e-19 1.03344452e-16 2.27609318e-22 2.00392140e-16
 3.33097361e-18 1.00000000e+00 1.05102385e-11 1.31456617e-14], sum to 1.0000
[2019-04-07 15:14:23,965] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3866
[2019-04-07 15:14:24,005] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 91.0, 0.0, 0.0, 24.0, 23.10914457441788, -0.1343807839508896, 0.0, 1.0, 44326.20134606568], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2073600.0000, 
sim time next is 2075400.0000, 
raw observation next is [-4.5, 91.0, 0.0, 0.0, 24.0, 23.17947872299828, -0.1224393263884614, 0.0, 1.0, 44361.92461295754], 
processed observation next is [1.0, 0.0, 0.3379501385041552, 0.91, 0.0, 0.0, 0.5, 0.4316232269165233, 0.4591868912038462, 0.0, 1.0, 0.21124726006170258], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7509286], dtype=float32), 1.922748]. 
=============================================
[2019-04-07 15:14:25,581] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.6384682e-19 4.1875205e-17 4.2592340e-22 1.1498174e-14 6.2876996e-17
 1.0000000e+00 3.2212297e-12 1.4891376e-15], sum to 1.0000
[2019-04-07 15:14:25,581] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1047
[2019-04-07 15:14:25,640] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 91.0, 0.0, 0.0, 24.0, 22.56604543351315, -0.3044592760154601, 0.0, 1.0, 44396.21157849796], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2264400.0000, 
sim time next is 2266200.0000, 
raw observation next is [-8.9, 91.0, 0.0, 0.0, 24.0, 22.46047732327023, -0.3250481806098179, 0.0, 1.0, 44231.93637598983], 
processed observation next is [1.0, 0.21739130434782608, 0.21606648199445982, 0.91, 0.0, 0.0, 0.5, 0.3717064436058524, 0.391650606463394, 0.0, 1.0, 0.21062826845709445], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6699977], dtype=float32), -1.0642295]. 
=============================================
[2019-04-07 15:14:27,581] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9702335e-18 5.0648155e-16 1.9956623e-21 4.5607673e-14 7.8177098e-17
 1.0000000e+00 9.8143681e-12 6.5888599e-14], sum to 1.0000
[2019-04-07 15:14:27,581] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5525
[2019-04-07 15:14:27,734] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.75, 71.0, 117.0, 0.0, 24.0, 24.24917619645569, -0.02285680332911795, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2197800.0000, 
sim time next is 2199600.0000, 
raw observation next is [-4.5, 71.0, 130.0, 0.0, 24.0, 24.06144890752602, -0.06285641147013508, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.3379501385041552, 0.71, 0.43333333333333335, 0.0, 0.5, 0.5051207422938351, 0.4790478628432883, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.58691907], dtype=float32), -0.9551881]. 
=============================================
[2019-04-07 15:14:39,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:14:39,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:14:39,688] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run25
[2019-04-07 15:14:46,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:14:46,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:14:46,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run25
[2019-04-07 15:14:56,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:14:56,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:14:56,843] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run25
[2019-04-07 15:15:03,177] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1255269e-16 2.0675783e-14 4.0969486e-18 2.6208736e-13 1.4675502e-15
 1.0000000e+00 1.7588996e-10 7.6535870e-13], sum to 1.0000
[2019-04-07 15:15:03,178] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0562
[2019-04-07 15:15:03,212] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.2, 27.0, 82.5, 808.0, 24.0, 23.09085857784311, -0.1512209523232629, 0.0, 1.0, 12459.647591599898], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2469600.0000, 
sim time next is 2471400.0000, 
raw observation next is [2.75, 27.0, 78.0, 784.0, 24.0, 23.09915399056338, -0.1519506988289956, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.5387811634349031, 0.27, 0.26, 0.8662983425414365, 0.5, 0.424929499213615, 0.44934976705700147, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.14250702], dtype=float32), -1.8571448]. 
=============================================
[2019-04-07 15:15:07,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:15:07,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:15:07,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run25
[2019-04-07 15:15:16,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:15:16,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:15:16,336] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run25
[2019-04-07 15:15:22,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:15:22,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:15:22,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run25
[2019-04-07 15:15:23,035] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-07 15:15:23,043] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:15:23,043] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:15:23,047] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run55
[2019-04-07 15:15:23,070] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:15:23,070] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:15:23,074] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run55
[2019-04-07 15:15:23,093] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:15:23,096] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:15:23,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run55
[2019-04-07 15:15:45,522] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.12347355], dtype=float32), 0.15248379]
[2019-04-07 15:15:45,523] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-2.7830727075, 69.25535794000001, 86.13406069, 0.0, 24.0, 23.22259439101601, -0.2084523154589459, 0.0, 1.0, 0.0]
[2019-04-07 15:15:45,523] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 15:15:45,524] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.0015719e-17 1.2044692e-15 3.5024979e-20 3.6173521e-14 4.7027375e-16
 1.0000000e+00 3.1706256e-11 1.1718388e-13], sampled 0.005188665410289728
[2019-04-07 15:17:47,125] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 15:18:02,242] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12347355], dtype=float32), 0.15248379]
[2019-04-07 15:18:02,242] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-3.0, 77.0, 0.0, 0.0, 24.0, 23.40584793343778, 0.007120156993852054, 0.0, 1.0, 51970.9088872129]
[2019-04-07 15:18:02,242] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 15:18:02,243] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.9635433e-19 5.1863460e-17 4.1083179e-22 1.7689277e-15 2.1354581e-17
 1.0000000e+00 3.5932605e-12 8.2099177e-15], sampled 0.19223417471631665
[2019-04-07 15:18:06,865] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.4863 79463814.5229 95.0531
[2019-04-07 15:18:09,881] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 15:18:10,904] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1080000, evaluation results [1080000.0, 2782.4863413368403, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 15:18:21,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:18:21,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:18:21,728] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run25
[2019-04-07 15:18:22,509] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3339309e-18 8.2513536e-17 8.6959535e-21 7.2177236e-15 5.5930178e-16
 1.0000000e+00 1.4223735e-12 8.5354324e-15], sum to 1.0000
[2019-04-07 15:18:22,510] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0529
[2019-04-07 15:18:22,575] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 86.0, 0.0, 0.0, 24.0, 23.07200089667855, -0.1876786524267557, 0.0, 1.0, 43132.82537048613], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 612000.0000, 
sim time next is 613800.0000, 
raw observation next is [-3.9, 80.5, 0.0, 0.0, 24.0, 23.00802871330751, -0.1969845467339755, 0.0, 1.0, 43285.259309582754], 
processed observation next is [0.0, 0.08695652173913043, 0.3545706371191136, 0.805, 0.0, 0.0, 0.5, 0.4173357261089592, 0.4343384844220082, 0.0, 1.0, 0.20612028242658453], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.04886562], dtype=float32), 1.4285281]. 
=============================================
[2019-04-07 15:18:29,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0895146e-21 1.8606452e-20 3.3128642e-26 3.4668105e-18 1.2505608e-20
 1.0000000e+00 2.6094100e-14 9.0969701e-18], sum to 1.0000
[2019-04-07 15:18:29,668] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7636
[2019-04-07 15:18:29,716] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.0, 100.0, 99.0, 647.0, 24.0, 24.50495003135889, 0.1207811227193371, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3144600.0000, 
sim time next is 3146400.0000, 
raw observation next is [7.0, 100.0, 103.5, 696.5, 24.0, 24.75520054655412, 0.1862628073286657, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.6565096952908588, 1.0, 0.345, 0.7696132596685082, 0.5, 0.5629333788795101, 0.5620876024428886, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4954374], dtype=float32), -0.07262929]. 
=============================================
[2019-04-07 15:18:29,869] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0582176e-18 3.0652937e-16 4.3370166e-21 3.0716396e-15 1.8192873e-17
 1.0000000e+00 8.8960728e-11 3.1197745e-14], sum to 1.0000
[2019-04-07 15:18:29,869] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1003
[2019-04-07 15:18:30,079] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.0, 80.0, 2.0, 94.0, 24.0, 22.9837577004455, -0.0506824198381452, 1.0, 1.0, 122528.60071866006], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3310200.0000, 
sim time next is 3312000.0000, 
raw observation next is [-11.0, 84.0, 44.0, 245.0, 24.0, 23.964480390723, 0.03466815818267265, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.15789473684210528, 0.84, 0.14666666666666667, 0.27071823204419887, 0.5, 0.49704003256025003, 0.5115560527275576, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4342487], dtype=float32), 0.062378187]. 
=============================================
[2019-04-07 15:18:30,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[93.157104]
 [91.75179 ]
 [92.367386]
 [93.11573 ]
 [93.76026 ]], R is [[93.87077332]
 [93.63431549]
 [93.69797516]
 [93.76099396]
 [93.82338715]].
[2019-04-07 15:18:31,848] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.29712321e-17 7.52599785e-16 6.42740145e-20 5.77914520e-14
 6.68835003e-16 1.00000000e+00 1.20762315e-11 2.33221730e-14], sum to 1.0000
[2019-04-07 15:18:31,870] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2515
[2019-04-07 15:18:31,924] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.9, 70.0, 0.0, 0.0, 24.0, 22.56856721768349, -0.2983159613929023, 0.0, 1.0, 48295.11581031609], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 342000.0000, 
sim time next is 343800.0000, 
raw observation next is [-13.9, 68.0, 0.0, 0.0, 24.0, 22.40905286769505, -0.3350494618038556, 0.0, 1.0, 48287.41644001284], 
processed observation next is [1.0, 1.0, 0.07756232686980608, 0.68, 0.0, 0.0, 0.5, 0.36742107230792076, 0.38831684606538147, 0.0, 1.0, 0.22994007828577545], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6747627], dtype=float32), 0.98178786]. 
=============================================
[2019-04-07 15:18:40,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:18:40,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:18:40,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run25
[2019-04-07 15:18:51,566] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5135232e-21 1.0341454e-18 3.9301546e-23 1.1966737e-16 5.2488597e-18
 1.0000000e+00 4.8890852e-12 1.9381901e-15], sum to 1.0000
[2019-04-07 15:18:51,566] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1455
[2019-04-07 15:18:51,605] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.4, 93.0, 0.0, 0.0, 24.0, 23.3758278775684, -0.1205357443963687, 0.0, 1.0, 56147.40638270263], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 520200.0000, 
sim time next is 522000.0000, 
raw observation next is [5.0, 89.0, 0.0, 0.0, 24.0, 23.42052219987976, -0.1034240629055504, 0.0, 1.0, 30182.63735706089], 
processed observation next is [0.0, 0.043478260869565216, 0.6011080332409973, 0.89, 0.0, 0.0, 0.5, 0.45171018332331325, 0.4655253123648165, 0.0, 1.0, 0.14372684455743281], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16167228], dtype=float32), -0.013616038]. 
=============================================
[2019-04-07 15:18:51,612] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[103.313354]
 [103.68121 ]
 [106.71321 ]
 [106.06087 ]
 [105.749664]], R is [[103.61715698]
 [103.58098602]
 [103.54517365]
 [103.50971985]
 [103.47462463]].
[2019-04-07 15:19:25,432] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.6535404e-20 2.0968886e-17 2.5745411e-22 2.2678145e-16 1.9415848e-17
 1.0000000e+00 1.9447094e-13 1.9344442e-16], sum to 1.0000
[2019-04-07 15:19:25,437] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3359
[2019-04-07 15:19:25,495] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.15, 49.5, 107.0, 677.0, 24.0, 24.75724520168303, 0.2162417661132132, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4354200.0000, 
sim time next is 4356000.0000, 
raw observation next is [10.0, 42.0, 111.0, 728.5, 24.0, 25.28209031672295, 0.3044206274456338, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.739612188365651, 0.42, 0.37, 0.8049723756906078, 0.5, 0.6068408597269125, 0.6014735424818779, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9188565], dtype=float32), 0.6641952]. 
=============================================
[2019-04-07 15:19:25,514] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[103.86887]
 [104.03541]
 [103.7797 ]
 [103.57103]
 [103.13086]], R is [[104.02600861]
 [103.98574829]
 [103.94589233]
 [103.90643311]
 [103.86737061]].
[2019-04-07 15:19:33,022] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:19:33,022] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:19:33,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run25
[2019-04-07 15:19:33,220] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5728095e-19 2.5192677e-17 9.0013928e-24 3.3888703e-16 2.8970154e-18
 1.0000000e+00 1.1579750e-12 7.7578228e-16], sum to 1.0000
[2019-04-07 15:19:33,220] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4052
[2019-04-07 15:19:33,237] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 95.0, 93.0, 0.0, 24.0, 24.15850718648234, 0.09484922926540483, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1425600.0000, 
sim time next is 1427400.0000, 
raw observation next is [0.25, 93.5, 96.0, 0.0, 24.0, 24.14350892456662, 0.06073258223151867, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.46952908587257625, 0.935, 0.32, 0.0, 0.5, 0.5119590770472184, 0.5202441940771729, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.08273908], dtype=float32), 0.6612849]. 
=============================================
[2019-04-07 15:19:41,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:19:41,186] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:19:41,192] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run25
[2019-04-07 15:19:41,271] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:19:41,271] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:19:41,276] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run25
[2019-04-07 15:19:42,424] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:19:42,424] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:19:42,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run25
[2019-04-07 15:19:42,520] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.99465263e-23 2.94081578e-20 2.49824163e-25 2.44727712e-18
 4.85704791e-19 1.00000000e+00 1.19846116e-14 5.73640557e-17], sum to 1.0000
[2019-04-07 15:19:42,520] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1336
[2019-04-07 15:19:42,595] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.8, 98.0, 0.0, 0.0, 24.0, 23.85423351978741, 0.2166220404162562, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1283400.0000, 
sim time next is 1285200.0000, 
raw observation next is [5.5, 100.0, 0.0, 0.0, 24.0, 23.85402904340233, 0.1940433511326049, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.6149584487534627, 1.0, 0.0, 0.0, 0.5, 0.48783575361686093, 0.5646811170442017, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.17188708], dtype=float32), 1.2589078]. 
=============================================
[2019-04-07 15:19:49,397] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:19:49,397] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:19:49,401] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run25
[2019-04-07 15:19:57,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:19:57,134] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:19:57,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run25
[2019-04-07 15:19:57,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:19:57,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:19:57,555] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run25
[2019-04-07 15:20:08,026] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7031112e-20 2.7548469e-17 7.8617979e-23 1.3929247e-15 2.9791088e-17
 1.0000000e+00 2.1214738e-12 9.7306061e-15], sum to 1.0000
[2019-04-07 15:20:08,027] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0816
[2019-04-07 15:20:08,124] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.75, 84.5, 0.0, 0.0, 24.0, 23.38077205742006, -0.08479449582538079, 0.0, 1.0, 46684.45892218533], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1801800.0000, 
sim time next is 1803600.0000, 
raw observation next is [-5.0, 86.0, 0.0, 0.0, 24.0, 23.3954899752101, -0.07291363478454996, 0.0, 1.0, 51037.4666783035], 
processed observation next is [0.0, 0.9130434782608695, 0.32409972299168976, 0.86, 0.0, 0.0, 0.5, 0.4496241646008417, 0.47569545507181665, 0.0, 1.0, 0.24303555561096904], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.34561834], dtype=float32), -1.5878717]. 
=============================================
[2019-04-07 15:20:15,744] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-07 15:20:15,745] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:20:15,745] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:20:15,749] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:20:15,749] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:20:15,753] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run56
[2019-04-07 15:20:15,774] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:20:15,775] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run56
[2019-04-07 15:20:15,797] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:20:15,808] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run56
[2019-04-07 15:22:37,574] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 15:22:53,439] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12346507], dtype=float32), 0.15299919]
[2019-04-07 15:22:53,487] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-6.0, 92.0, 0.0, 0.0, 24.0, 23.04812773493906, -0.110592632344479, 0.0, 1.0, 42214.62870109883]
[2019-04-07 15:22:53,487] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 15:22:53,488] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [7.4827885e-19 1.3010053e-16 2.0519936e-21 4.0865596e-15 6.8371427e-17
 1.0000000e+00 6.8062188e-12 1.7075759e-14], sampled 0.6149720675505145
[2019-04-07 15:22:57,829] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 15:23:01,954] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 15:23:02,977] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 1100000, evaluation results [1100000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 15:23:24,197] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3437676e-20 3.4680176e-16 2.8436991e-21 1.5417426e-14 2.0799832e-17
 1.0000000e+00 9.2154680e-13 8.1617859e-14], sum to 1.0000
[2019-04-07 15:23:24,197] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3733
[2019-04-07 15:23:24,374] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.45, 85.0, 41.0, 45.0, 24.0, 23.08351498327769, -0.1350116954463426, 0.0, 1.0, 33433.72507134292], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 577800.0000, 
sim time next is 579600.0000, 
raw observation next is [-1.7, 87.0, 20.5, 22.5, 24.0, 23.09133202185987, -0.1347151869522553, 0.0, 1.0, 38600.926992613364], 
processed observation next is [0.0, 0.7391304347826086, 0.4155124653739613, 0.87, 0.06833333333333333, 0.024861878453038673, 0.5, 0.4242776684883225, 0.4550949376825815, 0.0, 1.0, 0.18381393806006363], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.2441385], dtype=float32), 0.6397051]. 
=============================================
[2019-04-07 15:23:43,081] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2274230e-17 1.0844473e-14 8.9982865e-20 1.5330365e-14 6.8240135e-16
 1.0000000e+00 9.7587615e-12 1.5265502e-14], sum to 1.0000
[2019-04-07 15:23:43,081] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9257
[2019-04-07 15:23:43,340] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 79.0, 9.5, 0.0, 24.0, 22.42194526359404, -0.3347602179570242, 0.0, 1.0, 44712.21471105993], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 633600.0000, 
sim time next is 635400.0000, 
raw observation next is [-4.2, 75.0, 19.0, 0.0, 24.0, 22.72604154463039, -0.1911913060819272, 0.0, 1.0, 107481.78804773987], 
processed observation next is [0.0, 0.34782608695652173, 0.34626038781163443, 0.75, 0.06333333333333334, 0.0, 0.5, 0.3938367953858659, 0.43626956463935757, 0.0, 1.0, 0.5118180383225708], 
reward next is 0.7739, 
noisyNet noise sample is [array([-0.24262819], dtype=float32), 1.7591792]. 
=============================================
[2019-04-07 15:23:51,940] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1714489e-18 7.5530336e-16 5.0975991e-21 1.1021265e-13 1.9715671e-16
 1.0000000e+00 5.7041497e-11 4.4039297e-13], sum to 1.0000
[2019-04-07 15:23:51,940] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2423
[2019-04-07 15:23:52,020] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 45.0, 171.0, 64.5, 24.0, 23.93481061152443, -0.022156339843155, 1.0, 1.0, 6230.0176551115765], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2296800.0000, 
sim time next is 2298600.0000, 
raw observation next is [0.2500000000000001, 44.0, 121.0, 60.0, 24.0, 24.12911850383485, -0.09898061913168177, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.46952908587257625, 0.44, 0.4033333333333333, 0.06629834254143646, 0.5, 0.5107598753195708, 0.46700646028943943, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.51284003], dtype=float32), 0.4447691]. 
=============================================
[2019-04-07 15:24:01,567] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.59806784e-19 1.10000787e-16 1.29462611e-20 2.73687526e-15
 1.01391604e-16 1.00000000e+00 4.46628455e-12 1.66689088e-14], sum to 1.0000
[2019-04-07 15:24:01,568] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8847
[2019-04-07 15:24:01,717] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 56.5, 99.0, 635.0, 24.0, 23.6136885062966, -0.06617148965678225, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3058200.0000, 
sim time next is 3060000.0000, 
raw observation next is [-4.0, 54.0, 102.5, 697.0, 24.0, 23.49887860237084, -0.07593976193107176, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3518005540166205, 0.54, 0.3416666666666667, 0.7701657458563536, 0.5, 0.4582398835309034, 0.47468674602297606, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03953063], dtype=float32), -0.29398072]. 
=============================================
[2019-04-07 15:24:01,723] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[91.583534]
 [91.73459 ]
 [91.93391 ]
 [91.18681 ]
 [91.16655 ]], R is [[91.27228546]
 [91.35956573]
 [91.44596863]
 [91.43041229]
 [91.51610565]].
[2019-04-07 15:24:14,654] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8951234e-20 9.8503265e-18 3.0540778e-23 3.5474436e-16 1.0882042e-17
 1.0000000e+00 1.0393091e-13 9.9776712e-16], sum to 1.0000
[2019-04-07 15:24:14,654] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4773
[2019-04-07 15:24:14,696] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 24.0, 23.58753399128562, 0.09080964538450836, 0.0, 1.0, 12210.221543341808], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1321200.0000, 
sim time next is 1323000.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 24.0, 23.52269983324109, 0.08602452228708889, 1.0, 1.0, 13969.50428650214], 
processed observation next is [1.0, 0.30434782608695654, 0.49307479224376743, 0.92, 0.0, 0.0, 0.5, 0.46022498610342427, 0.5286748407623629, 1.0, 1.0, 0.06652144898334353], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7117736], dtype=float32), -0.54032063]. 
=============================================
[2019-04-07 15:24:14,703] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[106.465645]
 [106.8902  ]
 [106.57549 ]
 [106.64856 ]
 [107.216866]], R is [[106.65284729]
 [106.58631897]
 [106.38533783]
 [106.32148743]
 [106.25827026]].
[2019-04-07 15:24:25,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:24:25,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:24:25,094] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run26
[2019-04-07 15:24:31,549] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.2763612e-18 1.5147007e-16 1.9072986e-21 6.6831923e-14 8.4530242e-17
 1.0000000e+00 8.7679421e-12 1.6151068e-14], sum to 1.0000
[2019-04-07 15:24:31,550] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5021
[2019-04-07 15:24:31,617] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 86.0, 0.0, 0.0, 24.0, 23.13533139492483, -0.1455271141028645, 0.0, 1.0, 43950.79951711506], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2080800.0000, 
sim time next is 2082600.0000, 
raw observation next is [-4.75, 86.0, 0.0, 0.0, 24.0, 23.20956209426955, -0.1476207986671536, 0.0, 1.0, 43920.77737012369], 
processed observation next is [1.0, 0.08695652173913043, 0.3310249307479225, 0.86, 0.0, 0.0, 0.5, 0.43413017452246255, 0.4507930671109488, 0.0, 1.0, 0.2091465589053509], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.07352705], dtype=float32), -0.418094]. 
=============================================
[2019-04-07 15:24:42,705] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6247955e-17 3.2440627e-15 1.5243139e-20 1.7188895e-13 5.8983520e-16
 1.0000000e+00 5.4272010e-11 9.8597447e-14], sum to 1.0000
[2019-04-07 15:24:42,705] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6273
[2019-04-07 15:24:42,927] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 61.0, 104.5, 75.5, 24.0, 23.51630057880474, -0.04772401474458243, 1.0, 1.0, 65465.562942386074], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 140400.0000, 
sim time next is 142200.0000, 
raw observation next is [-6.7, 62.5, 61.0, 45.0, 24.0, 23.98636164911574, 0.0461763761610753, 1.0, 1.0, 85131.26064295774], 
processed observation next is [1.0, 0.6521739130434783, 0.2770083102493075, 0.625, 0.20333333333333334, 0.049723756906077346, 0.5, 0.49886347075964493, 0.5153921253870252, 1.0, 1.0, 0.4053869554426559], 
reward next is 0.8803, 
noisyNet noise sample is [array([-1.0083104], dtype=float32), -1.7066259]. 
=============================================
[2019-04-07 15:24:47,365] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1680233e-20 5.3945927e-17 7.2858840e-23 4.9615130e-16 1.0535530e-18
 1.0000000e+00 4.6119636e-12 4.8413873e-16], sum to 1.0000
[2019-04-07 15:24:47,365] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9915
[2019-04-07 15:24:47,418] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 72.5, 196.0, 6.0, 24.0, 24.24506538152679, 0.09802529492880645, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4717800.0000, 
sim time next is 4719600.0000, 
raw observation next is [1.0, 72.0, 171.5, 3.0, 24.0, 23.85580713888268, 0.02796540506221725, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.4903047091412743, 0.72, 0.5716666666666667, 0.0033149171270718232, 0.5, 0.4879839282402232, 0.5093218016874058, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0661291], dtype=float32), -0.32879162]. 
=============================================
[2019-04-07 15:24:56,439] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4566404e-19 3.0712263e-17 1.0596699e-21 3.9054961e-15 7.5783118e-17
 1.0000000e+00 2.0769519e-12 3.1529133e-15], sum to 1.0000
[2019-04-07 15:24:56,439] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1370
[2019-04-07 15:24:56,733] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 91.0, 24.0, 18.0, 24.0, 23.65540692874526, -0.121442135309188, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2275200.0000, 
sim time next is 2277000.0000, 
raw observation next is [-8.95, 89.0, 45.0, 16.0, 24.0, 23.76135805450556, -0.09166960434340238, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.21468144044321333, 0.89, 0.15, 0.017679558011049725, 0.5, 0.4801131712087967, 0.4694434652188659, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.21452968], dtype=float32), 1.2218982]. 
=============================================
[2019-04-07 15:24:56,749] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[96.013596]
 [95.729164]
 [93.93812 ]
 [94.27047 ]
 [94.56444 ]], R is [[96.21191406]
 [96.24979401]
 [95.85944366]
 [95.90084839]
 [95.94184113]].
[2019-04-07 15:24:57,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:24:57,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:24:57,540] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run26
[2019-04-07 15:25:00,030] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1119207: loss 0.6443
[2019-04-07 15:25:00,030] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1119207: learning rate 0.0000
[2019-04-07 15:25:00,144] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.69332798e-17 3.88377338e-16 1.31961658e-20 1.38507285e-14
 2.74150287e-16 1.00000000e+00 3.84271122e-11 3.70529006e-14], sum to 1.0000
[2019-04-07 15:25:00,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3384
[2019-04-07 15:25:00,210] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 37.0, 0.0, 0.0, 24.0, 23.45878825029294, -0.03783985355857514, 0.0, 1.0, 24821.703399372967], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4059000.0000, 
sim time next is 4060800.0000, 
raw observation next is [-6.0, 37.0, 0.0, 0.0, 24.0, 23.39958223031829, -0.04850852078223441, 0.0, 1.0, 54524.1844397786], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.37, 0.0, 0.0, 0.5, 0.4499651858598576, 0.4838304930725885, 0.0, 1.0, 0.2596389735227552], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1827123], dtype=float32), -1.1990597]. 
=============================================
[2019-04-07 15:25:04,847] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:25:04,848] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:25:04,851] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run26
[2019-04-07 15:25:04,970] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-07 15:25:04,973] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:25:04,973] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:25:04,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run57
[2019-04-07 15:25:04,997] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:25:05,009] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:25:05,009] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:25:05,010] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:25:05,016] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run57
[2019-04-07 15:25:05,047] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run57
[2019-04-07 15:26:05,387] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12350346], dtype=float32), 0.15344416]
[2019-04-07 15:26:05,387] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-5.0, 86.0, 0.0, 0.0, 24.0, 23.36852745854031, -0.09805779653537239, 0.0, 1.0, 49573.81280286069]
[2019-04-07 15:26:05,387] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 15:26:05,388] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [6.35836573e-19 9.61363668e-17 1.12588046e-21 3.06437166e-15
 4.65809954e-17 1.00000000e+00 5.47264447e-12 1.34545525e-14], sampled 0.5169104959931907
[2019-04-07 15:27:25,864] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 15:27:41,795] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 15:27:45,072] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 15:27:46,093] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 1120000, evaluation results [1120000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 15:27:56,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:27:56,457] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:27:56,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run26
[2019-04-07 15:28:00,419] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.3572144e-15 2.8687803e-14 8.8059559e-19 7.3330437e-13 7.6180029e-14
 1.0000000e+00 2.6101086e-09 5.7600171e-11], sum to 1.0000
[2019-04-07 15:28:00,419] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4566
[2019-04-07 15:28:00,548] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-15.5, 83.0, 0.0, 0.0, 24.0, 22.05018199442735, -0.3859859223279781, 0.0, 1.0, 44607.5736191322], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2698200.0000, 
sim time next is 2700000.0000, 
raw observation next is [-16.0, 83.0, 0.0, 0.0, 24.0, 21.93013261523448, -0.4187810807512407, 0.0, 1.0, 44307.39458723136], 
processed observation next is [1.0, 0.2608695652173913, 0.01939058171745151, 0.83, 0.0, 0.0, 0.5, 0.32751105126954005, 0.3604063064162531, 0.0, 1.0, 0.2109875932725303], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.13652566], dtype=float32), 0.05343946]. 
=============================================
[2019-04-07 15:28:00,595] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[88.5621  ]
 [89.340836]
 [90.08467 ]
 [90.7355  ]
 [91.26867 ]], R is [[87.86338806]
 [87.98475647]
 [88.1049118 ]
 [88.22386169]
 [88.3416214 ]].
[2019-04-07 15:28:09,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:28:09,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:28:09,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run26
[2019-04-07 15:28:09,793] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.2748690e-18 2.4040328e-15 5.5277824e-20 2.3761666e-14 5.9685171e-16
 1.0000000e+00 7.6684846e-11 6.3836455e-14], sum to 1.0000
[2019-04-07 15:28:09,793] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9026
[2019-04-07 15:28:09,868] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 62.5, 0.0, 0.0, 24.0, 23.11739718236412, -0.06867312502068515, 0.0, 1.0, 130383.42448703363], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3007800.0000, 
sim time next is 3009600.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.62817576806341, -0.03663619424266645, 0.0, 1.0, 28001.190747657238], 
processed observation next is [0.0, 0.8695652173913043, 0.3795013850415513, 0.65, 0.0, 0.0, 0.5, 0.4690146473386176, 0.4877879352524445, 0.0, 1.0, 0.13333900356027256], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17501315], dtype=float32), 0.65499586]. 
=============================================
[2019-04-07 15:28:13,248] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1124258: loss 0.9878
[2019-04-07 15:28:13,248] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1124258: learning rate 0.0000
[2019-04-07 15:28:13,431] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:28:13,431] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:28:13,436] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run26
[2019-04-07 15:28:14,621] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1124447: loss 1.0438
[2019-04-07 15:28:14,641] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1124449: learning rate 0.0000
[2019-04-07 15:28:18,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:28:18,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:28:18,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run26
[2019-04-07 15:28:26,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:28:26,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:28:26,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run26
[2019-04-07 15:28:29,620] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.39987811e-19 1.12735255e-17 1.84937799e-22 1.81573847e-16
 3.98218266e-19 1.00000000e+00 2.01852575e-12 7.01867213e-15], sum to 1.0000
[2019-04-07 15:28:29,621] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0707
[2019-04-07 15:28:29,708] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 24.0, 23.43861844373877, -0.09057697972508598, 0.0, 1.0, 53318.24246575489], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2862000.0000, 
sim time next is 2863800.0000, 
raw observation next is [1.0, 89.5, 0.0, 0.0, 24.0, 23.50867106115488, -0.1123548997393367, 0.0, 1.0, 28528.228734252993], 
processed observation next is [1.0, 0.13043478260869565, 0.4903047091412743, 0.895, 0.0, 0.0, 0.5, 0.4590559217629068, 0.46254836675355443, 0.0, 1.0, 0.13584870825834758], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.316023], dtype=float32), 0.55416685]. 
=============================================
[2019-04-07 15:28:32,167] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1126967: loss 90.2441
[2019-04-07 15:28:32,167] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1126967: learning rate 0.0000
[2019-04-07 15:28:32,217] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1126971: loss 0.8272
[2019-04-07 15:28:32,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1126971: learning rate 0.0000
[2019-04-07 15:28:37,940] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9431907e-19 5.6152238e-18 1.4698806e-23 7.9427031e-16 8.4375199e-19
 1.0000000e+00 9.1575586e-13 7.5572088e-17], sum to 1.0000
[2019-04-07 15:28:37,941] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6213
[2019-04-07 15:28:38,129] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.9, 84.0, 50.0, 0.0, 24.0, 22.64236069763369, -0.2127045426628814, 0.0, 1.0, 44191.19028386329], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 55800.0000, 
sim time next is 57600.0000, 
raw observation next is [6.6, 82.0, 34.0, 0.0, 24.0, 22.72953989368218, -0.2087257255689516, 0.0, 1.0, 19094.411111014455], 
processed observation next is [0.0, 0.6956521739130435, 0.6454293628808865, 0.82, 0.11333333333333333, 0.0, 0.5, 0.394128324473515, 0.4304247581436828, 0.0, 1.0, 0.09092576719530693], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0026803], dtype=float32), -1.1269372]. 
=============================================
[2019-04-07 15:28:44,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:28:44,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:28:44,596] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run26
[2019-04-07 15:28:46,814] A3C_AGENT_WORKER-Thread-6 INFO:Local step 71000, global step 1129250: loss 0.9079
[2019-04-07 15:28:46,815] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 71000, global step 1129250: learning rate 0.0000
[2019-04-07 15:28:50,178] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1129724: loss 0.7131
[2019-04-07 15:28:50,178] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1129724: learning rate 0.0000
[2019-04-07 15:28:52,508] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1130045: loss 0.9176
[2019-04-07 15:28:52,510] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1130045: learning rate 0.0000
[2019-04-07 15:29:00,291] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1131341: loss 0.6983
[2019-04-07 15:29:00,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1131341: learning rate 0.0000
[2019-04-07 15:29:03,737] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.0248908e-17 6.3002632e-15 4.2966575e-20 1.6001191e-14 2.6944645e-15
 1.0000000e+00 1.4880163e-11 4.3587952e-13], sum to 1.0000
[2019-04-07 15:29:03,737] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5323
[2019-04-07 15:29:03,926] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.5, 66.0, 0.0, 0.0, 24.0, 22.4295418528422, -0.2168694434277868, 1.0, 1.0, 149811.35813692477], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4001400.0000, 
sim time next is 4003200.0000, 
raw observation next is [-13.0, 63.0, 46.5, 222.0, 24.0, 23.87748233552614, -0.02116269018468491, 1.0, 1.0, 37375.41009068823], 
processed observation next is [1.0, 0.34782608695652173, 0.10249307479224376, 0.63, 0.155, 0.24530386740331492, 0.5, 0.48979019462717827, 0.49294576993843836, 1.0, 1.0, 0.17797814328899159], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6361874], dtype=float32), -1.2859911]. 
=============================================
[2019-04-07 15:29:05,498] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1132250: loss 88.6702
[2019-04-07 15:29:05,499] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1132250: learning rate 0.0000
[2019-04-07 15:29:06,726] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1132456: loss 89.8150
[2019-04-07 15:29:06,727] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1132456: learning rate 0.0000
[2019-04-07 15:29:10,492] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.4118810e-19 1.1824253e-16 2.2798223e-21 9.9305476e-16 1.4445547e-16
 1.0000000e+00 1.1383715e-11 1.3531735e-14], sum to 1.0000
[2019-04-07 15:29:10,492] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0788
[2019-04-07 15:29:10,555] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.0, 57.0, 208.5, 551.0, 24.0, 23.62766780483368, 0.03141595664007312, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4284000.0000, 
sim time next is 4285800.0000, 
raw observation next is [6.9, 58.5, 229.0, 385.0, 24.0, 23.66672743954403, 0.03556890595794669, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.6537396121883658, 0.585, 0.7633333333333333, 0.425414364640884, 0.5, 0.47222728662866914, 0.5118563019859822, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7808928], dtype=float32), -1.5741428]. 
=============================================
[2019-04-07 15:29:16,176] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.7936518e-18 1.1159929e-16 1.4055271e-22 1.8176937e-15 5.4632831e-18
 1.0000000e+00 6.9436205e-13 2.2202914e-14], sum to 1.0000
[2019-04-07 15:29:16,176] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6825
[2019-04-07 15:29:16,257] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.0, 53.5, 121.0, 822.0, 24.0, 23.35617892480491, -0.03657887854061975, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4275000.0000, 
sim time next is 4276800.0000, 
raw observation next is [7.0, 52.0, 120.5, 834.5, 24.0, 23.36878261083565, -0.02475929025824232, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.6565096952908588, 0.52, 0.40166666666666667, 0.9220994475138121, 0.5, 0.4473985509029707, 0.49174690324725256, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05716973], dtype=float32), 1.1270394]. 
=============================================
[2019-04-07 15:29:19,980] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1134726: loss 0.7593
[2019-04-07 15:29:19,981] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1134726: learning rate 0.0000
[2019-04-07 15:29:21,463] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2016226e-17 1.0851502e-15 1.5942165e-20 1.4827586e-14 6.1117117e-16
 1.0000000e+00 3.6140060e-11 8.2064032e-13], sum to 1.0000
[2019-04-07 15:29:21,463] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3233
[2019-04-07 15:29:21,515] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 55.5, 0.0, 0.0, 24.0, 23.29361018684909, -0.05102637189109514, 0.0, 1.0, 46700.35439199268], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3972600.0000, 
sim time next is 3974400.0000, 
raw observation next is [-10.0, 58.0, 0.0, 0.0, 24.0, 23.23882859337726, -0.07035646978730921, 0.0, 1.0, 46011.8248786617], 
processed observation next is [1.0, 0.0, 0.18559556786703602, 0.58, 0.0, 0.0, 0.5, 0.436569049448105, 0.4765478434042303, 0.0, 1.0, 0.21910392799362713], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7605843], dtype=float32), 1.1714101]. 
=============================================
[2019-04-07 15:29:22,222] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1135177: loss 5.2673
[2019-04-07 15:29:22,223] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1135177: learning rate 0.0000
[2019-04-07 15:29:23,712] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1135461: loss 86.9361
[2019-04-07 15:29:23,714] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1135461: learning rate 0.0000
[2019-04-07 15:29:23,909] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5280172e-18 1.7231576e-16 2.5136385e-20 1.3163877e-14 1.9316358e-15
 1.0000000e+00 1.9826476e-11 6.1879577e-15], sum to 1.0000
[2019-04-07 15:29:23,909] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3367
[2019-04-07 15:29:24,078] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 54.0, 46.0, 244.0, 24.0, 23.30831133420892, -0.07870354085651167, 0.0, 1.0, 42541.54802797427], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4176000.0000, 
sim time next is 4177800.0000, 
raw observation next is [-4.5, 49.5, 92.0, 488.0, 24.0, 23.41528410681512, -0.04624415588480511, 0.0, 1.0, 13683.326635271114], 
processed observation next is [0.0, 0.34782608695652173, 0.3379501385041552, 0.495, 0.30666666666666664, 0.5392265193370166, 0.5, 0.4512736755679265, 0.4845852813717317, 0.0, 1.0, 0.06515869826319579], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.32799205], dtype=float32), -0.63084346]. 
=============================================
[2019-04-07 15:29:36,287] A3C_AGENT_WORKER-Thread-6 INFO:Local step 71500, global step 1137892: loss 89.0857
[2019-04-07 15:29:36,290] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 71500, global step 1137894: learning rate 0.0000
[2019-04-07 15:29:39,372] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1138614: loss 87.0433
[2019-04-07 15:29:39,372] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1138614: learning rate 0.0000
[2019-04-07 15:29:41,670] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1139085: loss 88.5348
[2019-04-07 15:29:41,672] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1139085: learning rate 0.0000
[2019-04-07 15:29:42,026] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9969229e-18 1.4761849e-16 2.4092401e-21 1.4227024e-15 2.4995181e-18
 1.0000000e+00 1.0027715e-11 1.0182894e-14], sum to 1.0000
[2019-04-07 15:29:42,026] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3245
[2019-04-07 15:29:42,132] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 24.0, 23.06205781270497, -0.1293042489503869, 0.0, 1.0, 42290.73269206967], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4770000.0000, 
sim time next is 4771800.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 24.0, 23.03363843691237, -0.1367633719976122, 0.0, 1.0, 42362.05132928046], 
processed observation next is [0.0, 0.21739130434782608, 0.296398891966759, 0.92, 0.0, 0.0, 0.5, 0.41946986974269745, 0.45441220933412924, 0.0, 1.0, 0.20172405394895457], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.6040027], dtype=float32), 0.98091435]. 
=============================================
[2019-04-07 15:29:43,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:29:43,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:29:43,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run26
[2019-04-07 15:29:46,683] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-07 15:29:46,689] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:29:46,690] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:29:46,701] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:29:46,701] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:29:46,705] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run58
[2019-04-07 15:29:46,725] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:29:46,727] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:29:46,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run58
[2019-04-07 15:29:46,753] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run58
[2019-04-07 15:31:45,750] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12361023], dtype=float32), 0.15403938]
[2019-04-07 15:31:45,750] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [3.4, 43.0, 171.0, 384.0, 24.0, 24.71758529381328, 0.2270315387581379, 1.0, 1.0, 0.0]
[2019-04-07 15:31:45,750] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 15:31:45,752] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.0372944e-18 2.2605766e-16 3.4974093e-21 6.3832644e-15 3.7563476e-17
 1.0000000e+00 4.8007353e-12 1.8022047e-14], sampled 0.9378595099958321
[2019-04-07 15:32:12,982] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 15:32:32,664] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 15:32:34,787] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 15:32:35,809] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1140000, evaluation results [1140000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 15:32:38,005] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1140429: loss 86.6475
[2019-04-07 15:32:38,017] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1140429: learning rate 0.0000
[2019-04-07 15:32:39,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:32:39,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:32:39,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run26
[2019-04-07 15:32:43,343] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1141336: loss 4.4402
[2019-04-07 15:32:43,344] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1141336: learning rate 0.0000
[2019-04-07 15:32:43,583] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1141380: loss 4.7834
[2019-04-07 15:32:43,583] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1141380: learning rate 0.0000
[2019-04-07 15:32:43,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:32:43,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:32:43,946] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run26
[2019-04-07 15:32:45,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:32:45,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:32:45,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run26
[2019-04-07 15:32:51,101] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:32:51,101] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:32:51,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run26
[2019-04-07 15:32:52,485] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.1248842e-19 3.5753483e-16 1.4062250e-21 5.0806984e-14 5.0547379e-17
 1.0000000e+00 9.8019648e-12 2.0455102e-14], sum to 1.0000
[2019-04-07 15:32:52,485] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1399
[2019-04-07 15:32:52,684] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 78.0, 27.0, 0.0, 24.0, 22.47091897372741, -0.2010998638957815, 0.0, 1.0, 151175.3317485994], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1845000.0000, 
sim time next is 1846800.0000, 
raw observation next is [-6.7, 78.0, 87.5, 47.0, 24.0, 23.58368179591058, -0.1086334565100302, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.2770083102493075, 0.78, 0.2916666666666667, 0.051933701657458566, 0.5, 0.46530681632588156, 0.4637888478299899, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2830471], dtype=float32), 1.6689115]. 
=============================================
[2019-04-07 15:32:53,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:32:53,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:32:53,559] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run26
[2019-04-07 15:32:56,053] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1143127: loss 88.5196
[2019-04-07 15:32:56,059] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1143127: learning rate 0.0000
[2019-04-07 15:32:59,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:32:59,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:32:59,172] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run26
[2019-04-07 15:33:01,549] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.5709772e-16 3.0083544e-14 1.9557064e-19 1.1759452e-13 1.1924371e-14
 1.0000000e+00 1.5937988e-10 3.9766768e-13], sum to 1.0000
[2019-04-07 15:33:01,549] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7350
[2019-04-07 15:33:01,621] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 74.0, 0.0, 0.0, 24.0, 22.44488030434683, -0.3160633413126852, 0.0, 1.0, 45379.28082939688], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 178200.0000, 
sim time next is 180000.0000, 
raw observation next is [-8.9, 74.0, 0.0, 0.0, 24.0, 22.39507998022345, -0.3280842889735918, 0.0, 1.0, 45247.19476169648], 
processed observation next is [1.0, 0.08695652173913043, 0.21606648199445982, 0.74, 0.0, 0.0, 0.5, 0.3662566650186208, 0.39063857034213606, 0.0, 1.0, 0.21546283219855467], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6678233], dtype=float32), -2.180435]. 
=============================================
[2019-04-07 15:33:01,640] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[91.909004]
 [91.645515]
 [91.6376  ]
 [91.413   ]
 [92.47396 ]], R is [[91.82063293]
 [91.90242767]
 [91.98340607]
 [92.06357574]
 [92.14294434]].
[2019-04-07 15:33:04,141] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1144005: loss 0.1797
[2019-04-07 15:33:04,141] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1144005: learning rate 0.0000
[2019-04-07 15:33:04,282] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1144022: loss 4.5934
[2019-04-07 15:33:04,282] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1144022: learning rate 0.0000
[2019-04-07 15:33:05,001] A3C_AGENT_WORKER-Thread-4 INFO:Local step 71000, global step 1144104: loss 0.7187
[2019-04-07 15:33:05,005] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 71000, global step 1144104: learning rate 0.0000
[2019-04-07 15:33:12,717] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.0554603e-17 2.7777048e-16 1.4741736e-19 2.0536963e-14 3.1055936e-16
 1.0000000e+00 5.2781935e-11 6.5856337e-13], sum to 1.0000
[2019-04-07 15:33:12,717] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3327
[2019-04-07 15:33:12,760] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.9, 52.0, 0.0, 0.0, 24.0, 22.09860262423638, -0.4350366832222588, 0.0, 1.0, 46740.760959757645], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 441000.0000, 
sim time next is 442800.0000, 
raw observation next is [-10.6, 49.0, 0.0, 0.0, 24.0, 22.04272477203441, -0.4570458392370958, 0.0, 1.0, 46810.54773059485], 
processed observation next is [1.0, 0.13043478260869565, 0.1689750692520776, 0.49, 0.0, 0.0, 0.5, 0.3368937310028676, 0.3476513869209681, 0.0, 1.0, 0.22290737014568976], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.11331475], dtype=float32), 1.1452812]. 
=============================================
[2019-04-07 15:33:13,644] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6667898e-18 7.0857310e-17 4.9425698e-22 8.1216085e-15 1.4845986e-17
 1.0000000e+00 4.0517021e-12 3.5116980e-15], sum to 1.0000
[2019-04-07 15:33:13,644] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2287
[2019-04-07 15:33:13,852] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 24.0, 23.02039917676786, -0.1651399409682288, 0.0, 1.0, 96923.80047000722], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 244800.0000, 
sim time next is 246600.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 24.0, 23.10661816301034, -0.1586065251953595, 0.0, 1.0, 75255.3839867933], 
processed observation next is [1.0, 0.8695652173913043, 0.368421052631579, 0.65, 0.0, 0.0, 0.5, 0.4255515135841949, 0.44713115826821354, 0.0, 1.0, 0.3583589713656824], 
reward next is 0.9274, 
noisyNet noise sample is [array([0.6281528], dtype=float32), -1.7373111]. 
=============================================
[2019-04-07 15:33:16,498] A3C_AGENT_WORKER-Thread-5 INFO:Local step 71000, global step 1145588: loss 0.8082
[2019-04-07 15:33:16,499] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 71000, global step 1145588: learning rate 0.0000
[2019-04-07 15:33:16,618] A3C_AGENT_WORKER-Thread-6 INFO:Local step 72000, global step 1145606: loss 4.7013
[2019-04-07 15:33:16,619] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 72000, global step 1145606: learning rate 0.0000
[2019-04-07 15:33:20,757] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1146032: loss 5.1889
[2019-04-07 15:33:20,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1146032: learning rate 0.0000
[2019-04-07 15:33:20,795] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2615489e-18 3.4879205e-15 2.5963588e-21 6.1088012e-15 6.6781455e-18
 1.0000000e+00 8.2651052e-13 6.3044946e-15], sum to 1.0000
[2019-04-07 15:33:20,795] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4218
[2019-04-07 15:33:20,912] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 59.0, 0.0, 0.0, 24.0, 23.48619379018855, -0.004396852693777357, 0.0, 1.0, 48926.58154435627], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2750400.0000, 
sim time next is 2752200.0000, 
raw observation next is [-5.5, 61.5, 0.0, 0.0, 24.0, 23.4391737851023, 0.02168301348422038, 0.0, 1.0, 124013.27091916783], 
processed observation next is [1.0, 0.8695652173913043, 0.3102493074792244, 0.615, 0.0, 0.0, 0.5, 0.4532644820918585, 0.5072276711614068, 0.0, 1.0, 0.5905393853293707], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.86665297], dtype=float32), -1.4304118]. 
=============================================
[2019-04-07 15:33:21,304] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.6637422e-18 2.8815878e-16 1.4832095e-20 4.6048192e-15 6.1283310e-17
 1.0000000e+00 2.2448564e-11 1.1065493e-14], sum to 1.0000
[2019-04-07 15:33:21,304] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6753
[2019-04-07 15:33:21,379] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 75.0, 0.0, 0.0, 24.0, 23.06872532880417, -0.1803640923363517, 0.0, 1.0, 45822.50607586724], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 252000.0000, 
sim time next is 253800.0000, 
raw observation next is [-3.9, 78.5, 0.0, 0.0, 24.0, 23.01831547096532, -0.1930354737767235, 0.0, 1.0, 45617.72343514537], 
processed observation next is [1.0, 0.9565217391304348, 0.3545706371191136, 0.785, 0.0, 0.0, 0.5, 0.41819295591377664, 0.4356548420744255, 0.0, 1.0, 0.2172272544530732], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3782244], dtype=float32), -0.46648458]. 
=============================================
[2019-04-07 15:33:22,552] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1146252: loss 0.8697
[2019-04-07 15:33:22,553] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1146252: learning rate 0.0000
[2019-04-07 15:33:22,976] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1146311: loss 0.8401
[2019-04-07 15:33:22,977] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1146311: learning rate 0.0000
[2019-04-07 15:33:23,103] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1146329: loss 4.4585
[2019-04-07 15:33:23,118] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1146329: learning rate 0.0000
[2019-04-07 15:33:30,088] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1147166: loss 0.7830
[2019-04-07 15:33:30,089] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1147166: learning rate 0.0000
[2019-04-07 15:33:31,138] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1147325: loss 4.4550
[2019-04-07 15:33:31,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1147325: learning rate 0.0000
[2019-04-07 15:33:31,425] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2114085e-19 5.8212222e-20 2.3941848e-23 1.1212806e-15 4.5028952e-19
 1.0000000e+00 3.0033051e-13 9.1317529e-15], sum to 1.0000
[2019-04-07 15:33:31,426] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3287
[2019-04-07 15:33:31,506] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 85.0, 0.0, 0.0, 24.0, 23.56843634614177, 0.05490156264127995, 0.0, 1.0, 38685.17785069586], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2926800.0000, 
sim time next is 2928600.0000, 
raw observation next is [-1.0, 81.5, 0.0, 0.0, 24.0, 23.58481101586782, 0.03211344344923542, 0.0, 1.0, 6246.520663731687], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.815, 0.0, 0.0, 0.5, 0.4654009179889851, 0.5107044811497451, 0.0, 1.0, 0.029745336493960415], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4582657], dtype=float32), 0.15612432]. 
=============================================
[2019-04-07 15:33:32,847] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1147558: loss 0.8257
[2019-04-07 15:33:32,848] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1147558: learning rate 0.0000
[2019-04-07 15:33:33,896] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1415152e-19 6.3239533e-16 2.6863690e-21 4.6169228e-14 3.3857821e-16
 1.0000000e+00 1.4066480e-11 9.8094310e-15], sum to 1.0000
[2019-04-07 15:33:33,896] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9096
[2019-04-07 15:33:33,973] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 59.0, 39.5, 343.5, 24.0, 23.75964887360973, 0.03820434183504842, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3690000.0000, 
sim time next is 3691800.0000, 
raw observation next is [4.0, 59.0, 15.0, 165.0, 24.0, 23.61295095636528, -0.006309962185285123, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5734072022160666, 0.59, 0.05, 0.18232044198895028, 0.5, 0.46774591303044016, 0.4978966792715716, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7683061], dtype=float32), 1.0261501]. 
=============================================
[2019-04-07 15:33:38,022] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2170253e-18 1.8895041e-15 8.4135941e-22 6.0969310e-14 2.2743901e-16
 1.0000000e+00 2.8178312e-10 1.2510741e-12], sum to 1.0000
[2019-04-07 15:33:38,023] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7077
[2019-04-07 15:33:38,092] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.35, 86.5, 0.0, 0.0, 24.0, 23.2767239088998, -0.1318879287989422, 0.0, 1.0, 41653.84763509839], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 538200.0000, 
sim time next is 540000.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 24.0, 23.30439100760328, -0.1296644455654276, 0.0, 1.0, 41702.02243472444], 
processed observation next is [0.0, 0.2608695652173913, 0.49307479224376743, 0.88, 0.0, 0.0, 0.5, 0.4420325839669399, 0.4567785181448574, 0.0, 1.0, 0.1985810592129735], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7116441], dtype=float32), 0.16538881]. 
=============================================
[2019-04-07 15:33:38,117] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[101.61857 ]
 [102.080414]
 [102.48599 ]
 [103.068146]
 [103.506424]], R is [[101.36073303]
 [101.34712982]
 [101.33365631]
 [101.32032013]
 [101.30712128]].
[2019-04-07 15:33:38,165] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1148248: loss 0.9446
[2019-04-07 15:33:38,166] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1148248: learning rate 0.0000
[2019-04-07 15:33:39,431] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1148402: loss 0.1747
[2019-04-07 15:33:39,432] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1148402: learning rate 0.0000
[2019-04-07 15:33:39,668] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1148427: loss 0.1678
[2019-04-07 15:33:39,673] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1148427: learning rate 0.0000
[2019-04-07 15:33:46,647] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1149402: loss 0.5780
[2019-04-07 15:33:46,648] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1149402: learning rate 0.0000
[2019-04-07 15:33:49,406] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1149771: loss 4.4900
[2019-04-07 15:33:49,407] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1149771: learning rate 0.0000
[2019-04-07 15:33:58,769] A3C_AGENT_WORKER-Thread-4 INFO:Local step 71500, global step 1151221: loss 91.5132
[2019-04-07 15:33:58,773] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 71500, global step 1151221: learning rate 0.0000
[2019-04-07 15:34:01,172] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1151583: loss 0.1637
[2019-04-07 15:34:01,193] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1151583: learning rate 0.0000
[2019-04-07 15:34:09,848] A3C_AGENT_WORKER-Thread-5 INFO:Local step 71500, global step 1153233: loss 89.1219
[2019-04-07 15:34:09,848] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 71500, global step 1153233: learning rate 0.0000
[2019-04-07 15:34:12,296] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8903782e-20 7.1550991e-18 1.7046435e-22 4.0630060e-17 1.5105964e-18
 1.0000000e+00 1.7896181e-12 1.8110052e-14], sum to 1.0000
[2019-04-07 15:34:12,296] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9460
[2019-04-07 15:34:12,375] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 60.0, 40.5, 343.0, 24.0, 25.0602658637444, 0.3015458085874542, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3776400.0000, 
sim time next is 3778200.0000, 
raw observation next is [-1.0, 65.5, 17.0, 147.0, 24.0, 24.75203233067965, 0.1844079905930008, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.4349030470914128, 0.655, 0.056666666666666664, 0.16243093922651933, 0.5, 0.5626693608899709, 0.5614693301976669, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03775812], dtype=float32), 0.04054938]. 
=============================================
[2019-04-07 15:34:13,186] A3C_AGENT_WORKER-Thread-6 INFO:Local step 72500, global step 1153917: loss 0.1605
[2019-04-07 15:34:13,186] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 72500, global step 1153917: learning rate 0.0000
[2019-04-07 15:34:15,011] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1154336: loss 0.1624
[2019-04-07 15:34:15,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1154336: learning rate 0.0000
[2019-04-07 15:34:15,113] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1154354: loss 89.7662
[2019-04-07 15:34:15,113] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1154354: learning rate 0.0000
[2019-04-07 15:34:15,462] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1154422: loss 88.5534
[2019-04-07 15:34:15,463] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1154422: learning rate 0.0000
[2019-04-07 15:34:17,933] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1154984: loss 0.1602
[2019-04-07 15:34:17,937] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1154984: learning rate 0.0000
[2019-04-07 15:34:20,229] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1155490: loss 0.5695
[2019-04-07 15:34:20,232] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1155490: learning rate 0.0000
[2019-04-07 15:34:20,849] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1155629: loss 0.5197
[2019-04-07 15:34:20,850] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1155629: learning rate 0.0000
[2019-04-07 15:34:21,029] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1155666: loss 87.7793
[2019-04-07 15:34:21,035] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1155667: learning rate 0.0000
[2019-04-07 15:34:21,450] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6202053e-20 5.8909223e-19 6.1462658e-24 1.0514342e-16 3.8042074e-18
 1.0000000e+00 2.0760884e-12 9.1528077e-17], sum to 1.0000
[2019-04-07 15:34:21,450] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1009
[2019-04-07 15:34:21,506] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 92.0, 43.0, 226.0, 24.0, 23.69729072941846, 0.0743548139826619, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3225600.0000, 
sim time next is 3227400.0000, 
raw observation next is [-3.0, 92.0, 85.0, 370.0, 24.0, 23.7036605758409, 0.1145249372574927, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3795013850415513, 0.92, 0.2833333333333333, 0.4088397790055249, 0.5, 0.4753050479867416, 0.5381749790858309, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.99786276], dtype=float32), 1.4762781]. 
=============================================
[2019-04-07 15:34:21,707] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1155809: loss 87.0771
[2019-04-07 15:34:21,708] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1155809: learning rate 0.0000
[2019-04-07 15:34:24,524] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1156360: loss 0.1578
[2019-04-07 15:34:24,524] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1156360: learning rate 0.0000
[2019-04-07 15:34:25,695] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1156604: loss 0.0494
[2019-04-07 15:34:25,696] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1156604: learning rate 0.0000
[2019-04-07 15:34:27,762] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1157016: loss 87.2924
[2019-04-07 15:34:27,763] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1157017: learning rate 0.0000
[2019-04-07 15:34:36,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:34:36,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:34:36,135] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run27
[2019-04-07 15:34:39,947] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1159345: loss 0.4083
[2019-04-07 15:34:39,948] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1159345: learning rate 0.0000
[2019-04-07 15:34:41,077] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1159544: loss 0.1721
[2019-04-07 15:34:41,078] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1159544: learning rate 0.0000
[2019-04-07 15:34:43,959] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-07 15:34:43,959] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:34:43,960] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:34:43,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run59
[2019-04-07 15:34:43,980] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:34:43,981] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:34:43,996] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:34:43,997] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run59
[2019-04-07 15:34:44,017] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:34:44,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run59
[2019-04-07 15:37:05,281] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 15:37:22,379] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 15:37:26,610] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 15:37:27,633] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 1160000, evaluation results [1160000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 15:37:31,575] A3C_AGENT_WORKER-Thread-4 INFO:Local step 72000, global step 1160690: loss 4.2565
[2019-04-07 15:37:31,575] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 72000, global step 1160690: learning rate 0.0000
[2019-04-07 15:37:36,061] A3C_AGENT_WORKER-Thread-6 INFO:Local step 73000, global step 1161383: loss 0.4689
[2019-04-07 15:37:36,061] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 73000, global step 1161383: learning rate 0.0000
[2019-04-07 15:37:39,155] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1161864: loss 0.4655
[2019-04-07 15:37:39,155] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1161864: learning rate 0.0000
[2019-04-07 15:37:40,247] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1162011: loss 0.3684
[2019-04-07 15:37:40,248] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1162011: learning rate 0.0000
[2019-04-07 15:37:41,731] A3C_AGENT_WORKER-Thread-5 INFO:Local step 72000, global step 1162242: loss 4.1075
[2019-04-07 15:37:41,732] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 72000, global step 1162242: learning rate 0.0000
[2019-04-07 15:37:42,880] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1162427: loss 0.0400
[2019-04-07 15:37:42,880] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1162427: learning rate 0.0000
[2019-04-07 15:37:42,951] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1162444: loss 0.0448
[2019-04-07 15:37:42,953] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1162444: learning rate 0.0000
[2019-04-07 15:37:48,141] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1163251: loss 4.7920
[2019-04-07 15:37:48,142] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1163251: learning rate 0.0000
[2019-04-07 15:37:48,849] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1163377: loss 4.5025
[2019-04-07 15:37:48,849] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1163377: learning rate 0.0000
[2019-04-07 15:37:48,867] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1163378: loss 0.4417
[2019-04-07 15:37:48,867] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1163378: learning rate 0.0000
[2019-04-07 15:37:53,842] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:37:53,842] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:37:53,846] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run27
[2019-04-07 15:37:53,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:37:53,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:37:53,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run27
[2019-04-07 15:37:55,466] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1164490: loss 4.3763
[2019-04-07 15:37:55,466] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1164490: learning rate 0.0000
[2019-04-07 15:37:55,491] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1164495: loss 4.4383
[2019-04-07 15:37:55,495] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1164495: learning rate 0.0000
[2019-04-07 15:38:02,382] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1165500: loss 0.0258
[2019-04-07 15:38:02,385] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1165500: learning rate 0.0000
[2019-04-07 15:38:02,524] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1165527: loss 4.8304
[2019-04-07 15:38:02,525] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1165527: learning rate 0.0000
[2019-04-07 15:38:02,644] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.5753602e-17 3.0297179e-14 2.3250283e-20 2.1903052e-14 8.7010528e-16
 1.0000000e+00 2.9364351e-11 9.0193119e-14], sum to 1.0000
[2019-04-07 15:38:02,644] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3860
[2019-04-07 15:38:02,677] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.3, 25.5, 48.0, 279.0, 24.0, 23.0794465172246, -0.1652501309755385, 0.0, 1.0, 18681.19799880585], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2478600.0000, 
sim time next is 2480400.0000, 
raw observation next is [3.3, 25.0, 27.0, 161.0, 24.0, 23.16845297610958, -0.1933713708542831, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.554016620498615, 0.25, 0.09, 0.17790055248618786, 0.5, 0.4307044146757984, 0.43554287638190564, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5412149], dtype=float32), -0.27870408]. 
=============================================
[2019-04-07 15:38:06,892] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1166185: loss 0.5001
[2019-04-07 15:38:06,893] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1166185: learning rate 0.0000
[2019-04-07 15:38:13,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:38:13,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:38:13,985] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run27
[2019-04-07 15:38:15,486] A3C_AGENT_WORKER-Thread-6 INFO:Local step 73500, global step 1167573: loss 0.0294
[2019-04-07 15:38:15,487] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 73500, global step 1167573: learning rate 0.0000
[2019-04-07 15:38:18,682] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1167979: loss 0.0378
[2019-04-07 15:38:18,683] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1167979: learning rate 0.0000
[2019-04-07 15:38:19,357] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1168093: loss 0.0260
[2019-04-07 15:38:19,357] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1168093: learning rate 0.0000
[2019-04-07 15:38:26,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:38:26,554] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:38:26,614] A3C_AGENT_WORKER-Thread-4 INFO:Local step 72500, global step 1169268: loss 0.1674
[2019-04-07 15:38:26,614] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 72500, global step 1169268: learning rate 0.0000
[2019-04-07 15:38:26,615] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run27
[2019-04-07 15:38:26,681] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8494736e-20 4.8378955e-17 1.9593315e-23 3.6540250e-16 6.4393560e-19
 1.0000000e+00 2.8203986e-12 6.4738474e-16], sum to 1.0000
[2019-04-07 15:38:26,682] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5035
[2019-04-07 15:38:26,809] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.4, 89.0, 0.0, 0.0, 24.0, 22.73413845092564, -0.2001580577388831, 0.0, 1.0, 44047.32264158205], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 64800.0000, 
sim time next is 66600.0000, 
raw observation next is [4.1, 87.5, 0.0, 0.0, 24.0, 22.75608941333962, -0.197900456247739, 0.0, 1.0, 32655.397033876827], 
processed observation next is [0.0, 0.782608695652174, 0.5761772853185596, 0.875, 0.0, 0.0, 0.5, 0.3963407844449683, 0.4340331812507537, 0.0, 1.0, 0.1555018906375087], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6816938], dtype=float32), 0.25668362]. 
=============================================
[2019-04-07 15:38:27,917] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1169455: loss 0.0189
[2019-04-07 15:38:27,917] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1169455: learning rate 0.0000
[2019-04-07 15:38:29,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.1632454e-16 1.2577793e-14 7.2378676e-18 8.4172122e-13 4.0688422e-15
 1.0000000e+00 1.8554452e-10 5.7984043e-13], sum to 1.0000
[2019-04-07 15:38:29,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5111
[2019-04-07 15:38:30,084] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-16.45, 79.5, 0.0, 0.0, 24.0, 21.00356203929676, -0.5811783381194949, 1.0, 1.0, 151905.99167284355], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 372600.0000, 
sim time next is 374400.0000, 
raw observation next is [-16.7, 81.0, 12.5, 263.5, 24.0, 22.42339681148947, -0.353154065213471, 0.0, 1.0, 129567.56757596065], 
processed observation next is [1.0, 0.34782608695652173, 0.0, 0.81, 0.041666666666666664, 0.29116022099447514, 0.5, 0.36861640095745596, 0.3822819782621763, 0.0, 1.0, 0.616988417028384], 
reward next is 0.6687, 
noisyNet noise sample is [array([-0.12788828], dtype=float32), -1.0035329]. 
=============================================
[2019-04-07 15:38:30,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:38:30,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:38:30,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run27
[2019-04-07 15:38:30,694] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:38:30,694] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:38:30,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run27
[2019-04-07 15:38:32,541] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.0605735e-21 1.5659002e-20 2.2834220e-24 3.2522621e-17 1.9550564e-20
 1.0000000e+00 2.0453542e-14 2.5595176e-16], sum to 1.0000
[2019-04-07 15:38:32,542] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5784
[2019-04-07 15:38:32,662] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 93.0, 0.0, 0.0, 24.0, 23.45480626102453, -0.1070505083442991, 0.0, 1.0, 29429.97451867085], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2876400.0000, 
sim time next is 2878200.0000, 
raw observation next is [2.0, 93.0, 0.0, 0.0, 24.0, 23.36393709290072, -0.1091803487354661, 1.0, 1.0, 20005.06642049585], 
processed observation next is [1.0, 0.30434782608695654, 0.518005540166205, 0.93, 0.0, 0.0, 0.5, 0.44699475774172664, 0.4636065504215113, 1.0, 1.0, 0.09526222104998024], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1494515], dtype=float32), 0.5564141]. 
=============================================
[2019-04-07 15:38:34,495] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4670379e-19 1.2121933e-17 1.9384780e-23 1.0439411e-15 1.6139465e-17
 1.0000000e+00 1.0219679e-12 4.8608392e-15], sum to 1.0000
[2019-04-07 15:38:34,495] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9443
[2019-04-07 15:38:34,510] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.7, 97.0, 100.5, 0.0, 24.0, 24.02267391883382, -0.04627113910242343, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 907200.0000, 
sim time next is 909000.0000, 
raw observation next is [3.25, 95.0, 104.0, 0.0, 24.0, 23.96089753212429, -0.0571941093680626, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5526315789473685, 0.95, 0.3466666666666667, 0.0, 0.5, 0.4967414610103574, 0.48093529687731246, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.682659], dtype=float32), -0.72057384]. 
=============================================
[2019-04-07 15:38:34,518] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[107.3225 ]
 [106.23422]
 [105.24079]
 [104.59942]
 [104.33873]], R is [[107.90395355]
 [107.82491302]
 [107.74666595]
 [107.66919708]
 [107.59250641]].
[2019-04-07 15:38:35,725] A3C_AGENT_WORKER-Thread-5 INFO:Local step 72500, global step 1170447: loss 0.1849
[2019-04-07 15:38:35,726] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 72500, global step 1170447: learning rate 0.0000
[2019-04-07 15:38:39,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:38:39,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:38:39,213] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run27
[2019-04-07 15:38:43,360] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1171530: loss 0.1847
[2019-04-07 15:38:43,361] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1171530: learning rate 0.0000
[2019-04-07 15:38:43,424] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9128161e-19 9.4800563e-17 3.7579886e-21 1.0204587e-15 3.9712925e-18
 1.0000000e+00 1.3631145e-12 7.2600007e-15], sum to 1.0000
[2019-04-07 15:38:43,424] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8920
[2019-04-07 15:38:43,483] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.6, 25.0, 83.0, 38.0, 24.0, 23.78933661984439, -0.05860386782745974, 1.0, 1.0, 12453.607780153694], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2822400.0000, 
sim time next is 2824200.0000, 
raw observation next is [6.3, 26.5, 71.0, 76.0, 24.0, 24.03661149700474, -0.1321428880618087, 1.0, 1.0, 8302.405186769129], 
processed observation next is [1.0, 0.6956521739130435, 0.6371191135734073, 0.265, 0.23666666666666666, 0.08397790055248619, 0.5, 0.5030509580837282, 0.45595237064606375, 1.0, 1.0, 0.03953526279413871], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8147729], dtype=float32), -0.2234988]. 
=============================================
[2019-04-07 15:38:43,822] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1171615: loss 0.1613
[2019-04-07 15:38:43,823] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1171615: learning rate 0.0000
[2019-04-07 15:38:44,073] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.7879317e-20 1.0559194e-17 7.7878273e-24 9.3854573e-17 5.8209806e-19
 1.0000000e+00 8.6915738e-14 1.9222478e-16], sum to 1.0000
[2019-04-07 15:38:44,074] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8019
[2019-04-07 15:38:44,108] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 24.0, 23.72992336846314, 0.15018637635234, 1.0, 1.0, 65405.969806432106], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3261600.0000, 
sim time next is 3263400.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 24.0, 23.79389759195589, 0.1235725082945342, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3518005540166205, 0.65, 0.0, 0.0, 0.5, 0.4828247993296575, 0.5411908360981781, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2993919], dtype=float32), -1.1410404]. 
=============================================
[2019-04-07 15:38:45,341] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8969706e-19 1.0109186e-17 3.0952355e-22 2.9346486e-15 4.0734928e-19
 1.0000000e+00 1.9389761e-13 1.7216801e-15], sum to 1.0000
[2019-04-07 15:38:45,341] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0136
[2019-04-07 15:38:45,403] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 72.0, 0.0, 0.0, 24.0, 23.53254448762437, -0.07454187443582909, 0.0, 1.0, 18754.856441948], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2854800.0000, 
sim time next is 2856600.0000, 
raw observation next is [1.0, 75.5, 0.0, 0.0, 24.0, 23.49036682875298, -0.1033610798407556, 0.0, 1.0, 39330.01405666183], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 0.755, 0.0, 0.0, 0.5, 0.45753056906274825, 0.4655463067197481, 0.0, 1.0, 0.1872857812221992], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1821929], dtype=float32), -0.62883455]. 
=============================================
[2019-04-07 15:38:45,915] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1171935: loss 0.0289
[2019-04-07 15:38:45,916] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1171935: learning rate 0.0000
[2019-04-07 15:38:47,060] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4320967e-22 1.2805065e-18 2.9207975e-24 1.3696707e-17 1.1464208e-18
 1.0000000e+00 2.2304157e-13 1.0989677e-16], sum to 1.0000
[2019-04-07 15:38:47,060] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0396
[2019-04-07 15:38:47,143] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 100.0, 0.0, 0.0, 24.0, 23.59435583661636, -0.1305354483414201, 0.0, 1.0, 11195.557961621169], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3121200.0000, 
sim time next is 3123000.0000, 
raw observation next is [2.3, 100.0, 0.0, 0.0, 24.0, 23.44740577598159, -0.1226058912836516, 0.0, 1.0, 87891.47434506209], 
processed observation next is [1.0, 0.13043478260869565, 0.5263157894736843, 1.0, 0.0, 0.0, 0.5, 0.45395048133179916, 0.45913136957211614, 0.0, 1.0, 0.4185308302145814], 
reward next is 0.8672, 
noisyNet noise sample is [array([1.0994099], dtype=float32), 1.4992174]. 
=============================================
[2019-04-07 15:38:47,147] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[109.14194]
 [109.27765]
 [109.55141]
 [108.93746]
 [108.27772]], R is [[109.74373627]
 [109.64630127]
 [109.54984283]
 [109.40854645]
 [109.31446075]].
[2019-04-07 15:38:50,863] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1172668: loss 0.1831
[2019-04-07 15:38:50,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1172668: learning rate 0.0000
[2019-04-07 15:38:52,028] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1172809: loss 0.1795
[2019-04-07 15:38:52,028] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1172809: learning rate 0.0000
[2019-04-07 15:38:55,350] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.6562511e-18 8.2172413e-17 8.0037487e-23 2.3524500e-15 3.0016482e-18
 1.0000000e+00 3.3361321e-13 7.7932427e-15], sum to 1.0000
[2019-04-07 15:38:55,351] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1392
[2019-04-07 15:38:55,466] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 67.0, 0.0, 0.0, 24.0, 22.90402263414954, -0.2342958115961475, 0.0, 1.0, 45689.625495868015], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 262800.0000, 
sim time next is 264600.0000, 
raw observation next is [-7.0, 69.0, 0.0, 0.0, 24.0, 22.80729314676313, -0.2534974177343227, 0.0, 1.0, 46122.58268509939], 
processed observation next is [1.0, 0.043478260869565216, 0.2686980609418283, 0.69, 0.0, 0.0, 0.5, 0.4006077622302608, 0.41550086075522574, 0.0, 1.0, 0.2196313461195209], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5491513], dtype=float32), 0.1154708]. 
=============================================
[2019-04-07 15:38:57,352] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:38:57,352] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:38:57,356] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run27
[2019-04-07 15:38:57,837] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1173734: loss 0.1711
[2019-04-07 15:38:57,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1173734: learning rate 0.0000
[2019-04-07 15:39:09,745] A3C_AGENT_WORKER-Thread-4 INFO:Local step 73000, global step 1175468: loss 0.5329
[2019-04-07 15:39:09,746] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 73000, global step 1175468: learning rate 0.0000
[2019-04-07 15:39:16,365] A3C_AGENT_WORKER-Thread-5 INFO:Local step 73000, global step 1176546: loss 0.5458
[2019-04-07 15:39:16,366] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 73000, global step 1176546: learning rate 0.0000
[2019-04-07 15:39:19,472] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.7068874e-18 1.2469864e-15 1.2889592e-20 1.7271671e-14 4.2475484e-16
 1.0000000e+00 1.6418145e-11 1.2640226e-14], sum to 1.0000
[2019-04-07 15:39:19,472] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4664
[2019-04-07 15:39:19,546] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 52.0, 0.0, 0.0, 24.0, 23.41900056630656, -0.06332300316272454, 0.0, 1.0, 38128.50840028332], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4163400.0000, 
sim time next is 4165200.0000, 
raw observation next is [-4.0, 54.0, 0.0, 0.0, 24.0, 23.38237330920155, -0.0647948127630574, 0.0, 1.0, 54285.70900228326], 
processed observation next is [0.0, 0.21739130434782608, 0.3518005540166205, 0.54, 0.0, 0.0, 0.5, 0.4485311091001292, 0.4784017290789809, 0.0, 1.0, 0.2585033762013489], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9662763], dtype=float32), 0.28329036]. 
=============================================
[2019-04-07 15:39:24,431] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1178033: loss 0.5977
[2019-04-07 15:39:24,431] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1178033: learning rate 0.0000
[2019-04-07 15:39:24,458] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1178041: loss 0.5899
[2019-04-07 15:39:24,459] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1178041: learning rate 0.0000
[2019-04-07 15:39:27,055] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.0637521e-20 1.2071220e-17 2.2107817e-23 8.1671811e-16 2.9832143e-17
 1.0000000e+00 2.7096723e-12 4.5773932e-15], sum to 1.0000
[2019-04-07 15:39:27,055] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1561
[2019-04-07 15:39:27,083] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 67.0, 0.0, 0.0, 24.0, 23.78286296606154, -0.02220461872321834, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3706200.0000, 
sim time next is 3708000.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 24.0, 23.53101882593745, -0.04112198093626658, 0.0, 1.0, 74619.2016461321], 
processed observation next is [0.0, 0.9565217391304348, 0.46260387811634357, 0.72, 0.0, 0.0, 0.5, 0.4609182354947876, 0.48629267302124446, 0.0, 1.0, 0.3553295316482481], 
reward next is 0.9304, 
noisyNet noise sample is [array([-0.68165], dtype=float32), 0.6531837]. 
=============================================
[2019-04-07 15:39:27,141] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[99.212265]
 [99.71068 ]
 [99.72966 ]
 [99.762085]
 [98.43599 ]], R is [[99.31629944]
 [99.32313538]
 [99.32990265]
 [99.33660126]
 [99.05565643]].
[2019-04-07 15:39:28,316] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.9059094e-21 3.4712402e-20 1.3933594e-24 4.0729688e-17 1.0241922e-20
 1.0000000e+00 1.9450385e-14 3.6230984e-17], sum to 1.0000
[2019-04-07 15:39:28,316] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4386
[2019-04-07 15:39:28,364] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.4, 61.0, 0.0, 0.0, 24.0, 24.88886742673593, 0.3838910216827396, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4399200.0000, 
sim time next is 4401000.0000, 
raw observation next is [8.95, 61.5, 0.0, 0.0, 24.0, 24.57281854994812, 0.2700056712947128, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.7105263157894738, 0.615, 0.0, 0.0, 0.5, 0.5477348791623434, 0.5900018904315709, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7577348], dtype=float32), 0.68253416]. 
=============================================
[2019-04-07 15:39:28,374] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[110.31214 ]
 [110.66126 ]
 [110.95984 ]
 [111.128265]
 [111.59042 ]], R is [[109.46759033]
 [109.37291718]
 [109.27919006]
 [109.18640137]
 [109.09453583]].
[2019-04-07 15:39:30,780] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3988971e-20 3.4026386e-17 8.1678374e-23 9.7270013e-16 1.4450501e-17
 1.0000000e+00 4.6850676e-11 1.8252885e-15], sum to 1.0000
[2019-04-07 15:39:30,781] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9631
[2019-04-07 15:39:30,853] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 24.0, 23.50654437825035, 0.0311414705803309, 0.0, 1.0, 26476.19567625131], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1468800.0000, 
sim time next is 1470600.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 24.0, 23.45077562400641, 0.06723736698683284, 0.0, 1.0, 53764.525251115934], 
processed observation next is [1.0, 0.0, 0.5069252077562327, 0.92, 0.0, 0.0, 0.5, 0.45423130200053424, 0.5224124556622777, 0.0, 1.0, 0.2560215488148378], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3882893], dtype=float32), 0.32714564]. 
=============================================
[2019-04-07 15:39:31,651] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1179295: loss 0.6242
[2019-04-07 15:39:31,656] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1179298: learning rate 0.0000
[2019-04-07 15:39:31,714] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1179308: loss 0.6231
[2019-04-07 15:39:31,749] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1179308: learning rate 0.0000
[2019-04-07 15:39:33,700] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3533514e-18 1.6732089e-16 3.0983543e-22 1.8444949e-15 1.5414131e-18
 1.0000000e+00 2.9482974e-12 3.6073117e-15], sum to 1.0000
[2019-04-07 15:39:33,701] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5089
[2019-04-07 15:39:33,780] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 41.0, 41.0, 365.0, 24.0, 25.39564040622295, 0.2246051556924296, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3862800.0000, 
sim time next is 3864600.0000, 
raw observation next is [2.5, 44.5, 18.0, 179.0, 24.0, 25.06769606851252, 0.2514775599784929, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5318559556786704, 0.445, 0.06, 0.19779005524861878, 0.5, 0.5889746723760435, 0.5838258533261643, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0205892], dtype=float32), 0.74455726]. 
=============================================
[2019-04-07 15:39:33,928] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.8855284e-20 1.9443198e-17 2.1897325e-22 5.8510025e-15 1.2308547e-18
 1.0000000e+00 1.7000771e-12 8.1313379e-16], sum to 1.0000
[2019-04-07 15:39:33,928] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1213
[2019-04-07 15:39:33,968] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 49.0, 255.5, 80.5, 24.0, 23.8614224757379, 0.07280629878015422, 1.0, 1.0, 15733.487791755333], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4543200.0000, 
sim time next is 4545000.0000, 
raw observation next is [3.0, 47.0, 264.0, 113.0, 24.0, 24.27010649423183, 0.1394080558487435, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5457063711911359, 0.47, 0.88, 0.12486187845303867, 0.5, 0.522508874519319, 0.5464693519495811, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.14763227], dtype=float32), 1.1442508]. 
=============================================
[2019-04-07 15:39:33,977] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[97.89449 ]
 [97.930824]
 [97.91154 ]
 [97.9067  ]
 [98.326416]], R is [[97.69095612]
 [97.71405029]
 [97.73690796]
 [97.75953674]
 [97.78194427]].
[2019-04-07 15:39:35,153] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-07 15:39:35,154] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:39:35,155] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:39:35,158] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:39:35,160] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:39:35,164] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run60
[2019-04-07 15:39:35,180] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:39:35,182] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run60
[2019-04-07 15:39:35,207] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:39:35,214] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run60
[2019-04-07 15:39:48,365] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12368701], dtype=float32), 0.1550216]
[2019-04-07 15:39:48,365] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-5.949999999999999, 82.5, 0.0, 0.0, 24.0, 23.36291632227102, -0.1021450999196898, 0.0, 1.0, 46161.68943163225]
[2019-04-07 15:39:48,365] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 15:39:48,367] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [5.8914388e-19 7.8329636e-17 1.1021346e-21 2.8395128e-15 3.2164203e-17
 1.0000000e+00 3.6878296e-12 9.5544918e-15], sampled 0.7826888097281175
[2019-04-07 15:42:04,677] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 15:42:20,520] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 15:42:24,356] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 15:42:25,380] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1180000, evaluation results [1180000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 15:42:28,718] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1180648: loss 0.5542
[2019-04-07 15:42:28,719] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1180648: learning rate 0.0000
[2019-04-07 15:42:33,271] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8343150e-21 2.3039193e-19 1.2257155e-24 1.3845372e-17 1.0078866e-20
 1.0000000e+00 1.1805561e-14 2.5406264e-16], sum to 1.0000
[2019-04-07 15:42:33,273] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0554
[2019-04-07 15:42:33,353] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 94.0, 0.0, 0.0, 24.0, 23.3786391141081, -0.1308737825482239, 0.0, 1.0, 41189.344687752244], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 513000.0000, 
sim time next is 514800.0000, 
raw observation next is [3.3, 96.0, 0.0, 0.0, 24.0, 23.39737320419209, -0.1278044348696696, 0.0, 1.0, 35501.06956339912], 
processed observation next is [1.0, 1.0, 0.554016620498615, 0.96, 0.0, 0.0, 0.5, 0.44978110034934077, 0.45739852171011014, 0.0, 1.0, 0.1690527122066625], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0224421], dtype=float32), 0.6932004]. 
=============================================
[2019-04-07 15:42:33,667] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.1775160e-21 1.9135699e-17 3.4626233e-24 4.2443878e-17 2.2041601e-18
 1.0000000e+00 1.3466453e-12 4.7482198e-15], sum to 1.0000
[2019-04-07 15:42:33,667] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4223
[2019-04-07 15:42:33,726] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.6, 82.0, 0.0, 0.0, 24.0, 23.64802685825381, 0.01197874215119812, 0.0, 1.0, 8403.477287162346], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 957600.0000, 
sim time next is 959400.0000, 
raw observation next is [7.15, 81.0, 0.0, 0.0, 24.0, 23.64693547121273, -0.006627228555247384, 0.0, 1.0, 6364.220790626364], 
processed observation next is [1.0, 0.08695652173913043, 0.6606648199445985, 0.81, 0.0, 0.0, 0.5, 0.47057795593439405, 0.4977909238149176, 0.0, 1.0, 0.03030581328869697], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.640334], dtype=float32), 1.1792535]. 
=============================================
[2019-04-07 15:42:37,783] A3C_AGENT_WORKER-Thread-4 INFO:Local step 73500, global step 1182328: loss 0.0167
[2019-04-07 15:42:37,783] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 73500, global step 1182328: learning rate 0.0000
[2019-04-07 15:42:43,545] A3C_AGENT_WORKER-Thread-5 INFO:Local step 73500, global step 1183574: loss 0.0196
[2019-04-07 15:42:43,554] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 73500, global step 1183574: learning rate 0.0000
[2019-04-07 15:42:47,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:42:47,893] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:42:47,908] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run27
[2019-04-07 15:42:51,444] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1185227: loss 0.0146
[2019-04-07 15:42:51,445] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1185227: learning rate 0.0000
[2019-04-07 15:42:52,003] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1185316: loss 0.0177
[2019-04-07 15:42:52,011] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1185316: learning rate 0.0000
[2019-04-07 15:42:54,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:42:54,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:42:54,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run27
[2019-04-07 15:42:55,432] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8002862e-20 8.5021392e-19 5.8181908e-24 1.3777940e-16 1.2937684e-18
 1.0000000e+00 1.4574203e-13 1.9424821e-16], sum to 1.0000
[2019-04-07 15:42:55,433] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7022
[2019-04-07 15:42:55,518] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 24.0, 23.4123610726655, 0.06013614147585156, 0.0, 1.0, 81839.4625047653], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1465200.0000, 
sim time next is 1467000.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 24.0, 23.58936840800723, 0.05488575564082327, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.5069252077562327, 0.92, 0.0, 0.0, 0.5, 0.465780700667269, 0.5182952518802745, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09558265], dtype=float32), 0.22000875]. 
=============================================
[2019-04-07 15:42:55,580] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[108.29291 ]
 [108.331345]
 [107.76645 ]
 [108.09443 ]
 [107.725876]], R is [[108.15447235]
 [107.96893311]
 [107.87104797]
 [107.79233551]
 [107.7144165 ]].
[2019-04-07 15:43:00,573] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1186719: loss 0.0266
[2019-04-07 15:43:00,574] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1186719: learning rate 0.0000
[2019-04-07 15:43:00,825] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1186770: loss 0.0368
[2019-04-07 15:43:00,825] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1186770: learning rate 0.0000
[2019-04-07 15:43:02,571] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:43:02,572] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:43:02,575] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run27
[2019-04-07 15:43:03,352] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:43:03,352] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:43:03,356] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run27
[2019-04-07 15:43:06,731] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1187675: loss 0.0214
[2019-04-07 15:43:06,732] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1187675: learning rate 0.0000
[2019-04-07 15:43:11,867] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:43:11,867] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:43:11,872] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run27
[2019-04-07 15:43:12,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:43:12,110] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:43:12,113] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run27
[2019-04-07 15:43:17,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:43:17,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:43:17,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run27
[2019-04-07 15:43:21,706] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4080977e-20 4.8593324e-17 2.7438173e-22 1.0297460e-15 5.1373500e-19
 1.0000000e+00 2.2536015e-13 1.5590200e-15], sum to 1.0000
[2019-04-07 15:43:21,706] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3515
[2019-04-07 15:43:22,061] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 93.0, 21.0, 0.0, 24.0, 21.9191293035185, -0.3492143463773412, 0.0, 1.0, 90934.28898703305], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 30600.0000, 
sim time next is 32400.0000, 
raw observation next is [7.7, 93.0, 29.5, 0.0, 24.0, 22.58013643996006, -0.2901820277045345, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.6759002770083103, 0.93, 0.09833333333333333, 0.0, 0.5, 0.3816780366633384, 0.4032726574318219, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.07519152], dtype=float32), 0.40253177]. 
=============================================
[2019-04-07 15:43:54,808] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.5243754e-20 1.0588968e-16 4.7167034e-21 8.0306294e-16 2.1514012e-18
 1.0000000e+00 1.9483562e-12 2.8469641e-15], sum to 1.0000
[2019-04-07 15:43:54,809] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6757
[2019-04-07 15:43:54,849] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.04999999999999999, 53.5, 131.0, 449.0, 24.0, 24.01614613626757, -0.05570143586212142, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 736200.0000, 
sim time next is 738000.0000, 
raw observation next is [0.5, 50.0, 110.0, 611.0, 24.0, 23.87362216000258, -0.06487250303981476, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.4764542936288089, 0.5, 0.36666666666666664, 0.6751381215469613, 0.5, 0.4894685133335483, 0.47837583232006176, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0889387], dtype=float32), -0.7722209]. 
=============================================
[2019-04-07 15:43:54,879] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[98.241   ]
 [98.62574 ]
 [98.41932 ]
 [98.13785 ]
 [98.020164]], R is [[97.69193268]
 [97.7150116 ]
 [97.73786163]
 [97.76048279]
 [97.78288269]].
[2019-04-07 15:44:27,674] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0373264e-21 1.3020225e-17 1.9544932e-24 1.4316575e-16 1.6014279e-19
 1.0000000e+00 1.5393544e-13 5.9097449e-17], sum to 1.0000
[2019-04-07 15:44:27,674] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9720
[2019-04-07 15:44:27,719] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.39494547449193, -0.07518035795563441, 0.0, 1.0, 91724.8537215871], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3722400.0000, 
sim time next is 3724200.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.53647952339132, -0.07915880407931751, 0.0, 1.0, 12557.500490716426], 
processed observation next is [1.0, 0.08695652173913043, 0.3795013850415513, 0.65, 0.0, 0.0, 0.5, 0.4613732936159434, 0.4736137319735609, 0.0, 1.0, 0.05979762138436393], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05455888], dtype=float32), -2.4674287]. 
=============================================
[2019-04-07 15:44:30,252] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4267870e-18 4.3828290e-17 1.3235986e-21 2.8348806e-15 1.2542032e-17
 1.0000000e+00 1.1577630e-12 7.3438705e-15], sum to 1.0000
[2019-04-07 15:44:30,253] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4989
[2019-04-07 15:44:30,360] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 71.0, 104.5, 0.0, 24.0, 23.80280744946098, -0.1368863127324328, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 820800.0000, 
sim time next is 822600.0000, 
raw observation next is [-4.5, 75.0, 99.0, 0.0, 24.0, 23.57515084858268, -0.1304508603333238, 1.0, 1.0, 92181.77667424096], 
processed observation next is [1.0, 0.5217391304347826, 0.3379501385041552, 0.75, 0.33, 0.0, 0.5, 0.4645959040485567, 0.45651637988889204, 1.0, 1.0, 0.43896084130590934], 
reward next is 0.8468, 
noisyNet noise sample is [array([0.46944013], dtype=float32), 0.034721106]. 
=============================================
[2019-04-07 15:44:33,037] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-07 15:44:33,048] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:44:33,048] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:44:33,052] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:44:33,052] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:44:33,056] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run61
[2019-04-07 15:44:33,075] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:44:33,077] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:44:33,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run61
[2019-04-07 15:44:33,104] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run61
[2019-04-07 15:47:01,691] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 15:47:17,327] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 15:47:20,170] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 15:47:21,193] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1200000, evaluation results [1200000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 15:47:32,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:47:32,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:47:32,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run28
[2019-04-07 15:47:38,338] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5489048e-18 1.0850208e-17 6.7001565e-21 2.2535186e-14 8.0552013e-17
 1.0000000e+00 5.9632868e-11 6.3346769e-15], sum to 1.0000
[2019-04-07 15:47:38,338] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3262
[2019-04-07 15:47:38,502] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 119.0, 90.5, 24.0, 23.48075449599334, -0.06203221097080001, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2970000.0000, 
sim time next is 2971800.0000, 
raw observation next is [-4.0, 71.0, 154.0, 132.0, 24.0, 23.35349263547757, -0.09109685870617613, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3518005540166205, 0.71, 0.5133333333333333, 0.14585635359116023, 0.5, 0.4461243862897974, 0.4696343804312746, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.08480546], dtype=float32), 2.6393223]. 
=============================================
[2019-04-07 15:48:11,610] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.1457131e-19 4.3308776e-16 2.0456629e-21 7.4920869e-15 4.0211605e-16
 1.0000000e+00 1.2879322e-12 8.4890633e-15], sum to 1.0000
[2019-04-07 15:48:11,610] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5387
[2019-04-07 15:48:11,693] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 46.0, 0.0, 0.0, 24.0, 23.46362925116072, -0.01964925917011498, 0.0, 1.0, 41042.78615656982], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4154400.0000, 
sim time next is 4156200.0000, 
raw observation next is [-2.5, 48.0, 0.0, 0.0, 24.0, 23.42794500544272, -0.02675363350878128, 0.0, 1.0, 48604.53694998872], 
processed observation next is [0.0, 0.08695652173913043, 0.39335180055401664, 0.48, 0.0, 0.0, 0.5, 0.45232875045355997, 0.4910821221637396, 0.0, 1.0, 0.23145017595232723], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09653953], dtype=float32), -0.90138286]. 
=============================================
[2019-04-07 15:48:15,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:48:15,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:48:15,028] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run28
[2019-04-07 15:48:16,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:48:16,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:48:16,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run28
[2019-04-07 15:48:36,976] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:48:36,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:48:36,980] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run28
[2019-04-07 15:48:49,473] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:48:49,473] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:48:49,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run28
[2019-04-07 15:48:53,029] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:48:53,029] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:48:53,038] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run28
[2019-04-07 15:48:54,627] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:48:54,628] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:48:54,631] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run28
[2019-04-07 15:48:56,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:48:56,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:48:56,107] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run28
[2019-04-07 15:49:10,863] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.6033768e-19 6.6909495e-17 2.0757542e-21 3.1264564e-15 8.9641720e-18
 1.0000000e+00 1.0118670e-11 6.3420336e-13], sum to 1.0000
[2019-04-07 15:49:10,863] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8967
[2019-04-07 15:49:11,016] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.25, 61.0, 139.0, 484.0, 24.0, 24.2090802662114, 0.07772661427687669, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 135000.0000, 
sim time next is 136800.0000, 
raw observation next is [-6.7, 61.0, 143.5, 295.0, 24.0, 24.25678749909929, 0.06260807862181582, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.2770083102493075, 0.61, 0.47833333333333333, 0.3259668508287293, 0.5, 0.5213989582582741, 0.5208693595406052, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2952981], dtype=float32), 0.3325378]. 
=============================================
[2019-04-07 15:49:17,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:49:17,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:49:17,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run28
[2019-04-07 15:49:24,466] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-07 15:49:24,466] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:49:24,469] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:49:24,474] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run62
[2019-04-07 15:49:24,487] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:49:24,488] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:49:24,492] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run62
[2019-04-07 15:49:24,513] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:49:24,521] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:49:24,526] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run62
[2019-04-07 15:51:52,933] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 15:51:57,691] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.123647], dtype=float32), 0.15588284]
[2019-04-07 15:51:57,691] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-5.0, 33.0, 118.0, 841.0, 24.0, 25.05948754726548, 0.234095982647352, 1.0, 1.0, 0.0]
[2019-04-07 15:51:57,691] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 15:51:57,692] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [6.7354286e-18 9.8643244e-16 3.6536413e-20 2.7386678e-14 2.4128239e-16
 1.0000000e+00 1.4028031e-11 5.8603201e-14], sampled 0.8077322592667464
[2019-04-07 15:52:11,309] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 15:52:16,110] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 15:52:17,132] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1220000, evaluation results [1220000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 15:52:36,230] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3431900e-22 2.8585575e-20 7.3567028e-25 2.1925369e-18 3.4925582e-20
 1.0000000e+00 1.8971020e-15 1.6127279e-17], sum to 1.0000
[2019-04-07 15:52:36,231] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1837
[2019-04-07 15:52:36,298] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 24.0, 23.59543107418499, 0.1349201538127369, 0.0, 1.0, 26593.224101621327], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1314000.0000, 
sim time next is 1315800.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 24.0, 23.72474810022549, 0.1056689546918765, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.5069252077562327, 0.92, 0.0, 0.0, 0.5, 0.4770623416854575, 0.5352229848972921, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.43433633], dtype=float32), -1.3454319]. 
=============================================
[2019-04-07 15:52:55,079] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9313173e-19 7.2502199e-18 4.5437457e-23 5.4986835e-17 2.7327488e-19
 1.0000000e+00 4.1700261e-13 2.6642098e-16], sum to 1.0000
[2019-04-07 15:52:55,079] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1017
[2019-04-07 15:52:55,137] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.65, 65.5, 92.0, 491.0, 24.0, 23.76774615658987, 0.03871754873098666, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4350600.0000, 
sim time next is 4352400.0000, 
raw observation next is [6.3, 57.0, 99.5, 584.0, 24.0, 24.36183964905219, 0.1147669253442061, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6371191135734073, 0.57, 0.33166666666666667, 0.6453038674033149, 0.5, 0.5301533040876825, 0.5382556417814021, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.68463594], dtype=float32), 0.10160159]. 
=============================================
[2019-04-07 15:53:06,545] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7508759e-18 1.3389591e-16 3.1094858e-21 6.0615164e-15 6.7284691e-18
 1.0000000e+00 5.0180363e-12 2.8838009e-14], sum to 1.0000
[2019-04-07 15:53:06,545] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4112
[2019-04-07 15:53:06,601] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 79.0, 0.0, 0.0, 24.0, 22.99928992485471, -0.228413327128776, 0.0, 1.0, 46079.79786444249], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1897200.0000, 
sim time next is 1899000.0000, 
raw observation next is [-7.3, 80.5, 0.0, 0.0, 24.0, 22.90280793429552, -0.2473526244445009, 0.0, 1.0, 46038.17967635431], 
processed observation next is [0.0, 1.0, 0.26038781163434904, 0.805, 0.0, 0.0, 0.5, 0.40856732785796, 0.4175491251851664, 0.0, 1.0, 0.2192294270302586], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.77158743], dtype=float32), -0.5308569]. 
=============================================
[2019-04-07 15:53:06,608] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[94.38399 ]
 [95.03694 ]
 [95.77675 ]
 [96.579025]
 [96.99527 ]], R is [[93.79451752]
 [93.85657501]
 [93.9180069 ]
 [93.97882843]
 [94.03903961]].
[2019-04-07 15:53:10,150] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:53:10,150] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:53:10,157] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run28
[2019-04-07 15:53:18,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:53:18,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:53:18,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run28
[2019-04-07 15:53:23,839] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5179393e-19 2.5714264e-17 3.0249648e-22 1.6690852e-15 1.2430676e-16
 1.0000000e+00 7.6303677e-13 3.1082145e-15], sum to 1.0000
[2019-04-07 15:53:23,871] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0670
[2019-04-07 15:53:23,914] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 79.0, 0.0, 0.0, 24.0, 23.10459693829042, -0.1693407386596852, 0.0, 1.0, 43722.39705537173], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2163600.0000, 
sim time next is 2165400.0000, 
raw observation next is [-7.0, 78.5, 0.0, 0.0, 24.0, 22.97155496651635, -0.188251883160365, 0.0, 1.0, 43781.661204727396], 
processed observation next is [1.0, 0.043478260869565216, 0.2686980609418283, 0.785, 0.0, 0.0, 0.5, 0.4142962472096959, 0.4372493722798783, 0.0, 1.0, 0.20848410097489237], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5379863], dtype=float32), 0.4154634]. 
=============================================
[2019-04-07 15:53:26,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:53:26,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:53:26,314] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run28
[2019-04-07 15:53:26,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:53:26,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:53:26,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run28
[2019-04-07 15:53:35,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:53:35,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:53:35,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run28
[2019-04-07 15:53:35,275] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:53:35,275] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:53:35,279] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run28
[2019-04-07 15:53:43,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:53:43,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:53:43,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run28
[2019-04-07 15:53:49,283] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5649582e-19 1.1462858e-17 2.4940473e-21 3.5428320e-16 2.9782340e-17
 1.0000000e+00 5.8020662e-13 7.2079799e-16], sum to 1.0000
[2019-04-07 15:53:49,284] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7241
[2019-04-07 15:53:49,432] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 75.0, 41.0, 262.0, 24.0, 23.80780214299989, -0.04360608558582014, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2190600.0000, 
sim time next is 2192400.0000, 
raw observation next is [-5.6, 75.0, 71.5, 356.5, 24.0, 24.17498551956825, -0.01108855808990172, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.30747922437673136, 0.75, 0.23833333333333334, 0.3939226519337017, 0.5, 0.5145821266306875, 0.4963038139700328, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6755906], dtype=float32), 0.059831392]. 
=============================================
[2019-04-07 15:54:05,733] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8481282e-18 1.7663653e-15 6.6595102e-22 3.6104935e-14 2.8848984e-16
 1.0000000e+00 2.6570395e-12 1.7384615e-13], sum to 1.0000
[2019-04-07 15:54:05,733] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8083
[2019-04-07 15:54:06,020] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-15.05, 78.0, 39.0, 738.0, 24.0, 24.0034258020526, -0.1018350316805518, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 379800.0000, 
sim time next is 381600.0000, 
raw observation next is [-14.5, 66.0, 55.0, 733.5, 24.0, 23.96587580860119, -0.1074447046277416, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.06094182825484763, 0.66, 0.18333333333333332, 0.8104972375690608, 0.5, 0.4971563173834325, 0.46418509845741945, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.945319], dtype=float32), 1.1006143]. 
=============================================
[2019-04-07 15:54:26,083] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-07 15:54:26,087] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:54:26,088] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:54:26,088] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:54:26,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:54:26,088] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:54:26,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run63
[2019-04-07 15:54:26,098] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run63
[2019-04-07 15:54:26,115] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:54:26,124] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run63
[2019-04-07 15:56:51,548] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 15:57:08,482] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 15:57:13,393] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 15:57:14,417] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1240000, evaluation results [1240000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 15:57:17,604] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1259571e-19 2.3254498e-16 5.4342324e-23 4.6040793e-16 1.9633552e-17
 1.0000000e+00 7.7984548e-13 5.2446074e-14], sum to 1.0000
[2019-04-07 15:57:17,616] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8799
[2019-04-07 15:57:17,702] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 24.0, 23.61766544967751, 0.04845189507487161, 0.0, 1.0, 27834.534029068865], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3362400.0000, 
sim time next is 3364200.0000, 
raw observation next is [-4.5, 68.0, 0.0, 0.0, 24.0, 23.50281155441027, -0.01697170616622258, 0.0, 1.0, 65700.94546560582], 
processed observation next is [1.0, 0.9565217391304348, 0.3379501385041552, 0.68, 0.0, 0.0, 0.5, 0.458567629534189, 0.4943427646112591, 0.0, 1.0, 0.31286164507431347], 
reward next is 0.9729, 
noisyNet noise sample is [array([-0.8435897], dtype=float32), 0.5949717]. 
=============================================
[2019-04-07 15:57:40,093] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6457922e-16 1.4031168e-14 1.1447258e-17 4.0886766e-13 2.1853020e-14
 1.0000000e+00 1.1045377e-10 9.1094428e-13], sum to 1.0000
[2019-04-07 15:57:40,094] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5153
[2019-04-07 15:57:40,117] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [16.1, 78.0, 0.0, 0.0, 24.0, 22.96688002729923, -0.008902939754991013, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1209600.0000, 
sim time next is 1211400.0000, 
raw observation next is [16.1, 79.0, 0.0, 0.0, 24.0, 22.89662571522303, -0.01675795914243981, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.0, 0.9085872576177286, 0.79, 0.0, 0.0, 0.5, 0.4080521429352526, 0.49441401361918674, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.524399], dtype=float32), 0.7118258]. 
=============================================
[2019-04-07 15:57:47,184] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0770038e-20 3.4579233e-17 1.1143141e-21 7.8475366e-15 3.3548599e-17
 1.0000000e+00 5.0821744e-13 1.3894652e-14], sum to 1.0000
[2019-04-07 15:57:47,185] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3006
[2019-04-07 15:57:47,398] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.0, 53.0, 95.5, 579.0, 24.0, 24.23087300627515, 0.1004928407787922, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3920400.0000, 
sim time next is 3922200.0000, 
raw observation next is [-7.5, 51.0, 100.0, 692.0, 24.0, 24.42287931777762, 0.1566894788587688, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.2548476454293629, 0.51, 0.3333333333333333, 0.7646408839779005, 0.5, 0.5352399431481351, 0.5522298262862563, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2769691], dtype=float32), 0.55393916]. 
=============================================
[2019-04-07 15:57:51,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:57:51,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:57:51,360] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run29
[2019-04-07 15:58:10,645] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.4706022e-18 7.0612306e-17 7.0156225e-22 4.2193701e-15 2.5827515e-17
 1.0000000e+00 2.8006928e-12 2.1222851e-14], sum to 1.0000
[2019-04-07 15:58:10,646] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4494
[2019-04-07 15:58:10,690] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 75.0, 250.5, 80.5, 24.0, 24.03674844685373, -0.02328691290344076, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2113200.0000, 
sim time next is 2115000.0000, 
raw observation next is [-7.0, 69.5, 293.0, 101.0, 24.0, 23.96142819519491, -0.01662687304721657, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.2686980609418283, 0.695, 0.9766666666666667, 0.11160220994475138, 0.5, 0.4967856829329091, 0.49445770898426117, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.40508476], dtype=float32), 0.696718]. 
=============================================
[2019-04-07 15:58:10,693] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[94.32927]
 [94.36825]
 [94.85682]
 [94.95625]
 [94.84584]], R is [[94.22248077]
 [94.28025818]
 [94.33745575]
 [94.39408112]
 [94.45014191]].
[2019-04-07 15:58:12,564] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8020119e-18 6.7107636e-16 5.5248702e-21 1.4105065e-14 1.0915053e-17
 1.0000000e+00 9.9166751e-12 2.7538739e-14], sum to 1.0000
[2019-04-07 15:58:12,564] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2916
[2019-04-07 15:58:12,619] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 50.0, 116.0, 817.5, 24.0, 23.4777449995563, 0.0496296224750822, 0.0, 1.0, 18698.550480579757], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3589200.0000, 
sim time next is 3591000.0000, 
raw observation next is [-1.5, 46.0, 114.0, 812.0, 24.0, 23.58592578375457, 0.06469960641111282, 0.0, 1.0, 18695.594386662455], 
processed observation next is [0.0, 0.5652173913043478, 0.4210526315789474, 0.46, 0.38, 0.8972375690607735, 0.5, 0.4654938153128807, 0.5215665354703709, 0.0, 1.0, 0.08902663993648788], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.46809933], dtype=float32), -0.6184532]. 
=============================================
[2019-04-07 15:58:12,624] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[92.35717 ]
 [92.351555]
 [92.453636]
 [92.237144]
 [92.09257 ]], R is [[92.34513092]
 [92.42168427]
 [92.49746704]
 [92.57249451]
 [92.64676666]].
[2019-04-07 15:58:29,403] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.2627833e-19 2.2419752e-16 6.8758873e-22 9.1506181e-15 6.7359683e-18
 1.0000000e+00 2.9452792e-12 4.6894654e-15], sum to 1.0000
[2019-04-07 15:58:29,403] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3295
[2019-04-07 15:58:29,561] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.75, 75.0, 0.0, 0.0, 24.0, 23.87963726919256, -0.03850199985125019, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1967400.0000, 
sim time next is 1969200.0000, 
raw observation next is [-4.5, 71.0, 0.0, 0.0, 24.0, 23.6266689530615, -0.06706285007669836, 1.0, 1.0, 24972.18937642981], 
processed observation next is [1.0, 0.8260869565217391, 0.3379501385041552, 0.71, 0.0, 0.0, 0.5, 0.4688890794217917, 0.47764571664110056, 1.0, 1.0, 0.11891518750680863], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.53727275], dtype=float32), 0.22454175]. 
=============================================
[2019-04-07 15:58:34,221] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:58:34,221] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:58:34,225] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run29
[2019-04-07 15:58:39,157] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:58:39,158] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:58:39,179] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run29
[2019-04-07 15:58:48,807] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8627569e-19 1.2518234e-16 5.3938174e-22 4.9741747e-15 3.9662098e-16
 1.0000000e+00 7.0471981e-13 8.0377626e-14], sum to 1.0000
[2019-04-07 15:58:48,807] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0066
[2019-04-07 15:58:49,049] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.55, 69.0, 0.0, 0.0, 24.0, 23.60461251670856, -0.1245740577996566, 1.0, 1.0, 37262.70052916998], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2226600.0000, 
sim time next is 2228400.0000, 
raw observation next is [-4.6, 70.0, 0.0, 0.0, 24.0, 23.26353406613754, -0.0358054058989911, 0.0, 1.0, 93620.49416623893], 
processed observation next is [1.0, 0.8260869565217391, 0.33518005540166207, 0.7, 0.0, 0.0, 0.5, 0.4386278388447951, 0.4880648647003363, 0.0, 1.0, 0.4458118769820901], 
reward next is 0.8399, 
noisyNet noise sample is [array([0.28540418], dtype=float32), 0.6475971]. 
=============================================
[2019-04-07 15:58:49,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.82592912e-21 1.01732834e-18 2.14194471e-24 1.16170635e-17
 8.05150208e-20 1.00000000e+00 6.30461801e-14 1.72488069e-16], sum to 1.0000
[2019-04-07 15:58:49,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3571
[2019-04-07 15:58:49,871] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.6829687e-19 2.2668804e-16 1.3231349e-20 1.7831621e-15 3.0205678e-17
 1.0000000e+00 2.2799816e-11 3.9468042e-14], sum to 1.0000
[2019-04-07 15:58:49,871] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8602
[2019-04-07 15:58:50,005] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 41.0, 0.0, 0.0, 24.0, 24.05032233422526, 0.1446215859264181, 1.0, 1.0, 28160.61414170954], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3956400.0000, 
sim time next is 3958200.0000, 
raw observation next is [-6.5, 43.0, 0.0, 0.0, 24.0, 23.9637184120751, 0.09661074415813302, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.28254847645429365, 0.43, 0.0, 0.0, 0.5, 0.4969765343395916, 0.5322035813860443, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.2456934], dtype=float32), 0.702279]. 
=============================================
[2019-04-07 15:58:50,053] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.45, 86.0, 79.0, 0.0, 24.0, 22.66264716683804, -0.2127957231209524, 0.0, 1.0, 20263.878448568008], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 52200.0000, 
sim time next is 54000.0000, 
raw observation next is [7.2, 86.0, 64.5, 0.0, 24.0, 22.6778715962926, -0.2245489912633737, 0.0, 1.0, 17343.513406929444], 
processed observation next is [0.0, 0.6521739130434783, 0.662049861495845, 0.86, 0.215, 0.0, 0.5, 0.3898226330243834, 0.42515033624554216, 0.0, 1.0, 0.0825881590806164], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47495937], dtype=float32), 0.4832292]. 
=============================================
[2019-04-07 15:58:50,070] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[102.49885]
 [102.81591]
 [102.97715]
 [103.05566]
 [103.30371]], R is [[102.15380096]
 [102.13226318]
 [102.11093903]
 [102.08982849]
 [102.06893158]].
[2019-04-07 15:59:01,424] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:59:01,424] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:59:01,428] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run29
[2019-04-07 15:59:10,237] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 15:59:10,237] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:59:10,244] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run29
[2019-04-07 15:59:10,899] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-07 15:59:10,909] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:59:10,918] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:59:10,921] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 15:59:10,923] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:59:10,923] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run64
[2019-04-07 15:59:10,943] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 15:59:10,945] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 15:59:10,949] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run64
[2019-04-07 15:59:10,971] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run64
[2019-04-07 15:59:25,861] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.1240058], dtype=float32), 0.1571015]
[2019-04-07 15:59:25,861] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-9.45, 55.0, 92.0, 288.0, 24.0, 23.7860137092552, -0.05861568175399656, 1.0, 1.0, 0.0]
[2019-04-07 15:59:25,861] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 15:59:25,862] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.3986311e-17 1.7020569e-15 7.2591238e-20 3.9861977e-14 4.9440747e-16
 1.0000000e+00 1.9576476e-11 9.4219540e-14], sampled 0.6047121914655059
[2019-04-07 16:01:33,913] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.5307 70927233.8163 166.2180
[2019-04-07 16:01:37,498] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.1240058], dtype=float32), 0.1571015]
[2019-04-07 16:01:37,498] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [1.171121846, 42.83415303, 0.0, 198.4092044, 24.0, 24.71731712790687, 0.1785839801218746, 1.0, 1.0, 0.0]
[2019-04-07 16:01:37,499] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 16:01:37,500] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.1016775e-19 3.5385754e-17 5.3155245e-22 1.0240346e-15 6.5527767e-18
 1.0000000e+00 7.9871515e-13 2.4289123e-15], sampled 0.7885681638401342
[2019-04-07 16:01:50,678] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 16:01:55,058] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 16:01:56,097] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1260000, evaluation results [1260000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.5306997291827, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 16:02:04,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:02:04,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:02:04,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run29
[2019-04-07 16:02:04,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:02:04,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:02:04,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run29
[2019-04-07 16:02:05,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:02:05,477] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:02:05,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run29
[2019-04-07 16:02:23,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:02:23,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:02:23,824] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run29
[2019-04-07 16:03:22,060] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1480575e-21 2.8175296e-18 3.1524298e-24 1.5381723e-16 7.4016477e-20
 1.0000000e+00 1.5233543e-13 6.5363812e-16], sum to 1.0000
[2019-04-07 16:03:22,070] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9121
[2019-04-07 16:03:22,122] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.6, 75.5, 0.0, 0.0, 24.0, 23.63635769672375, -0.02448230097879215, 0.0, 1.0, 58291.53547054636], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4314600.0000, 
sim time next is 4316400.0000, 
raw observation next is [4.4, 75.0, 0.0, 0.0, 24.0, 23.66925383632038, -0.001595891315776102, 0.0, 1.0, 37075.017214997926], 
processed observation next is [0.0, 1.0, 0.5844875346260389, 0.75, 0.0, 0.0, 0.5, 0.47243781969336496, 0.4994680362280746, 0.0, 1.0, 0.17654770102379966], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5437995], dtype=float32), -0.6764224]. 
=============================================
[2019-04-07 16:03:24,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:03:24,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:03:24,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run29
[2019-04-07 16:03:34,734] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.43060079e-20 5.77244372e-19 1.04788275e-23 1.25055388e-16
 5.89523868e-19 1.00000000e+00 5.02651543e-15 4.67388744e-17], sum to 1.0000
[2019-04-07 16:03:34,734] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0078
[2019-04-07 16:03:34,793] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 49.0, 0.0, 0.0, 24.0, 25.37054973631039, 0.4436677150967085, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4644000.0000, 
sim time next is 4645800.0000, 
raw observation next is [3.5, 51.0, 0.0, 0.0, 24.0, 25.40520943133859, 0.4387123359741382, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.5595567867036012, 0.51, 0.0, 0.0, 0.5, 0.6171007859448826, 0.6462374453247127, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.36475214], dtype=float32), -0.77346945]. 
=============================================
[2019-04-07 16:03:39,185] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2194626e-22 3.3474949e-18 1.6585164e-24 1.0330301e-17 2.5974696e-20
 1.0000000e+00 1.5816521e-14 1.1329880e-16], sum to 1.0000
[2019-04-07 16:03:39,186] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3837
[2019-04-07 16:03:39,237] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.1, 77.5, 0.0, 0.0, 24.0, 23.77886444113878, 0.1436778260711853, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1053000.0000, 
sim time next is 1054800.0000, 
raw observation next is [13.8, 78.0, 0.0, 0.0, 24.0, 23.81427729562689, 0.1286878364546634, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.844875346260388, 0.78, 0.0, 0.0, 0.5, 0.4845231079689076, 0.5428959454848877, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.02240125], dtype=float32), -1.0088762]. 
=============================================
[2019-04-07 16:03:40,218] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:03:40,218] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:03:40,230] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run29
[2019-04-07 16:03:40,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:03:40,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:03:40,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run29
[2019-04-07 16:03:41,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:03:41,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:03:41,604] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run29
[2019-04-07 16:03:52,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:03:52,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:03:52,536] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run29
[2019-04-07 16:03:55,318] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:03:55,318] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:03:55,322] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run29
[2019-04-07 16:03:58,206] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-07 16:03:58,207] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:03:58,207] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:03:58,211] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run65
[2019-04-07 16:03:58,232] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:03:58,234] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 16:03:58,245] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:03:58,250] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run65
[2019-04-07 16:03:58,245] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:03:58,270] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run65
[2019-04-07 16:06:25,879] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 16:06:42,729] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 16:06:46,101] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 16:06:47,125] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1280000, evaluation results [1280000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 16:06:52,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:06:52,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:06:52,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run29
[2019-04-07 16:07:19,398] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5363709e-19 3.8494799e-16 5.7260310e-21 3.0068787e-15 3.2884780e-17
 1.0000000e+00 1.1544641e-12 1.5759104e-13], sum to 1.0000
[2019-04-07 16:07:19,400] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2571
[2019-04-07 16:07:19,600] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.95, 63.0, 71.0, 729.0, 24.0, 23.91509600848795, -0.1052254865608452, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 383400.0000, 
sim time next is 385200.0000, 
raw observation next is [-13.4, 60.0, 64.5, 746.5, 24.0, 23.81273392117757, -0.1280846958126492, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.09141274238227146, 0.6, 0.215, 0.8248618784530387, 0.5, 0.4843944934314643, 0.4573051013957836, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2224181], dtype=float32), 0.4193266]. 
=============================================
[2019-04-07 16:07:38,915] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2210882e-21 1.1813021e-17 8.7797032e-24 1.3831753e-17 1.0018498e-19
 1.0000000e+00 3.0255888e-14 2.5393945e-17], sum to 1.0000
[2019-04-07 16:07:38,915] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9497
[2019-04-07 16:07:38,968] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 96.5, 71.0, 54.0, 24.0, 23.40632111405294, -0.07158438766332897, 1.0, 1.0, 20023.872736789694], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2910600.0000, 
sim time next is 2912400.0000, 
raw observation next is [2.0, 93.0, 38.5, 47.5, 24.0, 23.73069430312457, -0.03796805780449509, 1.0, 1.0, 12453.607780153694], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.93, 0.12833333333333333, 0.052486187845303865, 0.5, 0.4775578585937141, 0.48734398073183494, 1.0, 1.0, 0.059302894191208065], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7414862], dtype=float32), -0.34855974]. 
=============================================
[2019-04-07 16:07:46,793] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5595443e-18 2.7739973e-17 1.7978611e-22 2.7684516e-14 7.7136141e-17
 1.0000000e+00 7.7435687e-13 6.5933820e-15], sum to 1.0000
[2019-04-07 16:07:46,794] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3836
[2019-04-07 16:07:46,833] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 24.0, 23.35000584115166, -0.113958623754742, 0.0, 1.0, 41521.055777707574], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3024000.0000, 
sim time next is 3025800.0000, 
raw observation next is [-4.5, 68.0, 0.0, 0.0, 24.0, 23.32669051637665, -0.1203556577712895, 0.0, 1.0, 42840.92071334513], 
processed observation next is [0.0, 0.0, 0.3379501385041552, 0.68, 0.0, 0.0, 0.5, 0.4438908763647209, 0.4598814474095702, 0.0, 1.0, 0.20400438434926252], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.44521293], dtype=float32), -0.7645229]. 
=============================================
[2019-04-07 16:07:47,149] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.4795308e-17 1.4100217e-15 3.9998564e-20 1.0027432e-14 3.6098820e-17
 1.0000000e+00 5.3053317e-12 1.8489481e-14], sum to 1.0000
[2019-04-07 16:07:47,150] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3698
[2019-04-07 16:07:47,245] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.5, 74.0, 0.0, 0.0, 24.0, 23.11096445565462, -0.1804546697317577, 0.0, 1.0, 39952.95220567385], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3033000.0000, 
sim time next is 3034800.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 24.0, 23.01755094446171, -0.2005295473985785, 0.0, 1.0, 40312.220762523786], 
processed observation next is [0.0, 0.13043478260869565, 0.296398891966759, 0.77, 0.0, 0.0, 0.5, 0.41812924537180923, 0.4331568175338072, 0.0, 1.0, 0.19196295601201802], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.13020031], dtype=float32), -1.1967846]. 
=============================================
[2019-04-07 16:07:47,501] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8857671e-23 1.2683375e-19 6.7532558e-26 3.9821827e-19 2.2264251e-20
 1.0000000e+00 6.2657706e-16 1.9749975e-18], sum to 1.0000
[2019-04-07 16:07:47,501] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6396
[2019-04-07 16:07:47,557] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 96.0, 0.0, 0.0, 24.0, 23.44225057613188, -0.01364598585846343, 0.0, 1.0, 45082.597121878905], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 945000.0000, 
sim time next is 946800.0000, 
raw observation next is [5.0, 96.0, 0.0, 0.0, 24.0, 23.47074643308136, -0.01218702964888502, 0.0, 1.0, 29243.797121682874], 
processed observation next is [1.0, 1.0, 0.6011080332409973, 0.96, 0.0, 0.0, 0.5, 0.4558955360901133, 0.495937656783705, 0.0, 1.0, 0.13925617676991844], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.07449286], dtype=float32), -1.6342833]. 
=============================================
[2019-04-07 16:08:01,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:08:01,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:08:01,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run30
[2019-04-07 16:08:02,071] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3805595e-21 1.5481714e-19 1.1555416e-23 1.6379185e-17 3.8953871e-18
 1.0000000e+00 4.3633992e-15 6.4380889e-16], sum to 1.0000
[2019-04-07 16:08:02,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0717
[2019-04-07 16:08:02,190] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 24.0, 23.32833845994326, -0.02782938399350159, 0.0, 1.0, 64154.33764673411], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2934000.0000, 
sim time next is 2935800.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 24.0, 23.35838508606079, -0.02729399716902068, 0.0, 1.0, 46135.11909908726], 
processed observation next is [1.0, 1.0, 0.40720221606648205, 0.85, 0.0, 0.0, 0.5, 0.44653209050506576, 0.49090200094365977, 0.0, 1.0, 0.21969104332898692], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0264999], dtype=float32), -0.536368]. 
=============================================
[2019-04-07 16:08:13,101] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9037822e-21 3.8997285e-18 1.5580966e-25 2.7642790e-17 7.0575845e-20
 1.0000000e+00 1.5699071e-13 1.8156267e-17], sum to 1.0000
[2019-04-07 16:08:13,107] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8126
[2019-04-07 16:08:13,141] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 71.0, 93.0, 727.5, 24.0, 23.92861332214373, 0.254751921174668, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3250800.0000, 
sim time next is 3252600.0000, 
raw observation next is [-2.5, 71.0, 85.0, 686.0, 24.0, 24.8461883486916, 0.339939102060808, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.39335180055401664, 0.71, 0.2833333333333333, 0.7580110497237569, 0.5, 0.5705156957243002, 0.6133130340202694, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.22834902], dtype=float32), -0.95144653]. 
=============================================
[2019-04-07 16:08:25,080] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.7920796e-20 1.3563025e-18 3.7658200e-23 8.3023491e-16 3.8787334e-19
 1.0000000e+00 1.6939231e-13 3.9489539e-16], sum to 1.0000
[2019-04-07 16:08:25,080] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7246
[2019-04-07 16:08:25,178] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 49.0, 115.0, 811.5, 24.0, 24.58337254438603, 0.1674021083919174, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3416400.0000, 
sim time next is 3418200.0000, 
raw observation next is [3.0, 49.0, 113.0, 806.0, 24.0, 24.42313802817743, 0.2032124526085068, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.49, 0.37666666666666665, 0.8906077348066298, 0.5, 0.5352615023481192, 0.5677374842028357, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.99929667], dtype=float32), -0.2055847]. 
=============================================
[2019-04-07 16:08:31,210] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.9757983e-19 3.6833723e-16 1.2621149e-21 7.1633856e-15 1.7563245e-18
 1.0000000e+00 3.5454959e-12 2.5059964e-14], sum to 1.0000
[2019-04-07 16:08:31,210] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6903
[2019-04-07 16:08:31,230] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 49.0, 120.0, 810.0, 24.0, 24.91767390465517, 0.2566854545114485, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3929400.0000, 
sim time next is 3931200.0000, 
raw observation next is [-6.0, 49.0, 119.5, 822.5, 24.0, 24.97462292352336, 0.2619311831457504, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.296398891966759, 0.49, 0.3983333333333333, 0.9088397790055248, 0.5, 0.5812185769602799, 0.5873103943819168, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9940737], dtype=float32), -0.887372]. 
=============================================
[2019-04-07 16:08:47,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:08:47,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:08:47,515] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run30
[2019-04-07 16:08:52,997] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-07 16:08:53,009] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:08:53,009] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:08:53,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run66
[2019-04-07 16:08:53,035] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:08:53,035] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:08:53,039] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run66
[2019-04-07 16:08:53,057] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 16:08:53,057] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:08:53,062] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run66
[2019-04-07 16:09:32,041] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12381475], dtype=float32), 0.157787]
[2019-04-07 16:09:32,041] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [11.0, 85.0, 0.0, 0.0, 24.0, 23.27613538730256, 0.1083588020731227, 0.0, 1.0, 130846.7105547766]
[2019-04-07 16:09:32,041] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 16:09:32,042] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [8.05465354e-23 3.88041864e-20 1.02528406e-25 1.97900976e-18
 8.99728714e-21 1.00000000e+00 7.00652737e-15 1.04717070e-17], sampled 0.26347720079742565
[2019-04-07 16:11:10,480] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 16:11:21,498] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.12381475], dtype=float32), 0.157787]
[2019-04-07 16:11:21,498] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-1.199888374, 38.81551179, 0.0, 0.0, 24.0, 23.64623454030457, 0.001237077369672527, 0.0, 1.0, 62988.73138311776]
[2019-04-07 16:11:21,498] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 16:11:21,499] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [8.9854283e-19 1.2343777e-16 3.5191838e-21 2.8824358e-15 4.2599110e-17
 1.0000000e+00 3.2809057e-12 1.0672924e-14], sampled 0.035682758739323917
[2019-04-07 16:11:27,836] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 16:11:32,860] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 16:11:33,883] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 1300000, evaluation results [1300000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 16:11:36,805] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:11:36,805] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:11:36,808] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run30
[2019-04-07 16:11:47,021] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2549964e-19 1.3420221e-16 2.2915407e-21 1.9850074e-16 7.6149037e-19
 1.0000000e+00 3.8475039e-13 6.4993590e-16], sum to 1.0000
[2019-04-07 16:11:47,021] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0145
[2019-04-07 16:11:47,072] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 35.0, 0.0, 0.0, 24.0, 23.47101039057589, -0.1307076161734373, 0.0, 1.0, 41944.884310168934], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2496600.0000, 
sim time next is 2498400.0000, 
raw observation next is [-1.2, 33.0, 0.0, 0.0, 24.0, 23.47795276457544, -0.1570659688489772, 0.0, 1.0, 21486.590117036732], 
processed observation next is [0.0, 0.9565217391304348, 0.42936288088642666, 0.33, 0.0, 0.0, 0.5, 0.4564960637146201, 0.4476446770503409, 0.0, 1.0, 0.10231709579541301], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3110002], dtype=float32), -0.63718545]. 
=============================================
[2019-04-07 16:11:48,395] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6680763e-18 2.2551074e-16 1.0976415e-20 3.6389480e-15 4.7861676e-17
 1.0000000e+00 4.9798785e-12 8.1658770e-15], sum to 1.0000
[2019-04-07 16:11:48,395] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4293
[2019-04-07 16:11:48,643] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 54.0, 0.0, 0.0, 24.0, 23.50186297427817, -0.1934232367130971, 0.0, 1.0, 13577.579051821262], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2530800.0000, 
sim time next is 2532600.0000, 
raw observation next is [-2.8, 54.0, 0.0, 0.0, 24.0, 23.53096849782335, -0.1725200737478372, 1.0, 1.0, 8363.130217674343], 
processed observation next is [1.0, 0.30434782608695654, 0.38504155124653744, 0.54, 0.0, 0.0, 0.5, 0.46091404148527904, 0.44249330875072096, 1.0, 1.0, 0.03982442960797306], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.52033764], dtype=float32), 0.23611253]. 
=============================================
[2019-04-07 16:11:58,468] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:11:58,469] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:11:58,475] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run30
[2019-04-07 16:12:02,744] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:12:02,744] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:12:02,748] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run30
[2019-04-07 16:12:15,729] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5806994e-21 1.9197470e-18 1.4431451e-23 1.9324802e-18 1.9491224e-19
 1.0000000e+00 6.5543152e-14 1.7799253e-17], sum to 1.0000
[2019-04-07 16:12:15,729] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3747
[2019-04-07 16:12:15,854] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.1, 87.5, 0.0, 0.0, 24.0, 22.75608941333962, -0.197900456247739, 0.0, 1.0, 32655.397033876827], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 66600.0000, 
sim time next is 68400.0000, 
raw observation next is [3.8, 86.0, 0.0, 0.0, 24.0, 22.76415128936222, -0.1960315733194058, 0.0, 1.0, 35215.74422032802], 
processed observation next is [0.0, 0.8260869565217391, 0.5678670360110805, 0.86, 0.0, 0.0, 0.5, 0.3970126074468518, 0.4346561422268647, 0.0, 1.0, 0.1676940200968001], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3100655], dtype=float32), 1.364673]. 
=============================================
[2019-04-07 16:12:16,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:12:16,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:12:16,708] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run30
[2019-04-07 16:12:20,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:12:20,378] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:12:20,394] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run30
[2019-04-07 16:12:22,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:12:22,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:12:22,936] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run30
[2019-04-07 16:12:30,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:12:30,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:12:30,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run30
[2019-04-07 16:12:30,629] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.6994986e-22 2.2516397e-19 3.9597989e-24 1.9281378e-16 4.4442765e-19
 1.0000000e+00 1.2767290e-14 1.0307004e-16], sum to 1.0000
[2019-04-07 16:12:30,630] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7179
[2019-04-07 16:12:30,718] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 92.0, 43.0, 226.0, 24.0, 23.69729072941846, 0.0743548139826619, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3225600.0000, 
sim time next is 3227400.0000, 
raw observation next is [-3.0, 92.0, 85.0, 370.0, 24.0, 23.7036605758409, 0.1145249372574927, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3795013850415513, 0.92, 0.2833333333333333, 0.4088397790055249, 0.5, 0.4753050479867416, 0.5381749790858309, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8509881], dtype=float32), -0.55223423]. 
=============================================
[2019-04-07 16:13:05,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7971243e-22 3.8081712e-18 1.1161581e-25 5.9518453e-18 2.9209369e-20
 1.0000000e+00 5.1819439e-14 9.3681042e-18], sum to 1.0000
[2019-04-07 16:13:05,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6620
[2019-04-07 16:13:05,268] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.3, 96.0, 80.5, 354.0, 24.0, 24.51705724059727, 0.1854334400112654, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1508400.0000, 
sim time next is 1510200.0000, 
raw observation next is [3.85, 94.5, 88.0, 708.0, 24.0, 24.76241579574049, 0.2579145859677494, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.569252077562327, 0.945, 0.29333333333333333, 0.7823204419889502, 0.5, 0.563534649645041, 0.5859715286559165, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4196455], dtype=float32), -0.85135925]. 
=============================================
[2019-04-07 16:13:22,184] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.2896522e-22 6.5893208e-19 1.4807028e-23 5.9894717e-18 2.0278184e-19
 1.0000000e+00 3.4564400e-13 5.7634313e-16], sum to 1.0000
[2019-04-07 16:13:22,184] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1624
[2019-04-07 16:13:22,243] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.8, 28.5, 118.0, 853.0, 24.0, 26.39502684964429, 0.5763035143823388, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4365000.0000, 
sim time next is 4366800.0000, 
raw observation next is [14.6, 29.0, 116.5, 847.5, 24.0, 25.75640121982713, 0.5061598925844062, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.8670360110803325, 0.29, 0.3883333333333333, 0.93646408839779, 0.5, 0.6463667683189275, 0.6687199641948021, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.20108429], dtype=float32), -1.4550084]. 
=============================================
[2019-04-07 16:13:30,502] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.2132168e-21 5.0054384e-19 2.2597580e-23 8.6346208e-17 1.5546052e-18
 1.0000000e+00 1.2287255e-13 1.1858228e-15], sum to 1.0000
[2019-04-07 16:13:30,503] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6719
[2019-04-07 16:13:30,656] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 24.0, 23.2674822162991, -0.1580010950944439, 1.0, 1.0, 32188.7800031973], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 842400.0000, 
sim time next is 844200.0000, 
raw observation next is [-3.9, 84.0, 0.0, 0.0, 24.0, 23.03300370802211, -0.1961313121532292, 1.0, 1.0, 70993.66613067372], 
processed observation next is [1.0, 0.782608695652174, 0.3545706371191136, 0.84, 0.0, 0.0, 0.5, 0.4194169756685093, 0.43462289594892356, 1.0, 1.0, 0.338065076812732], 
reward next is 0.9476, 
noisyNet noise sample is [array([-0.20429125], dtype=float32), -0.1157645]. 
=============================================
[2019-04-07 16:13:31,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:13:31,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:13:31,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run30
[2019-04-07 16:13:35,955] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-07 16:13:35,962] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:13:35,962] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:13:35,965] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:13:35,966] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:13:35,970] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run67
[2019-04-07 16:13:35,989] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 16:13:35,992] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:13:35,999] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run67
[2019-04-07 16:13:36,015] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run67
[2019-04-07 16:16:03,506] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 16:16:21,404] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 16:16:25,194] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 16:16:26,218] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1320000, evaluation results [1320000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 16:16:34,463] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.98763307e-19 2.17109950e-16 2.38340704e-21 4.66165938e-15
 1.20122854e-17 1.00000000e+00 2.26389619e-11 3.62346168e-15], sum to 1.0000
[2019-04-07 16:16:34,463] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1205
[2019-04-07 16:16:34,694] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 256.0, 284.0, 24.0, 23.10155065482063, -0.07264395444182577, 0.0, 1.0, 26915.937386482376], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2979000.0000, 
sim time next is 2980800.0000, 
raw observation next is [-3.0, 65.0, 218.5, 487.5, 24.0, 23.13652823215356, -0.05244180053521783, 0.0, 1.0, 28345.73836504908], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.65, 0.7283333333333334, 0.5386740331491713, 0.5, 0.4280440193461299, 0.48251939982159403, 0.0, 1.0, 0.13497970650023372], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2663147], dtype=float32), -0.6381579]. 
=============================================
[2019-04-07 16:16:37,125] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.3031463e-23 8.2384228e-18 9.4418338e-25 3.1946668e-17 6.2236714e-18
 1.0000000e+00 2.9948103e-13 1.5897136e-16], sum to 1.0000
[2019-04-07 16:16:37,126] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5919
[2019-04-07 16:16:37,177] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.35, 77.0, 0.0, 0.0, 24.0, 23.8357673337444, 0.1922136500556563, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1139400.0000, 
sim time next is 1141200.0000, 
raw observation next is [11.6, 77.0, 0.0, 0.0, 24.0, 23.86764864481017, 0.1847611424828969, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.7839335180055402, 0.77, 0.0, 0.0, 0.5, 0.48897072040084755, 0.561587047494299, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.81649673], dtype=float32), -0.14105481]. 
=============================================
[2019-04-07 16:16:38,402] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:16:38,402] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:16:38,414] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run30
[2019-04-07 16:16:41,059] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:16:41,059] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:16:41,062] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run30
[2019-04-07 16:16:42,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:16:42,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:16:42,820] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run30
[2019-04-07 16:16:49,018] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:16:49,018] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:16:49,035] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run30
[2019-04-07 16:16:54,051] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:16:54,051] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:16:54,074] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run30
[2019-04-07 16:17:03,372] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.7521550e-19 1.3644044e-16 3.5286455e-22 1.7776937e-16 6.4329265e-18
 1.0000000e+00 6.8584201e-13 1.4540046e-14], sum to 1.0000
[2019-04-07 16:17:03,373] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6880
[2019-04-07 16:17:03,435] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 78.0, 0.0, 0.0, 24.0, 22.73794068037159, -0.3222721928566867, 0.0, 1.0, 45610.91342246419], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1913400.0000, 
sim time next is 1915200.0000, 
raw observation next is [-8.4, 78.0, 0.0, 0.0, 24.0, 22.65014087727736, -0.3422169733817035, 0.0, 1.0, 45798.172495578474], 
processed observation next is [1.0, 0.17391304347826086, 0.2299168975069252, 0.78, 0.0, 0.0, 0.5, 0.3875117397731132, 0.38592767553943214, 0.0, 1.0, 0.21808653569323083], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.04486239], dtype=float32), 2.4543276]. 
=============================================
[2019-04-07 16:17:03,999] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3271880e-17 3.5108944e-15 5.2938545e-21 5.0869889e-15 1.9382862e-15
 1.0000000e+00 2.3602795e-11 1.0419768e-13], sum to 1.0000
[2019-04-07 16:17:03,999] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4368
[2019-04-07 16:17:04,269] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 91.0, 0.0, 0.0, 24.0, 22.06122896975347, -0.452561051099803, 0.0, 1.0, 45320.17520198002], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1926000.0000, 
sim time next is 1927800.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 24.0, 22.58097063486317, -0.2453294219875967, 1.0, 1.0, 150367.40320334263], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.5, 0.38174755290526424, 0.4182235260041344, 1.0, 1.0, 0.7160352533492507], 
reward next is 0.5697, 
noisyNet noise sample is [array([-0.24596223], dtype=float32), -1.1667476]. 
=============================================
[2019-04-07 16:17:04,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:17:04,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:17:04,791] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run30
[2019-04-07 16:17:38,268] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.68060754e-19 1.56559796e-17 2.96508949e-21 1.28930675e-15
 4.64980854e-17 1.00000000e+00 1.74372593e-12 1.07881985e-13], sum to 1.0000
[2019-04-07 16:17:38,268] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6316
[2019-04-07 16:17:38,393] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8999999999999999, 50.5, 252.0, 424.0, 24.0, 23.10656042095279, -0.09272347942562455, 0.0, 1.0, 21307.35378544351], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2377800.0000, 
sim time next is 2379600.0000, 
raw observation next is [-0.6, 54.0, 221.5, 212.0, 24.0, 23.1523505747131, -0.111982115301626, 0.0, 1.0, 3116.6169384998016], 
processed observation next is [0.0, 0.5652173913043478, 0.44598337950138506, 0.54, 0.7383333333333333, 0.23425414364640884, 0.5, 0.42936254789275835, 0.4626726282327913, 0.0, 1.0, 0.014841033040475245], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.45166036], dtype=float32), 0.42990476]. 
=============================================
[2019-04-07 16:17:39,323] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.0194535e-24 7.7524781e-21 6.6842064e-27 1.1217666e-18 5.9419453e-21
 1.0000000e+00 1.4366530e-15 3.4783218e-18], sum to 1.0000
[2019-04-07 16:17:39,324] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9987
[2019-04-07 16:17:39,365] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.2, 83.0, 22.0, 69.0, 24.0, 24.16159491584239, 0.2295144389946727, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1067400.0000, 
sim time next is 1069200.0000, 
raw observation next is [12.2, 83.0, 61.0, 151.5, 24.0, 24.64221157777231, 0.2864168482766056, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.8005540166204987, 0.83, 0.20333333333333334, 0.16740331491712707, 0.5, 0.553517631481026, 0.5954722827588685, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1026467], dtype=float32), 0.6143881]. 
=============================================
[2019-04-07 16:17:44,434] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.6657624e-18 2.0026845e-15 7.2880598e-21 3.2194435e-15 3.4429054e-17
 1.0000000e+00 2.0694110e-12 4.8953043e-14], sum to 1.0000
[2019-04-07 16:17:44,434] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6185
[2019-04-07 16:17:44,613] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-14.5, 87.0, 80.0, 330.0, 24.0, 24.06863276610724, -0.007745041285564205, 1.0, 1.0, 9290.7203812737], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2709000.0000, 
sim time next is 2710800.0000, 
raw observation next is [-14.0, 91.0, 88.5, 471.0, 24.0, 24.37830781417745, 0.02372194684171096, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.07479224376731301, 0.91, 0.295, 0.5204419889502763, 0.5, 0.5315256511814542, 0.5079073156139037, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09904254], dtype=float32), -0.9844168]. 
=============================================
[2019-04-07 16:18:04,526] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5561241e-18 2.9912836e-16 3.6183675e-21 8.8429011e-15 1.8231650e-16
 1.0000000e+00 1.9855038e-12 9.3311335e-15], sum to 1.0000
[2019-04-07 16:18:04,535] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0485
[2019-04-07 16:18:04,583] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 70.5, 0.0, 0.0, 24.0, 22.53334364148149, -0.3201391073639568, 0.0, 1.0, 41526.80287240399], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3051000.0000, 
sim time next is 3052800.0000, 
raw observation next is [-6.0, 64.0, 42.0, 214.5, 24.0, 22.46807074778421, -0.2952928717585175, 0.0, 1.0, 41560.103032759536], 
processed observation next is [0.0, 0.34782608695652173, 0.296398891966759, 0.64, 0.14, 0.23701657458563535, 0.5, 0.37233922898201754, 0.4015690427471608, 0.0, 1.0, 0.19790525253695018], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.27409792], dtype=float32), -1.2024397]. 
=============================================
[2019-04-07 16:18:11,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:18:11,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:18:11,288] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run31
[2019-04-07 16:18:23,671] A3C_AGENT_WORKER-Thread-3 INFO:Local step 85000, global step 1338167: loss 0.3420
[2019-04-07 16:18:23,673] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 85000, global step 1338167: learning rate 0.0000
[2019-04-07 16:18:31,205] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2542175e-22 6.0197955e-19 3.3441645e-25 9.0372708e-18 2.5132838e-20
 1.0000000e+00 1.6736056e-15 1.4061635e-17], sum to 1.0000
[2019-04-07 16:18:31,205] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5942
[2019-04-07 16:18:31,278] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.8, 98.0, 0.0, 0.0, 24.0, 23.85423351978741, 0.2166220404162562, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1283400.0000, 
sim time next is 1285200.0000, 
raw observation next is [5.5, 100.0, 0.0, 0.0, 24.0, 23.85402904340233, 0.1940433511326049, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.6149584487534627, 1.0, 0.0, 0.0, 0.5, 0.48783575361686093, 0.5646811170442017, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5735737], dtype=float32), -0.070022754]. 
=============================================
[2019-04-07 16:18:31,922] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-07 16:18:31,925] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:18:31,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:18:31,930] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run68
[2019-04-07 16:18:31,950] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:18:31,952] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:18:31,953] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 16:18:31,953] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:18:31,957] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run68
[2019-04-07 16:18:31,970] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run68
[2019-04-07 16:18:45,201] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12387163], dtype=float32), 0.15878159]
[2019-04-07 16:18:45,202] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-11.8, 73.0, 0.0, 0.0, 24.0, 21.82333199556171, -0.4503869448690782, 0.0, 1.0, 46634.12613400454]
[2019-04-07 16:18:45,202] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 16:18:45,203] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [7.3272370e-18 6.3875485e-16 3.2328619e-20 1.3861485e-14 3.3420246e-16
 1.0000000e+00 1.1974440e-11 4.6000811e-14], sampled 0.7927637410488421
[2019-04-07 16:20:59,086] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 16:21:15,730] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 16:21:19,406] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 16:21:20,428] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1340000, evaluation results [1340000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 16:21:44,051] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:21:44,051] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:21:44,055] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run31
[2019-04-07 16:21:46,731] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.16843110e-19 1.00590675e-16 1.83551196e-21 1.21782596e-15
 3.25022651e-18 1.00000000e+00 9.55298883e-13 1.39392468e-14], sum to 1.0000
[2019-04-07 16:21:46,731] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3411
[2019-04-07 16:21:46,938] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 86.0, 87.5, 0.0, 24.0, 24.25257901839727, -0.1089643999968851, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2041200.0000, 
sim time next is 2043000.0000, 
raw observation next is [-4.2, 84.0, 71.0, 0.0, 24.0, 23.60599683626941, -0.05930944357024478, 1.0, 1.0, 70716.18533967304], 
processed observation next is [1.0, 0.6521739130434783, 0.34626038781163443, 0.84, 0.23666666666666666, 0.0, 0.5, 0.4671664030224507, 0.4802301854765851, 1.0, 1.0, 0.3367437397127288], 
reward next is 0.9490, 
noisyNet noise sample is [array([1.0307643], dtype=float32), -2.194892]. 
=============================================
[2019-04-07 16:21:46,942] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[97.970634]
 [98.02145 ]
 [98.20515 ]
 [97.884575]
 [97.988945]], R is [[98.3544693 ]
 [98.3709259 ]
 [98.38721466]
 [98.4033432 ]
 [98.41931152]].
[2019-04-07 16:21:55,139] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7795609e-22 8.4921557e-19 2.5424001e-24 8.0816356e-18 9.1691840e-20
 1.0000000e+00 3.2067285e-14 1.4070334e-16], sum to 1.0000
[2019-04-07 16:21:55,139] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7911
[2019-04-07 16:21:55,275] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.0, 86.0, 87.0, 0.0, 24.0, 22.59192282372575, -0.2396982055917982, 0.0, 1.0, 30464.61881976014], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 48600.0000, 
sim time next is 50400.0000, 
raw observation next is [7.7, 86.0, 83.0, 0.0, 24.0, 22.61327960569714, -0.2273023177544893, 0.0, 1.0, 31186.44749241265], 
processed observation next is [0.0, 0.6086956521739131, 0.6759002770083103, 0.86, 0.27666666666666667, 0.0, 0.5, 0.3844399671414284, 0.4242325607485036, 0.0, 1.0, 0.14850689282101262], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6875903], dtype=float32), 0.29381788]. 
=============================================
[2019-04-07 16:21:56,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:21:56,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:21:56,435] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run31
[2019-04-07 16:21:57,175] A3C_AGENT_WORKER-Thread-18 INFO:Local step 85000, global step 1345956: loss 0.3351
[2019-04-07 16:21:57,187] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 85000, global step 1345956: learning rate 0.0000
[2019-04-07 16:22:09,993] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.47787174e-19 2.82926130e-16 1.66775719e-20 1.47112629e-15
 1.99070874e-17 1.00000000e+00 1.38122335e-11 3.92817154e-14], sum to 1.0000
[2019-04-07 16:22:09,994] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8012
[2019-04-07 16:22:10,099] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 47.0, 86.0, 341.0, 24.0, 23.08559699746303, -0.1219788510315652, 0.0, 1.0, 21512.876742780423], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2388600.0000, 
sim time next is 2390400.0000, 
raw observation next is [0.0, 47.0, 82.5, 199.5, 24.0, 23.11971074776517, -0.1446723803263576, 0.0, 1.0, 12465.515629789768], 
processed observation next is [0.0, 0.6956521739130435, 0.46260387811634357, 0.47, 0.275, 0.22044198895027625, 0.5, 0.426642562313764, 0.45177587322454743, 0.0, 1.0, 0.059359598237094136], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2177507], dtype=float32), -1.7881008]. 
=============================================
[2019-04-07 16:22:10,757] A3C_AGENT_WORKER-Thread-19 INFO:Local step 85000, global step 1348098: loss 0.3174
[2019-04-07 16:22:10,758] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 85000, global step 1348098: learning rate 0.0000
[2019-04-07 16:22:11,645] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0619741e-18 3.8814777e-16 2.6182399e-21 8.8224781e-16 1.2853921e-16
 1.0000000e+00 1.5671227e-12 2.7725402e-15], sum to 1.0000
[2019-04-07 16:22:11,652] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4594
[2019-04-07 16:22:11,737] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 44.0, 0.0, 0.0, 24.0, 23.32005425829166, -0.1409931016691199, 0.0, 1.0, 56662.907995288784], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2412000.0000, 
sim time next is 2413800.0000, 
raw observation next is [-4.75, 42.5, 0.0, 0.0, 24.0, 23.35192588483691, -0.1520170195201705, 0.0, 1.0, 44840.60625019503], 
processed observation next is [0.0, 0.9565217391304348, 0.3310249307479225, 0.425, 0.0, 0.0, 0.5, 0.4459938237364091, 0.4493276601599432, 0.0, 1.0, 0.21352669642950015], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.55485594], dtype=float32), 1.0062858]. 
=============================================
[2019-04-07 16:22:12,609] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1866673e-20 2.5334415e-19 2.7284414e-23 8.0974391e-17 5.5129179e-19
 1.0000000e+00 4.1223301e-14 1.3135873e-16], sum to 1.0000
[2019-04-07 16:22:12,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8057
[2019-04-07 16:22:12,732] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 56.0, 93.5, 25.5, 24.0, 23.86514448896148, -0.1317634509677651, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2538000.0000, 
sim time next is 2539800.0000, 
raw observation next is [-2.0, 52.5, 136.0, 33.0, 24.0, 23.99372538256477, -0.1039459056278945, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.40720221606648205, 0.525, 0.4533333333333333, 0.036464088397790057, 0.5, 0.4994771152137307, 0.4653513647907019, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.26301503], dtype=float32), 0.5153682]. 
=============================================
[2019-04-07 16:22:13,693] A3C_AGENT_WORKER-Thread-3 INFO:Local step 85500, global step 1348586: loss 0.3323
[2019-04-07 16:22:13,695] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 85500, global step 1348586: learning rate 0.0000
[2019-04-07 16:22:19,003] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8042827e-17 1.1053879e-16 2.0417404e-22 6.5498381e-15 1.1828127e-17
 1.0000000e+00 1.1040690e-12 8.4210046e-16], sum to 1.0000
[2019-04-07 16:22:19,004] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8729
[2019-04-07 16:22:19,146] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 63.0, 0.0, 0.0, 24.0, 23.12129826310711, -0.07671867032476132, 0.0, 1.0, 54992.77628224089], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2664000.0000, 
sim time next is 2665800.0000, 
raw observation next is [-1.2, 64.0, 0.0, 0.0, 24.0, 23.10431973832982, -0.051086925240936, 0.0, 1.0, 136950.59395041136], 
processed observation next is [1.0, 0.8695652173913043, 0.42936288088642666, 0.64, 0.0, 0.0, 0.5, 0.4253599781941517, 0.48297102491968796, 0.0, 1.0, 0.6521456854781493], 
reward next is 0.6336, 
noisyNet noise sample is [array([0.6482586], dtype=float32), -0.5814095]. 
=============================================
[2019-04-07 16:22:20,181] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5176821e-20 2.1417224e-18 2.9806683e-23 7.9692508e-18 2.0786189e-17
 1.0000000e+00 2.3082578e-14 4.7310979e-15], sum to 1.0000
[2019-04-07 16:22:20,181] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5079
[2019-04-07 16:22:20,282] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 24.0, 23.04812773493906, -0.110592632344479, 0.0, 1.0, 42214.62870109883], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4768200.0000, 
sim time next is 4770000.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 24.0, 23.06205781270497, -0.1293042489503869, 0.0, 1.0, 42290.73269206967], 
processed observation next is [0.0, 0.21739130434782608, 0.296398891966759, 0.92, 0.0, 0.0, 0.5, 0.4218381510587476, 0.4568985836832044, 0.0, 1.0, 0.20138444139080797], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.25668144], dtype=float32), -0.2883742]. 
=============================================
[2019-04-07 16:22:20,326] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[97.330376]
 [97.18777 ]
 [97.05839 ]
 [97.151665]
 [96.59606 ]], R is [[97.42652893]
 [97.45226288]
 [97.47773743]
 [97.50296021]
 [97.52793121]].
[2019-04-07 16:22:20,515] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:22:20,515] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:22:20,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run31
[2019-04-07 16:22:22,929] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2438195e-20 8.0043535e-17 7.8223437e-22 1.7615138e-15 1.2578782e-17
 1.0000000e+00 1.3850769e-12 5.3926230e-15], sum to 1.0000
[2019-04-07 16:22:22,929] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4447
[2019-04-07 16:22:22,972] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 34.0, 57.5, 367.0, 24.0, 23.51701739436515, -0.003079339555919251, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4813200.0000, 
sim time next is 4815000.0000, 
raw observation next is [2.5, 37.0, 33.0, 185.0, 24.0, 23.45669397637472, -0.02577545843756971, 0.0, 1.0, 18680.41167023054], 
processed observation next is [0.0, 0.7391304347826086, 0.5318559556786704, 0.37, 0.11, 0.20441988950276244, 0.5, 0.4547244980312266, 0.4914081805208101, 0.0, 1.0, 0.0889543412868121], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.37489253], dtype=float32), -0.7323645]. 
=============================================
[2019-04-07 16:22:22,990] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[93.726685]
 [94.104004]
 [94.07077 ]
 [94.05687 ]
 [94.18533 ]], R is [[93.465271  ]
 [93.53061676]
 [93.59531403]
 [93.65936279]
 [93.72277069]].
[2019-04-07 16:22:23,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:22:23,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:22:23,452] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run31
[2019-04-07 16:22:25,740] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8035197e-16 1.3307970e-15 9.6152360e-20 4.8088225e-14 1.6705502e-15
 1.0000000e+00 9.4900667e-12 6.5319793e-13], sum to 1.0000
[2019-04-07 16:22:25,740] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0416
[2019-04-07 16:22:25,822] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.2, 55.0, 0.0, 0.0, 24.0, 22.35713967742182, -0.3718342882051174, 0.0, 1.0, 46421.703970391805], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 435600.0000, 
sim time next is 437400.0000, 
raw observation next is [-11.2, 55.0, 0.0, 0.0, 24.0, 22.33220728887007, -0.3942762454506705, 0.0, 1.0, 46477.54284803438], 
processed observation next is [1.0, 0.043478260869565216, 0.15235457063711913, 0.55, 0.0, 0.0, 0.5, 0.3610172740725058, 0.3685745848497765, 0.0, 1.0, 0.22132163260968754], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3726724], dtype=float32), -0.49555916]. 
=============================================
[2019-04-07 16:22:27,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1109917e-18 5.3965273e-17 3.8489562e-21 7.4306320e-16 1.5392926e-17
 1.0000000e+00 7.9497971e-12 1.6038774e-14], sum to 1.0000
[2019-04-07 16:22:27,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8297
[2019-04-07 16:22:27,829] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 36.0, 0.0, 0.0, 24.0, 23.54180992298794, -0.07073883615279608, 0.0, 1.0, 53140.78956435351], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4917600.0000, 
sim time next is 4919400.0000, 
raw observation next is [0.5, 37.5, 0.0, 0.0, 24.0, 23.59418064997405, -0.07147366799891322, 0.0, 1.0, 27331.746879025057], 
processed observation next is [0.0, 0.9565217391304348, 0.4764542936288089, 0.375, 0.0, 0.0, 0.5, 0.46618172083117076, 0.47617544400036227, 0.0, 1.0, 0.13015117561440503], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5424973], dtype=float32), -0.21580869]. 
=============================================
[2019-04-07 16:22:33,837] A3C_AGENT_WORKER-Thread-14 INFO:Local step 85000, global step 1351836: loss 0.2970
[2019-04-07 16:22:33,838] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 85000, global step 1351836: learning rate 0.0000
[2019-04-07 16:22:36,171] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:22:36,172] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:22:36,175] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run31
[2019-04-07 16:22:37,138] A3C_AGENT_WORKER-Thread-6 INFO:Local step 85000, global step 1352363: loss 0.2933
[2019-04-07 16:22:37,149] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 85000, global step 1352364: learning rate 0.0000
[2019-04-07 16:22:38,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:22:38,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:22:38,816] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run31
[2019-04-07 16:22:40,775] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:22:40,775] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:22:40,779] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run31
[2019-04-07 16:22:48,296] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9519951e-21 1.2870295e-18 3.8927016e-24 1.3711927e-16 8.6187787e-20
 1.0000000e+00 1.0716542e-13 4.0907062e-16], sum to 1.0000
[2019-04-07 16:22:48,296] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2755
[2019-04-07 16:22:48,387] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 76.0, 0.0, 0.0, 24.0, 23.56080325894844, 0.1311151003906181, 0.0, 1.0, 97576.0584815226], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3270600.0000, 
sim time next is 3272400.0000, 
raw observation next is [-5.0, 81.0, 0.0, 0.0, 24.0, 23.73774225785608, 0.1479439651291026, 0.0, 1.0, 23595.139203521274], 
processed observation next is [1.0, 0.9130434782608695, 0.32409972299168976, 0.81, 0.0, 0.0, 0.5, 0.4781451881546734, 0.5493146550430342, 0.0, 1.0, 0.11235780573105368], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8592791], dtype=float32), 0.6837411]. 
=============================================
[2019-04-07 16:22:48,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:22:48,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:22:48,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run31
[2019-04-07 16:22:50,236] A3C_AGENT_WORKER-Thread-10 INFO:Local step 85000, global step 1354136: loss 0.3243
[2019-04-07 16:22:50,237] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 85000, global step 1354136: learning rate 0.0000
[2019-04-07 16:22:52,758] A3C_AGENT_WORKER-Thread-13 INFO:Local step 85000, global step 1354477: loss 0.2799
[2019-04-07 16:22:52,758] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 85000, global step 1354477: learning rate 0.0000
[2019-04-07 16:22:54,543] A3C_AGENT_WORKER-Thread-3 INFO:Local step 86000, global step 1354730: loss 0.1799
[2019-04-07 16:22:54,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 86000, global step 1354730: learning rate 0.0000
[2019-04-07 16:22:55,183] A3C_AGENT_WORKER-Thread-12 INFO:Local step 85000, global step 1354810: loss 0.2571
[2019-04-07 16:22:55,184] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 85000, global step 1354810: learning rate 0.0000
[2019-04-07 16:23:02,223] A3C_AGENT_WORKER-Thread-18 INFO:Local step 85500, global step 1355838: loss 0.2664
[2019-04-07 16:23:02,224] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 85500, global step 1355838: learning rate 0.0000
[2019-04-07 16:23:02,776] A3C_AGENT_WORKER-Thread-16 INFO:Local step 85000, global step 1355926: loss 0.3215
[2019-04-07 16:23:02,777] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 85000, global step 1355926: learning rate 0.0000
[2019-04-07 16:23:10,704] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.6822042e-24 2.2081037e-21 3.4214533e-28 1.5602833e-20 5.2732078e-24
 1.0000000e+00 1.3529509e-15 1.2042698e-18], sum to 1.0000
[2019-04-07 16:23:10,704] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3969
[2019-04-07 16:23:10,746] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 100.0, 0.0, 0.0, 24.0, 23.65422143057134, 0.2539433046914992, 0.0, 1.0, 139456.66147114744], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3187800.0000, 
sim time next is 3189600.0000, 
raw observation next is [2.0, 100.0, 0.0, 0.0, 24.0, 24.02890707721753, 0.2743468196111028, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.518005540166205, 1.0, 0.0, 0.0, 0.5, 0.5024089231014607, 0.5914489398703676, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.35205036], dtype=float32), -0.43258458]. 
=============================================
[2019-04-07 16:23:16,188] A3C_AGENT_WORKER-Thread-19 INFO:Local step 85500, global step 1358157: loss 0.2192
[2019-04-07 16:23:16,203] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 85500, global step 1358159: learning rate 0.0000
[2019-04-07 16:23:25,591] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.20265298e-20 1.38405142e-17 1.30321604e-23 1.29127060e-15
 2.93660367e-18 1.00000000e+00 1.72139294e-13 2.68095007e-16], sum to 1.0000
[2019-04-07 16:23:25,591] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7676
[2019-04-07 16:23:25,666] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 57.5, 0.0, 0.0, 24.0, 23.39656957073589, -0.08210968124495428, 0.0, 1.0, 68121.67849410117], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2327400.0000, 
sim time next is 2329200.0000, 
raw observation next is [-2.3, 59.0, 0.0, 0.0, 24.0, 23.33758607788711, -0.08221827061733565, 0.0, 1.0, 55307.75234768897], 
processed observation next is [1.0, 1.0, 0.3988919667590028, 0.59, 0.0, 0.0, 0.5, 0.4447988398239258, 0.4725939097942215, 0.0, 1.0, 0.26337024927470937], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.97073674], dtype=float32), -0.9833266]. 
=============================================
[2019-04-07 16:23:26,198] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-07 16:23:26,206] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.1657125e-22 6.6613210e-20 2.6536502e-24 1.5228674e-19 3.3061582e-20
 1.0000000e+00 3.0902324e-15 1.2448185e-16], sum to 1.0000
[2019-04-07 16:23:26,206] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5777
[2019-04-07 16:23:26,229] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:23:26,229] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:23:26,233] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run69
[2019-04-07 16:23:26,250] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:23:26,251] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:23:26,255] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run69
[2019-04-07 16:23:26,274] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 16:23:26,277] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 24.0, 23.52269983324109, 0.08602452228708889, 1.0, 1.0, 13969.50428650214], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1323000.0000, 
sim time next is 1324800.0000, 
raw observation next is [1.1, 92.0, 9.0, 0.0, 24.0, 23.44368031420213, 0.04448737091076998, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.49307479224376743, 0.92, 0.03, 0.0, 0.5, 0.4536400261835108, 0.5148291236369233, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4073611], dtype=float32), -0.3745271]. 
=============================================
[2019-04-07 16:23:26,277] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:23:26,282] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run69
[2019-04-07 16:25:53,978] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 16:25:57,087] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.12420103], dtype=float32), 0.15950315]
[2019-04-07 16:25:57,088] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [-5.681954959, 27.61603558, 39.51001386, 446.35015525, 24.0, 24.2090405530168, -0.0253013182079335, 1.0, 1.0, 0.0]
[2019-04-07 16:25:57,088] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 16:25:57,088] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [2.93161184e-18 4.95561179e-16 2.39498320e-20 1.01159519e-14
 1.02463584e-16 1.00000000e+00 4.38253947e-12 2.08820693e-14], sampled 0.11255604269333297
[2019-04-07 16:26:11,795] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 16:26:13,122] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 16:26:14,146] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1360000, evaluation results [1360000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 16:26:26,760] A3C_AGENT_WORKER-Thread-14 INFO:Local step 85500, global step 1362068: loss 0.2649
[2019-04-07 16:26:26,763] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 85500, global step 1362068: learning rate 0.0000
[2019-04-07 16:26:27,716] A3C_AGENT_WORKER-Thread-18 INFO:Local step 86000, global step 1362264: loss 0.1879
[2019-04-07 16:26:27,721] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 86000, global step 1362265: learning rate 0.0000
[2019-04-07 16:26:28,707] A3C_AGENT_WORKER-Thread-6 INFO:Local step 85500, global step 1362470: loss 0.2785
[2019-04-07 16:26:28,708] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 85500, global step 1362470: learning rate 0.0000
[2019-04-07 16:26:34,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:26:34,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:26:34,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run31
[2019-04-07 16:26:36,066] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.36211943e-22 1.13455615e-19 4.98349368e-25 1.15821891e-18
 7.05141826e-21 1.00000000e+00 1.11985345e-14 5.29555651e-19], sum to 1.0000
[2019-04-07 16:26:36,066] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2005
[2019-04-07 16:26:36,179] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.35, 75.5, 0.0, 0.0, 24.0, 23.66531677614322, -0.02595109215670391, 0.0, 1.0, 22299.889900148602], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4321800.0000, 
sim time next is 4323600.0000, 
raw observation next is [4.2, 75.0, 0.0, 0.0, 24.0, 23.65164681292695, -0.02409074136239375, 0.0, 1.0, 28836.811592845497], 
processed observation next is [1.0, 0.043478260869565216, 0.5789473684210527, 0.75, 0.0, 0.0, 0.5, 0.4709705677439124, 0.49196975287920214, 0.0, 1.0, 0.13731815044212142], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.65291786], dtype=float32), 0.3049396]. 
=============================================
[2019-04-07 16:26:39,047] A3C_AGENT_WORKER-Thread-3 INFO:Local step 86500, global step 1364446: loss 0.2195
[2019-04-07 16:26:39,055] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 86500, global step 1364446: learning rate 0.0000
[2019-04-07 16:26:40,080] A3C_AGENT_WORKER-Thread-10 INFO:Local step 85500, global step 1364635: loss 0.2369
[2019-04-07 16:26:40,088] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 85500, global step 1364635: learning rate 0.0000
[2019-04-07 16:26:41,082] A3C_AGENT_WORKER-Thread-13 INFO:Local step 85500, global step 1364816: loss 0.2382
[2019-04-07 16:26:41,086] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 85500, global step 1364819: learning rate 0.0000
[2019-04-07 16:26:41,599] A3C_AGENT_WORKER-Thread-19 INFO:Local step 86000, global step 1364902: loss 0.1381
[2019-04-07 16:26:41,600] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 86000, global step 1364902: learning rate 0.0000
[2019-04-07 16:26:43,803] A3C_AGENT_WORKER-Thread-12 INFO:Local step 85500, global step 1365302: loss 0.2405
[2019-04-07 16:26:43,804] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 85500, global step 1365302: learning rate 0.0000
[2019-04-07 16:26:45,700] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4446503e-21 1.5049361e-19 5.5366771e-24 2.8345640e-17 5.2058424e-20
 1.0000000e+00 3.5625067e-14 1.8740399e-17], sum to 1.0000
[2019-04-07 16:26:45,700] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2467
[2019-04-07 16:26:45,867] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 100.0, 0.0, 0.0, 24.0, 23.55895699986741, -0.02710184704059007, 0.0, 1.0, 19296.178101757127], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1494000.0000, 
sim time next is 1495800.0000, 
raw observation next is [1.1, 100.0, 0.0, 0.0, 24.0, 23.70154594091535, 0.04484694137394422, 0.0, 1.0, 45116.674590747396], 
processed observation next is [1.0, 0.30434782608695654, 0.49307479224376743, 1.0, 0.0, 0.0, 0.5, 0.4751288284096124, 0.5149489804579814, 0.0, 1.0, 0.2148413075749876], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.29280534], dtype=float32), -0.37411416]. 
=============================================
[2019-04-07 16:26:47,066] A3C_AGENT_WORKER-Thread-4 INFO:Local step 85000, global step 1365979: loss 0.2971
[2019-04-07 16:26:47,067] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 85000, global step 1365979: learning rate 0.0000
[2019-04-07 16:26:50,229] A3C_AGENT_WORKER-Thread-16 INFO:Local step 85500, global step 1366689: loss 0.2134
[2019-04-07 16:26:50,229] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 85500, global step 1366689: learning rate 0.0000
[2019-04-07 16:26:51,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5032598e-20 3.7479583e-18 1.2662320e-23 1.1318605e-16 4.4297709e-19
 1.0000000e+00 1.6780493e-14 3.1616677e-16], sum to 1.0000
[2019-04-07 16:26:51,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3811
[2019-04-07 16:26:51,356] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 46.0, 46.5, 280.0, 24.0, 23.81070303907723, -0.06927915644661746, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4953600.0000, 
sim time next is 4955400.0000, 
raw observation next is [-1.5, 42.5, 93.0, 560.0, 24.0, 23.84434108628028, -0.01083477910610232, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4210526315789474, 0.425, 0.31, 0.6187845303867403, 0.5, 0.48702842385669004, 0.49638840696463254, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9571625], dtype=float32), -0.9801841]. 
=============================================
[2019-04-07 16:26:51,933] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.3116318e-20 2.2004396e-17 2.2012819e-22 7.5670493e-16 9.9485856e-18
 1.0000000e+00 9.6797472e-13 9.6862287e-17], sum to 1.0000
[2019-04-07 16:26:51,933] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1988
[2019-04-07 16:26:51,966] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 24.0, 23.58973198178835, -0.05740398368041468, 0.0, 1.0, 19491.242059150343], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4838400.0000, 
sim time next is 4840200.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 24.0, 23.43119191569092, -0.08348199372088527, 0.0, 1.0, 60508.13932287068], 
processed observation next is [0.0, 0.0, 0.40720221606648205, 0.6, 0.0, 0.0, 0.5, 0.4525993263075767, 0.4721726687597049, 0.0, 1.0, 0.28813399677557466], 
reward next is 0.9976, 
noisyNet noise sample is [array([-0.18340851], dtype=float32), 0.91438234]. 
=============================================
[2019-04-07 16:26:55,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7766263e-22 6.1663373e-19 5.2502456e-24 4.9977736e-17 1.6890408e-18
 1.0000000e+00 6.7665261e-14 7.2024826e-16], sum to 1.0000
[2019-04-07 16:26:55,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6956
[2019-04-07 16:26:55,620] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8999999999999999, 85.0, 0.0, 0.0, 24.0, 23.4266542038052, -0.01049321244482905, 0.0, 1.0, 37170.94327804633], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1747800.0000, 
sim time next is 1749600.0000, 
raw observation next is [-1.2, 87.0, 0.0, 0.0, 24.0, 23.3588601568858, -0.02871233537572261, 0.0, 1.0, 48352.46895492129], 
processed observation next is [0.0, 0.2608695652173913, 0.42936288088642666, 0.87, 0.0, 0.0, 0.5, 0.44657167974048334, 0.4904292215414258, 0.0, 1.0, 0.23024985216629187], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.33802867], dtype=float32), 0.3807981]. 
=============================================
[2019-04-07 16:26:55,970] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:26:55,970] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:26:55,975] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run31
[2019-04-07 16:26:57,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:26:57,785] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:26:57,788] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run31
[2019-04-07 16:27:03,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:27:03,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:27:03,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run31
[2019-04-07 16:27:05,572] A3C_AGENT_WORKER-Thread-14 INFO:Local step 86000, global step 1369353: loss 0.1941
[2019-04-07 16:27:05,586] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 86000, global step 1369353: learning rate 0.0000
[2019-04-07 16:27:07,772] A3C_AGENT_WORKER-Thread-6 INFO:Local step 86000, global step 1369665: loss 0.1897
[2019-04-07 16:27:07,772] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 86000, global step 1369665: learning rate 0.0000
[2019-04-07 16:27:07,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:27:07,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:27:07,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run31
[2019-04-07 16:27:09,045] A3C_AGENT_WORKER-Thread-20 INFO:Local step 85000, global step 1369833: loss 0.3122
[2019-04-07 16:27:09,046] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 85000, global step 1369833: learning rate 0.0000
[2019-04-07 16:27:09,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:27:09,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:27:09,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run31
[2019-04-07 16:27:10,755] A3C_AGENT_WORKER-Thread-17 INFO:Local step 85000, global step 1370050: loss 0.2815
[2019-04-07 16:27:10,756] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 85000, global step 1370050: learning rate 0.0000
[2019-04-07 16:27:11,644] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5894565e-19 3.1183520e-18 5.3375707e-22 5.2249323e-16 1.2401677e-18
 1.0000000e+00 7.6613130e-13 1.2505067e-15], sum to 1.0000
[2019-04-07 16:27:11,644] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1378
[2019-04-07 16:27:11,766] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 60.0, 253.5, 171.5, 24.0, 23.45451592147283, -0.07916781967728537, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4874400.0000, 
sim time next is 4876200.0000, 
raw observation next is [-1.2, 56.0, 300.0, 164.0, 24.0, 23.27620407974743, -0.09692797689758663, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.42936288088642666, 0.56, 1.0, 0.18121546961325966, 0.5, 0.4396836733122858, 0.46769067436747114, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6214019], dtype=float32), -0.95483404]. 
=============================================
[2019-04-07 16:27:16,661] A3C_AGENT_WORKER-Thread-5 INFO:Local step 85000, global step 1370752: loss 0.2916
[2019-04-07 16:27:16,662] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 85000, global step 1370752: learning rate 0.0000
[2019-04-07 16:27:20,903] A3C_AGENT_WORKER-Thread-10 INFO:Local step 86000, global step 1371275: loss 0.1740
[2019-04-07 16:27:20,904] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 86000, global step 1371275: learning rate 0.0000
[2019-04-07 16:27:21,417] A3C_AGENT_WORKER-Thread-13 INFO:Local step 86000, global step 1371329: loss 0.1942
[2019-04-07 16:27:21,417] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 86000, global step 1371329: learning rate 0.0000
[2019-04-07 16:27:21,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:27:21,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:27:21,540] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run31
[2019-04-07 16:27:21,941] A3C_AGENT_WORKER-Thread-18 INFO:Local step 86500, global step 1371379: loss 0.1145
[2019-04-07 16:27:21,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 86500, global step 1371379: learning rate 0.0000
[2019-04-07 16:27:21,996] A3C_AGENT_WORKER-Thread-11 INFO:Local step 85000, global step 1371385: loss 0.2894
[2019-04-07 16:27:21,996] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 85000, global step 1371385: learning rate 0.0000
[2019-04-07 16:27:23,565] A3C_AGENT_WORKER-Thread-2 INFO:Local step 85000, global step 1371569: loss 0.2898
[2019-04-07 16:27:23,566] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 85000, global step 1371569: learning rate 0.0000
[2019-04-07 16:27:23,723] A3C_AGENT_WORKER-Thread-3 INFO:Local step 87000, global step 1371593: loss 2.2691
[2019-04-07 16:27:23,724] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 87000, global step 1371593: learning rate 0.0000
[2019-04-07 16:27:24,501] A3C_AGENT_WORKER-Thread-12 INFO:Local step 86000, global step 1371702: loss 0.1994
[2019-04-07 16:27:24,502] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 86000, global step 1371702: learning rate 0.0000
[2019-04-07 16:27:29,424] A3C_AGENT_WORKER-Thread-16 INFO:Local step 86000, global step 1372259: loss 0.1474
[2019-04-07 16:27:29,424] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 86000, global step 1372259: learning rate 0.0000
[2019-04-07 16:27:36,801] A3C_AGENT_WORKER-Thread-15 INFO:Local step 85000, global step 1373097: loss 0.3058
[2019-04-07 16:27:36,801] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 85000, global step 1373097: learning rate 0.0000
[2019-04-07 16:27:39,041] A3C_AGENT_WORKER-Thread-19 INFO:Local step 86500, global step 1373384: loss 0.1775
[2019-04-07 16:27:39,046] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 86500, global step 1373384: learning rate 0.0000
[2019-04-07 16:27:53,773] A3C_AGENT_WORKER-Thread-4 INFO:Local step 85500, global step 1375295: loss 0.2406
[2019-04-07 16:27:53,775] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 85500, global step 1375295: learning rate 0.0000
[2019-04-07 16:27:54,738] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.2132551e-20 9.1269678e-18 1.1225140e-21 3.9243387e-17 1.5094337e-17
 1.0000000e+00 6.4466753e-13 6.3452180e-16], sum to 1.0000
[2019-04-07 16:27:54,738] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6694
[2019-04-07 16:27:54,803] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 87.0, 0.0, 0.0, 24.0, 23.25996162219259, -0.1431675640067968, 0.0, 1.0, 43551.489249819584], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 604800.0000, 
sim time next is 606600.0000, 
raw observation next is [-3.65, 86.5, 0.0, 0.0, 24.0, 23.19422848383303, -0.1519383038549086, 0.0, 1.0, 43404.578910127435], 
processed observation next is [0.0, 0.0, 0.3614958448753463, 0.865, 0.0, 0.0, 0.5, 0.4328523736527525, 0.44935389871503045, 0.0, 1.0, 0.20668847100060683], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.1545506], dtype=float32), -0.563096]. 
=============================================
[2019-04-07 16:28:01,838] A3C_AGENT_WORKER-Thread-3 INFO:Local step 87500, global step 1376604: loss 0.8538
[2019-04-07 16:28:01,839] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 87500, global step 1376604: learning rate 0.0000
[2019-04-07 16:28:01,859] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1099836e-19 1.8152181e-17 1.8476786e-22 7.1458088e-15 6.8598680e-18
 1.0000000e+00 2.6250924e-12 2.0007526e-15], sum to 1.0000
[2019-04-07 16:28:01,859] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8548
[2019-04-07 16:28:01,892] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 24.0, 24.04788953131608, 0.1298814001070718, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4572000.0000, 
sim time next is 4573800.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 24.0, 23.76364188381744, 0.0152002696096904, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4903047091412743, 0.61, 0.0, 0.0, 0.5, 0.48030349031811986, 0.5050667565365635, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.11706126], dtype=float32), 0.9316281]. 
=============================================
[2019-04-07 16:28:06,460] A3C_AGENT_WORKER-Thread-14 INFO:Local step 86500, global step 1377312: loss 0.1831
[2019-04-07 16:28:06,461] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 86500, global step 1377312: learning rate 0.0000
[2019-04-07 16:28:06,508] A3C_AGENT_WORKER-Thread-18 INFO:Local step 87000, global step 1377318: loss 2.3183
[2019-04-07 16:28:06,513] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 87000, global step 1377319: learning rate 0.0000
[2019-04-07 16:28:11,290] A3C_AGENT_WORKER-Thread-6 INFO:Local step 86500, global step 1378019: loss 0.1699
[2019-04-07 16:28:11,313] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 86500, global step 1378023: learning rate 0.0000
[2019-04-07 16:28:16,277] A3C_AGENT_WORKER-Thread-17 INFO:Local step 85500, global step 1378926: loss 0.2237
[2019-04-07 16:28:16,278] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 85500, global step 1378926: learning rate 0.0000
[2019-04-07 16:28:16,302] A3C_AGENT_WORKER-Thread-20 INFO:Local step 85500, global step 1378936: loss 0.2825
[2019-04-07 16:28:16,302] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 85500, global step 1378936: learning rate 0.0000
[2019-04-07 16:28:19,734] A3C_AGENT_WORKER-Thread-10 INFO:Local step 86500, global step 1379537: loss 0.1898
[2019-04-07 16:28:19,734] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 86500, global step 1379537: learning rate 0.0000
[2019-04-07 16:28:21,592] A3C_AGENT_WORKER-Thread-12 INFO:Local step 86500, global step 1379898: loss 0.1704
[2019-04-07 16:28:21,594] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 86500, global step 1379898: learning rate 0.0000
[2019-04-07 16:28:22,148] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-07 16:28:22,148] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:28:22,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:28:22,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run70
[2019-04-07 16:28:22,168] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:28:22,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:28:22,173] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 16:28:22,174] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:28:22,184] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run70
[2019-04-07 16:28:22,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run70
[2019-04-07 16:30:51,633] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 16:31:07,335] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 16:31:10,679] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 16:31:11,702] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1380000, evaluation results [1380000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 16:31:12,066] A3C_AGENT_WORKER-Thread-19 INFO:Local step 87000, global step 1380065: loss 2.3655
[2019-04-07 16:31:12,067] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 87000, global step 1380065: learning rate 0.0000
[2019-04-07 16:31:12,631] A3C_AGENT_WORKER-Thread-5 INFO:Local step 85500, global step 1380166: loss 0.2426
[2019-04-07 16:31:12,632] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 85500, global step 1380166: learning rate 0.0000
[2019-04-07 16:31:12,792] A3C_AGENT_WORKER-Thread-13 INFO:Local step 86500, global step 1380200: loss 0.2139
[2019-04-07 16:31:12,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 86500, global step 1380200: learning rate 0.0000
[2019-04-07 16:31:13,405] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0015757e-17 2.3322282e-16 4.1332038e-21 9.3295978e-16 1.3481383e-16
 1.0000000e+00 2.3361241e-12 5.5119541e-14], sum to 1.0000
[2019-04-07 16:31:13,405] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8533
[2019-04-07 16:31:13,444] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 24.0, 22.46270373387445, -0.1011091377773739, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1229400.0000, 
sim time next is 1231200.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 24.0, 22.44420022484321, -0.1116782529837491, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.8781163434903049, 0.96, 0.0, 0.0, 0.5, 0.37035001873693424, 0.46277391567208365, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3167174], dtype=float32), 2.255161]. 
=============================================
[2019-04-07 16:31:13,658] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2919098e-17 8.9897618e-16 1.4829040e-20 2.0032394e-14 2.9202204e-15
 1.0000000e+00 1.5059213e-11 1.0866799e-13], sum to 1.0000
[2019-04-07 16:31:13,658] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9138
[2019-04-07 16:31:13,706] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.0, 98.0, 28.0, 0.0, 24.0, 22.27545137113476, -0.1398869556762601, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1240200.0000, 
sim time next is 1242000.0000, 
raw observation next is [15.0, 100.0, 51.0, 0.0, 24.0, 22.24054846025687, -0.1418663672401657, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.8781163434903049, 1.0, 0.17, 0.0, 0.5, 0.35337903835473927, 0.45271121091994476, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.07755025], dtype=float32), 0.031750582]. 
=============================================
[2019-04-07 16:31:13,710] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[87.0993 ]
 [87.07555]
 [87.01649]
 [87.16561]
 [87.27842]], R is [[87.48005676]
 [87.60525513]
 [87.72920227]
 [87.85191345]
 [87.9733963 ]].
[2019-04-07 16:31:14,254] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:31:14,255] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:31:14,266] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run32
[2019-04-07 16:31:15,944] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.8900914e-19 2.4527832e-17 1.5232319e-21 2.0045943e-16 8.3269220e-18
 1.0000000e+00 1.5149147e-12 1.2846581e-14], sum to 1.0000
[2019-04-07 16:31:15,944] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7795
[2019-04-07 16:31:16,146] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 61.5, 83.0, 359.0, 24.0, 22.97738684234859, -0.09682443326394163, 0.0, 1.0, 81231.03112238603], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3054600.0000, 
sim time next is 3056400.0000, 
raw observation next is [-6.0, 59.0, 91.0, 497.0, 24.0, 23.76947646577556, -0.05952160558738397, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.296398891966759, 0.59, 0.30333333333333334, 0.549171270718232, 0.5, 0.4807897054812968, 0.48015946480420535, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2021835], dtype=float32), -0.8836327]. 
=============================================
[2019-04-07 16:31:17,712] A3C_AGENT_WORKER-Thread-2 INFO:Local step 85500, global step 1381119: loss 0.2238
[2019-04-07 16:31:17,712] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 85500, global step 1381119: learning rate 0.0000
[2019-04-07 16:31:17,797] A3C_AGENT_WORKER-Thread-11 INFO:Local step 85500, global step 1381136: loss 0.2487
[2019-04-07 16:31:17,813] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 85500, global step 1381137: learning rate 0.0000
[2019-04-07 16:31:17,854] A3C_AGENT_WORKER-Thread-16 INFO:Local step 86500, global step 1381147: loss 0.2740
[2019-04-07 16:31:17,855] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 86500, global step 1381148: learning rate 0.0000
[2019-04-07 16:31:20,044] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6884059e-22 3.9748352e-20 2.2122810e-25 8.6158243e-19 4.0747785e-21
 1.0000000e+00 1.2543049e-15 2.9528485e-17], sum to 1.0000
[2019-04-07 16:31:20,044] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7837
[2019-04-07 16:31:20,128] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 75.0, 0.0, 0.0, 24.0, 23.93045652169253, 0.149154173106618, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1038600.0000, 
sim time next is 1040400.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 24.0, 23.86766537404801, 0.134152428621878, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.8614958448753465, 0.75, 0.0, 0.0, 0.5, 0.48897211450400074, 0.5447174762072927, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.29182], dtype=float32), -0.5661911]. 
=============================================
[2019-04-07 16:31:20,417] A3C_AGENT_WORKER-Thread-4 INFO:Local step 86000, global step 1381596: loss 0.1708
[2019-04-07 16:31:20,418] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 86000, global step 1381596: learning rate 0.0000
[2019-04-07 16:31:23,533] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.9884007e-23 4.8557279e-21 2.9424003e-26 2.9525752e-19 1.5703148e-20
 1.0000000e+00 1.5251328e-14 1.7643154e-18], sum to 1.0000
[2019-04-07 16:31:23,533] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4314
[2019-04-07 16:31:23,613] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.1, 77.0, 0.0, 0.0, 24.0, 23.67820830824496, 0.1874535313347347, 0.0, 1.0, 87069.8358688476], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1137600.0000, 
sim time next is 1139400.0000, 
raw observation next is [11.35, 77.0, 0.0, 0.0, 24.0, 23.8357673337444, 0.1922136500556563, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.7770083102493075, 0.77, 0.0, 0.0, 0.5, 0.48631394447869997, 0.5640712166852188, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2593874], dtype=float32), -1.3406394]. 
=============================================
[2019-04-07 16:31:25,315] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.62429910e-16 3.04643404e-15 3.90809429e-20 1.88052482e-13
 3.99325001e-15 1.00000000e+00 8.78911111e-11 1.08765244e-13], sum to 1.0000
[2019-04-07 16:31:25,315] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6080
[2019-04-07 16:31:25,357] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [16.6, 75.0, 0.0, 0.0, 24.0, 23.08791127726135, 0.01455885315644618, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1206000.0000, 
sim time next is 1207800.0000, 
raw observation next is [16.35, 76.5, 0.0, 0.0, 24.0, 23.0396226715999, 0.005314174557474137, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 1.0, 0.9155124653739612, 0.765, 0.0, 0.0, 0.5, 0.4199685559666584, 0.5017713915191581, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7912463], dtype=float32), 0.22004543]. 
=============================================
[2019-04-07 16:31:31,320] A3C_AGENT_WORKER-Thread-15 INFO:Local step 85500, global step 1383729: loss 0.2835
[2019-04-07 16:31:31,321] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 85500, global step 1383729: learning rate 0.0000
[2019-04-07 16:31:33,797] A3C_AGENT_WORKER-Thread-18 INFO:Local step 87500, global step 1384261: loss 0.9498
[2019-04-07 16:31:33,797] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 87500, global step 1384261: learning rate 0.0000
[2019-04-07 16:31:38,218] A3C_AGENT_WORKER-Thread-14 INFO:Local step 87000, global step 1385101: loss 2.1810
[2019-04-07 16:31:38,220] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 87000, global step 1385101: learning rate 0.0000
[2019-04-07 16:31:43,827] A3C_AGENT_WORKER-Thread-6 INFO:Local step 87000, global step 1386185: loss 2.2090
[2019-04-07 16:31:43,827] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 87000, global step 1386185: learning rate 0.0000
[2019-04-07 16:31:43,915] A3C_AGENT_WORKER-Thread-17 INFO:Local step 86000, global step 1386202: loss 0.1918
[2019-04-07 16:31:43,926] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 86000, global step 1386202: learning rate 0.0000
[2019-04-07 16:31:45,177] A3C_AGENT_WORKER-Thread-20 INFO:Local step 86000, global step 1386390: loss 0.2228
[2019-04-07 16:31:45,177] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 86000, global step 1386390: learning rate 0.0000
[2019-04-07 16:31:50,269] A3C_AGENT_WORKER-Thread-19 INFO:Local step 87500, global step 1387226: loss 0.9269
[2019-04-07 16:31:50,270] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 87500, global step 1387226: learning rate 0.0000
[2019-04-07 16:31:51,096] A3C_AGENT_WORKER-Thread-5 INFO:Local step 86000, global step 1387342: loss 0.2278
[2019-04-07 16:31:51,096] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 86000, global step 1387342: learning rate 0.0000
[2019-04-07 16:31:51,439] A3C_AGENT_WORKER-Thread-10 INFO:Local step 87000, global step 1387398: loss 2.3208
[2019-04-07 16:31:51,439] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 87000, global step 1387398: learning rate 0.0000
[2019-04-07 16:31:52,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.0448791e-21 1.4367494e-18 4.0989370e-24 8.6722191e-17 4.7899777e-20
 1.0000000e+00 1.2606518e-14 2.2329354e-17], sum to 1.0000
[2019-04-07 16:31:52,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1822
[2019-04-07 16:31:52,724] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 52.0, 125.5, 800.0, 24.0, 25.38825155976026, 0.2255330771819329, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4618800.0000, 
sim time next is 4620600.0000, 
raw observation next is [2.5, 50.5, 122.0, 833.0, 24.0, 25.26770051244191, 0.2316336024480952, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.5318559556786704, 0.505, 0.4066666666666667, 0.9204419889502763, 0.5, 0.605641709370159, 0.5772112008160317, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6565945], dtype=float32), 0.7342869]. 
=============================================
[2019-04-07 16:31:53,482] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3986716e-20 1.6268647e-18 5.4547883e-25 9.5023954e-17 3.6840270e-19
 1.0000000e+00 2.4477829e-13 1.0062752e-16], sum to 1.0000
[2019-04-07 16:31:53,482] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3469
[2019-04-07 16:31:53,522] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.6, 76.0, 76.0, 85.5, 24.0, 24.10894674592164, 0.1240426264540922, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1587600.0000, 
sim time next is 1589400.0000, 
raw observation next is [7.15, 72.0, 115.0, 136.0, 24.0, 24.38615803514736, 0.1975205443876361, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6606648199445985, 0.72, 0.38333333333333336, 0.15027624309392265, 0.5, 0.53217983626228, 0.5658401814625454, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8466257], dtype=float32), 0.8286869]. 
=============================================
[2019-04-07 16:31:53,688] A3C_AGENT_WORKER-Thread-12 INFO:Local step 87000, global step 1387836: loss 2.2453
[2019-04-07 16:31:53,701] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 87000, global step 1387836: learning rate 0.0000
[2019-04-07 16:31:55,178] A3C_AGENT_WORKER-Thread-13 INFO:Local step 87000, global step 1388086: loss 2.1928
[2019-04-07 16:31:55,179] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 87000, global step 1388086: learning rate 0.0000
[2019-04-07 16:31:55,849] A3C_AGENT_WORKER-Thread-11 INFO:Local step 86000, global step 1388192: loss 0.2081
[2019-04-07 16:31:55,850] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 86000, global step 1388192: learning rate 0.0000
[2019-04-07 16:31:56,969] A3C_AGENT_WORKER-Thread-2 INFO:Local step 86000, global step 1388363: loss 0.1983
[2019-04-07 16:31:56,973] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 86000, global step 1388363: learning rate 0.0000
[2019-04-07 16:31:57,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:31:57,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:31:57,270] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run32
[2019-04-07 16:32:00,864] A3C_AGENT_WORKER-Thread-16 INFO:Local step 87000, global step 1388950: loss 2.2012
[2019-04-07 16:32:00,865] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 87000, global step 1388950: learning rate 0.0000
[2019-04-07 16:32:10,426] A3C_AGENT_WORKER-Thread-15 INFO:Local step 86000, global step 1390345: loss 0.1868
[2019-04-07 16:32:10,427] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 86000, global step 1390345: learning rate 0.0000
[2019-04-07 16:32:10,696] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2677829e-21 2.6942741e-19 7.8778545e-24 2.2075354e-17 2.4669111e-20
 1.0000000e+00 2.1122257e-14 3.5593569e-17], sum to 1.0000
[2019-04-07 16:32:10,697] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8908
[2019-04-07 16:32:10,784] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.15, 67.5, 0.0, 0.0, 24.0, 24.05968748486412, 0.1405066071968682, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4422600.0000, 
sim time next is 4424400.0000, 
raw observation next is [3.8, 68.0, 0.0, 0.0, 24.0, 23.88832172575364, 0.09200764322055865, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.5678670360110805, 0.68, 0.0, 0.0, 0.5, 0.4906934771461368, 0.5306692144068529, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2614244], dtype=float32), 1.7096908]. 
=============================================
[2019-04-07 16:32:11,724] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.41284078e-19 6.11705278e-16 1.45226430e-21 2.46652225e-15
 1.06994105e-16 1.00000000e+00 4.32116669e-12 1.58183301e-14], sum to 1.0000
[2019-04-07 16:32:11,724] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1679
[2019-04-07 16:32:11,803] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 31.0, 0.0, 0.0, 24.0, 23.78858658479458, 0.1205603638649787, 1.0, 1.0, 63302.37931425681], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4042800.0000, 
sim time next is 4044600.0000, 
raw observation next is [-4.0, 31.0, 0.0, 0.0, 24.0, 23.97496414814442, 0.09156850737603277, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3518005540166205, 0.31, 0.0, 0.0, 0.5, 0.4979136790120349, 0.530522835792011, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4383624], dtype=float32), 0.7289673]. 
=============================================
[2019-04-07 16:32:12,047] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.40248945e-21 1.37622795e-17 2.79877594e-23 4.57403933e-16
 3.44131475e-18 1.00000000e+00 1.41896594e-14 2.13550114e-15], sum to 1.0000
[2019-04-07 16:32:12,047] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8801
[2019-04-07 16:32:12,104] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 77.0, 0.0, 0.0, 24.0, 22.65830140976488, -0.2729375328616368, 0.0, 1.0, 42862.96169247156], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2179800.0000, 
sim time next is 2181600.0000, 
raw observation next is [-6.2, 79.0, 0.0, 0.0, 24.0, 22.57964502854515, -0.2938941219849456, 0.0, 1.0, 42792.90940094983], 
processed observation next is [1.0, 0.2608695652173913, 0.2908587257617729, 0.79, 0.0, 0.0, 0.5, 0.3816370857120959, 0.4020352926716848, 0.0, 1.0, 0.20377575905214204], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0439347], dtype=float32), 0.15273651]. 
=============================================
[2019-04-07 16:32:13,262] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.1722183e-22 1.1200215e-19 3.2870473e-25 1.7319016e-17 3.2891271e-19
 1.0000000e+00 1.0435549e-15 1.9306981e-17], sum to 1.0000
[2019-04-07 16:32:13,262] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7214
[2019-04-07 16:32:13,291] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.0, 19.0, 86.0, 665.0, 24.0, 27.00292468609986, 0.7517892085021275, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5068800.0000, 
sim time next is 5070600.0000, 
raw observation next is [12.0, 18.0, 76.0, 585.0, 24.0, 27.28658621296148, 0.7962694082658949, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.7950138504155125, 0.18, 0.25333333333333335, 0.6464088397790055, 0.5, 0.7738821844134568, 0.7654231360886317, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3789626], dtype=float32), 0.5312106]. 
=============================================
[2019-04-07 16:32:15,268] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:32:15,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:32:15,272] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run32
[2019-04-07 16:32:17,034] A3C_AGENT_WORKER-Thread-4 INFO:Local step 86500, global step 1391376: loss 0.1850
[2019-04-07 16:32:17,037] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 86500, global step 1391376: learning rate 0.0000
[2019-04-07 16:32:17,548] A3C_AGENT_WORKER-Thread-14 INFO:Local step 87500, global step 1391461: loss 0.9720
[2019-04-07 16:32:17,549] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 87500, global step 1391461: learning rate 0.0000
[2019-04-07 16:32:18,128] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4492756e-20 3.3447251e-18 8.0539205e-22 6.5293998e-17 9.8431091e-19
 1.0000000e+00 4.1869838e-14 2.5675268e-16], sum to 1.0000
[2019-04-07 16:32:18,141] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6988
[2019-04-07 16:32:18,180] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 80.5, 0.0, 0.0, 24.0, 22.98035367328965, -0.154440670081765, 0.0, 1.0, 44047.57437676625], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2161800.0000, 
sim time next is 2163600.0000, 
raw observation next is [-7.3, 79.0, 0.0, 0.0, 24.0, 23.10459693829042, -0.1693407386596852, 0.0, 1.0, 43722.39705537173], 
processed observation next is [1.0, 0.043478260869565216, 0.26038781163434904, 0.79, 0.0, 0.0, 0.5, 0.42538307819086835, 0.44355308711343827, 0.0, 1.0, 0.2082018907398654], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5741132], dtype=float32), -0.52467585]. 
=============================================
[2019-04-07 16:32:24,703] A3C_AGENT_WORKER-Thread-6 INFO:Local step 87500, global step 1392565: loss 0.9037
[2019-04-07 16:32:24,704] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 87500, global step 1392565: learning rate 0.0000
[2019-04-07 16:32:30,636] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1365441e-20 9.9204284e-18 5.1911797e-23 3.0767508e-16 9.1315644e-18
 1.0000000e+00 1.9810088e-13 5.7808040e-16], sum to 1.0000
[2019-04-07 16:32:30,636] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9204
[2019-04-07 16:32:30,688] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 24.0, 22.82458879728822, -0.2360299407010299, 0.0, 1.0, 42402.639583818855], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2359800.0000, 
sim time next is 2361600.0000, 
raw observation next is [-3.4, 69.0, 19.5, 0.0, 24.0, 22.74703874151452, -0.2222193445883461, 0.0, 1.0, 42752.396137283155], 
processed observation next is [0.0, 0.34782608695652173, 0.368421052631579, 0.69, 0.065, 0.0, 0.5, 0.3955865617928766, 0.425926885137218, 0.0, 1.0, 0.2035828387489674], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6193798], dtype=float32), -1.4632584]. 
=============================================
[2019-04-07 16:32:32,237] A3C_AGENT_WORKER-Thread-10 INFO:Local step 87500, global step 1393901: loss 1.0030
[2019-04-07 16:32:32,239] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 87500, global step 1393901: learning rate 0.0000
[2019-04-07 16:32:32,719] A3C_AGENT_WORKER-Thread-12 INFO:Local step 87500, global step 1394000: loss 1.0164
[2019-04-07 16:32:32,720] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 87500, global step 1394000: learning rate 0.0000
[2019-04-07 16:32:33,017] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2270192e-19 2.2127689e-19 8.2279114e-23 4.1737460e-15 3.1499751e-18
 1.0000000e+00 2.2929578e-13 8.6715951e-16], sum to 1.0000
[2019-04-07 16:32:33,017] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4726
[2019-04-07 16:32:33,064] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.7, 62.0, 0.0, 0.0, 24.0, 23.57799797983006, 0.007263054014500087, 0.0, 1.0, 25212.94722258326], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4581000.0000, 
sim time next is 4582800.0000, 
raw observation next is [0.4, 63.0, 0.0, 0.0, 24.0, 23.54747983230766, -0.004891265456536838, 0.0, 1.0, 34632.017311252166], 
processed observation next is [1.0, 0.043478260869565216, 0.4736842105263158, 0.63, 0.0, 0.0, 0.5, 0.4622899860256382, 0.4983695781811544, 0.0, 1.0, 0.16491436814881985], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.55332035], dtype=float32), 0.6371728]. 
=============================================
[2019-04-07 16:32:34,595] A3C_AGENT_WORKER-Thread-13 INFO:Local step 87500, global step 1394315: loss 0.9164
[2019-04-07 16:32:34,596] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 87500, global step 1394315: learning rate 0.0000
[2019-04-07 16:32:40,570] A3C_AGENT_WORKER-Thread-16 INFO:Local step 87500, global step 1395423: loss 0.9441
[2019-04-07 16:32:40,570] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 87500, global step 1395423: learning rate 0.0000
[2019-04-07 16:32:40,940] A3C_AGENT_WORKER-Thread-17 INFO:Local step 86500, global step 1395497: loss 0.1735
[2019-04-07 16:32:40,942] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 86500, global step 1395497: learning rate 0.0000
[2019-04-07 16:32:41,546] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:32:41,547] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:32:41,550] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run32
[2019-04-07 16:32:41,793] A3C_AGENT_WORKER-Thread-20 INFO:Local step 86500, global step 1395615: loss 0.1693
[2019-04-07 16:32:41,809] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 86500, global step 1395615: learning rate 0.0000
[2019-04-07 16:32:47,924] A3C_AGENT_WORKER-Thread-5 INFO:Local step 86500, global step 1396569: loss 0.1703
[2019-04-07 16:32:47,925] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 86500, global step 1396569: learning rate 0.0000
[2019-04-07 16:32:48,289] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9461071e-24 1.7623006e-22 2.8106048e-26 1.6905539e-20 2.1690659e-21
 1.0000000e+00 7.8459169e-16 4.2665580e-19], sum to 1.0000
[2019-04-07 16:32:48,290] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7459
[2019-04-07 16:32:48,347] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:32:48,347] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:32:48,351] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run32
[2019-04-07 16:32:48,555] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 93.0, 6.0, 41.0, 24.0, 22.90956459630621, -0.1496034417261138, 1.0, 1.0, 75570.36285320675], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2914200.0000, 
sim time next is 2916000.0000, 
raw observation next is [1.0, 93.0, 0.0, 0.0, 24.0, 23.51847344049241, -0.00194402583854388, 1.0, 1.0, 47587.14448217727], 
processed observation next is [1.0, 0.782608695652174, 0.4903047091412743, 0.93, 0.0, 0.0, 0.5, 0.4598727867077009, 0.499351991387152, 1.0, 1.0, 0.22660544991512985], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.83577293], dtype=float32), -0.52450234]. 
=============================================
[2019-04-07 16:32:48,562] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[108.261444]
 [108.27551 ]
 [108.527466]
 [108.63205 ]
 [108.49995 ]], R is [[108.19636536]
 [108.04026031]
 [107.95986176]
 [107.88026428]
 [107.80146027]].
[2019-04-07 16:32:52,924] A3C_AGENT_WORKER-Thread-11 INFO:Local step 86500, global step 1397309: loss 0.1210
[2019-04-07 16:32:52,931] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 86500, global step 1397309: learning rate 0.0000
[2019-04-07 16:32:55,372] A3C_AGENT_WORKER-Thread-2 INFO:Local step 86500, global step 1397695: loss 0.2154
[2019-04-07 16:32:55,372] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 86500, global step 1397695: learning rate 0.0000
[2019-04-07 16:32:56,658] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:32:56,659] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:32:56,663] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run32
[2019-04-07 16:32:56,748] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:32:56,748] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:32:56,752] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run32
[2019-04-07 16:32:58,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:32:58,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:32:58,020] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run32
[2019-04-07 16:33:03,032] A3C_AGENT_WORKER-Thread-4 INFO:Local step 87000, global step 1398707: loss 2.2706
[2019-04-07 16:33:03,033] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 87000, global step 1398707: learning rate 0.0000
[2019-04-07 16:33:04,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7416504e-21 2.1484559e-19 6.7749859e-25 1.1078442e-17 1.6499125e-20
 1.0000000e+00 2.7240637e-15 4.7793962e-18], sum to 1.0000
[2019-04-07 16:33:04,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0566
[2019-04-07 16:33:04,661] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 96.5, 0.0, 0.0, 24.0, 23.5928371945519, 0.1386077965952288, 0.0, 1.0, 36484.49866890798], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3198600.0000, 
sim time next is 3200400.0000, 
raw observation next is [1.0, 100.0, 0.0, 0.0, 24.0, 23.78834255415501, 0.1512107311747071, 0.0, 1.0, 6243.07794240826], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 1.0, 0.0, 0.0, 0.5, 0.48236187951291765, 0.5504035770582357, 0.0, 1.0, 0.02972894258289648], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2386624], dtype=float32), 0.15996815]. 
=============================================
[2019-04-07 16:33:04,999] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1430541e-21 2.1200759e-18 1.6167692e-24 4.1955932e-18 7.6190553e-20
 1.0000000e+00 2.8431656e-15 1.1864240e-16], sum to 1.0000
[2019-04-07 16:33:05,000] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3142
[2019-04-07 16:33:05,073] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 24.0, 21.15439888979542, -0.5988358517197008, 0.0, 1.0, 40521.57259797563], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 19800.0000, 
sim time next is 21600.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 24.0, 21.19154630656796, -0.5838038839159895, 0.0, 1.0, 40385.629733236674], 
processed observation next is [0.0, 0.2608695652173913, 0.6759002770083103, 0.93, 0.0, 0.0, 0.5, 0.26596219221399675, 0.30539870536133684, 0.0, 1.0, 0.19231252253922226], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9706304], dtype=float32), -0.05141143]. 
=============================================
[2019-04-07 16:33:05,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:33:05,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:33:05,080] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run32
[2019-04-07 16:33:09,908] A3C_AGENT_WORKER-Thread-15 INFO:Local step 86500, global step 1399558: loss 0.1654
[2019-04-07 16:33:09,909] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 86500, global step 1399558: learning rate 0.0000
[2019-04-07 16:33:12,486] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1952628e-18 3.5625237e-16 4.7048070e-21 7.7506386e-15 2.0127221e-18
 1.0000000e+00 1.2729426e-11 1.3286919e-15], sum to 1.0000
[2019-04-07 16:33:12,486] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2261
[2019-04-07 16:33:12,634] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 44.0, 88.5, 627.0, 24.0, 24.84407993143082, 0.06061395628286715, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 309600.0000, 
sim time next is 311400.0000, 
raw observation next is [-9.5, 43.0, 82.0, 623.0, 24.0, 24.06105577647335, 0.04358455764965399, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.1994459833795014, 0.43, 0.2733333333333333, 0.6883977900552486, 0.5, 0.5050879813727791, 0.514528185883218, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05225995], dtype=float32), 0.41517448]. 
=============================================
[2019-04-07 16:33:12,819] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-07 16:33:12,819] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:33:12,820] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:33:12,822] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:33:12,824] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:33:12,824] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run71
[2019-04-07 16:33:12,858] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run71
[2019-04-07 16:33:12,881] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 16:33:12,883] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:33:12,886] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run71
[2019-04-07 16:35:37,670] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 16:35:57,196] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 16:36:01,240] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 16:36:02,263] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1400000, evaluation results [1400000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 16:36:07,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.97993926e-19 6.09910838e-17 3.51330677e-22 3.12449940e-16
 1.19479845e-17 1.00000000e+00 2.00264067e-13 4.90573055e-16], sum to 1.0000
[2019-04-07 16:36:07,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6100
[2019-04-07 16:36:07,400] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 56.0, 0.0, 0.0, 24.0, 23.32825714758948, -0.1056948526282776, 1.0, 1.0, 29152.695962678685], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 756000.0000, 
sim time next is 757800.0000, 
raw observation next is [-3.9, 54.5, 0.0, 0.0, 24.0, 23.04343304249935, -0.1558095048682821, 1.0, 1.0, 68025.3973584783], 
processed observation next is [1.0, 0.782608695652174, 0.3545706371191136, 0.545, 0.0, 0.0, 0.5, 0.4202860868749457, 0.4480634983772393, 1.0, 1.0, 0.3239304636118014], 
reward next is 0.9618, 
noisyNet noise sample is [array([0.26952663], dtype=float32), 0.35073185]. 
=============================================
[2019-04-07 16:36:13,133] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6595973e-20 5.4682247e-18 1.9367927e-23 1.6356966e-16 5.6339091e-19
 1.0000000e+00 2.0141481e-13 6.5672476e-16], sum to 1.0000
[2019-04-07 16:36:13,134] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3135
[2019-04-07 16:36:13,278] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 39.0, 0.0, 24.0, 23.66956157104298, -0.1203906088848645, 1.0, 1.0, 30257.165584245948], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 835200.0000, 
sim time next is 837000.0000, 
raw observation next is [-3.9, 84.0, 29.0, 0.0, 24.0, 23.84007035113995, -0.05501485067481429, 1.0, 1.0, 33146.08441743008], 
processed observation next is [1.0, 0.6956521739130435, 0.3545706371191136, 0.84, 0.09666666666666666, 0.0, 0.5, 0.4866725292616625, 0.48166171644172856, 1.0, 1.0, 0.15783849722585752], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.137987], dtype=float32), -0.98801845]. 
=============================================
[2019-04-07 16:36:13,281] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[99.11683]
 [98.83595]
 [98.5324 ]
 [98.03268]
 [97.8462 ]], R is [[99.46855927]
 [99.47387695]
 [99.47914124]
 [99.48435211]
 [99.48950958]].
[2019-04-07 16:36:14,621] A3C_AGENT_WORKER-Thread-17 INFO:Local step 87000, global step 1401845: loss 2.1565
[2019-04-07 16:36:14,622] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 87000, global step 1401845: learning rate 0.0000
[2019-04-07 16:36:15,144] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.2672928e-20 5.1073029e-17 3.1033917e-23 2.6295083e-15 3.1451123e-18
 1.0000000e+00 4.6377192e-13 2.3667877e-16], sum to 1.0000
[2019-04-07 16:36:15,144] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6276
[2019-04-07 16:36:15,204] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 43.0, 0.0, 0.0, 24.0, 24.06777651239319, 0.1306472570189876, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4132800.0000, 
sim time next is 4134600.0000, 
raw observation next is [1.0, 39.5, 0.0, 0.0, 24.0, 23.81772605145407, 0.08185828681744958, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.4903047091412743, 0.395, 0.0, 0.0, 0.5, 0.4848105042878392, 0.5272860956058165, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7234723], dtype=float32), -0.31190532]. 
=============================================
[2019-04-07 16:36:16,599] A3C_AGENT_WORKER-Thread-20 INFO:Local step 87000, global step 1402212: loss 2.1509
[2019-04-07 16:36:16,636] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 87000, global step 1402212: learning rate 0.0000
[2019-04-07 16:36:22,938] A3C_AGENT_WORKER-Thread-5 INFO:Local step 87000, global step 1403226: loss 2.1362
[2019-04-07 16:36:22,940] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 87000, global step 1403226: learning rate 0.0000
[2019-04-07 16:36:26,471] A3C_AGENT_WORKER-Thread-11 INFO:Local step 87000, global step 1403837: loss 2.2435
[2019-04-07 16:36:26,472] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 87000, global step 1403837: learning rate 0.0000
[2019-04-07 16:36:30,337] A3C_AGENT_WORKER-Thread-2 INFO:Local step 87000, global step 1404494: loss 2.2845
[2019-04-07 16:36:30,338] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 87000, global step 1404494: learning rate 0.0000
[2019-04-07 16:36:33,028] A3C_AGENT_WORKER-Thread-4 INFO:Local step 87500, global step 1404913: loss 0.7996
[2019-04-07 16:36:33,041] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 87500, global step 1404913: learning rate 0.0000
[2019-04-07 16:36:44,739] A3C_AGENT_WORKER-Thread-15 INFO:Local step 87000, global step 1406800: loss 2.0764
[2019-04-07 16:36:44,744] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 87000, global step 1406801: learning rate 0.0000
[2019-04-07 16:36:47,988] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.0844315e-19 1.8957193e-16 1.2797232e-21 1.6850597e-15 4.1843749e-17
 1.0000000e+00 8.3608138e-12 5.7082304e-15], sum to 1.0000
[2019-04-07 16:36:47,989] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1908
[2019-04-07 16:36:48,160] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 45.5, 0.0, 0.0, 24.0, 23.05668482269783, -0.1487251107548145, 0.0, 1.0, 59035.419031385136], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4905000.0000, 
sim time next is 4906800.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 24.0, 23.09794072547503, -0.1438158692245296, 0.0, 1.0, 28538.980081362868], 
processed observation next is [0.0, 0.8260869565217391, 0.4903047091412743, 0.47, 0.0, 0.0, 0.5, 0.42482839378958587, 0.45206137692515674, 0.0, 1.0, 0.135899905149347], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1120903], dtype=float32), 0.5483965]. 
=============================================
[2019-04-07 16:36:55,081] A3C_AGENT_WORKER-Thread-17 INFO:Local step 87500, global step 1408684: loss 0.9101
[2019-04-07 16:36:55,082] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 87500, global step 1408684: learning rate 0.0000
[2019-04-07 16:36:55,897] A3C_AGENT_WORKER-Thread-20 INFO:Local step 87500, global step 1408849: loss 0.8511
[2019-04-07 16:36:55,917] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 87500, global step 1408849: learning rate 0.0000
[2019-04-07 16:36:57,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:36:57,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:36:57,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run32
[2019-04-07 16:37:02,731] A3C_AGENT_WORKER-Thread-5 INFO:Local step 87500, global step 1410057: loss 0.8557
[2019-04-07 16:37:02,732] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 87500, global step 1410057: learning rate 0.0000
[2019-04-07 16:37:04,223] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.32161686e-21 6.66742894e-18 1.18298055e-23 1.18051432e-16
 5.21657989e-19 1.00000000e+00 1.58583352e-13 2.43135048e-15], sum to 1.0000
[2019-04-07 16:37:04,223] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9023
[2019-04-07 16:37:04,313] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 24.0, 23.34720283240604, -0.0419226085312254, 0.0, 1.0, 48345.40777962766], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4759200.0000, 
sim time next is 4761000.0000, 
raw observation next is [-5.0, 81.5, 0.0, 0.0, 24.0, 23.35426962401434, -0.0474065465924707, 0.0, 1.0, 43821.75088820622], 
processed observation next is [0.0, 0.08695652173913043, 0.32409972299168976, 0.815, 0.0, 0.0, 0.5, 0.44618913533452825, 0.48419781780250976, 0.0, 1.0, 0.20867500422955343], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8547724], dtype=float32), 0.024334103]. 
=============================================
[2019-04-07 16:37:04,334] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[96.042404]
 [96.465904]
 [97.12845 ]
 [97.233185]
 [98.39397 ]], R is [[96.40349579]
 [96.43946075]
 [96.47506714]
 [96.51031494]
 [96.54521179]].
[2019-04-07 16:37:06,400] A3C_AGENT_WORKER-Thread-11 INFO:Local step 87500, global step 1410801: loss 0.8611
[2019-04-07 16:37:06,402] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 87500, global step 1410801: learning rate 0.0000
[2019-04-07 16:37:08,649] A3C_AGENT_WORKER-Thread-2 INFO:Local step 87500, global step 1411261: loss 0.9077
[2019-04-07 16:37:08,670] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 87500, global step 1411261: learning rate 0.0000
[2019-04-07 16:37:17,422] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:37:17,431] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:37:17,434] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run32
[2019-04-07 16:37:18,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:37:18,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:37:18,198] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run32
[2019-04-07 16:37:23,076] A3C_AGENT_WORKER-Thread-15 INFO:Local step 87500, global step 1414043: loss 0.9152
[2019-04-07 16:37:23,077] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 87500, global step 1414043: learning rate 0.0000
[2019-04-07 16:37:23,839] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2613653e-19 1.4719171e-16 8.6710389e-22 2.1358504e-16 1.1858254e-18
 1.0000000e+00 5.3474313e-12 2.9557802e-16], sum to 1.0000
[2019-04-07 16:37:23,840] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2823
[2019-04-07 16:37:24,033] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 68.0, 0.0, 0.0, 24.0, 23.52667645626747, -0.03720493695608579, 1.0, 1.0, 32971.897379841714], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2224800.0000, 
sim time next is 2226600.0000, 
raw observation next is [-4.55, 69.0, 0.0, 0.0, 24.0, 23.60461251670856, -0.1245740577996566, 1.0, 1.0, 37262.70052916998], 
processed observation next is [1.0, 0.782608695652174, 0.3365650969529086, 0.69, 0.0, 0.0, 0.5, 0.46705104305904666, 0.45847531406678116, 1.0, 1.0, 0.17744143109128563], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7663067], dtype=float32), -0.17410167]. 
=============================================
[2019-04-07 16:37:24,663] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.5030817e-22 1.3929697e-19 8.0357099e-25 6.6422458e-18 7.2279275e-20
 1.0000000e+00 5.5799782e-15 5.5453816e-18], sum to 1.0000
[2019-04-07 16:37:24,663] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9206
[2019-04-07 16:37:24,679] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.5, 19.0, 0.0, 0.0, 24.0, 25.58571856046087, 0.4982332509322857, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5085000.0000, 
sim time next is 5086800.0000, 
raw observation next is [9.0, 19.0, 0.0, 0.0, 24.0, 25.43777979823167, 0.4663137087022881, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.7119113573407203, 0.19, 0.0, 0.0, 0.5, 0.6198149831859725, 0.6554379029007628, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2510839], dtype=float32), -1.6042782]. 
=============================================
[2019-04-07 16:37:26,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:37:26,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:37:26,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run32
[2019-04-07 16:37:30,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:37:30,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:37:30,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run32
[2019-04-07 16:37:32,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:37:32,194] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:37:32,198] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run32
[2019-04-07 16:37:33,345] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4794023e-21 3.1997844e-20 3.6332826e-26 1.5191838e-18 1.2873278e-20
 1.0000000e+00 1.8147640e-14 4.9782294e-18], sum to 1.0000
[2019-04-07 16:37:33,346] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1873
[2019-04-07 16:37:33,417] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.6, 93.0, 0.0, 0.0, 24.0, 23.64650206655232, 0.129928020173954, 0.0, 1.0, 62305.843050910604], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1645200.0000, 
sim time next is 1647000.0000, 
raw observation next is [6.9, 94.5, 0.0, 0.0, 24.0, 23.72467138582176, 0.1490471021382769, 0.0, 1.0, 17794.757544186436], 
processed observation next is [1.0, 0.043478260869565216, 0.6537396121883658, 0.945, 0.0, 0.0, 0.5, 0.47705594881848007, 0.5496823673794257, 0.0, 1.0, 0.08473694068660208], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0729446], dtype=float32), 0.40398413]. 
=============================================
[2019-04-07 16:37:33,437] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[110.16686]
 [109.19287]
 [108.81968]
 [109.39203]
 [109.26546]], R is [[110.44660187]
 [110.3311615 ]
 [110.22785187]
 [110.1255722 ]
 [110.02431488]].
[2019-04-07 16:37:39,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9858303e-19 3.2018666e-16 4.6771062e-21 7.3865195e-15 1.8461905e-16
 1.0000000e+00 4.2575010e-12 6.0340162e-15], sum to 1.0000
[2019-04-07 16:37:39,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1132
[2019-04-07 16:37:39,471] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 24.0, 21.80082452385794, -0.4755655761746977, 0.0, 1.0, 45630.35592901181], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 194400.0000, 
sim time next is 196200.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 24.0, 21.72307382125382, -0.4958342363510995, 0.0, 1.0, 45637.510661595305], 
processed observation next is [1.0, 0.2608695652173913, 0.21606648199445982, 0.78, 0.0, 0.0, 0.5, 0.3102561517711517, 0.3347219212163002, 0.0, 1.0, 0.21732147934093002], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0177968], dtype=float32), 0.45370442]. 
=============================================
[2019-04-07 16:37:46,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:37:46,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:37:46,870] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run32
[2019-04-07 16:38:02,757] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7237762e-20 3.0831141e-19 1.6403146e-23 1.2614394e-16 2.7342504e-19
 1.0000000e+00 1.9580152e-13 2.5348181e-16], sum to 1.0000
[2019-04-07 16:38:02,759] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0313
[2019-04-07 16:38:02,886] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.1, 83.0, 0.0, 0.0, 24.0, 23.16094535528575, -0.1436456704988258, 0.0, 1.0, 43862.881867454416], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 99000.0000, 
sim time next is 100800.0000, 
raw observation next is [-3.4, 79.0, 0.0, 0.0, 24.0, 23.03403383529524, -0.1584486690841523, 0.0, 1.0, 44170.00328607749], 
processed observation next is [1.0, 0.17391304347826086, 0.368421052631579, 0.79, 0.0, 0.0, 0.5, 0.41950281960793667, 0.4471837769719493, 0.0, 1.0, 0.21033334898132136], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6528118], dtype=float32), 0.54222375]. 
=============================================
[2019-04-07 16:38:07,734] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.5612819e-22 8.0674315e-19 4.3123939e-25 8.2500587e-18 1.0256672e-18
 1.0000000e+00 3.6703598e-14 3.1098021e-16], sum to 1.0000
[2019-04-07 16:38:07,734] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0476
[2019-04-07 16:38:07,877] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.550000000000001, 82.5, 101.0, 39.0, 24.0, 23.98086364396066, -0.08045110422273201, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2280600.0000, 
sim time next is 2282400.0000, 
raw observation next is [-6.7, 78.0, 139.5, 44.5, 24.0, 23.98461813382242, -0.07600179489999141, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.2770083102493075, 0.78, 0.465, 0.049171270718232046, 0.5, 0.49871817781853495, 0.4746660683666695, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.50058746], dtype=float32), 0.56321925]. 
=============================================
[2019-04-07 16:38:08,194] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5251027e-21 2.5077292e-20 3.9575337e-24 1.3751364e-17 8.7785492e-20
 1.0000000e+00 2.0316099e-14 2.7274804e-18], sum to 1.0000
[2019-04-07 16:38:08,194] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6079
[2019-04-07 16:38:08,269] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.7, 82.0, 0.0, 0.0, 24.0, 23.36124787497026, -0.1166228471705437, 0.0, 1.0, 42181.00580123942], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 532800.0000, 
sim time next is 534600.0000, 
raw observation next is [2.15, 83.5, 0.0, 0.0, 24.0, 23.37009295614787, -0.1166939659115815, 0.0, 1.0, 41350.98969925474], 
processed observation next is [0.0, 0.17391304347826086, 0.5221606648199446, 0.835, 0.0, 0.0, 0.5, 0.447507746345656, 0.46110201136280615, 0.0, 1.0, 0.19690947475835588], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.17441301], dtype=float32), 0.4646445]. 
=============================================
[2019-04-07 16:38:09,841] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-07 16:38:09,857] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:38:09,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:38:09,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run72
[2019-04-07 16:38:09,885] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:38:09,887] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:38:09,889] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 16:38:09,889] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:38:09,893] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run72
[2019-04-07 16:38:09,916] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run72
[2019-04-07 16:39:03,661] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.1243309], dtype=float32), 0.16091931]
[2019-04-07 16:39:03,662] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [8.1, 93.0, 0.0, 0.0, 24.0, 23.65673107105545, 0.1260221965993847, 0.0, 1.0, 41122.25779256806]
[2019-04-07 16:39:03,662] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 16:39:03,663] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [2.4316095e-23 1.1695749e-20 4.7128242e-26 4.2759106e-19 3.2212273e-21
 1.0000000e+00 2.3741042e-15 2.4623632e-18], sampled 0.07136011556145538
[2019-04-07 16:40:35,868] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 16:40:52,232] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 16:40:57,669] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 16:40:58,693] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1420000, evaluation results [1420000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 16:41:00,293] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4083100e-19 1.5565107e-17 1.9133469e-21 6.3156841e-16 5.6718021e-17
 1.0000000e+00 4.4533610e-13 5.5066658e-15], sum to 1.0000
[2019-04-07 16:41:00,293] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6049
[2019-04-07 16:41:00,337] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.62817576806341, -0.03663619424266645, 0.0, 1.0, 28001.190747657238], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3009600.0000, 
sim time next is 3011400.0000, 
raw observation next is [-3.25, 65.0, 0.0, 0.0, 24.0, 23.51593179546627, -0.07374009747605917, 0.0, 1.0, 16793.251681069258], 
processed observation next is [0.0, 0.8695652173913043, 0.3725761772853186, 0.65, 0.0, 0.0, 0.5, 0.45966098295552243, 0.47541996750798027, 0.0, 1.0, 0.07996786514794885], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0915173], dtype=float32), -1.0034591]. 
=============================================
[2019-04-07 16:41:30,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:41:30,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:41:30,614] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run33
[2019-04-07 16:41:43,111] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.2076837e-23 1.1972741e-20 1.4043391e-27 6.0427314e-20 3.0173932e-22
 1.0000000e+00 3.5226848e-16 1.9196455e-17], sum to 1.0000
[2019-04-07 16:41:43,111] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6693
[2019-04-07 16:41:43,186] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 75.0, 0.0, 0.0, 24.0, 24.2472272110742, 0.2057863115107251, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1031400.0000, 
sim time next is 1033200.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 24.0, 24.16159518011719, 0.187993714229894, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.8614958448753465, 0.75, 0.0, 0.0, 0.5, 0.5134662650097658, 0.5626645714099646, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4943907], dtype=float32), -1.3672309]. 
=============================================
[2019-04-07 16:41:51,749] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6080033e-24 1.2987918e-19 4.8653223e-25 7.3078052e-19 1.8184441e-21
 1.0000000e+00 1.0958328e-15 8.9553204e-18], sum to 1.0000
[2019-04-07 16:41:51,749] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6409
[2019-04-07 16:41:51,814] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.5, 100.0, 0.0, 0.0, 24.0, 23.648031668378, 0.1620284637468383, 0.0, 1.0, 18831.845292679955], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1292400.0000, 
sim time next is 1294200.0000, 
raw observation next is [4.95, 98.0, 0.0, 0.0, 24.0, 23.60936490905709, 0.1550359278754434, 0.0, 1.0, 35209.016279207404], 
processed observation next is [0.0, 1.0, 0.5997229916897507, 0.98, 0.0, 0.0, 0.5, 0.46744707575475736, 0.5516786426251478, 0.0, 1.0, 0.16766198228194001], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9035884], dtype=float32), -0.0653953]. 
=============================================
[2019-04-07 16:42:08,851] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3155702e-20 4.7048321e-18 1.2724688e-23 2.8969300e-16 1.0263012e-18
 1.0000000e+00 8.8582679e-14 1.2571263e-15], sum to 1.0000
[2019-04-07 16:42:08,852] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5070
[2019-04-07 16:42:08,928] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 24.0, 23.34049335268188, -0.03006133379726445, 1.0, 1.0, 18709.181378036814], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4563000.0000, 
sim time next is 4564800.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 24.0, 23.10330466696607, -0.04623812686126279, 1.0, 1.0, 44135.34107525734], 
processed observation next is [1.0, 0.8695652173913043, 0.518005540166205, 0.52, 0.0, 0.0, 0.5, 0.42527538891383926, 0.4845872910462457, 1.0, 1.0, 0.21016829083455876], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.27817556], dtype=float32), -0.33540624]. 
=============================================
[2019-04-07 16:42:14,703] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.6079393e-21 8.8994315e-19 1.2213235e-24 3.1161315e-16 1.3269981e-18
 1.0000000e+00 3.2396633e-13 5.0911408e-16], sum to 1.0000
[2019-04-07 16:42:14,704] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1356
[2019-04-07 16:42:14,781] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 77.0, 0.0, 0.0, 24.0, 23.64684892865994, 0.07944236340980147, 0.0, 1.0, 39536.66716542375], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3794400.0000, 
sim time next is 3796200.0000, 
raw observation next is [-3.0, 74.0, 0.0, 0.0, 24.0, 23.49476519285474, 0.01658663246086005, 0.0, 1.0, 74648.00709626618], 
processed observation next is [1.0, 0.9565217391304348, 0.3795013850415513, 0.74, 0.0, 0.0, 0.5, 0.45789709940456164, 0.5055288774869534, 0.0, 1.0, 0.3554667004584104], 
reward next is 0.9302, 
noisyNet noise sample is [array([-0.19456679], dtype=float32), -0.0065901927]. 
=============================================
[2019-04-07 16:42:20,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:42:20,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:42:20,572] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run33
[2019-04-07 16:42:24,802] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1923017e-18 1.3834399e-16 1.9042606e-20 4.5950106e-15 6.9226203e-17
 1.0000000e+00 3.8146526e-12 1.2264122e-13], sum to 1.0000
[2019-04-07 16:42:24,803] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6497
[2019-04-07 16:42:24,897] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 36.0, 66.0, 536.0, 24.0, 24.92635867823773, 0.2354296765215386, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3947400.0000, 
sim time next is 3949200.0000, 
raw observation next is [-5.0, 38.0, 42.5, 352.5, 24.0, 24.81493713283775, 0.210382652646658, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.32409972299168976, 0.38, 0.14166666666666666, 0.38950276243093923, 0.5, 0.5679114277364791, 0.5701275508822193, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.37611896], dtype=float32), -0.42077547]. 
=============================================
[2019-04-07 16:42:32,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:42:32,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:42:32,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run33
[2019-04-07 16:42:34,356] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.7685722e-20 3.5048139e-18 1.8869906e-22 5.5171733e-17 6.3801632e-18
 1.0000000e+00 1.2198829e-12 3.9415666e-15], sum to 1.0000
[2019-04-07 16:42:34,358] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3742
[2019-04-07 16:42:34,408] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.5, 64.0, 112.0, 781.0, 24.0, 24.44529336431368, 0.09205992291160364, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2719800.0000, 
sim time next is 2721600.0000, 
raw observation next is [-8.0, 64.0, 112.5, 790.0, 24.0, 24.36881514598242, 0.09087688662136788, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.24099722991689754, 0.64, 0.375, 0.8729281767955801, 0.5, 0.5307345954985351, 0.530292295540456, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.43163788], dtype=float32), -0.9589301]. 
=============================================
[2019-04-07 16:42:49,135] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1768370e-22 2.1448937e-19 1.9577307e-25 3.0350633e-17 1.6458768e-20
 1.0000000e+00 1.7318373e-15 5.6958909e-17], sum to 1.0000
[2019-04-07 16:42:49,135] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8858
[2019-04-07 16:42:49,167] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.95, 70.5, 0.0, 0.0, 24.0, 23.77683643165969, -0.02784272407932454, 0.0, 1.0, 13925.138591911762], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4332600.0000, 
sim time next is 4334400.0000, 
raw observation next is [3.9, 70.0, 0.0, 0.0, 24.0, 23.62430783908896, -0.03436933952065236, 0.0, 1.0, 22520.66090404839], 
processed observation next is [1.0, 0.17391304347826086, 0.5706371191135734, 0.7, 0.0, 0.0, 0.5, 0.46869231992408, 0.4885435534931159, 0.0, 1.0, 0.10724124240023042], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.89807445], dtype=float32), 0.685247]. 
=============================================
[2019-04-07 16:42:57,515] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-07 16:42:57,516] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:42:57,516] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:42:57,520] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run73
[2019-04-07 16:42:57,541] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:42:57,542] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:42:57,547] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run73
[2019-04-07 16:42:57,561] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 16:42:57,563] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:42:57,570] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run73
[2019-04-07 16:45:16,491] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 16:45:35,105] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 16:45:37,735] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 16:45:38,759] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1440000, evaluation results [1440000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 16:45:43,362] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.09486894e-20 4.83588191e-18 5.68829550e-23 1.19837830e-15
 9.89298707e-19 1.00000000e+00 1.92095959e-14 3.33008753e-16], sum to 1.0000
[2019-04-07 16:45:43,363] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1792
[2019-04-07 16:45:43,450] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 24.0, 23.79389759195589, 0.1235725082945342, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3263400.0000, 
sim time next is 3265200.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 24.0, 23.60417076271389, 0.1290424859848598, 1.0, 1.0, 103413.13618899077], 
processed observation next is [1.0, 0.8260869565217391, 0.3518005540166205, 0.65, 0.0, 0.0, 0.5, 0.46701423022615735, 0.5430141619949532, 1.0, 1.0, 0.4924435056618608], 
reward next is 0.7933, 
noisyNet noise sample is [array([0.6661843], dtype=float32), -0.3141865]. 
=============================================
[2019-04-07 16:45:43,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:45:43,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:45:43,724] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run33
[2019-04-07 16:45:51,745] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:45:51,745] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:45:51,748] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run33
[2019-04-07 16:45:56,760] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:45:56,760] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:45:56,764] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run33
[2019-04-07 16:46:01,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:46:01,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:46:01,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run33
[2019-04-07 16:46:01,223] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:46:01,224] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:46:01,231] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run33
[2019-04-07 16:46:01,271] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.2733564e-21 8.8889811e-19 1.4094565e-23 2.2367205e-17 2.3604904e-19
 1.0000000e+00 1.7321496e-13 4.3095194e-16], sum to 1.0000
[2019-04-07 16:46:01,271] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6028
[2019-04-07 16:46:01,357] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 24.0, 23.35838508606079, -0.02729399716902068, 0.0, 1.0, 46135.11909908726], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2935800.0000, 
sim time next is 2937600.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 24.0, 23.4173075513352, -0.03223728514474519, 0.0, 1.0, 31675.849921006156], 
processed observation next is [0.0, 0.0, 0.40720221606648205, 0.85, 0.0, 0.0, 0.5, 0.4514422959445999, 0.4892542382850849, 0.0, 1.0, 0.1508373805762198], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.02251598], dtype=float32), -0.70168555]. 
=============================================
[2019-04-07 16:46:03,441] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:46:03,441] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:46:03,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run33
[2019-04-07 16:46:21,595] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.20547936e-19 5.57148560e-17 1.17192405e-20 2.16879102e-15
 3.08477620e-17 1.00000000e+00 2.00833464e-11 7.81965655e-15], sum to 1.0000
[2019-04-07 16:46:21,595] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8396
[2019-04-07 16:46:21,678] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 69.0, 0.0, 0.0, 24.0, 22.80729314676313, -0.2534974177343227, 0.0, 1.0, 46122.58268509939], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 264600.0000, 
sim time next is 266400.0000, 
raw observation next is [-7.3, 71.0, 0.0, 0.0, 24.0, 22.82417999277916, -0.2614254661724929, 0.0, 1.0, 46363.75965167914], 
processed observation next is [1.0, 0.08695652173913043, 0.26038781163434904, 0.71, 0.0, 0.0, 0.5, 0.4020149993982634, 0.4128581779425024, 0.0, 1.0, 0.22077980786513876], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6526678], dtype=float32), -0.3449156]. 
=============================================
[2019-04-07 16:46:31,718] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3359163e-19 1.0762240e-17 2.0157222e-22 6.5368550e-16 1.4016000e-18
 1.0000000e+00 2.0513474e-14 1.3481030e-15], sum to 1.0000
[2019-04-07 16:46:31,719] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8594
[2019-04-07 16:46:31,852] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 55.0, 0.0, 0.0, 24.0, 23.39063651727228, 0.0180948816609291, 1.0, 1.0, 78549.16571634008], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3355200.0000, 
sim time next is 3357000.0000, 
raw observation next is [-3.5, 60.0, 0.0, 0.0, 24.0, 23.40441901001157, 0.05598185129722089, 0.0, 1.0, 138234.44876924573], 
processed observation next is [1.0, 0.8695652173913043, 0.36565096952908593, 0.6, 0.0, 0.0, 0.5, 0.45036825083429743, 0.5186606170990736, 0.0, 1.0, 0.6582592798535511], 
reward next is 0.6275, 
noisyNet noise sample is [array([1.1368387], dtype=float32), -0.44550678]. 
=============================================
[2019-04-07 16:46:31,856] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[95.92934 ]
 [95.245766]
 [96.54178 ]
 [96.56091 ]
 [96.652985]], R is [[95.93888855]
 [95.89116669]
 [95.93225861]
 [95.97293854]
 [96.01320648]].
[2019-04-07 16:47:07,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:47:07,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:47:07,933] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run33
[2019-04-07 16:47:08,561] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.6376834e-19 1.0927223e-16 5.2981145e-22 7.7230987e-16 1.5056955e-17
 1.0000000e+00 1.2112557e-12 7.8488805e-16], sum to 1.0000
[2019-04-07 16:47:08,561] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5926
[2019-04-07 16:47:08,621] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 46.0, 0.0, 0.0, 24.0, 23.46362925116072, -0.01964925917011498, 0.0, 1.0, 41042.78615656982], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4154400.0000, 
sim time next is 4156200.0000, 
raw observation next is [-2.5, 48.0, 0.0, 0.0, 24.0, 23.42794500544272, -0.02675363350878128, 0.0, 1.0, 48604.53694998872], 
processed observation next is [0.0, 0.08695652173913043, 0.39335180055401664, 0.48, 0.0, 0.0, 0.5, 0.45232875045355997, 0.4910821221637396, 0.0, 1.0, 0.23145017595232723], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3522519], dtype=float32), -0.6239267]. 
=============================================
[2019-04-07 16:47:10,358] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.0373086e-19 2.2830294e-17 7.8382898e-23 1.1030423e-15 1.5783708e-17
 1.0000000e+00 2.3509465e-12 4.4463057e-14], sum to 1.0000
[2019-04-07 16:47:10,358] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4701
[2019-04-07 16:47:10,554] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.3, 73.0, 184.0, 81.0, 24.0, 23.09573421737619, -0.1631153630901162, 0.0, 1.0, 35455.035665855416], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1855800.0000, 
sim time next is 1857600.0000, 
raw observation next is [-5.0, 71.0, 152.0, 40.5, 24.0, 23.10573572566692, -0.1573486574000573, 0.0, 1.0, 42914.389183274034], 
processed observation next is [0.0, 0.5217391304347826, 0.32409972299168976, 0.71, 0.5066666666666667, 0.044751381215469614, 0.5, 0.4254779771389101, 0.44755044753331424, 0.0, 1.0, 0.20435423420606683], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5689675], dtype=float32), 0.76245916]. 
=============================================
[2019-04-07 16:47:28,076] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:47:28,076] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:47:28,080] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run33
[2019-04-07 16:47:31,813] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.3678911e-22 3.6434947e-20 9.0525585e-25 2.0319621e-18 7.7348132e-21
 1.0000000e+00 9.8853116e-15 3.5519760e-18], sum to 1.0000
[2019-04-07 16:47:31,814] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2857
[2019-04-07 16:47:31,866] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 82.0, 0.0, 0.0, 24.0, 23.85953421785486, 0.131713688912469, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1558800.0000, 
sim time next is 1560600.0000, 
raw observation next is [5.0, 80.5, 0.0, 0.0, 24.0, 23.88066138528933, 0.1270001830693181, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.6011080332409973, 0.805, 0.0, 0.0, 0.5, 0.49005511544077746, 0.5423333943564393, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.31273997], dtype=float32), -0.66576517]. 
=============================================
[2019-04-07 16:47:32,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:47:32,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:47:32,041] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run33
[2019-04-07 16:47:40,473] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-07 16:47:40,508] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:47:40,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:47:40,509] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:47:40,509] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 16:47:40,509] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:47:40,509] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:47:40,515] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run74
[2019-04-07 16:47:40,530] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run74
[2019-04-07 16:47:40,547] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run74
[2019-04-07 16:49:02,944] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12435101], dtype=float32), 0.16175926]
[2019-04-07 16:49:02,945] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-3.65, 68.5, 187.0, 164.0, 24.0, 23.37442760249087, -0.1638230803542495, 1.0, 1.0, 45319.88587538913]
[2019-04-07 16:49:02,945] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 16:49:02,946] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [6.5669837e-20 8.4618922e-18 1.9788698e-22 1.9914086e-16 2.9697691e-18
 1.0000000e+00 2.9186308e-13 7.9347384e-16], sampled 0.3548108003890911
[2019-04-07 16:50:07,181] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 16:50:26,911] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 16:50:30,467] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 16:50:31,489] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1460000, evaluation results [1460000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 16:50:33,488] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:50:33,488] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:50:33,492] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run33
[2019-04-07 16:50:36,844] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:50:36,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:50:36,870] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run33
[2019-04-07 16:50:37,630] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:50:37,630] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:50:37,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run33
[2019-04-07 16:50:38,573] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8551031e-20 1.3720180e-18 3.5556291e-22 2.8670692e-17 1.7975759e-19
 1.0000000e+00 1.9566750e-13 1.9403123e-16], sum to 1.0000
[2019-04-07 16:50:38,573] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9501
[2019-04-07 16:50:38,651] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.5, 42.5, 86.0, 699.0, 24.0, 23.76487465648191, 0.1125136761791824, 0.0, 1.0, 6229.5960233948135], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3598200.0000, 
sim time next is 3600000.0000, 
raw observation next is [0.0, 43.0, 74.5, 607.0, 24.0, 23.84556010945287, 0.1024442096367569, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.46260387811634357, 0.43, 0.24833333333333332, 0.6707182320441989, 0.5, 0.4871300091210724, 0.5341480698789189, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.90616816], dtype=float32), -0.4462025]. 
=============================================
[2019-04-07 16:50:38,691] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[92.25154 ]
 [92.41729 ]
 [92.44236 ]
 [92.434296]
 [92.610886]], R is [[92.1556778 ]
 [92.23412323]
 [92.31178284]
 [92.38866425]
 [92.46477509]].
[2019-04-07 16:50:44,711] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8662041e-20 8.8265085e-18 2.2378840e-22 9.6222585e-17 7.5090386e-19
 1.0000000e+00 1.8207481e-14 2.8835907e-15], sum to 1.0000
[2019-04-07 16:50:44,711] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0830
[2019-04-07 16:50:44,895] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 40.0, 0.0, 0.0, 24.0, 23.72352928019232, 0.0116524114774256, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5014800.0000, 
sim time next is 5016600.0000, 
raw observation next is [1.0, 40.0, 0.0, 0.0, 24.0, 23.61480523544109, 0.02079599927633983, 0.0, 1.0, 93136.96373516448], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 0.4, 0.0, 0.0, 0.5, 0.4679004362867574, 0.5069319997587799, 0.0, 1.0, 0.44350935111983086], 
reward next is 0.8422, 
noisyNet noise sample is [array([0.70889646], dtype=float32), -0.62485874]. 
=============================================
[2019-04-07 16:50:48,874] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:50:48,874] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:50:48,879] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run33
[2019-04-07 16:51:04,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.5873569e-20 4.6908358e-18 1.0119495e-23 1.2143513e-15 1.6110924e-17
 1.0000000e+00 2.1165742e-13 8.9612704e-17], sum to 1.0000
[2019-04-07 16:51:04,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9064
[2019-04-07 16:51:04,552] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 17.0, 0.0, 24.0, 24.22904827111171, 0.01421318677748024, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2048400.0000, 
sim time next is 2050200.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 24.0, 24.0953166175642, -0.07186854908548154, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.82, 0.0, 0.0, 0.5, 0.5079430514636835, 0.47604381697150616, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1322962], dtype=float32), 0.30265725]. 
=============================================
[2019-04-07 16:51:17,687] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0122566e-19 1.7564059e-17 1.3004506e-22 1.6842749e-16 1.3571106e-17
 1.0000000e+00 4.1156152e-13 4.0420764e-16], sum to 1.0000
[2019-04-07 16:51:17,688] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3494
[2019-04-07 16:51:17,799] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 69.5, 0.0, 0.0, 24.0, 23.15520139859697, -0.05966330217674461, 0.0, 1.0, 129394.25655424285], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2233800.0000, 
sim time next is 2235600.0000, 
raw observation next is [-5.0, 68.0, 0.0, 0.0, 24.0, 23.43451403400044, -0.01475694592450817, 0.0, 1.0, 54335.22686512515], 
processed observation next is [1.0, 0.9130434782608695, 0.32409972299168976, 0.68, 0.0, 0.0, 0.5, 0.4528761695000367, 0.4950810180251639, 0.0, 1.0, 0.258739175548215], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09496762], dtype=float32), 1.1856203]. 
=============================================
[2019-04-07 16:51:35,294] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.1187674e-20 2.5570389e-16 1.4328394e-21 8.7653444e-17 5.4627233e-17
 1.0000000e+00 9.1155089e-13 8.8542382e-16], sum to 1.0000
[2019-04-07 16:51:35,294] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4585
[2019-04-07 16:51:35,375] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 24.0, 23.31591540758114, -0.1751568515601486, 0.0, 1.0, 45795.56980370992], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 682200.0000, 
sim time next is 684000.0000, 
raw observation next is [-3.4, 69.0, 0.0, 0.0, 24.0, 23.34019497039953, -0.1725892906214115, 0.0, 1.0, 43582.670641225624], 
processed observation next is [0.0, 0.9565217391304348, 0.368421052631579, 0.69, 0.0, 0.0, 0.5, 0.44501624753329416, 0.4424702364595295, 0.0, 1.0, 0.20753652686297916], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2124854], dtype=float32), -0.9108321]. 
=============================================
[2019-04-07 16:51:35,384] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[93.769325]
 [93.72423 ]
 [93.37371 ]
 [93.20626 ]
 [92.78539 ]], R is [[93.82221222]
 [93.88398743]
 [93.94514465]
 [94.00569153]
 [94.06563568]].
[2019-04-07 16:51:44,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:51:44,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:51:44,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run34
[2019-04-07 16:52:03,204] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7146094e-24 5.2071730e-20 1.5624228e-26 8.2640311e-21 3.6969874e-22
 1.0000000e+00 7.2846832e-17 5.5301871e-20], sum to 1.0000
[2019-04-07 16:52:03,204] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3822
[2019-04-07 16:52:03,252] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [12.7, 84.0, 16.0, 0.5, 24.0, 23.88260015068639, 0.1700524380007096, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1152000.0000, 
sim time next is 1153800.0000, 
raw observation next is [14.1, 79.5, 31.0, 0.0, 24.0, 23.78739937182349, 0.169198072761452, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.8531855955678671, 0.795, 0.10333333333333333, 0.0, 0.5, 0.48228328098529083, 0.5563993575871506, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.30509192], dtype=float32), -2.4099765]. 
=============================================
[2019-04-07 16:52:08,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2484576e-22 2.6865754e-20 2.3484300e-25 9.0666864e-19 2.1402561e-22
 1.0000000e+00 2.4843411e-15 3.3318015e-17], sum to 1.0000
[2019-04-07 16:52:08,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1024
[2019-04-07 16:52:09,015] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 96.0, 0.0, 0.0, 24.0, 23.72626443911753, -0.05549018838958084, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3097800.0000, 
sim time next is 3099600.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 24.0, 23.58958236624756, -0.0941172966817565, 0.0, 1.0, 15712.37130545431], 
processed observation next is [0.0, 0.9130434782608695, 0.4349030470914128, 1.0, 0.0, 0.0, 0.5, 0.46579853052062986, 0.46862756777274783, 0.0, 1.0, 0.07482081574025862], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.715094], dtype=float32), 0.72279227]. 
=============================================
[2019-04-07 16:52:10,069] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.1750536e-20 3.9277968e-18 2.1615634e-23 8.0341181e-17 5.3762004e-19
 1.0000000e+00 1.1276258e-13 1.2637369e-16], sum to 1.0000
[2019-04-07 16:52:10,069] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7757
[2019-04-07 16:52:10,227] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.8, 82.0, 123.0, 77.5, 24.0, 23.71616049812368, -0.05324491983125387, 1.0, 1.0, 15606.247286129365], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2106000.0000, 
sim time next is 2107800.0000, 
raw observation next is [-7.8, 82.0, 174.0, 118.0, 24.0, 24.02514320992898, -0.0122034959409626, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.82, 0.58, 0.13038674033149172, 0.5, 0.5020952674940817, 0.4959321680196791, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.86895204], dtype=float32), -1.5365458]. 
=============================================
[2019-04-07 16:52:20,329] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.0783292e-20 6.0693074e-17 3.1032867e-22 3.0396301e-16 1.4518352e-17
 1.0000000e+00 1.9287954e-13 2.7929853e-15], sum to 1.0000
[2019-04-07 16:52:20,329] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4974
[2019-04-07 16:52:20,487] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 75.0, 152.0, 66.0, 24.0, 23.14172226547402, -0.1586091794811277, 0.0, 1.0, 24908.574248377507], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1854000.0000, 
sim time next is 1855800.0000, 
raw observation next is [-5.3, 73.0, 184.0, 81.0, 24.0, 23.09573421737619, -0.1631153630901162, 0.0, 1.0, 35455.035665855416], 
processed observation next is [0.0, 0.4782608695652174, 0.31578947368421056, 0.73, 0.6133333333333333, 0.08950276243093923, 0.5, 0.4246445181146825, 0.44562821230329464, 0.0, 1.0, 0.16883350317074008], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0620799], dtype=float32), 1.0361873]. 
=============================================
[2019-04-07 16:52:23,720] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4628115e-20 5.6928658e-19 5.9799134e-23 1.8802699e-17 3.0309529e-19
 1.0000000e+00 7.1904112e-14 3.5391750e-14], sum to 1.0000
[2019-04-07 16:52:23,721] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7417
[2019-04-07 16:52:23,804] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 67.0, 61.0, 513.0, 24.0, 25.05357035455981, 0.1464062422328497, 1.0, 1.0, 6226.803890076845], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3429000.0000, 
sim time next is 3430800.0000, 
raw observation next is [2.0, 67.0, 36.5, 317.0, 24.0, 24.77146095425694, 0.2242725096468459, 1.0, 1.0, 889.5434128681219], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.67, 0.12166666666666667, 0.35027624309392263, 0.5, 0.5642884128547451, 0.5747575032156153, 1.0, 1.0, 0.0042359210136577235], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4298221], dtype=float32), 0.70121384]. 
=============================================
[2019-04-07 16:52:28,768] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6736507e-22 2.9723953e-20 1.8844053e-25 6.6332534e-19 9.9102764e-21
 1.0000000e+00 9.9372601e-15 8.0025787e-18], sum to 1.0000
[2019-04-07 16:52:28,768] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0069
[2019-04-07 16:52:28,830] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 72.0, 64.5, 19.5, 24.0, 23.9275570670901, 0.06399441192334372, 1.0, 1.0, 46275.983070702234], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4726800.0000, 
sim time next is 4728600.0000, 
raw observation next is [0.5, 75.0, 29.0, 28.0, 24.0, 24.07971828255457, 0.01587659085212209, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.4764542936288089, 0.75, 0.09666666666666666, 0.030939226519337018, 0.5, 0.5066431902128808, 0.5052921969507074, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.38784316], dtype=float32), 1.2077526]. 
=============================================
[2019-04-07 16:52:28,966] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5593944e-21 1.8295020e-19 3.3961052e-23 1.2007789e-18 6.2147921e-20
 1.0000000e+00 4.1819555e-14 8.2228847e-17], sum to 1.0000
[2019-04-07 16:52:28,966] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5890
[2019-04-07 16:52:29,091] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 85.0, 65.0, 0.0, 24.0, 23.30250703464714, -0.08481809313326467, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1762200.0000, 
sim time next is 1764000.0000, 
raw observation next is [-2.3, 87.0, 81.0, 0.0, 24.0, 23.0311951110985, -0.1197653812321054, 0.0, 1.0, 44807.215389795], 
processed observation next is [0.0, 0.43478260869565216, 0.3988919667590028, 0.87, 0.27, 0.0, 0.5, 0.41926625925820843, 0.4600782062559649, 0.0, 1.0, 0.21336769233235714], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5495943], dtype=float32), -0.6633211]. 
=============================================
[2019-04-07 16:52:29,094] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[ 98.90123 ]
 [ 99.61118 ]
 [100.128296]
 [100.552605]
 [100.58566 ]], R is [[98.78749084]
 [98.79961395]
 [98.81161499]
 [98.82350159]
 [98.83526611]].
[2019-04-07 16:52:31,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:52:31,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:52:31,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run34
[2019-04-07 16:52:40,096] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-07 16:52:40,097] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:52:40,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:52:40,101] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run75
[2019-04-07 16:52:40,116] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:52:40,128] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:52:40,133] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run75
[2019-04-07 16:52:40,118] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 16:52:40,154] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:52:40,158] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run75
[2019-04-07 16:54:02,758] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.1242293], dtype=float32), 0.16203286]
[2019-04-07 16:54:02,758] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-5.05, 64.5, 0.0, 0.0, 24.0, 23.70344460664452, -0.02887288279520793, 0.0, 1.0, 0.0]
[2019-04-07 16:54:02,759] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 16:54:02,760] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.7525623e-19 1.8689282e-17 7.1248791e-22 4.7111406e-16 5.9963985e-18
 1.0000000e+00 4.8427245e-13 1.4991520e-15], sampled 0.8552562930754702
[2019-04-07 16:54:59,915] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 16:55:17,688] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 16:55:20,166] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 16:55:21,189] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1480000, evaluation results [1480000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 16:55:26,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:55:26,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:55:26,076] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run34
[2019-04-07 16:55:30,385] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.7775412e-20 4.6474098e-19 8.3205186e-23 1.5009988e-17 2.4377628e-19
 1.0000000e+00 6.5466406e-15 8.6065742e-16], sum to 1.0000
[2019-04-07 16:55:30,386] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3825
[2019-04-07 16:55:30,491] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 24.0, 23.38194438091849, -0.02832878907878534, 0.0, 1.0, 77008.84729064966], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2066400.0000, 
sim time next is 2068200.0000, 
raw observation next is [-4.2, 84.0, 0.0, 0.0, 24.0, 23.37636473675245, -0.08897601739380527, 0.0, 1.0, 43305.36613176023], 
processed observation next is [1.0, 0.9565217391304348, 0.34626038781163443, 0.84, 0.0, 0.0, 0.5, 0.44803039472937084, 0.47034132753539826, 0.0, 1.0, 0.20621602919885823], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6589117], dtype=float32), 0.37753922]. 
=============================================
[2019-04-07 16:55:39,375] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4390451e-20 9.7348603e-18 2.4442293e-23 2.0061242e-16 3.5794951e-17
 1.0000000e+00 2.0400204e-14 1.1503082e-15], sum to 1.0000
[2019-04-07 16:55:39,379] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5010
[2019-04-07 16:55:39,463] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 47.0, 0.0, 0.0, 24.0, 23.51710835574436, -0.1029415875197667, 0.0, 1.0, 20854.764484328367], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4253400.0000, 
sim time next is 4255200.0000, 
raw observation next is [3.0, 49.0, 0.0, 0.0, 24.0, 23.48517111057748, -0.1064522803236564, 0.0, 1.0, 40685.921341413225], 
processed observation next is [0.0, 0.2608695652173913, 0.5457063711911359, 0.49, 0.0, 0.0, 0.5, 0.45709759254812327, 0.46451590655878117, 0.0, 1.0, 0.1937424825781582], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.705476], dtype=float32), 0.6875018]. 
=============================================
[2019-04-07 16:55:58,589] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.5163441e-20 1.2847829e-18 1.7195334e-23 3.2286150e-17 2.2007060e-19
 1.0000000e+00 4.3301739e-13 2.7485920e-16], sum to 1.0000
[2019-04-07 16:55:58,589] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8985
[2019-04-07 16:55:58,820] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 79.0, 0.0, 0.0, 24.0, 22.94703750222608, -0.1507221885707087, 1.0, 1.0, 95296.73941840604], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2619000.0000, 
sim time next is 2620800.0000, 
raw observation next is [-7.3, 79.0, 42.0, 4.0, 24.0, 23.619706097726, -0.1219287896730282, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.26038781163434904, 0.79, 0.14, 0.004419889502762431, 0.5, 0.46830884147716656, 0.45935707010899063, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.28233388], dtype=float32), 1.2777449]. 
=============================================
[2019-04-07 16:55:59,726] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:55:59,726] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:55:59,730] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run34
[2019-04-07 16:56:09,453] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8667501e-20 4.5791147e-18 7.2805253e-22 4.2727701e-16 8.2806068e-19
 1.0000000e+00 6.3755078e-13 3.1271586e-16], sum to 1.0000
[2019-04-07 16:56:09,454] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8076
[2019-04-07 16:56:09,492] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 24.0, 23.43087863827383, -0.08790070289969859, 0.0, 1.0, 42518.69661817197], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4845600.0000, 
sim time next is 4847400.0000, 
raw observation next is [-2.5, 60.0, 0.0, 0.0, 24.0, 23.40408789393516, -0.09439776176247454, 0.0, 1.0, 46372.28443412539], 
processed observation next is [0.0, 0.08695652173913043, 0.39335180055401664, 0.6, 0.0, 0.0, 0.5, 0.4503406578279299, 0.4685340794125085, 0.0, 1.0, 0.22082040206726375], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.813906], dtype=float32), 1.1665368]. 
=============================================
[2019-04-07 16:56:09,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:56:09,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:56:09,826] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run34
[2019-04-07 16:56:15,157] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:56:15,157] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:56:15,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run34
[2019-04-07 16:56:17,423] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5418620e-20 3.1976522e-18 5.3116706e-23 9.0284596e-16 7.3970825e-18
 1.0000000e+00 3.0507514e-13 3.4763774e-15], sum to 1.0000
[2019-04-07 16:56:17,423] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2133
[2019-04-07 16:56:17,490] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 55.0, 0.0, 0.0, 24.0, 23.59064672093353, 0.000891876713436171, 0.0, 1.0, 37035.57988488432], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5022000.0000, 
sim time next is 5023800.0000, 
raw observation next is [-1.0, 55.0, 0.0, 0.0, 24.0, 23.6425667624127, -0.01015778678812672, 0.0, 1.0, 26815.43030084703], 
processed observation next is [1.0, 0.13043478260869565, 0.4349030470914128, 0.55, 0.0, 0.0, 0.5, 0.4702138968677249, 0.49661407107062444, 0.0, 1.0, 0.1276925252421287], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4841571], dtype=float32), -1.9074818]. 
=============================================
[2019-04-07 16:56:17,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:56:17,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:56:17,888] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run34
[2019-04-07 16:56:18,241] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:56:18,241] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:56:18,244] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run34
[2019-04-07 16:56:21,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:56:21,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:56:21,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run34
[2019-04-07 16:57:01,305] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9618325e-20 7.1763659e-18 1.9463174e-23 4.7766100e-17 2.6773789e-19
 1.0000000e+00 4.2903181e-13 4.6027118e-15], sum to 1.0000
[2019-04-07 16:57:01,336] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8304
[2019-04-07 16:57:01,411] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 83.0, 0.0, 0.0, 24.0, 23.42341617974338, -0.06721732295337692, 0.0, 1.0, 47532.90100768785], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1800000.0000, 
sim time next is 1801800.0000, 
raw observation next is [-4.75, 84.5, 0.0, 0.0, 24.0, 23.38077205742006, -0.08479449582538079, 0.0, 1.0, 46684.45892218533], 
processed observation next is [0.0, 0.8695652173913043, 0.3310249307479225, 0.845, 0.0, 0.0, 0.5, 0.4483976714516717, 0.4717351680582064, 0.0, 1.0, 0.22230694724850159], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.46788126], dtype=float32), -1.1896005]. 
=============================================
[2019-04-07 16:57:17,004] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 16:57:17,004] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:57:17,008] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run34
[2019-04-07 16:57:20,167] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8702418e-22 7.0926472e-19 4.8590558e-24 1.4573786e-17 1.1179811e-19
 1.0000000e+00 6.1799371e-15 3.4062470e-18], sum to 1.0000
[2019-04-07 16:57:20,168] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7036
[2019-04-07 16:57:20,251] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 37.0, 58.0, 247.0, 24.0, 25.60938371302639, 0.4080570111214903, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4122000.0000, 
sim time next is 4123800.0000, 
raw observation next is [3.0, 35.5, 23.0, 57.0, 24.0, 25.7747783333125, 0.3574088053258936, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5457063711911359, 0.355, 0.07666666666666666, 0.06298342541436464, 0.5, 0.6478981944427084, 0.6191362684419645, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.75801134], dtype=float32), -0.55838853]. 
=============================================
[2019-04-07 16:57:20,810] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2436307e-18 7.5169886e-16 1.6015362e-21 1.0313106e-15 6.8810442e-18
 1.0000000e+00 6.2128024e-12 2.4258011e-15], sum to 1.0000
[2019-04-07 16:57:20,810] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0824
[2019-04-07 16:57:20,829] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 27.5, 114.0, 830.0, 24.0, 24.44564599173941, 0.1976982248514879, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4023000.0000, 
sim time next is 4024800.0000, 
raw observation next is [-3.0, 26.0, 109.0, 812.0, 24.0, 24.90834530396637, 0.2542554725678174, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3795013850415513, 0.26, 0.36333333333333334, 0.8972375690607735, 0.5, 0.5756954419971976, 0.5847518241892725, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4095023], dtype=float32), -2.0795662]. 
=============================================
[2019-04-07 16:57:23,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2053998e-19 5.3910309e-18 1.9343940e-22 6.9143333e-17 9.3159986e-19
 1.0000000e+00 1.5802236e-13 8.2979164e-16], sum to 1.0000
[2019-04-07 16:57:23,291] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6038
[2019-04-07 16:57:23,319] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 34.0, 166.0, 758.0, 24.0, 23.24125776687294, -0.02436796574963554, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4194000.0000, 
sim time next is 4195800.0000, 
raw observation next is [2.0, 37.0, 214.0, 669.0, 24.0, 23.26945066920132, -0.02140862825455249, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.518005540166205, 0.37, 0.7133333333333334, 0.7392265193370166, 0.5, 0.43912088910010993, 0.49286379058181584, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1926758], dtype=float32), 1.3444426]. 
=============================================
[2019-04-07 16:57:27,529] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.2667031e-23 4.1852945e-20 3.7102623e-25 2.8586258e-18 2.0911968e-21
 1.0000000e+00 4.0448682e-16 6.5051282e-19], sum to 1.0000
[2019-04-07 16:57:27,529] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2735
[2019-04-07 16:57:27,576] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.8, 76.0, 0.0, 0.0, 24.0, 23.83937982176959, -0.008050274975340435, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4312800.0000, 
sim time next is 4314600.0000, 
raw observation next is [4.6, 75.5, 0.0, 0.0, 24.0, 23.63635769672375, -0.02448230097879215, 0.0, 1.0, 58291.53547054636], 
processed observation next is [0.0, 0.9565217391304348, 0.590027700831025, 0.755, 0.0, 0.0, 0.5, 0.4696964747269791, 0.4918392330070693, 0.0, 1.0, 0.27757874033593505], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4222404], dtype=float32), -1.166637]. 
=============================================
[2019-04-07 16:57:27,602] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-07 16:57:27,653] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:57:27,664] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:57:27,675] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 16:57:27,675] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 16:57:27,681] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:57:27,692] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 16:57:28,235] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run76
[2019-04-07 16:57:28,389] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run76
[2019-04-07 16:57:28,405] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run76
[2019-04-07 16:59:55,002] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:00:11,759] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:00:14,736] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 17:00:15,760] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1500000, evaluation results [1500000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:00:20,224] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.7638987e-25 1.4660014e-21 1.5520738e-27 1.1509768e-20 5.2806986e-23
 1.0000000e+00 4.0641375e-17 1.8638501e-19], sum to 1.0000
[2019-04-07 17:00:20,235] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2239
[2019-04-07 17:00:20,298] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.3, 80.0, 0.0, 0.0, 24.0, 23.78039691424004, 0.1439197485961865, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1062000.0000, 
sim time next is 1063800.0000, 
raw observation next is [12.75, 81.5, 0.0, 0.0, 24.0, 23.96931216167453, 0.1668043155457952, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.8157894736842106, 0.815, 0.0, 0.0, 0.5, 0.4974426801395442, 0.5556014385152651, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.9017016], dtype=float32), -0.16616926]. 
=============================================
[2019-04-07 17:00:20,396] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8266629e-20 5.5935850e-19 1.8007568e-23 1.3130556e-17 2.3065399e-19
 1.0000000e+00 9.8770615e-14 6.7967055e-17], sum to 1.0000
[2019-04-07 17:00:20,396] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2974
[2019-04-07 17:00:20,432] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.9, 58.0, 116.0, 655.0, 24.0, 23.75746980125392, 0.06639513021022887, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4289400.0000, 
sim time next is 4291200.0000, 
raw observation next is [7.0, 56.0, 93.0, 605.5, 24.0, 23.83668495744651, 0.07592226079110799, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.6565096952908588, 0.56, 0.31, 0.669060773480663, 0.5, 0.4863904131205426, 0.5253074202637027, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7738143], dtype=float32), -0.32142964]. 
=============================================
[2019-04-07 17:00:29,359] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:00:29,359] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:00:29,363] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run34
[2019-04-07 17:00:32,393] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4219818e-21 1.6682988e-19 8.9266386e-25 4.6821500e-17 6.2197932e-21
 1.0000000e+00 6.0723013e-15 1.2026413e-16], sum to 1.0000
[2019-04-07 17:00:32,393] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6744
[2019-04-07 17:00:32,460] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 80.0, 0.0, 0.0, 24.0, 23.84651606009406, 0.08152096451433599, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4431600.0000, 
sim time next is 4433400.0000, 
raw observation next is [2.0, 80.0, 0.0, 0.0, 24.0, 23.75133747826289, 0.06179791958475173, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.518005540166205, 0.8, 0.0, 0.0, 0.5, 0.47927812318857416, 0.5205993065282506, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.20047104], dtype=float32), 0.5004355]. 
=============================================
[2019-04-07 17:00:32,986] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8664306e-20 3.8110213e-17 2.1986720e-22 8.6331716e-17 2.3890910e-18
 1.0000000e+00 4.2355491e-13 9.4069690e-16], sum to 1.0000
[2019-04-07 17:00:32,987] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0974
[2019-04-07 17:00:33,203] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 65.0, 136.0, 0.0, 24.0, 23.5799851096078, -0.1971616353307222, 1.0, 1.0, 44201.31736575631], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2206800.0000, 
sim time next is 2208600.0000, 
raw observation next is [-3.65, 68.0, 144.0, 0.0, 24.0, 23.417757393818, -0.06637255130111397, 1.0, 1.0, 38287.318652166374], 
processed observation next is [1.0, 0.5652173913043478, 0.3614958448753463, 0.68, 0.48, 0.0, 0.5, 0.4514797828181667, 0.477875816232962, 1.0, 1.0, 0.18232056501031607], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.228701], dtype=float32), 0.5309097]. 
=============================================
[2019-04-07 17:00:36,823] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:00:36,823] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:00:36,827] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run34
[2019-04-07 17:00:44,698] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3742663e-21 1.8893353e-18 1.3064607e-24 7.5355896e-17 9.3595577e-20
 1.0000000e+00 1.4292995e-13 9.2134460e-17], sum to 1.0000
[2019-04-07 17:00:44,698] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3195
[2019-04-07 17:00:44,761] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 108.0, 0.0, 24.0, 24.48415609363064, 0.08925706047674287, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4710600.0000, 
sim time next is 4712400.0000, 
raw observation next is [1.0, 86.0, 121.5, 0.0, 24.0, 24.10357313415678, 0.02889693002651241, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.4903047091412743, 0.86, 0.405, 0.0, 0.5, 0.5086310945130649, 0.5096323100088375, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2582287], dtype=float32), 0.57663614]. 
=============================================
[2019-04-07 17:00:44,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:00:44,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:00:44,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run34
[2019-04-07 17:00:49,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:00:49,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:00:49,325] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run34
[2019-04-07 17:00:54,329] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:00:54,329] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:00:54,332] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run34
[2019-04-07 17:00:59,773] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.05524074e-19 2.39214836e-16 1.32611625e-20 1.09700804e-15
 1.68727150e-16 1.00000000e+00 1.76055915e-12 3.56252528e-15], sum to 1.0000
[2019-04-07 17:00:59,774] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1081
[2019-04-07 17:01:00,192] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 91.0, 0.0, 0.0, 24.0, 22.06122896975347, -0.452561051099803, 0.0, 1.0, 45320.17520198002], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1926000.0000, 
sim time next is 1927800.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 24.0, 22.58097063486317, -0.2453294219875967, 1.0, 1.0, 150367.40320334263], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.5, 0.38174755290526424, 0.4182235260041344, 1.0, 1.0, 0.7160352533492507], 
reward next is 0.5697, 
noisyNet noise sample is [array([-1.1375214], dtype=float32), -0.3220934]. 
=============================================
[2019-04-07 17:01:03,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:01:03,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:01:03,452] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run34
[2019-04-07 17:01:19,369] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0262235e-17 1.3552864e-14 5.1319219e-20 1.2886312e-14 9.9362693e-16
 1.0000000e+00 9.8597736e-12 4.4512273e-14], sum to 1.0000
[2019-04-07 17:01:19,369] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4972
[2019-04-07 17:01:19,704] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.2, 38.0, 0.0, 0.0, 24.0, 23.53219579892431, -0.1057529708601696, 1.0, 1.0, 129273.41545705123], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 408600.0000, 
sim time next is 410400.0000, 
raw observation next is [-9.5, 40.0, 0.0, 0.0, 24.0, 23.71574799657051, -0.04588912690775877, 1.0, 1.0, 66993.12990079059], 
processed observation next is [1.0, 0.782608695652174, 0.1994459833795014, 0.4, 0.0, 0.0, 0.5, 0.4763123330475425, 0.4847036243640804, 1.0, 1.0, 0.319014904289479], 
reward next is 0.9667, 
noisyNet noise sample is [array([-0.6052493], dtype=float32), -0.969938]. 
=============================================
[2019-04-07 17:01:29,401] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2523027e-21 2.6218319e-18 3.3491435e-25 3.0616108e-17 1.1852460e-19
 1.0000000e+00 2.5027088e-15 6.3946364e-18], sum to 1.0000
[2019-04-07 17:01:29,401] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4076
[2019-04-07 17:01:29,552] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 87.0, 110.5, 122.0, 24.0, 22.98650079792435, -0.1684653162117973, 0.0, 1.0, 32256.542208607007], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 554400.0000, 
sim time next is 556200.0000, 
raw observation next is [-0.6, 85.0, 77.0, 141.0, 24.0, 22.94582462241683, -0.1437807200793975, 0.0, 1.0, 56541.336746930436], 
processed observation next is [0.0, 0.43478260869565216, 0.44598337950138506, 0.85, 0.25666666666666665, 0.1558011049723757, 0.5, 0.4121520518680691, 0.4520730933068675, 0.0, 1.0, 0.26924446069966873], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.33540842], dtype=float32), 0.6156192]. 
=============================================
[2019-04-07 17:01:38,453] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.8853111e-19 2.2174947e-17 2.3362573e-20 9.0946552e-16 3.5238523e-17
 1.0000000e+00 2.5626151e-12 2.4550477e-14], sum to 1.0000
[2019-04-07 17:01:38,453] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3446
[2019-04-07 17:01:38,753] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.15, 53.0, 0.0, 0.0, 24.0, 24.21803916966133, -0.06379359194634687, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 322200.0000, 
sim time next is 324000.0000, 
raw observation next is [-11.7, 57.0, 0.0, 0.0, 24.0, 23.64281690501608, -0.02543424648211488, 1.0, 1.0, 152228.9442270752], 
processed observation next is [1.0, 0.782608695652174, 0.13850415512465375, 0.57, 0.0, 0.0, 0.5, 0.4702347420846733, 0.49152191783929505, 1.0, 1.0, 0.7248997344146438], 
reward next is 0.5608, 
noisyNet noise sample is [array([-1.0580719], dtype=float32), 1.090881]. 
=============================================
[2019-04-07 17:01:38,764] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[85.9641  ]
 [86.71833 ]
 [85.506004]
 [86.42454 ]
 [86.78231 ]], R is [[87.53079987]
 [87.65549469]
 [87.44810486]
 [87.57362366]
 [87.67182922]].
[2019-04-07 17:01:38,916] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8842214e-20 3.8491969e-18 1.4101511e-22 1.1508393e-15 1.1632356e-18
 1.0000000e+00 7.5596566e-14 1.3986052e-16], sum to 1.0000
[2019-04-07 17:01:38,916] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3941
[2019-04-07 17:01:39,039] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.3, 53.0, 191.0, 0.0, 24.0, 23.05475151587113, -0.15071564506976, 0.0, 1.0, 32580.661099915902], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2381400.0000, 
sim time next is 2383200.0000, 
raw observation next is [0.0, 52.0, 175.5, 0.0, 24.0, 23.05104745654679, -0.1325303136528276, 0.0, 1.0, 38612.48432101568], 
processed observation next is [0.0, 0.6086956521739131, 0.46260387811634357, 0.52, 0.585, 0.0, 0.5, 0.4209206213788992, 0.45582322878239084, 0.0, 1.0, 0.18386897295721755], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4728687], dtype=float32), -0.765997]. 
=============================================
[2019-04-07 17:01:50,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9022758e-21 1.7518738e-19 2.1154565e-24 9.1085680e-18 1.1793153e-19
 1.0000000e+00 1.7241291e-14 1.6891970e-16], sum to 1.0000
[2019-04-07 17:01:50,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9599
[2019-04-07 17:01:50,450] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 79.0, 42.0, 4.0, 24.0, 23.619706097726, -0.1219287896730282, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2620800.0000, 
sim time next is 2622600.0000, 
raw observation next is [-7.0, 77.0, 77.0, 0.0, 24.0, 23.62300240263027, -0.09291784366162507, 1.0, 1.0, 6244.912833860156], 
processed observation next is [1.0, 0.34782608695652173, 0.2686980609418283, 0.77, 0.25666666666666665, 0.0, 0.5, 0.4685835335525225, 0.46902738544612493, 1.0, 1.0, 0.029737680161238837], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3772146], dtype=float32), 0.8178485]. 
=============================================
[2019-04-07 17:01:52,776] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:01:52,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:01:52,780] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run35
[2019-04-07 17:02:07,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7972157e-23 2.0178170e-20 1.1690456e-25 9.5965886e-19 1.2048239e-21
 1.0000000e+00 5.5797228e-15 2.5841594e-18], sum to 1.0000
[2019-04-07 17:02:07,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8118
[2019-04-07 17:02:07,467] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 24.0, 23.58753399128562, 0.09080964538450836, 0.0, 1.0, 12210.221543341808], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1321200.0000, 
sim time next is 1323000.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 24.0, 23.52269983324109, 0.08602452228708889, 1.0, 1.0, 13969.50428650214], 
processed observation next is [1.0, 0.30434782608695654, 0.49307479224376743, 0.92, 0.0, 0.0, 0.5, 0.46022498610342427, 0.5286748407623629, 1.0, 1.0, 0.06652144898334353], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5472808], dtype=float32), 0.8169241]. 
=============================================
[2019-04-07 17:02:07,494] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[109.1638 ]
 [109.60235]
 [109.2915 ]
 [109.42019]
 [110.02128]], R is [[109.41898346]
 [109.32479095]
 [109.09642792]
 [109.00546265]
 [108.91540527]].
[2019-04-07 17:02:12,784] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0700794e-22 6.9164820e-21 3.9932104e-27 6.2094867e-19 6.7569549e-22
 1.0000000e+00 2.7737885e-15 1.5488744e-19], sum to 1.0000
[2019-04-07 17:02:12,786] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7202
[2019-04-07 17:02:12,839] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.25, 92.5, 0.0, 0.0, 24.0, 23.53733112683368, -0.0016637152546387, 0.0, 1.0, 30696.10892615409], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 952200.0000, 
sim time next is 954000.0000, 
raw observation next is [5.5, 89.0, 0.0, 0.0, 24.0, 23.47309820189086, -0.008745390387428803, 0.0, 1.0, 36477.78185746895], 
processed observation next is [1.0, 0.043478260869565216, 0.6149584487534627, 0.89, 0.0, 0.0, 0.5, 0.4560915168242383, 0.49708486987085704, 0.0, 1.0, 0.17370372313080454], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.25985482], dtype=float32), 1.2661871]. 
=============================================
[2019-04-07 17:02:12,860] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[109.216774]
 [108.94206 ]
 [109.444855]
 [109.13658 ]
 [109.69911 ]], R is [[109.02880096]
 [108.93851471]
 [108.84912872]
 [108.76063538]
 [108.67302704]].
[2019-04-07 17:02:14,412] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9540982e-24 1.4208540e-21 6.1223849e-28 6.1089982e-19 1.0959249e-22
 1.0000000e+00 2.2357406e-16 1.2249007e-19], sum to 1.0000
[2019-04-07 17:02:14,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8947
[2019-04-07 17:02:14,471] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.9, 94.5, 0.0, 0.0, 24.0, 23.72467138582176, 0.1490471021382769, 0.0, 1.0, 17794.757544186436], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1647000.0000, 
sim time next is 1648800.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 24.0, 23.90116425946696, 0.1476072244564276, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.662049861495845, 0.96, 0.0, 0.0, 0.5, 0.4917636882889133, 0.5492024081521425, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0217491], dtype=float32), 0.6081955]. 
=============================================
[2019-04-07 17:02:19,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.5560001e-24 4.8308437e-20 2.0512595e-27 4.6575438e-19 2.3782121e-21
 1.0000000e+00 3.5205085e-16 2.8545147e-20], sum to 1.0000
[2019-04-07 17:02:19,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6988
[2019-04-07 17:02:19,913] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.4, 66.0, 0.0, 0.0, 24.0, 24.54625988841941, 0.2737787944188765, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1623600.0000, 
sim time next is 1625400.0000, 
raw observation next is [8.55, 70.0, 0.0, 0.0, 24.0, 24.21641742217381, 0.2190207874698238, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.6994459833795015, 0.7, 0.0, 0.0, 0.5, 0.5180347851811508, 0.5730069291566079, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8032453], dtype=float32), 0.6064929]. 
=============================================
[2019-04-07 17:02:21,618] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-07 17:02:21,619] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:02:21,619] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:02:21,623] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:02:21,626] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:02:21,629] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run77
[2019-04-07 17:02:21,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run77
[2019-04-07 17:02:21,651] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 17:02:21,653] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:02:21,657] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run77
[2019-04-07 17:04:49,010] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:05:07,718] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:05:09,130] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 17:05:10,152] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 1520000, evaluation results [1520000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:05:19,432] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6934898e-21 1.4451714e-17 4.3832696e-22 8.0170352e-17 2.6175946e-18
 1.0000000e+00 7.1543260e-13 1.7102772e-15], sum to 1.0000
[2019-04-07 17:05:19,432] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1817
[2019-04-07 17:05:19,492] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 79.0, 0.0, 0.0, 24.0, 22.5291524351861, -0.2879235331303679, 0.0, 1.0, 47939.577553967334], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1834200.0000, 
sim time next is 1836000.0000, 
raw observation next is [-6.2, 79.0, 0.0, 0.0, 24.0, 22.48088416756208, -0.3073188815622285, 0.0, 1.0, 47906.89323552918], 
processed observation next is [0.0, 0.2608695652173913, 0.2908587257617729, 0.79, 0.0, 0.0, 0.5, 0.3734070139635068, 0.3975603728125905, 0.0, 1.0, 0.22812806302632946], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9352283], dtype=float32), 1.5301243]. 
=============================================
[2019-04-07 17:05:19,500] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[92.60132 ]
 [92.9973  ]
 [93.36025 ]
 [93.660576]
 [93.86895 ]], R is [[92.37871552]
 [92.45492554]
 [92.53038025]
 [92.60507965]
 [92.67903137]].
[2019-04-07 17:05:22,969] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3283544e-22 4.1828544e-19 3.4539017e-25 3.4863322e-18 1.3932240e-20
 1.0000000e+00 6.4083978e-14 7.8359481e-18], sum to 1.0000
[2019-04-07 17:05:22,970] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9975
[2019-04-07 17:05:22,994] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6640514e-21 3.7342436e-18 1.6242429e-24 7.1177800e-17 1.5871480e-19
 1.0000000e+00 2.9715430e-14 2.0404230e-16], sum to 1.0000
[2019-04-07 17:05:22,994] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9796
[2019-04-07 17:05:23,046] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.9, 83.0, 0.0, 0.0, 24.0, 23.33781091016849, -0.1143610015455505, 0.0, 1.0, 43682.21752217081], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1981800.0000, 
sim time next is 1983600.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 24.0, 23.17303135973674, -0.1365841270981747, 0.0, 1.0, 47421.52949557963], 
processed observation next is [1.0, 1.0, 0.30747922437673136, 0.83, 0.0, 0.0, 0.5, 0.4310859466447283, 0.45447195763394177, 0.0, 1.0, 0.22581680712180774], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4218616], dtype=float32), -0.12241636]. 
=============================================
[2019-04-07 17:05:23,077] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 81.0, 41.5, 0.0, 24.0, 24.097800487338, 0.09477808598795257, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1699200.0000, 
sim time next is 1701000.0000, 
raw observation next is [1.35, 84.5, 30.0, 0.0, 24.0, 23.06130366464045, -0.0330621547616796, 1.0, 1.0, 54049.409767982295], 
processed observation next is [1.0, 0.6956521739130435, 0.5000000000000001, 0.845, 0.1, 0.0, 0.5, 0.4217753053867043, 0.4889792817461068, 1.0, 1.0, 0.2573781417522966], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17571078], dtype=float32), -1.7826015]. 
=============================================
[2019-04-07 17:05:23,081] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[104.23568 ]
 [104.65038 ]
 [105.15478 ]
 [105.648476]
 [105.79281 ]], R is [[104.12316132]
 [104.08193207]
 [104.04111481]
 [104.0007019 ]
 [103.96069336]].
[2019-04-07 17:05:27,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:05:27,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:05:27,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run35
[2019-04-07 17:05:33,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7294043e-19 1.2860094e-17 1.1607295e-21 1.1568953e-16 2.8209711e-18
 1.0000000e+00 3.7424408e-12 1.6810663e-15], sum to 1.0000
[2019-04-07 17:05:33,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1177
[2019-04-07 17:05:33,246] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 24.0, 23.43087863827383, -0.08790070289969859, 0.0, 1.0, 42518.69661817197], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4845600.0000, 
sim time next is 4847400.0000, 
raw observation next is [-2.5, 60.0, 0.0, 0.0, 24.0, 23.40408789393516, -0.09439776176247454, 0.0, 1.0, 46372.28443412539], 
processed observation next is [0.0, 0.08695652173913043, 0.39335180055401664, 0.6, 0.0, 0.0, 0.5, 0.4503406578279299, 0.4685340794125085, 0.0, 1.0, 0.22082040206726375], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2039604], dtype=float32), 0.5336241]. 
=============================================
[2019-04-07 17:05:35,171] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.8510463e-18 1.2713955e-17 3.8175158e-22 6.6363231e-17 2.8803870e-18
 1.0000000e+00 3.5346433e-13 1.0074313e-16], sum to 1.0000
[2019-04-07 17:05:35,171] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9832
[2019-04-07 17:05:35,224] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 80.5, 0.0, 0.0, 24.0, 22.90280793429552, -0.2473526244445009, 0.0, 1.0, 46038.17967635431], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1899000.0000, 
sim time next is 1900800.0000, 
raw observation next is [-7.3, 82.0, 0.0, 0.0, 24.0, 22.81601008242322, -0.2649876647995604, 0.0, 1.0, 46051.758376965656], 
processed observation next is [1.0, 0.0, 0.26038781163434904, 0.82, 0.0, 0.0, 0.5, 0.40133417353526823, 0.41167077840014654, 0.0, 1.0, 0.21929408750936027], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05033204], dtype=float32), -0.60755676]. 
=============================================
[2019-04-07 17:05:41,187] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2380420e-21 1.9823720e-18 4.0198076e-25 1.5974445e-18 1.0124811e-18
 1.0000000e+00 3.4795964e-14 1.0681345e-16], sum to 1.0000
[2019-04-07 17:05:41,187] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3182
[2019-04-07 17:05:41,269] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 24.0, 23.42093513655264, 0.05975283277794585, 1.0, 1.0, 55309.80622865477], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3787200.0000, 
sim time next is 3789000.0000, 
raw observation next is [-2.5, 68.0, 0.0, 0.0, 24.0, 23.45711355278931, 0.1096064000975583, 0.0, 1.0, 135041.4655344532], 
processed observation next is [1.0, 0.8695652173913043, 0.39335180055401664, 0.68, 0.0, 0.0, 0.5, 0.45475946273244244, 0.5365354666991861, 0.0, 1.0, 0.6430545977831105], 
reward next is 0.6427, 
noisyNet noise sample is [array([1.1329796], dtype=float32), -0.19439025]. 
=============================================
[2019-04-07 17:05:41,277] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[ 98.89115 ]
 [ 99.004555]
 [ 99.195335]
 [ 99.855064]
 [100.38853 ]], R is [[99.23152161]
 [99.23920441]
 [98.96047211]
 [98.97087097]
 [98.98116302]].
[2019-04-07 17:05:44,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:05:44,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:05:44,712] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run35
[2019-04-07 17:05:49,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5027497e-20 1.2844007e-18 2.3969537e-23 2.1519112e-17 2.3141546e-19
 1.0000000e+00 9.5545283e-15 1.5212781e-17], sum to 1.0000
[2019-04-07 17:05:49,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0579
[2019-04-07 17:05:49,558] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8500000000000001, 72.0, 0.0, 0.0, 24.0, 23.3781381757402, -0.001809602671467236, 0.0, 1.0, 67471.07142618838], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4509000.0000, 
sim time next is 4510800.0000, 
raw observation next is [-0.8, 71.0, 0.0, 0.0, 24.0, 23.61728629100338, -9.754851074379271e-05, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.4404432132963989, 0.71, 0.0, 0.0, 0.5, 0.46810719091694847, 0.4999674838297521, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.90811014], dtype=float32), -0.5794055]. 
=============================================
[2019-04-07 17:05:59,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.6601895e-20 5.1898635e-19 2.7268819e-22 2.7649328e-17 8.1869451e-19
 1.0000000e+00 8.0202589e-14 1.8389016e-16], sum to 1.0000
[2019-04-07 17:05:59,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0426
[2019-04-07 17:05:59,896] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 24.0, 23.55895990808847, 0.01634602596011092, 0.0, 1.0, 28048.37105189668], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4147200.0000, 
sim time next is 4149000.0000, 
raw observation next is [-1.0, 40.5, 0.0, 0.0, 24.0, 23.50813627772776, 0.01148645493347068, 0.0, 1.0, 48038.63227495891], 
processed observation next is [0.0, 0.0, 0.4349030470914128, 0.405, 0.0, 0.0, 0.5, 0.45901135647731345, 0.5038288183111569, 0.0, 1.0, 0.22875539178551862], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8396219], dtype=float32), -1.1204982]. 
=============================================
[2019-04-07 17:05:59,929] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[91.98492 ]
 [94.82469 ]
 [95.598946]
 [94.625175]
 [95.17128 ]], R is [[91.37039948]
 [91.45669556]
 [91.54212952]
 [91.38768768]
 [91.47380829]].
[2019-04-07 17:06:15,951] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2283861e-20 7.9547897e-19 5.1514495e-23 1.3159244e-16 2.3794124e-19
 1.0000000e+00 2.4277418e-14 1.3333727e-16], sum to 1.0000
[2019-04-07 17:06:15,952] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9063
[2019-04-07 17:06:15,980] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 47.0, 264.0, 113.0, 24.0, 24.27010649423183, 0.1394080558487435, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4545000.0000, 
sim time next is 4546800.0000, 
raw observation next is [3.0, 45.0, 208.5, 62.5, 24.0, 24.60125173059578, 0.1729548967838467, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.45, 0.695, 0.06906077348066299, 0.5, 0.5501043108829817, 0.5576516322612822, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1514958], dtype=float32), -0.23321927]. 
=============================================
[2019-04-07 17:06:17,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:06:17,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:06:17,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run35
[2019-04-07 17:06:23,850] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0685136e-21 1.0867968e-19 2.8140299e-24 1.3431071e-17 4.4478551e-19
 1.0000000e+00 1.8792965e-15 3.7103339e-17], sum to 1.0000
[2019-04-07 17:06:23,850] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0625
[2019-04-07 17:06:23,922] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 72.0, 100.0, 11.0, 24.0, 23.84018099679357, 0.02287966615407069, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4725000.0000, 
sim time next is 4726800.0000, 
raw observation next is [1.0, 72.0, 64.5, 19.5, 24.0, 23.9275570670901, 0.06399441192334372, 1.0, 1.0, 46275.983070702234], 
processed observation next is [1.0, 0.7391304347826086, 0.4903047091412743, 0.72, 0.215, 0.02154696132596685, 0.5, 0.4939630889241749, 0.5213314706411146, 1.0, 1.0, 0.22036182414620112], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0477151], dtype=float32), -1.947088]. 
=============================================
[2019-04-07 17:06:32,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:06:32,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:06:32,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run35
[2019-04-07 17:06:34,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:06:34,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:06:34,388] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run35
[2019-04-07 17:06:34,966] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.31135665e-20 9.77836920e-18 2.84049643e-24 3.36669325e-17
 1.13393372e-18 1.00000000e+00 2.72748607e-14 4.90262511e-16], sum to 1.0000
[2019-04-07 17:06:34,967] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2625
[2019-04-07 17:06:35,122] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 48.0, 0.0, 0.0, 24.0, 23.67768286930597, -0.08689680607402628, 1.0, 1.0, 15385.101009804586], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4951800.0000, 
sim time next is 4953600.0000, 
raw observation next is [-2.0, 46.0, 46.5, 280.0, 24.0, 23.81070303907723, -0.06927915644661746, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.40720221606648205, 0.46, 0.155, 0.30939226519337015, 0.5, 0.48422525325643573, 0.47690694785112747, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7053277], dtype=float32), -0.099939145]. 
=============================================
[2019-04-07 17:06:36,774] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9188080e-20 7.6177224e-19 1.7861035e-22 1.3702672e-16 1.8358710e-19
 1.0000000e+00 2.2238049e-14 1.7087307e-16], sum to 1.0000
[2019-04-07 17:06:36,774] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3614
[2019-04-07 17:06:36,887] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.8, 56.0, 105.5, 760.5, 24.0, 24.96112281906756, 0.2423863703864429, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2728800.0000, 
sim time next is 2730600.0000, 
raw observation next is [-4.4, 55.0, 102.0, 733.0, 24.0, 24.69818270207914, 0.2032684320864317, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3407202216066482, 0.55, 0.34, 0.8099447513812155, 0.5, 0.5581818918399284, 0.5677561440288106, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.56619966], dtype=float32), -0.7783305]. 
=============================================
[2019-04-07 17:06:39,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2164578e-20 9.7904198e-19 3.5623767e-22 8.8055994e-16 7.9740780e-20
 1.0000000e+00 4.7607935e-13 4.3609838e-16], sum to 1.0000
[2019-04-07 17:06:39,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2180
[2019-04-07 17:06:39,953] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 79.0, 0.0, 0.0, 24.0, 23.27427593485051, -0.1454946104449931, 0.0, 1.0, 45578.06195997237], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 874800.0000, 
sim time next is 876600.0000, 
raw observation next is [-1.45, 77.5, 0.0, 0.0, 24.0, 23.31312212718883, -0.1374010805637478, 0.0, 1.0, 40542.53344684385], 
processed observation next is [1.0, 0.13043478260869565, 0.422437673130194, 0.775, 0.0, 0.0, 0.5, 0.44276017726573585, 0.45419963981208406, 0.0, 1.0, 0.19305968308020882], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.46866727], dtype=float32), 1.2744404]. 
=============================================
[2019-04-07 17:06:41,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:06:41,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:06:41,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run35
[2019-04-07 17:06:42,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:06:42,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:06:42,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run35
[2019-04-07 17:06:42,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:06:42,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:06:42,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run35
[2019-04-07 17:07:03,014] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8875134e-21 7.9481204e-18 1.9922830e-23 7.8360978e-18 1.0077867e-20
 1.0000000e+00 5.9641081e-14 9.8814559e-17], sum to 1.0000
[2019-04-07 17:07:03,015] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3532
[2019-04-07 17:07:03,067] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 77.0, 0.0, 0.0, 24.0, 23.63290218226885, -0.02124577777095077, 0.0, 1.0, 15839.277382060907], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3808800.0000, 
sim time next is 3810600.0000, 
raw observation next is [-4.0, 74.0, 0.0, 0.0, 24.0, 23.51090868743003, -0.05612864787865466, 0.0, 1.0, 47861.77562796402], 
processed observation next is [1.0, 0.08695652173913043, 0.3518005540166205, 0.74, 0.0, 0.0, 0.5, 0.4592423906191693, 0.4812904507071151, 0.0, 1.0, 0.22791321727601915], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8116032], dtype=float32), -1.0249377]. 
=============================================
[2019-04-07 17:07:14,387] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-07 17:07:14,388] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:07:14,388] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:07:14,392] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run78
[2019-04-07 17:07:14,412] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:07:14,425] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:07:14,429] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run78
[2019-04-07 17:07:14,419] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 17:07:14,450] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:07:14,458] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run78
[2019-04-07 17:08:10,082] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12465771], dtype=float32), 0.16362]
[2019-04-07 17:08:10,082] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [0.0, 91.0, 0.0, 0.0, 24.0, 23.42379203193462, -0.002684956172197666, 0.0, 1.0, 40556.01552955867]
[2019-04-07 17:08:10,082] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 17:08:10,084] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.1265188e-22 5.4126622e-20 6.6587379e-25 1.5477117e-18 1.9944455e-20
 1.0000000e+00 5.7926830e-15 7.8754146e-18], sampled 0.614917846371257
[2019-04-07 17:09:37,561] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:09:59,030] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:10:03,517] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 17:10:04,539] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 1540000, evaluation results [1540000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:10:05,898] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6066227e-19 1.2512028e-16 2.8978427e-19 9.4764458e-16 2.0214488e-17
 1.0000000e+00 1.0700060e-13 6.8565555e-15], sum to 1.0000
[2019-04-07 17:10:05,898] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0619
[2019-04-07 17:10:06,120] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 40.0, 0.0, 0.0, 24.0, 23.79085398441617, -0.07246096769973462, 1.0, 1.0, 27804.499056096236], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 412200.0000, 
sim time next is 414000.0000, 
raw observation next is [-9.5, 40.0, 0.0, 0.0, 24.0, 23.45001549487514, -0.1255087753547393, 1.0, 1.0, 71526.24002011148], 
processed observation next is [1.0, 0.8260869565217391, 0.1994459833795014, 0.4, 0.0, 0.0, 0.5, 0.4541679579062616, 0.45816374154842027, 1.0, 1.0, 0.34060114295291183], 
reward next is 0.9451, 
noisyNet noise sample is [array([0.01271262], dtype=float32), 1.8974066]. 
=============================================
[2019-04-07 17:10:06,123] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[87.31615 ]
 [87.60841 ]
 [87.8337  ]
 [87.75375 ]
 [88.932755]], R is [[87.88490295]
 [88.00605774]
 [88.09269714]
 [87.88189697]
 [88.00308228]].
[2019-04-07 17:10:08,993] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.5072190e-22 2.1973360e-17 4.5426539e-23 3.8239673e-17 2.3256591e-19
 1.0000000e+00 1.5801383e-14 1.6127218e-17], sum to 1.0000
[2019-04-07 17:10:08,993] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7720
[2019-04-07 17:10:09,098] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 24.0, 23.44883910015352, -0.06074352497192955, 0.0, 1.0, 41515.914045654514], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3717000.0000, 
sim time next is 3718800.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 24.0, 23.72052585988768, -0.0388211753719036, 0.0, 1.0, 15351.302672514663], 
processed observation next is [1.0, 0.043478260869565216, 0.3795013850415513, 0.71, 0.0, 0.0, 0.5, 0.4767104883239733, 0.48705960820936545, 0.0, 1.0, 0.07310144129768888], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3037628], dtype=float32), -0.51738274]. 
=============================================
[2019-04-07 17:10:14,971] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.2261554e-21 1.1186893e-19 1.1161714e-24 9.0115554e-18 9.4200879e-21
 1.0000000e+00 1.7068293e-15 3.2638204e-17], sum to 1.0000
[2019-04-07 17:10:14,972] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7459
[2019-04-07 17:10:15,098] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 81.5, 127.0, 467.0, 24.0, 23.12083209370496, -0.08288043091897622, 0.0, 1.0, 21330.345031704743], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 570600.0000, 
sim time next is 572400.0000, 
raw observation next is [-1.2, 83.0, 113.5, 270.0, 24.0, 23.13273101365264, -0.1036773107634101, 0.0, 1.0, 21293.64384140423], 
processed observation next is [0.0, 0.6521739130434783, 0.42936288088642666, 0.83, 0.37833333333333335, 0.2983425414364641, 0.5, 0.42772758447105347, 0.4654408964121966, 0.0, 1.0, 0.10139830400668681], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.57989144], dtype=float32), -1.5563557]. 
=============================================
[2019-04-07 17:10:21,396] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.6215162e-21 1.8321149e-18 1.6431390e-23 8.7076848e-18 1.6544133e-19
 1.0000000e+00 8.0342490e-15 8.4772434e-17], sum to 1.0000
[2019-04-07 17:10:21,397] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1056
[2019-04-07 17:10:21,459] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 79.0, 0.0, 0.0, 24.0, 23.27427593485051, -0.1454946104449931, 0.0, 1.0, 45578.06195997237], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 874800.0000, 
sim time next is 876600.0000, 
raw observation next is [-1.45, 77.5, 0.0, 0.0, 24.0, 23.31312212718883, -0.1374010805637478, 0.0, 1.0, 40542.53344684385], 
processed observation next is [1.0, 0.13043478260869565, 0.422437673130194, 0.775, 0.0, 0.0, 0.5, 0.44276017726573585, 0.45419963981208406, 0.0, 1.0, 0.19305968308020882], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.9086413], dtype=float32), 0.73827976]. 
=============================================
[2019-04-07 17:10:22,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:10:22,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:10:22,152] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run35
[2019-04-07 17:10:25,737] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1961490e-20 6.0703663e-19 9.4214029e-24 2.4006396e-17 1.5043686e-18
 1.0000000e+00 8.3169548e-14 1.8760008e-16], sum to 1.0000
[2019-04-07 17:10:25,738] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8989
[2019-04-07 17:10:25,780] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 71.0, 0.0, 0.0, 24.0, 23.51794952147753, -0.03249194960935935, 0.0, 1.0, 26483.925061323203], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4518000.0000, 
sim time next is 4519800.0000, 
raw observation next is [-0.9, 72.0, 0.0, 0.0, 24.0, 23.49317660479851, -0.04282111465504116, 1.0, 1.0, 12904.204287834558], 
processed observation next is [1.0, 0.30434782608695654, 0.43767313019390586, 0.72, 0.0, 0.0, 0.5, 0.4577647170665425, 0.4857262951149863, 1.0, 1.0, 0.06144859184683123], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.19084989], dtype=float32), -1.3777814]. 
=============================================
[2019-04-07 17:10:51,015] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:10:51,015] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:10:51,020] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run35
[2019-04-07 17:10:55,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8790357e-22 4.3705891e-18 1.0878445e-22 5.1283289e-17 5.6202328e-20
 1.0000000e+00 1.1247432e-13 1.8329698e-16], sum to 1.0000
[2019-04-07 17:10:55,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3442
[2019-04-07 17:10:55,545] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.1, 92.5, 0.0, 0.0, 24.0, 22.65759597462569, -0.215130332564336, 0.0, 1.0, 42823.46385682845], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4779000.0000, 
sim time next is 4780800.0000, 
raw observation next is [-6.0, 92.0, 62.0, 209.5, 24.0, 22.61991323239174, -0.1872782295058889, 0.0, 1.0, 42670.30308336703], 
processed observation next is [0.0, 0.34782608695652173, 0.296398891966759, 0.92, 0.20666666666666667, 0.23149171270718233, 0.5, 0.3849927693659782, 0.437573923498037, 0.0, 1.0, 0.20319191944460488], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0617143], dtype=float32), 1.6613891]. 
=============================================
[2019-04-07 17:10:56,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:10:56,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:10:56,954] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run35
[2019-04-07 17:10:59,075] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.3215963e-23 1.1482535e-20 1.3905870e-25 1.1615196e-18 7.0663595e-22
 1.0000000e+00 4.7256662e-16 1.9721518e-18], sum to 1.0000
[2019-04-07 17:10:59,109] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0347
[2019-04-07 17:10:59,129] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 93.0, 31.0, 0.0, 24.0, 24.02802309863277, 0.09029376876507274, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1353600.0000, 
sim time next is 1355400.0000, 
raw observation next is [0.8, 94.5, 18.0, 0.0, 24.0, 23.97230966933513, 0.05091167520611905, 1.0, 1.0, 6226.803890076847], 
processed observation next is [1.0, 0.6956521739130435, 0.4847645429362882, 0.945, 0.06, 0.0, 0.5, 0.4976924724445941, 0.5169705584020396, 1.0, 1.0, 0.029651447095604033], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.241723], dtype=float32), -1.3218508]. 
=============================================
[2019-04-07 17:11:10,101] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8150235e-19 1.5226541e-17 2.7195168e-22 7.5259367e-17 4.5555243e-18
 1.0000000e+00 1.7672129e-13 1.9638292e-15], sum to 1.0000
[2019-04-07 17:11:10,101] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7997
[2019-04-07 17:11:10,165] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 69.5, 0.0, 0.0, 24.0, 22.97169766204649, -0.1681505151701038, 0.0, 1.0, 47867.40296404795], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 163800.0000, 
sim time next is 165600.0000, 
raw observation next is [-8.4, 71.0, 0.0, 0.0, 24.0, 22.87543435258983, -0.1899784575844363, 0.0, 1.0, 46978.521345671536], 
processed observation next is [1.0, 0.9565217391304348, 0.2299168975069252, 0.71, 0.0, 0.0, 0.5, 0.4062861960491526, 0.43667384747185456, 0.0, 1.0, 0.2237072445031978], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17887518], dtype=float32), -1.680764]. 
=============================================
[2019-04-07 17:11:10,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:11:10,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:11:10,868] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run35
[2019-04-07 17:11:11,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:11:11,653] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:11:11,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run35
[2019-04-07 17:11:15,956] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:11:15,956] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:11:15,959] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run35
[2019-04-07 17:11:18,091] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9832650e-21 6.7750356e-18 4.7102074e-23 7.0713116e-17 1.2485648e-18
 1.0000000e+00 6.0658103e-14 4.1788577e-16], sum to 1.0000
[2019-04-07 17:11:18,091] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3673
[2019-04-07 17:11:18,317] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 83.0, 122.5, 0.0, 24.0, 23.06239128483891, -0.08776843207845207, 0.0, 1.0, 27867.70213127749], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1771200.0000, 
sim time next is 1773000.0000, 
raw observation next is [-2.55, 83.0, 126.0, 0.0, 24.0, 23.05572354281031, -0.08598751575729306, 0.0, 1.0, 40485.92297825631], 
processed observation next is [0.0, 0.5217391304347826, 0.3919667590027701, 0.83, 0.42, 0.0, 0.5, 0.42131029523419244, 0.471337494747569, 0.0, 1.0, 0.19279010942026814], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.60639644], dtype=float32), 0.9887356]. 
=============================================
[2019-04-07 17:11:18,321] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[98.292786]
 [98.62461 ]
 [98.58329 ]
 [98.65268 ]
 [98.67137 ]], R is [[98.11060333]
 [98.12950134]
 [98.14820862]
 [98.16672516]
 [98.18505859]].
[2019-04-07 17:11:22,766] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:11:22,766] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:11:22,783] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run35
[2019-04-07 17:11:30,113] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0124690e-19 1.0569188e-17 2.4532075e-22 5.2954234e-16 3.4415625e-19
 1.0000000e+00 1.9880644e-13 2.9167914e-15], sum to 1.0000
[2019-04-07 17:11:30,113] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8038
[2019-04-07 17:11:30,226] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 24.0, 22.98805696469357, -0.1982826853367437, 0.0, 1.0, 42845.819899614085], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1994400.0000, 
sim time next is 1996200.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 24.0, 23.05814520612277, -0.1846900881154061, 0.0, 1.0, 42752.23293112017], 
processed observation next is [1.0, 0.08695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.5, 0.42151210051023086, 0.43843663729486465, 0.0, 1.0, 0.2035820615767627], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3056788], dtype=float32), -1.0994891]. 
=============================================
[2019-04-07 17:11:36,020] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7957341e-22 9.5477271e-20 2.3372674e-25 6.7152089e-19 1.2931151e-21
 1.0000000e+00 1.4765912e-15 1.3881797e-19], sum to 1.0000
[2019-04-07 17:11:36,020] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1989
[2019-04-07 17:11:36,067] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 93.0, 82.5, 0.0, 24.0, 23.86265290133347, -0.07525069875016907, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2890800.0000, 
sim time next is 2892600.0000, 
raw observation next is [1.0, 96.5, 87.0, 0.0, 24.0, 23.77871530836607, -0.09086888550136779, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4903047091412743, 0.965, 0.29, 0.0, 0.5, 0.4815596090305059, 0.4697103714995441, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0086836], dtype=float32), 0.08166126]. 
=============================================
[2019-04-07 17:11:46,591] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2788308e-20 3.6908210e-19 3.1324945e-24 7.0287092e-18 3.6109646e-20
 1.0000000e+00 1.1605608e-14 5.6845142e-18], sum to 1.0000
[2019-04-07 17:11:46,592] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5576
[2019-04-07 17:11:46,634] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 47.0, 264.0, 113.0, 24.0, 24.27010649423183, 0.1394080558487435, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4545000.0000, 
sim time next is 4546800.0000, 
raw observation next is [3.0, 45.0, 208.5, 62.5, 24.0, 24.60125173059578, 0.1729548967838467, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.45, 0.695, 0.06906077348066299, 0.5, 0.5501043108829817, 0.5576516322612822, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.71530914], dtype=float32), 0.10429986]. 
=============================================
[2019-04-07 17:11:50,309] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6890565e-21 3.6219460e-20 5.0542764e-24 2.6525970e-17 4.7014364e-20
 1.0000000e+00 4.5594103e-14 1.1844116e-16], sum to 1.0000
[2019-04-07 17:11:50,309] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1854
[2019-04-07 17:11:50,422] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.45, 76.5, 0.0, 0.0, 24.0, 23.07234521930419, -0.1487172872259057, 0.0, 1.0, 45781.85661876141], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2244600.0000, 
sim time next is 2246400.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 24.0, 22.96461909966193, -0.1719392002098655, 0.0, 1.0, 45648.04400637979], 
processed observation next is [1.0, 0.0, 0.2770083102493075, 0.78, 0.0, 0.0, 0.5, 0.4137182583051609, 0.4426869332633782, 0.0, 1.0, 0.21737163812561802], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.41048706], dtype=float32), -0.65783346]. 
=============================================
[2019-04-07 17:11:53,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8960410e-18 7.1038099e-17 3.9260528e-21 2.1992167e-15 8.8475821e-17
 1.0000000e+00 3.2232702e-12 9.2356949e-15], sum to 1.0000
[2019-04-07 17:11:53,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1706
[2019-04-07 17:11:53,220] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.9, 70.0, 0.0, 0.0, 24.0, 22.56856721768349, -0.2983159613929023, 0.0, 1.0, 48295.11581031609], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 342000.0000, 
sim time next is 343800.0000, 
raw observation next is [-13.9, 68.0, 0.0, 0.0, 24.0, 22.40905286769505, -0.3350494618038556, 0.0, 1.0, 48287.41644001284], 
processed observation next is [1.0, 1.0, 0.07756232686980608, 0.68, 0.0, 0.0, 0.5, 0.36742107230792076, 0.38831684606538147, 0.0, 1.0, 0.22994007828577545], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.49763814], dtype=float32), 1.6021391]. 
=============================================
[2019-04-07 17:12:11,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:12:11,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:12:11,084] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run36
[2019-04-07 17:12:13,736] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2257289e-25 8.1010297e-23 2.0339206e-29 2.7146585e-20 2.7349139e-22
 1.0000000e+00 5.9288025e-17 6.1724295e-20], sum to 1.0000
[2019-04-07 17:12:13,736] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6658
[2019-04-07 17:12:13,789] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 78.0, 0.0, 0.0, 24.0, 23.81427729562689, 0.1286878364546634, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1054800.0000, 
sim time next is 1056600.0000, 
raw observation next is [13.55, 79.0, 0.0, 0.0, 24.0, 23.76697990760129, 0.1230991939454664, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.8379501385041552, 0.79, 0.0, 0.0, 0.5, 0.48058165896677413, 0.5410330646484888, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.024824], dtype=float32), -0.8881808]. 
=============================================
[2019-04-07 17:12:14,131] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-07 17:12:14,132] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:12:14,132] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:12:14,138] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run79
[2019-04-07 17:12:14,159] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:12:14,160] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:12:14,164] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run79
[2019-04-07 17:12:14,186] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 17:12:14,189] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:12:14,194] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run79
[2019-04-07 17:12:46,460] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12472894], dtype=float32), 0.16408731]
[2019-04-07 17:12:46,460] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [1.35, 77.5, 0.0, 0.0, 24.0, 23.48352442175664, 0.09506659646144922, 0.0, 1.0, 38464.56609453104]
[2019-04-07 17:12:46,460] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 17:12:46,462] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [2.0969952e-22 5.0320473e-20 6.3754205e-25 1.4411793e-18 1.6380973e-20
 1.0000000e+00 4.7359730e-15 6.7086833e-18], sampled 0.5440748627297317
[2019-04-07 17:13:55,736] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12472894], dtype=float32), 0.16408731]
[2019-04-07 17:13:55,753] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-3.9, 62.0, 188.0, 223.0, 24.0, 24.04807995789442, -0.03644783183256826, 1.0, 1.0, 0.0]
[2019-04-07 17:13:55,753] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 17:13:55,755] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [3.6839691e-20 4.3336828e-18 1.5861711e-22 1.0145235e-16 1.2555859e-18
 1.0000000e+00 1.1582549e-13 3.5023182e-16], sampled 0.9257609971202262
[2019-04-07 17:14:38,438] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:14:56,052] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:15:02,127] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 17:15:03,150] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1560000, evaluation results [1560000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:15:07,343] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.5019530e-20 3.6439831e-19 4.6700591e-23 9.6475407e-18 3.5522183e-19
 1.0000000e+00 2.9919844e-13 1.7124240e-16], sum to 1.0000
[2019-04-07 17:15:07,343] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7418
[2019-04-07 17:15:07,533] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 54.0, 34.0, 2.5, 24.0, 24.14808333337125, -0.08952128178340178, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 752400.0000, 
sim time next is 754200.0000, 
raw observation next is [-3.35, 55.0, 0.0, 0.0, 24.0, 23.31893229569163, -0.1015168652234669, 1.0, 1.0, 102002.08044950613], 
processed observation next is [1.0, 0.7391304347826086, 0.3698060941828255, 0.55, 0.0, 0.0, 0.5, 0.4432443579743026, 0.4661610449255111, 1.0, 1.0, 0.48572419261669586], 
reward next is 0.8000, 
noisyNet noise sample is [array([-0.35283977], dtype=float32), -0.932713]. 
=============================================
[2019-04-07 17:15:47,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:15:47,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:15:47,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run36
[2019-04-07 17:15:48,010] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.22505424e-20 5.02642865e-19 2.92015126e-24 1.29069309e-17
 8.12124698e-20 1.00000000e+00 2.07987517e-14 1.79003102e-16], sum to 1.0000
[2019-04-07 17:15:48,010] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3333
[2019-04-07 17:15:48,090] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 66.0, 0.0, 0.0, 24.0, 23.31460672896235, 0.06390055814658181, 0.0, 1.0, 172826.70171012584], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3538800.0000, 
sim time next is 3540600.0000, 
raw observation next is [-1.5, 63.0, 0.0, 0.0, 24.0, 23.6830575057227, 0.07125068543190688, 0.0, 1.0, 6251.7213142617065], 
processed observation next is [1.0, 1.0, 0.4210526315789474, 0.63, 0.0, 0.0, 0.5, 0.4735881254768917, 0.5237502284773022, 0.0, 1.0, 0.029770101496484316], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1282542], dtype=float32), 1.0526571]. 
=============================================
[2019-04-07 17:15:51,230] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3526165e-21 5.0500684e-19 1.5717568e-23 1.1197150e-17 3.5879538e-19
 1.0000000e+00 1.3390370e-14 2.0445369e-16], sum to 1.0000
[2019-04-07 17:15:51,230] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4080
[2019-04-07 17:15:51,301] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 24.0, 23.34763635487469, -0.03127101628891126, 0.0, 1.0, 57934.761039324105], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4755600.0000, 
sim time next is 4757400.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 24.0, 23.42721544213297, -0.02853900541235424, 0.0, 1.0, 32937.69070476357], 
processed observation next is [0.0, 0.043478260869565216, 0.3518005540166205, 0.71, 0.0, 0.0, 0.5, 0.45226795351108073, 0.49048699819588193, 0.0, 1.0, 0.15684614621315984], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2722284], dtype=float32), 0.87377137]. 
=============================================
[2019-04-07 17:15:52,426] A3C_AGENT_WORKER-Thread-3 INFO:Local step 99500, global step 1568869: loss 0.6704
[2019-04-07 17:15:52,426] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 99500, global step 1568869: learning rate 0.0000
[2019-04-07 17:15:56,238] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.61710562e-20 5.42616751e-18 1.01800504e-23 9.55751320e-16
 6.08617988e-19 1.00000000e+00 2.50768898e-14 1.12835125e-16], sum to 1.0000
[2019-04-07 17:15:56,238] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6129
[2019-04-07 17:15:56,311] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 72.0, 0.0, 0.0, 24.0, 23.18906412661108, -0.1076188229679178, 0.0, 1.0, 46017.38959258851], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2678400.0000, 
sim time next is 2680200.0000, 
raw observation next is [-8.0, 70.5, 0.0, 0.0, 24.0, 23.1736575129584, -0.1191878635515144, 0.0, 1.0, 45876.37581700442], 
processed observation next is [1.0, 0.0, 0.24099722991689754, 0.705, 0.0, 0.0, 0.5, 0.4311381260798666, 0.46027071214949516, 0.0, 1.0, 0.2184589324619258], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6112295], dtype=float32), -0.39770174]. 
=============================================
[2019-04-07 17:15:59,491] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.03049781e-20 2.17066668e-18 1.89329142e-23 2.38423831e-18
 1.03025074e-19 1.00000000e+00 4.40944727e-15 1.01543335e-16], sum to 1.0000
[2019-04-07 17:15:59,491] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0770
[2019-04-07 17:15:59,586] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 35.5, 23.0, 57.0, 24.0, 25.7747783333125, 0.3574088053258936, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4123800.0000, 
sim time next is 4125600.0000, 
raw observation next is [3.0, 34.0, 0.0, 0.0, 24.0, 24.95355094407661, 0.3015803599704182, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.5457063711911359, 0.34, 0.0, 0.0, 0.5, 0.5794625786730508, 0.6005267866568061, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1691619], dtype=float32), 1.0711424]. 
=============================================
[2019-04-07 17:16:04,682] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.7095877e-20 1.1478430e-18 6.1085899e-23 2.0214024e-17 1.1768307e-18
 1.0000000e+00 2.9215813e-14 3.8041947e-17], sum to 1.0000
[2019-04-07 17:16:04,682] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3123
[2019-04-07 17:16:04,873] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.2, 88.5, 33.0, 21.0, 24.0, 23.72735472102244, -0.1641537735535341, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1931400.0000, 
sim time next is 1933200.0000, 
raw observation next is [-8.9, 86.0, 59.0, 285.0, 24.0, 23.83165336618471, -0.1262751505225607, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.21606648199445982, 0.86, 0.19666666666666666, 0.3149171270718232, 0.5, 0.4859711138487259, 0.4579082831591464, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.10359107], dtype=float32), 0.3124486]. 
=============================================
[2019-04-07 17:16:07,684] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:16:07,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:16:07,688] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run36
[2019-04-07 17:16:17,008] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2842867e-20 1.0256281e-18 3.9682386e-23 7.3764314e-17 1.4414157e-18
 1.0000000e+00 7.6151847e-14 7.0785452e-17], sum to 1.0000
[2019-04-07 17:16:17,008] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4895
[2019-04-07 17:16:17,105] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.35, 68.5, 30.0, 0.0, 24.0, 23.80927685300432, -0.1973150268984666, 1.0, 1.0, 55719.706175539824], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1960200.0000, 
sim time next is 1962000.0000, 
raw observation next is [-3.9, 75.0, 17.5, 1.0, 24.0, 23.79431996473574, -0.1073006608626666, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.75, 0.058333333333333334, 0.0011049723756906078, 0.5, 0.48285999706131183, 0.4642331130457778, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1213701], dtype=float32), 0.22227806]. 
=============================================
[2019-04-07 17:16:17,109] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[93.6198  ]
 [93.01467 ]
 [92.464554]
 [92.58789 ]
 [92.74671 ]], R is [[94.08352661]
 [94.14269257]
 [94.20126343]
 [94.25925446]
 [94.31666565]].
[2019-04-07 17:16:19,167] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.0031832e-20 4.0663996e-18 2.3739056e-22 3.0996522e-16 8.2190196e-19
 1.0000000e+00 1.0746918e-13 7.7099109e-16], sum to 1.0000
[2019-04-07 17:16:19,167] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9605
[2019-04-07 17:16:19,261] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 24.0, 22.82458879728822, -0.2360299407010299, 0.0, 1.0, 42402.639583818855], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2359800.0000, 
sim time next is 2361600.0000, 
raw observation next is [-3.4, 69.0, 19.5, 0.0, 24.0, 22.74703874151452, -0.2222193445883461, 0.0, 1.0, 42752.396137283155], 
processed observation next is [0.0, 0.34782608695652173, 0.368421052631579, 0.69, 0.065, 0.0, 0.5, 0.3955865617928766, 0.425926885137218, 0.0, 1.0, 0.2035828387489674], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.19380671], dtype=float32), -1.6715782]. 
=============================================
[2019-04-07 17:16:33,170] A3C_AGENT_WORKER-Thread-3 INFO:Local step 100000, global step 1575422: loss 0.1364
[2019-04-07 17:16:33,189] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 100000, global step 1575422: learning rate 0.0000
[2019-04-07 17:16:40,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:16:40,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:16:40,323] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run36
[2019-04-07 17:16:42,608] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.4895115e-22 3.4382460e-17 2.5923492e-22 3.7302590e-17 1.4438584e-19
 1.0000000e+00 8.4199534e-14 3.1976309e-16], sum to 1.0000
[2019-04-07 17:16:42,608] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2970
[2019-04-07 17:16:42,674] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 24.0, 23.19416819773794, -0.08995344263812655, 0.0, 1.0, 41928.187143834984], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4764600.0000, 
sim time next is 4766400.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 24.0, 23.08553588841091, -0.1115833476573287, 0.0, 1.0, 42048.57963657758], 
processed observation next is [0.0, 0.17391304347826086, 0.296398891966759, 0.92, 0.0, 0.0, 0.5, 0.42379465736757577, 0.4628055507808904, 0.0, 1.0, 0.2002313316027504], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.04128836], dtype=float32), 0.5326626]. 
=============================================
[2019-04-07 17:16:46,637] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6826721e-21 4.3586654e-19 3.9831771e-23 5.5992696e-17 1.8844398e-19
 1.0000000e+00 1.6614409e-14 1.8461474e-17], sum to 1.0000
[2019-04-07 17:16:46,638] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5424
[2019-04-07 17:16:46,841] A3C_AGENT_WORKER-Thread-18 INFO:Local step 99500, global step 1577668: loss 0.5872
[2019-04-07 17:16:46,842] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 99500, global step 1577668: learning rate 0.0000
[2019-04-07 17:16:46,863] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 78.0, 0.0, 0.0, 24.0, 23.27854774911933, -0.02853223235408448, 1.0, 1.0, 25406.176172017163], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4735800.0000, 
sim time next is 4737600.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 24.0, 23.08658583009058, -0.03180030565351619, 0.0, 1.0, 62853.74485474941], 
processed observation next is [1.0, 0.8695652173913043, 0.4349030470914128, 0.78, 0.0, 0.0, 0.5, 0.4238821525075484, 0.4893998981154946, 0.0, 1.0, 0.29930354692737815], 
reward next is 0.9864, 
noisyNet noise sample is [array([0.08916459], dtype=float32), -1.6495414]. 
=============================================
[2019-04-07 17:16:54,399] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:16:54,399] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:16:54,403] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run36
[2019-04-07 17:16:54,880] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.76784394e-20 1.09737105e-17 3.71855702e-22 1.03424565e-15
 8.89688480e-19 1.00000000e+00 2.36074859e-14 3.69129123e-16], sum to 1.0000
[2019-04-07 17:16:54,880] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5350
[2019-04-07 17:16:54,913] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 44.5, 236.0, 374.0, 24.0, 23.23724139735202, -0.06597872801498898, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4890600.0000, 
sim time next is 4892400.0000, 
raw observation next is [3.0, 45.0, 199.5, 398.0, 24.0, 23.24774868052636, -0.06259398550421101, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.5457063711911359, 0.45, 0.665, 0.4397790055248619, 0.5, 0.43731239004386335, 0.479135338165263, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3659495], dtype=float32), -1.260731]. 
=============================================
[2019-04-07 17:16:56,894] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.6852863e-21 5.7945718e-19 5.8220096e-24 8.2803583e-18 2.8729550e-20
 1.0000000e+00 4.0988153e-15 4.3846518e-17], sum to 1.0000
[2019-04-07 17:16:56,894] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3025
[2019-04-07 17:16:57,068] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 59.5, 152.0, 233.0, 24.0, 24.28757902515088, 0.01963097616992186, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2799000.0000, 
sim time next is 2800800.0000, 
raw observation next is [-3.0, 55.0, 163.0, 370.5, 24.0, 24.37158115861859, 0.04838093570959493, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.55, 0.5433333333333333, 0.4093922651933702, 0.5, 0.5309650965515491, 0.516126978569865, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.50525266], dtype=float32), -0.39689103]. 
=============================================
[2019-04-07 17:16:58,028] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:16:58,028] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:16:58,031] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run36
[2019-04-07 17:17:01,683] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-07 17:17:01,685] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:17:01,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:17:01,704] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run80
[2019-04-07 17:17:01,725] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:17:01,726] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:17:01,730] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run80
[2019-04-07 17:17:01,747] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 17:17:01,748] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:17:01,757] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run80
[2019-04-07 17:17:16,237] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12484372], dtype=float32), 0.1645474]
[2019-04-07 17:17:16,237] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-9.7, 58.0, 183.5, 309.0, 24.0, 24.16163649323862, 0.006841568227573268, 1.0, 1.0, 0.0]
[2019-04-07 17:17:16,237] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 17:17:16,238] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [2.3911230e-19 2.5399663e-17 1.4879122e-21 5.2052970e-16 6.9844476e-18
 1.0000000e+00 3.8642722e-13 1.3564547e-15], sampled 0.2866459056558889
[2019-04-07 17:17:58,671] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12484372], dtype=float32), 0.1645474]
[2019-04-07 17:17:58,671] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [3.6, 83.5, 0.0, 0.0, 24.0, 23.52135772015521, 0.05321144662462401, 0.0, 1.0, 35606.12904753641]
[2019-04-07 17:17:58,672] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 17:17:58,672] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [4.8358698e-23 1.2631897e-20 1.1665464e-25 3.7606453e-19 3.5038995e-21
 1.0000000e+00 1.5147419e-15 1.9218208e-18], sampled 0.1745501541157478
[2019-04-07 17:19:19,624] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:19:41,381] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:19:44,817] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 17:19:45,840] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1580000, evaluation results [1580000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:19:48,194] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:19:48,194] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:19:48,198] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run36
[2019-04-07 17:19:48,558] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:19:48,558] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:19:48,562] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run36
[2019-04-07 17:19:50,780] A3C_AGENT_WORKER-Thread-19 INFO:Local step 99500, global step 1580742: loss 0.6411
[2019-04-07 17:19:50,780] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 99500, global step 1580742: learning rate 0.0000
[2019-04-07 17:19:51,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:19:51,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:19:51,532] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run36
[2019-04-07 17:20:10,072] A3C_AGENT_WORKER-Thread-18 INFO:Local step 100000, global step 1583569: loss 0.1447
[2019-04-07 17:20:10,073] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 100000, global step 1583569: learning rate 0.0000
[2019-04-07 17:20:16,238] A3C_AGENT_WORKER-Thread-3 INFO:Local step 100500, global step 1584606: loss 0.3931
[2019-04-07 17:20:16,239] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 100500, global step 1584606: learning rate 0.0000
[2019-04-07 17:20:20,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9645296e-21 6.3254879e-19 2.7559948e-23 4.7171960e-18 9.4216376e-20
 1.0000000e+00 8.1765064e-15 4.5476613e-17], sum to 1.0000
[2019-04-07 17:20:20,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9113
[2019-04-07 17:20:20,477] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 29.0, 70.0, 162.0, 24.0, 23.87811502567286, -0.03454145088134128, 1.0, 1.0, 19976.306945443048], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2565000.0000, 
sim time next is 2566800.0000, 
raw observation next is [2.7, 29.0, 38.5, 83.5, 24.0, 24.218759878628, 0.002273360613668868, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5373961218836566, 0.29, 0.12833333333333333, 0.09226519337016574, 0.5, 0.5182299898856666, 0.500757786871223, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7294686], dtype=float32), 0.25709856]. 
=============================================
[2019-04-07 17:20:24,116] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8512071e-19 5.9592292e-18 9.1290682e-23 7.6664138e-17 4.5529680e-19
 1.0000000e+00 4.1536737e-13 1.1304975e-15], sum to 1.0000
[2019-04-07 17:20:24,116] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4353
[2019-04-07 17:20:24,167] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 24.0, 23.30861510080494, -0.07881192331563415, 0.0, 1.0, 54885.24039125929], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3909600.0000, 
sim time next is 3911400.0000, 
raw observation next is [-6.5, 61.5, 0.0, 0.0, 24.0, 23.40833525108841, -0.07798580543967222, 0.0, 1.0, 36050.215827533946], 
processed observation next is [1.0, 0.2608695652173913, 0.28254847645429365, 0.615, 0.0, 0.0, 0.5, 0.45069460425736746, 0.47400473152010925, 0.0, 1.0, 0.1716676944168283], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.04742236], dtype=float32), 1.5877202]. 
=============================================
[2019-04-07 17:20:25,216] A3C_AGENT_WORKER-Thread-14 INFO:Local step 99500, global step 1585984: loss 0.5897
[2019-04-07 17:20:25,217] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 99500, global step 1585984: learning rate 0.0000
[2019-04-07 17:20:30,857] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.37967860e-21 2.10495688e-19 1.80039263e-23 6.45303159e-18
 7.34488401e-21 1.00000000e+00 1.00599604e-14 1.95485807e-17], sum to 1.0000
[2019-04-07 17:20:30,857] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6497
[2019-04-07 17:20:31,052] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 80.5, 130.0, 396.0, 24.0, 23.10064522551386, -0.1172756605086516, 0.0, 1.0, 6237.027106562677], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 563400.0000, 
sim time next is 565200.0000, 
raw observation next is [-1.2, 80.0, 134.0, 495.5, 24.0, 23.09352453397711, -0.1090142680709736, 0.0, 1.0, 24338.606330497558], 
processed observation next is [0.0, 0.5652173913043478, 0.42936288088642666, 0.8, 0.44666666666666666, 0.5475138121546961, 0.5, 0.4244603778314258, 0.4636619106430088, 0.0, 1.0, 0.1158981253833217], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0743384], dtype=float32), -0.21698499]. 
=============================================
[2019-04-07 17:20:32,504] A3C_AGENT_WORKER-Thread-19 INFO:Local step 100000, global step 1587198: loss 0.1534
[2019-04-07 17:20:32,511] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 100000, global step 1587198: learning rate 0.0000
[2019-04-07 17:20:33,635] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:20:33,635] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:20:33,643] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run36
[2019-04-07 17:20:38,019] A3C_AGENT_WORKER-Thread-12 INFO:Local step 99500, global step 1588030: loss 0.6203
[2019-04-07 17:20:38,020] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 99500, global step 1588030: learning rate 0.0000
[2019-04-07 17:20:39,421] A3C_AGENT_WORKER-Thread-6 INFO:Local step 99500, global step 1588234: loss 0.5925
[2019-04-07 17:20:39,421] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 99500, global step 1588234: learning rate 0.0000
[2019-04-07 17:20:48,196] A3C_AGENT_WORKER-Thread-13 INFO:Local step 99500, global step 1589610: loss 0.5802
[2019-04-07 17:20:48,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 99500, global step 1589610: learning rate 0.0000
[2019-04-07 17:20:50,125] A3C_AGENT_WORKER-Thread-10 INFO:Local step 99500, global step 1589924: loss 0.5244
[2019-04-07 17:20:50,125] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 99500, global step 1589924: learning rate 0.0000
[2019-04-07 17:20:52,037] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4416485e-23 5.4465445e-21 5.0779812e-27 2.2727377e-20 5.9100005e-22
 1.0000000e+00 2.3565994e-15 1.1246239e-19], sum to 1.0000
[2019-04-07 17:20:52,038] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1018
[2019-04-07 17:20:52,082] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 100.0, 0.0, 0.0, 24.0, 23.57839183507092, -0.07851037784059875, 0.0, 1.0, 27469.754228095117], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3114000.0000, 
sim time next is 3115800.0000, 
raw observation next is [1.0, 100.0, 0.0, 0.0, 24.0, 23.6605979420596, -0.1006842854875028, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 1.0, 0.0, 0.0, 0.5, 0.4717164951716333, 0.46643857150416573, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.18580928], dtype=float32), 1.128865]. 
=============================================
[2019-04-07 17:20:53,615] A3C_AGENT_WORKER-Thread-16 INFO:Local step 99500, global step 1590501: loss 0.5983
[2019-04-07 17:20:53,677] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 99500, global step 1590501: learning rate 0.0000
[2019-04-07 17:21:02,310] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.0457257e-21 2.9929698e-18 6.7198334e-23 1.1844659e-16 6.8605933e-20
 1.0000000e+00 7.4739604e-15 1.9747273e-17], sum to 1.0000
[2019-04-07 17:21:02,311] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6639
[2019-04-07 17:21:02,395] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 39.0, 0.0, 0.0, 24.0, 23.5256441591222, 0.000901250893392283, 0.0, 1.0, 31451.157029570062], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4150800.0000, 
sim time next is 4152600.0000, 
raw observation next is [-1.5, 42.5, 0.0, 0.0, 24.0, 23.47912885047186, -0.007356715435244386, 0.0, 1.0, 45814.34745460638], 
processed observation next is [0.0, 0.043478260869565216, 0.4210526315789474, 0.425, 0.0, 0.0, 0.5, 0.45659407087265497, 0.49754776152158525, 0.0, 1.0, 0.21816355930764944], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2657539], dtype=float32), -1.276827]. 
=============================================
[2019-04-07 17:21:03,971] A3C_AGENT_WORKER-Thread-3 INFO:Local step 101000, global step 1592500: loss 0.0496
[2019-04-07 17:21:03,972] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 101000, global step 1592500: learning rate 0.0000
[2019-04-07 17:21:04,061] A3C_AGENT_WORKER-Thread-14 INFO:Local step 100000, global step 1592525: loss 0.1332
[2019-04-07 17:21:04,063] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 100000, global step 1592526: learning rate 0.0000
[2019-04-07 17:21:05,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:21:05,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:21:05,598] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run36
[2019-04-07 17:21:07,087] A3C_AGENT_WORKER-Thread-18 INFO:Local step 100500, global step 1593132: loss 0.4310
[2019-04-07 17:21:07,088] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 100500, global step 1593132: learning rate 0.0000
[2019-04-07 17:21:11,032] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4155565e-23 8.3876133e-20 2.2612315e-24 2.6859018e-18 3.1583223e-20
 1.0000000e+00 8.8329892e-15 2.0440044e-18], sum to 1.0000
[2019-04-07 17:21:11,032] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1111
[2019-04-07 17:21:11,094] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 59.0, 0.0, 0.0, 24.0, 24.06957886006229, 0.1474203244678009, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4570200.0000, 
sim time next is 4572000.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 24.0, 24.04788953131608, 0.1298814001070718, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4903047091412743, 0.61, 0.0, 0.0, 0.5, 0.5039907942763401, 0.5432938000356906, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0813894], dtype=float32), 2.6420677]. 
=============================================
[2019-04-07 17:21:11,098] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[99.19008 ]
 [99.07301 ]
 [98.38509 ]
 [97.55451 ]
 [97.545654]], R is [[99.25693512]
 [99.26436615]
 [99.188797  ]
 [98.76254272]
 [98.7749176 ]].
[2019-04-07 17:21:17,839] A3C_AGENT_WORKER-Thread-12 INFO:Local step 100000, global step 1595305: loss 0.1326
[2019-04-07 17:21:17,841] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 100000, global step 1595305: learning rate 0.0000
[2019-04-07 17:21:18,276] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:21:18,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:21:18,291] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run36
[2019-04-07 17:21:18,601] A3C_AGENT_WORKER-Thread-6 INFO:Local step 100000, global step 1595462: loss 0.1328
[2019-04-07 17:21:18,602] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 100000, global step 1595462: learning rate 0.0000
[2019-04-07 17:21:19,390] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0494411e-22 3.6485573e-20 3.2369877e-25 1.0524885e-18 1.0741880e-20
 1.0000000e+00 1.5146552e-15 1.1113193e-17], sum to 1.0000
[2019-04-07 17:21:19,390] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4836
[2019-04-07 17:21:19,488] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 71.0, 113.0, 795.5, 24.0, 24.91525335379378, 0.2079695473430271, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3754800.0000, 
sim time next is 3756600.0000, 
raw observation next is [-2.5, 68.0, 115.0, 822.0, 24.0, 24.93857010007013, 0.2297346724210362, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.39335180055401664, 0.68, 0.38333333333333336, 0.9082872928176795, 0.5, 0.5782141750058442, 0.5765782241403454, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7386127], dtype=float32), 0.4028088]. 
=============================================
[2019-04-07 17:21:21,848] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4314780e-21 1.1664255e-19 1.6025552e-23 1.3655344e-16 7.8514138e-19
 1.0000000e+00 2.1343387e-13 4.7253956e-16], sum to 1.0000
[2019-04-07 17:21:21,848] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8909
[2019-04-07 17:21:21,977] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 62.0, 153.0, 378.0, 24.0, 23.06544617242427, -0.1259654488057622, 0.0, 1.0, 30905.244003013435], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2372400.0000, 
sim time next is 2374200.0000, 
raw observation next is [-1.75, 54.5, 167.0, 306.0, 24.0, 23.11995101632572, -0.1270843223206782, 0.0, 1.0, 13807.91559567001], 
processed observation next is [0.0, 0.4782608695652174, 0.4141274238227147, 0.545, 0.5566666666666666, 0.33812154696132596, 0.5, 0.42666258469381013, 0.45763855922644064, 0.0, 1.0, 0.06575197902700006], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.64628184], dtype=float32), 0.44391468]. 
=============================================
[2019-04-07 17:21:26,616] A3C_AGENT_WORKER-Thread-13 INFO:Local step 100000, global step 1596758: loss 0.1300
[2019-04-07 17:21:26,617] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 100000, global step 1596758: learning rate 0.0000
[2019-04-07 17:21:27,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:21:27,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:21:27,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run36
[2019-04-07 17:21:29,185] A3C_AGENT_WORKER-Thread-10 INFO:Local step 100000, global step 1597135: loss 0.1294
[2019-04-07 17:21:29,202] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 100000, global step 1597135: learning rate 0.0000
[2019-04-07 17:21:29,529] A3C_AGENT_WORKER-Thread-19 INFO:Local step 100500, global step 1597193: loss 0.4378
[2019-04-07 17:21:29,530] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 100500, global step 1597193: learning rate 0.0000
[2019-04-07 17:21:30,624] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:21:30,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:21:30,628] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run36
[2019-04-07 17:21:31,333] A3C_AGENT_WORKER-Thread-16 INFO:Local step 100000, global step 1597497: loss 0.1297
[2019-04-07 17:21:31,333] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 100000, global step 1597497: learning rate 0.0000
[2019-04-07 17:21:32,408] A3C_AGENT_WORKER-Thread-4 INFO:Local step 99500, global step 1597646: loss 0.5707
[2019-04-07 17:21:32,408] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 99500, global step 1597646: learning rate 0.0000
[2019-04-07 17:21:34,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:21:34,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:21:34,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run36
[2019-04-07 17:21:42,063] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:21:42,064] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:21:42,067] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run36
[2019-04-07 17:21:44,307] A3C_AGENT_WORKER-Thread-3 INFO:Local step 101500, global step 1599074: loss 5.4008
[2019-04-07 17:21:44,321] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 101500, global step 1599074: learning rate 0.0000
[2019-04-07 17:21:51,489] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-07 17:21:51,501] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:21:51,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:21:51,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run81
[2019-04-07 17:21:51,531] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:21:51,531] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:21:51,535] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run81
[2019-04-07 17:21:51,556] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 17:21:51,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:21:51,571] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run81
[2019-04-07 17:24:15,586] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:24:35,115] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:24:39,843] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 17:24:40,868] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1600000, evaluation results [1600000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:24:43,732] A3C_AGENT_WORKER-Thread-18 INFO:Local step 101000, global step 1600388: loss 0.0138
[2019-04-07 17:24:43,733] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 101000, global step 1600388: learning rate 0.0000
[2019-04-07 17:24:53,562] A3C_AGENT_WORKER-Thread-14 INFO:Local step 100500, global step 1601708: loss 0.3276
[2019-04-07 17:24:53,563] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 100500, global step 1601708: learning rate 0.0000
[2019-04-07 17:24:54,469] A3C_AGENT_WORKER-Thread-17 INFO:Local step 99500, global step 1601812: loss 0.6108
[2019-04-07 17:24:54,470] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 99500, global step 1601812: learning rate 0.0000
[2019-04-07 17:24:59,520] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6242902e-23 3.3714159e-21 2.3892829e-25 3.1597925e-20 1.9760949e-21
 1.0000000e+00 1.0751043e-16 1.0684640e-17], sum to 1.0000
[2019-04-07 17:24:59,520] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5943
[2019-04-07 17:24:59,569] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 24.0, 23.3884554840365, -0.1346585211624166, 0.0, 1.0, 32853.86991318947], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 543600.0000, 
sim time next is 545400.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 24.0, 23.19730540116349, -0.1490053509390667, 0.0, 1.0, 52086.26704483691], 
processed observation next is [0.0, 0.30434782608695654, 0.4764542936288089, 0.92, 0.0, 0.0, 0.5, 0.43310878343029086, 0.45033154968697775, 0.0, 1.0, 0.24802984307065196], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06639998], dtype=float32), -1.1536765]. 
=============================================
[2019-04-07 17:25:02,279] A3C_AGENT_WORKER-Thread-4 INFO:Local step 100000, global step 1602918: loss 0.1399
[2019-04-07 17:25:02,308] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 100000, global step 1602918: learning rate 0.0000
[2019-04-07 17:25:03,581] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8058649e-22 2.9116272e-19 1.3522172e-24 2.3295128e-19 4.9876689e-21
 1.0000000e+00 4.8348378e-15 2.7182272e-17], sum to 1.0000
[2019-04-07 17:25:03,582] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9738
[2019-04-07 17:25:03,787] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 91.0, 0.0, 0.0, 24.0, 22.44855434982595, -0.1983501088867489, 1.0, 1.0, 149849.40718274654], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2273400.0000, 
sim time next is 2275200.0000, 
raw observation next is [-9.5, 91.0, 24.0, 18.0, 24.0, 23.65540692874526, -0.121442135309188, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.1994459833795014, 0.91, 0.08, 0.019889502762430938, 0.5, 0.4712839107287718, 0.4595192882302707, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4049993], dtype=float32), 0.17974305]. 
=============================================
[2019-04-07 17:25:08,301] A3C_AGENT_WORKER-Thread-6 INFO:Local step 100500, global step 1603772: loss 0.3498
[2019-04-07 17:25:08,302] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 100500, global step 1603772: learning rate 0.0000
[2019-04-07 17:25:08,441] A3C_AGENT_WORKER-Thread-12 INFO:Local step 100500, global step 1603790: loss 0.3569
[2019-04-07 17:25:08,441] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 100500, global step 1603790: learning rate 0.0000
[2019-04-07 17:25:08,785] A3C_AGENT_WORKER-Thread-19 INFO:Local step 101000, global step 1603835: loss 0.0119
[2019-04-07 17:25:08,786] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 101000, global step 1603835: learning rate 0.0000
[2019-04-07 17:25:09,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:25:09,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:25:09,288] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run37
[2019-04-07 17:25:10,490] A3C_AGENT_WORKER-Thread-20 INFO:Local step 99500, global step 1604070: loss 0.6101
[2019-04-07 17:25:10,491] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 99500, global step 1604070: learning rate 0.0000
[2019-04-07 17:25:11,402] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3462548e-19 1.1306171e-17 3.5805513e-22 2.8949193e-16 6.5777212e-18
 1.0000000e+00 7.2346702e-13 7.6564224e-16], sum to 1.0000
[2019-04-07 17:25:11,402] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5695
[2019-04-07 17:25:11,457] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.5, 51.0, 0.0, 0.0, 24.0, 23.38867630216296, -0.03037281153773276, 0.0, 1.0, 69646.61460833746], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3969000.0000, 
sim time next is 3970800.0000, 
raw observation next is [-9.0, 53.0, 0.0, 0.0, 24.0, 23.30536886257006, -0.03620143405406836, 0.0, 1.0, 63590.40375400035], 
processed observation next is [1.0, 1.0, 0.21329639889196678, 0.53, 0.0, 0.0, 0.5, 0.4421140718808383, 0.48793285531531055, 0.0, 1.0, 0.3028114464476207], 
reward next is 0.9829, 
noisyNet noise sample is [array([-0.4851187], dtype=float32), 0.8751127]. 
=============================================
[2019-04-07 17:25:17,710] A3C_AGENT_WORKER-Thread-13 INFO:Local step 100500, global step 1605086: loss 0.3351
[2019-04-07 17:25:17,710] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 100500, global step 1605086: learning rate 0.0000
[2019-04-07 17:25:19,122] A3C_AGENT_WORKER-Thread-2 INFO:Local step 99500, global step 1605293: loss 0.6112
[2019-04-07 17:25:19,122] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 99500, global step 1605293: learning rate 0.0000
[2019-04-07 17:25:19,858] A3C_AGENT_WORKER-Thread-16 INFO:Local step 100500, global step 1605413: loss 0.3007
[2019-04-07 17:25:19,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 100500, global step 1605413: learning rate 0.0000
[2019-04-07 17:25:20,561] A3C_AGENT_WORKER-Thread-10 INFO:Local step 100500, global step 1605520: loss 0.4219
[2019-04-07 17:25:20,562] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 100500, global step 1605520: learning rate 0.0000
[2019-04-07 17:25:22,409] A3C_AGENT_WORKER-Thread-5 INFO:Local step 99500, global step 1605821: loss 0.6131
[2019-04-07 17:25:22,410] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 99500, global step 1605821: learning rate 0.0000
[2019-04-07 17:25:26,308] A3C_AGENT_WORKER-Thread-18 INFO:Local step 101500, global step 1606428: loss 5.4582
[2019-04-07 17:25:26,335] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 101500, global step 1606428: learning rate 0.0000
[2019-04-07 17:25:27,017] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9488569e-23 4.7945482e-20 2.7733604e-26 2.3641853e-19 3.1385876e-21
 1.0000000e+00 1.9736300e-15 2.0378850e-18], sum to 1.0000
[2019-04-07 17:25:27,018] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2328
[2019-04-07 17:25:27,148] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 100.0, 0.0, 0.0, 24.0, 22.83459740710754, -0.09531690678848788, 0.0, 1.0, 128565.36855286657], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 937800.0000, 
sim time next is 939600.0000, 
raw observation next is [5.0, 100.0, 0.0, 0.0, 24.0, 23.31259612972158, -0.02362434469556063, 0.0, 1.0, 61817.691666402], 
processed observation next is [1.0, 0.9130434782608695, 0.6011080332409973, 1.0, 0.0, 0.0, 0.5, 0.442716344143465, 0.4921252184348131, 0.0, 1.0, 0.2943699603162], 
reward next is 0.9913, 
noisyNet noise sample is [array([-1.0674771], dtype=float32), 0.9864054]. 
=============================================
[2019-04-07 17:25:28,026] A3C_AGENT_WORKER-Thread-11 INFO:Local step 99500, global step 1606696: loss 0.5937
[2019-04-07 17:25:28,026] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 99500, global step 1606696: learning rate 0.0000
[2019-04-07 17:25:33,063] A3C_AGENT_WORKER-Thread-15 INFO:Local step 99500, global step 1607504: loss 0.5959
[2019-04-07 17:25:33,064] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 99500, global step 1607504: learning rate 0.0000
[2019-04-07 17:25:34,170] A3C_AGENT_WORKER-Thread-17 INFO:Local step 100000, global step 1607717: loss 0.1401
[2019-04-07 17:25:34,170] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 100000, global step 1607717: learning rate 0.0000
[2019-04-07 17:25:40,502] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.8153211e-19 1.6118616e-16 6.9888078e-21 1.3773848e-15 9.3480773e-18
 1.0000000e+00 1.7841742e-13 1.8246132e-15], sum to 1.0000
[2019-04-07 17:25:40,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4217
[2019-04-07 17:25:40,661] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.0, 65.0, 95.0, 383.0, 24.0, 23.904145956371, -0.08732575653347106, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 293400.0000, 
sim time next is 295200.0000, 
raw observation next is [-11.7, 63.0, 91.0, 447.5, 24.0, 23.91951035889454, -0.08764788882319831, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.13850415512465375, 0.63, 0.30333333333333334, 0.494475138121547, 0.5, 0.4932925299078785, 0.47078403705893385, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3423057], dtype=float32), 1.6920385]. 
=============================================
[2019-04-07 17:25:41,079] A3C_AGENT_WORKER-Thread-14 INFO:Local step 101000, global step 1608901: loss 0.0345
[2019-04-07 17:25:41,079] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 101000, global step 1608901: learning rate 0.0000
[2019-04-07 17:25:50,378] A3C_AGENT_WORKER-Thread-19 INFO:Local step 101500, global step 1610624: loss 5.3814
[2019-04-07 17:25:50,387] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 101500, global step 1610624: learning rate 0.0000
[2019-04-07 17:25:50,777] A3C_AGENT_WORKER-Thread-20 INFO:Local step 100000, global step 1610707: loss 0.1479
[2019-04-07 17:25:50,782] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 100000, global step 1610707: learning rate 0.0000
[2019-04-07 17:25:53,150] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.4021756e-22 1.4098574e-19 5.0776791e-24 7.7484139e-17 1.0372459e-20
 1.0000000e+00 9.8209252e-15 5.5202651e-18], sum to 1.0000
[2019-04-07 17:25:53,150] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8315
[2019-04-07 17:25:53,194] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 54.0, 116.0, 805.5, 24.0, 24.50211886089776, 0.1098878889291733, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3330000.0000, 
sim time next is 3331800.0000, 
raw observation next is [-4.5, 52.0, 114.0, 800.0, 24.0, 24.14655081693791, 0.1739756233357644, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3379501385041552, 0.52, 0.38, 0.8839779005524862, 0.5, 0.5122125680781592, 0.5579918744452548, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6070702], dtype=float32), 0.51986337]. 
=============================================
[2019-04-07 17:25:55,403] A3C_AGENT_WORKER-Thread-6 INFO:Local step 101000, global step 1611658: loss 0.0142
[2019-04-07 17:25:55,405] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 101000, global step 1611658: learning rate 0.0000
[2019-04-07 17:25:55,651] A3C_AGENT_WORKER-Thread-12 INFO:Local step 101000, global step 1611714: loss 0.0328
[2019-04-07 17:25:55,652] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 101000, global step 1611714: learning rate 0.0000
[2019-04-07 17:25:58,786] A3C_AGENT_WORKER-Thread-4 INFO:Local step 100500, global step 1612376: loss 0.3466
[2019-04-07 17:25:58,788] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 100500, global step 1612376: learning rate 0.0000
[2019-04-07 17:25:59,365] A3C_AGENT_WORKER-Thread-2 INFO:Local step 100000, global step 1612482: loss 0.1339
[2019-04-07 17:25:59,367] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 100000, global step 1612483: learning rate 0.0000
[2019-04-07 17:26:00,522] A3C_AGENT_WORKER-Thread-5 INFO:Local step 100000, global step 1612713: loss 0.1360
[2019-04-07 17:26:00,550] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 100000, global step 1612713: learning rate 0.0000
[2019-04-07 17:26:02,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:26:02,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:26:02,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run37
[2019-04-07 17:26:06,048] A3C_AGENT_WORKER-Thread-13 INFO:Local step 101000, global step 1613608: loss 0.0151
[2019-04-07 17:26:06,049] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 101000, global step 1613608: learning rate 0.0000
[2019-04-07 17:26:06,645] A3C_AGENT_WORKER-Thread-16 INFO:Local step 101000, global step 1613710: loss 0.0342
[2019-04-07 17:26:06,646] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 101000, global step 1613710: learning rate 0.0000
[2019-04-07 17:26:07,748] A3C_AGENT_WORKER-Thread-10 INFO:Local step 101000, global step 1613874: loss 0.0104
[2019-04-07 17:26:07,749] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 101000, global step 1613874: learning rate 0.0000
[2019-04-07 17:26:08,320] A3C_AGENT_WORKER-Thread-11 INFO:Local step 100000, global step 1613963: loss 0.1225
[2019-04-07 17:26:08,322] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 100000, global step 1613963: learning rate 0.0000
[2019-04-07 17:26:11,574] A3C_AGENT_WORKER-Thread-15 INFO:Local step 100000, global step 1614514: loss 0.1296
[2019-04-07 17:26:11,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 100000, global step 1614514: learning rate 0.0000
[2019-04-07 17:26:22,306] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0439026e-21 1.7259377e-19 8.6807280e-24 3.4956541e-18 8.9568487e-20
 1.0000000e+00 3.2424421e-15 6.5623828e-18], sum to 1.0000
[2019-04-07 17:26:22,306] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0449
[2019-04-07 17:26:22,477] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 24.0, 23.09958209542033, -0.1186082721523953, 0.0, 1.0, 42713.67300686961], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1791000.0000, 
sim time next is 1792800.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 24.0, 23.0977663047933, -0.1219227311729654, 0.0, 1.0, 42355.617430779974], 
processed observation next is [0.0, 0.782608695652174, 0.3545706371191136, 0.82, 0.0, 0.0, 0.5, 0.424813858732775, 0.45935908960901156, 0.0, 1.0, 0.2016934163370475], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47238734], dtype=float32), -0.15782095]. 
=============================================
[2019-04-07 17:26:22,612] A3C_AGENT_WORKER-Thread-14 INFO:Local step 101500, global step 1616331: loss 5.4906
[2019-04-07 17:26:22,631] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 101500, global step 1616331: learning rate 0.0000
[2019-04-07 17:26:25,882] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:26:25,882] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:26:25,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run37
[2019-04-07 17:26:30,711] A3C_AGENT_WORKER-Thread-17 INFO:Local step 100500, global step 1617576: loss 0.4047
[2019-04-07 17:26:30,711] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 100500, global step 1617576: learning rate 0.0000
[2019-04-07 17:26:37,478] A3C_AGENT_WORKER-Thread-12 INFO:Local step 101500, global step 1618671: loss 5.3373
[2019-04-07 17:26:37,478] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 101500, global step 1618671: learning rate 0.0000
[2019-04-07 17:26:37,563] A3C_AGENT_WORKER-Thread-6 INFO:Local step 101500, global step 1618690: loss 5.4238
[2019-04-07 17:26:37,564] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 101500, global step 1618690: learning rate 0.0000
[2019-04-07 17:26:44,586] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2485179e-17 2.2939003e-15 8.8732227e-20 3.2331046e-15 1.1709925e-16
 1.0000000e+00 1.5748565e-12 2.7780839e-14], sum to 1.0000
[2019-04-07 17:26:44,586] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0702
[2019-04-07 17:26:44,651] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.2, 55.0, 0.0, 0.0, 24.0, 22.35713967742182, -0.3718342882051174, 0.0, 1.0, 46421.703970391805], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 435600.0000, 
sim time next is 437400.0000, 
raw observation next is [-11.2, 55.0, 0.0, 0.0, 24.0, 22.33220728887007, -0.3942762454506705, 0.0, 1.0, 46477.54284803438], 
processed observation next is [1.0, 0.043478260869565216, 0.15235457063711913, 0.55, 0.0, 0.0, 0.5, 0.3610172740725058, 0.3685745848497765, 0.0, 1.0, 0.22132163260968754], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0682445], dtype=float32), 1.2539693]. 
=============================================
[2019-04-07 17:26:45,462] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-07 17:26:45,463] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:26:45,463] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:26:45,467] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run82
[2019-04-07 17:26:45,487] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:26:45,487] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:26:45,499] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run82
[2019-04-07 17:26:45,517] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 17:26:45,517] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:26:45,524] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run82
[2019-04-07 17:29:04,239] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:29:07,658] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12491672], dtype=float32), 0.16541682]
[2019-04-07 17:29:07,659] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-4.5, 30.0, 0.0, 0.0, 24.0, 23.67318257788159, 0.04870576809890508, 0.0, 1.0, 21831.867855197648]
[2019-04-07 17:29:07,659] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 17:29:07,659] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.0574724e-19 3.1293765e-17 2.8469771e-21 6.0786017e-16 1.0265484e-17
 1.0000000e+00 3.8971880e-13 1.9043744e-15], sampled 0.9035302808424875
[2019-04-07 17:29:21,054] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:29:24,933] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 17:29:25,956] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1620000, evaluation results [1620000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:29:26,487] A3C_AGENT_WORKER-Thread-4 INFO:Local step 101000, global step 1620101: loss 0.0222
[2019-04-07 17:29:26,488] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 101000, global step 1620101: learning rate 0.0000
[2019-04-07 17:29:26,672] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.4519216e-20 5.7227204e-18 4.2640601e-23 6.9312118e-16 6.5049545e-19
 1.0000000e+00 2.7837328e-14 6.8950568e-16], sum to 1.0000
[2019-04-07 17:29:26,672] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5106
[2019-04-07 17:29:26,766] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 60.0, 0.0, 0.0, 24.0, 23.39638273503744, -0.124214103650239, 0.0, 1.0, 28791.349558006244], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3391200.0000, 
sim time next is 3393000.0000, 
raw observation next is [-3.0, 62.5, 0.0, 0.0, 24.0, 23.29505759293177, -0.1277563778410997, 0.0, 1.0, 58149.37536281065], 
processed observation next is [1.0, 0.2608695652173913, 0.3795013850415513, 0.625, 0.0, 0.0, 0.5, 0.4412547994109808, 0.45741454071963344, 0.0, 1.0, 0.2769017874419555], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4911122], dtype=float32), 1.3238218]. 
=============================================
[2019-04-07 17:29:26,813] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[94.61935 ]
 [95.016174]
 [95.23579 ]
 [95.32633 ]
 [95.42761 ]], R is [[94.71700287]
 [94.76983643]
 [94.82213593]
 [94.87391663]
 [94.92517853]].
[2019-04-07 17:29:27,330] A3C_AGENT_WORKER-Thread-13 INFO:Local step 101500, global step 1620233: loss 5.3177
[2019-04-07 17:29:27,330] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 101500, global step 1620233: learning rate 0.0000
[2019-04-07 17:29:28,010] A3C_AGENT_WORKER-Thread-20 INFO:Local step 100500, global step 1620352: loss 0.3668
[2019-04-07 17:29:28,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 100500, global step 1620352: learning rate 0.0000
[2019-04-07 17:29:28,249] A3C_AGENT_WORKER-Thread-16 INFO:Local step 101500, global step 1620402: loss 5.2395
[2019-04-07 17:29:28,250] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 101500, global step 1620402: learning rate 0.0000
[2019-04-07 17:29:28,785] A3C_AGENT_WORKER-Thread-10 INFO:Local step 101500, global step 1620515: loss 5.2578
[2019-04-07 17:29:28,788] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 101500, global step 1620515: learning rate 0.0000
[2019-04-07 17:29:32,407] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.7186685e-23 7.5175683e-22 2.9360540e-26 1.7927977e-17 1.4819369e-20
 1.0000000e+00 6.0037034e-17 5.1368826e-18], sum to 1.0000
[2019-04-07 17:29:32,407] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5323
[2019-04-07 17:29:32,456] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.95, 61.5, 0.0, 0.0, 24.0, 24.57281854994812, 0.2700056712947128, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4401000.0000, 
sim time next is 4402800.0000, 
raw observation next is [8.5, 62.0, 0.0, 0.0, 24.0, 24.23568456248068, 0.2137396966239927, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 1.0, 0.698060941828255, 0.62, 0.0, 0.0, 0.5, 0.5196403802067234, 0.5712465655413309, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09071212], dtype=float32), -0.13088861]. 
=============================================
[2019-04-07 17:29:36,585] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8097881e-20 4.2720955e-19 1.3132169e-23 1.6509097e-17 3.5426104e-19
 1.0000000e+00 2.3560928e-14 6.3985683e-17], sum to 1.0000
[2019-04-07 17:29:36,585] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2349
[2019-04-07 17:29:36,690] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 50.0, 115.0, 165.0, 24.0, 23.12552473357525, -0.0480427320947661, 1.0, 1.0, 52352.182114844], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2649600.0000, 
sim time next is 2651400.0000, 
raw observation next is [0.5, 50.0, 75.0, 124.0, 24.0, 24.20633326577267, 0.05277531744680946, 1.0, 1.0, 7670.423100549627], 
processed observation next is [1.0, 0.6956521739130435, 0.4764542936288089, 0.5, 0.25, 0.13701657458563535, 0.5, 0.5171944388143892, 0.5175917724822698, 1.0, 1.0, 0.03652582428833156], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.48366177], dtype=float32), 0.9980125]. 
=============================================
[2019-04-07 17:29:37,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:29:37,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:29:37,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run37
[2019-04-07 17:29:38,216] A3C_AGENT_WORKER-Thread-5 INFO:Local step 100500, global step 1622159: loss 0.3787
[2019-04-07 17:29:38,223] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 100500, global step 1622159: learning rate 0.0000
[2019-04-07 17:29:38,234] A3C_AGENT_WORKER-Thread-2 INFO:Local step 100500, global step 1622163: loss 0.3372
[2019-04-07 17:29:38,248] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 100500, global step 1622163: learning rate 0.0000
[2019-04-07 17:29:46,787] A3C_AGENT_WORKER-Thread-11 INFO:Local step 100500, global step 1623469: loss 0.3720
[2019-04-07 17:29:46,788] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 100500, global step 1623469: learning rate 0.0000
[2019-04-07 17:29:48,611] A3C_AGENT_WORKER-Thread-15 INFO:Local step 100500, global step 1623805: loss 0.4195
[2019-04-07 17:29:48,612] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 100500, global step 1623805: learning rate 0.0000
[2019-04-07 17:29:52,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:29:52,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:29:52,316] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run37
[2019-04-07 17:29:52,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:29:52,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:29:52,688] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run37
[2019-04-07 17:30:00,623] A3C_AGENT_WORKER-Thread-17 INFO:Local step 101000, global step 1625591: loss 0.0197
[2019-04-07 17:30:00,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 101000, global step 1625591: learning rate 0.0000
[2019-04-07 17:30:01,777] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.9623548e-20 1.6366124e-18 3.4702832e-22 2.6582696e-17 5.2194264e-19
 1.0000000e+00 2.0436540e-14 2.0514734e-17], sum to 1.0000
[2019-04-07 17:30:01,778] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4843
[2019-04-07 17:30:01,885] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 24.0, 23.55895990808847, 0.01634602596011092, 0.0, 1.0, 28048.37105189668], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4147200.0000, 
sim time next is 4149000.0000, 
raw observation next is [-1.0, 40.5, 0.0, 0.0, 24.0, 23.50813627772776, 0.01148645493347068, 0.0, 1.0, 48038.63227495891], 
processed observation next is [0.0, 0.0, 0.4349030470914128, 0.405, 0.0, 0.0, 0.5, 0.45901135647731345, 0.5038288183111569, 0.0, 1.0, 0.22875539178551862], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2472746], dtype=float32), -0.09380652]. 
=============================================
[2019-04-07 17:30:01,906] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[92.75812]
 [95.44273]
 [96.20401]
 [95.23762]
 [95.78595]], R is [[92.17557526]
 [92.25382233]
 [92.33128357]
 [92.16895294]
 [92.24726105]].
[2019-04-07 17:30:02,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:30:02,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:30:02,664] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run37
[2019-04-07 17:30:04,127] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:30:04,128] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:30:04,145] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run37
[2019-04-07 17:30:04,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:30:04,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:30:04,943] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run37
[2019-04-07 17:30:07,913] A3C_AGENT_WORKER-Thread-4 INFO:Local step 101500, global step 1626656: loss 5.2183
[2019-04-07 17:30:07,914] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 101500, global step 1626656: learning rate 0.0000
[2019-04-07 17:30:09,461] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.4663774e-21 2.1966213e-19 2.5948722e-22 4.6620991e-17 3.4214299e-19
 1.0000000e+00 2.3684147e-15 1.9147246e-16], sum to 1.0000
[2019-04-07 17:30:09,462] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9410
[2019-04-07 17:30:09,562] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.62817576806341, -0.03663619424266645, 0.0, 1.0, 28001.190747657238], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3009600.0000, 
sim time next is 3011400.0000, 
raw observation next is [-3.25, 65.0, 0.0, 0.0, 24.0, 23.51593179546627, -0.07374009747605917, 0.0, 1.0, 16793.251681069258], 
processed observation next is [0.0, 0.8695652173913043, 0.3725761772853186, 0.65, 0.0, 0.0, 0.5, 0.45966098295552243, 0.47541996750798027, 0.0, 1.0, 0.07996786514794885], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7967598], dtype=float32), 0.79019]. 
=============================================
[2019-04-07 17:30:09,956] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3025652e-20 1.3028914e-18 4.4633959e-24 4.3730594e-17 7.9057477e-20
 1.0000000e+00 4.1200035e-14 5.9948234e-17], sum to 1.0000
[2019-04-07 17:30:09,956] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7576
[2019-04-07 17:30:10,114] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.1, 61.0, 130.0, 603.0, 24.0, 23.64351888213438, -0.03606688296584665, 1.0, 1.0, 65675.31588276669], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 131400.0000, 
sim time next is 133200.0000, 
raw observation next is [-7.8, 61.0, 134.5, 543.5, 24.0, 24.00963268211738, 0.05972549207653747, 1.0, 1.0, 49176.2538779974], 
processed observation next is [1.0, 0.5652173913043478, 0.24653739612188366, 0.61, 0.4483333333333333, 0.6005524861878453, 0.5, 0.5008027235097817, 0.5199084973588458, 1.0, 1.0, 0.23417263751427334], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.61653364], dtype=float32), -0.067795835]. 
=============================================
[2019-04-07 17:30:16,673] A3C_AGENT_WORKER-Thread-20 INFO:Local step 101000, global step 1627818: loss 0.0209
[2019-04-07 17:30:16,674] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 101000, global step 1627818: learning rate 0.0000
[2019-04-07 17:30:27,503] A3C_AGENT_WORKER-Thread-5 INFO:Local step 101000, global step 1629547: loss 0.0236
[2019-04-07 17:30:27,504] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 101000, global step 1629547: learning rate 0.0000
[2019-04-07 17:30:27,974] A3C_AGENT_WORKER-Thread-2 INFO:Local step 101000, global step 1629630: loss 0.0272
[2019-04-07 17:30:27,975] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 101000, global step 1629630: learning rate 0.0000
[2019-04-07 17:30:31,326] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6682051e-21 2.9324171e-18 9.1176835e-24 1.0629919e-17 1.9290463e-20
 1.0000000e+00 6.5932062e-15 1.9301679e-17], sum to 1.0000
[2019-04-07 17:30:31,326] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3297
[2019-04-07 17:30:31,365] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 78.5, 0.0, 0.0, 24.0, 23.01831547096532, -0.1930354737767235, 0.0, 1.0, 45617.72343514537], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 253800.0000, 
sim time next is 255600.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 24.0, 23.01119133405594, -0.1964768535123685, 0.0, 1.0, 45508.31093924312], 
processed observation next is [1.0, 1.0, 0.3545706371191136, 0.82, 0.0, 0.0, 0.5, 0.41759927783799505, 0.4345077154958772, 0.0, 1.0, 0.2167062425678244], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6002372], dtype=float32), -0.1012033]. 
=============================================
[2019-04-07 17:30:33,837] A3C_AGENT_WORKER-Thread-11 INFO:Local step 101000, global step 1630545: loss 0.0196
[2019-04-07 17:30:33,837] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 101000, global step 1630545: learning rate 0.0000
[2019-04-07 17:30:37,287] A3C_AGENT_WORKER-Thread-15 INFO:Local step 101000, global step 1631064: loss 0.0250
[2019-04-07 17:30:37,287] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 101000, global step 1631064: learning rate 0.0000
[2019-04-07 17:30:42,466] A3C_AGENT_WORKER-Thread-17 INFO:Local step 101500, global step 1631927: loss 5.2762
[2019-04-07 17:30:42,471] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 101500, global step 1631928: learning rate 0.0000
[2019-04-07 17:30:44,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:30:44,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:30:44,020] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run37
[2019-04-07 17:30:53,603] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.5850749e-21 2.4798127e-17 2.6750271e-22 2.5209704e-16 6.4987047e-19
 1.0000000e+00 5.5387357e-13 2.3285478e-16], sum to 1.0000
[2019-04-07 17:30:53,603] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5081
[2019-04-07 17:30:53,645] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.5, 41.5, 116.0, 824.0, 24.0, 24.12498077012452, 0.1713553257175334, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3936600.0000, 
sim time next is 3938400.0000, 
raw observation next is [-5.0, 38.0, 110.5, 806.0, 24.0, 24.57089741720664, 0.2280620399922047, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.32409972299168976, 0.38, 0.36833333333333335, 0.8906077348066298, 0.5, 0.5475747847672201, 0.5760206799974016, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.80313635], dtype=float32), -0.278829]. 
=============================================
[2019-04-07 17:30:58,624] A3C_AGENT_WORKER-Thread-20 INFO:Local step 101500, global step 1634419: loss 5.2025
[2019-04-07 17:30:58,625] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 101500, global step 1634419: learning rate 0.0000
[2019-04-07 17:30:59,172] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.8151249e-21 1.0310375e-18 7.4423782e-23 1.7180700e-17 4.0506660e-20
 1.0000000e+00 4.0616466e-15 1.8211622e-17], sum to 1.0000
[2019-04-07 17:30:59,172] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0436
[2019-04-07 17:30:59,207] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 64.0, 0.0, 0.0, 24.0, 23.27539986808231, -0.1170413654140346, 0.0, 1.0, 45112.076563226954], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 770400.0000, 
sim time next is 772200.0000, 
raw observation next is [-6.45, 65.5, 0.0, 0.0, 24.0, 23.19855953815041, -0.1327071903705387, 0.0, 1.0, 44696.11064118278], 
processed observation next is [1.0, 0.9565217391304348, 0.28393351800554023, 0.655, 0.0, 0.0, 0.5, 0.4332132948458674, 0.45576426987648705, 0.0, 1.0, 0.21283862210087037], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6062696], dtype=float32), 0.07696675]. 
=============================================
[2019-04-07 17:31:09,439] A3C_AGENT_WORKER-Thread-2 INFO:Local step 101500, global step 1636242: loss 5.1791
[2019-04-07 17:31:09,440] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 101500, global step 1636242: learning rate 0.0000
[2019-04-07 17:31:09,591] A3C_AGENT_WORKER-Thread-5 INFO:Local step 101500, global step 1636274: loss 5.2308
[2019-04-07 17:31:09,592] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 101500, global step 1636274: learning rate 0.0000
[2019-04-07 17:31:15,293] A3C_AGENT_WORKER-Thread-11 INFO:Local step 101500, global step 1637355: loss 5.1382
[2019-04-07 17:31:15,294] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 101500, global step 1637355: learning rate 0.0000
[2019-04-07 17:31:17,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:31:17,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:31:17,174] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run37
[2019-04-07 17:31:17,831] A3C_AGENT_WORKER-Thread-15 INFO:Local step 101500, global step 1637887: loss 5.2436
[2019-04-07 17:31:17,833] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 101500, global step 1637887: learning rate 0.0000
[2019-04-07 17:31:28,207] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-07 17:31:28,207] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:31:28,208] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:31:28,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run83
[2019-04-07 17:31:28,232] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:31:28,241] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:31:28,245] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 17:31:28,245] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:31:28,247] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run83
[2019-04-07 17:31:28,269] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run83
[2019-04-07 17:31:59,835] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12498045], dtype=float32), 0.16587102]
[2019-04-07 17:31:59,835] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-3.6, 82.5, 0.0, 0.0, 24.0, 22.13103400760157, -0.4627574620758192, 0.0, 1.0, 52218.56438095699]
[2019-04-07 17:31:59,835] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 17:31:59,836] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [6.5934909e-20 6.2227218e-18 4.4242248e-22 1.1394721e-16 2.7779140e-18
 1.0000000e+00 1.3017743e-13 4.2900498e-16], sampled 0.8038758086643344
[2019-04-07 17:33:57,067] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:34:15,819] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:34:19,137] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.5330 83805026.4189 32.8860
[2019-04-07 17:34:20,161] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1640000, evaluation results [1640000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.5329620425596, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:34:24,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:34:24,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:34:24,555] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run37
[2019-04-07 17:34:34,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:34:34,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:34:34,687] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run37
[2019-04-07 17:34:35,733] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:34:35,733] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:34:35,738] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run37
[2019-04-07 17:34:36,121] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0178697e-19 3.0021766e-17 9.0042871e-22 2.0434998e-16 3.0037885e-19
 1.0000000e+00 1.4404492e-13 8.3076081e-16], sum to 1.0000
[2019-04-07 17:34:36,127] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0139
[2019-04-07 17:34:36,176] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 23.0, 67.0, 548.0, 24.0, 25.34198195478512, 0.3006758169602036, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4033800.0000, 
sim time next is 4035600.0000, 
raw observation next is [-2.0, 24.0, 43.5, 370.5, 24.0, 25.27665482507669, 0.1600377140250132, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.40720221606648205, 0.24, 0.145, 0.4093922651933702, 0.5, 0.6063879020897242, 0.5533459046750044, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.27839047], dtype=float32), -0.2188566]. 
=============================================
[2019-04-07 17:34:41,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:34:41,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:34:41,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run37
[2019-04-07 17:34:43,473] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:34:43,473] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:34:43,476] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run37
[2019-04-07 17:34:45,315] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.81064408e-20 1.14537665e-17 2.10602196e-22 7.32525673e-17
 1.03596565e-18 1.00000000e+00 1.95429068e-14 2.16470586e-17], sum to 1.0000
[2019-04-07 17:34:45,315] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3550
[2019-04-07 17:34:45,384] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 78.0, 0.0, 0.0, 24.0, 22.73794068037159, -0.3222721928566867, 0.0, 1.0, 45610.91342246419], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1913400.0000, 
sim time next is 1915200.0000, 
raw observation next is [-8.4, 78.0, 0.0, 0.0, 24.0, 22.65014087727736, -0.3422169733817035, 0.0, 1.0, 45798.172495578474], 
processed observation next is [1.0, 0.17391304347826086, 0.2299168975069252, 0.78, 0.0, 0.0, 0.5, 0.3875117397731132, 0.38592767553943214, 0.0, 1.0, 0.21808653569323083], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0787683], dtype=float32), -0.6963425]. 
=============================================
[2019-04-07 17:34:46,402] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.3750615e-21 1.1884385e-18 5.3287586e-23 8.9614074e-17 4.7377862e-20
 1.0000000e+00 6.0629880e-14 2.9603050e-16], sum to 1.0000
[2019-04-07 17:34:46,402] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1722
[2019-04-07 17:34:46,468] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.1, 81.0, 0.0, 0.0, 24.0, 23.25461925235111, -0.1308756468600325, 0.0, 1.0, 43106.90912377633], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 858600.0000, 
sim time next is 860400.0000, 
raw observation next is [-2.8, 79.0, 0.0, 0.0, 24.0, 23.29242483950999, -0.1282556413880825, 0.0, 1.0, 42654.62872055128], 
processed observation next is [1.0, 1.0, 0.38504155124653744, 0.79, 0.0, 0.0, 0.5, 0.44103540329249924, 0.4572481195373059, 0.0, 1.0, 0.20311727962167275], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7736271], dtype=float32), 0.15866064]. 
=============================================
[2019-04-07 17:35:05,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6608084e-22 2.7272711e-19 9.1258307e-23 1.7944946e-17 6.7110313e-20
 1.0000000e+00 3.0542566e-13 6.2310118e-18], sum to 1.0000
[2019-04-07 17:35:05,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8035
[2019-04-07 17:35:06,018] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 24.0, 23.42721544213297, -0.02853900541235424, 0.0, 1.0, 32937.69070476357], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4757400.0000, 
sim time next is 4759200.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 24.0, 23.34720283240604, -0.0419226085312254, 0.0, 1.0, 48345.40777962766], 
processed observation next is [0.0, 0.08695652173913043, 0.3518005540166205, 0.71, 0.0, 0.0, 0.5, 0.4456002360338367, 0.4860257971562582, 0.0, 1.0, 0.2302162275220365], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.35714102], dtype=float32), -0.3154849]. 
=============================================
[2019-04-07 17:35:18,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8833600e-21 8.0791961e-19 1.4136242e-23 4.2752441e-18 8.1851967e-19
 1.0000000e+00 3.2115228e-13 3.0117544e-17], sum to 1.0000
[2019-04-07 17:35:18,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5553
[2019-04-07 17:35:18,317] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.1, 67.0, 0.0, 0.0, 24.0, 22.98667259301833, -0.2046797227680671, 0.0, 1.0, 42110.62820513222], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2356200.0000, 
sim time next is 2358000.0000, 
raw observation next is [-3.4, 69.0, 0.0, 0.0, 24.0, 22.91106768706481, -0.2189703673053253, 0.0, 1.0, 42221.24580297598], 
processed observation next is [0.0, 0.30434782608695654, 0.368421052631579, 0.69, 0.0, 0.0, 0.5, 0.40925564058873426, 0.42700987756489156, 0.0, 1.0, 0.20105355144274276], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6541169], dtype=float32), 0.8789417]. 
=============================================
[2019-04-07 17:35:18,393] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[92.001114]
 [92.10563 ]
 [92.30688 ]
 [92.49093 ]
 [92.51102 ]], R is [[92.03665161]
 [92.11628723]
 [92.19512177]
 [92.27317047]
 [92.35044098]].
[2019-04-07 17:35:21,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:35:21,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:35:21,112] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run38
[2019-04-07 17:35:29,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.05111125e-20 2.50076629e-19 2.33925776e-24 1.17975239e-18
 6.53895806e-21 1.00000000e+00 6.02952950e-15 1.88959584e-17], sum to 1.0000
[2019-04-07 17:35:29,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1771
[2019-04-07 17:35:29,795] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.1, 67.0, 0.0, 0.0, 24.0, 23.44579172865834, -0.1580748617135473, 0.0, 1.0, 28088.498083954084], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 678600.0000, 
sim time next is 680400.0000, 
raw observation next is [-3.4, 69.0, 0.0, 0.0, 24.0, 23.36455103437891, -0.1659592189046364, 0.0, 1.0, 55681.21644658199], 
processed observation next is [0.0, 0.9130434782608695, 0.368421052631579, 0.69, 0.0, 0.0, 0.5, 0.44704591953157574, 0.4446802603651212, 0.0, 1.0, 0.2651486497456285], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5924911], dtype=float32), 2.3974147]. 
=============================================
[2019-04-07 17:36:09,037] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7810944e-23 1.3290022e-21 5.1201685e-28 6.0329655e-20 5.8911798e-23
 1.0000000e+00 2.3261075e-15 1.0572726e-19], sum to 1.0000
[2019-04-07 17:36:09,037] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2497
[2019-04-07 17:36:09,120] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.4, 86.0, 0.0, 0.0, 24.0, 23.77742234946776, 0.09459578222548515, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1566000.0000, 
sim time next is 1567800.0000, 
raw observation next is [4.5, 85.5, 0.0, 0.0, 24.0, 23.726650974542, 0.06233304257661761, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.5872576177285319, 0.855, 0.0, 0.0, 0.5, 0.4772209145451667, 0.5207776808588725, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.18628491], dtype=float32), -0.3930093]. 
=============================================
[2019-04-07 17:36:14,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:36:14,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:36:14,904] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run38
[2019-04-07 17:36:17,279] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.85372644e-22 3.25366091e-19 5.63967607e-25 1.11431204e-17
 4.51663847e-20 1.00000000e+00 2.21671042e-15 8.10612019e-18], sum to 1.0000
[2019-04-07 17:36:17,281] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1626
[2019-04-07 17:36:17,322] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 77.0, 0.0, 0.0, 24.0, 23.3818555122214, 0.01626425366262385, 0.0, 1.0, 44286.362903677946], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3285000.0000, 
sim time next is 3286800.0000, 
raw observation next is [-7.0, 70.0, 0.0, 0.0, 24.0, 23.44263430980672, 0.003497286179444378, 0.0, 1.0, 28352.351329397938], 
processed observation next is [1.0, 0.043478260869565216, 0.2686980609418283, 0.7, 0.0, 0.0, 0.5, 0.45355285915056004, 0.5011657620598148, 0.0, 1.0, 0.13501119680665685], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.19958812], dtype=float32), 0.7554171]. 
=============================================
[2019-04-07 17:36:26,356] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2537569e-21 3.2477830e-19 6.5390231e-24 1.4528159e-17 1.5823051e-20
 1.0000000e+00 4.9772118e-15 6.4657248e-17], sum to 1.0000
[2019-04-07 17:36:26,356] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7456
[2019-04-07 17:36:26,437] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 24.0, 23.31095150600218, -0.07597871312864793, 0.0, 1.0, 58042.30496580177], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3376800.0000, 
sim time next is 3378600.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 24.0, 23.36624137152024, -0.07089552089262756, 0.0, 1.0, 43330.70380132997], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.77, 0.0, 0.0, 0.5, 0.4471867809600199, 0.47636815970245744, 0.0, 1.0, 0.20633668476823794], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.55647343], dtype=float32), 1.1022723]. 
=============================================
[2019-04-07 17:36:28,102] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-07 17:36:28,104] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:36:28,104] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:36:28,108] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run84
[2019-04-07 17:36:28,132] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:36:28,137] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 17:36:28,144] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:36:28,145] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:36:28,154] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run84
[2019-04-07 17:36:28,155] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run84
[2019-04-07 17:38:54,296] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:39:10,515] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:39:12,771] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 17:39:13,795] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 1660000, evaluation results [1660000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:39:26,557] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:39:26,557] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:39:26,560] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run38
[2019-04-07 17:39:29,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.26914864e-20 3.74837308e-18 1.19838716e-23 9.90345628e-17
 5.74401972e-19 1.00000000e+00 8.60098668e-14 7.22978937e-16], sum to 1.0000
[2019-04-07 17:39:29,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9487
[2019-04-07 17:39:29,807] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.2, 84.0, 71.0, 0.0, 24.0, 23.60599683626941, -0.05930944357024478, 1.0, 1.0, 70716.18533967304], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2043000.0000, 
sim time next is 2044800.0000, 
raw observation next is [-3.9, 82.0, 51.5, 0.0, 24.0, 24.09802971100159, -0.1086127368248255, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.3545706371191136, 0.82, 0.17166666666666666, 0.0, 0.5, 0.5081691425834659, 0.4637957543917248, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.18246901], dtype=float32), 0.04887476]. 
=============================================
[2019-04-07 17:39:32,586] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.2505410e-21 5.2773063e-19 4.7591713e-23 5.5351972e-17 1.9635930e-19
 1.0000000e+00 8.7598765e-14 2.2023459e-17], sum to 1.0000
[2019-04-07 17:39:32,586] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9005
[2019-04-07 17:39:32,646] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.3, 88.5, 0.0, 0.0, 24.0, 23.08757610523422, -0.1799898961783381, 0.0, 1.0, 44366.29697888405], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2086200.0000, 
sim time next is 2088000.0000, 
raw observation next is [-5.6, 91.0, 0.0, 0.0, 24.0, 23.06206772599649, -0.1672994363810815, 0.0, 1.0, 44654.81668902221], 
processed observation next is [1.0, 0.17391304347826086, 0.30747922437673136, 0.91, 0.0, 0.0, 0.5, 0.42183897716637403, 0.44423352120630616, 0.0, 1.0, 0.2126419842334391], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.60899043], dtype=float32), 2.33756]. 
=============================================
[2019-04-07 17:39:32,657] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[99.04887 ]
 [99.30312 ]
 [99.530495]
 [99.57232 ]
 [99.71514 ]], R is [[98.94935608]
 [98.95986176]
 [98.97026062]
 [98.9805603 ]
 [98.99075317]].
[2019-04-07 17:39:44,062] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2589144e-18 1.6009713e-17 3.2179219e-22 5.4946604e-16 2.9530497e-18
 1.0000000e+00 2.5544006e-13 2.1188249e-16], sum to 1.0000
[2019-04-07 17:39:44,063] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7503
[2019-04-07 17:39:44,153] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 31.0, 0.0, 0.0, 24.0, 23.78858658479458, 0.1205603638649787, 1.0, 1.0, 63302.37931425681], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4042800.0000, 
sim time next is 4044600.0000, 
raw observation next is [-4.0, 31.0, 0.0, 0.0, 24.0, 23.97496414814442, 0.09156850737603277, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3518005540166205, 0.31, 0.0, 0.0, 0.5, 0.4979136790120349, 0.530522835792011, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03329956], dtype=float32), 0.09098121]. 
=============================================
[2019-04-07 17:39:53,260] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:39:53,260] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:39:53,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run38
[2019-04-07 17:39:55,459] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3241781e-23 7.0732941e-21 2.5413223e-25 1.7277435e-18 1.6471761e-21
 1.0000000e+00 1.2130457e-15 1.1669734e-18], sum to 1.0000
[2019-04-07 17:39:55,459] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1305
[2019-04-07 17:39:55,510] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 78.0, 37.0, 27.5, 24.0, 23.44862745770132, 0.04581162086127947, 1.0, 1.0, 44254.90677542796], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4467600.0000, 
sim time next is 4469400.0000, 
raw observation next is [0.0, 75.0, 25.0, 55.0, 24.0, 24.09954656086408, 0.06493853772118806, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.46260387811634357, 0.75, 0.08333333333333333, 0.06077348066298342, 0.5, 0.5082955467386734, 0.521646179240396, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.9616861], dtype=float32), 0.6883576]. 
=============================================
[2019-04-07 17:40:07,661] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3169585e-18 1.3027839e-15 1.4855593e-20 1.2732564e-14 2.6361947e-17
 1.0000000e+00 4.1344610e-12 3.0193052e-14], sum to 1.0000
[2019-04-07 17:40:07,661] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5007
[2019-04-07 17:40:07,737] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.6, 47.0, 0.0, 0.0, 24.0, 23.18092942558251, -0.1732695587721446, 0.0, 1.0, 51577.46183061381], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 421200.0000, 
sim time next is 423000.0000, 
raw observation next is [-10.6, 48.0, 0.0, 0.0, 24.0, 23.04406847706321, -0.2036587644538416, 0.0, 1.0, 47537.08359818675], 
processed observation next is [1.0, 0.9130434782608695, 0.1689750692520776, 0.48, 0.0, 0.0, 0.5, 0.4203390397552675, 0.43211374518205276, 0.0, 1.0, 0.22636706475327023], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4139397], dtype=float32), 1.0867673]. 
=============================================
[2019-04-07 17:40:07,747] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[84.48453 ]
 [84.871346]
 [84.90929 ]
 [86.03507 ]
 [86.24877 ]], R is [[84.17971802]
 [84.33792114]
 [84.41951752]
 [84.57532501]
 [84.72640228]].
[2019-04-07 17:40:09,344] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0199974e-19 1.8358597e-16 1.9206084e-21 2.8945440e-16 5.7162403e-18
 1.0000000e+00 2.8163561e-12 5.5782091e-16], sum to 1.0000
[2019-04-07 17:40:09,345] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7638
[2019-04-07 17:40:09,419] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8999999999999999, 34.0, 0.0, 0.0, 24.0, 23.37943828022526, -0.1529613539270445, 0.0, 1.0, 67416.92410594819], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2500200.0000, 
sim time next is 2502000.0000, 
raw observation next is [-0.6, 35.0, 0.0, 0.0, 24.0, 23.45803224223952, -0.1505318223142094, 0.0, 1.0, 23840.211414913505], 
processed observation next is [0.0, 1.0, 0.44598337950138506, 0.35, 0.0, 0.0, 0.5, 0.45483602018662656, 0.44982272589526356, 0.0, 1.0, 0.11352481626149288], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2166276], dtype=float32), 1.0938421]. 
=============================================
[2019-04-07 17:40:09,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[88.97724 ]
 [88.680214]
 [89.013725]
 [89.158485]
 [88.86999 ]], R is [[88.86117554]
 [88.93724823]
 [89.04787445]
 [89.15739441]
 [89.26582336]].
[2019-04-07 17:40:17,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:40:17,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:40:17,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run38
[2019-04-07 17:40:18,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:40:18,602] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:40:18,652] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run38
[2019-04-07 17:40:26,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:40:26,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:40:26,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run38
[2019-04-07 17:40:26,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:40:26,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:40:26,340] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run38
[2019-04-07 17:40:28,788] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.64885001e-19 2.08586090e-19 1.00844665e-23 3.43511089e-18
 7.93981305e-19 1.00000000e+00 1.66421049e-13 1.90630588e-17], sum to 1.0000
[2019-04-07 17:40:28,788] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0867
[2019-04-07 17:40:28,893] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 181.0, 691.0, 24.0, 23.17718129833202, -0.0387248823067117, 0.0, 1.0, 18850.460185139626], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2982600.0000, 
sim time next is 2984400.0000, 
raw observation next is [-3.0, 65.0, 145.5, 745.5, 24.0, 23.1971421852588, -0.03293119587120927, 0.0, 1.0, 20160.664834121624], 
processed observation next is [0.0, 0.5652173913043478, 0.3795013850415513, 0.65, 0.485, 0.8237569060773481, 0.5, 0.4330951821049001, 0.4890229347095969, 0.0, 1.0, 0.09600316587676964], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.91209203], dtype=float32), -0.5706606]. 
=============================================
[2019-04-07 17:40:31,295] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:40:31,296] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:40:31,303] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run38
[2019-04-07 17:40:41,174] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5690842e-24 7.8612319e-22 5.7439060e-28 2.1804313e-21 1.1944946e-22
 1.0000000e+00 2.5947216e-16 3.0282009e-20], sum to 1.0000
[2019-04-07 17:40:41,175] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7407
[2019-04-07 17:40:41,259] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 82.0, 0.0, 0.0, 24.0, 23.56032826239871, 0.1141233084583882, 0.0, 1.0, 99120.96523205434], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1555200.0000, 
sim time next is 1557000.0000, 
raw observation next is [5.0, 82.0, 0.0, 0.0, 24.0, 23.64316837258973, 0.1326308931945471, 0.0, 1.0, 22343.976105005644], 
processed observation next is [1.0, 0.0, 0.6011080332409973, 0.82, 0.0, 0.0, 0.5, 0.4702640310491442, 0.5442102977315156, 0.0, 1.0, 0.1063998862143126], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3146784], dtype=float32), 0.8268905]. 
=============================================
[2019-04-07 17:40:41,284] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[108.952034]
 [108.72596 ]
 [109.041046]
 [109.11192 ]
 [108.339294]], R is [[108.66924286]
 [108.39626312]
 [108.31230164]
 [108.22917938]
 [108.07952118]].
[2019-04-07 17:40:49,004] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6245639e-24 1.4516891e-20 4.0931224e-25 3.0624723e-19 4.9502494e-22
 1.0000000e+00 9.0195086e-16 7.9443274e-19], sum to 1.0000
[2019-04-07 17:40:49,004] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2058
[2019-04-07 17:40:49,074] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 49.0, 115.0, 811.5, 24.0, 24.58337254438603, 0.1674021083919174, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3416400.0000, 
sim time next is 3418200.0000, 
raw observation next is [3.0, 49.0, 113.0, 806.0, 24.0, 24.42313802817743, 0.2032124526085068, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.49, 0.37666666666666665, 0.8906077348066298, 0.5, 0.5352615023481192, 0.5677374842028357, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1067445], dtype=float32), 0.8030304]. 
=============================================
[2019-04-07 17:41:02,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:41:02,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:41:02,346] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run38
[2019-04-07 17:41:20,234] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-07 17:41:20,234] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:41:20,235] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:41:20,238] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:41:20,238] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:41:20,238] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 17:41:20,240] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run85
[2019-04-07 17:41:20,243] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run85
[2019-04-07 17:41:20,259] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:41:20,284] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run85
[2019-04-07 17:43:46,834] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:44:03,646] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:44:06,565] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 17:44:07,589] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 1680000, evaluation results [1680000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:44:08,999] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.1847038e-20 1.5507730e-18 1.1787378e-22 1.4016549e-16 2.4340377e-18
 1.0000000e+00 4.1038885e-13 4.9580888e-16], sum to 1.0000
[2019-04-07 17:44:08,999] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6516
[2019-04-07 17:44:09,168] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 68.0, 0.0, 0.0, 24.0, 23.14046603212583, -0.1157500484941304, 0.0, 1.0, 66532.91341041373], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 158400.0000, 
sim time next is 160200.0000, 
raw observation next is [-8.4, 68.0, 0.0, 0.0, 24.0, 23.13941032818106, -0.1197508205073469, 0.0, 1.0, 71208.73109875822], 
processed observation next is [1.0, 0.8695652173913043, 0.2299168975069252, 0.68, 0.0, 0.0, 0.5, 0.4282841940150884, 0.4600830598308843, 0.0, 1.0, 0.3390891957083725], 
reward next is 0.9466, 
noisyNet noise sample is [array([-0.37054443], dtype=float32), 0.19139]. 
=============================================
[2019-04-07 17:44:20,253] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:44:20,253] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:44:20,262] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run38
[2019-04-07 17:44:24,234] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.41334261e-20 1.28674545e-17 3.15160332e-22 7.90760366e-16
 1.08769792e-17 1.00000000e+00 1.74391128e-13 6.76412263e-15], sum to 1.0000
[2019-04-07 17:44:24,234] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4896
[2019-04-07 17:44:24,284] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.9, 68.0, 0.0, 0.0, 24.0, 22.40905286769505, -0.3350494618038556, 0.0, 1.0, 48287.41644001284], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 343800.0000, 
sim time next is 345600.0000, 
raw observation next is [-13.9, 66.0, 0.0, 0.0, 24.0, 22.30761453791205, -0.3612878928491468, 0.0, 1.0, 48333.95385626658], 
processed observation next is [1.0, 0.0, 0.07756232686980608, 0.66, 0.0, 0.0, 0.5, 0.35896787815933734, 0.37957070238361773, 0.0, 1.0, 0.23016168502984083], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4019656], dtype=float32), 0.39487195]. 
=============================================
[2019-04-07 17:44:29,077] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3533647e-21 1.4304379e-19 1.0166778e-23 1.2110979e-17 1.3582538e-19
 1.0000000e+00 5.8379374e-15 8.2580253e-18], sum to 1.0000
[2019-04-07 17:44:29,078] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9978
[2019-04-07 17:44:29,150] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 79.0, 0.0, 0.0, 24.0, 23.10459693829042, -0.1693407386596852, 0.0, 1.0, 43722.39705537173], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2163600.0000, 
sim time next is 2165400.0000, 
raw observation next is [-7.0, 78.5, 0.0, 0.0, 24.0, 22.97155496651635, -0.188251883160365, 0.0, 1.0, 43781.661204727396], 
processed observation next is [1.0, 0.043478260869565216, 0.2686980609418283, 0.785, 0.0, 0.0, 0.5, 0.4142962472096959, 0.4372493722798783, 0.0, 1.0, 0.20848410097489237], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.25613227], dtype=float32), -0.99486065]. 
=============================================
[2019-04-07 17:44:44,127] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:44:44,127] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:44:44,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run38
[2019-04-07 17:44:48,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:44:48,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:44:48,441] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run38
[2019-04-07 17:44:48,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:44:48,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:44:48,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run38
[2019-04-07 17:44:56,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:44:56,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:44:56,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run38
[2019-04-07 17:45:01,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:45:01,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:45:01,408] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run38
[2019-04-07 17:45:04,674] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0363651e-21 2.1607023e-19 4.1069998e-23 1.5074025e-17 1.4938057e-19
 1.0000000e+00 1.0106488e-13 1.4042131e-16], sum to 1.0000
[2019-04-07 17:45:04,675] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2129
[2019-04-07 17:45:04,758] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.2, 96.0, 0.0, 0.0, 24.0, 20.58943728148884, -0.7294043441150452, 0.0, 1.0, 42405.57484272158], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 10800.0000, 
sim time next is 12600.0000, 
raw observation next is [7.45, 94.5, 0.0, 0.0, 24.0, 20.75195243092939, -0.6874634758983964, 0.0, 1.0, 41825.57035195166], 
processed observation next is [0.0, 0.13043478260869565, 0.6689750692520776, 0.945, 0.0, 0.0, 0.5, 0.22932936924411576, 0.27084550803386787, 0.0, 1.0, 0.19916938262834125], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05768272], dtype=float32), 0.4287739]. 
=============================================
[2019-04-07 17:45:25,485] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0765467e-20 1.2970496e-18 4.2549956e-22 8.7633724e-17 2.3137485e-19
 1.0000000e+00 4.0858677e-14 1.2134524e-16], sum to 1.0000
[2019-04-07 17:45:25,485] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0574
[2019-04-07 17:45:25,571] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.75, 71.0, 117.0, 0.0, 24.0, 24.24917619645569, -0.02285680332911795, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2197800.0000, 
sim time next is 2199600.0000, 
raw observation next is [-4.5, 71.0, 130.0, 0.0, 24.0, 24.06144890752602, -0.06285641147013508, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.3379501385041552, 0.71, 0.43333333333333335, 0.0, 0.5, 0.5051207422938351, 0.4790478628432883, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.274543], dtype=float32), -0.9835535]. 
=============================================
[2019-04-07 17:45:34,798] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8098073e-21 1.1279794e-19 9.3106768e-25 1.1662887e-17 6.6799733e-20
 1.0000000e+00 8.6861953e-16 9.5573573e-18], sum to 1.0000
[2019-04-07 17:45:34,799] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2120
[2019-04-07 17:45:34,962] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 71.0, 109.5, 225.5, 24.0, 24.26580105822482, 0.004496619828989097, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2196000.0000, 
sim time next is 2197800.0000, 
raw observation next is [-4.75, 71.0, 117.0, 0.0, 24.0, 24.24917619645569, -0.02285680332911795, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3310249307479225, 0.71, 0.39, 0.0, 0.5, 0.5207646830379741, 0.4923810655569607, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.18267167], dtype=float32), 1.2186267]. 
=============================================
[2019-04-07 17:45:35,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:45:35,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:45:35,198] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run39
[2019-04-07 17:45:40,156] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.2950448e-20 6.4753229e-18 2.7325454e-23 3.3940584e-16 1.1117555e-18
 1.0000000e+00 9.9647483e-14 1.8274821e-16], sum to 1.0000
[2019-04-07 17:45:40,156] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3063
[2019-04-07 17:45:40,375] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 91.0, 0.0, 0.0, 24.0, 22.22971589038708, -0.3861411782653451, 0.0, 1.0, 43938.21351197089], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2271600.0000, 
sim time next is 2273400.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 24.0, 22.44855434982595, -0.1983501088867489, 1.0, 1.0, 149849.40718274654], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.5, 0.3707128624854959, 0.43388329703775036, 1.0, 1.0, 0.7135686056321263], 
reward next is 0.5721, 
noisyNet noise sample is [array([-0.8139669], dtype=float32), -0.31978092]. 
=============================================
[2019-04-07 17:46:02,472] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.1258333e-20 3.4540984e-18 4.9172543e-23 7.2530695e-18 4.6387287e-20
 1.0000000e+00 6.1888141e-13 3.9640904e-17], sum to 1.0000
[2019-04-07 17:46:02,472] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5317
[2019-04-07 17:46:02,677] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.85, 70.0, 93.0, 91.0, 24.0, 24.06782642500183, -0.05149155239947234, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2626200.0000, 
sim time next is 2628000.0000, 
raw observation next is [-5.0, 65.0, 122.5, 183.0, 24.0, 24.10794499190758, -0.0456360103250209, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.32409972299168976, 0.65, 0.4083333333333333, 0.2022099447513812, 0.5, 0.5089954159922984, 0.4847879965583264, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3578517], dtype=float32), -0.9293511]. 
=============================================
[2019-04-07 17:46:02,681] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[94.80239 ]
 [94.97583 ]
 [95.18995 ]
 [95.197975]
 [95.056114]], R is [[94.88204193]
 [94.93321991]
 [94.98388672]
 [95.03404999]
 [95.08370972]].
[2019-04-07 17:46:03,675] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0330000e-22 2.7499290e-20 4.4955724e-24 2.6097978e-18 1.9242176e-20
 1.0000000e+00 1.1875107e-16 2.0245123e-17], sum to 1.0000
[2019-04-07 17:46:03,675] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7460
[2019-04-07 17:46:03,806] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 84.0, 29.0, 0.0, 24.0, 23.84007035113995, -0.05501485067481429, 1.0, 1.0, 33146.08441743008], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 837000.0000, 
sim time next is 838800.0000, 
raw observation next is [-3.9, 86.0, 14.5, 0.0, 24.0, 24.04260153313161, -0.1443330617661624, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.86, 0.04833333333333333, 0.0, 0.5, 0.5035501277609674, 0.4518889794112792, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.47824997], dtype=float32), -1.2301633]. 
=============================================
[2019-04-07 17:46:15,396] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-07 17:46:15,397] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:46:15,397] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:46:15,408] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:46:15,409] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 17:46:15,411] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:46:15,411] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run86
[2019-04-07 17:46:15,433] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run86
[2019-04-07 17:46:15,433] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:46:15,452] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run86
[2019-04-07 17:48:42,897] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:48:59,010] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:49:03,592] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 17:49:04,618] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1700000, evaluation results [1700000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:49:13,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4781013e-21 2.4715185e-19 5.1720036e-24 7.0242862e-18 4.7790429e-21
 1.0000000e+00 3.5011577e-15 5.2441193e-17], sum to 1.0000
[2019-04-07 17:49:13,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8244
[2019-04-07 17:49:14,018] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 24.0, 23.45194528219655, 0.007704701142957622, 0.0, 1.0, 35211.45625448536], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1400400.0000, 
sim time next is 1402200.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 24.0, 23.50878257824345, 0.04005600993777392, 0.0, 1.0, 54047.39843745023], 
processed observation next is [1.0, 0.21739130434782608, 0.44598337950138506, 1.0, 0.0, 0.0, 0.5, 0.45906521485362095, 0.5133520033125913, 0.0, 1.0, 0.25736856398785823], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0812542], dtype=float32), -0.62521374]. 
=============================================
[2019-04-07 17:49:16,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:49:16,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:49:16,652] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run39
[2019-04-07 17:49:16,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7856549e-22 8.6928734e-20 4.5105489e-25 2.2828792e-19 1.0036203e-20
 1.0000000e+00 8.2237989e-16 1.5505896e-18], sum to 1.0000
[2019-04-07 17:49:16,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7982
[2019-04-07 17:49:16,923] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 71.0, 0.0, 24.0, 24.19620867487777, 0.1322922858442266, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1348200.0000, 
sim time next is 1350000.0000, 
raw observation next is [1.1, 92.0, 57.5, 0.0, 24.0, 24.076611357374, 0.1034317215313917, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.92, 0.19166666666666668, 0.0, 0.5, 0.5063842797811665, 0.534477240510464, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.57233715], dtype=float32), -0.43128356]. 
=============================================
[2019-04-07 17:49:16,978] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[106.10102 ]
 [106.31775 ]
 [106.517075]
 [106.65674 ]
 [106.787445]], R is [[105.82657623]
 [105.76831055]
 [105.71062469]
 [105.65351868]
 [105.59698486]].
[2019-04-07 17:49:25,712] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0038328e-24 5.6989629e-22 4.5922136e-27 9.7070763e-20 3.2537786e-23
 1.0000000e+00 2.0397060e-17 2.9443771e-18], sum to 1.0000
[2019-04-07 17:49:25,713] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4012
[2019-04-07 17:49:25,753] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.9, 51.0, 77.0, 478.0, 24.0, 25.34555458759705, 0.4232704433396051, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1524600.0000, 
sim time next is 1526400.0000, 
raw observation next is [12.2, 50.0, 82.0, 253.0, 24.0, 25.65505349520977, 0.4586762520090519, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.8005540166204987, 0.5, 0.2733333333333333, 0.2795580110497238, 0.5, 0.6379211246008142, 0.6528920840030173, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.22362833], dtype=float32), 0.57854736]. 
=============================================
[2019-04-07 17:49:42,050] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4166301e-22 3.2112786e-20 3.0329692e-24 3.6836896e-19 4.4453910e-21
 1.0000000e+00 1.9380116e-16 3.4467669e-18], sum to 1.0000
[2019-04-07 17:49:42,051] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8562
[2019-04-07 17:49:42,097] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 60.0, 110.0, 775.0, 24.0, 24.88781269968867, 0.2210802921931585, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3839400.0000, 
sim time next is 3841200.0000, 
raw observation next is [-1.0, 60.0, 113.5, 798.5, 24.0, 24.95509685226552, 0.2491795007477085, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4349030470914128, 0.6, 0.37833333333333335, 0.8823204419889503, 0.5, 0.57959140435546, 0.5830598335825695, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5170959], dtype=float32), -0.30806452]. 
=============================================
[2019-04-07 17:49:42,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:49:42,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:49:42,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run39
[2019-04-07 17:49:42,771] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.6466080e-21 1.9373002e-18 1.6621337e-23 1.7752185e-18 3.6571968e-20
 1.0000000e+00 2.5136509e-14 3.9231863e-17], sum to 1.0000
[2019-04-07 17:49:42,772] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6236
[2019-04-07 17:49:42,816] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 51.0, 0.0, 0.0, 24.0, 23.30558026842278, 0.03033939081084262, 0.0, 1.0, 25434.079058071668], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3873600.0000, 
sim time next is 3875400.0000, 
raw observation next is [0.0, 55.5, 0.0, 0.0, 24.0, 23.33181561364562, 0.06779196482592133, 0.0, 1.0, 140136.16907309808], 
processed observation next is [1.0, 0.8695652173913043, 0.46260387811634357, 0.555, 0.0, 0.0, 0.5, 0.44431796780380167, 0.5225973216086405, 0.0, 1.0, 0.6673150908242765], 
reward next is 0.6184, 
noisyNet noise sample is [array([0.18830156], dtype=float32), -0.37522185]. 
=============================================
[2019-04-07 17:50:01,352] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.0999996e-22 4.9854294e-19 4.1439013e-24 2.6977530e-17 1.6121658e-20
 1.0000000e+00 2.3329502e-15 2.7607052e-18], sum to 1.0000
[2019-04-07 17:50:01,352] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3718
[2019-04-07 17:50:01,504] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 55.5, 153.0, 730.0, 24.0, 23.51336058134284, 0.01349845908906531, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4789800.0000, 
sim time next is 4791600.0000, 
raw observation next is [-2.0, 46.0, 137.5, 784.5, 24.0, 23.3566462062599, -0.001530717984264102, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.40720221606648205, 0.46, 0.4583333333333333, 0.8668508287292818, 0.5, 0.4463871838549916, 0.499489760671912, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6853981], dtype=float32), -0.5858968]. 
=============================================
[2019-04-07 17:50:15,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:50:15,614] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:50:15,618] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run39
[2019-04-07 17:50:18,823] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.7596145e-20 2.8859978e-17 6.3231172e-21 3.9508073e-16 3.7360961e-18
 1.0000000e+00 4.1218762e-13 1.4164640e-15], sum to 1.0000
[2019-04-07 17:50:18,823] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9440
[2019-04-07 17:50:18,957] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 31.0, 88.0, 837.0, 24.0, 23.24859200193053, -0.1462962096729993, 0.0, 1.0, 3118.5490331740325], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2462400.0000, 
sim time next is 2464200.0000, 
raw observation next is [0.5, 29.5, 90.0, 845.0, 24.0, 23.13787215946996, -0.164004134051151, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.4764542936288089, 0.295, 0.3, 0.9337016574585635, 0.5, 0.42815601328916336, 0.44533195531628306, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5685147], dtype=float32), 0.5184813]. 
=============================================
[2019-04-07 17:50:20,263] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3257533e-22 3.7577322e-20 2.7724415e-25 8.1807015e-19 1.3743626e-21
 1.0000000e+00 8.0272910e-16 1.1593954e-17], sum to 1.0000
[2019-04-07 17:50:20,265] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3809
[2019-04-07 17:50:20,325] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.1, 73.0, 0.0, 0.0, 24.0, 23.65570740180183, -0.07735776424946854, 0.0, 1.0, 11438.254247948322], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4343400.0000, 
sim time next is 4345200.0000, 
raw observation next is [2.9, 75.0, 0.0, 0.0, 24.0, 23.53533558446707, -0.05843616263572774, 0.0, 1.0, 66392.2117646247], 
processed observation next is [1.0, 0.30434782608695654, 0.5429362880886427, 0.75, 0.0, 0.0, 0.5, 0.46127796537225585, 0.4805212791214241, 0.0, 1.0, 0.31615338935535575], 
reward next is 0.9696, 
noisyNet noise sample is [array([1.2795343], dtype=float32), -0.15500069]. 
=============================================
[2019-04-07 17:50:26,873] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9056104e-21 2.9268390e-19 1.9947250e-22 7.0438747e-18 3.1522695e-19
 1.0000000e+00 2.0210808e-15 5.1617311e-18], sum to 1.0000
[2019-04-07 17:50:26,874] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7751
[2019-04-07 17:50:26,950] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 24.0, 23.43087863827383, -0.08790070289969859, 0.0, 1.0, 42518.69661817197], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4845600.0000, 
sim time next is 4847400.0000, 
raw observation next is [-2.5, 60.0, 0.0, 0.0, 24.0, 23.40408789393516, -0.09439776176247454, 0.0, 1.0, 46372.28443412539], 
processed observation next is [0.0, 0.08695652173913043, 0.39335180055401664, 0.6, 0.0, 0.0, 0.5, 0.4503406578279299, 0.4685340794125085, 0.0, 1.0, 0.22082040206726375], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.80327046], dtype=float32), 1.2881304]. 
=============================================
[2019-04-07 17:50:28,574] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.20970164e-20 1.31193275e-19 7.85370038e-24 1.90487287e-18
 1.19609696e-19 1.00000000e+00 1.26867398e-15 2.58927358e-16], sum to 1.0000
[2019-04-07 17:50:28,574] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0679
[2019-04-07 17:50:28,589] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 24.0, 23.85087779218934, 0.04087156776035959, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4559400.0000, 
sim time next is 4561200.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 24.0, 23.54893940295428, 0.009082108177908077, 1.0, 1.0, 22038.148172836096], 
processed observation next is [1.0, 0.8260869565217391, 0.518005540166205, 0.52, 0.0, 0.0, 0.5, 0.46241161691285654, 0.503027369392636, 1.0, 1.0, 0.10494356272779093], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5196092], dtype=float32), -0.75740206]. 
=============================================
[2019-04-07 17:50:34,404] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7620747e-19 1.3831066e-17 1.0358524e-23 2.0595879e-18 9.9035977e-19
 1.0000000e+00 4.3155282e-14 2.1882350e-17], sum to 1.0000
[2019-04-07 17:50:34,404] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9339
[2019-04-07 17:50:34,465] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 62.0, 188.0, 223.0, 24.0, 24.04807995789442, -0.03644783183256826, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2631600.0000, 
sim time next is 2633400.0000, 
raw observation next is [-3.1, 58.0, 224.0, 171.0, 24.0, 24.02539004409099, -0.04170633549726566, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.37673130193905824, 0.58, 0.7466666666666667, 0.18895027624309393, 0.5, 0.5021158370075826, 0.4860978881675781, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.41999808], dtype=float32), 0.18950142]. 
=============================================
[2019-04-07 17:50:38,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:50:38,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:50:38,544] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run39
[2019-04-07 17:50:38,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:50:38,702] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:50:38,763] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run39
[2019-04-07 17:50:39,812] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.3845175e-23 1.7686879e-19 9.0799152e-25 3.3432179e-19 1.3130179e-21
 1.0000000e+00 1.2031375e-15 3.5142925e-18], sum to 1.0000
[2019-04-07 17:50:39,812] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7926
[2019-04-07 17:50:39,870] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.5, 25.0, 117.0, 860.0, 24.0, 25.60646727125017, 0.3862138125045506, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4973400.0000, 
sim time next is 4975200.0000, 
raw observation next is [8.0, 26.0, 113.0, 839.5, 24.0, 25.80349602391754, 0.4734891214096524, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.6842105263157896, 0.26, 0.37666666666666665, 0.9276243093922651, 0.5, 0.6502913353264616, 0.6578297071365508, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05940662], dtype=float32), -0.2781592]. 
=============================================
[2019-04-07 17:50:45,723] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:50:45,723] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:50:45,727] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run39
[2019-04-07 17:50:47,611] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:50:47,611] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:50:47,614] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run39
[2019-04-07 17:50:51,675] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5070702e-23 8.4860219e-22 2.2846917e-26 2.5961521e-20 1.0452484e-22
 1.0000000e+00 2.1421811e-17 1.3758381e-19], sum to 1.0000
[2019-04-07 17:50:51,676] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2172
[2019-04-07 17:50:51,742] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.2, 94.0, 0.0, 0.0, 24.0, 23.53039086267809, 0.007163942698893829, 0.0, 1.0, 24773.71597038143], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1479600.0000, 
sim time next is 1481400.0000, 
raw observation next is [2.2, 95.0, 0.0, 0.0, 24.0, 23.55481266233096, 0.03715990927240905, 0.0, 1.0, 51436.45873840485], 
processed observation next is [1.0, 0.13043478260869565, 0.5235457063711911, 0.95, 0.0, 0.0, 0.5, 0.4629010551942467, 0.5123866364241364, 0.0, 1.0, 0.24493551780192785], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.22446588], dtype=float32), -1.0561956]. 
=============================================
[2019-04-07 17:50:52,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:50:52,998] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:50:53,030] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run39
[2019-04-07 17:51:04,626] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.5369068e-22 1.5925031e-19 4.7046741e-24 2.5196110e-19 1.9775362e-20
 1.0000000e+00 4.8299716e-15 2.5854822e-17], sum to 1.0000
[2019-04-07 17:51:04,626] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4737
[2019-04-07 17:51:04,689] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 24.0, 23.38257513681543, -0.01446101872409449, 0.0, 1.0, 82423.8694593531], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3366000.0000, 
sim time next is 3367800.0000, 
raw observation next is [-5.5, 74.0, 0.0, 0.0, 24.0, 23.41976535583642, -0.01927382959563523, 0.0, 1.0, 35949.00201233016], 
processed observation next is [1.0, 1.0, 0.3102493074792244, 0.74, 0.0, 0.0, 0.5, 0.45164711298636845, 0.4935753901347883, 0.0, 1.0, 0.17118572386823885], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8337617], dtype=float32), -0.5836732]. 
=============================================
[2019-04-07 17:51:05,105] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-07 17:51:05,112] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:51:05,113] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:51:05,126] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:51:05,126] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:51:05,138] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run87
[2019-04-07 17:51:05,152] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 17:51:05,154] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:51:05,158] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run87
[2019-04-07 17:51:05,173] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run87
[2019-04-07 17:53:27,370] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:53:49,006] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:53:51,692] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 17:53:52,715] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 1720000, evaluation results [1720000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:54:05,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:54:05,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:54:05,528] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run39
[2019-04-07 17:54:10,111] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6715945e-24 1.0369921e-21 1.3237266e-26 3.6542264e-20 2.8049660e-22
 1.0000000e+00 5.3304015e-17 1.8892201e-18], sum to 1.0000
[2019-04-07 17:54:10,111] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3255
[2019-04-07 17:54:10,146] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 24.0, 23.45382567430192, -0.02842721075777599, 0.0, 1.0, 37787.95731980281], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3474000.0000, 
sim time next is 3475800.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 24.0, 23.49660606939261, -0.02037916139342633, 0.0, 1.0, 29649.821757389447], 
processed observation next is [1.0, 0.21739130434782608, 0.46260387811634357, 0.72, 0.0, 0.0, 0.5, 0.4580505057827174, 0.49320694620219124, 0.0, 1.0, 0.14118962741614022], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.11078653], dtype=float32), 0.1941004]. 
=============================================
[2019-04-07 17:54:21,838] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3314582e-21 9.5143141e-20 7.0016558e-25 9.1597494e-19 8.3800618e-21
 1.0000000e+00 3.0762714e-15 4.7699823e-17], sum to 1.0000
[2019-04-07 17:54:21,839] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8139
[2019-04-07 17:54:21,877] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.15, 94.0, 0.0, 0.0, 24.0, 23.27407418323507, -0.1503244611216039, 0.0, 1.0, 43841.53579732953], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 509400.0000, 
sim time next is 511200.0000, 
raw observation next is [2.7, 92.0, 0.0, 0.0, 24.0, 23.34195971914093, -0.1386444461369805, 0.0, 1.0, 42945.58772004904], 
processed observation next is [1.0, 0.9565217391304348, 0.5373961218836566, 0.92, 0.0, 0.0, 0.5, 0.4451633099284109, 0.45378518462100653, 0.0, 1.0, 0.20450279866690022], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.23096517], dtype=float32), -0.34173784]. 
=============================================
[2019-04-07 17:54:37,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:54:37,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:54:37,293] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run39
[2019-04-07 17:54:37,616] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.1564500e-21 3.7891554e-20 9.1358179e-25 1.1082954e-19 4.1616684e-20
 1.0000000e+00 4.0584715e-15 8.7515080e-18], sum to 1.0000
[2019-04-07 17:54:37,616] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9023
[2019-04-07 17:54:37,704] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 83.0, 0.0, 0.0, 24.0, 23.244762368946, -0.124818085280961, 0.0, 1.0, 43509.00704533084], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 856800.0000, 
sim time next is 858600.0000, 
raw observation next is [-3.1, 81.0, 0.0, 0.0, 24.0, 23.25461925235111, -0.1308756468600325, 0.0, 1.0, 43106.90912377633], 
processed observation next is [1.0, 0.9565217391304348, 0.37673130193905824, 0.81, 0.0, 0.0, 0.5, 0.43788493769592574, 0.4563747843799892, 0.0, 1.0, 0.20527099582750633], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3030668], dtype=float32), 0.9291394]. 
=============================================
[2019-04-07 17:55:01,690] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:55:01,691] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:55:01,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run39
[2019-04-07 17:55:09,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:55:09,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:55:09,733] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run39
[2019-04-07 17:55:10,318] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:55:10,319] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:55:10,323] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run39
[2019-04-07 17:55:19,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:55:19,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:55:19,162] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run39
[2019-04-07 17:55:21,473] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:55:21,473] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:55:21,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run39
[2019-04-07 17:55:27,837] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.4031464e-20 6.8913384e-19 3.2667128e-23 1.2062613e-17 1.8197566e-20
 1.0000000e+00 1.8071062e-14 9.3540396e-17], sum to 1.0000
[2019-04-07 17:55:27,838] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1882
[2019-04-07 17:55:28,018] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 71.0, 0.0, 0.0, 24.0, 23.46362533256185, -0.02622657789941994, 1.0, 1.0, 103258.8203528324], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 147600.0000, 
sim time next is 149400.0000, 
raw observation next is [-7.3, 66.0, 0.0, 0.0, 24.0, 24.03172284014539, -0.03949193154156055, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.26038781163434904, 0.66, 0.0, 0.0, 0.5, 0.502643570012116, 0.48683602281947985, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16396806], dtype=float32), -1.727545]. 
=============================================
[2019-04-07 17:55:30,909] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8761301e-23 3.9367460e-21 1.3093639e-25 4.1029523e-19 5.0844320e-21
 1.0000000e+00 4.5314029e-16 1.8722088e-19], sum to 1.0000
[2019-04-07 17:55:30,909] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2796
[2019-04-07 17:55:31,088] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 85.0, 0.0, 0.0, 24.0, 23.08519872300671, -0.07501495488719763, 1.0, 1.0, 58031.080910722514], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2921400.0000, 
sim time next is 2923200.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 24.0, 23.03047403451121, -0.05900963563435459, 0.0, 1.0, 62084.272960692935], 
processed observation next is [1.0, 0.8695652173913043, 0.4349030470914128, 0.78, 0.0, 0.0, 0.5, 0.419206169542601, 0.48033012145521514, 0.0, 1.0, 0.29563939505091874], 
reward next is 0.9901, 
noisyNet noise sample is [array([0.36577058], dtype=float32), 0.10350178]. 
=============================================
[2019-04-07 17:55:32,738] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1535175e-20 6.1380575e-19 7.3993777e-23 1.2210251e-17 2.9613056e-19
 1.0000000e+00 2.0338807e-15 1.9950346e-17], sum to 1.0000
[2019-04-07 17:55:32,738] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6332
[2019-04-07 17:55:32,894] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 75.0, 151.5, 0.0, 24.0, 23.81127586652951, -0.1085397937254431, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2030400.0000, 
sim time next is 2032200.0000, 
raw observation next is [-4.5, 77.0, 156.0, 0.0, 24.0, 23.54664131067668, -0.1565584338319133, 1.0, 1.0, 51591.84316888807], 
processed observation next is [1.0, 0.5217391304347826, 0.3379501385041552, 0.77, 0.52, 0.0, 0.5, 0.4622201092230567, 0.44781385538936225, 1.0, 1.0, 0.24567544366137176], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.10635814], dtype=float32), 1.2561549]. 
=============================================
[2019-04-07 17:55:52,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:55:52,321] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:55:52,330] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run40
[2019-04-07 17:56:01,423] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-07 17:56:01,424] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:56:01,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:56:01,431] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run88
[2019-04-07 17:56:01,453] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 17:56:01,466] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:56:01,461] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 17:56:01,469] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:56:01,471] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run88
[2019-04-07 17:56:01,497] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run88
[2019-04-07 17:58:24,767] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 17:58:45,807] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 17:58:48,399] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 17:58:49,424] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1740000, evaluation results [1740000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 17:58:57,281] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.02716348e-24 6.11495792e-22 1.58069015e-25 9.45508605e-20
 2.48396401e-21 1.00000000e+00 3.94366999e-16 1.24796836e-20], sum to 1.0000
[2019-04-07 17:58:57,281] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8256
[2019-04-07 17:58:57,327] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 24.0, 23.53312280804241, 0.03925824074478144, 0.0, 1.0, 10945.928454832712], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1398600.0000, 
sim time next is 1400400.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 24.0, 23.45194528219655, 0.007704701142957622, 0.0, 1.0, 35211.45625448536], 
processed observation next is [1.0, 0.21739130434782608, 0.44598337950138506, 1.0, 0.0, 0.0, 0.5, 0.45432877351637924, 0.5025682337143192, 0.0, 1.0, 0.16767360121183505], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.96661586], dtype=float32), 0.9068315]. 
=============================================
[2019-04-07 17:59:06,045] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.9057287e-20 1.6488140e-17 1.6407722e-22 1.0000567e-16 1.0581411e-17
 1.0000000e+00 6.0067823e-14 2.9654915e-17], sum to 1.0000
[2019-04-07 17:59:06,046] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1174
[2019-04-07 17:59:06,138] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 71.0, 0.0, 0.0, 24.0, 22.67159406372972, -0.2977738578943607, 0.0, 1.0, 42483.32072613529], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 795600.0000, 
sim time next is 797400.0000, 
raw observation next is [-7.3, 71.0, 0.0, 0.0, 24.0, 22.51950450585866, -0.3225540759891898, 0.0, 1.0, 42742.88449407965], 
processed observation next is [1.0, 0.21739130434782608, 0.26038781163434904, 0.71, 0.0, 0.0, 0.5, 0.3766253754882216, 0.3924819746702701, 0.0, 1.0, 0.20353754520990308], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.66940033], dtype=float32), -0.2069096]. 
=============================================
[2019-04-07 17:59:07,280] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.0865114e-21 1.4093680e-19 1.9202476e-23 1.7037953e-18 4.3006587e-20
 1.0000000e+00 1.7884893e-15 2.2220662e-18], sum to 1.0000
[2019-04-07 17:59:07,280] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2258
[2019-04-07 17:59:07,432] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 75.0, 46.5, 0.0, 24.0, 24.22328555258376, -0.06056005685288266, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 810000.0000, 
sim time next is 811800.0000, 
raw observation next is [-6.2, 75.0, 61.0, 0.0, 24.0, 24.19357576682481, -0.05860752609792206, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.2908587257617729, 0.75, 0.20333333333333334, 0.0, 0.5, 0.5161313139020676, 0.48046415796735936, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.95242006], dtype=float32), 0.71287024]. 
=============================================
[2019-04-07 17:59:15,506] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4859464e-20 3.5222090e-19 6.9825916e-23 3.7476887e-17 2.3555971e-19
 1.0000000e+00 2.1611365e-14 3.2718628e-16], sum to 1.0000
[2019-04-07 17:59:15,540] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0269
[2019-04-07 17:59:15,807] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-15.0, 83.0, 40.0, 165.0, 24.0, 23.5239874499083, -0.103222854671568, 1.0, 1.0, 58721.17952797026], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2707200.0000, 
sim time next is 2709000.0000, 
raw observation next is [-14.5, 87.0, 80.0, 330.0, 24.0, 24.06863276610724, -0.007745041285564205, 1.0, 1.0, 9290.7203812737], 
processed observation next is [1.0, 0.34782608695652173, 0.06094182825484763, 0.87, 0.26666666666666666, 0.36464088397790057, 0.5, 0.5057193971756032, 0.4974183195714786, 1.0, 1.0, 0.04424152562511286], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2444683], dtype=float32), -0.8872411]. 
=============================================
[2019-04-07 17:59:15,813] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[88.4141  ]
 [86.79225 ]
 [85.075645]
 [85.6306  ]
 [86.45083 ]], R is [[90.30036926]
 [90.39736938]
 [90.06494141]
 [90.16429138]
 [90.26264954]].
[2019-04-07 17:59:21,211] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0238445e-20 1.1406409e-18 2.6091056e-22 2.0056258e-17 3.5101239e-19
 1.0000000e+00 1.2165119e-15 1.5562155e-15], sum to 1.0000
[2019-04-07 17:59:21,211] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0791
[2019-04-07 17:59:21,255] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 40.0, 200.5, 379.0, 24.0, 23.29977609091807, -0.0326401971994448, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4197600.0000, 
sim time next is 4199400.0000, 
raw observation next is [2.0, 42.0, 187.0, 89.0, 24.0, 23.25856766070465, -0.0737403129237212, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.518005540166205, 0.42, 0.6233333333333333, 0.09834254143646409, 0.5, 0.43821397172538745, 0.4754198956920929, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5044091], dtype=float32), 1.2080743]. 
=============================================
[2019-04-07 17:59:31,213] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4642350e-24 1.7263508e-21 4.7311047e-27 6.0630243e-21 1.1374617e-23
 1.0000000e+00 6.2460109e-16 3.1833484e-20], sum to 1.0000
[2019-04-07 17:59:31,213] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5224
[2019-04-07 17:59:31,269] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 78.0, 0.0, 0.0, 24.0, 23.69167111814352, 0.1117869546597689, 0.0, 1.0, 55171.79594043067], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1044000.0000, 
sim time next is 1045800.0000, 
raw observation next is [14.1, 77.5, 0.0, 0.0, 24.0, 23.8516501155399, 0.1213994822486622, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.8531855955678671, 0.775, 0.0, 0.0, 0.5, 0.487637509628325, 0.5404664940828874, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2762463], dtype=float32), 0.7226337]. 
=============================================
[2019-04-07 17:59:31,722] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 17:59:31,722] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 17:59:31,726] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run40
[2019-04-07 17:59:32,449] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8019325e-24 2.1363734e-22 2.2002941e-27 1.8143213e-21 2.1937540e-22
 1.0000000e+00 3.4825191e-17 6.9281314e-20], sum to 1.0000
[2019-04-07 17:59:32,450] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7242
[2019-04-07 17:59:32,514] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 49.0, 160.5, 0.0, 24.0, 25.49634097619905, 0.4083129342531143, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1605600.0000, 
sim time next is 1607400.0000, 
raw observation next is [13.8, 49.0, 145.0, 0.0, 24.0, 25.60470790582042, 0.3274439130572067, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.844875346260388, 0.49, 0.48333333333333334, 0.0, 0.5, 0.6337256588183683, 0.6091479710190689, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5144243], dtype=float32), -0.96683526]. 
=============================================
[2019-04-07 17:59:48,002] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.1472657e-23 1.9504899e-20 4.5092931e-25 1.1946064e-18 2.5670024e-20
 1.0000000e+00 1.0315107e-16 1.4363229e-17], sum to 1.0000
[2019-04-07 17:59:48,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2462
[2019-04-07 17:59:48,086] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 45.0, 0.0, 0.0, 24.0, 23.18432387544205, -0.0518837748524126, 0.0, 1.0, 145302.92592218707], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4822200.0000, 
sim time next is 4824000.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 24.0, 23.65062803152453, 0.02834580914021587, 0.0, 1.0, 52577.6234917276], 
processed observation next is [0.0, 0.8695652173913043, 0.4903047091412743, 0.47, 0.0, 0.0, 0.5, 0.47088566929371084, 0.5094486030467386, 0.0, 1.0, 0.25036963567489334], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.28602424], dtype=float32), 1.5899906]. 
=============================================
[2019-04-07 17:59:48,098] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[92.34801 ]
 [91.015884]
 [90.62253 ]
 [90.94593 ]
 [91.27385 ]], R is [[93.04103088]
 [92.70441437]
 [92.77737427]
 [92.84960175]
 [92.92110443]].
[2019-04-07 17:59:53,444] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5118767e-20 4.4030369e-18 1.7324333e-21 2.1589000e-17 5.7114857e-19
 1.0000000e+00 6.8162544e-14 6.8990294e-16], sum to 1.0000
[2019-04-07 17:59:53,444] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6805
[2019-04-07 17:59:53,535] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 24.0, 43.5, 370.5, 24.0, 25.27665482507669, 0.1600377140250132, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4035600.0000, 
sim time next is 4037400.0000, 
raw observation next is [-2.5, 25.0, 20.0, 193.0, 24.0, 24.85180371198848, 0.1857443223320734, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.39335180055401664, 0.25, 0.06666666666666667, 0.2132596685082873, 0.5, 0.5709836426657068, 0.5619147741106911, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.10758218], dtype=float32), -0.10900492]. 
=============================================
[2019-04-07 17:59:54,707] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.57335247e-23 3.65408348e-22 1.32876125e-25 2.18403591e-21
 3.54911121e-22 1.00000000e+00 1.69194351e-17 1.05617206e-19], sum to 1.0000
[2019-04-07 17:59:54,708] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7185
[2019-04-07 17:59:54,768] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.5, 29.0, 89.0, 403.0, 24.0, 23.7213409811301, -0.0109929753727267, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3659400.0000, 
sim time next is 3661200.0000, 
raw observation next is [11.0, 26.0, 95.0, 533.0, 24.0, 23.80082042781959, 0.02099349534565122, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.7673130193905818, 0.26, 0.31666666666666665, 0.5889502762430939, 0.5, 0.48340170231829926, 0.5069978317818837, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4559642], dtype=float32), 1.3942481]. 
=============================================
[2019-04-07 18:00:00,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:00:00,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:00:00,746] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run40
[2019-04-07 18:00:16,411] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6034969e-23 1.1161179e-21 2.0223120e-25 3.2449349e-19 3.9845319e-22
 1.0000000e+00 1.0014927e-15 1.9161391e-19], sum to 1.0000
[2019-04-07 18:00:16,422] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0037
[2019-04-07 18:00:16,457] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.3, 96.0, 80.5, 354.0, 24.0, 24.51705724059727, 0.1854334400112654, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1508400.0000, 
sim time next is 1510200.0000, 
raw observation next is [3.85, 94.5, 88.0, 708.0, 24.0, 24.76241579574049, 0.2579145859677494, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.569252077562327, 0.945, 0.29333333333333333, 0.7823204419889502, 0.5, 0.563534649645041, 0.5859715286559165, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3402127], dtype=float32), -0.48799777]. 
=============================================
[2019-04-07 18:00:18,675] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.7284283e-23 6.4623578e-21 6.8647354e-26 1.4554999e-18 1.8364575e-21
 1.0000000e+00 1.1224447e-15 1.6638056e-19], sum to 1.0000
[2019-04-07 18:00:18,675] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1985
[2019-04-07 18:00:18,742] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.65, 84.5, 0.0, 0.0, 24.0, 23.69455809078534, 0.0608007216438613, 0.0, 1.0, 10230.167599151444], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1571400.0000, 
sim time next is 1573200.0000, 
raw observation next is [4.7, 84.0, 0.0, 0.0, 24.0, 23.55406724727725, 0.08325801006342413, 0.0, 1.0, 67650.73097301733], 
processed observation next is [1.0, 0.21739130434782608, 0.592797783933518, 0.84, 0.0, 0.0, 0.5, 0.4628389372731041, 0.5277526700211413, 0.0, 1.0, 0.3221463379667492], 
reward next is 0.9636, 
noisyNet noise sample is [array([-1.2520803], dtype=float32), -2.3756156]. 
=============================================
[2019-04-07 18:00:20,082] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.7554417e-24 2.6452339e-22 2.0608831e-27 1.0099655e-19 1.6369836e-22
 1.0000000e+00 2.4044076e-16 2.2160127e-19], sum to 1.0000
[2019-04-07 18:00:20,083] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3346
[2019-04-07 18:00:20,142] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 24.0, 23.63159174496115, 0.05380656855731659, 0.0, 1.0, 29115.883962088832], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3454200.0000, 
sim time next is 3456000.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 24.0, 23.58493053683601, 0.02421845113759023, 0.0, 1.0, 12465.73857399192], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.86, 0.0, 0.0, 0.5, 0.46541087806966736, 0.5080728170458634, 0.0, 1.0, 0.059360659876151994], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.304035], dtype=float32), -0.5703509]. 
=============================================
[2019-04-07 18:00:20,146] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[104.744804]
 [104.891426]
 [103.97584 ]
 [104.34617 ]
 [104.193306]], R is [[104.42210388]
 [104.37788391]
 [104.09771729]
 [104.05673981]
 [104.01617432]].
[2019-04-07 18:00:22,065] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.5062367e-23 6.3072897e-21 6.1398388e-26 8.1805143e-19 6.5528133e-22
 1.0000000e+00 2.9008253e-14 9.6263237e-19], sum to 1.0000
[2019-04-07 18:00:22,065] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0055
[2019-04-07 18:00:22,131] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.5, 65.5, 99.0, 670.0, 24.0, 24.10488994744014, 0.1107768550736364, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3490200.0000, 
sim time next is 3492000.0000, 
raw observation next is [0.0, 60.0, 104.0, 720.0, 24.0, 24.54185498762416, 0.1790937761301329, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.46260387811634357, 0.6, 0.3466666666666667, 0.7955801104972375, 0.5, 0.5451545823020133, 0.559697925376711, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.08490653], dtype=float32), 0.18908864]. 
=============================================
[2019-04-07 18:00:22,157] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[100.88965 ]
 [101.01089 ]
 [100.97717 ]
 [100.67238 ]
 [100.390465]], R is [[100.55735779]
 [100.55178833]
 [100.54627228]
 [100.54080963]
 [100.53540039]].
[2019-04-07 18:00:27,898] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.9485999e-24 5.2333345e-22 9.8948333e-27 4.8979044e-20 1.9093067e-22
 1.0000000e+00 4.1414530e-16 4.4667117e-19], sum to 1.0000
[2019-04-07 18:00:27,899] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6672
[2019-04-07 18:00:27,933] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.5, 67.0, 0.0, 0.0, 24.0, 24.06080961020262, 0.1538680127140591, 0.0, 1.0, 15629.750137496105], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4420800.0000, 
sim time next is 4422600.0000, 
raw observation next is [4.15, 67.5, 0.0, 0.0, 24.0, 24.05968748486412, 0.1405066071968682, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5775623268698062, 0.675, 0.0, 0.0, 0.5, 0.5049739570720101, 0.5468355357322894, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.87610734], dtype=float32), 0.2244452]. 
=============================================
[2019-04-07 18:00:28,752] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7789363e-22 6.3747768e-21 1.6772072e-26 4.2244689e-18 2.0925124e-22
 1.0000000e+00 7.6914922e-16 6.7837992e-19], sum to 1.0000
[2019-04-07 18:00:28,759] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1538
[2019-04-07 18:00:28,785] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.65, 82.0, 120.0, 232.0, 24.0, 23.77323401000677, 0.1224541515645922, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4437000.0000, 
sim time next is 4438800.0000, 
raw observation next is [1.3, 84.0, 142.5, 131.5, 24.0, 24.37876688552415, 0.1591773162295694, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49861495844875353, 0.84, 0.475, 0.1453038674033149, 0.5, 0.5315639071270125, 0.5530591054098565, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.63934255], dtype=float32), 0.49270332]. 
=============================================
[2019-04-07 18:00:32,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4463133e-20 2.8648921e-18 5.5847283e-22 4.7624732e-17 5.4023538e-18
 1.0000000e+00 5.4195716e-13 1.2740331e-15], sum to 1.0000
[2019-04-07 18:00:32,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5951
[2019-04-07 18:00:32,475] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 24.0, 22.21763590225199, -0.3599407192220349, 0.0, 1.0, 47982.38653275673], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1841400.0000, 
sim time next is 1843200.0000, 
raw observation next is [-6.7, 78.0, 14.0, 0.0, 24.0, 22.15390429603796, -0.371546490216847, 0.0, 1.0, 47927.80078270364], 
processed observation next is [0.0, 0.34782608695652173, 0.2770083102493075, 0.78, 0.04666666666666667, 0.0, 0.5, 0.34615869133649674, 0.37615116992771763, 0.0, 1.0, 0.22822762277477926], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.08263697], dtype=float32), 0.35065243]. 
=============================================
[2019-04-07 18:00:38,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:00:38,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:00:38,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run40
[2019-04-07 18:00:49,617] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-07 18:00:49,628] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:00:49,628] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:00:49,638] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:00:49,638] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:00:49,642] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run89
[2019-04-07 18:00:49,671] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:00:49,673] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:00:49,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run89
[2019-04-07 18:00:49,702] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run89
[2019-04-07 18:00:58,378] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12515493], dtype=float32), 0.16831551]
[2019-04-07 18:00:58,378] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [8.3, 90.0, 0.0, 0.0, 24.0, 22.79746866310383, -0.1420392563998172, 1.0, 1.0, 88076.77610533382]
[2019-04-07 18:00:58,378] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 18:00:58,379] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [2.6668731e-24 7.3400349e-22 8.5444044e-27 1.7815461e-20 1.8811691e-22
 1.0000000e+00 6.0362202e-17 8.6206857e-20], sampled 0.34603828623517874
[2019-04-07 18:01:41,298] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12515493], dtype=float32), 0.16831551]
[2019-04-07 18:01:41,298] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [14.0, 64.0, 175.5, 343.5, 24.0, 23.69076875959002, 0.1889660479275102, 0.0, 1.0, 0.0]
[2019-04-07 18:01:41,298] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 18:01:41,299] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [5.8071453e-25 1.8200950e-22 2.0735873e-27 5.0698481e-21 3.6645789e-23
 1.0000000e+00 2.7167551e-17 2.6880926e-20], sampled 0.012050116086234408
[2019-04-07 18:03:07,850] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 18:03:25,958] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 18:03:29,171] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 18:03:30,195] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 1760000, evaluation results [1760000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 18:03:31,037] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1885636e-21 8.7772096e-20 1.8162091e-24 7.0198592e-20 1.9871843e-21
 1.0000000e+00 2.7924741e-15 8.4314706e-19], sum to 1.0000
[2019-04-07 18:03:31,037] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8500
[2019-04-07 18:03:31,133] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 80.0, 132.5, 531.0, 24.0, 23.12349837600605, -0.08580170502769409, 0.0, 1.0, 18708.03034560342], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 568800.0000, 
sim time next is 570600.0000, 
raw observation next is [-1.2, 81.5, 127.0, 467.0, 24.0, 23.12083209370496, -0.08288043091897622, 0.0, 1.0, 21330.345031704743], 
processed observation next is [0.0, 0.6086956521739131, 0.42936288088642666, 0.815, 0.42333333333333334, 0.5160220994475138, 0.5, 0.42673600780874654, 0.47237318969367464, 0.0, 1.0, 0.1015730715795464], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.491647], dtype=float32), 0.4055494]. 
=============================================
[2019-04-07 18:03:31,766] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2714669e-19 1.7298737e-18 1.4143370e-22 1.2077628e-16 1.9459585e-18
 1.0000000e+00 6.4744962e-14 5.2787035e-16], sum to 1.0000
[2019-04-07 18:03:31,769] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6936
[2019-04-07 18:03:31,896] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 56.0, 93.5, 25.5, 24.0, 23.86514448896148, -0.1317634509677651, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2538000.0000, 
sim time next is 2539800.0000, 
raw observation next is [-2.0, 52.5, 136.0, 33.0, 24.0, 23.99372538256477, -0.1039459056278945, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.40720221606648205, 0.525, 0.4533333333333333, 0.036464088397790057, 0.5, 0.4994771152137307, 0.4653513647907019, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.65182674], dtype=float32), 0.034597933]. 
=============================================
[2019-04-07 18:03:36,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6226794e-20 1.1893592e-18 1.4776783e-23 2.4506041e-17 8.2062327e-20
 1.0000000e+00 1.5577954e-15 2.2643211e-17], sum to 1.0000
[2019-04-07 18:03:36,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4750
[2019-04-07 18:03:36,502] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 56.0, 0.0, 0.0, 24.0, 23.67005323809885, 0.009117109036556154, 0.0, 1.0, 28531.909225434258], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2581200.0000, 
sim time next is 2583000.0000, 
raw observation next is [-2.8, 56.0, 0.0, 0.0, 24.0, 23.66598724777921, -0.01380138234871185, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.38504155124653744, 0.56, 0.0, 0.0, 0.5, 0.47216560398160085, 0.49539953921709606, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.39809895], dtype=float32), -1.1626757]. 
=============================================
[2019-04-07 18:03:36,505] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[92.456566]
 [92.213684]
 [91.34537 ]
 [91.52956 ]
 [92.39101 ]], R is [[92.60133362]
 [92.67532349]
 [92.4013443 ]
 [92.44654083]
 [92.52207947]].
[2019-04-07 18:03:36,762] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.18427744e-21 2.58051348e-19 4.51987164e-23 5.26815698e-18
 1.07296809e-19 1.00000000e+00 4.61762510e-15 1.31690305e-17], sum to 1.0000
[2019-04-07 18:03:36,763] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7760
[2019-04-07 18:03:36,905] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 60.0, 131.5, 74.5, 24.0, 23.04516933755869, -0.1928349710296634, 0.0, 1.0, 22076.14599531762], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 655200.0000, 
sim time next is 657000.0000, 
raw observation next is [-0.8999999999999999, 57.0, 81.0, 56.0, 24.0, 23.00837891745867, -0.2053908841534972, 0.0, 1.0, 37327.57524513524], 
processed observation next is [0.0, 0.6086956521739131, 0.43767313019390586, 0.57, 0.27, 0.061878453038674036, 0.5, 0.4173649097882226, 0.43153637194883426, 0.0, 1.0, 0.1777503583101678], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.43402523], dtype=float32), -0.95609117]. 
=============================================
[2019-04-07 18:03:36,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[91.2875 ]
 [91.81164]
 [91.58819]
 [91.45057]
 [91.38911]], R is [[91.07871246]
 [91.16792297]
 [91.25624084]
 [91.34368134]
 [91.43024445]].
[2019-04-07 18:03:38,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:03:38,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:03:38,544] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run40
[2019-04-07 18:03:40,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:03:40,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:03:40,664] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run40
[2019-04-07 18:03:45,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:03:45,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:03:45,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run40
[2019-04-07 18:03:48,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:03:48,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:03:48,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run40
[2019-04-07 18:03:49,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9169750e-24 6.7638918e-22 1.4365189e-26 1.7677705e-19 3.5586570e-21
 1.0000000e+00 8.9393852e-17 1.2365302e-18], sum to 1.0000
[2019-04-07 18:03:49,973] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5404
[2019-04-07 18:03:50,064] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.800000000000001, 83.0, 100.0, 700.0, 24.0, 24.46272944463656, 0.2066704830513791, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1513800.0000, 
sim time next is 1515600.0000, 
raw observation next is [7.2, 73.0, 92.5, 700.5, 24.0, 24.24732175748782, 0.2193762647015225, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.662049861495845, 0.73, 0.30833333333333335, 0.7740331491712708, 0.5, 0.5206101464573184, 0.5731254215671742, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.276927], dtype=float32), 0.7151173]. 
=============================================
[2019-04-07 18:03:52,603] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:03:52,603] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:03:52,607] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run40
[2019-04-07 18:03:58,464] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3460255e-23 8.4864194e-20 1.5589237e-24 1.0708949e-19 4.5011905e-21
 1.0000000e+00 1.8264018e-16 7.0107910e-19], sum to 1.0000
[2019-04-07 18:03:58,465] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7116
[2019-04-07 18:03:58,539] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 24.0, 23.48417802282731, 0.01537952052368152, 0.0, 1.0, 30375.456004818454], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1731600.0000, 
sim time next is 1733400.0000, 
raw observation next is [0.35, 91.5, 0.0, 0.0, 24.0, 23.42094333883396, 0.01385908614059086, 0.0, 1.0, 54236.07320438882], 
processed observation next is [0.0, 0.043478260869565216, 0.47229916897506935, 0.915, 0.0, 0.0, 0.5, 0.45174527823616345, 0.504619695380197, 0.0, 1.0, 0.25826701525899437], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.01621825], dtype=float32), -1.6268129]. 
=============================================
[2019-04-07 18:04:02,043] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.3570867e-21 2.6975429e-20 1.6986372e-24 7.9276163e-19 1.3175750e-19
 1.0000000e+00 1.1154019e-15 4.4669184e-18], sum to 1.0000
[2019-04-07 18:04:02,044] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1135
[2019-04-07 18:04:02,103] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.5, 57.5, 0.0, 0.0, 24.0, 23.54636233559431, -0.0526804552049508, 0.0, 1.0, 29638.981209876918], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4836600.0000, 
sim time next is 4838400.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 24.0, 23.58973198178835, -0.05740398368041468, 0.0, 1.0, 19491.242059150343], 
processed observation next is [0.0, 0.0, 0.40720221606648205, 0.6, 0.0, 0.0, 0.5, 0.46581099848236257, 0.4808653387731951, 0.0, 1.0, 0.0928154383769064], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.616263], dtype=float32), -0.8516255]. 
=============================================
[2019-04-07 18:04:13,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6866018e-23 1.3776749e-21 8.3953388e-25 1.7926180e-19 2.9050882e-22
 1.0000000e+00 3.6203096e-16 2.0078514e-19], sum to 1.0000
[2019-04-07 18:04:13,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7840
[2019-04-07 18:04:13,385] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 66.0, 0.0, 0.0, 24.0, 23.31460672896235, 0.06390055814658181, 0.0, 1.0, 172826.70171012584], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3538800.0000, 
sim time next is 3540600.0000, 
raw observation next is [-1.5, 63.0, 0.0, 0.0, 24.0, 23.6830575057227, 0.07125068543190688, 0.0, 1.0, 6251.7213142617065], 
processed observation next is [1.0, 1.0, 0.4210526315789474, 0.63, 0.0, 0.0, 0.5, 0.4735881254768917, 0.5237502284773022, 0.0, 1.0, 0.029770101496484316], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.41771963], dtype=float32), 1.5064759]. 
=============================================
[2019-04-07 18:04:13,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:04:13,574] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:04:13,577] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run40
[2019-04-07 18:04:34,437] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.1948024e-21 4.7967484e-18 3.5988322e-22 6.3921275e-17 6.7167205e-19
 1.0000000e+00 9.9323338e-15 2.0567704e-17], sum to 1.0000
[2019-04-07 18:04:34,438] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3383
[2019-04-07 18:04:34,494] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.5, 66.0, 0.0, 0.0, 24.0, 22.79231110507592, -0.23442825495603, 0.0, 1.0, 44742.75917090644], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3990600.0000, 
sim time next is 3992400.0000, 
raw observation next is [-13.0, 69.0, 0.0, 0.0, 24.0, 22.61718773518722, -0.2686980109553114, 0.0, 1.0, 44786.08956846624], 
processed observation next is [1.0, 0.21739130434782608, 0.10249307479224376, 0.69, 0.0, 0.0, 0.5, 0.3847656445989349, 0.4104339963482295, 0.0, 1.0, 0.21326709318317258], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.15077424], dtype=float32), -1.6369774]. 
=============================================
[2019-04-07 18:04:48,800] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:04:48,800] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:04:48,809] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run40
[2019-04-07 18:04:53,779] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.3027836e-23 1.3627260e-21 4.2239018e-27 3.9676849e-20 5.8990312e-22
 1.0000000e+00 6.1922291e-16 1.4075137e-20], sum to 1.0000
[2019-04-07 18:04:53,780] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6780
[2019-04-07 18:04:53,892] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.7, 94.0, 0.0, 0.0, 24.0, 23.61627057422769, -0.1297289899590786, 1.0, 1.0, 4447.7170643406], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 927000.0000, 
sim time next is 928800.0000, 
raw observation next is [4.4, 96.0, 0.0, 0.0, 24.0, 22.95705748922729, -0.1341621502275182, 1.0, 1.0, 93294.98051800636], 
processed observation next is [1.0, 0.782608695652174, 0.5844875346260389, 0.96, 0.0, 0.0, 0.5, 0.4130881241022741, 0.4552792832574939, 1.0, 1.0, 0.44426181199050646], 
reward next is 0.8415, 
noisyNet noise sample is [array([0.9473891], dtype=float32), 0.31648085]. 
=============================================
[2019-04-07 18:05:03,102] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5355511e-25 8.2599574e-23 6.9005366e-29 1.6741168e-22 5.8824891e-23
 1.0000000e+00 4.4120821e-18 6.9166670e-21], sum to 1.0000
[2019-04-07 18:05:03,103] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5380
[2019-04-07 18:05:03,137] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 24.0, 23.73007279837715, 0.06918740803858696, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1018800.0000, 
sim time next is 1020600.0000, 
raw observation next is [14.4, 79.0, 0.0, 0.0, 24.0, 23.48614518833727, 0.009052179468234445, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.8614958448753465, 0.79, 0.0, 0.0, 0.5, 0.4571787656947726, 0.5030173931560782, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3425115], dtype=float32), 1.2798206]. 
=============================================
[2019-04-07 18:05:11,260] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.6574339e-24 2.9021432e-21 1.5602310e-26 3.9300407e-20 2.0733405e-21
 1.0000000e+00 4.5459814e-16 5.4566153e-19], sum to 1.0000
[2019-04-07 18:05:11,260] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3466
[2019-04-07 18:05:11,318] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [17.75, 66.0, 130.0, 0.0, 24.0, 23.60393912457155, 0.116083094661498, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1161000.0000, 
sim time next is 1162800.0000, 
raw observation next is [18.3, 65.0, 145.0, 0.0, 24.0, 23.57778193398431, 0.1182630543638772, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.9695290858725764, 0.65, 0.48333333333333334, 0.0, 0.5, 0.46481516116535904, 0.5394210181212924, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7847294], dtype=float32), 0.6103203]. 
=============================================
[2019-04-07 18:05:11,630] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.5811827e-20 5.2166595e-19 1.5172853e-24 1.4428130e-18 3.3811046e-19
 1.0000000e+00 3.4134975e-15 1.2074858e-17], sum to 1.0000
[2019-04-07 18:05:11,632] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3981
[2019-04-07 18:05:11,810] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 65.0, 141.0, 0.0, 24.0, 23.78711745744437, -0.1411336704134757, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 216000.0000, 
sim time next is 217800.0000, 
raw observation next is [-4.75, 65.0, 129.0, 0.0, 24.0, 22.95446375979964, -0.1812351537085542, 1.0, 1.0, 108247.69128613318], 
processed observation next is [1.0, 0.5217391304347826, 0.3310249307479225, 0.65, 0.43, 0.0, 0.5, 0.4128719799833034, 0.4395882820971486, 1.0, 1.0, 0.5154651966006342], 
reward next is 0.7702, 
noisyNet noise sample is [array([0.32391793], dtype=float32), -0.14312048]. 
=============================================
[2019-04-07 18:05:14,855] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:05:14,855] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:05:14,858] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run40
[2019-04-07 18:05:22,586] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:05:22,586] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:05:22,591] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run40
[2019-04-07 18:05:22,694] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:05:22,695] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:05:22,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run40
[2019-04-07 18:05:32,908] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-07 18:05:32,912] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:05:32,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:05:32,918] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:05:32,918] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:05:32,918] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:05:32,919] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:05:32,922] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run90
[2019-04-07 18:05:32,946] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run90
[2019-04-07 18:05:32,970] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run90
[2019-04-07 18:05:53,265] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.12494717], dtype=float32), 0.16852792]
[2019-04-07 18:05:53,266] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [1.1939489745, 82.27130825, 174.1627349, 646.8909292, 24.0, 23.05390046477986, -0.111000334859762, 0.0, 1.0, 6234.1283345979455]
[2019-04-07 18:05:53,266] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 18:05:53,267] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [1.2023395e-22 1.6412685e-20 5.7820566e-25 3.6919475e-19 4.4938130e-21
 1.0000000e+00 1.0908154e-15 1.6000853e-18], sampled 0.0508190344233056
[2019-04-07 18:06:37,104] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12494717], dtype=float32), 0.16852792]
[2019-04-07 18:06:37,105] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [3.9, 86.0, 0.0, 0.0, 24.0, 23.48485381767308, 0.05295652958308426, 0.0, 1.0, 82401.2533516914]
[2019-04-07 18:06:37,105] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 18:06:37,106] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [6.4970770e-24 1.0717111e-21 1.7381085e-26 2.9061107e-20 3.4991159e-22
 1.0000000e+00 1.0228433e-16 1.3285524e-19], sampled 0.9983950179471366
[2019-04-07 18:07:55,414] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 18:08:17,077] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 18:08:22,473] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 18:08:23,497] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1780000, evaluation results [1780000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 18:08:25,616] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:08:25,616] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:08:25,619] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run40
[2019-04-07 18:08:27,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:08:27,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:08:27,744] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run40
[2019-04-07 18:08:30,571] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6688998e-23 2.0409570e-19 1.1525298e-24 1.6360006e-18 3.3935965e-21
 1.0000000e+00 3.2416629e-15 6.0220465e-19], sum to 1.0000
[2019-04-07 18:08:30,571] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6039
[2019-04-07 18:08:30,651] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 56.0, 129.0, 767.0, 24.0, 25.26681837194482, 0.3226525669655335, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4617000.0000, 
sim time next is 4618800.0000, 
raw observation next is [2.0, 52.0, 125.5, 800.0, 24.0, 25.38825155976026, 0.2255330771819329, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.518005540166205, 0.52, 0.41833333333333333, 0.8839779005524862, 0.5, 0.6156876299800217, 0.5751776923939776, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0150662], dtype=float32), -0.8134498]. 
=============================================
[2019-04-07 18:08:30,676] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2048866e-21 3.0463712e-18 3.5243003e-22 5.1813259e-16 1.1652336e-19
 1.0000000e+00 1.8673634e-14 7.1171010e-17], sum to 1.0000
[2019-04-07 18:08:30,676] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6167
[2019-04-07 18:08:30,894] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 24.0, 23.42335401299858, -0.1329282747533721, 1.0, 1.0, 65573.3388538959], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 234000.0000, 
sim time next is 235800.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 24.0, 23.66570872305907, -0.2165194267953542, 1.0, 1.0, 26659.566164876054], 
processed observation next is [1.0, 0.7391304347826086, 0.368421052631579, 0.65, 0.0, 0.0, 0.5, 0.47214239358825577, 0.427826857734882, 1.0, 1.0, 0.12695031507083834], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0662902], dtype=float32), -0.12494249]. 
=============================================
[2019-04-07 18:08:39,641] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.2701162e-21 1.9976445e-19 7.3915028e-24 3.1775174e-17 1.0129326e-19
 1.0000000e+00 7.7503134e-15 1.7607319e-18], sum to 1.0000
[2019-04-07 18:08:39,641] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3773
[2019-04-07 18:08:39,896] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 71.0, 0.0, 0.0, 24.0, 23.6266689530615, -0.06706285007669836, 1.0, 1.0, 24972.18937642981], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1969200.0000, 
sim time next is 1971000.0000, 
raw observation next is [-5.05, 77.0, 0.0, 0.0, 24.0, 23.44100895665624, -0.0924917948168611, 1.0, 1.0, 40475.509127273224], 
processed observation next is [1.0, 0.8260869565217391, 0.32271468144044324, 0.77, 0.0, 0.0, 0.5, 0.4534174130546867, 0.469169401727713, 1.0, 1.0, 0.19274051965368202], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.505403], dtype=float32), -1.2061758]. 
=============================================
[2019-04-07 18:08:39,924] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[96.45747]
 [96.61798]
 [96.68967]
 [95.70224]
 [94.6844 ]], R is [[96.41699219]
 [96.45281982]
 [96.48828888]
 [96.50582123]
 [96.29447174]].
[2019-04-07 18:08:52,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:08:52,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:08:52,040] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run41
[2019-04-07 18:09:05,155] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2427237e-20 1.1112302e-17 8.7466467e-23 3.9481840e-17 5.6056938e-20
 1.0000000e+00 2.0914425e-15 1.0446497e-16], sum to 1.0000
[2019-04-07 18:09:05,155] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8850
[2019-04-07 18:09:05,235] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.3, 46.5, 41.0, 0.0, 24.0, 23.44274524790061, -0.1225748263874524, 1.0, 1.0, 25826.156457601242], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2305800.0000, 
sim time next is 2307600.0000, 
raw observation next is [-0.6, 49.0, 23.0, 0.0, 24.0, 23.74314952539801, -0.06882896382687605, 1.0, 1.0, 26814.84389604366], 
processed observation next is [1.0, 0.7391304347826086, 0.44598337950138506, 0.49, 0.07666666666666666, 0.0, 0.5, 0.4785957937831675, 0.477057012057708, 1.0, 1.0, 0.12768973283830315], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1663993], dtype=float32), 0.2569541]. 
=============================================
[2019-04-07 18:09:29,075] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.1083450e-21 1.5310923e-19 7.8832054e-24 1.3863765e-17 1.4413648e-20
 1.0000000e+00 8.5963039e-16 6.8223408e-18], sum to 1.0000
[2019-04-07 18:09:29,075] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3566
[2019-04-07 18:09:29,132] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 79.0, 0.0, 0.0, 24.0, 23.38572384236971, -0.1380504995941051, 0.0, 1.0, 34400.70121050938], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 873000.0000, 
sim time next is 874800.0000, 
raw observation next is [-1.7, 79.0, 0.0, 0.0, 24.0, 23.27427593485051, -0.1454946104449931, 0.0, 1.0, 45578.06195997237], 
processed observation next is [1.0, 0.13043478260869565, 0.4155124653739613, 0.79, 0.0, 0.0, 0.5, 0.4395229945708759, 0.45150179651833566, 0.0, 1.0, 0.21703839028558272], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.21547699], dtype=float32), 0.006958598]. 
=============================================
[2019-04-07 18:09:32,894] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1072933e-20 1.1104241e-19 1.4618785e-23 6.3635163e-17 1.0230373e-18
 1.0000000e+00 3.3629824e-14 1.3271455e-17], sum to 1.0000
[2019-04-07 18:09:32,894] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7273
[2019-04-07 18:09:33,043] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.5, 27.0, 118.0, 0.0, 24.0, 23.65796786003804, -0.1023142372479352, 1.0, 1.0, 12453.607780153689], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2817000.0000, 
sim time next is 2818800.0000, 
raw observation next is [7.0, 24.0, 106.5, 0.0, 24.0, 23.72240975479113, -0.07384127141280113, 1.0, 1.0, 9340.205835115268], 
processed observation next is [1.0, 0.6521739130434783, 0.6565096952908588, 0.24, 0.355, 0.0, 0.5, 0.4768674795659275, 0.4753862428623996, 1.0, 1.0, 0.04447717064340604], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.21269095], dtype=float32), 0.82414263]. 
=============================================
[2019-04-07 18:09:33,527] A3C_AGENT_WORKER-Thread-3 INFO:Local step 113500, global step 1789740: loss 2.2812
[2019-04-07 18:09:33,528] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 113500, global step 1789740: learning rate 0.0000
[2019-04-07 18:09:45,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:09:45,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:09:45,009] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run41
[2019-04-07 18:09:51,843] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.6084515e-20 1.3487439e-18 1.8943318e-23 2.3044843e-17 1.1224595e-19
 1.0000000e+00 1.2809152e-13 1.2233101e-16], sum to 1.0000
[2019-04-07 18:09:51,843] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5699
[2019-04-07 18:09:52,040] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 52.5, 11.0, 133.0, 24.0, 23.81659701550019, -0.007227520589133202, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3346200.0000, 
sim time next is 3348000.0000, 
raw observation next is [-3.0, 55.0, 0.0, 0.0, 24.0, 23.3501715150634, 0.1141217095621559, 1.0, 1.0, 144231.02211229922], 
processed observation next is [1.0, 0.782608695652174, 0.3795013850415513, 0.55, 0.0, 0.0, 0.5, 0.44584762625528346, 0.5380405698540519, 1.0, 1.0, 0.6868143910109487], 
reward next is 0.5989, 
noisyNet noise sample is [array([-0.6976112], dtype=float32), 0.33008602]. 
=============================================
[2019-04-07 18:09:52,054] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[92.2012 ]
 [93.04025]
 [93.17566]
 [93.39336]
 [93.43724]], R is [[92.95137024]
 [93.02185822]
 [93.09164429]
 [93.16072845]
 [93.22911835]].
[2019-04-07 18:09:56,594] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5918561e-21 2.4072031e-19 4.0224349e-23 4.6415656e-18 2.3539353e-19
 1.0000000e+00 7.8125862e-16 1.3238841e-17], sum to 1.0000
[2019-04-07 18:09:56,596] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5846
[2019-04-07 18:09:56,651] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.5, 74.0, 0.0, 0.0, 24.0, 23.11096445565462, -0.1804546697317577, 0.0, 1.0, 39952.95220567385], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3033000.0000, 
sim time next is 3034800.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 24.0, 23.01755094446171, -0.2005295473985785, 0.0, 1.0, 40312.220762523786], 
processed observation next is [0.0, 0.13043478260869565, 0.296398891966759, 0.77, 0.0, 0.0, 0.5, 0.41812924537180923, 0.4331568175338072, 0.0, 1.0, 0.19196295601201802], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3052416], dtype=float32), 0.3975457]. 
=============================================
[2019-04-07 18:10:10,511] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:10:10,512] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:10:10,536] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run41
[2019-04-07 18:10:19,853] A3C_AGENT_WORKER-Thread-3 INFO:Local step 114000, global step 1797964: loss 1.2047
[2019-04-07 18:10:19,854] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 114000, global step 1797964: learning rate 0.0000
[2019-04-07 18:10:20,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8415671e-19 6.5527554e-17 8.3847256e-22 1.1387118e-16 1.9763325e-17
 1.0000000e+00 6.2255035e-13 2.7351308e-16], sum to 1.0000
[2019-04-07 18:10:20,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0342
[2019-04-07 18:10:20,276] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-15.05, 78.0, 39.0, 738.0, 24.0, 24.0034258020526, -0.1018350316805518, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 379800.0000, 
sim time next is 381600.0000, 
raw observation next is [-14.5, 66.0, 55.0, 733.5, 24.0, 23.96587580860119, -0.1074447046277416, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.06094182825484763, 0.66, 0.18333333333333332, 0.8104972375690608, 0.5, 0.4971563173834325, 0.46418509845741945, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1329182], dtype=float32), -0.66781044]. 
=============================================
[2019-04-07 18:10:21,948] A3C_AGENT_WORKER-Thread-18 INFO:Local step 113500, global step 1798300: loss 2.3153
[2019-04-07 18:10:21,948] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 113500, global step 1798300: learning rate 0.0000
[2019-04-07 18:10:24,003] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.6431158e-20 7.7909676e-19 1.8802149e-22 4.9475650e-16 1.3441983e-18
 1.0000000e+00 1.3006500e-13 6.8016335e-17], sum to 1.0000
[2019-04-07 18:10:24,003] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2887
[2019-04-07 18:10:24,223] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.75, 41.0, 0.0, 0.0, 24.0, 23.42347391523294, -0.1197785301536521, 1.0, 1.0, 60667.17313736575], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 415800.0000, 
sim time next is 417600.0000, 
raw observation next is [-10.0, 42.0, 0.0, 0.0, 24.0, 23.34412565878754, -0.1352676713896013, 0.0, 1.0, 54852.50122157626], 
processed observation next is [1.0, 0.8695652173913043, 0.18559556786703602, 0.42, 0.0, 0.0, 0.5, 0.4453438048989617, 0.45491077620346626, 0.0, 1.0, 0.26120238676941077], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1609435], dtype=float32), 0.81408834]. 
=============================================
[2019-04-07 18:10:32,628] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-07 18:10:32,628] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:10:32,629] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:10:32,630] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:10:32,631] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:10:32,631] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:10:32,635] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:10:32,642] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run91
[2019-04-07 18:10:32,666] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run91
[2019-04-07 18:10:32,692] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run91
[2019-04-07 18:12:39,445] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12494308], dtype=float32), 0.16889472]
[2019-04-07 18:12:39,446] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [-5.25, 78.5, 0.0, 0.0, 24.0, 23.32605072047796, -0.09602852304108343, 0.0, 1.0, 40746.38149328436]
[2019-04-07 18:12:39,446] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 18:12:39,447] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [1.4847371e-21 1.5188411e-19 9.7422239e-24 3.0658285e-18 6.6043910e-20
 1.0000000e+00 4.7783280e-15 1.1054548e-17], sampled 0.40509812219206387
[2019-04-07 18:12:53,494] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 18:13:09,765] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 18:13:13,036] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 18:13:14,059] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1800000, evaluation results [1800000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 18:13:19,668] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.9979576e-21 7.9280053e-20 2.7189035e-23 9.1640875e-18 2.4632181e-18
 1.0000000e+00 1.0051708e-15 1.9770650e-16], sum to 1.0000
[2019-04-07 18:13:19,668] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0741
[2019-04-07 18:13:19,760] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.5, 67.5, 0.0, 0.0, 24.0, 23.27089569942666, -0.05824196619048146, 0.0, 1.0, 51322.71380559388], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3562200.0000, 
sim time next is 3564000.0000, 
raw observation next is [-6.0, 70.0, 0.0, 0.0, 24.0, 23.26965301160038, -0.07233019096887405, 0.0, 1.0, 42660.994161136965], 
processed observation next is [0.0, 0.2608695652173913, 0.296398891966759, 0.7, 0.0, 0.0, 0.5, 0.43913775096669827, 0.47588993634370863, 0.0, 1.0, 0.20314759124350937], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05747683], dtype=float32), 1.0029308]. 
=============================================
[2019-04-07 18:13:19,767] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[94.89001]
 [95.32915]
 [95.70592]
 [96.09842]
 [95.99654]], R is [[94.53491974]
 [94.58956909]
 [94.64367676]
 [94.69724274]
 [94.71819305]].
[2019-04-07 18:13:29,346] A3C_AGENT_WORKER-Thread-19 INFO:Local step 113500, global step 1802504: loss 2.2779
[2019-04-07 18:13:29,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 113500, global step 1802504: learning rate 0.0000
[2019-04-07 18:13:31,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:13:31,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:13:32,000] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run41
[2019-04-07 18:13:44,355] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.9297664e-20 2.5722099e-18 2.4494858e-22 6.8545347e-17 8.4347199e-19
 1.0000000e+00 3.9910590e-14 3.7547862e-17], sum to 1.0000
[2019-04-07 18:13:44,356] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1024
[2019-04-07 18:13:44,427] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 37.0, 0.0, 0.0, 24.0, 23.40713532087729, -0.0237425371841503, 0.0, 1.0, 79445.0420280568], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4057200.0000, 
sim time next is 4059000.0000, 
raw observation next is [-6.0, 37.0, 0.0, 0.0, 24.0, 23.45878825029294, -0.03783985355857514, 0.0, 1.0, 24821.703399372967], 
processed observation next is [1.0, 1.0, 0.296398891966759, 0.37, 0.0, 0.0, 0.5, 0.45489902085774503, 0.48738671548047496, 0.0, 1.0, 0.11819858761606175], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.31210524], dtype=float32), 1.6555148]. 
=============================================
[2019-04-07 18:13:44,437] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[88.44908 ]
 [88.31955 ]
 [88.059586]
 [87.88494 ]
 [88.01754 ]], R is [[88.13262939]
 [88.15870667]
 [88.2771225 ]
 [88.39435577]
 [88.51041412]].
[2019-04-07 18:13:50,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:13:50,895] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:13:50,898] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run41
[2019-04-07 18:13:51,618] A3C_AGENT_WORKER-Thread-18 INFO:Local step 114000, global step 1806309: loss 1.0882
[2019-04-07 18:13:51,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 114000, global step 1806309: learning rate 0.0000
[2019-04-07 18:13:51,652] A3C_AGENT_WORKER-Thread-3 INFO:Local step 114500, global step 1806313: loss 1.9375
[2019-04-07 18:13:51,652] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 114500, global step 1806313: learning rate 0.0000
[2019-04-07 18:13:59,744] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:13:59,745] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:13:59,748] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run41
[2019-04-07 18:14:02,011] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:14:02,011] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:14:02,015] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run41
[2019-04-07 18:14:02,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.9629917e-22 4.1504753e-20 3.7696267e-24 1.1883796e-18 8.5679355e-20
 1.0000000e+00 4.7956579e-15 1.1591793e-16], sum to 1.0000
[2019-04-07 18:14:02,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5781
[2019-04-07 18:14:02,722] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.5, 56.0, 97.0, 533.0, 24.0, 23.68869793682354, 0.04722925609381442, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5041800.0000, 
sim time next is 5043600.0000, 
raw observation next is [1.0, 47.0, 104.5, 615.5, 24.0, 24.45510059295397, 0.1331378834420426, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4903047091412743, 0.47, 0.34833333333333333, 0.6801104972375691, 0.5, 0.5379250494128307, 0.5443792944806809, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.23105215], dtype=float32), -0.9465595]. 
=============================================
[2019-04-07 18:14:05,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:14:05,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:14:05,284] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run41
[2019-04-07 18:14:09,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:14:09,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:14:09,902] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.76253913e-21 5.97787630e-18 3.13219589e-24 1.38794273e-17
 1.18797157e-18 1.00000000e+00 1.09490985e-14 2.85739683e-16], sum to 1.0000
[2019-04-07 18:14:09,902] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4167
[2019-04-07 18:14:09,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run41
[2019-04-07 18:14:09,965] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 39.5, 178.0, 685.0, 24.0, 23.811005810541, 0.006274312221600159, 1.0, 1.0, 32180.89451357593], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2809800.0000, 
sim time next is 2811600.0000, 
raw observation next is [4.0, 35.0, 213.5, 429.0, 24.0, 24.01589252103852, 0.02168451355114055, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5734072022160666, 0.35, 0.7116666666666667, 0.4740331491712707, 0.5, 0.50132437675321, 0.5072281711837135, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6027793], dtype=float32), -0.7774175]. 
=============================================
[2019-04-07 18:14:10,992] A3C_AGENT_WORKER-Thread-14 INFO:Local step 113500, global step 1809255: loss 2.2246
[2019-04-07 18:14:10,993] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 113500, global step 1809255: learning rate 0.0000
[2019-04-07 18:14:16,361] A3C_AGENT_WORKER-Thread-19 INFO:Local step 114000, global step 1810043: loss 1.1734
[2019-04-07 18:14:16,362] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 114000, global step 1810043: learning rate 0.0000
[2019-04-07 18:14:29,668] A3C_AGENT_WORKER-Thread-6 INFO:Local step 113500, global step 1812032: loss 2.3654
[2019-04-07 18:14:29,668] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 113500, global step 1812032: learning rate 0.0000
[2019-04-07 18:14:30,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:14:30,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:14:30,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run41
[2019-04-07 18:14:31,985] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0077565e-22 1.5151425e-20 4.9554215e-24 2.3523375e-19 1.6854531e-21
 1.0000000e+00 4.5989712e-16 1.0059173e-18], sum to 1.0000
[2019-04-07 18:14:31,986] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3575
[2019-04-07 18:14:32,169] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 54.5, 114.0, 816.0, 24.0, 23.33582879717972, 0.01393577915710843, 0.0, 1.0, 18706.862632847275], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3583800.0000, 
sim time next is 3585600.0000, 
raw observation next is [-3.0, 55.0, 116.0, 819.5, 24.0, 23.39603666220753, 0.02749921385375594, 0.0, 1.0, 18704.633052294335], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.55, 0.38666666666666666, 0.905524861878453, 0.5, 0.44966972185062737, 0.5091664046179186, 0.0, 1.0, 0.0890696812014016], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.99082327], dtype=float32), -1.1059557]. 
=============================================
[2019-04-07 18:14:38,836] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5466241e-20 1.3602210e-16 1.9783198e-21 3.0966959e-17 4.5989840e-18
 1.0000000e+00 2.2939890e-14 5.7731574e-16], sum to 1.0000
[2019-04-07 18:14:38,837] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2731
[2019-04-07 18:14:38,954] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-11.15, 68.5, 0.0, 0.0, 24.0, 21.88680674104263, -0.4480505105183565, 0.0, 1.0, 48462.61455799263], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 279000.0000, 
sim time next is 280800.0000, 
raw observation next is [-11.7, 70.0, 0.0, 0.0, 24.0, 21.77494779189567, -0.4783543307738649, 0.0, 1.0, 48554.20020900925], 
processed observation next is [1.0, 0.2608695652173913, 0.13850415512465375, 0.7, 0.0, 0.0, 0.5, 0.3145789826579725, 0.3405485564087117, 0.0, 1.0, 0.23121047718575832], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.992889], dtype=float32), -0.044088285]. 
=============================================
[2019-04-07 18:14:40,402] A3C_AGENT_WORKER-Thread-12 INFO:Local step 113500, global step 1813596: loss 2.3236
[2019-04-07 18:14:40,402] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 113500, global step 1813596: learning rate 0.0000
[2019-04-07 18:14:41,815] A3C_AGENT_WORKER-Thread-10 INFO:Local step 113500, global step 1813787: loss 2.2628
[2019-04-07 18:14:41,816] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 113500, global step 1813787: learning rate 0.0000
[2019-04-07 18:14:44,993] A3C_AGENT_WORKER-Thread-18 INFO:Local step 114500, global step 1814247: loss 1.9051
[2019-04-07 18:14:45,026] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 114500, global step 1814247: learning rate 0.0000
[2019-04-07 18:14:45,909] A3C_AGENT_WORKER-Thread-13 INFO:Local step 113500, global step 1814395: loss 2.3436
[2019-04-07 18:14:45,910] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 113500, global step 1814395: learning rate 0.0000
[2019-04-07 18:14:46,997] A3C_AGENT_WORKER-Thread-3 INFO:Local step 115000, global step 1814561: loss 25.9668
[2019-04-07 18:14:46,998] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 115000, global step 1814561: learning rate 0.0000
[2019-04-07 18:14:49,395] A3C_AGENT_WORKER-Thread-16 INFO:Local step 113500, global step 1814888: loss 2.2209
[2019-04-07 18:14:49,396] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 113500, global step 1814888: learning rate 0.0000
[2019-04-07 18:14:59,615] A3C_AGENT_WORKER-Thread-14 INFO:Local step 114000, global step 1816631: loss 1.1162
[2019-04-07 18:14:59,616] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 114000, global step 1816631: learning rate 0.0000
[2019-04-07 18:15:02,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:15:02,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:15:02,652] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run41
[2019-04-07 18:15:05,587] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3048484e-22 8.9288363e-21 4.1499739e-25 5.3174592e-19 1.7964978e-21
 1.0000000e+00 2.2055093e-15 7.3726262e-19], sum to 1.0000
[2019-04-07 18:15:05,587] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4537
[2019-04-07 18:15:05,619] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 57.0, 107.5, 614.0, 24.0, 24.0526078141846, -0.03625838265028836, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 734400.0000, 
sim time next is 736200.0000, 
raw observation next is [-0.04999999999999999, 53.5, 131.0, 449.0, 24.0, 24.01614613626757, -0.05570143586212142, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.461218836565097, 0.535, 0.43666666666666665, 0.49613259668508286, 0.5, 0.5013455113556308, 0.48143285471262615, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1842706], dtype=float32), -0.38590294]. 
=============================================
[2019-04-07 18:15:08,826] A3C_AGENT_WORKER-Thread-19 INFO:Local step 114500, global step 1818141: loss 1.9006
[2019-04-07 18:15:08,836] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 114500, global step 1818141: learning rate 0.0000
[2019-04-07 18:15:09,471] A3C_AGENT_WORKER-Thread-4 INFO:Local step 113500, global step 1818228: loss 2.2792
[2019-04-07 18:15:09,471] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 113500, global step 1818228: learning rate 0.0000
[2019-04-07 18:15:14,706] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3486093e-23 4.5590463e-21 1.9405846e-25 1.0385574e-18 2.3403413e-21
 1.0000000e+00 2.2936117e-15 1.0288884e-18], sum to 1.0000
[2019-04-07 18:15:14,707] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4123
[2019-04-07 18:15:14,744] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 80.0, 0.0, 0.0, 24.0, 23.25628961455881, -0.1255741800287849, 0.0, 1.0, 41135.272159567976], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 865800.0000, 
sim time next is 867600.0000, 
raw observation next is [-2.3, 80.0, 0.0, 0.0, 24.0, 23.4026768349614, -0.1208161165495785, 0.0, 1.0, 31167.7451216023], 
processed observation next is [1.0, 0.043478260869565216, 0.3988919667590028, 0.8, 0.0, 0.0, 0.5, 0.45022306958011676, 0.45972796115014053, 0.0, 1.0, 0.1484178339123919], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4219869], dtype=float32), 0.42985377]. 
=============================================
[2019-04-07 18:15:18,050] A3C_AGENT_WORKER-Thread-6 INFO:Local step 114000, global step 1819794: loss 1.0681
[2019-04-07 18:15:18,050] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 114000, global step 1819794: learning rate 0.0000
[2019-04-07 18:15:19,027] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-07 18:15:19,033] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:15:19,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:15:19,038] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run92
[2019-04-07 18:15:19,058] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:15:19,058] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:15:19,061] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:15:19,061] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:15:19,070] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run92
[2019-04-07 18:15:19,088] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run92
[2019-04-07 18:17:47,048] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 18:18:04,068] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 18:18:08,511] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 18:18:09,548] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1820000, evaluation results [1820000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 18:18:16,216] A3C_AGENT_WORKER-Thread-3 INFO:Local step 115500, global step 1821304: loss 0.6289
[2019-04-07 18:18:16,232] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 115500, global step 1821305: learning rate 0.0000
[2019-04-07 18:18:16,378] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8228883e-27 5.1699127e-24 4.1632530e-29 8.9363617e-22 4.1701617e-24
 1.0000000e+00 3.4896703e-19 1.7254084e-22], sum to 1.0000
[2019-04-07 18:18:16,378] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8873
[2019-04-07 18:18:16,423] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [13.8, 78.0, 0.0, 0.0, 24.0, 23.69167111814352, 0.1117869546597689, 0.0, 1.0, 55171.79594043067], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1044000.0000, 
sim time next is 1045800.0000, 
raw observation next is [14.1, 77.5, 0.0, 0.0, 24.0, 23.8516501155399, 0.1213994822486622, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.8531855955678671, 0.775, 0.0, 0.0, 0.5, 0.487637509628325, 0.5404664940828874, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1447142], dtype=float32), 1.8986762]. 
=============================================
[2019-04-07 18:18:18,701] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1492228e-21 4.1486887e-19 2.6252381e-23 6.5392955e-17 1.9365012e-19
 1.0000000e+00 2.9665353e-15 3.4817488e-17], sum to 1.0000
[2019-04-07 18:18:18,702] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6860
[2019-04-07 18:18:18,724] A3C_AGENT_WORKER-Thread-12 INFO:Local step 114000, global step 1821840: loss 1.1625
[2019-04-07 18:18:18,727] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 114000, global step 1821841: learning rate 0.0000
[2019-04-07 18:18:18,778] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 46.5, 0.0, 0.0, 24.0, 23.51236017519089, -0.1737314776339142, 0.0, 1.0, 7620.2650715255], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2518200.0000, 
sim time next is 2520000.0000, 
raw observation next is [-1.7, 49.0, 0.0, 0.0, 24.0, 23.37729605097395, -0.199589585100304, 0.0, 1.0, 55059.0287396408], 
processed observation next is [1.0, 0.17391304347826086, 0.4155124653739613, 0.49, 0.0, 0.0, 0.5, 0.44810800424782915, 0.43347013829989867, 0.0, 1.0, 0.2621858511411467], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.72122896], dtype=float32), 1.1823875]. 
=============================================
[2019-04-07 18:18:18,796] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[92.25404 ]
 [92.296974]
 [92.36545 ]
 [92.40576 ]
 [93.01866 ]], R is [[92.82432556]
 [92.89608002]
 [92.96711731]
 [93.03744507]
 [93.10707092]].
[2019-04-07 18:18:19,896] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.1810879e-21 9.6768331e-20 8.3440350e-24 1.2584541e-17 9.6050810e-20
 1.0000000e+00 2.0245299e-15 2.0173417e-18], sum to 1.0000
[2019-04-07 18:18:19,896] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8988
[2019-04-07 18:18:19,927] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 47.0, 282.0, 349.0, 24.0, 23.17834922648316, -0.07938196335450186, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4881600.0000, 
sim time next is 4883400.0000, 
raw observation next is [1.2, 46.0, 281.0, 390.0, 24.0, 23.25516686353371, -0.06645957202749687, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.4958448753462604, 0.46, 0.9366666666666666, 0.430939226519337, 0.5, 0.43793057196114243, 0.4778468093241677, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02256577], dtype=float32), 0.24763547]. 
=============================================
[2019-04-07 18:18:20,352] A3C_AGENT_WORKER-Thread-10 INFO:Local step 114000, global step 1822190: loss 1.1439
[2019-04-07 18:18:20,355] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 114000, global step 1822190: learning rate 0.0000
[2019-04-07 18:18:20,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:18:20,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:18:20,899] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run41
[2019-04-07 18:18:23,215] A3C_AGENT_WORKER-Thread-13 INFO:Local step 114000, global step 1822730: loss 1.1117
[2019-04-07 18:18:23,217] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 114000, global step 1822730: learning rate 0.0000
[2019-04-07 18:18:26,468] A3C_AGENT_WORKER-Thread-16 INFO:Local step 114000, global step 1823316: loss 1.0658
[2019-04-07 18:18:26,469] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 114000, global step 1823316: learning rate 0.0000
[2019-04-07 18:18:27,035] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:18:27,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:18:27,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run41
[2019-04-07 18:18:27,101] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.7039601e-21 2.3761471e-19 3.5367313e-22 8.8886124e-18 3.3007770e-20
 1.0000000e+00 1.0005309e-14 2.1165537e-17], sum to 1.0000
[2019-04-07 18:18:27,101] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6162
[2019-04-07 18:18:27,206] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.35, 73.0, 87.0, 0.0, 24.0, 24.13288299837289, -0.0815501044239972, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 815400.0000, 
sim time next is 817200.0000, 
raw observation next is [-4.5, 71.0, 98.5, 0.0, 24.0, 24.01251184051635, -0.09544933166081798, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.3379501385041552, 0.71, 0.3283333333333333, 0.0, 0.5, 0.5010426533763624, 0.4681835561130607, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4932197], dtype=float32), -0.016427012]. 
=============================================
[2019-04-07 18:18:27,334] A3C_AGENT_WORKER-Thread-18 INFO:Local step 115000, global step 1823472: loss 26.2727
[2019-04-07 18:18:27,334] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 115000, global step 1823472: learning rate 0.0000
[2019-04-07 18:18:28,371] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.5631638e-24 1.6000820e-22 8.0158930e-27 3.5110596e-20 9.4004420e-23
 1.0000000e+00 9.1570292e-18 1.0274793e-20], sum to 1.0000
[2019-04-07 18:18:28,371] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1826
[2019-04-07 18:18:28,387] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 109.5, 0.0, 24.0, 24.12980287363732, 0.1257292184704436, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1342800.0000, 
sim time next is 1344600.0000, 
raw observation next is [1.1, 92.0, 106.0, 0.0, 24.0, 24.1122423287827, 0.1249316632190127, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.49307479224376743, 0.92, 0.35333333333333333, 0.0, 0.5, 0.5093535273985582, 0.5416438877396709, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.25611347], dtype=float32), 0.17745534]. 
=============================================
[2019-04-07 18:18:28,464] A3C_AGENT_WORKER-Thread-17 INFO:Local step 113500, global step 1823650: loss 2.2100
[2019-04-07 18:18:28,464] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 113500, global step 1823650: learning rate 0.0000
[2019-04-07 18:18:28,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:18:28,951] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:18:28,954] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run41
[2019-04-07 18:18:37,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.4424025e-24 1.2124875e-20 2.1299965e-27 6.3581684e-20 4.5586790e-22
 1.0000000e+00 7.0963620e-17 9.4486992e-21], sum to 1.0000
[2019-04-07 18:18:37,932] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9271
[2019-04-07 18:18:37,968] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.15, 94.0, 0.0, 0.0, 24.0, 23.27407418323507, -0.1503244611216039, 0.0, 1.0, 43841.53579732953], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 509400.0000, 
sim time next is 511200.0000, 
raw observation next is [2.7, 92.0, 0.0, 0.0, 24.0, 23.34195971914093, -0.1386444461369805, 0.0, 1.0, 42945.58772004904], 
processed observation next is [1.0, 0.9565217391304348, 0.5373961218836566, 0.92, 0.0, 0.0, 0.5, 0.4451633099284109, 0.45378518462100653, 0.0, 1.0, 0.20450279866690022], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9698342], dtype=float32), 0.30097604]. 
=============================================
[2019-04-07 18:18:39,956] A3C_AGENT_WORKER-Thread-14 INFO:Local step 114500, global step 1825431: loss 1.8822
[2019-04-07 18:18:39,965] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 114500, global step 1825431: learning rate 0.0000
[2019-04-07 18:18:42,637] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4335884e-21 5.9844212e-19 7.3856440e-23 1.3589289e-17 1.2561309e-20
 1.0000000e+00 1.6515287e-15 1.6170949e-18], sum to 1.0000
[2019-04-07 18:18:42,637] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8498
[2019-04-07 18:18:42,707] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.5167866987965, -0.05582574656619604, 0.0, 1.0, 33357.715582477445], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5036400.0000, 
sim time next is 5038200.0000, 
raw observation next is [-2.5, 65.0, 59.0, 101.0, 24.0, 23.43946247889821, -0.05472353358722652, 1.0, 1.0, 6413.791113272273], 
processed observation next is [1.0, 0.30434782608695654, 0.39335180055401664, 0.65, 0.19666666666666666, 0.11160220994475138, 0.5, 0.45328853990818424, 0.4817588221375912, 1.0, 1.0, 0.030541862444153682], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7194986], dtype=float32), -1.56724]. 
=============================================
[2019-04-07 18:18:45,983] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:18:45,983] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:18:45,986] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run41
[2019-04-07 18:18:46,881] A3C_AGENT_WORKER-Thread-4 INFO:Local step 114000, global step 1826541: loss 1.1680
[2019-04-07 18:18:46,882] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 114000, global step 1826541: learning rate 0.0000
[2019-04-07 18:18:48,293] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:18:48,293] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:18:48,296] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run41
[2019-04-07 18:18:51,012] A3C_AGENT_WORKER-Thread-19 INFO:Local step 115000, global step 1826997: loss 25.7886
[2019-04-07 18:18:51,012] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 115000, global step 1826997: learning rate 0.0000
[2019-04-07 18:18:55,243] A3C_AGENT_WORKER-Thread-3 INFO:Local step 116000, global step 1827510: loss 0.3395
[2019-04-07 18:18:55,243] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 116000, global step 1827510: learning rate 0.0000
[2019-04-07 18:19:01,251] A3C_AGENT_WORKER-Thread-20 INFO:Local step 113500, global step 1828347: loss 2.3013
[2019-04-07 18:19:01,263] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 113500, global step 1828347: learning rate 0.0000
[2019-04-07 18:19:01,433] A3C_AGENT_WORKER-Thread-6 INFO:Local step 114500, global step 1828369: loss 1.8742
[2019-04-07 18:19:01,433] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 114500, global step 1828369: learning rate 0.0000
[2019-04-07 18:19:04,460] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:19:04,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:19:04,464] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run42
[2019-04-07 18:19:05,718] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.2944961e-24 7.1737279e-21 2.3284471e-26 1.6580335e-19 1.6598734e-21
 1.0000000e+00 6.7250818e-18 8.0451814e-19], sum to 1.0000
[2019-04-07 18:19:05,719] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3312
[2019-04-07 18:19:05,796] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 58.0, 93.5, 739.5, 24.0, 24.93139202759396, 0.277638060078241, 1.0, 1.0, 6226.803890076847], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3423600.0000, 
sim time next is 3425400.0000, 
raw observation next is [2.5, 62.5, 84.0, 704.0, 24.0, 25.18259042109601, 0.2160165984372022, 1.0, 1.0, 1245.360778015369], 
processed observation next is [1.0, 0.6521739130434783, 0.5318559556786704, 0.625, 0.28, 0.7779005524861878, 0.5, 0.5985492017580007, 0.5720055328124007, 1.0, 1.0, 0.005930289419120805], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03104496], dtype=float32), -0.54375744]. 
=============================================
[2019-04-07 18:19:07,618] A3C_AGENT_WORKER-Thread-2 INFO:Local step 113500, global step 1829165: loss 2.3348
[2019-04-07 18:19:07,618] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 113500, global step 1829165: learning rate 0.0000
[2019-04-07 18:19:08,117] A3C_AGENT_WORKER-Thread-18 INFO:Local step 115500, global step 1829211: loss 0.6493
[2019-04-07 18:19:08,119] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 115500, global step 1829211: learning rate 0.0000
[2019-04-07 18:19:09,045] A3C_AGENT_WORKER-Thread-5 INFO:Local step 113500, global step 1829309: loss 2.3909
[2019-04-07 18:19:09,046] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 113500, global step 1829309: learning rate 0.0000
[2019-04-07 18:19:09,203] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4391422e-22 2.9351769e-21 9.4563289e-24 1.7552663e-18 1.7078346e-20
 1.0000000e+00 1.9874378e-14 1.1953090e-17], sum to 1.0000
[2019-04-07 18:19:09,204] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5972
[2019-04-07 18:19:09,260] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 52.0, 115.5, 814.5, 24.0, 24.13619370923308, 0.1854157506233747, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3502800.0000, 
sim time next is 3504600.0000, 
raw observation next is [2.5, 50.5, 115.0, 806.0, 24.0, 24.79696535770502, 0.2804797610380711, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5318559556786704, 0.505, 0.38333333333333336, 0.8906077348066298, 0.5, 0.5664137798087516, 0.593493253679357, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0845038], dtype=float32), -0.780317]. 
=============================================
[2019-04-07 18:19:12,309] A3C_AGENT_WORKER-Thread-12 INFO:Local step 114500, global step 1829742: loss 1.9309
[2019-04-07 18:19:12,345] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 114500, global step 1829742: learning rate 0.0000
[2019-04-07 18:19:15,021] A3C_AGENT_WORKER-Thread-10 INFO:Local step 114500, global step 1830129: loss 2.0234
[2019-04-07 18:19:15,022] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 114500, global step 1830129: learning rate 0.0000
[2019-04-07 18:19:17,469] A3C_AGENT_WORKER-Thread-17 INFO:Local step 114000, global step 1830470: loss 1.1054
[2019-04-07 18:19:17,469] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 114000, global step 1830470: learning rate 0.0000
[2019-04-07 18:19:18,693] A3C_AGENT_WORKER-Thread-13 INFO:Local step 114500, global step 1830631: loss 1.9544
[2019-04-07 18:19:18,694] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 114500, global step 1830631: learning rate 0.0000
[2019-04-07 18:19:20,458] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7776733e-22 5.4711584e-21 2.4121688e-25 3.5318445e-18 2.0829167e-21
 1.0000000e+00 3.1003752e-15 4.3963548e-19], sum to 1.0000
[2019-04-07 18:19:20,458] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4404
[2019-04-07 18:19:20,546] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 60.0, 75.5, 625.0, 24.0, 25.55731964486488, 0.3860374885840668, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3772800.0000, 
sim time next is 3774600.0000, 
raw observation next is [0.0, 60.0, 64.0, 539.0, 24.0, 25.28479282286366, 0.3368115836632102, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.46260387811634357, 0.6, 0.21333333333333335, 0.5955801104972376, 0.5, 0.6070660685719718, 0.6122705278877367, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.4967282], dtype=float32), -0.6604457]. 
=============================================
[2019-04-07 18:19:21,751] A3C_AGENT_WORKER-Thread-16 INFO:Local step 114500, global step 1831043: loss 1.8672
[2019-04-07 18:19:21,753] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 114500, global step 1831043: learning rate 0.0000
[2019-04-07 18:19:23,795] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.0736069e-24 3.3077440e-22 9.2046170e-27 3.6244873e-21 2.4686866e-23
 1.0000000e+00 1.4905570e-17 1.4242082e-20], sum to 1.0000
[2019-04-07 18:19:23,795] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5758
[2019-04-07 18:19:23,839] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.949999999999999, 74.5, 0.0, 0.0, 24.0, 24.01876221850415, 0.03273125399449131, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4311000.0000, 
sim time next is 4312800.0000, 
raw observation next is [4.8, 76.0, 0.0, 0.0, 24.0, 23.83937982176959, -0.008050274975340435, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.5955678670360112, 0.76, 0.0, 0.0, 0.5, 0.4866149851474659, 0.49731657500821985, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.34821108], dtype=float32), -0.39849186]. 
=============================================
[2019-04-07 18:19:27,173] A3C_AGENT_WORKER-Thread-11 INFO:Local step 113500, global step 1831856: loss 2.2424
[2019-04-07 18:19:27,173] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 113500, global step 1831856: learning rate 0.0000
[2019-04-07 18:19:29,276] A3C_AGENT_WORKER-Thread-15 INFO:Local step 113500, global step 1832104: loss 2.3013
[2019-04-07 18:19:29,277] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 113500, global step 1832104: learning rate 0.0000
[2019-04-07 18:19:31,900] A3C_AGENT_WORKER-Thread-19 INFO:Local step 115500, global step 1832470: loss 0.6901
[2019-04-07 18:19:31,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 115500, global step 1832470: learning rate 0.0000
[2019-04-07 18:19:36,815] A3C_AGENT_WORKER-Thread-14 INFO:Local step 115000, global step 1833162: loss 26.2154
[2019-04-07 18:19:36,816] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 115000, global step 1833162: learning rate 0.0000
[2019-04-07 18:19:41,164] A3C_AGENT_WORKER-Thread-4 INFO:Local step 114500, global step 1833826: loss 1.8341
[2019-04-07 18:19:41,164] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 114500, global step 1833826: learning rate 0.0000
[2019-04-07 18:19:43,023] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3799929e-22 3.6111300e-20 7.9494869e-25 1.6632733e-18 1.8611208e-20
 1.0000000e+00 4.4532291e-15 4.8038167e-18], sum to 1.0000
[2019-04-07 18:19:43,023] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4797
[2019-04-07 18:19:43,180] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 174.0, 421.0, 24.0, 23.74505199730778, 0.0271874793372605, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4786200.0000, 
sim time next is 4788000.0000, 
raw observation next is [-3.0, 65.0, 163.5, 575.5, 24.0, 23.69051226993184, 0.02744617446743249, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3795013850415513, 0.65, 0.545, 0.6359116022099448, 0.5, 0.4742093558276534, 0.5091487248224775, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5331258], dtype=float32), -1.214021]. 
=============================================
[2019-04-07 18:19:43,194] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[96.68289]
 [96.983  ]
 [97.1078 ]
 [95.92735]
 [95.19309]], R is [[96.04901886]
 [96.08853149]
 [96.1276474 ]
 [96.09101868]
 [96.13011169]].
[2019-04-07 18:19:48,545] A3C_AGENT_WORKER-Thread-18 INFO:Local step 116000, global step 1835018: loss 0.2921
[2019-04-07 18:19:48,546] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 116000, global step 1835018: learning rate 0.0000
[2019-04-07 18:19:50,640] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.2571005e-28 3.6260685e-26 1.0926021e-30 2.1246853e-23 1.1325285e-26
 1.0000000e+00 1.8583197e-19 8.5401533e-23], sum to 1.0000
[2019-04-07 18:19:50,640] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2012
[2019-04-07 18:19:50,710] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [15.5, 70.0, 184.0, 107.5, 24.0, 25.54336994817416, 0.4848975436706007, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1076400.0000, 
sim time next is 1078200.0000, 
raw observation next is [16.05, 67.5, 254.0, 215.0, 24.0, 25.79635401900352, 0.245541065605331, 1.0, 0.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.9072022160664821, 0.675, 0.8466666666666667, 0.23756906077348067, 0.5, 0.6496961682502933, 0.5818470218684436, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4522989], dtype=float32), -1.046672]. 
=============================================
[2019-04-07 18:19:52,363] A3C_AGENT_WORKER-Thread-20 INFO:Local step 114000, global step 1835726: loss 1.1176
[2019-04-07 18:19:52,390] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 114000, global step 1835729: learning rate 0.0000
[2019-04-07 18:19:56,575] A3C_AGENT_WORKER-Thread-6 INFO:Local step 115000, global step 1836519: loss 25.9320
[2019-04-07 18:19:56,576] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 115000, global step 1836519: learning rate 0.0000
[2019-04-07 18:19:57,161] A3C_AGENT_WORKER-Thread-2 INFO:Local step 114000, global step 1836634: loss 1.1526
[2019-04-07 18:19:57,162] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 114000, global step 1836634: learning rate 0.0000
[2019-04-07 18:19:57,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:19:57,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:19:57,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run42
[2019-04-07 18:19:59,946] A3C_AGENT_WORKER-Thread-5 INFO:Local step 114000, global step 1837055: loss 1.1384
[2019-04-07 18:19:59,947] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 114000, global step 1837055: learning rate 0.0000
[2019-04-07 18:20:00,567] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1169174e-23 2.3619394e-20 1.3456704e-26 2.0148402e-20 2.5462557e-22
 1.0000000e+00 3.2736479e-16 3.3102737e-19], sum to 1.0000
[2019-04-07 18:20:00,568] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9185
[2019-04-07 18:20:00,723] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 24.0, 23.74796928189979, -0.08599892729912133, 1.0, 1.0, 8496.30788556198], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 891000.0000, 
sim time next is 892800.0000, 
raw observation next is [0.0, 72.0, 14.5, 0.0, 24.0, 23.51077336776335, -0.126977970120183, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.46260387811634357, 0.72, 0.04833333333333333, 0.0, 0.5, 0.4592311139802791, 0.457674009959939, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.02537648], dtype=float32), -0.56878763]. 
=============================================
[2019-04-07 18:20:03,863] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.1539263e-22 5.9608599e-20 6.5513573e-24 7.0056842e-19 2.2090727e-21
 1.0000000e+00 7.8956070e-16 2.0851300e-18], sum to 1.0000
[2019-04-07 18:20:03,863] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6988
[2019-04-07 18:20:03,946] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.47193198632659, -0.1112596056627601, 0.0, 1.0, 21889.538816231343], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3736800.0000, 
sim time next is 3738600.0000, 
raw observation next is [-3.5, 71.0, 0.0, 0.0, 24.0, 23.50883758283749, -0.1285952209411031, 0.0, 1.0, 30360.036164362624], 
processed observation next is [1.0, 0.2608695652173913, 0.36565096952908593, 0.71, 0.0, 0.0, 0.5, 0.45906979856979085, 0.45713492635296565, 0.0, 1.0, 0.14457160078267917], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.06409414], dtype=float32), -2.411921]. 
=============================================
[2019-04-07 18:20:04,499] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.08801905e-22 1.10035455e-19 7.45521834e-24 2.38702301e-18
 1.58455881e-19 1.00000000e+00 1.08542349e-15 1.14690255e-17], sum to 1.0000
[2019-04-07 18:20:04,499] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3367
[2019-04-07 18:20:04,540] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.1, 92.5, 0.0, 0.0, 24.0, 22.81363608894983, -0.1816362151632738, 0.0, 1.0, 42625.39113358647], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4775400.0000, 
sim time next is 4777200.0000, 
raw observation next is [-6.2, 93.0, 0.0, 0.0, 24.0, 22.72893032850049, -0.1995005228263301, 0.0, 1.0, 42745.656292017025], 
processed observation next is [0.0, 0.30434782608695654, 0.2908587257617729, 0.93, 0.0, 0.0, 0.5, 0.39407752737504076, 0.43349982572455664, 0.0, 1.0, 0.20355074424770012], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.2068763], dtype=float32), 0.92705864]. 
=============================================
[2019-04-07 18:20:06,149] A3C_AGENT_WORKER-Thread-12 INFO:Local step 115000, global step 1838106: loss 26.1133
[2019-04-07 18:20:06,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 115000, global step 1838106: learning rate 0.0000
[2019-04-07 18:20:08,777] A3C_AGENT_WORKER-Thread-17 INFO:Local step 114500, global step 1838614: loss 1.9078
[2019-04-07 18:20:08,786] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 114500, global step 1838617: learning rate 0.0000
[2019-04-07 18:20:08,891] A3C_AGENT_WORKER-Thread-10 INFO:Local step 115000, global step 1838634: loss 26.1437
[2019-04-07 18:20:08,893] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 115000, global step 1838634: learning rate 0.0000
[2019-04-07 18:20:10,934] A3C_AGENT_WORKER-Thread-19 INFO:Local step 116000, global step 1839061: loss 0.2919
[2019-04-07 18:20:10,946] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 116000, global step 1839061: learning rate 0.0000
[2019-04-07 18:20:12,460] A3C_AGENT_WORKER-Thread-13 INFO:Local step 115000, global step 1839389: loss 26.5174
[2019-04-07 18:20:12,461] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 115000, global step 1839389: learning rate 0.0000
[2019-04-07 18:20:13,656] A3C_AGENT_WORKER-Thread-11 INFO:Local step 114000, global step 1839645: loss 1.1988
[2019-04-07 18:20:13,657] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 114000, global step 1839645: learning rate 0.0000
[2019-04-07 18:20:15,098] A3C_AGENT_WORKER-Thread-14 INFO:Local step 115500, global step 1839917: loss 0.6340
[2019-04-07 18:20:15,098] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 115500, global step 1839917: learning rate 0.0000
[2019-04-07 18:20:15,466] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-07 18:20:15,468] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:20:15,468] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:20:15,470] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:20:15,470] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:20:15,474] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run93
[2019-04-07 18:20:15,491] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:20:15,494] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:20:15,498] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run93
[2019-04-07 18:20:15,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run93
[2019-04-07 18:20:30,110] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.1250705], dtype=float32), 0.1697791]
[2019-04-07 18:20:30,111] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-15.6, 73.0, 0.0, 0.0, 24.0, 21.0882055231609, -0.6315596088044458, 0.0, 1.0, 50167.690521263045]
[2019-04-07 18:20:30,111] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 18:20:30,112] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [3.8804523e-18 1.4156692e-16 4.9403317e-20 1.8278454e-15 8.5603691e-17
 1.0000000e+00 9.6986720e-13 5.0655137e-15], sampled 0.007146133895275852
[2019-04-07 18:22:42,263] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 18:22:57,746] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 18:23:03,781] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 18:23:04,804] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1840000, evaluation results [1840000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 18:23:04,854] A3C_AGENT_WORKER-Thread-16 INFO:Local step 115000, global step 1840020: loss 26.2514
[2019-04-07 18:23:04,854] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 115000, global step 1840020: learning rate 0.0000
[2019-04-07 18:23:05,810] A3C_AGENT_WORKER-Thread-15 INFO:Local step 114000, global step 1840194: loss 1.1370
[2019-04-07 18:23:05,812] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 114000, global step 1840194: learning rate 0.0000
[2019-04-07 18:23:08,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:23:08,526] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:23:08,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run42
[2019-04-07 18:23:23,915] A3C_AGENT_WORKER-Thread-4 INFO:Local step 115000, global step 1843237: loss 26.4282
[2019-04-07 18:23:23,916] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 115000, global step 1843237: learning rate 0.0000
[2019-04-07 18:23:25,649] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3157849e-22 4.9369406e-20 4.5170794e-23 1.7024123e-17 1.1002328e-19
 1.0000000e+00 1.2648758e-15 3.9002512e-17], sum to 1.0000
[2019-04-07 18:23:25,649] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5915
[2019-04-07 18:23:25,660] A3C_AGENT_WORKER-Thread-6 INFO:Local step 115500, global step 1843550: loss 0.6968
[2019-04-07 18:23:25,660] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 115500, global step 1843550: learning rate 0.0000
[2019-04-07 18:23:25,755] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 24.0, 23.53101882593745, -0.04112198093626658, 0.0, 1.0, 74619.2016461321], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3708000.0000, 
sim time next is 3709800.0000, 
raw observation next is [-1.5, 68.5, 0.0, 0.0, 24.0, 23.4937084192445, -0.03280996480182814, 0.0, 1.0, 59165.116932465055], 
processed observation next is [0.0, 0.9565217391304348, 0.4210526315789474, 0.685, 0.0, 0.0, 0.5, 0.45780903493704156, 0.4890633450660573, 0.0, 1.0, 0.2817386520593574], 
reward next is 1.0000, 
noisyNet noise sample is [array([-3.3969164], dtype=float32), -0.08928724]. 
=============================================
[2019-04-07 18:23:31,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2126224e-24 5.5423459e-22 9.7486776e-27 8.4416641e-21 3.7376403e-23
 1.0000000e+00 1.3193273e-16 2.6783700e-19], sum to 1.0000
[2019-04-07 18:23:31,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0605
[2019-04-07 18:23:31,125] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [10.0, 60.0, 0.0, 0.0, 24.0, 25.09744092529318, 0.3759640568145155, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1533600.0000, 
sim time next is 1535400.0000, 
raw observation next is [9.7, 60.5, 0.0, 0.0, 24.0, 25.02133733929897, 0.3473985316511617, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.7313019390581719, 0.605, 0.0, 0.0, 0.5, 0.5851114449415808, 0.6157995105503872, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1652436], dtype=float32), -1.6554933]. 
=============================================
[2019-04-07 18:23:32,740] A3C_AGENT_WORKER-Thread-20 INFO:Local step 114500, global step 1844674: loss 1.8808
[2019-04-07 18:23:32,740] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 114500, global step 1844674: learning rate 0.0000
[2019-04-07 18:23:35,856] A3C_AGENT_WORKER-Thread-12 INFO:Local step 115500, global step 1845199: loss 0.6321
[2019-04-07 18:23:35,857] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 115500, global step 1845199: learning rate 0.0000
[2019-04-07 18:23:36,724] A3C_AGENT_WORKER-Thread-2 INFO:Local step 114500, global step 1845337: loss 1.8484
[2019-04-07 18:23:36,724] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 114500, global step 1845337: learning rate 0.0000
[2019-04-07 18:23:39,118] A3C_AGENT_WORKER-Thread-10 INFO:Local step 115500, global step 1845719: loss 0.6078
[2019-04-07 18:23:39,118] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 115500, global step 1845719: learning rate 0.0000
[2019-04-07 18:23:39,584] A3C_AGENT_WORKER-Thread-5 INFO:Local step 114500, global step 1845784: loss 1.8388
[2019-04-07 18:23:39,584] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 114500, global step 1845784: learning rate 0.0000
[2019-04-07 18:23:41,382] A3C_AGENT_WORKER-Thread-13 INFO:Local step 115500, global step 1846046: loss 0.6280
[2019-04-07 18:23:41,382] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 115500, global step 1846046: learning rate 0.0000
[2019-04-07 18:23:44,399] A3C_AGENT_WORKER-Thread-14 INFO:Local step 116000, global step 1846502: loss 0.3656
[2019-04-07 18:23:44,414] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 116000, global step 1846506: learning rate 0.0000
[2019-04-07 18:23:45,501] A3C_AGENT_WORKER-Thread-16 INFO:Local step 115500, global step 1846681: loss 0.6583
[2019-04-07 18:23:45,503] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 115500, global step 1846681: learning rate 0.0000
[2019-04-07 18:23:50,135] A3C_AGENT_WORKER-Thread-17 INFO:Local step 115000, global step 1847393: loss 26.4113
[2019-04-07 18:23:50,139] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 115000, global step 1847393: learning rate 0.0000
[2019-04-07 18:23:53,794] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:23:53,794] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:23:53,798] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run42
[2019-04-07 18:23:56,333] A3C_AGENT_WORKER-Thread-11 INFO:Local step 114500, global step 1848477: loss 1.8362
[2019-04-07 18:23:56,333] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 114500, global step 1848477: learning rate 0.0000
[2019-04-07 18:23:58,945] A3C_AGENT_WORKER-Thread-15 INFO:Local step 114500, global step 1848908: loss 1.8401
[2019-04-07 18:23:58,946] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 114500, global step 1848908: learning rate 0.0000
[2019-04-07 18:24:02,004] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.8376340e-24 5.7451913e-23 1.1339891e-27 2.4718848e-20 8.8546797e-23
 1.0000000e+00 1.5769626e-17 1.0653251e-19], sum to 1.0000
[2019-04-07 18:24:02,004] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5501
[2019-04-07 18:24:02,042] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [8.8, 83.0, 0.0, 0.0, 24.0, 23.59033919686464, 0.01273505277203198, 0.0, 1.0, 26652.584914089686], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 968400.0000, 
sim time next is 970200.0000, 
raw observation next is [8.8, 83.0, 0.0, 0.0, 24.0, 23.66514298086993, 0.0004373068257622671, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.7063711911357342, 0.83, 0.0, 0.0, 0.5, 0.47209524840582756, 0.5001457689419208, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.9693751], dtype=float32), -1.2191751]. 
=============================================
[2019-04-07 18:24:03,547] A3C_AGENT_WORKER-Thread-6 INFO:Local step 116000, global step 1849687: loss 0.2984
[2019-04-07 18:24:03,549] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 116000, global step 1849687: learning rate 0.0000
[2019-04-07 18:24:04,736] A3C_AGENT_WORKER-Thread-4 INFO:Local step 115500, global step 1849922: loss 0.6719
[2019-04-07 18:24:04,736] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 115500, global step 1849922: learning rate 0.0000
[2019-04-07 18:24:12,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:24:12,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:24:12,340] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run42
[2019-04-07 18:24:14,086] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1147945e-21 6.6488306e-20 3.0453610e-25 3.3212418e-18 3.0955693e-20
 1.0000000e+00 8.5477779e-16 1.0609502e-17], sum to 1.0000
[2019-04-07 18:24:14,087] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9881
[2019-04-07 18:24:14,186] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 24.0, 22.91902103027243, -0.1615050112023795, 0.0, 1.0, 42467.95203883526], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4773600.0000, 
sim time next is 4775400.0000, 
raw observation next is [-6.1, 92.5, 0.0, 0.0, 24.0, 22.81363608894983, -0.1816362151632738, 0.0, 1.0, 42625.39113358647], 
processed observation next is [0.0, 0.2608695652173913, 0.29362880886426596, 0.925, 0.0, 0.0, 0.5, 0.4011363407458193, 0.4394545949455754, 0.0, 1.0, 0.2029780530170784], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1406071], dtype=float32), 0.14650254]. 
=============================================
[2019-04-07 18:24:15,631] A3C_AGENT_WORKER-Thread-12 INFO:Local step 116000, global step 1851762: loss 0.3332
[2019-04-07 18:24:15,632] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 116000, global step 1851762: learning rate 0.0000
[2019-04-07 18:24:17,549] A3C_AGENT_WORKER-Thread-10 INFO:Local step 116000, global step 1852062: loss 0.3303
[2019-04-07 18:24:17,579] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 116000, global step 1852062: learning rate 0.0000
[2019-04-07 18:24:19,513] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.30112711e-22 6.50199957e-20 1.76070537e-25 2.35287596e-19
 4.19554085e-20 1.00000000e+00 5.21004513e-16 1.01229136e-19], sum to 1.0000
[2019-04-07 18:24:19,514] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7815
[2019-04-07 18:24:19,670] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 40.5, 0.0, 0.0, 24.0, 23.08562338312027, -0.1374861972954216, 1.0, 1.0, 10035.904602055187], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2835000.0000, 
sim time next is 2836800.0000, 
raw observation next is [2.0, 44.0, 0.0, 0.0, 24.0, 22.87245565321694, -0.1377163136054401, 0.0, 1.0, 67295.42827057], 
processed observation next is [1.0, 0.8695652173913043, 0.518005540166205, 0.44, 0.0, 0.0, 0.5, 0.40603797110141154, 0.45409456213152, 0.0, 1.0, 0.32045442033604765], 
reward next is 0.9653, 
noisyNet noise sample is [array([-1.2238169], dtype=float32), 0.57891357]. 
=============================================
[2019-04-07 18:24:20,741] A3C_AGENT_WORKER-Thread-13 INFO:Local step 116000, global step 1852555: loss 0.3335
[2019-04-07 18:24:20,742] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 116000, global step 1852555: learning rate 0.0000
[2019-04-07 18:24:25,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:24:25,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:24:25,137] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run42
[2019-04-07 18:24:25,763] A3C_AGENT_WORKER-Thread-16 INFO:Local step 116000, global step 1853462: loss 0.3407
[2019-04-07 18:24:25,767] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 116000, global step 1853463: learning rate 0.0000
[2019-04-07 18:24:26,627] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:24:26,627] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:24:26,666] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run42
[2019-04-07 18:24:28,959] A3C_AGENT_WORKER-Thread-20 INFO:Local step 115000, global step 1853917: loss 25.6351
[2019-04-07 18:24:28,967] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 115000, global step 1853917: learning rate 0.0000
[2019-04-07 18:24:29,619] A3C_AGENT_WORKER-Thread-17 INFO:Local step 115500, global step 1854006: loss 0.6836
[2019-04-07 18:24:29,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 115500, global step 1854006: learning rate 0.0000
[2019-04-07 18:24:30,073] A3C_AGENT_WORKER-Thread-2 INFO:Local step 115000, global step 1854061: loss 25.8030
[2019-04-07 18:24:30,073] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 115000, global step 1854061: learning rate 0.0000
[2019-04-07 18:24:30,220] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:24:30,220] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:24:30,224] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run42
[2019-04-07 18:24:34,970] A3C_AGENT_WORKER-Thread-5 INFO:Local step 115000, global step 1854787: loss 25.7756
[2019-04-07 18:24:34,970] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 115000, global step 1854787: learning rate 0.0000
[2019-04-07 18:24:35,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:24:35,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:24:35,052] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run42
[2019-04-07 18:24:35,614] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.5361700e-23 5.3445442e-20 1.5457944e-25 3.0195064e-18 1.6361175e-20
 1.0000000e+00 2.3799516e-16 1.2276285e-18], sum to 1.0000
[2019-04-07 18:24:35,624] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3936
[2019-04-07 18:24:35,694] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.4, 80.0, 111.0, 781.5, 24.0, 24.66840786267023, 0.1480053185032081, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3236400.0000, 
sim time next is 3238200.0000, 
raw observation next is [-2.2, 75.5, 113.0, 811.0, 24.0, 24.52651398189222, 0.1338181423062676, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4016620498614959, 0.755, 0.37666666666666665, 0.8961325966850828, 0.5, 0.5438761651576849, 0.5446060474354225, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1741146], dtype=float32), 0.40739247]. 
=============================================
[2019-04-07 18:24:36,408] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.05975140e-25 1.60436650e-22 3.49549159e-27 2.12859066e-20
 6.87297272e-23 1.00000000e+00 1.12190415e-17 4.79932389e-20], sum to 1.0000
[2019-04-07 18:24:36,408] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6301
[2019-04-07 18:24:36,461] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 100.0, 0.0, 0.0, 24.0, 23.50439758277746, -0.1126963155788753, 0.0, 1.0, 58742.10748341997], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3133800.0000, 
sim time next is 3135600.0000, 
raw observation next is [6.0, 100.0, 0.0, 0.0, 24.0, 23.54892627182743, -0.09655859297361842, 0.0, 1.0, 34148.77670086454], 
processed observation next is [1.0, 0.30434782608695654, 0.6288088642659281, 1.0, 0.0, 0.0, 0.5, 0.4624105226522858, 0.4678138023421272, 0.0, 1.0, 0.16261322238506923], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0070925], dtype=float32), 0.083871216]. 
=============================================
[2019-04-07 18:24:45,861] A3C_AGENT_WORKER-Thread-4 INFO:Local step 116000, global step 1856321: loss 0.3429
[2019-04-07 18:24:45,878] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 116000, global step 1856321: learning rate 0.0000
[2019-04-07 18:24:51,113] A3C_AGENT_WORKER-Thread-11 INFO:Local step 115000, global step 1857155: loss 26.1157
[2019-04-07 18:24:51,114] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 115000, global step 1857155: learning rate 0.0000
[2019-04-07 18:24:53,467] A3C_AGENT_WORKER-Thread-15 INFO:Local step 115000, global step 1857511: loss 25.8981
[2019-04-07 18:24:53,468] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 115000, global step 1857511: learning rate 0.0000
[2019-04-07 18:24:55,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:24:55,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:24:55,029] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run42
[2019-04-07 18:25:08,182] A3C_AGENT_WORKER-Thread-17 INFO:Local step 116000, global step 1859732: loss 0.2956
[2019-04-07 18:25:08,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 116000, global step 1859732: learning rate 0.0000
[2019-04-07 18:25:09,858] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-07 18:25:09,858] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:25:09,859] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:25:09,870] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:25:09,871] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:25:09,875] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:25:09,876] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:25:09,878] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run94
[2019-04-07 18:25:09,897] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run94
[2019-04-07 18:25:09,924] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run94
[2019-04-07 18:27:38,880] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 18:27:54,009] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 18:27:58,933] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 18:27:59,959] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1860000, evaluation results [1860000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 18:28:00,319] A3C_AGENT_WORKER-Thread-20 INFO:Local step 115500, global step 1860079: loss 0.6486
[2019-04-07 18:28:00,320] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 115500, global step 1860079: learning rate 0.0000
[2019-04-07 18:28:00,576] A3C_AGENT_WORKER-Thread-2 INFO:Local step 115500, global step 1860116: loss 0.6440
[2019-04-07 18:28:00,582] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 115500, global step 1860117: learning rate 0.0000
[2019-04-07 18:28:04,919] A3C_AGENT_WORKER-Thread-5 INFO:Local step 115500, global step 1860807: loss 0.6953
[2019-04-07 18:28:04,926] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 115500, global step 1860807: learning rate 0.0000
[2019-04-07 18:28:06,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:28:06,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:28:06,776] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run42
[2019-04-07 18:28:08,319] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3570628e-22 7.5444404e-19 2.6690727e-23 4.9732754e-18 7.4688399e-20
 1.0000000e+00 4.2588695e-14 1.8282690e-17], sum to 1.0000
[2019-04-07 18:28:08,319] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9850
[2019-04-07 18:28:08,367] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 39.0, 0.0, 0.0, 24.0, 23.5256441591222, 0.000901250893392283, 0.0, 1.0, 31451.157029570062], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4150800.0000, 
sim time next is 4152600.0000, 
raw observation next is [-1.5, 42.5, 0.0, 0.0, 24.0, 23.47912885047186, -0.007356715435244386, 0.0, 1.0, 45814.34745460638], 
processed observation next is [0.0, 0.043478260869565216, 0.4210526315789474, 0.425, 0.0, 0.0, 0.5, 0.45659407087265497, 0.49754776152158525, 0.0, 1.0, 0.21816355930764944], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5854559], dtype=float32), -0.35929742]. 
=============================================
[2019-04-07 18:28:19,524] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4262906e-20 2.5295774e-20 1.2253602e-24 3.9378444e-20 7.1788744e-21
 1.0000000e+00 6.8831816e-15 1.1710767e-17], sum to 1.0000
[2019-04-07 18:28:19,525] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5208
[2019-04-07 18:28:19,724] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 76.0, 14.5, 0.0, 24.0, 23.44995315031392, -0.1962514355064577, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 720000.0000, 
sim time next is 721800.0000, 
raw observation next is [-2.3, 76.0, 29.0, 0.0, 24.0, 23.40379348058244, -0.2005983063478224, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3988919667590028, 0.76, 0.09666666666666666, 0.0, 0.5, 0.45031612338187, 0.43313389788405915, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6064384], dtype=float32), 0.21534227]. 
=============================================
[2019-04-07 18:28:21,777] A3C_AGENT_WORKER-Thread-11 INFO:Local step 115500, global step 1863517: loss 0.7051
[2019-04-07 18:28:21,777] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 115500, global step 1863517: learning rate 0.0000
[2019-04-07 18:28:22,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7339227e-19 1.9112637e-18 8.0212929e-23 2.3112909e-16 8.3529417e-19
 1.0000000e+00 1.9699387e-13 2.5772216e-16], sum to 1.0000
[2019-04-07 18:28:22,921] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0151
[2019-04-07 18:28:22,974] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.0, 63.0, 0.0, 0.0, 24.0, 22.97134097991919, -0.1841321521937596, 0.0, 1.0, 44734.59085655055], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3987000.0000, 
sim time next is 3988800.0000, 
raw observation next is [-12.0, 63.0, 0.0, 0.0, 24.0, 22.89161245782837, -0.2107191391855446, 0.0, 1.0, 44700.939687310565], 
processed observation next is [1.0, 0.17391304347826086, 0.13019390581717452, 0.63, 0.0, 0.0, 0.5, 0.4076343714856974, 0.4297602869381518, 0.0, 1.0, 0.21286161755862174], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1709677], dtype=float32), 0.3800132]. 
=============================================
[2019-04-07 18:28:23,316] A3C_AGENT_WORKER-Thread-15 INFO:Local step 115500, global step 1863777: loss 0.7586
[2019-04-07 18:28:23,323] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 115500, global step 1863779: learning rate 0.0000
[2019-04-07 18:28:27,463] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2438890e-23 3.6422006e-21 1.2792618e-25 6.4927048e-20 7.1891472e-22
 1.0000000e+00 3.5317383e-17 7.3071915e-19], sum to 1.0000
[2019-04-07 18:28:27,471] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6047
[2019-04-07 18:28:27,553] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.8, 75.0, 0.0, 0.0, 24.0, 23.09982403664581, -0.2442847007688024, 0.0, 1.0, 42490.56530090143], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 705600.0000, 
sim time next is 707400.0000, 
raw observation next is [-2.55, 75.5, 0.0, 0.0, 24.0, 23.1446701207751, -0.2333164518914413, 0.0, 1.0, 42438.20897829771], 
processed observation next is [1.0, 0.17391304347826086, 0.3919667590027701, 0.755, 0.0, 0.0, 0.5, 0.42872251006459167, 0.42222784936951957, 0.0, 1.0, 0.2020867094204653], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.65770185], dtype=float32), 1.367023]. 
=============================================
[2019-04-07 18:28:39,025] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2974965e-25 1.7657662e-22 1.5890976e-28 1.1390303e-21 7.8911184e-24
 1.0000000e+00 6.6055062e-18 6.6509799e-22], sum to 1.0000
[2019-04-07 18:28:39,025] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0425
[2019-04-07 18:28:39,117] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.1, 76.5, 0.0, 0.0, 24.0, 23.87098691626638, 0.1176431028791462, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1042200.0000, 
sim time next is 1044000.0000, 
raw observation next is [13.8, 78.0, 0.0, 0.0, 24.0, 23.69167111814352, 0.1117869546597689, 0.0, 1.0, 55171.79594043067], 
processed observation next is [1.0, 0.08695652173913043, 0.844875346260388, 0.78, 0.0, 0.0, 0.5, 0.4743059265119601, 0.537262318219923, 0.0, 1.0, 0.2627228378115746], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.99696034], dtype=float32), 0.37364283]. 
=============================================
[2019-04-07 18:28:39,137] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[112.91525 ]
 [112.75724 ]
 [112.76288 ]
 [112.732086]
 [113.14333 ]], R is [[113.24694061]
 [113.11447144]
 [112.98332977]
 [112.85350037]
 [112.72496796]].
[2019-04-07 18:28:39,809] A3C_AGENT_WORKER-Thread-20 INFO:Local step 116000, global step 1866741: loss 0.3256
[2019-04-07 18:28:39,814] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 116000, global step 1866741: learning rate 0.0000
[2019-04-07 18:28:39,819] A3C_AGENT_WORKER-Thread-2 INFO:Local step 116000, global step 1866743: loss 0.3055
[2019-04-07 18:28:39,821] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 116000, global step 1866743: learning rate 0.0000
[2019-04-07 18:28:44,430] A3C_AGENT_WORKER-Thread-5 INFO:Local step 116000, global step 1867731: loss 0.3938
[2019-04-07 18:28:44,431] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 116000, global step 1867731: learning rate 0.0000
[2019-04-07 18:28:48,330] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:28:48,330] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:28:48,339] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run42
[2019-04-07 18:28:48,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:28:48,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:28:48,733] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run42
[2019-04-07 18:28:52,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:28:52,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:28:53,001] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run42
[2019-04-07 18:29:01,435] A3C_AGENT_WORKER-Thread-11 INFO:Local step 116000, global step 1870533: loss 0.3338
[2019-04-07 18:29:01,435] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 116000, global step 1870533: learning rate 0.0000
[2019-04-07 18:29:02,813] A3C_AGENT_WORKER-Thread-15 INFO:Local step 116000, global step 1870783: loss 0.3894
[2019-04-07 18:29:02,814] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 116000, global step 1870783: learning rate 0.0000
[2019-04-07 18:29:10,639] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:29:10,639] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:29:10,643] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run42
[2019-04-07 18:29:11,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:29:11,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:29:11,893] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run42
[2019-04-07 18:29:16,019] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.6294034e-24 4.7627882e-22 2.8246530e-26 1.1316817e-19 8.7269833e-23
 1.0000000e+00 2.9574592e-17 7.4152372e-21], sum to 1.0000
[2019-04-07 18:29:16,019] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6817
[2019-04-07 18:29:16,050] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 95.0, 93.0, 0.0, 24.0, 24.15850718648234, 0.09484922926540483, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1425600.0000, 
sim time next is 1427400.0000, 
raw observation next is [0.25, 93.5, 96.0, 0.0, 24.0, 24.14350892456662, 0.06073258223151867, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.46952908587257625, 0.935, 0.32, 0.0, 0.5, 0.5119590770472184, 0.5202441940771729, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17050987], dtype=float32), 0.3664571]. 
=============================================
[2019-04-07 18:29:27,673] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:29:27,673] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:29:27,676] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run43
[2019-04-07 18:29:42,497] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3702762e-22 5.0565018e-21 3.8056161e-25 1.0811448e-18 4.5291473e-20
 1.0000000e+00 1.4626991e-15 2.7299684e-18], sum to 1.0000
[2019-04-07 18:29:42,498] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8025
[2019-04-07 18:29:42,540] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 77.0, 0.0, 0.0, 24.0, 23.63290218226885, -0.02124577777095077, 0.0, 1.0, 15839.277382060907], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3808800.0000, 
sim time next is 3810600.0000, 
raw observation next is [-4.0, 74.0, 0.0, 0.0, 24.0, 23.51090868743003, -0.05612864787865466, 0.0, 1.0, 47861.77562796402], 
processed observation next is [1.0, 0.08695652173913043, 0.3518005540166205, 0.74, 0.0, 0.0, 0.5, 0.4592423906191693, 0.4812904507071151, 0.0, 1.0, 0.22791321727601915], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24950784], dtype=float32), 0.66083354]. 
=============================================
[2019-04-07 18:30:03,795] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1231642e-21 2.3324548e-20 2.3881372e-23 4.9794045e-19 5.6576614e-20
 1.0000000e+00 1.4255001e-15 1.1181735e-18], sum to 1.0000
[2019-04-07 18:30:03,795] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6807
[2019-04-07 18:30:03,835] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.55, 76.5, 0.0, 0.0, 24.0, 22.77692972743842, -0.2850807278725085, 0.0, 1.0, 46153.106150008745], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1906200.0000, 
sim time next is 1908000.0000, 
raw observation next is [-7.8, 78.0, 0.0, 0.0, 24.0, 22.77530522760812, -0.2926849311460312, 0.0, 1.0, 46007.43178586505], 
processed observation next is [1.0, 0.08695652173913043, 0.24653739612188366, 0.78, 0.0, 0.0, 0.5, 0.39794210230067656, 0.40243835628465624, 0.0, 1.0, 0.21908300850411927], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8205831], dtype=float32), -1.234669]. 
=============================================
[2019-04-07 18:30:03,838] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[94.23934]
 [94.29625]
 [95.33565]
 [95.02896]
 [93.94821]], R is [[93.84176636]
 [93.90335083]
 [93.96431732]
 [94.02467346]
 [94.08442688]].
[2019-04-07 18:30:08,011] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-07 18:30:08,011] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:30:08,012] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:30:08,016] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run95
[2019-04-07 18:30:08,038] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:30:08,050] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:30:08,055] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run95
[2019-04-07 18:30:08,071] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:30:08,072] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:30:08,080] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run95
[2019-04-07 18:32:33,154] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 18:32:51,650] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 18:32:53,448] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 18:32:54,471] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1880000, evaluation results [1880000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 18:32:55,088] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9500135e-28 1.3660446e-24 3.7905115e-29 4.8838666e-23 6.2750947e-25
 1.0000000e+00 2.4368051e-19 4.7374558e-22], sum to 1.0000
[2019-04-07 18:32:55,088] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5320
[2019-04-07 18:32:55,121] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [11.05, 89.5, 96.0, 0.0, 24.0, 24.71195535881979, 0.1963364487916653, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 988200.0000, 
sim time next is 990000.0000, 
raw observation next is [11.6, 86.0, 108.0, 0.0, 24.0, 24.82328961107969, 0.2155691770383143, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.7839335180055402, 0.86, 0.36, 0.0, 0.5, 0.5686074675899743, 0.5718563923461047, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.21095642], dtype=float32), 1.0870686]. 
=============================================
[2019-04-07 18:32:55,139] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[113.82243 ]
 [113.79603 ]
 [113.420685]
 [113.22198 ]
 [112.58341 ]], R is [[114.30075836]
 [114.15775299]
 [114.01617432]
 [113.87601471]
 [113.73725891]].
[2019-04-07 18:32:57,980] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8484672e-23 5.5197512e-21 2.4020132e-25 4.9258626e-19 1.1761551e-22
 1.0000000e+00 6.5246726e-16 5.8399525e-19], sum to 1.0000
[2019-04-07 18:32:57,980] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9264
[2019-04-07 18:32:58,003] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.5, 48.5, 109.0, 764.0, 24.0, 24.88230762084509, 0.2208015222862647, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3407400.0000, 
sim time next is 3409200.0000, 
raw observation next is [3.0, 49.0, 112.0, 784.0, 24.0, 25.01612421089506, 0.2284104519901944, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.5457063711911359, 0.49, 0.37333333333333335, 0.8662983425414365, 0.5, 0.5846770175745885, 0.5761368173300648, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.30392843], dtype=float32), 0.9367599]. 
=============================================
[2019-04-07 18:33:01,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:33:01,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:33:01,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run43
[2019-04-07 18:33:07,104] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.6421544e-24 2.0221696e-21 3.5463430e-26 5.3909610e-21 5.5587525e-23
 1.0000000e+00 1.4166470e-16 6.6966814e-21], sum to 1.0000
[2019-04-07 18:33:07,105] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0053
[2019-04-07 18:33:07,150] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 100.0, 0.0, 0.0, 24.0, 24.15146293840699, 0.2565920635660581, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3182400.0000, 
sim time next is 3184200.0000, 
raw observation next is [3.0, 100.0, 0.0, 0.0, 24.0, 23.90598134479505, 0.2060884568266055, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.5457063711911359, 1.0, 0.0, 0.0, 0.5, 0.4921651120662543, 0.5686961522755352, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.845786], dtype=float32), -0.40186527]. 
=============================================
[2019-04-07 18:33:23,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0866049e-23 1.9221781e-20 6.6027367e-25 2.6442809e-18 5.8145829e-21
 1.0000000e+00 2.4958239e-16 2.6048732e-19], sum to 1.0000
[2019-04-07 18:33:23,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8760
[2019-04-07 18:33:23,994] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 79.0, 75.0, 0.0, 24.0, 23.50242937298667, -0.1038950696808327, 1.0, 1.0, 34790.6017839989], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 828000.0000, 
sim time next is 829800.0000, 
raw observation next is [-3.9, 82.5, 59.0, 0.0, 24.0, 23.98364441646405, -0.05896632692284576, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3545706371191136, 0.825, 0.19666666666666666, 0.0, 0.5, 0.49863703470533743, 0.48034455769238477, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.21031901], dtype=float32), -1.0665845]. 
=============================================
[2019-04-07 18:33:24,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:33:24,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:33:24,060] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run43
[2019-04-07 18:33:43,323] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0452202e-19 1.4742764e-17 2.2429277e-21 3.4174045e-16 1.5719414e-17
 1.0000000e+00 3.6137180e-14 4.9325831e-16], sum to 1.0000
[2019-04-07 18:33:43,323] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0001
[2019-04-07 18:33:43,396] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.6, 49.0, 0.0, 0.0, 24.0, 22.04272477203441, -0.4570458392370958, 0.0, 1.0, 46810.54773059485], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 442800.0000, 
sim time next is 444600.0000, 
raw observation next is [-10.9, 50.5, 0.0, 0.0, 24.0, 21.99765294801396, -0.4802639305967254, 0.0, 1.0, 46874.76437658638], 
processed observation next is [1.0, 0.13043478260869565, 0.16066481994459833, 0.505, 0.0, 0.0, 0.5, 0.3331377456678301, 0.33991202313442487, 0.0, 1.0, 0.2232131636980304], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6800692], dtype=float32), -1.1182172]. 
=============================================
[2019-04-07 18:33:51,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.1898648e-23 2.6480029e-20 5.0062444e-25 2.6371688e-18 9.2664399e-21
 1.0000000e+00 2.0285575e-15 5.0513594e-19], sum to 1.0000
[2019-04-07 18:33:51,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3844
[2019-04-07 18:33:51,244] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 60.0, 117.0, 822.0, 24.0, 24.8480953303693, 0.1120643195314032, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3843000.0000, 
sim time next is 3844800.0000, 
raw observation next is [-1.0, 60.0, 117.0, 828.5, 24.0, 24.76092826504495, 0.1071125314151607, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4349030470914128, 0.6, 0.39, 0.9154696132596685, 0.5, 0.5634106887537458, 0.5357041771383869, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.18081181], dtype=float32), 0.9153115]. 
=============================================
[2019-04-07 18:34:04,356] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2527469e-20 2.7993490e-18 2.8256717e-22 2.8752838e-17 5.0127211e-18
 1.0000000e+00 2.3878748e-14 1.5567728e-16], sum to 1.0000
[2019-04-07 18:34:04,356] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2506
[2019-04-07 18:34:04,496] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.0, 42.0, 0.0, 0.0, 24.0, 23.34412565878754, -0.1352676713896013, 0.0, 1.0, 54852.50122157626], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 417600.0000, 
sim time next is 419400.0000, 
raw observation next is [-10.3, 44.5, 0.0, 0.0, 24.0, 23.29686304917654, -0.1436610011428048, 0.0, 1.0, 75755.58865926276], 
processed observation next is [1.0, 0.8695652173913043, 0.1772853185595568, 0.445, 0.0, 0.0, 0.5, 0.44140525409804504, 0.4521129996190651, 0.0, 1.0, 0.3607408983774417], 
reward next is 0.9250, 
noisyNet noise sample is [array([0.34282398], dtype=float32), 0.14452237]. 
=============================================
[2019-04-07 18:34:10,421] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.8488781e-24 1.1227795e-21 3.9533499e-26 9.5277482e-21 4.2829587e-21
 1.0000000e+00 4.4337989e-17 1.9426191e-20], sum to 1.0000
[2019-04-07 18:34:10,421] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6011
[2019-04-07 18:34:10,494] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.5, 77.0, 100.0, 675.0, 24.0, 24.54428334643686, 0.1108185894016948, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3749400.0000, 
sim time next is 3751200.0000, 
raw observation next is [-3.0, 77.0, 105.5, 722.0, 24.0, 24.69038272221522, 0.1503818252244234, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.77, 0.3516666666666667, 0.7977900552486188, 0.5, 0.5575318935179349, 0.5501272750748077, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6310127], dtype=float32), 1.696226]. 
=============================================
[2019-04-07 18:34:11,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:34:11,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:34:11,396] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run43
[2019-04-07 18:34:19,777] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0501538e-22 1.3739231e-20 2.1834482e-25 4.1980062e-20 1.0721037e-21
 1.0000000e+00 1.8052338e-16 1.4858378e-19], sum to 1.0000
[2019-04-07 18:34:19,777] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6382
[2019-04-07 18:34:19,930] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 80.5, 0.0, 0.0, 24.0, 23.17343868270534, -0.06477015092408668, 0.0, 1.0, 115945.8211321362], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1974600.0000, 
sim time next is 1976400.0000, 
raw observation next is [-5.6, 78.0, 0.0, 0.0, 24.0, 23.4629624600413, -0.03165508875031064, 0.0, 1.0, 41424.74451326194], 
processed observation next is [1.0, 0.9130434782608695, 0.30747922437673136, 0.78, 0.0, 0.0, 0.5, 0.45524687167010836, 0.48944830374989645, 0.0, 1.0, 0.19726068815839018], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.9857389], dtype=float32), -0.16116503]. 
=============================================
[2019-04-07 18:34:25,910] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9459526e-21 5.6001611e-19 1.0666374e-21 3.2336068e-17 2.2353706e-19
 1.0000000e+00 5.3959565e-15 6.1717322e-17], sum to 1.0000
[2019-04-07 18:34:25,910] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7045
[2019-04-07 18:34:25,961] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-12.9, 83.0, 0.0, 0.0, 24.0, 22.63688831259336, -0.2536142527011677, 0.0, 1.0, 45531.640217738575], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2689200.0000, 
sim time next is 2691000.0000, 
raw observation next is [-13.95, 87.0, 0.0, 0.0, 24.0, 22.43580661449646, -0.2938135227602069, 0.0, 1.0, 45539.46320106407], 
processed observation next is [1.0, 0.13043478260869565, 0.07617728531855956, 0.87, 0.0, 0.0, 0.5, 0.36965055120803836, 0.4020621590799311, 0.0, 1.0, 0.21685458667173366], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.27353272], dtype=float32), 0.5040262]. 
=============================================
[2019-04-07 18:34:25,967] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[89.72399]
 [90.38522]
 [91.10444]
 [92.06776]
 [92.85058]], R is [[89.06916046]
 [89.1784668 ]
 [89.28668213]
 [89.39381409]
 [89.49987793]].
[2019-04-07 18:34:32,502] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:34:32,502] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:34:32,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run43
[2019-04-07 18:34:45,710] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:34:45,710] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:34:45,718] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run43
[2019-04-07 18:34:46,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:34:46,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:34:46,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run43
[2019-04-07 18:34:46,771] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:34:46,771] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:34:46,775] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run43
[2019-04-07 18:34:52,494] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-07 18:34:52,497] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:34:52,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:34:52,517] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:34:52,517] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:34:52,519] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run96
[2019-04-07 18:34:52,546] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:34:52,547] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:34:52,551] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run96
[2019-04-07 18:34:52,577] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run96
[2019-04-07 18:35:12,408] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.12518296], dtype=float32), 0.17098023]
[2019-04-07 18:35:12,408] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation this: [2.7849130845, 86.88242755, 0.0, 0.0, 24.0, 23.37037794297926, -0.138524844381476, 0.0, 1.0, 44944.78591334647]
[2019-04-07 18:35:12,409] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-07 18:35:12,410] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Softmax [3.5720209e-24 6.5014473e-22 2.1655135e-26 1.2674228e-20 2.1256512e-22
 1.0000000e+00 4.3182223e-17 5.9792156e-20], sampled 0.9858346230618618
[2019-04-07 18:37:16,645] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 18:37:33,104] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 18:37:36,327] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 18:37:37,350] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1900000, evaluation results [1900000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 18:37:42,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:37:42,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:37:42,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run43
[2019-04-07 18:37:43,580] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.87400720e-25 2.05092930e-21 2.47599202e-26 1.06418725e-20
 2.97955566e-22 1.00000000e+00 5.23426868e-16 2.74529613e-20], sum to 1.0000
[2019-04-07 18:37:43,588] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2021
[2019-04-07 18:37:43,707] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.15, 91.0, 0.0, 0.0, 24.0, 23.36218475361684, -0.09668601869525562, 0.0, 1.0, 41986.86118672096], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 91800.0000, 
sim time next is 93600.0000, 
raw observation next is [-1.7, 91.0, 0.0, 0.0, 24.0, 23.28309240609698, -0.1037605079569552, 0.0, 1.0, 42543.395456103404], 
processed observation next is [1.0, 0.08695652173913043, 0.4155124653739613, 0.91, 0.0, 0.0, 0.5, 0.44025770050808166, 0.46541316401434824, 0.0, 1.0, 0.20258759741001622], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.58479744], dtype=float32), -0.7523571]. 
=============================================
[2019-04-07 18:37:53,448] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7853864e-24 1.4752009e-22 7.0409141e-27 3.3856959e-21 3.0362368e-22
 1.0000000e+00 7.6347196e-17 1.0141654e-20], sum to 1.0000
[2019-04-07 18:37:53,448] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8650
[2019-04-07 18:37:53,504] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 24.0, 23.45212699307942, 0.02165158443279206, 0.0, 1.0, 39923.42823632017], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1729800.0000, 
sim time next is 1731600.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 24.0, 23.48417802282731, 0.01537952052368152, 0.0, 1.0, 30375.456004818454], 
processed observation next is [0.0, 0.043478260869565216, 0.4764542936288089, 0.92, 0.0, 0.0, 0.5, 0.4570148352356093, 0.5051265068412272, 0.0, 1.0, 0.1446450285943736], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9941607], dtype=float32), -0.6327944]. 
=============================================
[2019-04-07 18:37:54,482] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0932365e-21 1.9155608e-20 4.6121644e-24 3.1142714e-20 3.0055507e-21
 1.0000000e+00 5.6249626e-16 8.6426193e-19], sum to 1.0000
[2019-04-07 18:37:54,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8575
[2019-04-07 18:37:54,554] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.0, 65.0, 0.0, 0.0, 24.0, 23.37024094116181, -0.05557187327100645, 0.0, 1.0, 44183.161973005954], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3560400.0000, 
sim time next is 3562200.0000, 
raw observation next is [-5.5, 67.5, 0.0, 0.0, 24.0, 23.27089569942666, -0.05824196619048146, 0.0, 1.0, 51322.71380559388], 
processed observation next is [0.0, 0.21739130434782608, 0.3102493074792244, 0.675, 0.0, 0.0, 0.5, 0.439241308285555, 0.4805860112698395, 0.0, 1.0, 0.24439387526473275], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.29636535], dtype=float32), -0.7325909]. 
=============================================
[2019-04-07 18:37:56,293] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:37:56,293] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:37:56,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run43
[2019-04-07 18:38:06,946] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6810338e-22 4.7800064e-22 4.5883133e-25 4.0990258e-19 1.3487830e-21
 1.0000000e+00 5.1608672e-17 1.2472939e-18], sum to 1.0000
[2019-04-07 18:38:06,946] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6367
[2019-04-07 18:38:07,062] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 74.0, 91.0, 447.0, 24.0, 23.63691701654698, 0.02804591866372868, 1.0, 1.0, 8317.910322593998], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3832200.0000, 
sim time next is 3834000.0000, 
raw observation next is [-4.0, 71.0, 96.0, 563.5, 24.0, 24.32905846205117, 0.09754188196446052, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3518005540166205, 0.71, 0.32, 0.6226519337016575, 0.5, 0.5274215385042641, 0.5325139606548202, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.42089918], dtype=float32), -0.8232112]. 
=============================================
[2019-04-07 18:38:07,067] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[99.6066  ]
 [99.093155]
 [98.507675]
 [97.66391 ]
 [97.63783 ]], R is [[99.80228424]
 [99.80426025]
 [99.80622101]
 [99.80815887]
 [99.81008148]].
[2019-04-07 18:38:14,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:38:14,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:38:14,068] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run43
[2019-04-07 18:38:32,245] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.4034189e-23 2.6836049e-20 7.7519260e-26 1.1173671e-19 1.8190338e-21
 1.0000000e+00 4.8373263e-16 5.9708533e-19], sum to 1.0000
[2019-04-07 18:38:32,245] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5239
[2019-04-07 18:38:32,275] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.7, 97.0, 100.5, 0.0, 24.0, 24.02267391883382, -0.04627113910242343, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 907200.0000, 
sim time next is 909000.0000, 
raw observation next is [3.25, 95.0, 104.0, 0.0, 24.0, 23.96089753212429, -0.0571941093680626, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5526315789473685, 0.95, 0.3466666666666667, 0.0, 0.5, 0.4967414610103574, 0.48093529687731246, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8351219], dtype=float32), 0.10842539]. 
=============================================
[2019-04-07 18:38:32,311] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[104.628  ]
 [103.62234]
 [102.70113]
 [102.1866 ]
 [102.03167]], R is [[105.20903778]
 [105.1569519 ]
 [105.10538483]
 [105.05432892]
 [105.00378418]].
[2019-04-07 18:38:58,825] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0493286e-26 6.1152813e-23 7.8513736e-29 3.2152469e-22 1.4841573e-24
 1.0000000e+00 3.7848523e-19 4.6775476e-23], sum to 1.0000
[2019-04-07 18:38:58,825] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2266
[2019-04-07 18:38:58,870] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.7, 88.0, 0.0, 0.0, 24.0, 23.63042941058681, 0.01132851860607889, 1.0, 1.0, 13333.203064145586], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 977400.0000, 
sim time next is 979200.0000, 
raw observation next is [9.4, 93.0, 13.5, 0.0, 24.0, 23.58228006088011, 0.001195022497471332, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.7229916897506927, 0.93, 0.045, 0.0, 0.5, 0.4651900050733424, 0.5003983408324905, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.36176434], dtype=float32), -0.62569964]. 
=============================================
[2019-04-07 18:39:03,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:39:03,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:39:03,099] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run43
[2019-04-07 18:39:04,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:39:04,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:39:04,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run43
[2019-04-07 18:39:05,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:39:05,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:39:05,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run43
[2019-04-07 18:39:12,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7316358e-24 1.4938278e-20 1.6907616e-26 1.3752122e-21 4.1155020e-22
 1.0000000e+00 3.1308469e-16 2.7660982e-21], sum to 1.0000
[2019-04-07 18:39:12,976] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9391
[2019-04-07 18:39:13,007] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.7, 68.0, 157.5, 112.0, 24.0, 24.74617291193058, 0.2499255746437652, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1591200.0000, 
sim time next is 1593000.0000, 
raw observation next is [8.55, 64.5, 200.0, 88.0, 24.0, 24.95292014975103, 0.2826435163520918, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.6994459833795015, 0.645, 0.6666666666666666, 0.09723756906077348, 0.5, 0.5794100124792525, 0.5942145054506972, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.12517206], dtype=float32), 1.099203]. 
=============================================
[2019-04-07 18:39:13,011] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[107.097786]
 [107.05823 ]
 [107.13523 ]
 [106.744545]
 [106.70975 ]], R is [[106.8479538 ]
 [106.77947235]
 [106.71167755]
 [106.64456177]
 [106.57811737]].
[2019-04-07 18:39:25,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:39:25,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:39:25,102] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run43
[2019-04-07 18:39:29,587] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0678810e-25 1.1321371e-23 5.9627234e-28 3.2750476e-23 3.8736774e-26
 1.0000000e+00 5.8029305e-20 7.6617751e-22], sum to 1.0000
[2019-04-07 18:39:29,587] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8614
[2019-04-07 18:39:29,643] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.95, 79.5, 0.0, 0.0, 24.0, 24.61529320971017, 0.1869219350464975, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1013400.0000, 
sim time next is 1015200.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 24.0, 24.21620251887738, 0.1203270049309181, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.8614958448753465, 0.81, 0.0, 0.0, 0.5, 0.5180168765731151, 0.5401090016436394, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2063547], dtype=float32), -0.7325539]. 
=============================================
[2019-04-07 18:39:29,946] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:39:29,946] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:39:29,950] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run43
[2019-04-07 18:39:37,558] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.0122974e-24 1.8589984e-21 4.5666611e-25 7.6120249e-20 5.1054560e-23
 1.0000000e+00 6.2802480e-16 3.4716505e-20], sum to 1.0000
[2019-04-07 18:39:37,558] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7046
[2019-04-07 18:39:37,595] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 24.0, 23.45597679942846, 0.02810646800461389, 0.0, 1.0, 109642.08967129175], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3452400.0000, 
sim time next is 3454200.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 24.0, 23.63159174496115, 0.05380656855731659, 0.0, 1.0, 29115.883962088832], 
processed observation next is [1.0, 1.0, 0.4903047091412743, 0.86, 0.0, 0.0, 0.5, 0.46929931208009573, 0.5179355228524388, 0.0, 1.0, 0.13864706648613728], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.13031818], dtype=float32), -0.117458954]. 
=============================================
[2019-04-07 18:39:41,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:39:41,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:39:41,268] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run44
[2019-04-07 18:39:42,746] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-07 18:39:42,761] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:39:42,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:39:42,788] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run97
[2019-04-07 18:39:42,812] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:39:42,814] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:39:42,815] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:39:42,819] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run97
[2019-04-07 18:39:42,842] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:39:42,849] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run97
[2019-04-07 18:42:10,874] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 18:42:25,566] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12507837], dtype=float32), 0.17130068]
[2019-04-07 18:42:25,567] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.0, 45.0, 0.0, 0.0, 24.0, 23.18432387544205, -0.0518837748524126, 0.0, 1.0, 145302.92592218707]
[2019-04-07 18:42:25,567] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 18:42:25,567] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [8.8608674e-22 9.9543083e-20 1.0632523e-23 1.3738406e-18 2.7797873e-20
 1.0000000e+00 1.7013947e-15 4.4239302e-18], sampled 0.32608281770709535
[2019-04-07 18:42:29,097] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 18:42:33,621] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 18:42:34,644] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1920000, evaluation results [1920000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 18:42:35,088] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4054622e-21 1.6490073e-19 6.2965615e-23 9.3840927e-18 1.2013510e-19
 1.0000000e+00 2.6544319e-15 1.4371175e-17], sum to 1.0000
[2019-04-07 18:42:35,088] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5364
[2019-04-07 18:42:35,145] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [7.2, 96.0, 0.0, 0.0, 24.0, 20.47841048627283, -0.7542229061449767, 0.0, 1.0, 43072.738547725276], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 9000.0000, 
sim time next is 10800.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 24.0, 20.58943728148884, -0.7294043441150452, 0.0, 1.0, 42405.57484272158], 
processed observation next is [0.0, 0.13043478260869565, 0.662049861495845, 0.96, 0.0, 0.0, 0.5, 0.2157864401240701, 0.2568652186283183, 0.0, 1.0, 0.20193130877486468], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.256569], dtype=float32), -0.9184705]. 
=============================================
[2019-04-07 18:42:38,254] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.4234249e-22 7.9109370e-20 1.4557461e-23 3.6589848e-19 2.2440841e-20
 1.0000000e+00 7.5740384e-16 2.5068817e-17], sum to 1.0000
[2019-04-07 18:42:38,254] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1867
[2019-04-07 18:42:38,338] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 24.0, 23.1256989250085, -0.1935268740615446, 0.0, 1.0, 42339.918985846685], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1999800.0000, 
sim time next is 2001600.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 24.0, 23.0171266439678, -0.2195087345935919, 0.0, 1.0, 42216.87445635761], 
processed observation next is [1.0, 0.17391304347826086, 0.30747922437673136, 0.83, 0.0, 0.0, 0.5, 0.4180938869973166, 0.426830421802136, 0.0, 1.0, 0.2010327355064648], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5408747], dtype=float32), 1.615805]. 
=============================================
[2019-04-07 18:42:59,403] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2279958e-21 9.4454195e-21 3.3730316e-24 1.7300849e-18 4.4657892e-20
 1.0000000e+00 5.9937290e-16 6.6969725e-18], sum to 1.0000
[2019-04-07 18:42:59,404] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8825
[2019-04-07 18:42:59,600] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 53.0, 0.0, 0.0, 24.0, 23.24883185762052, -0.1076820458773353, 1.0, 1.0, 44905.6831833461], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 759600.0000, 
sim time next is 761400.0000, 
raw observation next is [-4.45, 55.5, 0.0, 0.0, 24.0, 23.21886493125773, -0.1510907761139799, 1.0, 1.0, 12563.05142077202], 
processed observation next is [1.0, 0.8260869565217391, 0.3393351800554017, 0.555, 0.0, 0.0, 0.5, 0.4349054109381442, 0.4496364079620067, 1.0, 1.0, 0.05982405438462867], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.62544316], dtype=float32), 0.20204987]. 
=============================================
[2019-04-07 18:43:16,792] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.32630773e-20 8.64858896e-19 8.00463408e-23 7.86073789e-18
 1.02919014e-19 1.00000000e+00 2.07327272e-14 5.18448394e-18], sum to 1.0000
[2019-04-07 18:43:16,792] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3901
[2019-04-07 18:43:16,899] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.5, 70.0, 117.0, 674.0, 24.0, 24.4295354471131, 0.07622527949898629, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2716200.0000, 
sim time next is 2718000.0000, 
raw observation next is [-9.0, 64.0, 114.5, 727.5, 24.0, 24.48118614871373, 0.09160561117466494, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.21329639889196678, 0.64, 0.38166666666666665, 0.8038674033149171, 0.5, 0.5400988457261441, 0.5305352037248884, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9988773], dtype=float32), 0.3239927]. 
=============================================
[2019-04-07 18:43:16,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[92.37819 ]
 [92.12545 ]
 [91.6904  ]
 [90.79559 ]
 [89.241165]], R is [[92.55038452]
 [92.62487793]
 [92.69863129]
 [92.77164459]
 [92.84392548]].
[2019-04-07 18:43:17,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:43:17,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:43:17,756] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run44
[2019-04-07 18:43:33,132] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3197864e-22 2.0647620e-20 1.1042834e-24 5.7710344e-19 1.5327562e-21
 1.0000000e+00 1.1328021e-16 1.8805631e-18], sum to 1.0000
[2019-04-07 18:43:33,132] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4167
[2019-04-07 18:43:33,161] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 74.0, 0.0, 0.0, 24.0, 23.78958965911031, 0.1039511120087825, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3792600.0000, 
sim time next is 3794400.0000, 
raw observation next is [-3.0, 77.0, 0.0, 0.0, 24.0, 23.64684892865994, 0.07944236340980147, 0.0, 1.0, 39536.66716542375], 
processed observation next is [1.0, 0.9565217391304348, 0.3795013850415513, 0.77, 0.0, 0.0, 0.5, 0.4705707440549949, 0.5264807878032671, 0.0, 1.0, 0.188269843644875], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0694373], dtype=float32), 0.100666486]. 
=============================================
[2019-04-07 18:43:37,517] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0642188e-23 1.8989579e-20 3.0747992e-26 1.4544439e-20 9.8569213e-22
 1.0000000e+00 1.4235920e-16 4.6958801e-20], sum to 1.0000
[2019-04-07 18:43:37,517] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0094
[2019-04-07 18:43:37,592] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 24.0, 23.45801929974365, 0.009689524909248334, 0.0, 1.0, 54948.73191444375], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3889800.0000, 
sim time next is 3891600.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 24.0, 23.49830528596996, 0.008013932969226964, 0.0, 1.0, 28156.988876628486], 
processed observation next is [1.0, 0.043478260869565216, 0.40720221606648205, 0.65, 0.0, 0.0, 0.5, 0.45819210716416325, 0.5026713109897424, 0.0, 1.0, 0.1340808994125166], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8229195], dtype=float32), -1.6766689]. 
=============================================
[2019-04-07 18:43:43,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:43:43,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:43:43,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run44
[2019-04-07 18:43:46,557] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.4311241e-21 3.6234264e-19 5.7235764e-24 7.1245640e-19 4.2325620e-20
 1.0000000e+00 1.2844964e-14 1.4423672e-18], sum to 1.0000
[2019-04-07 18:43:46,557] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7553
[2019-04-07 18:43:46,742] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.7, 83.0, 45.5, 0.0, 24.0, 23.52397359511966, -0.03336155638123023, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1760400.0000, 
sim time next is 1762200.0000, 
raw observation next is [-2.0, 85.0, 65.0, 0.0, 24.0, 23.30250703464714, -0.08481809313326467, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.40720221606648205, 0.85, 0.21666666666666667, 0.0, 0.5, 0.4418755862205949, 0.47172730228891174, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2192777], dtype=float32), -0.24315932]. 
=============================================
[2019-04-07 18:43:57,758] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8359882e-23 7.3085785e-21 2.8725954e-26 3.9823628e-20 6.9199585e-23
 1.0000000e+00 8.2534308e-17 5.2506194e-19], sum to 1.0000
[2019-04-07 18:43:57,758] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7396
[2019-04-07 18:43:57,855] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 24.0, 23.85885160348921, 0.1948201176443893, 0.0, 1.0, 67830.27814102407], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3531600.0000, 
sim time next is 3533400.0000, 
raw observation next is [-0.5, 75.0, 0.0, 0.0, 24.0, 24.12993212360826, 0.190527028984341, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.44875346260387816, 0.75, 0.0, 0.0, 0.5, 0.510827676967355, 0.563509009661447, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7308395], dtype=float32), -1.7716652]. 
=============================================
[2019-04-07 18:44:00,150] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3518455e-22 5.5276771e-20 5.2571569e-25 5.4242162e-20 1.3146066e-21
 1.0000000e+00 1.1821863e-16 1.4965498e-18], sum to 1.0000
[2019-04-07 18:44:00,151] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5855
[2019-04-07 18:44:00,223] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [9.0, 27.0, 0.0, 0.0, 24.0, 23.64784471005614, -0.07182912458289538, 0.0, 1.0, 22990.382968229023], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3646800.0000, 
sim time next is 3648600.0000, 
raw observation next is [9.5, 26.0, 0.0, 0.0, 24.0, 23.65180461454467, -0.07818922135708627, 0.0, 1.0, 18727.428328083402], 
processed observation next is [0.0, 0.21739130434782608, 0.7257617728531857, 0.26, 0.0, 0.0, 0.5, 0.47098371787872245, 0.47393692621430455, 0.0, 1.0, 0.08917823013373048], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.943379], dtype=float32), 0.12366036]. 
=============================================
[2019-04-07 18:44:08,213] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2735598e-24 1.5409572e-22 5.0415403e-27 2.5549861e-20 1.5848768e-22
 1.0000000e+00 9.6231764e-17 5.4753786e-20], sum to 1.0000
[2019-04-07 18:44:08,213] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4756
[2019-04-07 18:44:08,256] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 82.0, 19.0, 20.0, 24.0, 23.65875738091052, 0.03805811652586332, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1584000.0000, 
sim time next is 1585800.0000, 
raw observation next is [5.8, 79.0, 37.0, 35.0, 24.0, 23.78439324195352, 0.0900395925626497, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.6232686980609419, 0.79, 0.12333333333333334, 0.03867403314917127, 0.5, 0.48203277016279333, 0.5300131975208832, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.34287906], dtype=float32), 1.0969005]. 
=============================================
[2019-04-07 18:44:31,290] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:44:31,290] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:44:31,294] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run44
[2019-04-07 18:44:34,341] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.41959168e-21 1.16138161e-19 4.00207636e-24 8.07537141e-20
 1.24093304e-20 1.00000000e+00 4.60734731e-16 6.85199196e-19], sum to 1.0000
[2019-04-07 18:44:34,341] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8226
[2019-04-07 18:44:34,469] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 86.0, 49.0, 0.0, 24.0, 23.77114445843691, -0.1267620961020357, 1.0, 1.0, 6242.311616848667], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2019600.0000, 
sim time next is 2021400.0000, 
raw observation next is [-5.8, 84.5, 69.0, 0.0, 24.0, 23.70331178215571, -0.1191141995695083, 1.0, 1.0, 19948.20677150168], 
processed observation next is [1.0, 0.391304347826087, 0.30193905817174516, 0.845, 0.23, 0.0, 0.5, 0.47527598184630904, 0.4602952668101639, 1.0, 1.0, 0.09499146081667466], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5297639], dtype=float32), 0.12037516]. 
=============================================
[2019-04-07 18:44:38,808] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-07 18:44:38,809] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:44:38,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:44:38,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run98
[2019-04-07 18:44:38,846] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:44:38,848] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:44:38,848] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:44:38,852] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run98
[2019-04-07 18:44:38,848] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:44:38,871] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run98
[2019-04-07 18:46:58,077] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 18:47:09,596] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.125258], dtype=float32), 0.17182398]
[2019-04-07 18:47:09,596] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [1.0, 47.0, 282.0, 349.0, 24.0, 23.17834922648316, -0.07938196335450186, 0.0, 1.0, 0.0]
[2019-04-07 18:47:09,596] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 18:47:09,597] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [1.08568102e-21 9.26351102e-20 1.09908535e-23 1.53500547e-18
 1.88843282e-20 1.00000000e+00 1.85456297e-15 4.68595335e-18], sampled 0.8349682462045291
[2019-04-07 18:47:11,968] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 18:47:17,653] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 18:47:18,677] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1940000, evaluation results [1940000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 18:47:24,845] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0189997e-23 6.6655843e-22 3.7169731e-27 1.7012718e-22 2.3380825e-22
 1.0000000e+00 2.6654383e-17 2.5180724e-20], sum to 1.0000
[2019-04-07 18:47:24,846] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6219
[2019-04-07 18:47:24,979] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 24.0, 23.19364287383047, 0.03981324230975087, 1.0, 1.0, 33774.747092015714], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1360800.0000, 
sim time next is 1362600.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 24.0, 23.45811501480948, 0.05008819164663166, 1.0, 1.0, 32585.44250125031], 
processed observation next is [1.0, 0.782608695652174, 0.4764542936288089, 0.96, 0.0, 0.0, 0.5, 0.45484291790078996, 0.5166960638822106, 1.0, 1.0, 0.15516877381547767], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.83771425], dtype=float32), -0.73437345]. 
=============================================
[2019-04-07 18:47:30,947] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:47:30,947] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:47:30,952] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run44
[2019-04-07 18:47:34,218] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.57867980e-22 5.03757872e-20 1.41225590e-22 7.13490262e-18
 1.34383795e-20 1.00000000e+00 1.08150533e-15 3.17315520e-18], sum to 1.0000
[2019-04-07 18:47:34,219] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4472
[2019-04-07 18:47:34,252] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 40.0, 195.0, 677.5, 24.0, 23.33493421604161, 0.009665874084013973, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4798800.0000, 
sim time next is 4800600.0000, 
raw observation next is [2.5, 38.5, 220.0, 568.0, 24.0, 23.3384023864899, 0.007036477085218105, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.5318559556786704, 0.385, 0.7333333333333333, 0.6276243093922652, 0.5, 0.444866865540825, 0.5023454923617393, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.10576012], dtype=float32), 0.1950571]. 
=============================================
[2019-04-07 18:47:43,823] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6179002e-21 4.5719888e-20 2.4843391e-24 1.1293104e-18 2.4414934e-20
 1.0000000e+00 1.4212371e-16 1.7871907e-18], sum to 1.0000
[2019-04-07 18:47:43,823] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0278
[2019-04-07 18:47:43,879] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [3.0, 35.5, 0.0, 0.0, 24.0, 23.78352780995926, 0.02760465181939266, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 5005800.0000, 
sim time next is 5007600.0000, 
raw observation next is [3.0, 34.0, 0.0, 0.0, 24.0, 23.50753847955265, 0.05200704211839605, 0.0, 1.0, 196676.43051584437], 
processed observation next is [1.0, 1.0, 0.5457063711911359, 0.34, 0.0, 0.0, 0.5, 0.4589615399627209, 0.517335680706132, 0.0, 1.0, 0.9365544310278303], 
reward next is 0.3492, 
noisyNet noise sample is [array([-0.1009317], dtype=float32), 0.9749837]. 
=============================================
[2019-04-07 18:47:44,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:47:44,091] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:47:44,094] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run44
[2019-04-07 18:47:48,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:47:48,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:47:48,039] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run44
[2019-04-07 18:47:48,102] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:47:48,102] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:47:48,123] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run44
[2019-04-07 18:47:52,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.61804617e-23 7.95323001e-22 6.47168776e-27 1.15217990e-21
 1.04484576e-22 1.00000000e+00 4.17759661e-17 3.56810626e-20], sum to 1.0000
[2019-04-07 18:47:52,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9811
[2019-04-07 18:47:52,624] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.65, 82.0, 120.0, 232.0, 24.0, 23.77323401000677, 0.1224541515645922, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4437000.0000, 
sim time next is 4438800.0000, 
raw observation next is [1.3, 84.0, 142.5, 131.5, 24.0, 24.37876688552415, 0.1591773162295694, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49861495844875353, 0.84, 0.475, 0.1453038674033149, 0.5, 0.5315639071270125, 0.5530591054098565, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02493905], dtype=float32), -1.5175649]. 
=============================================
[2019-04-07 18:47:53,354] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0184440e-23 3.2538654e-23 2.6846090e-27 7.3759946e-21 2.7209993e-23
 1.0000000e+00 4.5609343e-17 1.3248824e-20], sum to 1.0000
[2019-04-07 18:47:53,355] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3564
[2019-04-07 18:47:53,418] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 24.0, 23.56255605534059, 0.05109492901550673, 0.0, 1.0, 12496.989338161153], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1393200.0000, 
sim time next is 1395000.0000, 
raw observation next is [-0.3, 97.5, 0.0, 0.0, 24.0, 23.60105340988039, 0.02183606225787756, 0.0, 1.0, 18737.517297374692], 
processed observation next is [1.0, 0.13043478260869565, 0.4542936288088643, 0.975, 0.0, 0.0, 0.5, 0.4667544508233658, 0.5072786874192925, 0.0, 1.0, 0.0892262728446414], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2953411], dtype=float32), -1.3353854]. 
=============================================
[2019-04-07 18:47:53,422] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[105.69916 ]
 [105.90157 ]
 [105.760284]
 [105.93158 ]
 [105.41279 ]], R is [[105.53166199]
 [105.47634888]
 [105.42158508]
 [105.36737061]
 [105.23217773]].
[2019-04-07 18:47:54,400] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.3259711e-23 1.4534392e-21 9.0765861e-26 5.5767509e-20 8.5825815e-22
 1.0000000e+00 1.4516809e-16 4.7678829e-20], sum to 1.0000
[2019-04-07 18:47:54,400] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0855
[2019-04-07 18:47:54,623] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 100.0, 18.0, 0.0, 24.0, 23.85626095848235, 0.07488928284049852, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1413000.0000, 
sim time next is 1414800.0000, 
raw observation next is [-0.6, 100.0, 32.0, 0.0, 24.0, 24.28578456989578, 0.1244615703778111, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.44598337950138506, 1.0, 0.10666666666666667, 0.0, 0.5, 0.5238153808246485, 0.541487190125937, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05080766], dtype=float32), -0.11360328]. 
=============================================
[2019-04-07 18:47:55,904] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:47:55,904] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:47:55,908] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run44
[2019-04-07 18:48:00,686] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3144208e-25 1.0139008e-23 9.3988716e-29 4.9726178e-23 5.4460791e-24
 1.0000000e+00 5.0217548e-18 5.0870897e-21], sum to 1.0000
[2019-04-07 18:48:00,686] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8306
[2019-04-07 18:48:00,765] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.6, 76.0, 0.0, 0.0, 24.0, 23.61606635396368, 0.1537247092383472, 0.0, 1.0, 130811.93961286407], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1548000.0000, 
sim time next is 1549800.0000, 
raw observation next is [6.05, 79.0, 0.0, 0.0, 24.0, 23.73048799279765, 0.155071812207692, 0.0, 1.0, 74147.30194279704], 
processed observation next is [1.0, 0.9565217391304348, 0.6301939058171746, 0.79, 0.0, 0.0, 0.5, 0.4775406660664707, 0.5516906040692307, 0.0, 1.0, 0.35308239020379545], 
reward next is 0.9326, 
noisyNet noise sample is [array([0.76103723], dtype=float32), 0.64886045]. 
=============================================
[2019-04-07 18:48:10,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:48:10,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:48:10,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run44
[2019-04-07 18:48:13,331] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7436496e-22 1.5172312e-19 7.3754166e-25 8.7091134e-18 7.0048756e-21
 1.0000000e+00 4.2963569e-15 1.2137521e-18], sum to 1.0000
[2019-04-07 18:48:13,331] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4741
[2019-04-07 18:48:13,406] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 66.0, 111.5, 423.5, 24.0, 23.9355021345288, -0.09091840296460053, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 730800.0000, 
sim time next is 732600.0000, 
raw observation next is [-0.6, 61.5, 84.0, 779.0, 24.0, 23.97262068390554, -0.04529984015954969, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.44598337950138506, 0.615, 0.28, 0.8607734806629834, 0.5, 0.4977183903254616, 0.4849000532801501, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.07480462], dtype=float32), 0.65010285]. 
=============================================
[2019-04-07 18:48:24,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:48:24,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:48:24,064] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run44
[2019-04-07 18:48:25,886] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.0921635e-22 7.5797993e-21 4.6711235e-25 9.8671315e-19 6.1277776e-22
 1.0000000e+00 9.9300552e-16 1.1329609e-18], sum to 1.0000
[2019-04-07 18:48:25,888] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3463
[2019-04-07 18:48:25,925] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-2.5, 68.0, 0.0, 0.0, 24.0, 23.50857020387546, -0.04566921368229491, 0.0, 1.0, 50338.50691016659], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3900600.0000, 
sim time next is 3902400.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 24.0, 23.40779831364794, -0.02745006615074001, 0.0, 1.0, 71341.48612958506], 
processed observation next is [1.0, 0.17391304347826086, 0.3795013850415513, 0.71, 0.0, 0.0, 0.5, 0.4506498594706618, 0.4908499779497533, 0.0, 1.0, 0.3397213625218336], 
reward next is 0.9460, 
noisyNet noise sample is [array([-0.89532983], dtype=float32), 0.30648765]. 
=============================================
[2019-04-07 18:48:59,602] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.7454701e-23 1.7217734e-21 3.0511286e-25 3.1465973e-20 3.5203115e-21
 1.0000000e+00 1.9636174e-17 6.0944739e-19], sum to 1.0000
[2019-04-07 18:48:59,603] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6022
[2019-04-07 18:48:59,667] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.7, 82.0, 0.0, 0.0, 24.0, 23.36124787497026, -0.1166228471705437, 0.0, 1.0, 42181.00580123942], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 532800.0000, 
sim time next is 534600.0000, 
raw observation next is [2.15, 83.5, 0.0, 0.0, 24.0, 23.37009295614787, -0.1166939659115815, 0.0, 1.0, 41350.98969925474], 
processed observation next is [0.0, 0.17391304347826086, 0.5221606648199446, 0.835, 0.0, 0.0, 0.5, 0.447507746345656, 0.46110201136280615, 0.0, 1.0, 0.19690947475835588], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2523489], dtype=float32), -1.003516]. 
=============================================
[2019-04-07 18:49:14,210] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6675756e-24 9.3312425e-22 9.8533249e-27 4.3294956e-21 1.2011620e-21
 1.0000000e+00 9.0532470e-18 1.5391905e-20], sum to 1.0000
[2019-04-07 18:49:14,211] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9559
[2019-04-07 18:49:14,266] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.25, 73.0, 0.0, 0.0, 24.0, 24.07864691621197, 0.08152130029787137, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4307400.0000, 
sim time next is 4309200.0000, 
raw observation next is [5.1, 73.0, 0.0, 0.0, 24.0, 24.12525201267306, 0.06452017571740315, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.6038781163434903, 0.73, 0.0, 0.0, 0.5, 0.5104376677227549, 0.5215067252391344, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.00149434], dtype=float32), -0.8430208]. 
=============================================
[2019-04-07 18:49:16,786] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:49:16,786] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:49:16,790] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res2/Eplus-env-sub_run44
[2019-04-07 18:49:16,966] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:49:16,966] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:49:16,983] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res5/Eplus-env-sub_run44
[2019-04-07 18:49:17,967] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:49:17,968] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:49:17,971] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res17/Eplus-env-sub_run44
[2019-04-07 18:49:21,157] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-07 18:49:21,158] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:49:21,159] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:49:21,159] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:49:21,159] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:49:21,159] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:49:21,160] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:49:21,165] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run99
[2019-04-07 18:49:21,190] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run99
[2019-04-07 18:49:21,211] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run99
[2019-04-07 18:51:23,054] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12532288], dtype=float32), 0.17225666]
[2019-04-07 18:51:23,055] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [-2.0, 85.0, 0.0, 0.0, 24.0, 23.34378729541791, -0.05395433612356854, 0.0, 1.0, 44541.37667836037]
[2019-04-07 18:51:23,055] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 18:51:23,056] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [3.0919179e-23 3.5049424e-21 1.9699041e-25 6.5735003e-20 1.1196658e-21
 1.0000000e+00 1.3670719e-16 2.3869853e-19], sampled 0.44727120409022814
[2019-04-07 18:51:32,100] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12532288], dtype=float32), 0.17225666]
[2019-04-07 18:51:32,100] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [3.5, 100.0, 0.0, 0.0, 24.0, 24.53581111110731, 0.3125010661239083, 0.0, 1.0, 0.0]
[2019-04-07 18:51:32,100] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 18:51:32,101] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [4.0588357e-26 1.0205324e-23 1.4350168e-28 2.2174469e-22 2.2794187e-24
 1.0000000e+00 9.9790635e-19 8.8380805e-22], sampled 0.8955253087898797
[2019-04-07 18:51:49,702] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 18:51:57,717] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12532288], dtype=float32), 0.17225666]
[2019-04-07 18:51:57,718] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation this: [2.0, 42.0, 187.0, 89.0, 24.0, 23.25856766070465, -0.0737403129237212, 0.0, 1.0, 0.0]
[2019-04-07 18:51:57,718] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 18:51:57,718] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Softmax [2.4312316e-21 2.6031250e-19 4.3993823e-23 3.5256659e-18 4.6994283e-20
 1.0000000e+00 2.4576748e-15 7.6249939e-18], sampled 0.11426221386799085
[2019-04-07 18:52:08,642] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 18:52:11,584] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 18:52:12,608] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1960000, evaluation results [1960000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 18:52:30,781] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:52:30,781] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:52:30,784] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res12/Eplus-env-sub_run44
[2019-04-07 18:52:40,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:52:40,018] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:52:40,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res8/Eplus-env-sub_run44
[2019-04-07 18:52:40,851] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:52:40,851] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:52:40,854] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res3/Eplus-env-sub_run45
[2019-04-07 18:52:44,401] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.11413918e-22 1.30143884e-21 7.55548098e-24 1.03413652e-20
 1.01032616e-22 1.00000000e+00 7.73577324e-17 2.43174298e-20], sum to 1.0000
[2019-04-07 18:52:44,401] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9673
[2019-04-07 18:52:44,463] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [4.0, 35.0, 93.5, 566.0, 24.0, 25.83665518028322, 0.4521366715141553, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4118400.0000, 
sim time next is 4120200.0000, 
raw observation next is [3.5, 36.0, 93.0, 437.0, 24.0, 25.5485953298965, 0.401610625938796, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5595567867036012, 0.36, 0.31, 0.48287292817679556, 0.5, 0.6290496108247083, 0.6338702086462653, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.11180455], dtype=float32), 1.7146916]. 
=============================================
[2019-04-07 18:52:49,455] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2628393e-21 6.4550681e-20 1.7543714e-23 4.0418894e-17 1.2441467e-20
 1.0000000e+00 9.1543488e-16 5.2553713e-18], sum to 1.0000
[2019-04-07 18:52:49,697] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7465
[2019-04-07 18:52:49,807] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 42.0, 102.0, 788.0, 24.0, 23.62535174574676, 0.07884250987264084, 0.0, 1.0, 18690.748461523584], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3594600.0000, 
sim time next is 3596400.0000, 
raw observation next is [-1.0, 42.0, 94.0, 743.5, 24.0, 23.65654355384777, 0.08306169588607025, 0.0, 1.0, 18690.718500810475], 
processed observation next is [0.0, 0.6521739130434783, 0.4349030470914128, 0.42, 0.31333333333333335, 0.8215469613259668, 0.5, 0.47137862948731407, 0.5276872319620234, 0.0, 1.0, 0.08900342143243084], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6411317], dtype=float32), 1.1175011]. 
=============================================
[2019-04-07 18:53:01,289] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5202512e-23 4.3308830e-21 1.0583271e-24 1.2983261e-19 1.5037287e-22
 1.0000000e+00 2.3228244e-17 2.0645415e-20], sum to 1.0000
[2019-04-07 18:53:01,318] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7338
[2019-04-07 18:53:01,386] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [2.0, 48.0, 131.0, 40.0, 24.0, 24.48237594234192, 0.1437095501795559, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4550400.0000, 
sim time next is 4552200.0000, 
raw observation next is [2.0, 50.0, 109.0, 68.0, 24.0, 24.60704186461879, 0.1478394421144951, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.518005540166205, 0.5, 0.36333333333333334, 0.07513812154696133, 0.5, 0.5505868220515658, 0.5492798140381651, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.34077674], dtype=float32), -2.984044]. 
=============================================
[2019-04-07 18:53:22,727] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.5401630e-24 7.9891068e-23 3.5978482e-27 8.3981062e-22 8.9378193e-24
 1.0000000e+00 1.0354176e-16 1.1633853e-20], sum to 1.0000
[2019-04-07 18:53:22,728] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8715
[2019-04-07 18:53:22,801] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.25, 73.0, 0.0, 0.0, 24.0, 24.07864691621197, 0.08152130029787137, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4307400.0000, 
sim time next is 4309200.0000, 
raw observation next is [5.1, 73.0, 0.0, 0.0, 24.0, 24.12525201267306, 0.06452017571740315, 0.0, 1.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.6038781163434903, 0.73, 0.0, 0.0, 0.5, 0.5104376677227549, 0.5215067252391344, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.71425056], dtype=float32), 0.592277]. 
=============================================
[2019-04-07 18:53:26,224] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:53:26,224] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:53:26,234] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res15/Eplus-env-sub_run45
[2019-04-07 18:53:30,640] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1654540e-20 1.8198904e-18 8.9671296e-22 1.3167674e-17 1.7689249e-18
 1.0000000e+00 2.1573927e-14 1.8422920e-17], sum to 1.0000
[2019-04-07 18:53:30,642] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7368
[2019-04-07 18:53:30,674] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [18.55, 64.0, 171.0, 0.0, 24.0, 23.53403583369346, 0.1284882576090416, 0.0, 0.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1168200.0000, 
sim time next is 1170000.0000, 
raw observation next is [18.3, 65.0, 165.0, 0.0, 24.0, 23.55373708748808, 0.1291558200480368, 0.0, 0.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.9695290858725764, 0.65, 0.55, 0.0, 0.5, 0.46281142395734004, 0.5430519400160122, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.23440927], dtype=float32), 0.94279695]. 
=============================================
[2019-04-07 18:53:30,738] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[ 89.78686]
 [ 92.21622]
 [ 95.56932]
 [100.20954]
 [103.05498]], R is [[89.75249481]
 [89.85497284]
 [89.9564209 ]
 [90.05685425]
 [90.15628815]].
[2019-04-07 18:53:36,054] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6992079e-22 7.8385372e-21 1.6910084e-24 3.7600715e-19 2.0032208e-21
 1.0000000e+00 1.9630257e-17 4.1191209e-19], sum to 1.0000
[2019-04-07 18:53:36,055] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7478
[2019-04-07 18:53:36,217] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8999999999999999, 57.0, 0.0, 0.0, 24.0, 23.5314804522821, -0.05553804792197009, 1.0, 1.0, 27731.692851198186], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2658600.0000, 
sim time next is 2660400.0000, 
raw observation next is [-1.2, 60.0, 0.0, 0.0, 24.0, 23.3085470329043, -0.06328030754359826, 1.0, 1.0, 33203.004962455285], 
processed observation next is [1.0, 0.8260869565217391, 0.42936288088642666, 0.6, 0.0, 0.0, 0.5, 0.44237891940869173, 0.4789065641521339, 1.0, 1.0, 0.15810954744026326], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.35415953], dtype=float32), -1.9342343]. 
=============================================
[2019-04-07 18:53:37,987] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.5917802e-22 1.9058677e-19 2.0348358e-22 2.8957889e-18 1.6478942e-19
 1.0000000e+00 5.3442083e-16 2.9346343e-17], sum to 1.0000
[2019-04-07 18:53:37,987] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0810
[2019-04-07 18:53:38,060] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 53.0, 0.0, 0.0, 24.0, 22.8493735919646, -0.269572152377894, 0.0, 1.0, 44539.41802430718], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2426400.0000, 
sim time next is 2428200.0000, 
raw observation next is [-7.55, 54.0, 0.0, 0.0, 24.0, 22.73304338557922, -0.2914966061826448, 0.0, 1.0, 44589.63538672067], 
processed observation next is [0.0, 0.08695652173913043, 0.25346260387811637, 0.54, 0.0, 0.0, 0.5, 0.3944202821316016, 0.4028344646057851, 0.0, 1.0, 0.21233159707962224], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.27022353], dtype=float32), -1.9706898]. 
=============================================
[2019-04-07 18:53:57,724] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:53:57,725] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:53:57,728] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res16/Eplus-env-sub_run45
[2019-04-07 18:54:07,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3635004e-22 6.2665943e-20 1.1260935e-24 2.0167021e-19 3.3697202e-20
 1.0000000e+00 2.1481805e-16 7.5327937e-19], sum to 1.0000
[2019-04-07 18:54:07,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4532
[2019-04-07 18:54:07,716] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.5, 47.5, 0.0, 0.0, 24.0, 23.5204042800608, -0.06962828340365944, 0.0, 1.0, 43153.47124664352], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4231800.0000, 
sim time next is 4233600.0000, 
raw observation next is [2.0, 48.0, 0.0, 0.0, 24.0, 23.53404184153937, -0.07156969558533413, 0.0, 1.0, 32276.42554212052], 
processed observation next is [0.0, 0.0, 0.518005540166205, 0.48, 0.0, 0.0, 0.5, 0.46117015346161416, 0.4761434348048886, 0.0, 1.0, 0.15369726448628818], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3167396], dtype=float32), -1.1516377]. 
=============================================
[2019-04-07 18:54:14,443] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5260825e-24 6.6405604e-22 4.6544165e-27 1.1525762e-20 1.4250274e-22
 1.0000000e+00 1.0061787e-17 6.3345608e-21], sum to 1.0000
[2019-04-07 18:54:14,454] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5230
[2019-04-07 18:54:14,504] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 67.0, 0.0, 0.0, 24.0, 23.84071493456909, 0.08996695849996621, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4417200.0000, 
sim time next is 4419000.0000, 
raw observation next is [4.75, 67.0, 0.0, 0.0, 24.0, 23.55780803721343, 0.1136343260329576, 0.0, 1.0, 124963.09081465188], 
processed observation next is [1.0, 0.13043478260869565, 0.5941828254847646, 0.67, 0.0, 0.0, 0.5, 0.46315066976778585, 0.5378781086776525, 0.0, 1.0, 0.595062337212628], 
reward next is 0.6907, 
noisyNet noise sample is [array([-0.43972802], dtype=float32), 0.30437464]. 
=============================================
[2019-04-07 18:54:14,558] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[104.658165]
 [105.64488 ]
 [106.22072 ]
 [106.63076 ]
 [106.834015]], R is [[104.77438354]
 [104.72663879]
 [104.67937469]
 [104.63258362]
 [104.58625793]].
[2019-04-07 18:54:18,474] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7685039e-21 5.0965325e-20 3.5998289e-25 4.7334554e-18 1.3127531e-20
 1.0000000e+00 7.1438462e-15 2.3273823e-18], sum to 1.0000
[2019-04-07 18:54:18,475] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0574
[2019-04-07 18:54:18,542] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.40280958341459, -0.09988408310007478, 0.0, 1.0, 57281.614356173064], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3726000.0000, 
sim time next is 3727800.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.58545346129764, -0.06814201127278852, 0.0, 1.0, 25645.57637128237], 
processed observation next is [1.0, 0.13043478260869565, 0.3795013850415513, 0.65, 0.0, 0.0, 0.5, 0.4654544551081366, 0.47728599624240386, 0.0, 1.0, 0.12212179224420175], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7692116], dtype=float32), -0.5828736]. 
=============================================
[2019-04-07 18:54:18,567] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1377581e-23 5.5714989e-20 5.2096806e-26 1.1501046e-18 9.2000771e-22
 1.0000000e+00 8.5559943e-17 4.6038262e-19], sum to 1.0000
[2019-04-07 18:54:18,567] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0110
[2019-04-07 18:54:18,765] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 24.0, 22.98276790999551, -0.02177624169113411, 1.0, 1.0, 70537.5098961712], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1454400.0000, 
sim time next is 1456200.0000, 
raw observation next is [1.35, 90.5, 0.0, 0.0, 24.0, 23.09635041966624, 0.0506300956897871, 0.0, 1.0, 138660.44197516877], 
processed observation next is [1.0, 0.8695652173913043, 0.5000000000000001, 0.905, 0.0, 0.0, 0.5, 0.42469586830552003, 0.5168766985632623, 0.0, 1.0, 0.660287818929375], 
reward next is 0.6254, 
noisyNet noise sample is [array([-1.4082953], dtype=float32), 0.6007314]. 
=============================================
[2019-04-07 18:54:20,322] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-07 18:54:20,323] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:54:20,324] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:54:20,324] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:54:20,325] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:54:20,332] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run100
[2019-04-07 18:54:20,324] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:54:20,355] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run100
[2019-04-07 18:54:20,379] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:54:20,383] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run100
[2019-04-07 18:56:43,995] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:NoisyNet noise sample: [array([0.12519354], dtype=float32), 0.17250891]
[2019-04-07 18:56:43,995] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation this: [12.15, 77.0, 0.0, 0.0, 24.0, 25.10913736003595, 0.4859623597849772, 0.0, 1.0, 0.0]
[2019-04-07 18:56:43,995] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 DEBUG:Observation forecast: []
[2019-04-07 18:56:43,996] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Softmax [6.2706134e-27 1.6538601e-24 2.0640281e-29 4.2304086e-23 2.8911096e-25
 1.0000000e+00 1.6618709e-19 1.7508223e-22], sampled 0.9120693551178617
[2019-04-07 18:56:44,071] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 18:57:01,390] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 18:57:04,797] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 18:57:05,822] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1980000, evaluation results [1980000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
[2019-04-07 18:57:28,111] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1915638e-22 1.9481264e-19 2.0837879e-24 6.1910147e-19 2.8023150e-21
 1.0000000e+00 4.7447773e-16 1.4814919e-18], sum to 1.0000
[2019-04-07 18:57:28,116] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0702
[2019-04-07 18:57:28,166] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 86.0, 0.0, 0.0, 24.0, 23.23206646878747, -0.1061129369464013, 0.0, 1.0, 51352.27556075033], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2070000.0000, 
sim time next is 2071800.0000, 
raw observation next is [-4.5, 88.5, 0.0, 0.0, 24.0, 23.16753319918368, -0.1203147038651999, 0.0, 1.0, 44551.9750077741], 
processed observation next is [1.0, 1.0, 0.3379501385041552, 0.885, 0.0, 0.0, 0.5, 0.43062776659864, 0.4598950987116, 0.0, 1.0, 0.2121522619417814], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5360418], dtype=float32), -1.8053541]. 
=============================================
[2019-04-07 18:57:30,708] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:57:30,708] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:57:30,711] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res11/Eplus-env-sub_run45
[2019-04-07 18:57:33,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1681844e-25 1.0085505e-23 1.3083740e-27 4.5075113e-22 4.4877735e-25
 1.0000000e+00 2.7066048e-19 5.3686506e-22], sum to 1.0000
[2019-04-07 18:57:33,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4789
[2019-04-07 18:57:33,625] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.5, 31.0, 155.0, 735.5, 24.0, 26.58333253148979, 0.6732724313519967, 1.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 4370400.0000, 
sim time next is 4372200.0000, 
raw observation next is [14.2, 31.5, 195.0, 629.0, 24.0, 26.86292005127353, 0.7402492300450066, 1.0, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.8559556786703602, 0.315, 0.65, 0.6950276243093922, 0.5, 0.7385766709394609, 0.7467497433483355, 1.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.01548431], dtype=float32), 2.451251]. 
=============================================
[2019-04-07 18:57:34,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3439690e-22 2.0189564e-20 7.0133639e-25 8.0887562e-19 3.3048448e-21
 1.0000000e+00 1.1816143e-15 2.6136734e-18], sum to 1.0000
[2019-04-07 18:57:34,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7183
[2019-04-07 18:57:35,031] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.1, 86.5, 29.0, 0.0, 24.0, 23.40689115901016, -0.1549156306094019, 1.0, 1.0, 19400.124636486344], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2017800.0000, 
sim time next is 2019600.0000, 
raw observation next is [-6.0, 86.0, 49.0, 0.0, 24.0, 23.77114445843691, -0.1267620961020357, 1.0, 1.0, 6242.311616848667], 
processed observation next is [1.0, 0.391304347826087, 0.296398891966759, 0.86, 0.16333333333333333, 0.0, 0.5, 0.4809287048697426, 0.4577459679659881, 1.0, 1.0, 0.02972529341356508], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.945686], dtype=float32), -0.11877564]. 
=============================================
[2019-04-07 18:57:47,216] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.28117511e-23 2.91749470e-21 2.16090064e-26 4.74972469e-22
 1.03870186e-22 1.00000000e+00 5.22169921e-18 2.90944948e-20], sum to 1.0000
[2019-04-07 18:57:47,216] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3302
[2019-04-07 18:57:47,264] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [5.0, 82.0, 0.0, 0.0, 24.0, 23.83014488846288, 0.08600652553960049, 0.0, 1.0, 0.0], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 1576800.0000, 
sim time next is 1578600.0000, 
raw observation next is [5.25, 80.5, 0.0, 0.0, 24.0, 23.75324798609144, 0.0470304974755398, 0.0, 1.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.60803324099723, 0.805, 0.0, 0.0, 0.5, 0.4794373321742868, 0.5156768324918466, 0.0, 1.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.08943859], dtype=float32), 0.9575629]. 
=============================================
[2019-04-07 18:57:51,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:57:51,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:57:51,916] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res6/Eplus-env-sub_run45
[2019-04-07 18:58:02,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:58:02,774] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:58:02,777] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res9/Eplus-env-sub_run45
[2019-04-07 18:58:06,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:58:06,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:58:06,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res7/Eplus-env-sub_run45
[2019-04-07 18:58:12,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:58:12,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:58:12,672] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res10/Eplus-env-sub_run45
[2019-04-07 18:58:16,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:58:16,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:58:16,036] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res13/Eplus-env-sub_run45
[2019-04-07 18:58:30,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:58:30,491] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:58:30,494] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res4/Eplus-env-sub_run45
[2019-04-07 18:58:33,164] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.5725704e-22 9.3732785e-20 6.1420702e-24 1.0042188e-18 1.9989013e-20
 1.0000000e+00 2.9388609e-15 3.9110510e-18], sum to 1.0000
[2019-04-07 18:58:33,165] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7247
[2019-04-07 18:58:33,270] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.53196764771628, -0.1017415951727405, 0.0, 1.0, 13190.727277309661], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 3729600.0000, 
sim time next is 3731400.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 24.0, 23.47507082667667, -0.1071034703255761, 0.0, 1.0, 55323.825163573616], 
processed observation next is [1.0, 0.17391304347826086, 0.3795013850415513, 0.65, 0.0, 0.0, 0.5, 0.4562559022230559, 0.4642988432248079, 0.0, 1.0, 0.2634467864932077], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9768364], dtype=float32), 0.7719581]. 
=============================================
[2019-04-07 18:58:38,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-07 18:58:38,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:58:38,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res14/Eplus-env-sub_run45
[2019-04-07 18:58:53,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8813968e-24 4.6124177e-21 2.1566114e-25 3.3436517e-19 1.0011917e-21
 1.0000000e+00 8.1495621e-17 4.2854795e-19], sum to 1.0000
[2019-04-07 18:58:53,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9103
[2019-04-07 18:58:53,351] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.5, 88.5, 0.0, 0.0, 24.0, 23.16753319918368, -0.1203147038651999, 0.0, 1.0, 44551.9750077741], 
current ob forecast is [], 
actual action is [24.0], 
sim time this is 2071800.0000, 
sim time next is 2073600.0000, 
raw observation next is [-4.5, 91.0, 0.0, 0.0, 24.0, 23.10914457441788, -0.1343807839508896, 0.0, 1.0, 44326.20134606568], 
processed observation next is [1.0, 0.0, 0.3379501385041552, 0.91, 0.0, 0.0, 0.5, 0.4257620478681566, 0.4552064053497034, 0.0, 1.0, 0.21107714926697943], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.19505881], dtype=float32), -1.1591569]. 
=============================================
[2019-04-07 18:59:10,861] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-07 18:59:10,871] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:59:10,872] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:59:10,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Train-Repeat-v1-res1/Eplus-env-sub_run101
[2019-04-07 18:59:10,933] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation job starts!
[2019-04-07 18:59:10,946] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation job starts!
[2019-04-07 18:59:10,946] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:59:10,952] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-07 18:59:12,446] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v2-res1/Eplus-env-sub_run101
[2019-04-07 18:59:12,474] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_light/47/Eplus-env-Part4-Light-Pit-Test-Repeat-v1-res1/Eplus-env-sub_run101
[2019-04-07 19:01:03,581] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v1 INFO:Evaluation: average rewards by now are 2789.0480 70927233.8163 166.2180
[2019-04-07 19:01:18,971] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v1 INFO:Evaluation: average rewards by now are 2782.7721 79463814.5229 95.0531
[2019-04-07 19:01:23,203] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v2 INFO:Evaluation: average rewards by now are 2784.6758 83805026.4189 32.8860
[2019-04-07 19:01:24,227] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 2000000, evaluation results [2000000.0, 2782.772055622555, 79463814.52292724, 95.05306144070829, 2789.048033151059, 70927233.8162715, 166.21801628696863, 2784.6758191854165, 83805026.41892925, 32.88598103848735]
