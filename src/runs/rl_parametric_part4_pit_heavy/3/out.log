Using TensorFlow backend.
[2019-04-17 15:12:37,250] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part4_v3', activation='linear', agent_num=5, check_args_only=False, clip_norm=1.0, debug_log_prob=0.001, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part4-Heavy-Pit-Train-Repeat-v2', eval_act_func='part4_v4', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=50000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_add_time_to_state=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_r_term_zero=True, is_warm_start=False, job_mode='Train', learning_rate=0.0001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=3000000, metric_func='part4_v2', model_dir='None', model_param=[13, 1], model_type='nn', num_threads=16, output='./Part4-Heavy-Pit-Train-Repeat-v2-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part4_heuri_v8', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=10.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=11, test_env=['Part4-Heavy-Pit-Test-Repeat-v3', 'Part4-Heavy-Pit-Test-Repeat-v4'], test_mode='Multiple', train_act_func='part4_v4', train_freq=25, v_loss_frac=0.5, violation_penalty_scl=5.0, weight_initer='glorot_uniform', window_len=10)
[2019-04-17 15:12:37,250] A3C_AGENT_MAIN INFO:Start compiling...
2019-04-17 15:12:37.305536: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-04-17 15:13:06,653] A3C_AGENT_MAIN INFO:Start the learning...
[2019-04-17 15:13:06,654] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part4-Heavy-Pit-Train-Repeat-v2', 'Part4-Heavy-Pit-Test-Repeat-v3', 'Part4-Heavy-Pit-Test-Repeat-v4'] ...
[2019-04-17 15:13:06,724] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation worker starts!
[2019-04-17 15:13:06,744] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-04-17 15:13:06,763] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-04-17 15:13:06,764] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:06,764] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-04-17 15:13:06,892] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:06,894] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res2/Eplus-env-sub_run1
[2019-04-17 15:13:07,775] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:07,777] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-04-17 15:13:07,917] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:07,919] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res3/Eplus-env-sub_run1
[2019-04-17 15:13:08,778] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:08,779] A3C_AGENT_WORKER-Thread-4 INFO:Local worker starts!
[2019-04-17 15:13:08,927] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:08,928] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res4/Eplus-env-sub_run1
[2019-04-17 15:13:09,780] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:09,780] A3C_AGENT_WORKER-Thread-5 INFO:Local worker starts!
[2019-04-17 15:13:09,959] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:09,961] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res5/Eplus-env-sub_run1
[2019-04-17 15:13:10,781] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:10,783] A3C_AGENT_WORKER-Thread-6 INFO:Local worker starts!
[2019-04-17 15:13:10,978] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:10,979] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res6/Eplus-env-sub_run1
[2019-04-17 15:13:11,784] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:11,785] A3C_AGENT_WORKER-Thread-7 INFO:Local worker starts!
[2019-04-17 15:13:11,941] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:11,943] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res7/Eplus-env-sub_run1
[2019-04-17 15:13:12,785] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:12,786] A3C_AGENT_WORKER-Thread-8 INFO:Local worker starts!
[2019-04-17 15:13:13,121] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:13,123] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res8/Eplus-env-sub_run1
[2019-04-17 15:13:13,318] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-17 15:13:13,329] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-17 15:13:13,329] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:13,331] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res1/Eplus-env-sub_run1
[2019-04-17 15:13:13,369] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation job starts!
[2019-04-17 15:13:13,369] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:13,371] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-04-17 15:13:13,415] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation job starts!
[2019-04-17 15:13:13,415] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:13,417] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-04-17 15:13:13,791] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:13,792] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-04-17 15:13:14,078] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:14,080] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res9/Eplus-env-sub_run1
[2019-04-17 15:13:14,793] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:14,793] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-04-17 15:13:15,126] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:15,128] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res10/Eplus-env-sub_run1
[2019-04-17 15:13:15,800] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:15,801] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-04-17 15:13:16,026] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:16,028] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res11/Eplus-env-sub_run1
[2019-04-17 15:13:16,807] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:16,808] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-04-17 15:13:16,989] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:16,991] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res12/Eplus-env-sub_run1
[2019-04-17 15:13:17,809] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:17,810] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-04-17 15:13:18,108] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:18,110] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res13/Eplus-env-sub_run1
[2019-04-17 15:13:18,811] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:18,812] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-04-17 15:13:19,085] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:19,086] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res14/Eplus-env-sub_run1
[2019-04-17 15:13:19,813] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:19,813] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-04-17 15:13:20,232] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:20,250] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res15/Eplus-env-sub_run1
[2019-04-17 15:13:20,818] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:20,820] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-04-17 15:13:21,532] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:21,549] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res16/Eplus-env-sub_run1
[2019-04-17 15:13:21,820] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-17 15:13:21,833] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-04-17 15:13:23,197] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:13:23,199] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res17/Eplus-env-sub_run1
[2019-04-17 15:15:02,973] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation: average rewards by now are 1785.8593 122494.7948 627.9216
[2019-04-17 15:15:02,993] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:15:03,101] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:15:12,020] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation: average rewards by now are 1769.4268 129307.6363 292.0861
[2019-04-17 15:15:12,054] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:15:12,161] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:15:14,782] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation: average rewards by now are 1725.9083 131567.9021 133.6680
[2019-04-17 15:15:14,802] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:15:14,907] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:15:15,804] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 1769.426801112137, 129307.63632869671, 292.08606972734367, 1785.859260782979, 122494.79479152923, 627.9215585654679, 1725.9083235346575, 131567.90212626726, 133.66802302963794]
[2019-04-17 15:15:16,220] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [0.21077017 0.07446663 0.1750737  0.06495721 0.09426121 0.07612491
 0.06789634 0.05798546 0.03560488 0.08797945 0.05488005], sum to 1.0000
[2019-04-17 15:15:16,222] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6980
[2019-04-17 15:15:16,318] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 19.0, 21.49771495995706, -0.4419122855217257, 0.0, 1.0, 40.0, 38.088487042031005], 
current ob forecast is [], 
actual action is [1, 45.0], 
sim time this is 18000.0000, 
sim time next is 19200.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 19.0, 21.57610493212249, -0.4259265832425815, 0.0, 1.0, 45.0, 30.986304449952023], 
processed observation next is [0.0, 0.21739130434782608, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.29800874434354085, 0.35802447225247286, 0.0, 1.0, 0.6, 0.30986304449952023], 
reward next is 0.0901, 
noisyNet noise sample is [array([-1.0405318], dtype=float32), -0.21755627]. 
=============================================
[2019-04-17 15:15:23,162] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.24047928 0.07385853 0.15349016 0.06178666 0.12006969 0.07595327
 0.10578563 0.04159918 0.02875961 0.06270965 0.03550839], sum to 1.0000
[2019-04-17 15:15:23,162] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8212
[2019-04-17 15:15:23,314] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [-7.633333333333333, 63.0, 0.0, 0.0, 22.5, 22.07968157842155, -0.336565605386912, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 45.0], 
sim time this is 153600.0000, 
sim time next is 154800.0000, 
raw observation next is [-7.8, 64.0, 0.0, 0.0, 22.5, 22.04626167726073, -0.2863081353975314, 1.0, 1.0, 45.0, 59.96538716180497], 
processed observation next is [1.0, 0.8260869565217391, 0.24653739612188366, 0.64, 0.0, 0.0, 0.375, 0.3371884731050609, 0.40456395486748953, 1.0, 1.0, 0.6, 0.5996538716180497], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.5718842], dtype=float32), 0.38079146]. 
=============================================
[2019-04-17 15:15:29,093] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.176658   0.03785196 0.17727806 0.08830598 0.16225037 0.05957907
 0.0658764  0.08762792 0.01643234 0.10251343 0.02562644], sum to 1.0000
[2019-04-17 15:15:29,093] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8219
[2019-04-17 15:15:29,267] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-11.7, 70.0, 0.0, 0.0, 19.0, 20.59776958656404, -0.6595815159465425, 0.0, 1.0, 65.0, 80.92794318763046], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 280800.0000, 
sim time next is 282000.0000, 
raw observation next is [-11.9, 69.0, 0.0, 0.0, 19.0, 21.01791120192384, -0.621883482510648, 0.0, 1.0, 50.0, 53.14808812319716], 
processed observation next is [1.0, 0.2608695652173913, 0.13296398891966757, 0.69, 0.0, 0.0, 0.08333333333333333, 0.2514926001603201, 0.292705505829784, 0.0, 1.0, 0.7, 0.5314808812319716], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0008439], dtype=float32), -0.10772872]. 
=============================================
[2019-04-17 15:15:42,751] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.2045049  0.08909663 0.12937292 0.06206984 0.11958028 0.07444423
 0.14293383 0.06029676 0.03295372 0.04680214 0.03794475], sum to 1.0000
[2019-04-17 15:15:42,751] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1327
[2019-04-17 15:15:42,916] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.1, 27.0, 118.0, 0.0, 22.5, 22.6410435422061, -0.4133613482704293, 1.0, 1.0, 25.0, 32.287091365406035], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 472800.0000, 
sim time next is 474000.0000, 
raw observation next is [-1.9, 26.0, 123.1666666666667, 0.0, 22.5, 22.57713210020439, -0.4532810859288987, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4099722991689751, 0.26, 0.4105555555555557, 0.0, 0.375, 0.3814276750170326, 0.3489063046903671, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5269934], dtype=float32), 0.38640356]. 
=============================================
[2019-04-17 15:15:47,849] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.22267725 0.07039962 0.22213167 0.07386904 0.0714786  0.06738246
 0.06174517 0.04172117 0.03570773 0.09728055 0.03560677], sum to 1.0000
[2019-04-17 15:15:47,852] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5481
[2019-04-17 15:15:47,962] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-2.8, 87.0, 0.0, 0.0, 19.0, 21.37101654126001, -0.5578763531889118, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 589200.0000, 
sim time next is 590400.0000, 
raw observation next is [-2.8, 87.0, 0.0, 0.0, 19.0, 21.44641379531163, -0.4722925370835913, 0.0, 1.0, 30.0, 65.80174863872219], 
processed observation next is [0.0, 0.8695652173913043, 0.38504155124653744, 0.87, 0.0, 0.0, 0.08333333333333333, 0.2872011496093026, 0.3425691543054696, 0.0, 1.0, 0.3, 0.6580174863872219], 
reward next is 0.0420, 
noisyNet noise sample is [array([0.37386817], dtype=float32), -0.5313142]. 
=============================================
[2019-04-17 15:15:52,511] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.24750979 0.04634991 0.12746155 0.0590025  0.13358003 0.06011273
 0.08669147 0.08668254 0.02361103 0.06841759 0.06058083], sum to 1.0000
[2019-04-17 15:15:52,511] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5415
[2019-04-17 15:15:52,742] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 63.00000000000001, 93.16666666666666, 660.5000000000001, 22.5, 22.40093527241732, -0.4126798018524853, 1.0, 1.0, 25.0, 27.780735526671986], 
current ob forecast is [], 
actual action is [1, 35.0], 
sim time this is 732000.0000, 
sim time next is 733200.0000, 
raw observation next is [-0.6, 60.0, 91.83333333333333, 724.0, 22.5, 22.45139715893418, -0.3947749422504824, 1.0, 1.0, 35.0, 23.238051687201985], 
processed observation next is [1.0, 0.4782608695652174, 0.44598337950138506, 0.6, 0.3061111111111111, 0.8, 0.375, 0.3709497632445151, 0.3684083525831725, 1.0, 1.0, 0.4, 0.23238051687201985], 
reward next is 0.3676, 
noisyNet noise sample is [array([-1.2313333], dtype=float32), 0.8690837]. 
=============================================
[2019-04-17 15:15:52,849] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.24321024 0.06249243 0.10263041 0.04578448 0.1173696  0.05496104
 0.13680626 0.09339009 0.03655791 0.05733887 0.04945864], sum to 1.0000
[2019-04-17 15:15:52,850] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1430
[2019-04-17 15:15:53,058] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 57.0, 107.5, 614.0, 22.5, 22.75461593774477, -0.3692587400753679, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 734400.0000, 
sim time next is 735600.0000, 
raw observation next is [-0.2333333333333334, 54.66666666666667, 123.1666666666667, 504.0, 22.5, 22.40793011783611, -0.4234863241890546, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.456140350877193, 0.5466666666666667, 0.4105555555555557, 0.5569060773480663, 0.375, 0.36732750981967577, 0.35883789193698185, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1345017], dtype=float32), 0.9300984]. 
=============================================
[2019-04-17 15:15:59,613] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.15967897 0.03999246 0.22941399 0.05140019 0.14043088 0.06497522
 0.09026907 0.06487598 0.02883083 0.06791414 0.06221826], sum to 1.0000
[2019-04-17 15:15:59,613] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3108
[2019-04-17 15:15:59,650] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.7, 79.0, 0.0, 0.0, 19.0, 21.7702249968623, -0.5415535762546781, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 872400.0000, 
sim time next is 873600.0000, 
raw observation next is [-1.7, 79.0, 0.0, 0.0, 19.0, 21.42919677704417, -0.5234332757203689, 0.0, 1.0, 25.0, 53.425931049400546], 
processed observation next is [1.0, 0.08695652173913043, 0.4155124653739613, 0.79, 0.0, 0.0, 0.08333333333333333, 0.28576639808701404, 0.3255222414265437, 0.0, 1.0, 0.2, 0.5342593104940054], 
reward next is 0.2657, 
noisyNet noise sample is [array([1.6591271], dtype=float32), 0.7790266]. 
=============================================
[2019-04-17 15:16:01,821] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.26093006 0.04661267 0.12553135 0.03906405 0.13460389 0.05344505
 0.11156489 0.06759981 0.0295079  0.07168192 0.05945847], sum to 1.0000
[2019-04-17 15:16:01,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7220
[2019-04-17 15:16:01,968] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [4.600000000000001, 92.66666666666667, 24.0, 0.0, 22.5, 23.77308694752046, 0.004074095709669975, 1.0, 1.0, 25.0, 47.677921469349315], 
current ob forecast is [], 
actual action is [1, 45.0], 
sim time this is 922800.0000, 
sim time next is 924000.0000, 
raw observation next is [4.8, 92.33333333333333, 15.0, 0.0, 22.5, 23.93162660056171, 0.01969246460523518, 1.0, 1.0, 45.0, 38.28158136818074], 
processed observation next is [1.0, 0.6956521739130435, 0.5955678670360112, 0.9233333333333333, 0.05, 0.0, 0.375, 0.49430221671347585, 0.5065641548684118, 1.0, 1.0, 0.6, 0.3828158136818074], 
reward next is 0.0172, 
noisyNet noise sample is [array([1.533572], dtype=float32), -0.8873214]. 
=============================================
[2019-04-17 15:16:04,112] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.1691671  0.03834645 0.1582027  0.04001459 0.17340407 0.04682504
 0.09435128 0.08933312 0.02827653 0.05604647 0.10603262], sum to 1.0000
[2019-04-17 15:16:04,114] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9800
[2019-04-17 15:16:04,150] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [14.76666666666667, 73.33333333333334, 137.3333333333333, 35.83333333333333, 22.5, 26.69096062226921, 0.8422494593771006, 1.0, 1.0, 30.0, 31.306641739811997], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 1075200.0000, 
sim time next is 1076400.0000, 
raw observation next is [15.5, 70.0, 184.0, 107.5, 22.5, 26.828391933323, 0.8717978438489546, 1.0, 1.0, 65.0, 34.45290469267324], 
processed observation next is [1.0, 0.4782608695652174, 0.8919667590027703, 0.7, 0.6133333333333333, 0.11878453038674033, 0.375, 0.7356993277769167, 0.7905992812829848, 1.0, 1.0, 1.0, 0.3445290469267324], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.69194067], dtype=float32), 1.0324359]. 
=============================================
[2019-04-17 15:16:05,849] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.11574169 0.02099878 0.2636197  0.03362039 0.20653814 0.05165303
 0.0548776  0.0764458  0.01722742 0.06223933 0.09703809], sum to 1.0000
[2019-04-17 15:16:05,849] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1733
[2019-04-17 15:16:05,982] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.63333333333333, 78.66666666666667, 0.0, 0.0, 19.0, 24.71810416652566, 0.3417521886234962, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1056000.0000, 
sim time next is 1057200.0000, 
raw observation next is [13.46666666666667, 79.33333333333333, 0.0, 0.0, 19.0, 24.7465647945096, 0.402716893375491, 0.0, 1.0, 25.0, 44.26793857515945], 
processed observation next is [1.0, 0.21739130434782608, 0.8356417359187445, 0.7933333333333333, 0.0, 0.0, 0.08333333333333333, 0.5622137328757999, 0.634238964458497, 0.0, 1.0, 0.2, 0.4426793857515945], 
reward next is 0.3573, 
noisyNet noise sample is [array([-0.18094835], dtype=float32), 0.8825787]. 
=============================================
[2019-04-17 15:16:06,543] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.13504913 0.02489855 0.07341994 0.01329437 0.17553987 0.02791656
 0.22845295 0.17431808 0.03004776 0.04117848 0.07588428], sum to 1.0000
[2019-04-17 15:16:06,543] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1267
[2019-04-17 15:16:06,576] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.63333333333333, 60.66666666666667, 0.0, 0.0, 19.0, 27.22312292273731, 1.026719521990562, 0.0, 1.0, 40.0, 27.295269410954095], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1110000.0000, 
sim time next is 1111200.0000, 
raw observation next is [13.46666666666667, 61.33333333333333, 0.0, 0.0, 19.0, 27.11617905050282, 0.9676364069702794, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.8356417359187445, 0.6133333333333333, 0.0, 0.0, 0.08333333333333333, 0.7596815875419015, 0.8225454689900932, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6087051], dtype=float32), -0.012915725]. 
=============================================
[2019-04-17 15:16:07,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.15856591 0.03898579 0.2263064  0.04924738 0.09772146 0.04470276
 0.05889245 0.08693228 0.04022497 0.07125191 0.12716863], sum to 1.0000
[2019-04-17 15:16:07,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4707
[2019-04-17 15:16:07,466] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [14.56666666666667, 78.0, 39.66666666666666, 0.0, 19.0, 27.16344375376472, 0.9633871537184856, 0.0, 1.0, 25.0, 28.973941920412287], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 1154400.0000, 
sim time next is 1155600.0000, 
raw observation next is [15.5, 75.0, 57.0, 0.0, 19.0, 27.15757438901959, 0.9638545390520751, 0.0, 1.0, 30.0, 28.06344295113406], 
processed observation next is [0.0, 0.391304347826087, 0.8919667590027703, 0.75, 0.19, 0.0, 0.08333333333333333, 0.7631311990849658, 0.8212848463506917, 0.0, 1.0, 0.3, 0.2806344295113406], 
reward next is 0.4194, 
noisyNet noise sample is [array([-0.54994214], dtype=float32), 0.028578205]. 
=============================================
[2019-04-17 15:16:09,912] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.10763852 0.0219683  0.09869643 0.02251389 0.12448232 0.03515043
 0.10930927 0.16168456 0.04506614 0.0631463  0.21034384], sum to 1.0000
[2019-04-17 15:16:09,913] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1475
[2019-04-17 15:16:10,042] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 19.0, 27.66403575595274, 1.126575309180395, 0.0, 0.0, 35.0, 23.347704927872122], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1231200.0000, 
sim time next is 1232400.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 19.0, 27.62628763771226, 1.121836397395976, 0.0, 0.0, 25.0, 20.444100230103825], 
processed observation next is [0.0, 0.2608695652173913, 0.8781163434903049, 0.96, 0.0, 0.0, 0.08333333333333333, 0.8021906364760216, 0.8739454657986586, 0.0, 0.0, 0.2, 0.20444100230103823], 
reward next is 0.5956, 
noisyNet noise sample is [array([-0.75293034], dtype=float32), -0.538681]. 
=============================================
[2019-04-17 15:16:10,740] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.13912445 0.02084471 0.33861864 0.03969352 0.07952975 0.03666032
 0.04766042 0.06588321 0.02831254 0.05626148 0.14741096], sum to 1.0000
[2019-04-17 15:16:10,740] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2325
[2019-04-17 15:16:10,752] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.8, 100.0, 45.66666666666666, 0.0, 19.0, 27.80320631230759, 1.196235955579009, 0.0, 1.0, 25.0, 21.113002717008193], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1266000.0000, 
sim time next is 1267200.0000, 
raw observation next is [13.8, 100.0, 35.0, 0.0, 19.0, 27.80333638219263, 1.196861515772092, 0.0, 1.0, 25.0, 21.076324019245206], 
processed observation next is [0.0, 0.6956521739130435, 0.844875346260388, 1.0, 0.11666666666666667, 0.0, 0.08333333333333333, 0.8169446985160524, 0.8989538385906973, 0.0, 1.0, 0.2, 0.21076324019245207], 
reward next is 0.5892, 
noisyNet noise sample is [array([0.91105396], dtype=float32), 0.1618411]. 
=============================================
[2019-04-17 15:16:12,807] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.08541838 0.00543401 0.35424381 0.03844196 0.1154867  0.0247916
 0.0533378  0.09932459 0.01358018 0.04527838 0.1646626 ], sum to 1.0000
[2019-04-17 15:16:12,808] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8285
[2019-04-17 15:16:12,826] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 26.21335670939445, 0.7712075593514794, 0.0, 1.0, 25.0, 27.508021626019378], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1383600.0000, 
sim time next is 1384800.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 19.0, 26.30827923868925, 0.8033519194036797, 0.0, 1.0, 60.0, 50.78275497466153], 
processed observation next is [1.0, 0.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.08333333333333333, 0.6923566032241041, 0.7677839731345598, 0.0, 1.0, 0.9, 0.5078275497466153], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.637397], dtype=float32), -0.88900477]. 
=============================================
[2019-04-17 15:16:12,938] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.11040942 0.00395088 0.3186906  0.02225478 0.0997899  0.01762494
 0.07187463 0.12015071 0.01056501 0.03258072 0.19210848], sum to 1.0000
[2019-04-17 15:16:12,938] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9298
[2019-04-17 15:16:12,975] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 19.0, 26.7462955869228, 0.9190581822276048, 0.0, 1.0, 20.0, 37.49329905520885], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 1375200.0000, 
sim time next is 1376400.0000, 
raw observation next is [0.3333333333333334, 95.66666666666666, 0.0, 0.0, 19.0, 26.7202351282836, 0.889546063831599, 0.0, 1.0, 65.0, 48.38184675505843], 
processed observation next is [1.0, 0.9565217391304348, 0.4718374884579871, 0.9566666666666666, 0.0, 0.0, 0.08333333333333333, 0.7266862606903001, 0.7965153546105329, 0.0, 1.0, 1.0, 0.48381846755058433], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9324504], dtype=float32), 0.66861176]. 
=============================================
[2019-04-17 15:16:13,529] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.06349509 0.00667258 0.30978313 0.04111712 0.137084   0.01915638
 0.05937055 0.08835755 0.01980661 0.04442441 0.21073253], sum to 1.0000
[2019-04-17 15:16:13,533] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3119
[2019-04-17 15:16:13,556] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.2, 96.66666666666666, 50.33333333333333, 0.0, 22.5, 27.12523692267091, 0.8811111299063216, 1.0, 1.0, 65.0, 33.53751332433657], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1417200.0000, 
sim time next is 1418400.0000, 
raw observation next is [0.0, 95.0, 59.0, 0.0, 22.5, 27.17911520908131, 0.8938700089934626, 1.0, 1.0, 25.0, 29.0365210563974], 
processed observation next is [1.0, 0.43478260869565216, 0.46260387811634357, 0.95, 0.19666666666666666, 0.0, 0.375, 0.7649262674234425, 0.7979566696644875, 1.0, 1.0, 0.2, 0.290365210563974], 
reward next is 0.5096, 
noisyNet noise sample is [array([-0.34747514], dtype=float32), 0.25156537]. 
=============================================
[2019-04-17 15:16:15,590] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.05367488 0.00357258 0.39120817 0.03199233 0.11330497 0.01662954
 0.02780312 0.1133353  0.01040279 0.04100814 0.19706826], sum to 1.0000
[2019-04-17 15:16:15,591] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3982
[2019-04-17 15:16:15,608] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.2, 96.0, 0.0, 0.0, 19.0, 26.38213512217272, 0.747188819857333, 0.0, 1.0, 50.0, 39.43623677907673], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1488000.0000, 
sim time next is 1489200.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 19.0, 26.4308848830688, 0.7430913246251013, 0.0, 1.0, 25.0, 35.70402748683648], 
processed observation next is [1.0, 0.21739130434782608, 0.5235457063711911, 0.96, 0.0, 0.0, 0.08333333333333333, 0.7025737402557333, 0.7476971082083671, 0.0, 1.0, 0.2, 0.3570402748683648], 
reward next is 0.4430, 
noisyNet noise sample is [array([0.4706572], dtype=float32), -0.3577743]. 
=============================================
[2019-04-17 15:16:29,891] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0855460e-03 2.7643226e-05 4.7483495e-01 2.1066954e-03 1.9597799e-02
 1.0051043e-03 5.8150254e-03 1.8160470e-02 2.9451835e-03 3.1104742e-03
 4.7031116e-01], sum to 1.0000
[2019-04-17 15:16:29,893] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1603
[2019-04-17 15:16:29,931] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.233333333333333, 79.0, 0.0, 0.0, 22.5, 24.86608599102275, 0.3435487674944055, 1.0, 1.0, 25.0, 40.32013358048712], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1971600.0000, 
sim time next is 1972800.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 22.5, 24.67336336686692, 0.3133334077896027, 0.0, 1.0, 25.0, 36.08009567771178], 
processed observation next is [1.0, 0.8695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.375, 0.5561136139055766, 0.6044444692632008, 0.0, 1.0, 0.2, 0.3608009567771178], 
reward next is 0.4392, 
noisyNet noise sample is [array([-0.98874545], dtype=float32), -1.9720939]. 
=============================================
[2019-04-17 15:16:33,961] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2708397e-03 2.2250637e-05 5.9520364e-01 2.0897319e-03 1.8408591e-02
 6.3696824e-04 2.3391980e-03 2.8584190e-02 1.9518515e-03 3.2481907e-03
 3.4624454e-01], sum to 1.0000
[2019-04-17 15:16:33,961] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3401
[2019-04-17 15:16:33,992] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-7.633333333333333, 81.0, 89.0, 50.5, 22.5, 25.33120367118591, 0.3860132083400855, 1.0, 1.0, 25.0, 47.51910819308658], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2104800.0000, 
sim time next is 2106000.0000, 
raw observation next is [-7.8, 82.0, 123.0, 77.5, 22.5, 25.29736519802336, 0.4012432955890788, 1.0, 1.0, 25.0, 39.194221906235384], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.82, 0.41, 0.0856353591160221, 0.375, 0.6081137665019467, 0.6337477651963596, 1.0, 1.0, 0.2, 0.3919422190623538], 
reward next is 0.4081, 
noisyNet noise sample is [array([0.2816064], dtype=float32), 0.47401202]. 
=============================================
[2019-04-17 15:16:35,769] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [4.9484649e-04 3.6306947e-06 5.0379938e-01 7.4147235e-04 5.1668864e-03
 2.4599498e-04 1.3903575e-03 1.0320551e-02 1.1470936e-03 6.2011147e-04
 4.7606966e-01], sum to 1.0000
[2019-04-17 15:16:35,769] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4522
[2019-04-17 15:16:35,915] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-4.300000000000001, 70.0, 138.6666666666667, 0.0, 22.5, 26.12041268975238, 0.5896301016097784, 1.0, 1.0, 65.0, 51.09819749236499], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2200800.0000, 
sim time next is 2202000.0000, 
raw observation next is [-4.1, 69.0, 140.5, 0.0, 22.5, 26.2362992807228, 0.6077730428130986, 1.0, 1.0, 25.0, 40.70107640400444], 
processed observation next is [1.0, 0.4782608695652174, 0.3490304709141275, 0.69, 0.4683333333333333, 0.0, 0.375, 0.6863582733935667, 0.7025910142710329, 1.0, 1.0, 0.2, 0.4070107640400444], 
reward next is 0.3930, 
noisyNet noise sample is [array([-0.5340722], dtype=float32), 2.4774058]. 
=============================================
[2019-04-17 15:16:38,225] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3458236e-04 2.0787481e-06 5.9747893e-01 4.3772600e-04 4.8106606e-03
 1.2443696e-04 8.7673950e-04 1.0601090e-02 5.5715401e-04 5.3492398e-04
 3.8434175e-01], sum to 1.0000
[2019-04-17 15:16:38,237] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0366
[2019-04-17 15:16:38,275] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.6, 71.0, 0.0, 0.0, 19.0, 25.63512499569543, 0.5631432348102651, 0.0, 1.0, 25.0, 44.57951169763219], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2239200.0000, 
sim time next is 2240400.0000, 
raw observation next is [-5.8, 72.33333333333334, 0.0, 0.0, 19.0, 25.54587022455858, 0.5023125810325216, 0.0, 1.0, 25.0, 44.46202449305447], 
processed observation next is [1.0, 0.9565217391304348, 0.30193905817174516, 0.7233333333333334, 0.0, 0.0, 0.08333333333333333, 0.628822518713215, 0.6674375270108405, 0.0, 1.0, 0.2, 0.4446202449305447], 
reward next is 0.3554, 
noisyNet noise sample is [array([-0.13357699], dtype=float32), -2.1268594]. 
=============================================
[2019-04-17 15:16:40,916] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3838761e-03 4.0100953e-05 7.1097291e-01 2.6844312e-03 7.9425154e-03
 8.7488111e-04 2.2543315e-03 2.4171334e-02 3.5414121e-03 3.6158229e-03
 2.4151838e-01], sum to 1.0000
[2019-04-17 15:16:40,916] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3567
[2019-04-17 15:16:40,944] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.4, 42.33333333333333, 0.0, 0.0, 19.0, 25.30372851265995, 0.3589457758331112, 0.0, 1.0, 25.0, 46.92879416846862], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2418000.0000, 
sim time next is 2419200.0000, 
raw observation next is [-5.6, 43.0, 0.0, 0.0, 19.0, 25.22185840439547, 0.3354534567153431, 0.0, 1.0, 25.0, 40.93793105139946], 
processed observation next is [0.0, 0.0, 0.30747922437673136, 0.43, 0.0, 0.0, 0.08333333333333333, 0.6018215336996224, 0.6118178189051143, 0.0, 1.0, 0.2, 0.4093793105139946], 
reward next is 0.3906, 
noisyNet noise sample is [array([0.598006], dtype=float32), -0.583513]. 
=============================================
[2019-04-17 15:16:42,827] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1153510e-03 1.1689509e-05 6.1896741e-01 2.5243426e-03 3.2348339e-03
 4.4413775e-04 1.2714098e-03 8.3430763e-03 2.0905505e-03 1.5600660e-03
 3.6043710e-01], sum to 1.0000
[2019-04-17 15:16:42,828] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6395
[2019-04-17 15:16:42,855] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.6, 43.0, 0.0, 0.0, 19.0, 25.24682172061039, 0.3788416655524264, 0.0, 1.0, 65.0, 59.16939023451678], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2419200.0000, 
sim time next is 2420400.0000, 
raw observation next is [-5.8, 44.66666666666667, 0.0, 0.0, 19.0, 25.29887144816351, 0.385311376740762, 0.0, 1.0, 60.0, 49.91418584589135], 
processed observation next is [0.0, 0.0, 0.30193905817174516, 0.4466666666666667, 0.0, 0.0, 0.08333333333333333, 0.6082392873469592, 0.628437125580254, 0.0, 1.0, 0.9, 0.4991418584589135], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.28599435], dtype=float32), -1.1438956]. 
=============================================
[2019-04-17 15:16:43,005] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.8787958e-04 3.6658945e-05 6.1918199e-01 3.2679746e-03 9.1195265e-03
 9.3698979e-04 2.4448738e-03 1.1955311e-02 3.2198939e-03 2.2254663e-03
 3.4662348e-01], sum to 1.0000
[2019-04-17 15:16:43,007] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9022
[2019-04-17 15:16:43,130] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-6.933333333333334, 51.33333333333333, 0.0, 0.0, 19.0, 25.42853725198362, 0.396454279665279, 0.0, 1.0, 25.0, 38.147091872731835], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2425200.0000, 
sim time next is 2426400.0000, 
raw observation next is [-7.3, 53.0, 0.0, 0.0, 19.0, 25.24927939677561, 0.394666707305861, 0.0, 1.0, 65.0, 59.26136563619305], 
processed observation next is [0.0, 0.08695652173913043, 0.26038781163434904, 0.53, 0.0, 0.0, 0.08333333333333333, 0.6041066163979675, 0.6315555691019537, 0.0, 1.0, 1.0, 0.5926136563619305], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.39778715], dtype=float32), -1.6010981]. 
=============================================
[2019-04-17 15:16:44,689] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.0044182e-04 1.3775137e-05 6.6404778e-01 1.5202204e-03 3.6575170e-03
 4.2189079e-04 1.5743384e-03 1.8260775e-02 3.2700838e-03 1.6267666e-03
 3.0510634e-01], sum to 1.0000
[2019-04-17 15:16:44,690] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0786
[2019-04-17 15:16:44,720] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.8666666666666667, 31.66666666666667, 0.0, 0.0, 19.0, 25.14505800867159, 0.3727056807125471, 0.0, 1.0, 65.0, 60.07610094865976], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2492400.0000, 
sim time next is 2493600.0000, 
raw observation next is [-1.033333333333333, 34.33333333333333, 0.0, 0.0, 19.0, 25.37441540386266, 0.4017579424689803, 0.0, 1.0, 25.0, 42.308987573270855], 
processed observation next is [0.0, 0.8695652173913043, 0.43397968605724846, 0.34333333333333327, 0.0, 0.0, 0.08333333333333333, 0.6145346169885549, 0.6339193141563267, 0.0, 1.0, 0.2, 0.42308987573270856], 
reward next is 0.3769, 
noisyNet noise sample is [array([-1.2540635], dtype=float32), 0.7760791]. 
=============================================
[2019-04-17 15:16:47,760] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2840889e-05 7.2019368e-08 5.2016062e-01 7.3643256e-05 9.6727349e-04
 2.7508424e-05 2.3646548e-04 2.6954736e-03 1.5568793e-04 8.3094550e-05
 4.7555736e-01], sum to 1.0000
[2019-04-17 15:16:47,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5544
[2019-04-17 15:16:47,803] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-1.333333333333333, 41.33333333333334, 0.0, 0.0, 22.5, 26.53078700687507, 0.7147188985990621, 0.0, 1.0, 25.0, 32.065050290584544], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2576400.0000, 
sim time next is 2577600.0000, 
raw observation next is [-1.7, 44.0, 0.0, 0.0, 22.5, 26.46436610637397, 0.7084570164325251, 0.0, 1.0, 65.0, 45.42944694784445], 
processed observation next is [1.0, 0.8695652173913043, 0.4155124653739613, 0.44, 0.0, 0.0, 0.375, 0.7053638421978308, 0.7361523388108417, 0.0, 1.0, 1.0, 0.4542944694784445], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.45804647], dtype=float32), -0.4104741]. 
=============================================
[2019-04-17 15:16:49,318] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4886340e-05 3.4060761e-08 5.6715345e-01 3.6338199e-05 7.2657689e-04
 1.2215520e-05 1.7581384e-04 1.6791152e-03 1.6285355e-04 1.0509584e-04
 4.2993367e-01], sum to 1.0000
[2019-04-17 15:16:49,319] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1560
[2019-04-17 15:16:49,446] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.7, 29.0, 38.5, 83.5, 22.5, 27.19676962834003, 0.8010390053254719, 1.0, 1.0, 25.0, 28.479936215557274], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2566800.0000, 
sim time next is 2568000.0000, 
raw observation next is [1.966666666666667, 31.0, 17.5, 31.16666666666666, 22.5, 27.25603248352758, 0.7890501514160708, 1.0, 1.0, 25.0, 31.33521793473242], 
processed observation next is [1.0, 0.7391304347826086, 0.5170821791320407, 0.31, 0.058333333333333334, 0.03443830570902393, 0.375, 0.771336040293965, 0.7630167171386902, 1.0, 1.0, 0.2, 0.3133521793473242], 
reward next is 0.4866, 
noisyNet noise sample is [array([0.19135468], dtype=float32), 0.7571032]. 
=============================================
[2019-04-17 15:16:50,682] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0343084e-05 1.1882817e-07 6.7803025e-01 3.1321705e-04 1.9239191e-03
 4.5743691e-05 3.1120962e-04 5.9673861e-03 2.1004987e-04 2.3396492e-04
 3.1293386e-01], sum to 1.0000
[2019-04-17 15:16:50,682] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9477
[2019-04-17 15:16:50,716] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-9.0, 69.0, 0.0, 0.0, 19.0, 24.97706415694273, 0.4446755543141456, 0.0, 1.0, 65.0, 76.39384151155997], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2682000.0000, 
sim time next is 2683200.0000, 
raw observation next is [-9.666666666666668, 71.33333333333334, 0.0, 0.0, 19.0, 25.23636760604068, 0.4861512098811485, 0.0, 1.0, 65.0, 66.74967981692556], 
processed observation next is [1.0, 0.043478260869565216, 0.19482917820867957, 0.7133333333333334, 0.0, 0.0, 0.08333333333333333, 0.6030306338367234, 0.6620504032937161, 0.0, 1.0, 1.0, 0.6674967981692557], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3789538], dtype=float32), 0.9416015]. 
=============================================
[2019-04-17 15:16:52,790] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0064154e-05 1.0291353e-08 8.1678528e-01 4.2395153e-05 6.0336484e-04
 6.4728692e-06 1.0085181e-04 2.2461133e-03 5.0255545e-05 3.5758771e-05
 1.8011938e-01], sum to 1.0000
[2019-04-17 15:16:52,790] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5135
[2019-04-17 15:16:52,832] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.333333333333334, 60.66666666666667, 0.0, 0.0, 19.0, 25.82780246729468, 0.5921748208667624, 0.0, 1.0, 25.0, 56.06849810587437], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2751600.0000, 
sim time next is 2752800.0000, 
raw observation next is [-5.666666666666667, 62.33333333333333, 0.0, 0.0, 19.0, 25.76415650862333, 0.5779387518071225, 0.0, 1.0, 25.0, 49.57897737214424], 
processed observation next is [1.0, 0.8695652173913043, 0.30563250230840255, 0.6233333333333333, 0.0, 0.0, 0.08333333333333333, 0.6470130423852775, 0.6926462506023742, 0.0, 1.0, 0.2, 0.4957897737214424], 
reward next is 0.3042, 
noisyNet noise sample is [array([0.49361894], dtype=float32), 0.3182028]. 
=============================================
[2019-04-17 15:16:56,092] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.8477279e-05 2.5251410e-07 8.7797099e-01 1.6894532e-04 1.8658873e-03
 3.7628801e-05 1.2691415e-04 3.9552199e-03 2.1402116e-04 2.3517509e-04
 1.1537646e-01], sum to 1.0000
[2019-04-17 15:16:56,092] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6904
[2019-04-17 15:16:56,103] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.666666666666667, 95.33333333333334, 0.0, 0.0, 19.0, 22.2609892842999, -0.2885097652507642, 0.0, 1.0, 25.0, 18.881449504487122], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2875200.0000, 
sim time next is 2876400.0000, 
raw observation next is [2.0, 93.0, 0.0, 0.0, 19.0, 22.2318184029514, -0.3054782270523851, 0.0, 1.0, 25.0, 17.883795054174207], 
processed observation next is [1.0, 0.30434782608695654, 0.518005540166205, 0.93, 0.0, 0.0, 0.08333333333333333, 0.3526515335792834, 0.3981739243158717, 0.0, 1.0, 0.2, 0.17883795054174206], 
reward next is 0.6212, 
noisyNet noise sample is [array([-0.20565648], dtype=float32), 0.6204607]. 
=============================================
[2019-04-17 15:16:58,135] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.09992912e-07 2.68480654e-10 7.63152063e-01 7.05557522e-06
 1.64760349e-04 4.46197049e-07 1.33265685e-05 6.03120250e-04
 1.71562278e-05 1.61830285e-05 2.36025110e-01], sum to 1.0000
[2019-04-17 15:16:58,136] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6332
[2019-04-17 15:16:58,158] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.333333333333333, 93.0, 0.0, 0.0, 22.5, 25.06465064641282, 0.4586338631409, 1.0, 1.0, 65.0, 60.64543167145763], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2914800.0000, 
sim time next is 2916000.0000, 
raw observation next is [1.0, 93.0, 0.0, 0.0, 22.5, 25.38777490795038, 0.4708431563331605, 1.0, 1.0, 25.0, 45.24888133613088], 
processed observation next is [1.0, 0.782608695652174, 0.4903047091412743, 0.93, 0.0, 0.0, 0.375, 0.615647908995865, 0.6569477187777202, 1.0, 1.0, 0.2, 0.4524888133613088], 
reward next is 0.3475, 
noisyNet noise sample is [array([-0.14260429], dtype=float32), -0.67964906]. 
=============================================
[2019-04-17 15:16:58,186] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39209: loss 60.7532
[2019-04-17 15:16:58,230] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39210: learning rate 0.0001
[2019-04-17 15:16:58,496] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39359: loss 36.0951
[2019-04-17 15:16:58,501] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39359: learning rate 0.0001
[2019-04-17 15:16:58,875] A3C_AGENT_WORKER-Thread-8 INFO:Local step 2500, global step 39578: loss 80.1039
[2019-04-17 15:16:58,876] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 2500, global step 39578: learning rate 0.0001
[2019-04-17 15:16:59,363] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2500, global step 39833: loss 134.6482
[2019-04-17 15:16:59,366] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 2500, global step 39833: learning rate 0.0001
[2019-04-17 15:16:59,405] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39857: loss 57.7085
[2019-04-17 15:16:59,405] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39857: learning rate 0.0001
[2019-04-17 15:16:59,418] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39861: loss 105.9088
[2019-04-17 15:16:59,419] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39861: learning rate 0.0001
[2019-04-17 15:16:59,426] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39866: loss 81.9915
[2019-04-17 15:16:59,426] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39866: learning rate 0.0001
[2019-04-17 15:16:59,452] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2500, global step 39878: loss 137.3039
[2019-04-17 15:16:59,453] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 2500, global step 39878: learning rate 0.0001
[2019-04-17 15:16:59,510] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2500, global step 39910: loss 219.8745
[2019-04-17 15:16:59,511] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 2500, global step 39910: learning rate 0.0001
[2019-04-17 15:16:59,661] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39992: loss 196.5131
[2019-04-17 15:16:59,662] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39993: learning rate 0.0001
[2019-04-17 15:17:00,056] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40197: loss 63.9721
[2019-04-17 15:17:00,062] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 40199: learning rate 0.0001
[2019-04-17 15:17:00,068] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40202: loss 42.4207
[2019-04-17 15:17:00,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40203: learning rate 0.0001
[2019-04-17 15:17:00,169] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40263: loss 98.2348
[2019-04-17 15:17:00,169] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 40263: learning rate 0.0001
[2019-04-17 15:17:00,354] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40366: loss 57.7974
[2019-04-17 15:17:00,355] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40366: learning rate 0.0001
[2019-04-17 15:17:00,755] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2500, global step 40590: loss 148.3652
[2019-04-17 15:17:00,755] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 2500, global step 40590: learning rate 0.0001
[2019-04-17 15:17:01,840] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 41156: loss 55.6619
[2019-04-17 15:17:01,842] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 41158: learning rate 0.0001
[2019-04-17 15:17:08,149] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3704059e-08 1.9635451e-11 9.1871828e-01 1.9254026e-06 1.6845994e-05
 7.2192371e-08 1.9295680e-06 1.8404116e-04 5.4008265e-06 9.7995053e-07
 8.1070296e-02], sum to 1.0000
[2019-04-17 15:17:08,153] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8096
[2019-04-17 15:17:08,219] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.666666666666667, 50.0, 107.3333333333333, 760.0, 22.5, 26.1356719132576, 0.5895285136539531, 1.0, 1.0, 25.0, 36.65614667078863], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3334800.0000, 
sim time next is 3336000.0000, 
raw observation next is [-3.333333333333333, 50.0, 102.8333333333333, 739.0, 22.5, 25.70562866513669, 0.5399432817527203, 1.0, 1.0, 25.0, 35.04373443166148], 
processed observation next is [1.0, 0.6086956521739131, 0.37026777469990774, 0.5, 0.3427777777777777, 0.8165745856353591, 0.375, 0.6421357220947241, 0.6799810939175734, 1.0, 1.0, 0.2, 0.3504373443166148], 
reward next is 0.4496, 
noisyNet noise sample is [array([-1.3277618], dtype=float32), 0.52126735]. 
=============================================
[2019-04-17 15:17:08,512] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8277645e-07 8.2450956e-11 9.4796383e-01 1.5336470e-06 3.4234850e-05
 1.6962727e-07 4.8312290e-06 2.6477195e-04 9.3832741e-06 3.0720555e-06
 5.1717840e-02], sum to 1.0000
[2019-04-17 15:17:08,512] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7918
[2019-04-17 15:17:08,557] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.333333333333333, 51.66666666666667, 19.16666666666666, 194.3333333333333, 22.5, 25.93991415489705, 0.3984821712527577, 1.0, 1.0, 25.0, 26.087338736251873], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3345600.0000, 
sim time next is 3346800.0000, 
raw observation next is [-2.666666666666667, 53.33333333333333, 9.166666666666668, 110.8333333333333, 22.5, 25.31387263073795, 0.4618761984752091, 1.0, 1.0, 25.0, 23.636933476010363], 
processed observation next is [1.0, 0.7391304347826086, 0.38873499538319484, 0.5333333333333333, 0.030555555555555558, 0.12246777163904232, 0.375, 0.6094893858948293, 0.6539587328250697, 1.0, 1.0, 0.2, 0.23636933476010363], 
reward next is 0.5636, 
noisyNet noise sample is [array([0.20900263], dtype=float32), 1.9583031]. 
=============================================
[2019-04-17 15:17:09,693] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2453867e-07 3.6722129e-11 9.3258059e-01 2.6285593e-06 2.1213533e-05
 1.4371929e-07 1.8375922e-06 1.9751617e-04 3.9936858e-06 1.9039070e-06
 6.7189932e-02], sum to 1.0000
[2019-04-17 15:17:09,694] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1319
[2019-04-17 15:17:09,718] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 19.0, 25.29486507865768, 0.4834185565865508, 0.0, 1.0, 25.0, 24.31093287584548], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3360000.0000, 
sim time next is 3361200.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 19.0, 25.13635507349629, 0.4536682496548806, 0.0, 1.0, 25.0, 22.056078610817174], 
processed observation next is [1.0, 0.9130434782608695, 0.3518005540166205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.5946962561246908, 0.6512227498849602, 0.0, 1.0, 0.2, 0.22056078610817173], 
reward next is 0.5794, 
noisyNet noise sample is [array([-0.10666075], dtype=float32), 0.10916647]. 
=============================================
[2019-04-17 15:17:11,372] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.40060091e-07 3.76293691e-10 8.60012472e-01 1.00208335e-05
 5.47806267e-05 7.17819205e-07 3.84695250e-06 3.25074536e-04
 7.86056080e-06 7.59547220e-06 1.39577091e-01], sum to 1.0000
[2019-04-17 15:17:11,375] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2990
[2019-04-17 15:17:11,409] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 24.72788865687088, 0.3555905864316232, 0.0, 1.0, 65.0, 63.46279615041922], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3480000.0000, 
sim time next is 3481200.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 24.96421056878255, 0.3701984396843743, 0.0, 1.0, 25.0, 55.67340218423716], 
processed observation next is [1.0, 0.30434782608695654, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.5803508807318792, 0.6233994798947914, 0.0, 1.0, 0.2, 0.5567340218423716], 
reward next is 0.2433, 
noisyNet noise sample is [array([-0.21655032], dtype=float32), -1.3140433]. 
=============================================
[2019-04-17 15:17:15,128] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.27241719e-06 1.11902025e-08 8.70384395e-01 1.35413802e-05
 3.54576659e-05 1.75486582e-06 4.42258570e-05 1.33868877e-03
 1.96750945e-04 2.88651427e-05 1.27953038e-01], sum to 1.0000
[2019-04-17 15:17:15,129] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2521
[2019-04-17 15:17:15,170] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 43.0, 74.5, 607.0, 19.0, 23.27882085539624, -0.04728122257414447, 0.0, 1.0, 25.0, 44.80768848991022], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3600000.0000, 
sim time next is 3601200.0000, 
raw observation next is [0.0, 41.66666666666667, 66.83333333333333, 545.6666666666666, 19.0, 23.48244036936397, -0.0356263733794949, 0.0, 1.0, 25.0, 39.42834711374242], 
processed observation next is [0.0, 0.6956521739130435, 0.46260387811634357, 0.41666666666666674, 0.22277777777777777, 0.6029465930018416, 0.08333333333333333, 0.4568700307803309, 0.48812454220683504, 0.0, 1.0, 0.2, 0.3942834711374242], 
reward next is 0.4057, 
noisyNet noise sample is [array([-0.36245656], dtype=float32), 1.980465]. 
=============================================
[2019-04-17 15:17:16,031] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.5664186e-07 1.0647766e-09 8.9076364e-01 5.1490520e-06 1.1843661e-05
 1.0111988e-06 1.6134005e-05 4.9519038e-04 9.3731600e-05 3.2767841e-06
 1.0860957e-01], sum to 1.0000
[2019-04-17 15:17:16,031] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5488
[2019-04-17 15:17:16,061] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [5.333333333333334, 42.33333333333334, 113.6666666666667, 819.8333333333334, 19.0, 24.75463977893792, 0.263209604759384, 0.0, 1.0, 25.0, 24.503050766167092], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3676800.0000, 
sim time next is 3678000.0000, 
raw observation next is [5.666666666666667, 42.66666666666666, 111.5, 811.0, 19.0, 24.75577555516943, 0.2667606536012639, 0.0, 1.0, 25.0, 22.41045585196997], 
processed observation next is [0.0, 0.5652173913043478, 0.6195752539242845, 0.4266666666666666, 0.37166666666666665, 0.8961325966850828, 0.08333333333333333, 0.5629812962641191, 0.5889202178670879, 0.0, 1.0, 0.2, 0.2241045585196997], 
reward next is 0.5759, 
noisyNet noise sample is [array([-0.6690431], dtype=float32), -1.2494541]. 
=============================================
[2019-04-17 15:17:16,593] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6385603e-07 3.0091640e-10 9.1621399e-01 5.4155353e-06 1.4106543e-05
 3.7049395e-07 6.5231757e-06 3.9488141e-04 1.6643855e-05 5.2788414e-06
 8.3342433e-02], sum to 1.0000
[2019-04-17 15:17:16,595] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3306
[2019-04-17 15:17:16,624] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.333333333333333, 65.33333333333334, 0.0, 0.0, 19.0, 24.89002471439345, 0.2601420060150123, 0.0, 1.0, 25.0, 22.514936836859086], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3705600.0000, 
sim time next is 3706800.0000, 
raw observation next is [0.6666666666666667, 68.66666666666667, 0.0, 0.0, 19.0, 24.7117926832396, 0.2285841187418773, 0.0, 1.0, 25.0, 20.565360627082057], 
processed observation next is [0.0, 0.9130434782608695, 0.4810710987996307, 0.6866666666666668, 0.0, 0.0, 0.08333333333333333, 0.5593160569366334, 0.5761947062472924, 0.0, 1.0, 0.2, 0.20565360627082058], 
reward next is 0.5943, 
noisyNet noise sample is [array([-0.5494535], dtype=float32), -2.42438]. 
=============================================
[2019-04-17 15:17:17,475] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-17 15:17:17,475] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-17 15:17:17,476] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation job starts!
[2019-04-17 15:17:17,476] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:17:17,476] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:17:17,477] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation job starts!
[2019-04-17 15:17:17,477] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:17:17,484] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res1/Eplus-env-sub_run2
[2019-04-17 15:17:17,500] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v2-res1/Eplus-env-sub_run2
[2019-04-17 15:17:17,513] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v1-res1/Eplus-env-sub_run2
[2019-04-17 15:18:05,639] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08957276], dtype=float32), 0.06362119]
[2019-04-17 15:18:05,639] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:Observation this: [10.13333333333333, 87.33333333333334, 0.0, 0.0, 19.0, 26.208450007982, 0.7512421257946698, 0.0, 1.0, 25.0, 15.1883422844678]
[2019-04-17 15:18:05,639] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-04-17 15:18:05,641] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Softmax [3.8435722e-08 2.9339531e-11 8.7740922e-01 1.4006910e-06 4.4368539e-06
 7.7056008e-08 5.9744974e-07 1.1866613e-04 4.9220794e-06 1.3676126e-06
 1.2245911e-01], sampled 0.33664963123369307
[2019-04-17 15:19:14,091] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2047.9280 119270.8671 568.7146
[2019-04-17 15:19:14,136] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:19:14,136] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:19:14,478] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:19:14,478] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:19:38,108] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2038.4882 128382.2142 289.5119
[2019-04-17 15:19:38,183] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:19:38,183] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:19:38,280] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2030.0472 128124.8721 9.3471
[2019-04-17 15:19:38,315] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:19:38,315] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:19:38,440] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:19:38,440] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:19:38,550] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:19:38,550] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:19:39,317] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 50000, evaluation results [50000.0, 2038.4882145359625, 128382.21424847958, 289.51194942426287, 2047.9279871126655, 119270.8671371331, 568.7146333025895, 2030.0471755725403, 128124.87209290786, 9.34708389021426]
[2019-04-17 15:19:43,592] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6435145e-07 3.0294786e-10 9.3408245e-01 5.1153502e-06 1.8463101e-05
 3.3856071e-07 2.2962374e-06 4.4604074e-04 7.5777616e-06 5.1001034e-06
 6.5432385e-02], sum to 1.0000
[2019-04-17 15:19:43,593] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1656
[2019-04-17 15:19:43,666] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.666666666666667, 69.0, 0.0, 0.0, 19.0, 23.69256153185307, 0.03820231653765643, 0.0, 1.0, 25.0, 22.126447481989523], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3901200.0000, 
sim time next is 3902400.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 19.0, 23.5162800874171, 0.01385681648888859, 0.0, 1.0, 25.0, 20.216026122256295], 
processed observation next is [1.0, 0.17391304347826086, 0.3795013850415513, 0.71, 0.0, 0.0, 0.08333333333333333, 0.45969000728475845, 0.5046189388296295, 0.0, 1.0, 0.2, 0.20216026122256295], 
reward next is 0.5978, 
noisyNet noise sample is [array([-0.32639694], dtype=float32), -0.91589695]. 
=============================================
[2019-04-17 15:19:44,978] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0849188e-10 9.8499889e-14 8.1831330e-01 4.3414236e-08 8.0217103e-07
 9.1267616e-10 6.4588271e-08 3.0805291e-05 2.5586752e-07 3.6983256e-08
 1.8165474e-01], sum to 1.0000
[2019-04-17 15:19:44,978] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5773
[2019-04-17 15:19:45,036] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.666666666666667, 46.0, 83.16666666666666, 689.3333333333333, 22.5, 26.98182405235865, 0.802272552949642, 1.0, 1.0, 25.0, 28.209043141949273], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3858000.0000, 
sim time next is 3859200.0000, 
raw observation next is [3.0, 45.0, 75.5, 634.0, 22.5, 27.05242764186601, 0.8230209459435963, 1.0, 1.0, 25.0, 24.703993257276288], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.45, 0.25166666666666665, 0.7005524861878453, 0.375, 0.7543689701555009, 0.7743403153145322, 1.0, 1.0, 0.2, 0.24703993257276288], 
reward next is 0.5530, 
noisyNet noise sample is [array([-0.6368432], dtype=float32), -0.9015151]. 
=============================================
[2019-04-17 15:19:47,187] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3323888e-08 5.5407991e-11 8.5210937e-01 3.1471943e-06 2.0344722e-05
 1.9851520e-07 1.5910222e-06 3.1083875e-04 6.4140886e-06 2.3936723e-06
 1.4754552e-01], sum to 1.0000
[2019-04-17 15:19:47,187] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8869
[2019-04-17 15:19:47,241] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-4.666666666666667, 71.0, 0.0, 0.0, 19.0, 24.24889040458533, 0.190508914357453, 0.0, 1.0, 25.0, 19.179880040116316], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 3907200.0000, 
sim time next is 3908400.0000, 
raw observation next is [-5.333333333333334, 65.0, 0.0, 0.0, 19.0, 24.09014325591828, 0.2170276281430082, 0.0, 1.0, 65.0, 76.84486707031489], 
processed observation next is [1.0, 0.21739130434782608, 0.31486611265004616, 0.65, 0.0, 0.0, 0.08333333333333333, 0.5075119379931902, 0.572342542714336, 0.0, 1.0, 1.0, 0.7684486707031489], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0711497], dtype=float32), -0.87731296]. 
=============================================
[2019-04-17 15:20:12,301] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7786808e-11 3.7109483e-15 9.6936685e-01 2.7604454e-09 3.7690338e-08
 3.0902125e-10 8.7516865e-09 5.0828735e-06 3.6849560e-08 4.9306657e-09
 3.0627983e-02], sum to 1.0000
[2019-04-17 15:20:12,302] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0807
[2019-04-17 15:20:12,324] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.56666666666667, 29.66666666666667, 115.5, 843.8333333333334, 22.5, 24.25459277796103, 0.1731715413502637, 1.0, 1.0, 25.0, 1.2278846597321524], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4368000.0000, 
sim time next is 4369200.0000, 
raw observation next is [14.53333333333333, 30.33333333333333, 128.3333333333333, 806.5, 22.5, 24.71050912605575, 0.2276296240681448, 1.0, 1.0, 25.0, 1.137657129247379], 
processed observation next is [1.0, 0.5652173913043478, 0.8651892890120036, 0.3033333333333333, 0.42777777777777765, 0.8911602209944751, 0.375, 0.5592090938379792, 0.5758765413560483, 1.0, 1.0, 0.2, 0.01137657129247379], 
reward next is 0.7886, 
noisyNet noise sample is [array([0.19154784], dtype=float32), 0.119960144]. 
=============================================
[2019-04-17 15:20:12,729] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5956249e-10 3.7524085e-15 9.0033406e-01 5.4936460e-09 8.7176055e-08
 2.8020811e-10 4.7789928e-09 1.1161520e-05 8.7220798e-08 5.6613341e-09
 9.9654518e-02], sum to 1.0000
[2019-04-17 15:20:12,730] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5883
[2019-04-17 15:20:12,773] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.6, 29.0, 116.5, 847.5, 22.5, 24.51388942348082, 0.1172827609264943, 1.0, 1.0, 25.0, 2.1214118067139367], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4366800.0000, 
sim time next is 4368000.0000, 
raw observation next is [14.56666666666667, 29.66666666666667, 115.5, 843.8333333333334, 22.5, 24.10825886780353, 0.1882615863674442, 1.0, 1.0, 25.0, 2.0685206998352954], 
processed observation next is [1.0, 0.5652173913043478, 0.8661126500461682, 0.2966666666666667, 0.385, 0.9324125230202579, 0.375, 0.509021572316961, 0.5627538621224814, 1.0, 1.0, 0.2, 0.020685206998352954], 
reward next is 0.7793, 
noisyNet noise sample is [array([-0.66853917], dtype=float32), 0.27547747]. 
=============================================
[2019-04-17 15:20:13,089] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.8902071e-11 2.7845742e-16 9.8202270e-01 1.2714128e-09 4.1134044e-08
 7.3114452e-11 3.3013368e-09 1.3022569e-06 1.2067960e-08 6.0783565e-09
 1.7975982e-02], sum to 1.0000
[2019-04-17 15:20:13,089] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2453
[2019-04-17 15:20:13,116] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 92.0, 177.5, 5.0, 22.5, 24.89136835237693, 0.336572444797534, 1.0, 1.0, 25.0, 10.51683218167801], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4455600.0000, 
sim time next is 4456800.0000, 
raw observation next is [0.0, 92.0, 140.5, 3.0, 22.5, 24.93375928065269, 0.3478950197820441, 1.0, 1.0, 25.0, 10.660179072058074], 
processed observation next is [1.0, 0.6086956521739131, 0.46260387811634357, 0.92, 0.4683333333333333, 0.0033149171270718232, 0.375, 0.5778132733877243, 0.6159650065940147, 1.0, 1.0, 0.2, 0.10660179072058075], 
reward next is 0.6934, 
noisyNet noise sample is [array([-0.11665442], dtype=float32), 1.0713661]. 
=============================================
[2019-04-17 15:20:15,135] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9388281e-11 2.5889712e-15 9.7951138e-01 4.6111306e-09 1.6892990e-08
 1.4123468e-10 2.9746834e-09 3.7290279e-06 3.4319292e-08 8.8236796e-09
 2.0484801e-02], sum to 1.0000
[2019-04-17 15:20:15,136] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7005
[2019-04-17 15:20:15,186] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.666666666666667, 50.0, 249.8333333333333, 58.83333333333333, 22.5, 23.77536607830706, 0.0999202173353619, 1.0, 1.0, 65.0, 71.83736897857261], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4542000.0000, 
sim time next is 4543200.0000, 
raw observation next is [3.0, 49.0, 255.5, 80.5, 22.5, 24.38345344193709, 0.1463092481688232, 1.0, 1.0, 25.0, 48.78153504218039], 
processed observation next is [1.0, 0.6086956521739131, 0.5457063711911359, 0.49, 0.8516666666666667, 0.08895027624309393, 0.375, 0.5319544534947575, 0.5487697493896078, 1.0, 1.0, 0.2, 0.48781535042180385], 
reward next is 0.3122, 
noisyNet noise sample is [array([-1.060922], dtype=float32), -1.3563546]. 
=============================================
[2019-04-17 15:20:19,402] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2605320e-09 1.6767699e-13 9.2472678e-01 1.4839686e-07 5.7624828e-07
 2.0002582e-09 3.7666450e-08 2.4212524e-05 1.0871114e-06 7.0051335e-08
 7.5247213e-02], sum to 1.0000
[2019-04-17 15:20:19,402] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8248
[2019-04-17 15:20:19,432] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.333333333333333, 67.33333333333334, 157.1666666666667, 452.6666666666667, 22.5, 22.64166080161967, -0.2381663136890401, 1.0, 1.0, 25.0, 12.335324006619569], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4612800.0000, 
sim time next is 4614000.0000, 
raw observation next is [-0.6666666666666667, 63.66666666666667, 158.1666666666667, 552.0, 22.5, 22.83554624775554, -0.2052292562486416, 1.0, 1.0, 25.0, 11.408471046448721], 
processed observation next is [1.0, 0.391304347826087, 0.44413665743305636, 0.6366666666666667, 0.5272222222222224, 0.6099447513812155, 0.375, 0.4029621873129618, 0.4315902479171195, 1.0, 1.0, 0.2, 0.1140847104644872], 
reward next is 0.6859, 
noisyNet noise sample is [array([0.45416728], dtype=float32), 0.30626023]. 
=============================================
[2019-04-17 15:20:20,071] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.47364845e-11 3.79590785e-15 9.50236738e-01 1.04163593e-08
 1.09194644e-07 2.03072364e-10 3.96823818e-09 1.55316666e-05
 2.58471591e-08 9.01221853e-09 4.97476421e-02], sum to 1.0000
[2019-04-17 15:20:20,071] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1925
[2019-04-17 15:20:20,099] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 19.0, 24.29780695982799, 0.2514668906604125, 0.0, 1.0, 25.0, 11.383883586304975], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4652400.0000, 
sim time next is 4653600.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 19.0, 24.21759972512191, 0.2355220678908232, 0.0, 1.0, 25.0, 10.727265422585731], 
processed observation next is [1.0, 0.8695652173913043, 0.518005540166205, 0.52, 0.0, 0.0, 0.08333333333333333, 0.5181333104268259, 0.5785073559636077, 0.0, 1.0, 0.2, 0.10727265422585731], 
reward next is 0.6927, 
noisyNet noise sample is [array([-0.25756294], dtype=float32), 0.563648]. 
=============================================
[2019-04-17 15:20:21,319] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.3854128e-09 5.7047178e-13 9.4296169e-01 1.9932598e-07 6.2331242e-07
 4.4832822e-09 7.0271732e-08 3.6372094e-05 2.9003502e-07 1.6594761e-07
 5.7000510e-02], sum to 1.0000
[2019-04-17 15:20:21,322] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8162
[2019-04-17 15:20:21,344] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 19.0, 23.05464647028099, -0.1471459958664229, 0.0, 1.0, 25.0, 7.71967642317097], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4688400.0000, 
sim time next is 4689600.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 19.0, 22.95886705345655, -0.1540022093173087, 0.0, 1.0, 25.0, 7.948207559866885], 
processed observation next is [1.0, 0.2608695652173913, 0.4349030470914128, 1.0, 0.0, 0.0, 0.08333333333333333, 0.4132389211213792, 0.44866593022756374, 0.0, 1.0, 0.2, 0.07948207559866885], 
reward next is 0.7205, 
noisyNet noise sample is [array([-0.49914727], dtype=float32), -1.166115]. 
=============================================
[2019-04-17 15:20:24,272] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3939429e-07 7.2613177e-10 9.4230908e-01 7.7275481e-06 1.5203106e-05
 4.3319531e-07 2.9884006e-06 3.4873016e-04 1.9647357e-05 4.7545473e-06
 5.7291128e-02], sum to 1.0000
[2019-04-17 15:20:24,280] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5493
[2019-04-17 15:20:24,302] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 19.0, 21.28925465524098, -0.4540146850192475, 0.0, 1.0, 65.0, 89.9788266500835], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4762800.0000, 
sim time next is 4764000.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 19.0, 21.47477603547053, -0.4164891621601901, 0.0, 1.0, 25.0, 41.47298963995764], 
processed observation next is [0.0, 0.13043478260869565, 0.296398891966759, 0.92, 0.0, 0.0, 0.08333333333333333, 0.2895646696225442, 0.36117027927993667, 0.0, 1.0, 0.2, 0.4147298963995764], 
reward next is 0.3853, 
noisyNet noise sample is [array([0.43002638], dtype=float32), -2.328237]. 
=============================================
[2019-04-17 15:20:24,328] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1308164e-08 8.8649775e-11 9.6293908e-01 1.6519559e-06 2.0327700e-06
 1.6983611e-07 2.4776007e-06 1.9447488e-04 2.2213424e-05 2.2732427e-06
 3.6835581e-02], sum to 1.0000
[2019-04-17 15:20:24,329] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0672
[2019-04-17 15:20:24,346] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.0, 35.0, 73.83333333333334, 488.3333333333333, 19.0, 21.57604504329898, -0.4535836772177211, 0.0, 1.0, 25.0, 3.86398221377784], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4812000.0000, 
sim time next is 4813200.0000, 
raw observation next is [3.0, 34.0, 57.5, 367.0, 19.0, 21.5828993099028, -0.4587183937799811, 0.0, 1.0, 25.0, 6.16624910554214], 
processed observation next is [0.0, 0.7391304347826086, 0.5457063711911359, 0.34, 0.19166666666666668, 0.40552486187845305, 0.08333333333333333, 0.2985749424919, 0.3470938687400063, 0.0, 1.0, 0.2, 0.0616624910554214], 
reward next is 0.7383, 
noisyNet noise sample is [array([-2.1485069], dtype=float32), 1.0482581]. 
=============================================
[2019-04-17 15:20:25,846] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [4.5348909e-08 3.8497115e-11 9.6196258e-01 7.1056047e-07 8.3764814e-07
 3.7744364e-08 1.9425559e-06 1.2217676e-04 4.5149932e-06 4.8057285e-07
 3.7906684e-02], sum to 1.0000
[2019-04-17 15:20:25,847] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4718
[2019-04-17 15:20:25,861] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.0, 43.0, 0.0, 0.0, 19.0, 22.11026805743485, -0.3829022134145224, 0.0, 1.0, 25.0, 23.968193825427697], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4820400.0000, 
sim time next is 4821600.0000, 
raw observation next is [1.0, 44.33333333333334, 0.0, 0.0, 19.0, 22.00332171761014, -0.3980408558191217, 0.0, 1.0, 25.0, 21.773997311929442], 
processed observation next is [0.0, 0.8260869565217391, 0.4903047091412743, 0.4433333333333334, 0.0, 0.0, 0.08333333333333333, 0.33361014313417847, 0.3673197147269594, 0.0, 1.0, 0.2, 0.2177399731192944], 
reward next is 0.5823, 
noisyNet noise sample is [array([0.30368787], dtype=float32), 0.50502264]. 
=============================================
[2019-04-17 15:20:26,997] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.7515057e-08 3.0945229e-11 9.6605754e-01 7.9244580e-07 1.2645520e-06
 6.5304924e-08 5.9938975e-07 6.6205706e-05 1.4877430e-06 5.3975668e-07
 3.3871550e-02], sum to 1.0000
[2019-04-17 15:20:27,001] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3153
[2019-04-17 15:20:27,142] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.6666666666666667, 48.33333333333334, 0.0, 0.0, 19.0, 21.77491859738905, -0.4352530151149951, 0.0, 1.0, 25.0, 15.566654829230494], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4825200.0000, 
sim time next is 4826400.0000, 
raw observation next is [0.3333333333333334, 49.66666666666667, 0.0, 0.0, 19.0, 21.69943126290916, -0.4540332786487906, 0.0, 1.0, 25.0, 14.478023136012165], 
processed observation next is [0.0, 0.8695652173913043, 0.4718374884579871, 0.4966666666666667, 0.0, 0.0, 0.08333333333333333, 0.3082859385757635, 0.34865557378373646, 0.0, 1.0, 0.2, 0.14478023136012166], 
reward next is 0.6552, 
noisyNet noise sample is [array([-0.9720077], dtype=float32), -0.95247537]. 
=============================================
[2019-04-17 15:20:30,644] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9069343e-10 2.6904553e-14 9.7851527e-01 2.8473437e-08 1.7009266e-07
 1.3737343e-09 3.5704019e-08 2.0964717e-05 1.0032519e-07 5.0093160e-08
 2.1463489e-02], sum to 1.0000
[2019-04-17 15:20:30,644] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8478
[2019-04-17 15:20:30,664] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.333333333333333, 34.33333333333333, 0.0, 0.0, 19.0, 22.35231184656451, -0.3113631777336328, 0.0, 1.0, 25.0, 11.70466010624735], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 5002800.0000, 
sim time next is 5004000.0000, 
raw observation next is [3.0, 37.0, 0.0, 0.0, 19.0, 22.29129113319556, -0.323335171828364, 0.0, 1.0, 25.0, 11.046247637986266], 
processed observation next is [1.0, 0.9565217391304348, 0.5457063711911359, 0.37, 0.0, 0.0, 0.08333333333333333, 0.35760759443296336, 0.3922216093905453, 0.0, 1.0, 0.2, 0.11046247637986266], 
reward next is 0.6895, 
noisyNet noise sample is [array([0.05448395], dtype=float32), 0.51240844]. 
=============================================
[2019-04-17 15:20:30,665] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:30,938] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:31,421] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:31,608] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:31,646] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:31,647] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:31,656] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.1986752e-11 1.9177026e-16 9.9195075e-01 1.0493099e-09 8.3341547e-09
 2.9047764e-11 2.1615494e-09 3.0174972e-06 7.1444418e-08 2.3759770e-09
 8.0460962e-03], sum to 1.0000
[2019-04-17 15:20:31,656] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6828
[2019-04-17 15:20:31,658] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res16/Eplus-env-sub_run2
[2019-04-17 15:20:31,734] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [8.666666666666668, 25.33333333333333, 88.66666666666667, 751.8333333333333, 22.5, 23.13344791439081, -0.1910001580740916, 1.0, 1.0, 25.0, 1.302992293387299], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4981200.0000, 
sim time next is 4982400.0000, 
raw observation next is [9.0, 25.0, 82.0, 707.5, 22.5, 23.19712249263127, -0.2509097302614617, 1.0, 1.0, 25.0, 1.1824418812885864], 
processed observation next is [1.0, 0.6956521739130435, 0.7119113573407203, 0.25, 0.2733333333333333, 0.7817679558011049, 0.375, 0.4330935410526058, 0.4163634232461795, 1.0, 1.0, 0.2, 0.011824418812885864], 
reward next is 0.7882, 
noisyNet noise sample is [array([0.23945124], dtype=float32), -0.39973283]. 
=============================================
[2019-04-17 15:20:31,892] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:31,944] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:32,044] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:32,098] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:32,122] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:32,153] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:32,161] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:32,241] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:32,324] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:32,355] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:32,429] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:32,429] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:32,432] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res7/Eplus-env-sub_run2
[2019-04-17 15:20:32,895] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:32,895] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:32,897] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res6/Eplus-env-sub_run2
[2019-04-17 15:20:32,936] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:32,936] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:32,938] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res4/Eplus-env-sub_run2
[2019-04-17 15:20:33,037] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:33,038] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:33,039] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res11/Eplus-env-sub_run2
[2019-04-17 15:20:33,154] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:33,154] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:33,155] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res13/Eplus-env-sub_run2
[2019-04-17 15:20:33,197] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:33,197] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:33,199] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res2/Eplus-env-sub_run2
[2019-04-17 15:20:33,445] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:33,605] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:33,772] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:33,777] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:33,800] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:33,821] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:33,942] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:33,961] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:34,025] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:34,025] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:34,214] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:34,292] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:34,391] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:34,439] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:34,439] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:34,441] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res15/Eplus-env-sub_run2
[2019-04-17 15:20:34,485] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:34,605] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:34,608] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:34,610] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res12/Eplus-env-sub_run2
[2019-04-17 15:20:34,768] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:34,768] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:34,769] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res14/Eplus-env-sub_run2
[2019-04-17 15:20:34,801] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:34,801] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:34,803] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res3/Eplus-env-sub_run2
[2019-04-17 15:20:34,865] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:34,866] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:34,868] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res8/Eplus-env-sub_run2
[2019-04-17 15:20:35,215] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:35,215] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:35,217] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res10/Eplus-env-sub_run2
[2019-04-17 15:20:35,280] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:35,281] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:35,283] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res17/Eplus-env-sub_run2
[2019-04-17 15:20:35,669] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:36,089] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:36,670] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:36,670] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:36,672] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res5/Eplus-env-sub_run2
[2019-04-17 15:20:40,889] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:20:41,202] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:20:41,869] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:20:41,869] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:20:41,871] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res9/Eplus-env-sub_run2
[2019-04-17 15:20:49,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1206875e-10 1.9443194e-14 9.9121749e-01 1.0876533e-08 9.6351052e-08
 4.9425442e-10 1.4574522e-08 6.6258385e-06 8.1380598e-08 2.4720984e-08
 8.7757139e-03], sum to 1.0000
[2019-04-17 15:20:49,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0080
[2019-04-17 15:20:49,335] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 22.5, 17.94969884061991, -1.414037438110795, 1.0, 1.0, 25.0, 19.44366657451487], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 238800.0000, 
sim time next is 240000.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 22.5, 17.69412829466362, -1.450266247121298, 1.0, 1.0, 25.0, 19.4418075903986], 
processed observation next is [1.0, 0.782608695652174, 0.368421052631579, 0.65, 0.0, 0.0, 0.375, -0.02548930877803161, 0.016577917626234024, 1.0, 1.0, 0.2, 0.194418075903986], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.7936933], dtype=float32), 1.214627]. 
=============================================
[2019-04-17 15:20:49,376] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[37.93267 ]
 [37.980213]
 [38.044563]
 [38.104523]
 [38.159164]
 [38.1795  ]
 [38.253437]
 [38.35328 ]
 [38.44507 ]
 [38.47831 ]
 [38.53651 ]
 [38.559376]
 [38.520424]
 [38.527855]
 [38.50185 ]
 [38.508915]
 [38.422607]
 [38.29843 ]
 [38.140778]
 [37.96122 ]
 [37.73033 ]
 [37.43757 ]
 [37.16461 ]
 [36.867104]
 [36.524708]], R is [[37.53103256]
 [37.15572357]
 [36.78416824]
 [36.41632843]
 [36.05216599]
 [35.75924301]
 [35.40433884]
 [35.05029678]
 [34.80104065]
 [34.51113129]
 [34.16601944]
 [33.8649292 ]
 [33.67866516]
 [33.60785294]
 [33.96628571]
 [34.03709412]
 [33.69672394]
 [33.39691544]
 [33.06294632]
 [32.78456497]
 [32.45671844]
 [32.20841217]
 [31.93735504]
 [31.73374176]
 [31.46795464]].
[2019-04-17 15:20:49,543] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.3066047e-10 1.9578052e-14 9.6537358e-01 2.0417161e-08 5.5556367e-08
 4.7889975e-10 1.5965480e-08 1.5861713e-05 6.3852724e-08 2.6549882e-08
 3.4610480e-02], sum to 1.0000
[2019-04-17 15:20:49,545] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.0054
[2019-04-17 15:20:49,563] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-8.4, 70.0, 0.0, 0.0, 19.0, 20.24084585668384, -0.8012129570445964, 0.0, 1.0, 25.0, 16.59549925714846], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 164400.0000, 
sim time next is 165600.0000, 
raw observation next is [-8.4, 71.0, 0.0, 0.0, 19.0, 20.16539915576099, -0.8204891068686136, 0.0, 1.0, 25.0, 16.696026822417764], 
processed observation next is [1.0, 0.9565217391304348, 0.2299168975069252, 0.71, 0.0, 0.0, 0.08333333333333333, 0.18044992964674922, 0.22650363104379545, 0.0, 1.0, 0.2, 0.16696026822417764], 
reward next is 0.6330, 
noisyNet noise sample is [array([-1.178712], dtype=float32), 0.47922963]. 
=============================================
[2019-04-17 15:20:51,439] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.8760158e-10 4.1314472e-14 9.3750185e-01 1.2756389e-07 2.9538901e-07
 1.4253474e-09 4.4285052e-08 4.3596923e-05 1.5491712e-07 8.7052754e-08
 6.2453851e-02], sum to 1.0000
[2019-04-17 15:20:51,439] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8220
[2019-04-17 15:20:51,510] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-11.7, 63.0, 91.0, 447.5, 22.5, 18.40444889147874, -1.376676387386125, 1.0, 1.0, 25.0, 21.462973688667432], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 295200.0000, 
sim time next is 296400.0000, 
raw observation next is [-11.33333333333333, 62.00000000000001, 88.33333333333333, 490.5, 22.5, 18.41992706068281, -1.368544687599631, 1.0, 1.0, 25.0, 19.051677251328073], 
processed observation next is [1.0, 0.43478260869565216, 0.14866112650046176, 0.6200000000000001, 0.29444444444444445, 0.541988950276243, 0.375, 0.034993921723567446, 0.04381843746678967, 1.0, 1.0, 0.2, 0.19051677251328072], 
reward next is 0.0813, 
noisyNet noise sample is [array([-0.9725733], dtype=float32), 0.67595094]. 
=============================================
[2019-04-17 15:20:54,378] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.17088811e-11 1.96545038e-15 8.91858876e-01 6.14067197e-09
 2.89800628e-08 2.18482565e-10 1.07466711e-08 2.48908545e-05
 4.99642958e-08 6.53092869e-09 1.08116165e-01], sum to 1.0000
[2019-04-17 15:20:54,378] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5438
[2019-04-17 15:20:54,538] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-10.96666666666667, 51.66666666666667, 0.0, 0.0, 22.5, 21.07385140560368, -0.8276856390115156, 1.0, 1.0, 25.0, 37.75979995551772], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 321600.0000, 
sim time next is 322800.0000, 
raw observation next is [-11.33333333333333, 54.33333333333334, 0.0, 0.0, 22.5, 20.57271366587623, -0.8913068030541602, 1.0, 1.0, 25.0, 33.234666240948116], 
processed observation next is [1.0, 0.7391304347826086, 0.14866112650046176, 0.5433333333333334, 0.0, 0.0, 0.375, 0.21439280548968576, 0.20289773231527994, 1.0, 1.0, 0.2, 0.33234666240948113], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0222386], dtype=float32), 0.37450033]. 
=============================================
[2019-04-17 15:21:03,297] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7741450e-09 3.2013483e-12 9.2742443e-01 2.8298359e-07 1.8066089e-06
 2.0910633e-08 3.7971066e-07 3.8262129e-05 9.9315127e-07 1.5356468e-07
 7.2533712e-02], sum to 1.0000
[2019-04-17 15:21:03,297] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4403
[2019-04-17 15:21:03,381] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-11.33333333333333, 52.33333333333334, 0.0, 0.0, 19.0, 18.39981239492765, -1.329652247749764, 0.0, 1.0, 25.0, 21.589293811899754], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 427200.0000, 
sim time next is 428400.0000, 
raw observation next is [-11.7, 54.0, 0.0, 0.0, 19.0, 18.26142792467178, -1.360389918171281, 0.0, 1.0, 25.0, 19.80623850620178], 
processed observation next is [1.0, 1.0, 0.13850415512465375, 0.54, 0.0, 0.0, 0.08333333333333333, 0.02178566038931488, 0.046536693942906306, 0.0, 1.0, 0.2, 0.1980623850620178], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18153447], dtype=float32), 1.5638257]. 
=============================================
[2019-04-17 15:21:09,067] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.1828303e-08 6.2307597e-11 5.2789742e-01 1.8035115e-06 4.1535927e-06
 1.7982688e-07 9.6037684e-07 4.8348916e-04 2.8635923e-06 2.8759655e-06
 4.7160619e-01], sum to 1.0000
[2019-04-17 15:21:09,068] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5947
[2019-04-17 15:21:09,113] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-4.5, 75.33333333333333, 0.0, 0.0, 19.0, 20.23627729112295, -0.8556396346857773, 0.0, 1.0, 25.0, 44.712419368760976], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 632400.0000, 
sim time next is 633600.0000, 
raw observation next is [-4.5, 79.0, 9.5, 0.0, 19.0, 20.1404793622439, -0.8365173701440263, 0.0, 1.0, 65.0, 65.41121492576946], 
processed observation next is [0.0, 0.34782608695652173, 0.3379501385041552, 0.79, 0.03166666666666667, 0.0, 0.08333333333333333, 0.1783732801869918, 0.2211608766186579, 0.0, 1.0, 1.0, 0.6541121492576946], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11986378], dtype=float32), 0.59070206]. 
=============================================
[2019-04-17 15:21:09,232] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0654040e-08 1.4877466e-11 6.5488595e-01 7.0012385e-07 1.1397636e-06
 3.0708534e-08 9.0164792e-07 1.7799539e-04 3.8536236e-06 1.1469482e-06
 3.4492823e-01], sum to 1.0000
[2019-04-17 15:21:09,233] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3489
[2019-04-17 15:21:09,272] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7407348e-08 7.7215656e-12 7.1897018e-01 4.4530756e-07 7.3372405e-07
 2.1884071e-08 4.0081599e-07 1.8323233e-04 2.6075440e-06 5.2722964e-07
 2.8084186e-01], sum to 1.0000
[2019-04-17 15:21:09,273] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2764
[2019-04-17 15:21:09,274] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.7, 82.0, 0.0, 0.0, 19.0, 20.78588659496835, -0.7548443083381534, 0.0, 1.0, 25.0, 22.91359105482677], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 532800.0000, 
sim time next is 534000.0000, 
raw observation next is [2.333333333333333, 83.0, 0.0, 0.0, 19.0, 20.67449857970237, -0.7732355656840122, 0.0, 1.0, 25.0, 21.065876876710703], 
processed observation next is [0.0, 0.17391304347826086, 0.5272391505078486, 0.83, 0.0, 0.0, 0.08333333333333333, 0.22287488164186411, 0.2422548114386626, 0.0, 1.0, 0.2, 0.21065876876710704], 
reward next is 0.5893, 
noisyNet noise sample is [array([1.3441061], dtype=float32), 0.52710456]. 
=============================================
[2019-04-17 15:21:09,291] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 91.0, 89.0, 103.5, 19.0, 20.06053164528273, -0.9061511649201335, 0.0, 1.0, 25.0, 42.44972143784328], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 550800.0000, 
sim time next is 552000.0000, 
raw observation next is [-0.2, 89.66666666666667, 125.6666666666667, 103.1666666666667, 19.0, 20.01369367956909, -0.9110645125205087, 0.0, 1.0, 25.0, 37.59651858831377], 
processed observation next is [0.0, 0.391304347826087, 0.4570637119113574, 0.8966666666666667, 0.418888888888889, 0.11399631675874773, 0.08333333333333333, 0.16780780663075756, 0.19631182915983045, 0.0, 1.0, 0.2, 0.3759651858831377], 
reward next is 0.4240, 
noisyNet noise sample is [array([-1.6806446], dtype=float32), -0.4472117]. 
=============================================
[2019-04-17 15:21:13,844] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2073820e-09 2.1606213e-13 8.4963930e-01 5.7033397e-08 1.3274713e-06
 1.4576450e-09 5.3644793e-08 6.2094630e-05 1.5221109e-07 1.7685325e-07
 1.5029670e-01], sum to 1.0000
[2019-04-17 15:21:13,844] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0199
[2019-04-17 15:21:13,860] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-7.8, 74.0, 0.0, 0.0, 19.0, 22.33950274123906, -0.3857204081105861, 0.0, 1.0, 25.0, 38.293608464163356], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 788400.0000, 
sim time next is 789600.0000, 
raw observation next is [-7.633333333333333, 74.33333333333334, 0.0, 0.0, 19.0, 22.29147297251971, -0.4048813026576277, 0.0, 1.0, 25.0, 33.98433891821125], 
processed observation next is [1.0, 0.13043478260869565, 0.2511542012927055, 0.7433333333333334, 0.0, 0.0, 0.08333333333333333, 0.3576227477099758, 0.3650395657807908, 0.0, 1.0, 0.2, 0.3398433891821125], 
reward next is 0.4602, 
noisyNet noise sample is [array([0.25389734], dtype=float32), 1.3300524]. 
=============================================
[2019-04-17 15:21:15,824] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.9834186e-12 4.4940375e-17 9.2600870e-01 1.3844474e-10 8.0895246e-09
 5.0133018e-12 1.2324815e-09 1.7515066e-06 5.7679510e-09 2.7502584e-10
 7.3989578e-02], sum to 1.0000
[2019-04-17 15:21:15,824] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3857
[2019-04-17 15:21:15,960] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.166666666666667, 54.66666666666667, 0.0, 0.0, 22.5, 25.11437130665445, 0.1668397151471061, 1.0, 1.0, 25.0, 53.97403381101236], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 753600.0000, 
sim time next is 754800.0000, 
raw observation next is [-3.533333333333333, 55.33333333333333, 0.0, 0.0, 22.5, 24.74522267789069, 0.1250450812051614, 1.0, 1.0, 25.0, 45.95092494661404], 
processed observation next is [1.0, 0.7391304347826086, 0.36472760849492153, 0.5533333333333332, 0.0, 0.0, 0.375, 0.5621018898242243, 0.5416816937350538, 1.0, 1.0, 0.2, 0.45950924946614036], 
reward next is 0.3405, 
noisyNet noise sample is [array([1.4028723], dtype=float32), -0.5394771]. 
=============================================
[2019-04-17 15:21:20,981] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5377959e-12 5.6038521e-18 7.1808803e-01 5.1337386e-11 7.7294207e-09
 1.8961070e-12 6.0431554e-10 6.5395961e-06 3.7971146e-09 4.5773360e-10
 2.8190544e-01], sum to 1.0000
[2019-04-17 15:21:20,981] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1942
[2019-04-17 15:21:21,124] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4226673e-10 7.4241028e-14 8.1069261e-01 1.0194913e-07 4.7836147e-07
 2.5226130e-09 7.3599331e-08 1.1798567e-04 9.0867786e-08 5.4844076e-08
 1.8918854e-01], sum to 1.0000
[2019-04-17 15:21:21,124] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3094
[2019-04-17 15:21:21,129] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.1666666666666667, 46.33333333333334, 80.83333333333334, 600.1666666666666, 22.5, 24.85335585383796, 0.05238810664304976, 1.0, 1.0, 25.0, 37.55302144569251], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 744000.0000, 
sim time next is 745200.0000, 
raw observation next is [0.0, 47.0, 82.5, 372.5, 22.5, 24.63130011091135, 0.1263185261365813, 1.0, 1.0, 25.0, 33.70219457875784], 
processed observation next is [1.0, 0.6521739130434783, 0.46260387811634357, 0.47, 0.275, 0.4116022099447514, 0.375, 0.5526083425759459, 0.5421061753788604, 1.0, 1.0, 0.2, 0.3370219457875784], 
reward next is 0.4630, 
noisyNet noise sample is [array([1.795359], dtype=float32), -0.71044314]. 
=============================================
[2019-04-17 15:21:21,186] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-7.8, 74.0, 0.0, 0.0, 19.0, 23.41553486228387, -0.1144134830932615, 0.0, 1.0, 25.0, 38.87596631863872], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 788400.0000, 
sim time next is 789600.0000, 
raw observation next is [-7.633333333333333, 74.33333333333334, 0.0, 0.0, 19.0, 23.41289717268771, -0.1325280881333395, 0.0, 1.0, 25.0, 34.651428271960654], 
processed observation next is [1.0, 0.13043478260869565, 0.2511542012927055, 0.7433333333333334, 0.0, 0.0, 0.08333333333333333, 0.45107476439064254, 0.4558239706222202, 0.0, 1.0, 0.2, 0.34651428271960655], 
reward next is 0.4535, 
noisyNet noise sample is [array([0.20739414], dtype=float32), -1.7098528]. 
=============================================
[2019-04-17 15:21:26,448] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4605435e-11 3.8230999e-16 5.9970081e-01 1.3370491e-09 1.3490151e-08
 1.5722663e-11 4.7601267e-10 3.8562584e-06 5.3530291e-09 1.4818851e-09
 4.0029538e-01], sum to 1.0000
[2019-04-17 15:21:26,448] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7309
[2019-04-17 15:21:26,499] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-5.066666666666666, 72.33333333333333, 90.83333333333333, 0.0, 22.5, 24.2446404572319, 0.09694005733542115, 1.0, 1.0, 25.0, 35.40596737980934], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 816000.0000, 
sim time next is 817200.0000, 
raw observation next is [-4.5, 71.0, 98.5, 0.0, 22.5, 24.2634632544007, 0.1317660248333353, 1.0, 1.0, 65.0, 57.562826886890875], 
processed observation next is [1.0, 0.4782608695652174, 0.3379501385041552, 0.71, 0.3283333333333333, 0.0, 0.375, 0.5219552712000585, 0.5439220082777784, 1.0, 1.0, 1.0, 0.5756282688689087], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2280506], dtype=float32), -3.2267432]. 
=============================================
[2019-04-17 15:21:27,550] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6095797e-10 2.4766794e-15 6.7437476e-01 5.3249321e-09 3.9457223e-08
 1.4449633e-10 5.7383618e-09 8.3781697e-06 5.4025936e-08 1.1202107e-08
 3.2561687e-01], sum to 1.0000
[2019-04-17 15:21:27,551] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5146
[2019-04-17 15:21:27,579] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.2, 76.0, 0.0, 0.0, 19.0, 24.78954487490297, 0.2805875450634465, 0.0, 1.0, 25.0, 33.421519467558085], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 878400.0000, 
sim time next is 879600.0000, 
raw observation next is [-1.0, 74.66666666666667, 0.0, 0.0, 19.0, 24.6784161299747, 0.2410937328521768, 0.0, 1.0, 25.0, 31.3688213734642], 
processed observation next is [1.0, 0.17391304347826086, 0.4349030470914128, 0.7466666666666667, 0.0, 0.0, 0.08333333333333333, 0.5565346774978916, 0.5803645776173922, 0.0, 1.0, 0.2, 0.313688213734642], 
reward next is 0.4863, 
noisyNet noise sample is [array([2.1616168], dtype=float32), 0.8352474]. 
=============================================
[2019-04-17 15:21:27,750] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.3841215e-12 4.9628038e-17 2.7556345e-01 1.2267460e-09 4.6815963e-08
 7.4042737e-11 3.2868395e-09 3.5017638e-05 1.0425750e-08 5.6254823e-09
 7.2440153e-01], sum to 1.0000
[2019-04-17 15:21:27,750] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3065
[2019-04-17 15:21:27,809] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [7.7, 80.0, 0.0, 0.0, 19.0, 25.51075165055875, 0.5479369993897464, 0.0, 1.0, 65.0, 53.64873139994417], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 961200.0000, 
sim time next is 962400.0000, 
raw observation next is [7.7, 81.0, 0.0, 0.0, 19.0, 25.64197873175858, 0.5647395052097631, 0.0, 1.0, 65.0, 52.08550837127733], 
processed observation next is [1.0, 0.13043478260869565, 0.6759002770083103, 0.81, 0.0, 0.0, 0.08333333333333333, 0.6368315609798817, 0.6882465017365877, 0.0, 1.0, 1.0, 0.5208550837127732], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2591883], dtype=float32), -0.052886706]. 
=============================================
[2019-04-17 15:21:36,247] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8794764e-09 1.0141881e-12 4.5713577e-01 4.4346528e-08 7.1810825e-07
 2.8744265e-09 5.4224535e-07 1.8749284e-04 5.8150022e-07 1.3026589e-07
 5.4267478e-01], sum to 1.0000
[2019-04-17 15:21:36,248] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6522
[2019-04-17 15:21:36,277] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [17.7, 67.0, 0.0, 0.0, 19.0, 28.06288405152083, 1.214488292859254, 0.0, 0.0, 25.0, 19.0428725609601], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 1192800.0000, 
sim time next is 1194000.0000, 
raw observation next is [17.7, 67.0, 0.0, 0.0, 19.0, 28.05818200054071, 1.214353601168962, 0.0, 0.0, 65.0, 22.091214712231075], 
processed observation next is [0.0, 0.8260869565217391, 0.9529085872576178, 0.67, 0.0, 0.0, 0.08333333333333333, 0.8381818333783926, 0.9047845337229873, 0.0, 0.0, 1.0, 0.22091214712231075], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9465471], dtype=float32), -0.061010856]. 
=============================================
[2019-04-17 15:21:36,439] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.6939916e-13 2.9379944e-18 9.7029167e-01 1.6489966e-10 5.7457034e-10
 1.6611296e-12 2.0203968e-10 1.0253403e-06 2.5423819e-09 1.1158265e-10
 2.9707266e-02], sum to 1.0000
[2019-04-17 15:21:36,450] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5812
[2019-04-17 15:21:36,493] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [10.33333333333333, 58.66666666666667, 0.0, 0.0, 22.5, 27.59615882735689, 1.06006776313291, 1.0, 1.0, 25.0, 39.3847217666624], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1531200.0000, 
sim time next is 1532400.0000, 
raw observation next is [10.16666666666667, 59.33333333333334, 0.0, 0.0, 22.5, 27.50015228807732, 1.053280088984933, 1.0, 1.0, 25.0, 15.558217911687969], 
processed observation next is [1.0, 0.7391304347826086, 0.7442289935364729, 0.5933333333333334, 0.0, 0.0, 0.375, 0.7916793573397767, 0.8510933629949777, 1.0, 1.0, 0.2, 0.1555821791168797], 
reward next is 0.6444, 
noisyNet noise sample is [array([-0.59860396], dtype=float32), -0.9684745]. 
=============================================
[2019-04-17 15:21:39,866] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.3422234e-13 3.8424219e-18 9.3475229e-01 2.8363120e-10 1.2098338e-09
 1.5485620e-12 8.7204528e-11 9.7494251e-07 2.0683224e-09 2.0586434e-10
 6.5246738e-02], sum to 1.0000
[2019-04-17 15:21:39,867] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1161
[2019-04-17 15:21:39,895] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.1, 92.0, 67.66666666666667, 0.0, 22.5, 27.41283571266384, 0.9721725227954888, 1.0, 1.0, 25.0, 22.42277365507605], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1435200.0000, 
sim time next is 1436400.0000, 
raw observation next is [1.1, 92.0, 59.0, 0.0, 22.5, 27.41602133712455, 0.9723834722709244, 1.0, 1.0, 25.0, 20.454267362047116], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.92, 0.19666666666666666, 0.0, 0.375, 0.7846684447603792, 0.8241278240903082, 1.0, 1.0, 0.2, 0.20454267362047115], 
reward next is 0.5955, 
noisyNet noise sample is [array([0.38345632], dtype=float32), -0.15618928]. 
=============================================
[2019-04-17 15:21:41,832] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.9988189e-12 2.3049600e-17 6.6106832e-01 4.6301091e-10 9.0085237e-09
 9.5930399e-12 3.7922632e-10 5.0078611e-06 5.1115454e-09 2.1214040e-10
 3.3892658e-01], sum to 1.0000
[2019-04-17 15:21:41,834] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1661
[2019-04-17 15:21:41,886] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.933333333333333, 97.33333333333334, 75.5, 118.0, 22.5, 26.86572445989303, 0.809506812557153, 1.0, 1.0, 25.0, 34.03932022069107], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1507200.0000, 
sim time next is 1508400.0000, 
raw observation next is [3.3, 96.0, 80.5, 354.0, 22.5, 26.92733410423723, 0.8404746257014698, 1.0, 1.0, 25.0, 34.74944794988518], 
processed observation next is [1.0, 0.4782608695652174, 0.554016620498615, 0.96, 0.2683333333333333, 0.3911602209944751, 0.375, 0.7439445086864357, 0.7801582085671566, 1.0, 1.0, 0.2, 0.3474944794988518], 
reward next is 0.4525, 
noisyNet noise sample is [array([1.0351202], dtype=float32), 0.99426895]. 
=============================================
[2019-04-17 15:21:43,398] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.3497059e-12 8.6582358e-17 5.5157870e-01 4.6527085e-10 4.8535442e-09
 1.5945065e-11 1.4264074e-09 6.3672728e-06 9.0982786e-09 6.1883515e-10
 4.4841492e-01], sum to 1.0000
[2019-04-17 15:21:43,398] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9298
[2019-04-17 15:21:43,423] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [4.7, 84.0, 0.0, 0.0, 19.0, 26.85293216914323, 0.8735152475197135, 0.0, 1.0, 25.0, 33.94749990650945], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 1573200.0000, 
sim time next is 1574400.0000, 
raw observation next is [4.800000000000001, 83.33333333333334, 0.0, 0.0, 19.0, 26.9162877908557, 0.8740487675847385, 0.0, 1.0, 65.0, 37.05224271954742], 
processed observation next is [1.0, 0.21739130434782608, 0.5955678670360112, 0.8333333333333335, 0.0, 0.0, 0.08333333333333333, 0.7430239825713084, 0.7913495891949128, 0.0, 1.0, 1.0, 0.37052242719547424], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06645582], dtype=float32), -1.3238066]. 
=============================================
[2019-04-17 15:21:43,992] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7923818e-13 2.5612794e-18 5.5301696e-01 1.5472200e-10 2.1772499e-09
 1.0159959e-12 1.9800496e-10 2.4621211e-06 1.7419478e-09 1.4018391e-10
 4.4698063e-01], sum to 1.0000
[2019-04-17 15:21:43,992] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0792
[2019-04-17 15:21:44,030] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [4.4, 93.0, 94.0, 704.0, 22.5, 27.59701249569415, 0.8297365676772048, 1.0, 1.0, 25.0, 29.4000636141227], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1512000.0000, 
sim time next is 1513200.0000, 
raw observation next is [5.333333333333334, 86.33333333333334, 98.0, 701.3333333333334, 22.5, 27.19585587482188, 0.9951310662929146, 1.0, 1.0, 25.0, 24.28829596636151], 
processed observation next is [1.0, 0.5217391304347826, 0.6103416435826409, 0.8633333333333334, 0.32666666666666666, 0.7749539594843463, 0.375, 0.7663213229018234, 0.8317103554309715, 1.0, 1.0, 0.2, 0.2428829596636151], 
reward next is 0.5571, 
noisyNet noise sample is [array([0.24457075], dtype=float32), -0.8738378]. 
=============================================
[2019-04-17 15:21:45,767] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7448986e-12 7.5345612e-17 7.4019229e-01 5.3071325e-10 6.8214798e-09
 6.5130904e-12 5.4306254e-10 3.5658486e-06 4.6229038e-09 4.5116283e-10
 2.5980416e-01], sum to 1.0000
[2019-04-17 15:21:45,767] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7145
[2019-04-17 15:21:45,790] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [5.5, 97.0, 0.0, 0.0, 19.0, 27.19294996006709, 0.976790496419843, 0.0, 1.0, 25.0, 31.458144779640392], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1663200.0000, 
sim time next is 1664400.0000, 
raw observation next is [5.333333333333334, 95.33333333333334, 0.0, 0.0, 19.0, 27.25982858945148, 0.9805257525486031, 0.0, 1.0, 25.0, 30.0456323557977], 
processed observation next is [1.0, 0.2608695652173913, 0.6103416435826409, 0.9533333333333335, 0.0, 0.0, 0.08333333333333333, 0.77165238245429, 0.8268419175162011, 0.0, 1.0, 0.2, 0.300456323557977], 
reward next is 0.4995, 
noisyNet noise sample is [array([-0.00581447], dtype=float32), 2.2170994]. 
=============================================
[2019-04-17 15:21:47,865] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6770435e-09 1.2610876e-12 9.2496812e-01 1.5151038e-07 3.8447251e-07
 6.2059149e-09 1.4303556e-07 2.9556197e-05 9.9178749e-07 2.0547698e-07
 7.5000517e-02], sum to 1.0000
[2019-04-17 15:21:47,866] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2804
[2019-04-17 15:21:48,008] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.9, 82.0, 14.5, 0.0, 19.0, 22.74419976892127, -0.1400264649222046, 0.0, 1.0, 25.0, 14.331431071590835], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1789200.0000, 
sim time next is 1790400.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 19.0, 22.66897731716527, -0.1598725253049972, 0.0, 1.0, 25.0, 14.54772943397519], 
processed observation next is [0.0, 0.7391304347826086, 0.3545706371191136, 0.82, 0.0, 0.0, 0.08333333333333333, 0.38908144309710596, 0.44670915823166757, 0.0, 1.0, 0.2, 0.1454772943397519], 
reward next is 0.6545, 
noisyNet noise sample is [array([-1.4973724], dtype=float32), -0.52343816]. 
=============================================
[2019-04-17 15:21:48,116] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8850136e-10 2.5702230e-13 9.1077000e-01 4.6808271e-08 1.6085505e-07
 1.2730057e-09 4.5278572e-08 5.3392101e-05 3.1801378e-07 4.0337710e-08
 8.9176126e-02], sum to 1.0000
[2019-04-17 15:21:48,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3508
[2019-04-17 15:21:48,132] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.2, 89.66666666666667, 0.0, 0.0, 19.0, 25.02144291512758, 0.4469811632834362, 0.0, 1.0, 25.0, 23.824861079246325], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1740000.0000, 
sim time next is 1741200.0000, 
raw observation next is [-0.4, 88.33333333333334, 0.0, 0.0, 19.0, 24.86260375694954, 0.4166072986701064, 0.0, 1.0, 25.0, 21.785111263130325], 
processed observation next is [0.0, 0.13043478260869565, 0.45152354570637127, 0.8833333333333334, 0.0, 0.0, 0.08333333333333333, 0.5718836464124616, 0.6388690995567021, 0.0, 1.0, 0.2, 0.21785111263130325], 
reward next is 0.5821, 
noisyNet noise sample is [array([0.85921586], dtype=float32), -0.5038464]. 
=============================================
[2019-04-17 15:21:48,785] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.36006889e-09 2.49970834e-12 6.90843463e-01 3.07522669e-07
 5.30485181e-07 4.59103200e-09 2.66425616e-07 1.10209214e-04
 1.76538072e-06 5.04152240e-07 3.09042990e-01], sum to 1.0000
[2019-04-17 15:21:48,786] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1325
[2019-04-17 15:21:48,839] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-6.2, 79.0, 0.0, 0.0, 19.0, 23.83280007906161, 0.1605970336011844, 0.0, 1.0, 65.0, 72.13229986668412], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1833600.0000, 
sim time next is 1834800.0000, 
raw observation next is [-6.199999999999999, 79.0, 0.0, 0.0, 19.0, 24.40452119820629, 0.1881515125584583, 0.0, 1.0, 25.0, 52.40762814661342], 
processed observation next is [0.0, 0.21739130434782608, 0.2908587257617729, 0.79, 0.0, 0.0, 0.08333333333333333, 0.5337100998505241, 0.5627171708528195, 0.0, 1.0, 0.2, 0.5240762814661342], 
reward next is 0.2759, 
noisyNet noise sample is [array([-0.22797105], dtype=float32), -0.35196292]. 
=============================================
[2019-04-17 15:21:58,376] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.4530369e-10 7.3418376e-14 8.5358948e-01 3.5327627e-08 3.5280172e-07
 6.0801353e-10 2.5890253e-08 1.7004128e-05 1.1226839e-07 5.4514203e-08
 1.4639309e-01], sum to 1.0000
[2019-04-17 15:21:58,376] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5163
[2019-04-17 15:21:58,423] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 19.0, 22.36785495373489, -0.2852813561374348, 0.0, 1.0, 25.0, 35.90602364909796], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2091600.0000, 
sim time next is 2092800.0000, 
raw observation next is [-6.366666666666667, 85.66666666666667, 0.0, 0.0, 19.0, 22.26265698015703, -0.2981943052170339, 0.0, 1.0, 25.0, 32.205745068197515], 
processed observation next is [1.0, 0.21739130434782608, 0.28624192059095105, 0.8566666666666667, 0.0, 0.0, 0.08333333333333333, 0.35522141501308574, 0.4006018982609887, 0.0, 1.0, 0.2, 0.32205745068197517], 
reward next is 0.4779, 
noisyNet noise sample is [array([0.26840252], dtype=float32), -0.17510384]. 
=============================================
[2019-04-17 15:21:58,584] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.29190235e-11 1.57774987e-16 8.71552646e-01 1.83342175e-09
 8.99717634e-09 3.71356973e-11 1.82953730e-09 2.94539450e-06
 1.01691331e-08 1.65066893e-09 1.28444463e-01], sum to 1.0000
[2019-04-17 15:21:58,584] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7844
[2019-04-17 15:21:58,683] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-4.5, 86.0, 87.5, 0.0, 22.5, 24.00325021394074, -0.05996933156903683, 1.0, 1.0, 25.0, 37.1846042532873], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2041200.0000, 
sim time next is 2042400.0000, 
raw observation next is [-4.300000000000001, 84.66666666666667, 76.5, 0.0, 22.5, 23.97911477602747, -0.1398060771724037, 1.0, 1.0, 25.0, 34.05580940760941], 
processed observation next is [1.0, 0.6521739130434783, 0.34349030470914127, 0.8466666666666667, 0.255, 0.0, 0.375, 0.49825956466895577, 0.4533979742758654, 1.0, 1.0, 0.2, 0.3405580940760941], 
reward next is 0.4594, 
noisyNet noise sample is [array([0.44690728], dtype=float32), -0.48964062]. 
=============================================
[2019-04-17 15:22:00,884] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.21294191e-10 4.96567610e-14 8.04616392e-01 1.06437135e-07
 2.91594233e-07 2.14701346e-09 4.19587245e-08 3.32506788e-05
 1.00103406e-07 3.11209476e-08 1.95349753e-01], sum to 1.0000
[2019-04-17 15:22:00,884] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8123
[2019-04-17 15:22:00,938] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-4.5, 89.33333333333334, 0.0, 0.0, 19.0, 21.35305760226621, -0.5020076805516286, 0.0, 1.0, 25.0, 33.76303212703471], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2078400.0000, 
sim time next is 2079600.0000, 
raw observation next is [-4.5, 87.66666666666666, 0.0, 0.0, 19.0, 21.42089201272941, -0.4455646057243883, 0.0, 1.0, 65.0, 71.65218771394248], 
processed observation next is [1.0, 0.043478260869565216, 0.3379501385041552, 0.8766666666666666, 0.0, 0.0, 0.08333333333333333, 0.28507433439411756, 0.3514784647585372, 0.0, 1.0, 1.0, 0.7165218771394248], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16268986], dtype=float32), -1.0634313]. 
=============================================
[2019-04-17 15:22:02,680] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.1848371e-11 8.8527818e-16 7.8621519e-01 3.4675256e-09 6.5561916e-09
 5.9484362e-11 3.6862371e-09 7.6485321e-06 1.9697174e-08 4.5699986e-09
 2.1377711e-01], sum to 1.0000
[2019-04-17 15:22:02,681] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9161
[2019-04-17 15:22:02,857] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 22.5, 23.55732919781425, -0.01949107436031034, 1.0, 1.0, 25.0, 24.193157654109555], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2138400.0000, 
sim time next is 2139600.0000, 
raw observation next is [-5.0, 72.0, 0.0, 0.0, 22.5, 23.6708087237672, 0.06859342743526442, 1.0, 1.0, 65.0, 103.569085044184], 
processed observation next is [1.0, 0.782608695652174, 0.32409972299168976, 0.72, 0.0, 0.0, 0.375, 0.4725673936472665, 0.5228644758117548, 1.0, 1.0, 1.0, 1.03569085044184], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60120314], dtype=float32), 1.0832561]. 
=============================================
[2019-04-17 15:22:09,903] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.25351784e-11 1.58278112e-15 9.74788427e-01 1.35940281e-08
 9.01917474e-08 1.40644593e-10 1.46126915e-08 1.37815623e-05
 4.17393089e-08 8.10365908e-09 2.51976456e-02], sum to 1.0000
[2019-04-17 15:22:09,903] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0728
[2019-04-17 15:22:09,973] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.6, 75.0, 51.16666666666667, 293.5, 22.5, 23.44192345587797, -0.1418742622660247, 1.0, 1.0, 25.0, 34.63878110305396], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2191200.0000, 
sim time next is 2192400.0000, 
raw observation next is [-5.6, 75.0, 71.5, 356.5, 22.5, 23.50510377024516, -0.1338571886725645, 1.0, 1.0, 25.0, 30.797375237523028], 
processed observation next is [1.0, 0.391304347826087, 0.30747922437673136, 0.75, 0.23833333333333334, 0.3939226519337017, 0.375, 0.45875864752043, 0.4553809371091451, 1.0, 1.0, 0.2, 0.3079737523752303], 
reward next is 0.4920, 
noisyNet noise sample is [array([-2.1123767], dtype=float32), 1.9632099]. 
=============================================
[2019-04-17 15:22:15,688] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0800386e-11 9.3159161e-16 9.0129495e-01 7.2195436e-09 2.4064937e-08
 2.5490829e-10 6.5616814e-09 4.1879757e-06 3.5713523e-08 7.8600779e-09
 9.8700792e-02], sum to 1.0000
[2019-04-17 15:22:15,688] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6568
[2019-04-17 15:22:15,852] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.2, 52.66666666666667, 0.0, 0.0, 22.5, 22.92444127611547, -0.1528307041642263, 1.0, 1.0, 65.0, 97.3369087703083], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2312400.0000, 
sim time next is 2313600.0000, 
raw observation next is [-1.2, 53.33333333333334, 0.0, 0.0, 22.5, 23.74977510335102, -0.0496212835676448, 1.0, 1.0, 25.0, 48.76398467761766], 
processed observation next is [1.0, 0.782608695652174, 0.42936288088642666, 0.5333333333333334, 0.0, 0.0, 0.375, 0.47914792527925165, 0.4834595721441184, 1.0, 1.0, 0.2, 0.48763984677617656], 
reward next is 0.3124, 
noisyNet noise sample is [array([-1.6660136], dtype=float32), 1.5975667]. 
=============================================
[2019-04-17 15:22:17,945] A3C_AGENT_WORKER-Thread-7 INFO:Evaluating...
[2019-04-17 15:22:17,946] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-17 15:22:17,947] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:22:17,947] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation job starts!
[2019-04-17 15:22:17,949] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation job starts!
[2019-04-17 15:22:17,949] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:22:17,951] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v2-res1/Eplus-env-sub_run3
[2019-04-17 15:22:17,962] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:22:17,965] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res1/Eplus-env-sub_run3
[2019-04-17 15:22:17,981] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v1-res1/Eplus-env-sub_run3
[2019-04-17 15:22:40,503] A3C_EVAL-Part4-Heavy-Pit-Train-v3 DEBUG:NoisyNet noise sample: [array([-0.13406242], dtype=float32), 0.120983236]
[2019-04-17 15:22:40,503] A3C_EVAL-Part4-Heavy-Pit-Train-v3 DEBUG:Observation this: [1.1, 92.0, 0.0, 0.0, 22.5, 26.61741593389835, 0.8244012254811252, 1.0, 1.0, 25.0, 34.92371920176704]
[2019-04-17 15:22:40,503] A3C_EVAL-Part4-Heavy-Pit-Train-v3 DEBUG:Observation forecast: []
[2019-04-17 15:22:40,504] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Softmax [9.9342418e-12 2.4019779e-16 8.3463281e-01 1.5451082e-09 1.2935627e-08
 2.2334530e-11 1.5253052e-09 2.2424911e-06 1.4721137e-08 2.6814193e-09
 1.6536491e-01], sampled 0.40615513889356203
[2019-04-17 15:23:42,875] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation: average rewards by now are 1686.9882 139338.2450 1093.7138
[2019-04-17 15:23:42,935] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:23:42,935] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:23:42,935] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:23:43,120] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:23:43,120] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:23:43,120] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:23:59,529] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation: average rewards by now are 1656.6762 148592.5608 852.5865
[2019-04-17 15:23:59,576] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:23:59,576] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:23:59,576] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:23:59,803] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:23:59,803] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:23:59,803] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:24:07,612] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation: average rewards by now are 1687.6383 150140.7340 666.0803
[2019-04-17 15:24:07,649] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:24:07,649] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:24:07,649] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:24:07,831] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:24:07,831] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:24:07,831] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:24:08,650] A3C_AGENT_WORKER-Thread-7 INFO:Global step: 100000, evaluation results [100000.0, 1656.6762193927223, 148592.56079245327, 852.5864764308662, 1686.9881749539463, 139338.24498976415, 1093.7138499066084, 1687.6383284913754, 150140.73399142627, 666.0802750306606]
[2019-04-17 15:24:18,863] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.53195453e-09 3.23310909e-12 8.61452222e-01 3.19469166e-07
 3.13767885e-07 1.41281005e-08 8.75359319e-07 1.02638187e-04
 2.46740842e-06 9.36720937e-07 1.38440177e-01], sum to 1.0000
[2019-04-17 15:24:18,863] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4024
[2019-04-17 15:24:18,881] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.1, 28.0, 0.0, 0.0, 19.0, 24.05594489186709, 0.04532059984337326, 0.0, 1.0, 25.0, 20.576577574355433], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2484000.0000, 
sim time next is 2485200.0000, 
raw observation next is [0.7333333333333335, 28.66666666666667, 0.0, 0.0, 19.0, 23.89534183470474, 0.01661403151148788, 0.0, 1.0, 25.0, 19.042796543017573], 
processed observation next is [0.0, 0.782608695652174, 0.4829178208679595, 0.28666666666666674, 0.0, 0.0, 0.08333333333333333, 0.4912784862253951, 0.5055380105038293, 0.0, 1.0, 0.2, 0.19042796543017573], 
reward next is 0.6096, 
noisyNet noise sample is [array([0.17800984], dtype=float32), -0.09750836]. 
=============================================
[2019-04-17 15:24:18,906] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.5353768e-10 1.6160889e-14 9.2742550e-01 2.5146258e-08 1.4371267e-07
 2.8386249e-10 5.9609917e-09 9.1375641e-06 3.5698957e-08 1.1866612e-08
 7.2565138e-02], sum to 1.0000
[2019-04-17 15:24:18,906] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9194
[2019-04-17 15:24:18,996] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.8429762e-11 4.2970913e-15 8.6408454e-01 8.2851290e-09 7.7635910e-08
 2.0017293e-10 5.2236913e-09 3.7371740e-06 3.0277953e-08 6.4984351e-09
 1.3591163e-01], sum to 1.0000
[2019-04-17 15:24:18,996] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2984
[2019-04-17 15:24:19,013] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.2, 61.00000000000001, 0.0, 0.0, 22.5, 23.20576622905087, -0.0552298660885957, 0.0, 1.0, 25.0, 14.54175569498958], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2661600.0000, 
sim time next is 2662800.0000, 
raw observation next is [-1.2, 62.0, 0.0, 0.0, 22.5, 22.97220044532952, -0.08843863899822113, 1.0, 1.0, 25.0, 13.71428291734825], 
processed observation next is [1.0, 0.8260869565217391, 0.42936288088642666, 0.62, 0.0, 0.0, 0.375, 0.4143500371107933, 0.47052045366725964, 1.0, 1.0, 0.2, 0.1371428291734825], 
reward next is 0.6629, 
noisyNet noise sample is [array([0.58153784], dtype=float32), 0.2114509]. 
=============================================
[2019-04-17 15:24:19,027] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-6.9, 78.33333333333334, 0.0, 0.0, 19.0, 23.15259918101563, -0.08382059736488907, 0.0, 1.0, 25.0, 25.193605266712556], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2614800.0000, 
sim time next is 2616000.0000, 
raw observation next is [-7.1, 78.66666666666667, 0.0, 0.0, 19.0, 23.09106656628734, -0.1111901776542188, 0.0, 1.0, 25.0, 23.058183084640696], 
processed observation next is [1.0, 0.2608695652173913, 0.2659279778393352, 0.7866666666666667, 0.0, 0.0, 0.08333333333333333, 0.42425554719061154, 0.4629366074485937, 0.0, 1.0, 0.2, 0.23058183084640696], 
reward next is 0.5694, 
noisyNet noise sample is [array([-0.5613692], dtype=float32), 0.36184433]. 
=============================================
[2019-04-17 15:24:22,662] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.2922749e-12 1.9193622e-16 8.3879238e-01 3.6722689e-09 3.7937347e-09
 2.4785073e-11 1.8728339e-09 1.1369441e-06 6.0411325e-09 2.6655831e-09
 1.6120656e-01], sum to 1.0000
[2019-04-17 15:24:22,662] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2718
[2019-04-17 15:24:22,707] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-8.666666666666668, 64.0, 112.8333333333333, 763.1666666666667, 22.5, 24.15878510064837, 0.1699656454289275, 1.0, 1.0, 65.0, 60.62957405520602], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2719200.0000, 
sim time next is 2720400.0000, 
raw observation next is [-8.333333333333334, 64.0, 112.1666666666667, 784.0, 22.5, 24.50862338179032, 0.1963157054497152, 1.0, 1.0, 25.0, 47.661510400548806], 
processed observation next is [1.0, 0.4782608695652174, 0.23176361957525393, 0.64, 0.373888888888889, 0.8662983425414365, 0.375, 0.5423852818158599, 0.5654385684832384, 1.0, 1.0, 0.2, 0.47661510400548807], 
reward next is 0.3234, 
noisyNet noise sample is [array([-0.3340138], dtype=float32), 1.5197247]. 
=============================================
[2019-04-17 15:24:22,972] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1374629e-11 2.2421690e-16 8.7410635e-01 3.6526469e-09 7.3650930e-09
 2.5082733e-11 1.0436703e-09 1.0878655e-06 1.0923608e-08 1.1272010e-09
 1.2589262e-01], sum to 1.0000
[2019-04-17 15:24:22,976] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2928
[2019-04-17 15:24:23,081] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.1, 39.0, 225.0, 46.5, 22.5, 24.62058211605262, 0.093638929596993, 1.0, 1.0, 25.0, 22.70006176313067], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2548800.0000, 
sim time next is 2550000.0000, 
raw observation next is [1.466666666666667, 36.0, 220.3333333333333, 30.16666666666666, 22.5, 24.63412355353945, 0.09467850861827525, 1.0, 1.0, 25.0, 20.16744921559696], 
processed observation next is [1.0, 0.5217391304347826, 0.5032317636195753, 0.36, 0.7344444444444442, 0.033333333333333326, 0.375, 0.5528436294616208, 0.5315595028727584, 1.0, 1.0, 0.2, 0.2016744921559696], 
reward next is 0.5983, 
noisyNet noise sample is [array([1.0289434], dtype=float32), -1.5971534]. 
=============================================
[2019-04-17 15:24:23,107] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[42.768166]
 [43.82322 ]
 [43.235355]
 [44.111263]
 [43.14678 ]
 [42.38608 ]
 [42.597706]
 [41.307247]
 [40.300602]
 [38.86476 ]
 [38.88211 ]
 [37.053295]
 [36.999405]
 [35.39007 ]
 [35.874344]
 [35.892498]
 [35.47701 ]
 [35.47468 ]
 [35.435543]
 [35.411728]
 [35.24523 ]
 [35.11523 ]
 [35.029037]
 [35.179493]
 [35.111107]], R is [[43.05023956]
 [43.19273376]
 [43.3058815 ]
 [43.38493729]
 [43.42568207]
 [43.42243576]
 [43.36919022]
 [43.21933746]
 [42.78714371]
 [42.72807312]
 [42.56682205]
 [42.14115524]
 [41.99591064]
 [41.57595062]
 [41.77267075]
 [41.95418549]
 [42.10992813]
 [42.2415657 ]
 [42.35865021]
 [42.44996643]
 [42.51194763]
 [42.53802109]
 [42.50247955]
 [42.42889023]
 [42.00460052]].
[2019-04-17 15:24:23,264] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8570887e-12 3.4671874e-17 8.6798805e-01 7.4676765e-10 1.4170836e-09
 7.9801166e-12 8.3037788e-10 3.6795777e-07 2.7222942e-09 9.3601538e-10
 1.3201156e-01], sum to 1.0000
[2019-04-17 15:24:23,264] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2489
[2019-04-17 15:24:23,308] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-4.8, 56.0, 105.5, 760.5, 22.5, 25.12588710824551, 0.3559886637754948, 1.0, 1.0, 25.0, 41.28990723164707], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2728800.0000, 
sim time next is 2730000.0000, 
raw observation next is [-4.533333333333333, 55.33333333333334, 103.1666666666667, 742.1666666666667, 22.5, 25.1929916161547, 0.3711733030080095, 1.0, 1.0, 25.0, 35.49789730546338], 
processed observation next is [1.0, 0.6086956521739131, 0.3370267774699908, 0.5533333333333335, 0.343888888888889, 0.8200736648250462, 0.375, 0.5994159680128917, 0.6237244343360032, 1.0, 1.0, 0.2, 0.35497897305463383], 
reward next is 0.4450, 
noisyNet noise sample is [array([-0.3340138], dtype=float32), 1.5197247]. 
=============================================
[2019-04-17 15:24:23,312] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[47.69289 ]
 [47.734432]
 [46.6807  ]
 [46.88623 ]
 [46.97175 ]
 [46.487934]
 [46.02708 ]
 [46.25208 ]
 [45.20268 ]
 [44.70311 ]
 [43.050354]
 [43.36281 ]
 [42.33212 ]
 [41.66216 ]
 [40.01724 ]
 [39.69349 ]
 [39.00683 ]
 [38.56188 ]
 [38.075264]
 [38.649746]
 [37.848534]
 [37.662495]
 [38.26727 ]
 [38.13505 ]
 [38.768486]], R is [[47.90652466]
 [47.81455994]
 [47.33641434]
 [47.22623825]
 [46.75397491]
 [46.78305817]
 [46.75734711]
 [46.68294907]
 [46.539505  ]
 [46.07411194]
 [45.6133728 ]
 [45.63549423]
 [45.60974503]
 [45.50614166]
 [45.0510788 ]
 [45.27587128]
 [45.48356247]
 [45.67556381]
 [45.84301376]
 [45.99892807]
 [46.14035797]
 [46.26407242]
 [46.36777115]
 [46.44831467]
 [46.50178146]].
[2019-04-17 15:24:35,762] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.64513791e-10 7.47623975e-15 8.20872188e-01 4.17455448e-09
 1.10233984e-07 1.62367189e-10 8.79891360e-09 1.70010628e-06
 2.99458343e-08 5.98378858e-09 1.79126009e-01], sum to 1.0000
[2019-04-17 15:24:35,762] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7338
[2019-04-17 15:24:35,847] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [6.6, 25.0, 83.0, 38.0, 22.5, 23.48033758496126, -0.08171972181539056, 1.0, 1.0, 25.0, 24.928433160303314], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2822400.0000, 
sim time next is 2823600.0000, 
raw observation next is [6.4, 26.0, 75.0, 63.33333333333334, 22.5, 23.30127551044646, -0.123562920341948, 1.0, 1.0, 25.0, 22.227231336974224], 
processed observation next is [1.0, 0.6956521739130435, 0.6398891966759004, 0.26, 0.25, 0.0699815837937385, 0.375, 0.44177295920387155, 0.4588123598860174, 1.0, 1.0, 0.2, 0.22227231336974224], 
reward next is 0.5777, 
noisyNet noise sample is [array([-0.1289308], dtype=float32), 1.3417293]. 
=============================================
[2019-04-17 15:24:38,069] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.74344905e-10 1.74100084e-14 5.51911831e-01 1.28694655e-08
 3.85523045e-08 3.60323965e-10 1.62963865e-08 2.48242122e-05
 1.24880771e-07 1.98874641e-08 4.48063135e-01], sum to 1.0000
[2019-04-17 15:24:38,070] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9090
[2019-04-17 15:24:38,120] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-3.0, 65.0, 193.5, 623.1666666666667, 19.0, 24.22393179051588, 0.1533323407809954, 0.0, 1.0, 65.0, 62.79096168454323], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2982000.0000, 
sim time next is 2983200.0000, 
raw observation next is [-3.0, 65.0, 169.1666666666667, 709.1666666666667, 19.0, 24.40391512021594, 0.1853114910837003, 0.0, 1.0, 65.0, 59.86387794026497], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.65, 0.563888888888889, 0.783609576427256, 0.08333333333333333, 0.5336595933513285, 0.5617704970279002, 0.0, 1.0, 1.0, 0.5986387794026498], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.728084], dtype=float32), -0.8265434]. 
=============================================
[2019-04-17 15:24:39,572] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.00638855e-11 2.52641817e-16 6.47853792e-01 6.00545302e-09
 4.64614835e-08 4.75202273e-11 1.68476810e-09 3.40865427e-06
 2.24082886e-08 1.04888742e-09 3.52142632e-01], sum to 1.0000
[2019-04-17 15:24:39,573] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4109
[2019-04-17 15:24:39,654] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 93.0, 17.5, 48.49999999999999, 22.5, 23.77625390645742, 0.0855103496641253, 1.0, 1.0, 65.0, 77.18505347929681], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2878800.0000, 
sim time next is 2880000.0000, 
raw observation next is [2.0, 93.0, 52.5, 91.5, 22.5, 24.24813690027563, 0.1197968304375092, 1.0, 1.0, 25.0, 55.00236580688006], 
processed observation next is [1.0, 0.34782608695652173, 0.518005540166205, 0.93, 0.175, 0.1011049723756906, 0.375, 0.520678075022969, 0.5399322768125031, 1.0, 1.0, 0.2, 0.5500236580688006], 
reward next is 0.2500, 
noisyNet noise sample is [array([-0.05732269], dtype=float32), 0.770909]. 
=============================================
[2019-04-17 15:24:39,713] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[46.447647]
 [45.36627 ]
 [44.849346]
 [44.8422  ]
 [44.7568  ]
 [44.75513 ]
 [44.890255]
 [44.244194]
 [43.630093]
 [43.89285 ]
 [43.37181 ]
 [44.6403  ]
 [44.40381 ]
 [45.497604]
 [44.159576]
 [44.347923]
 [44.00143 ]
 [43.87136 ]
 [43.334225]
 [43.037   ]
 [43.137234]
 [42.246464]
 [42.775646]
 [41.558163]
 [41.440964]], R is [[46.83583832]
 [46.36748123]
 [46.37278748]
 [46.30358887]
 [46.19164658]
 [46.02453613]
 [45.76581573]
 [45.30815887]
 [44.85507584]
 [44.90394592]
 [44.92079544]
 [44.90062332]
 [44.83675385]
 [44.72042465]
 [44.60516357]
 [44.40467834]
 [43.96063232]
 [43.74368668]
 [43.30625153]
 [43.15925217]
 [42.99520874]
 [42.56525803]
 [42.13960648]
 [41.71821213]
 [41.81368637]].
[2019-04-17 15:24:40,603] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1495514e-11 7.2112404e-16 8.4815353e-01 1.9251796e-09 2.9548627e-08
 3.9917968e-11 7.5863129e-09 1.7107340e-06 4.6275439e-08 8.3917424e-09
 1.5184470e-01], sum to 1.0000
[2019-04-17 15:24:40,603] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9392
[2019-04-17 15:24:40,650] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [5.333333333333334, 31.66666666666667, 227.1666666666667, 144.1666666666667, 22.5, 23.95762107692222, -0.07273544837167671, 1.0, 1.0, 25.0, 25.925349104428594], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2814000.0000, 
sim time next is 2815200.0000, 
raw observation next is [6.0, 30.0, 183.5, 86.5, 22.5, 23.75052898149922, 0.1053458412397993, 1.0, 1.0, 65.0, 86.92001574392626], 
processed observation next is [1.0, 0.6086956521739131, 0.6288088642659281, 0.3, 0.6116666666666667, 0.09558011049723757, 0.375, 0.4792107484582682, 0.5351152804132665, 1.0, 1.0, 1.0, 0.8692001574392626], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5892444], dtype=float32), -0.1596504]. 
=============================================
[2019-04-17 15:24:54,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2611148e-10 9.6748688e-15 7.6175624e-01 1.9831809e-08 1.0956015e-07
 4.5194379e-10 2.1400968e-08 6.5042627e-06 5.4589901e-08 2.3334847e-08
 2.3823711e-01], sum to 1.0000
[2019-04-17 15:24:54,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6953
[2019-04-17 15:24:54,804] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-8.600000000000001, 77.0, 0.0, 0.0, 19.0, 24.3814520573524, 0.2086776136888369, 0.0, 1.0, 25.0, 43.27185669142324], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3296400.0000, 
sim time next is 3297600.0000, 
raw observation next is [-8.9, 77.0, 0.0, 0.0, 19.0, 24.3265708158393, 0.1751390829453369, 0.0, 1.0, 25.0, 38.60828866046786], 
processed observation next is [1.0, 0.17391304347826086, 0.21606648199445982, 0.77, 0.0, 0.0, 0.08333333333333333, 0.527214234653275, 0.5583796943151124, 0.0, 1.0, 0.2, 0.38608288660467865], 
reward next is 0.4139, 
noisyNet noise sample is [array([-0.83088505], dtype=float32), 0.5900319]. 
=============================================
[2019-04-17 15:24:59,685] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.1753166e-10 7.8527755e-15 8.9998817e-01 2.4635165e-08 5.9839167e-08
 7.2161710e-10 7.8775226e-09 2.8468705e-06 3.1816914e-08 1.5365888e-08
 1.0000879e-01], sum to 1.0000
[2019-04-17 15:24:59,686] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6096
[2019-04-17 15:24:59,707] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-11.0, 76.0, 0.0, 0.0, 19.0, 24.08494625155705, 0.1781291810355848, 0.0, 1.0, 25.0, 22.069990637753257], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3307200.0000, 
sim time next is 3308400.0000, 
raw observation next is [-11.0, 76.0, 0.0, 0.0, 19.0, 23.97034770816645, 0.1527447419553233, 0.0, 1.0, 25.0, 20.388889314075364], 
processed observation next is [1.0, 0.30434782608695654, 0.15789473684210528, 0.76, 0.0, 0.0, 0.08333333333333333, 0.4975289756805375, 0.5509149139851078, 0.0, 1.0, 0.2, 0.20388889314075365], 
reward next is 0.5961, 
noisyNet noise sample is [array([0.67418724], dtype=float32), -0.18857917]. 
=============================================
[2019-04-17 15:25:03,746] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.2207831e-11 4.2545171e-16 9.2677617e-01 2.2445996e-09 1.5325631e-08
 4.8560996e-11 3.9116692e-09 2.8554309e-06 2.2175874e-08 2.7607994e-09
 7.3220924e-02], sum to 1.0000
[2019-04-17 15:25:03,748] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.9817
[2019-04-17 15:25:03,876] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [0.0, 100.0, 0.0, 0.0, 19.0, 24.5206517051733, 0.3423380820772906, 0.0, 1.0, 25.0, 10.020422592689204], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 3204000.0000, 
sim time next is 3205200.0000, 
raw observation next is [-0.3333333333333333, 100.0, 0.0, 0.0, 19.0, 24.44038415917526, 0.4079528916972959, 0.0, 1.0, 65.0, 76.84207265037949], 
processed observation next is [1.0, 0.08695652173913043, 0.4533702677747, 1.0, 0.0, 0.0, 0.08333333333333333, 0.5366986799312716, 0.635984297232432, 0.0, 1.0, 1.0, 0.7684207265037949], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1452701], dtype=float32), -1.0869818]. 
=============================================
[2019-04-17 15:25:13,045] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.5024496e-12 6.8683764e-17 8.7213504e-01 3.0350098e-09 1.2053552e-08
 1.6268632e-11 9.0705105e-10 7.3456181e-07 8.6990202e-09 6.8830369e-10
 1.2786423e-01], sum to 1.0000
[2019-04-17 15:25:13,045] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3064
[2019-04-17 15:25:13,124] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.0, 50.0, 96.5, 713.0, 22.5, 25.80056794593546, 0.5772350372305736, 1.0, 1.0, 25.0, 35.95240245035872], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3337200.0000, 
sim time next is 3338400.0000, 
raw observation next is [-2.666666666666667, 48.66666666666667, 90.16666666666666, 687.0, 22.5, 26.03641561423551, 0.6053587653347675, 1.0, 1.0, 25.0, 29.789939736758406], 
processed observation next is [1.0, 0.6521739130434783, 0.38873499538319484, 0.4866666666666667, 0.3005555555555555, 0.7591160220994475, 0.375, 0.6697013011862923, 0.7017862551115891, 1.0, 1.0, 0.2, 0.2978993973675841], 
reward next is 0.5021, 
noisyNet noise sample is [array([1.3037437], dtype=float32), 0.03666975]. 
=============================================
[2019-04-17 15:25:14,083] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.1597051e-12 5.6152216e-17 6.9919932e-01 5.8800781e-10 3.6678607e-09
 2.8450443e-12 7.1178269e-10 4.9397386e-07 3.7380272e-09 7.5707474e-10
 3.0080017e-01], sum to 1.0000
[2019-04-17 15:25:14,083] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3765
[2019-04-17 15:25:14,165] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 19.0, 26.51715094619017, 0.7375682664480622, 0.0, 1.0, 25.0, 37.85989196268379], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3452400.0000, 
sim time next is 3453600.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 19.0, 26.49482650026334, 0.7284966401532779, 0.0, 1.0, 25.0, 33.23719173964906], 
processed observation next is [1.0, 1.0, 0.4903047091412743, 0.86, 0.0, 0.0, 0.08333333333333333, 0.7079022083552783, 0.742832213384426, 0.0, 1.0, 0.2, 0.33237191739649063], 
reward next is 0.4676, 
noisyNet noise sample is [array([0.8955686], dtype=float32), -0.5199154]. 
=============================================
[2019-04-17 15:25:14,283] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3187457e-12 5.1374361e-17 5.9157729e-01 2.5436903e-10 1.7408093e-08
 1.0030665e-11 1.7521909e-09 5.6610855e-07 6.9901471e-09 3.9787045e-09
 4.0842214e-01], sum to 1.0000
[2019-04-17 15:25:14,283] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8579
[2019-04-17 15:25:14,305] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-2.0, 46.0, 73.5, 587.5, 22.5, 26.35360954474204, 0.7117487098447098, 1.0, 1.0, 25.0, 31.975405382403558], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 3340800.0000, 
sim time next is 3342000.0000, 
raw observation next is [-2.0, 47.33333333333334, 64.5, 529.8333333333333, 22.5, 26.81662640722004, 0.7511865680861263, 1.0, 1.0, 65.0, 37.30588968942223], 
processed observation next is [1.0, 0.6956521739130435, 0.40720221606648205, 0.47333333333333344, 0.215, 0.5854511970534069, 0.375, 0.7347188672683366, 0.7503955226953755, 1.0, 1.0, 1.0, 0.3730588968942223], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.33143014], dtype=float32), 1.2538925]. 
=============================================
[2019-04-17 15:25:16,651] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.8067899e-12 7.2471318e-17 7.3367035e-01 5.6459115e-10 4.6655555e-09
 1.3643647e-11 3.1186362e-09 3.1551423e-07 1.2151815e-08 4.6818216e-10
 2.6632920e-01], sum to 1.0000
[2019-04-17 15:25:16,651] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5150
[2019-04-17 15:25:16,728] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 55.33333333333334, 115.8333333333333, 820.8333333333334, 22.5, 27.34332469011205, 0.7724163579134977, 1.0, 1.0, 65.0, 49.565379960243185], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3500400.0000, 
sim time next is 3501600.0000, 
raw observation next is [2.0, 53.66666666666667, 115.8333333333333, 820.1666666666667, 22.5, 26.46343117993078, 0.8420028105460388, 1.0, 1.0, 25.0, 23.03187652521435], 
processed observation next is [1.0, 0.5217391304347826, 0.518005540166205, 0.5366666666666667, 0.386111111111111, 0.9062615101289135, 0.375, 0.7052859316608983, 0.7806676035153463, 1.0, 1.0, 0.2, 0.2303187652521435], 
reward next is 0.5697, 
noisyNet noise sample is [array([0.87895674], dtype=float32), 0.9555739]. 
=============================================
[2019-04-17 15:25:17,139] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6818359e-12 3.6348526e-17 5.9664017e-01 5.4072946e-10 4.7570197e-09
 6.0265972e-12 3.2862539e-09 2.7628350e-06 6.5393366e-09 1.3212663e-09
 4.0335709e-01], sum to 1.0000
[2019-04-17 15:25:17,142] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8633
[2019-04-17 15:25:17,201] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [3.0, 49.0, 95.0, 734.0, 22.5, 27.41266319848726, 0.9590417559440692, 1.0, 1.0, 65.0, 20.591210084107114], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 3510000.0000, 
sim time next is 3511200.0000, 
raw observation next is [3.0, 49.0, 90.33333333333334, 702.6666666666666, 22.5, 27.74416995357504, 0.997648618095131, 1.0, 1.0, 65.0, 22.763728853809425], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.49, 0.30111111111111116, 0.776427255985267, 0.375, 0.8120141627979199, 0.8325495393650436, 1.0, 1.0, 1.0, 0.22763728853809426], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0102258], dtype=float32), 1.0131841]. 
=============================================
[2019-04-17 15:25:18,309] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.6226815e-10 1.3504673e-13 4.3558976e-01 7.6633519e-08 9.3147570e-08
 3.6314998e-09 1.1667555e-07 2.7901358e-05 4.6252569e-07 6.7176316e-08
 5.6438142e-01], sum to 1.0000
[2019-04-17 15:25:18,322] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4840
[2019-04-17 15:25:18,361] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [9.0, 25.0, 0.0, 0.0, 19.0, 26.86896680694343, 0.7214143482207994, 0.0, 1.0, 65.0, 37.82628173070557], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 3634800.0000, 
sim time next is 3636000.0000, 
raw observation next is [9.0, 25.0, 0.0, 0.0, 19.0, 26.86634661095795, 0.7203246277046175, 0.0, 1.0, 65.0, 37.77400200525334], 
processed observation next is [0.0, 0.08695652173913043, 0.7119113573407203, 0.25, 0.0, 0.0, 0.08333333333333333, 0.7388622175798293, 0.7401082092348724, 0.0, 1.0, 1.0, 0.3777400200525334], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8332515], dtype=float32), -1.7342253]. 
=============================================
[2019-04-17 15:25:18,688] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1051574e-11 1.4128963e-15 9.3884307e-01 3.6542107e-09 6.2296273e-08
 4.8341268e-11 2.0143205e-09 2.6949590e-06 2.9650399e-08 2.7687639e-09
 6.1154086e-02], sum to 1.0000
[2019-04-17 15:25:18,688] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2337
[2019-04-17 15:25:18,713] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-4.333333333333334, 67.0, 0.0, 0.0, 19.0, 26.05898346585489, 0.6149694037771637, 0.0, 1.0, 25.0, 26.46021654553458], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3363600.0000, 
sim time next is 3364800.0000, 
raw observation next is [-4.666666666666666, 69.0, 0.0, 0.0, 19.0, 25.82601680169904, 0.5701624151456953, 0.0, 1.0, 25.0, 23.040218646260616], 
processed observation next is [1.0, 0.9565217391304348, 0.33333333333333337, 0.69, 0.0, 0.0, 0.08333333333333333, 0.6521680668082533, 0.6900541383818984, 0.0, 1.0, 0.2, 0.23040218646260616], 
reward next is 0.5696, 
noisyNet noise sample is [array([-1.5033308], dtype=float32), 0.047996487]. 
=============================================
[2019-04-17 15:25:20,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.80553130e-11 4.02446614e-15 8.16012144e-01 1.15390648e-08
 1.90834228e-07 2.21785618e-10 1.48664725e-08 2.90509024e-06
 2.21875140e-08 1.58450302e-08 1.83984756e-01], sum to 1.0000
[2019-04-17 15:25:20,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5658
[2019-04-17 15:25:20,501] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.0, 70.33333333333334, 0.0, 0.0, 19.0, 25.7875869604993, 0.5333843885661821, 0.0, 1.0, 25.0, 34.29775649227102], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3468000.0000, 
sim time next is 3469200.0000, 
raw observation next is [1.0, 68.66666666666667, 0.0, 0.0, 19.0, 25.75956007598506, 0.52403672283065, 0.0, 1.0, 25.0, 30.65188697804027], 
processed observation next is [1.0, 0.13043478260869565, 0.4903047091412743, 0.6866666666666668, 0.0, 0.0, 0.08333333333333333, 0.6466300063320883, 0.6746789076102168, 0.0, 1.0, 0.2, 0.3065188697804027], 
reward next is 0.4935, 
noisyNet noise sample is [array([-0.47993654], dtype=float32), 0.52884704]. 
=============================================
[2019-04-17 15:25:28,147] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.92172232e-11 1.29342662e-15 8.75640392e-01 7.24379356e-09
 8.17291337e-08 1.27687444e-10 5.06639575e-09 1.06373147e-06
 1.26460691e-08 9.18545595e-09 1.24358386e-01], sum to 1.0000
[2019-04-17 15:25:28,166] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5923
[2019-04-17 15:25:28,197] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-4.0, 77.0, 0.0, 0.0, 19.0, 25.60040884907955, 0.5542204692895324, 0.0, 1.0, 65.0, 77.31438551668427], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3808800.0000, 
sim time next is 3810000.0000, 
raw observation next is [-4.0, 75.0, 0.0, 0.0, 19.0, 25.88686611099647, 0.591813662027895, 0.0, 1.0, 25.0, 47.76063040648651], 
processed observation next is [1.0, 0.08695652173913043, 0.3518005540166205, 0.75, 0.0, 0.0, 0.08333333333333333, 0.657238842583039, 0.6972712206759649, 0.0, 1.0, 0.2, 0.47760630406486515], 
reward next is 0.3224, 
noisyNet noise sample is [array([0.19449636], dtype=float32), 0.5817098]. 
=============================================
[2019-04-17 15:25:28,232] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[41.44739 ]
 [40.207836]
 [40.92666 ]
 [40.80507 ]
 [41.44909 ]
 [41.488792]
 [42.031136]
 [41.3386  ]
 [41.45356 ]
 [41.23916 ]
 [41.331264]
 [41.827686]
 [42.04665 ]
 [42.214466]
 [42.47746 ]
 [42.75313 ]
 [43.38215 ]
 [43.799408]
 [44.47522 ]
 [44.234474]
 [44.458214]
 [44.13859 ]
 [44.87671 ]
 [44.432247]
 [45.28461 ]], R is [[40.58851242]
 [40.18262863]
 [40.32994843]
 [40.44817734]
 [40.53551102]
 [40.58903122]
 [40.55080795]
 [40.14530182]
 [40.43156433]
 [40.70959854]
 [40.97899628]
 [41.23899841]
 [41.48604202]
 [41.72578049]
 [41.9499054 ]
 [42.16343689]
 [42.35840988]
 [42.53821564]
 [42.69929504]
 [42.83825684]
 [42.95461655]
 [43.03673553]
 [43.10864639]
 [43.16677475]
 [43.28514099]].
[2019-04-17 15:25:28,968] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.2257161e-12 8.6957746e-17 9.0786088e-01 5.3187732e-10 1.9273557e-08
 9.9412215e-12 3.5106449e-09 6.5388070e-07 4.6963464e-09 1.2575382e-09
 9.2138439e-02], sum to 1.0000
[2019-04-17 15:25:28,968] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5375
[2019-04-17 15:25:29,015] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 60.0, 56.16666666666667, 473.6666666666667, 22.5, 27.04576394895981, 0.855126651227376, 1.0, 1.0, 25.0, 33.24370370468156], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3775200.0000, 
sim time next is 3776400.0000, 
raw observation next is [0.0, 60.0, 40.5, 343.0, 22.5, 27.47481316549898, 0.6777859492347506, 1.0, 1.0, 25.0, 32.78921270714781], 
processed observation next is [1.0, 0.7391304347826086, 0.46260387811634357, 0.6, 0.135, 0.37900552486187844, 0.375, 0.7895677637915816, 0.7259286497449168, 1.0, 1.0, 0.2, 0.32789212707147813], 
reward next is 0.4721, 
noisyNet noise sample is [array([1.5973887], dtype=float32), -0.3378435]. 
=============================================
[2019-04-17 15:25:32,254] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6964238e-11 2.2991820e-16 9.3736911e-01 7.7288548e-10 1.1849204e-08
 2.1904633e-11 5.7666187e-09 5.8912900e-07 1.2614591e-08 2.4751352e-09
 6.2630378e-02], sum to 1.0000
[2019-04-17 15:25:32,254] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6518
[2019-04-17 15:25:32,312] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.333333333333333, 67.33333333333333, 14.16666666666667, 122.5, 22.5, 26.18333135498146, 0.7032700219875587, 1.0, 1.0, 25.0, 20.75339038779057], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3778800.0000, 
sim time next is 3780000.0000, 
raw observation next is [-2.0, 71.0, 0.0, 0.0, 22.5, 26.34272740344109, 0.7069861863626326, 1.0, 1.0, 25.0, 17.61246682980766], 
processed observation next is [1.0, 0.782608695652174, 0.40720221606648205, 0.71, 0.0, 0.0, 0.375, 0.6952272836200907, 0.7356620621208775, 1.0, 1.0, 0.2, 0.17612466829807658], 
reward next is 0.6239, 
noisyNet noise sample is [array([-0.50299513], dtype=float32), 1.9907795]. 
=============================================
[2019-04-17 15:25:32,356] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[44.514145]
 [44.28088 ]
 [44.70757 ]
 [44.293453]
 [44.497368]
 [43.94558 ]
 [43.98382 ]
 [43.031532]
 [43.049747]
 [43.088825]
 [43.11391 ]
 [43.186882]
 [43.290394]
 [43.397087]
 [43.563667]
 [43.712147]
 [43.814342]
 [43.903328]
 [43.975872]
 [43.947353]
 [44.339264]
 [43.942738]
 [43.67189 ]
 [44.25748 ]
 [44.367027]], R is [[44.16937256]
 [44.32014465]
 [44.44966507]
 [44.54536819]
 [44.61097717]
 [44.61309433]
 [44.5826683 ]
 [44.13684082]
 [44.44262314]
 [44.74575424]
 [45.03914642]
 [45.34666824]
 [45.65081024]
 [45.94619751]
 [46.22711945]
 [46.50415039]
 [46.77511978]
 [47.03972244]
 [47.29743195]
 [47.54789352]
 [47.79028702]
 [48.02399826]
 [48.24671936]
 [48.45056534]
 [48.63721085]].
[2019-04-17 15:25:44,795] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.06025585e-10 5.12341736e-14 9.76501286e-01 3.02996312e-08
 1.05986921e-07 1.24746335e-09 1.12579945e-08 1.18616720e-06
 3.73693361e-08 2.04362838e-08 2.34973840e-02], sum to 1.0000
[2019-04-17 15:25:44,795] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7253
[2019-04-17 15:25:44,836] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-13.33333333333333, 65.0, 15.5, 73.99999999999999, 22.5, 22.45208933908177, -0.25100222883463, 1.0, 1.0, 25.0, 26.077183169998868], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4002000.0000, 
sim time next is 4003200.0000, 
raw observation next is [-13.0, 63.0, 46.5, 222.0, 22.5, 22.43131984130233, -0.2535175690839495, 1.0, 1.0, 25.0, 23.418142559361428], 
processed observation next is [1.0, 0.34782608695652173, 0.10249307479224376, 0.63, 0.155, 0.24530386740331492, 0.375, 0.3692766534418608, 0.4154941436386835, 1.0, 1.0, 0.2, 0.23418142559361427], 
reward next is 0.5658, 
noisyNet noise sample is [array([0.33839044], dtype=float32), 1.1941793]. 
=============================================
[2019-04-17 15:25:44,840] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.1735778e-09 5.7948444e-14 8.2875931e-01 7.1546765e-08 1.7803056e-07
 2.8186247e-09 2.7695974e-08 6.6864500e-06 3.4702924e-07 4.9833879e-08
 1.7123337e-01], sum to 1.0000
[2019-04-17 15:25:44,841] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9795
[2019-04-17 15:25:44,869] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-6.0, 41.0, 0.0, 0.0, 19.0, 24.53888603930497, 0.2326386118661663, 0.0, 1.0, 25.0, 30.030137170617948], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 4065600.0000, 
sim time next is 4066800.0000, 
raw observation next is [-6.0, 41.0, 0.0, 0.0, 19.0, 24.57916715907261, 0.265524125725423, 0.0, 1.0, 65.0, 58.96136690158051], 
processed observation next is [1.0, 0.043478260869565216, 0.296398891966759, 0.41, 0.0, 0.0, 0.08333333333333333, 0.5482639299227176, 0.5885080419084744, 0.0, 1.0, 1.0, 0.5896136690158051], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0341095], dtype=float32), -0.82222825]. 
=============================================
[2019-04-17 15:26:00,833] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.3045532e-12 1.1174528e-16 9.3824452e-01 6.8362727e-10 7.6116091e-09
 1.4503989e-11 4.9503307e-10 9.2814908e-08 2.0782525e-09 1.5495957e-09
 6.1755352e-02], sum to 1.0000
[2019-04-17 15:26:00,835] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1397
[2019-04-17 15:26:00,850] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.0, 47.66666666666667, 261.1666666666666, 102.1666666666667, 22.5, 24.26789261751917, 0.1990173448913969, 1.0, 1.0, 25.0, 29.801011997681428], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4544400.0000, 
sim time next is 4545600.0000, 
raw observation next is [3.0, 46.33333333333334, 245.5, 96.16666666666667, 22.5, 24.70877771912212, 0.2449066350735124, 1.0, 1.0, 25.0, 24.034339749958043], 
processed observation next is [1.0, 0.6086956521739131, 0.5457063711911359, 0.46333333333333343, 0.8183333333333334, 0.10626151012891345, 0.375, 0.5590648099268435, 0.5816355450245041, 1.0, 1.0, 0.2, 0.24034339749958045], 
reward next is 0.5597, 
noisyNet noise sample is [array([-0.21485384], dtype=float32), -0.61803967]. 
=============================================
[2019-04-17 15:26:01,922] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7115272e-13 1.5441245e-17 9.0038198e-01 2.3556584e-10 2.5528386e-09
 6.5282116e-12 7.4577061e-10 8.3615838e-08 4.2350670e-09 2.1365831e-10
 9.9617921e-02], sum to 1.0000
[2019-04-17 15:26:01,923] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4824
[2019-04-17 15:26:01,961] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.5333333333333334, 72.66666666666667, 92.5, 55.0, 22.5, 24.85016437652324, 0.433471976572936, 1.0, 1.0, 65.0, 55.18087250469825], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4522800.0000, 
sim time next is 4524000.0000, 
raw observation next is [-0.2666666666666667, 72.33333333333334, 113.0, 55.0, 22.5, 25.76944761239896, 0.4931800629125351, 1.0, 1.0, 25.0, 44.9198545112253], 
processed observation next is [1.0, 0.34782608695652173, 0.4552169898430287, 0.7233333333333334, 0.37666666666666665, 0.06077348066298342, 0.375, 0.6474539676999133, 0.6643933543041783, 1.0, 1.0, 0.2, 0.44919854511225304], 
reward next is 0.3508, 
noisyNet noise sample is [array([-0.13110329], dtype=float32), -0.8216696]. 
=============================================
[2019-04-17 15:26:03,789] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2420256e-12 3.3061816e-16 9.6634012e-01 7.9647805e-10 4.0078341e-09
 1.7847978e-11 8.9690094e-10 2.1851064e-07 4.5528847e-09 2.6359976e-09
 3.3659626e-02], sum to 1.0000
[2019-04-17 15:26:03,790] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1683
[2019-04-17 15:26:03,798] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 57.00000000000001, 0.0, 0.0, 19.0, 25.08170870018111, 0.4312210349325403, 0.0, 1.0, 25.0, 8.207110772465025], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4659600.0000, 
sim time next is 4660800.0000, 
raw observation next is [2.0, 57.0, 0.0, 0.0, 19.0, 24.9261378165762, 0.4053019019581087, 0.0, 1.0, 25.0, 7.650743461129637], 
processed observation next is [1.0, 0.9565217391304348, 0.518005540166205, 0.57, 0.0, 0.0, 0.08333333333333333, 0.5771781513813501, 0.6351006339860362, 0.0, 1.0, 0.2, 0.07650743461129637], 
reward next is 0.7235, 
noisyNet noise sample is [array([-1.8345588], dtype=float32), -0.6927317]. 
=============================================
[2019-04-17 15:26:07,377] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.9366965e-10 2.2384416e-14 8.1783187e-01 4.1011717e-08 3.8141327e-08
 9.9826214e-10 1.7795548e-08 2.0101313e-06 2.6985100e-07 1.2123642e-08
 1.8216580e-01], sum to 1.0000
[2019-04-17 15:26:07,377] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8686
[2019-04-17 15:26:07,419] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [3.0, 37.0, 184.0, 655.0, 19.0, 24.25539331242048, 0.2600818476174185, 0.0, 1.0, 65.0, 56.385747336966574], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 4802400.0000, 
sim time next is 4803600.0000, 
raw observation next is [3.0, 37.0, 160.0, 713.0, 19.0, 24.64621430917259, 0.3221154053875289, 0.0, 1.0, 65.0, 54.405526113753346], 
processed observation next is [0.0, 0.6086956521739131, 0.5457063711911359, 0.37, 0.5333333333333333, 0.7878453038674034, 0.08333333333333333, 0.5538511924310491, 0.607371801795843, 0.0, 1.0, 1.0, 0.5440552611375334], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18787415], dtype=float32), -0.44292125]. 
=============================================
[2019-04-17 15:26:07,473] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1946620e-09 1.2000390e-12 8.3977515e-01 4.7851904e-07 2.5339244e-07
 4.5145985e-09 1.7450004e-07 1.4600272e-05 8.9250477e-07 1.8068688e-07
 1.6020818e-01], sum to 1.0000
[2019-04-17 15:26:07,473] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2181
[2019-04-17 15:26:07,503] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 39.0, 0.0, 0.0, 19.0, 22.06584608981517, -0.3481868498541347, 0.0, 1.0, 65.0, 88.27649488013316], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4921200.0000, 
sim time next is 4922400.0000, 
raw observation next is [0.3333333333333333, 39.33333333333334, 0.0, 0.0, 19.0, 22.32760431695393, -0.2999323082229358, 0.0, 1.0, 25.0, 39.419225124972755], 
processed observation next is [0.0, 1.0, 0.4718374884579871, 0.3933333333333334, 0.0, 0.0, 0.08333333333333333, 0.3606336930794942, 0.4000225639256881, 0.0, 1.0, 0.2, 0.39419225124972757], 
reward next is 0.4058, 
noisyNet noise sample is [array([0.40739736], dtype=float32), -0.19026504]. 
=============================================
[2019-04-17 15:26:08,020] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4066062e-10 8.7960890e-15 7.5236040e-01 3.6431221e-08 1.9195159e-08
 5.5864374e-10 1.1146109e-08 2.4553301e-06 1.2451453e-07 1.6178719e-08
 2.4763691e-01], sum to 1.0000
[2019-04-17 15:26:08,020] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8003
[2019-04-17 15:26:08,042] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-3.0, 65.0, 163.5, 575.5, 19.0, 23.13573609523491, -0.002344560350364849, 0.0, 1.0, 65.0, 67.4551423406694], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 4788000.0000, 
sim time next is 4789200.0000, 
raw observation next is [-2.666666666666667, 58.66666666666667, 156.5, 678.5, 19.0, 23.61595491712697, 0.07801630299967631, 0.0, 1.0, 65.0, 60.63228821034585], 
processed observation next is [0.0, 0.43478260869565216, 0.38873499538319484, 0.5866666666666667, 0.5216666666666666, 0.7497237569060774, 0.08333333333333333, 0.4679962430939142, 0.5260054343332254, 0.0, 1.0, 1.0, 0.6063228821034585], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2763811], dtype=float32), 0.19741854]. 
=============================================
[2019-04-17 15:26:08,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9651375e-11 3.1753510e-15 8.2555741e-01 8.2961709e-09 2.4941391e-08
 5.9943141e-11 5.3315605e-09 8.2051815e-07 2.5025594e-08 3.6911907e-09
 1.7444171e-01], sum to 1.0000
[2019-04-17 15:26:08,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5134
[2019-04-17 15:26:08,622] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.666666666666667, 29.66666666666667, 115.5, 788.6666666666667, 22.5, 23.33020676361318, -0.1582323289216726, 1.0, 1.0, 25.0, 6.877292791368127], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4962000.0000, 
sim time next is 4963200.0000, 
raw observation next is [2.333333333333333, 29.33333333333334, 117.8333333333333, 810.0, 22.5, 23.34237025317947, -0.1392377242413641, 1.0, 1.0, 25.0, 6.090237548965227], 
processed observation next is [1.0, 0.43478260869565216, 0.5272391505078486, 0.2933333333333334, 0.39277777777777767, 0.8950276243093923, 0.375, 0.44519752109828925, 0.45358742525287865, 1.0, 1.0, 0.2, 0.06090237548965227], 
reward next is 0.7391, 
noisyNet noise sample is [array([-0.63683033], dtype=float32), 1.8590403]. 
=============================================
[2019-04-17 15:26:11,974] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:12,195] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:12,283] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:12,365] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:12,460] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:12,486] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:12,524] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:12,561] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:12,656] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:12,698] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:12,773] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:12,938] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:12,971] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:12,972] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:12,974] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res5/Eplus-env-sub_run3
[2019-04-17 15:26:13,281] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:13,281] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:13,283] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res15/Eplus-env-sub_run3
[2019-04-17 15:26:13,321] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:13,369] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:13,369] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:13,371] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res7/Eplus-env-sub_run3
[2019-04-17 15:26:13,486] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:13,498] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:13,498] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:13,500] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res16/Eplus-env-sub_run3
[2019-04-17 15:26:13,533] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:13,533] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:13,535] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res2/Eplus-env-sub_run3
[2019-04-17 15:26:13,775] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:13,775] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:13,777] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res13/Eplus-env-sub_run3
[2019-04-17 15:26:14,318] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:14,318] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:14,320] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res4/Eplus-env-sub_run3
[2019-04-17 15:26:14,937] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:15,013] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:15,229] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:15,230] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:15,937] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:15,937] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:15,941] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res6/Eplus-env-sub_run3
[2019-04-17 15:26:16,019] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:16,019] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:16,021] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res14/Eplus-env-sub_run3
[2019-04-17 15:26:16,238] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:16,339] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:16,461] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:16,533] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:16,607] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:16,687] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:16,810] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:16,858] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:16,991] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0986055e-12 1.4276915e-16 9.4826585e-01 1.6379991e-09 5.0180211e-09
 1.2954709e-11 1.7166639e-09 3.1836797e-07 1.0806651e-08 2.6244589e-09
 5.1733851e-02], sum to 1.0000
[2019-04-17 15:26:16,992] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7731
[2019-04-17 15:26:17,008] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.666666666666667, 36.0, 0.0, 0.0, 19.0, 23.65581507473157, -0.003474069576786013, 0.0, 1.0, 25.0, 19.22789201812151], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 5008800.0000, 
sim time next is 5010000.0000, 
raw observation next is [2.333333333333333, 38.0, 0.0, 0.0, 19.0, 23.53609535253982, -0.02793170625456649, 0.0, 1.0, 25.0, 17.71011743309846], 
processed observation next is [1.0, 1.0, 0.5272391505078486, 0.38, 0.0, 0.0, 0.08333333333333333, 0.4613412793783184, 0.4906894312484778, 0.0, 1.0, 0.2, 0.1771011743309846], 
reward next is 0.6229, 
noisyNet noise sample is [array([-0.6852017], dtype=float32), 0.31481743]. 
=============================================
[2019-04-17 15:26:17,015] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[47.951355]
 [47.787365]
 [47.684917]
 [47.859627]
 [48.099762]
 [47.634205]
 [49.06955 ]
 [48.259533]
 [47.712677]
 [47.374924]
 [46.88828 ]
 [47.902557]
 [46.89466 ]
 [47.565117]
 [47.078854]
 [47.345566]
 [46.12933 ]
 [46.4282  ]
 [46.706573]
 [46.896732]
 [46.936535]
 [46.879723]
 [46.76977 ]
 [46.672012]
 [46.5245  ]], R is [[48.38440323]
 [48.50827789]
 [48.61305237]
 [48.69645309]
 [48.74238205]
 [48.77245712]
 [48.7675705 ]
 [48.7263031 ]
 [48.61661911]
 [48.13045502]
 [48.27318954]
 [48.37714005]
 [48.45030594]
 [48.48989487]
 [48.47779083]
 [48.36128998]
 [47.87767792]
 [48.18874359]
 [48.49827576]
 [48.80543137]
 [49.10969162]
 [49.41063309]
 [49.70777512]
 [50.00065231]
 [50.28947067]].
[2019-04-17 15:26:17,239] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:17,239] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:17,241] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res8/Eplus-env-sub_run3
[2019-04-17 15:26:17,340] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:17,340] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:17,342] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res10/Eplus-env-sub_run3
[2019-04-17 15:26:17,452] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:17,453] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:17,453] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:17,455] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res12/Eplus-env-sub_run3
[2019-04-17 15:26:17,609] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:17,610] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:17,611] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res3/Eplus-env-sub_run3
[2019-04-17 15:26:17,697] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:18,453] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:18,453] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:18,455] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res11/Eplus-env-sub_run3
[2019-04-17 15:26:19,173] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:19,355] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:26:19,514] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:19,541] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-17 15:26:20,164] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:20,164] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:20,166] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res17/Eplus-env-sub_run3
[2019-04-17 15:26:20,356] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:26:20,356] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:26:20,358] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res9/Eplus-env-sub_run3
[2019-04-17 15:26:24,315] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.2220888e-12 3.0704541e-17 5.2432233e-01 7.4531548e-10 3.7897632e-09
 1.2012234e-11 6.8997102e-10 5.5225303e-07 4.4127435e-09 9.0935753e-10
 4.7567713e-01], sum to 1.0000
[2019-04-17 15:26:24,316] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5668
[2019-04-17 15:26:24,373] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 19.0, 22.88316579312103, -0.1318723935114444, 0.0, 1.0, 65.0, 55.14612840361652], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 15600.0000, 
sim time next is 16800.0000, 
raw observation next is [7.699999999999999, 93.0, 0.0, 0.0, 19.0, 22.91733654555584, -0.1147992607191884, 0.0, 1.0, 65.0, 56.39232292008685], 
processed observation next is [0.0, 0.17391304347826086, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.40977804546298674, 0.4617335797602706, 0.0, 1.0, 1.0, 0.5639232292008685], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.21215396], dtype=float32), -0.33942375]. 
=============================================
[2019-04-17 15:26:27,287] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4437799e-11 3.8417243e-15 5.9784108e-01 5.5299685e-09 1.1470946e-08
 1.1578136e-10 2.4974918e-09 1.2042171e-06 4.5562892e-08 5.6018172e-09
 4.0215775e-01], sum to 1.0000
[2019-04-17 15:26:27,287] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1098
[2019-04-17 15:26:27,318] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 19.0, 22.40782738216412, -0.2461104390472924, 0.0, 1.0, 25.0, 42.042521580411204], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 14400.0000, 
sim time next is 15600.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 19.0, 22.46091810494919, -0.245783127866456, 0.0, 1.0, 25.0, 37.31388259590777], 
processed observation next is [0.0, 0.17391304347826086, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.3717431754124325, 0.41807229071118135, 0.0, 1.0, 0.2, 0.3731388259590777], 
reward next is 0.4269, 
noisyNet noise sample is [array([1.1727144], dtype=float32), 0.8838407]. 
=============================================
[2019-04-17 15:26:33,195] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.7767902e-13 2.0863036e-18 9.4211721e-01 8.6498947e-11 1.9478987e-09
 9.7970449e-13 5.5592426e-11 4.9949186e-08 2.8537400e-10 1.2333790e-10
 5.7882819e-02], sum to 1.0000
[2019-04-17 15:26:33,195] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8841
[2019-04-17 15:26:33,366] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.4, 62.0, 37.0, 0.0, 22.5, 23.42861525225948, -0.07167681698114993, 1.0, 1.0, 65.0, 101.0438656475113], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 230400.0000, 
sim time next is 231600.0000, 
raw observation next is [-3.4, 63.0, 24.33333333333333, 0.0, 22.5, 24.13440856579147, -0.01285732757753427, 1.0, 1.0, 25.0, 54.84941955178331], 
processed observation next is [1.0, 0.6956521739130435, 0.368421052631579, 0.63, 0.08111111111111109, 0.0, 0.375, 0.5112007138159559, 0.4957142241408219, 1.0, 1.0, 0.2, 0.5484941955178332], 
reward next is 0.2515, 
noisyNet noise sample is [array([0.880565], dtype=float32), 2.0850995]. 
=============================================
[2019-04-17 15:26:34,419] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1565013e-13 7.4756739e-17 7.5411540e-01 2.1766944e-10 2.4616782e-09
 4.4016626e-12 3.3804157e-10 9.1011252e-08 4.9389504e-10 8.3731222e-10
 2.4588446e-01], sum to 1.0000
[2019-04-17 15:26:34,419] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6674
[2019-04-17 15:26:34,459] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-7.3, 64.33333333333333, 0.0, 0.0, 22.5, 24.04796836622011, 0.08361078010444112, 1.0, 1.0, 25.0, 16.31912222351429], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 150000.0000, 
sim time next is 151200.0000, 
raw observation next is [-7.3, 61.0, 0.0, 0.0, 22.5, 23.83604399073749, 0.05230958548805401, 1.0, 1.0, 25.0, 14.76035764656024], 
processed observation next is [1.0, 0.782608695652174, 0.26038781163434904, 0.61, 0.0, 0.0, 0.375, 0.4863369992281242, 0.517436528496018, 1.0, 1.0, 0.2, 0.1476035764656024], 
reward next is 0.6524, 
noisyNet noise sample is [array([1.048381], dtype=float32), -0.22490188]. 
=============================================
[2019-04-17 15:26:36,779] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0545035e-11 4.3017656e-16 6.8248707e-01 1.1430464e-08 1.7386709e-08
 1.2157933e-10 1.9580300e-09 1.9247996e-06 3.6012530e-08 1.1791011e-08
 3.1751099e-01], sum to 1.0000
[2019-04-17 15:26:36,779] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4624
[2019-04-17 15:26:36,799] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-12.3, 67.0, 0.0, 0.0, 19.0, 22.99441786037496, -0.2416061889411894, 0.0, 1.0, 25.0, 46.471650165875495], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 284400.0000, 
sim time next is 285600.0000, 
raw observation next is [-12.46666666666667, 68.0, 0.0, 0.0, 22.5, 22.68295663593628, -0.2912147510239047, 1.0, 1.0, 25.0, 41.783285926426835], 
processed observation next is [1.0, 0.30434782608695654, 0.11726685133887339, 0.68, 0.0, 0.0, 0.375, 0.3902463863280232, 0.4029284163253651, 1.0, 1.0, 0.2, 0.41783285926426833], 
reward next is 0.3822, 
noisyNet noise sample is [array([0.30634928], dtype=float32), -0.96647704]. 
=============================================
[2019-04-17 15:26:38,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.3766444e-13 1.1025161e-17 8.1902438e-01 3.1576419e-10 3.9993249e-09
 2.1169928e-12 1.2286071e-09 2.6885920e-07 5.4005767e-10 4.3536288e-10
 1.8097532e-01], sum to 1.0000
[2019-04-17 15:26:38,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0397
[2019-04-17 15:26:38,248] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-10.23333333333333, 47.33333333333334, 86.83333333333334, 741.3333333333334, 22.5, 24.34123793118763, 0.09090486054305628, 1.0, 1.0, 65.0, 81.91772393824601], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 303600.0000, 
sim time next is 304800.0000, 
raw observation next is [-9.866666666666667, 45.66666666666667, 85.0, 736.8333333333334, 22.5, 24.55784462627748, 0.0005028247422678989, 1.0, 1.0, 25.0, 57.96529859108883], 
processed observation next is [1.0, 0.5217391304347826, 0.18928901200369344, 0.4566666666666667, 0.2833333333333333, 0.8141804788213628, 0.375, 0.5464870521897899, 0.5001676082474226, 1.0, 1.0, 0.2, 0.5796529859108883], 
reward next is 0.2203, 
noisyNet noise sample is [array([-0.098065], dtype=float32), 0.68919647]. 
=============================================
[2019-04-17 15:26:42,767] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.92784443e-11 1.02314423e-15 4.75154638e-01 6.31139541e-09
 8.28841920e-08 7.88190416e-11 2.73525513e-09 9.14126929e-07
 1.42672905e-08 8.56525340e-09 5.24844408e-01], sum to 1.0000
[2019-04-17 15:26:42,767] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2757
[2019-04-17 15:26:42,833] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-14.83333333333333, 69.0, 0.0, 0.0, 19.0, 22.19023794678008, -0.3508417857064302, 0.0, 1.0, 65.0, 67.82581095055723], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 351600.0000, 
sim time next is 352800.0000, 
raw observation next is [-15.0, 69.0, 0.0, 0.0, 19.0, 22.41489939000783, -0.3438126433023356, 0.0, 1.0, 25.0, 49.76188061561089], 
processed observation next is [1.0, 0.08695652173913043, 0.04709141274238226, 0.69, 0.0, 0.0, 0.08333333333333333, 0.3679082825006524, 0.3853957855658881, 0.0, 1.0, 0.2, 0.49761880615610893], 
reward next is 0.3024, 
noisyNet noise sample is [array([-1.7621351], dtype=float32), -0.18356915]. 
=============================================
[2019-04-17 15:26:51,074] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.1406267e-11 5.6570480e-15 8.2711774e-01 5.5251865e-09 1.6898092e-08
 8.7103047e-11 5.9435892e-09 5.9073727e-07 4.2406835e-08 5.9991239e-09
 1.7288160e-01], sum to 1.0000
[2019-04-17 15:26:51,075] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2457
[2019-04-17 15:26:51,106] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.566666666666667, 69.66666666666667, 0.0, 0.0, 19.0, 24.45126870585039, 0.1771653087816905, 0.0, 1.0, 25.0, 25.94794058534443], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 685200.0000, 
sim time next is 686400.0000, 
raw observation next is [-3.733333333333333, 70.33333333333333, 0.0, 0.0, 19.0, 24.30813799974154, 0.1498389995523062, 0.0, 1.0, 25.0, 23.521441466721715], 
processed observation next is [0.0, 0.9565217391304348, 0.35918744228993543, 0.7033333333333333, 0.0, 0.0, 0.08333333333333333, 0.5256781666451283, 0.549946333184102, 0.0, 1.0, 0.2, 0.23521441466721715], 
reward next is 0.5648, 
noisyNet noise sample is [array([-1.029046], dtype=float32), -0.7846575]. 
=============================================
[2019-04-17 15:26:52,148] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4532034e-11 1.9681787e-15 5.2535516e-01 5.8473373e-09 1.6916411e-08
 1.6899078e-10 3.6546088e-09 1.0359747e-06 3.4567645e-08 1.0497911e-08
 4.7464374e-01], sum to 1.0000
[2019-04-17 15:26:52,148] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6256
[2019-04-17 15:26:52,340] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [0.3666666666666667, 36.0, 62.33333333333334, 0.0, 22.5, 25.22726551252759, 0.1771620558171002, 1.0, 1.0, 25.0, 48.90699156264351], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 487200.0000, 
sim time next is 488400.0000, 
raw observation next is [0.7333333333333334, 35.0, 50.00000000000001, 0.0, 22.5, 25.15011994003614, 0.2241062088690189, 1.0, 1.0, 65.0, 84.39619300478947], 
processed observation next is [1.0, 0.6521739130434783, 0.4829178208679595, 0.35, 0.16666666666666669, 0.0, 0.375, 0.5958433283363451, 0.5747020696230063, 1.0, 1.0, 1.0, 0.8439619300478947], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1364086], dtype=float32), -0.9555434]. 
=============================================
[2019-04-17 15:26:53,464] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9605493e-12 5.7642763e-17 3.8608596e-01 4.7237797e-10 4.1606212e-09
 9.0158662e-12 1.5709561e-09 7.0538647e-07 5.2983831e-09 1.0526221e-09
 6.1391336e-01], sum to 1.0000
[2019-04-17 15:26:53,464] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3061
[2019-04-17 15:26:53,496] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.2, 80.0, 132.5, 531.0, 19.0, 25.37991700363836, 0.4868682818896152, 0.0, 1.0, 65.0, 54.74692200792654], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 568800.0000, 
sim time next is 570000.0000, 
raw observation next is [-1.2, 81.0, 128.8333333333333, 488.3333333333333, 19.0, 25.47327283026325, 0.4965574582372818, 0.0, 1.0, 25.0, 42.162872451654565], 
processed observation next is [0.0, 0.6086956521739131, 0.42936288088642666, 0.81, 0.4294444444444443, 0.5395948434622467, 0.08333333333333333, 0.6227727358552709, 0.6655191527457606, 0.0, 1.0, 0.2, 0.42162872451654565], 
reward next is 0.3784, 
noisyNet noise sample is [array([-0.082234], dtype=float32), 1.9174392]. 
=============================================
[2019-04-17 15:26:53,521] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[48.27142 ]
 [47.883957]
 [48.33692 ]
 [49.018734]
 [48.594868]
 [48.19038 ]
 [47.670467]
 [47.6967  ]
 [47.10785 ]
 [47.82871 ]
 [46.54206 ]
 [47.29579 ]
 [46.205296]
 [46.543648]
 [45.45382 ]
 [45.697174]
 [45.63434 ]
 [45.38785 ]
 [45.63493 ]
 [44.828117]
 [45.964527]
 [46.12276 ]
 [46.984306]
 [46.77724 ]
 [47.468422]], R is [[47.57759094]
 [47.10181427]
 [47.0489006 ]
 [46.94223404]
 [46.47281265]
 [46.00808334]
 [45.54800415]
 [45.09252548]
 [44.64160156]
 [44.19518661]
 [43.75323486]
 [43.6757164 ]
 [43.23896027]
 [42.80657196]
 [42.37850571]
 [42.32494354]
 [41.90169525]
 [41.84317017]
 [41.42473984]
 [41.01049423]
 [41.05694199]
 [41.06578445]
 [41.00970078]
 [40.59960556]
 [40.55666733]].
[2019-04-17 15:26:58,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2500278e-12 3.0612204e-17 8.1055266e-01 5.2343258e-10 1.6346181e-08
 1.1148407e-11 8.2683199e-10 2.5349098e-07 5.1639120e-09 5.5485261e-10
 1.8944708e-01], sum to 1.0000
[2019-04-17 15:26:58,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4012
[2019-04-17 15:26:58,201] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.0, 58.0, 0.0, 0.0, 22.5, 25.54817753281066, 0.4890163960293409, 1.0, 1.0, 25.0, 46.22799414697677], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 763200.0000, 
sim time next is 764400.0000, 
raw observation next is [-5.2, 59.0, 0.0, 0.0, 19.0, 25.40268020292021, 0.4599785279216159, 0.0, 1.0, 25.0, 38.749892612029306], 
processed observation next is [1.0, 0.8695652173913043, 0.31855955678670367, 0.59, 0.0, 0.0, 0.08333333333333333, 0.6168900169100174, 0.653326175973872, 0.0, 1.0, 0.2, 0.3874989261202931], 
reward next is 0.4125, 
noisyNet noise sample is [array([-1.0924232], dtype=float32), 1.1927903]. 
=============================================
[2019-04-17 15:26:59,342] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1723847e-13 3.2335578e-18 4.2747369e-01 7.1417941e-11 5.1190590e-09
 2.5884210e-12 2.9411129e-10 1.3311090e-07 2.0459301e-09 4.9808740e-10
 5.7252622e-01], sum to 1.0000
[2019-04-17 15:26:59,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9658
[2019-04-17 15:26:59,377] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-3.9, 84.66666666666667, 0.0, 0.0, 22.5, 26.08134276596284, 0.6088431584117395, 1.0, 1.0, 25.0, 43.18842438910846], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 840000.0000, 
sim time next is 841200.0000, 
raw observation next is [-3.899999999999999, 83.33333333333334, 0.0, 0.0, 22.5, 26.05428183475897, 0.6121596019269916, 1.0, 1.0, 65.0, 54.275965226521365], 
processed observation next is [1.0, 0.7391304347826086, 0.35457063711911363, 0.8333333333333335, 0.0, 0.0, 0.375, 0.6711901528965809, 0.7040532006423305, 1.0, 1.0, 1.0, 0.5427596522652136], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.42845774], dtype=float32), -1.3260962]. 
=============================================
[2019-04-17 15:27:00,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.8737585e-12 1.9108811e-16 2.9012626e-01 1.2491626e-09 3.7147732e-08
 3.0844709e-11 2.3434892e-09 8.5564955e-07 5.0855737e-09 4.0042796e-09
 7.0987284e-01], sum to 1.0000
[2019-04-17 15:27:00,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6031
[2019-04-17 15:27:00,389] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-6.7, 67.0, 0.0, 0.0, 19.0, 25.01466593056409, 0.3274917603665989, 0.0, 1.0, 25.0, 44.19899316623629], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 802800.0000, 
sim time next is 804000.0000, 
raw observation next is [-6.700000000000001, 69.66666666666667, 0.0, 0.0, 22.5, 24.96264936089988, 0.3227210924872762, 1.0, 1.0, 65.0, 55.699357548905795], 
processed observation next is [1.0, 0.30434782608695654, 0.2770083102493075, 0.6966666666666668, 0.0, 0.0, 0.375, 0.5802207800749901, 0.6075736974957587, 1.0, 1.0, 1.0, 0.5569935754890579], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.46590978], dtype=float32), -0.25773105]. 
=============================================
[2019-04-17 15:27:00,915] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1347538e-10 7.6454981e-15 4.5453712e-01 2.8655688e-08 1.2765939e-07
 2.4088728e-10 1.5813798e-08 2.9530377e-06 8.2934427e-08 2.9634929e-08
 5.4545963e-01], sum to 1.0000
[2019-04-17 15:27:00,917] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0432
[2019-04-17 15:27:00,949] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-7.466666666666667, 71.0, 0.0, 0.0, 19.0, 23.85799619757283, 0.1372956880935953, 0.0, 1.0, 25.0, 43.35460608287629], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 782400.0000, 
sim time next is 783600.0000, 
raw observation next is [-7.633333333333333, 71.0, 0.0, 0.0, 19.0, 24.01152674472487, 0.1272988927094727, 0.0, 1.0, 25.0, 34.109118948237764], 
processed observation next is [1.0, 0.043478260869565216, 0.2511542012927055, 0.71, 0.0, 0.0, 0.08333333333333333, 0.5009605620604057, 0.5424329642364909, 0.0, 1.0, 0.2, 0.34109118948237765], 
reward next is 0.4589, 
noisyNet noise sample is [array([0.78381866], dtype=float32), -0.6637281]. 
=============================================
[2019-04-17 15:27:03,527] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.6555979e-14 2.7894789e-19 6.3284713e-01 1.9055570e-11 1.8389237e-09
 8.5636592e-13 3.5727834e-11 7.9960792e-08 3.3125780e-10 9.5600056e-11
 3.6715278e-01], sum to 1.0000
[2019-04-17 15:27:03,527] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6911
[2019-04-17 15:27:03,542] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [11.6, 86.0, 108.0, 0.0, 22.5, 27.55507381874095, 0.9939561216313547, 1.0, 1.0, 25.0, 23.708398554443075], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 990000.0000, 
sim time next is 991200.0000, 
raw observation next is [11.8, 86.0, 116.0, 0.0, 22.5, 27.54935565281096, 1.005498965964748, 1.0, 1.0, 65.0, 28.26948980812439], 
processed observation next is [1.0, 0.4782608695652174, 0.7894736842105264, 0.86, 0.38666666666666666, 0.0, 0.375, 0.7957796377342466, 0.8351663219882494, 1.0, 1.0, 1.0, 0.28269489808124393], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3660017], dtype=float32), 0.09460989]. 
=============================================
[2019-04-17 15:27:04,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5128279e-13 5.7481273e-18 7.6137906e-01 2.3245680e-10 3.4016823e-09
 8.0856155e-12 1.9624020e-10 1.2818688e-07 9.2240560e-10 1.8131986e-10
 2.3862085e-01], sum to 1.0000
[2019-04-17 15:27:04,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7979
[2019-04-17 15:27:04,232] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [5.0, 100.0, 0.0, 0.0, 19.0, 25.91284844528643, 0.6465380348423396, 0.0, 1.0, 25.0, 32.93156809922166], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 939600.0000, 
sim time next is 940800.0000, 
raw observation next is [5.0, 98.66666666666667, 0.0, 0.0, 19.0, 25.86085692588279, 0.6598040163590387, 0.0, 1.0, 65.0, 52.94048158190249], 
processed observation next is [1.0, 0.9130434782608695, 0.6011080332409973, 0.9866666666666667, 0.0, 0.0, 0.08333333333333333, 0.6550714104902324, 0.7199346721196797, 0.0, 1.0, 1.0, 0.5294048158190249], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.30669245], dtype=float32), 1.0757778]. 
=============================================
[2019-04-17 15:27:05,877] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4153541e-12 5.5623860e-18 9.0694201e-01 3.0177066e-10 2.7497200e-09
 4.3780383e-12 6.8695488e-10 6.8589770e-08 8.4143714e-10 4.3080142e-10
 9.3057834e-02], sum to 1.0000
[2019-04-17 15:27:05,882] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3265
[2019-04-17 15:27:05,897] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [10.16666666666667, 92.33333333333334, 54.5, 0.0, 22.5, 26.79534663379673, 0.8217419207115061, 1.0, 1.0, 25.0, 24.090909004013845], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 984000.0000, 
sim time next is 985200.0000, 
raw observation next is [10.33333333333333, 92.66666666666667, 66.0, 0.0, 22.5, 26.94150468389171, 0.8335748162720981, 1.0, 1.0, 25.0, 20.94058072263315], 
processed observation next is [1.0, 0.391304347826087, 0.7488457987072946, 0.9266666666666667, 0.22, 0.0, 0.375, 0.7451253903243092, 0.7778582720906994, 1.0, 1.0, 0.2, 0.2094058072263315], 
reward next is 0.5906, 
noisyNet noise sample is [array([0.3724444], dtype=float32), 0.2276982]. 
=============================================
[2019-04-17 15:27:07,008] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-17 15:27:07,009] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-17 15:27:07,010] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:27:07,010] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation job starts!
[2019-04-17 15:27:07,011] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:27:07,012] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation job starts!
[2019-04-17 15:27:07,014] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:27:07,016] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v1-res1/Eplus-env-sub_run4
[2019-04-17 15:27:07,032] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v2-res1/Eplus-env-sub_run4
[2019-04-17 15:27:07,045] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res1/Eplus-env-sub_run4
[2019-04-17 15:28:01,149] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation: average rewards by now are 1649.0799 140785.4746 1139.3406
[2019-04-17 15:28:01,169] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:28:01,169] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:28:01,169] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:28:01,169] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:28:01,280] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:28:01,280] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:28:01,280] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:28:01,280] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:28:01,289] A3C_EVAL-Part4-Heavy-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.13323961], dtype=float32), 0.13944925]
[2019-04-17 15:28:01,290] A3C_EVAL-Part4-Heavy-Pit-Test-v2 DEBUG:Observation this: [-2.149589473, 33.59967242, 0.0, 0.0, 19.0, 26.48329640844514, 0.7219201895710671, 0.0, 1.0, 25.0, 34.30645834039328]
[2019-04-17 15:28:01,290] A3C_EVAL-Part4-Heavy-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-04-17 15:28:01,292] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Softmax [1.4226311e-09 2.9030914e-13 8.3460289e-01 6.8459180e-08 6.3394305e-07
 2.3338569e-09 8.0917353e-08 9.8441342e-06 2.7038124e-07 8.6167127e-08
 1.6538610e-01], sampled 0.07851498460996453
[2019-04-17 15:28:13,971] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation: average rewards by now are 1634.5029 148710.5834 805.4515
[2019-04-17 15:28:14,006] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:28:14,006] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:28:14,006] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:28:14,006] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:28:14,199] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:28:14,199] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:28:14,199] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:28:14,199] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:28:17,349] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation: average rewards by now are 1611.2951 153184.2261 691.8994
[2019-04-17 15:28:17,386] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:28:17,386] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:28:17,386] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:28:17,386] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:28:17,565] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:28:17,565] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:28:17,565] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:28:17,565] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:28:18,386] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 150000, evaluation results [150000.0, 1634.502945604481, 148710.5834393624, 805.4514785684565, 1649.079883436474, 140785.47461896518, 1139.340551975967, 1611.295065158632, 153184.2261445446, 691.8994021359049]
[2019-04-17 15:28:20,226] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.3900220e-12 4.8029309e-17 6.0061008e-01 9.5198094e-10 1.7448176e-08
 1.4826593e-11 8.0881463e-10 1.1744769e-06 1.3295131e-08 2.0328168e-09
 3.9938882e-01], sum to 1.0000
[2019-04-17 15:28:20,226] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6668
[2019-04-17 15:28:20,275] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [0.7000000000000001, 92.0, 22.5, 0.0, 22.5, 27.00516875022445, 0.9377308538235329, 1.0, 1.0, 25.0, 15.142086355438405], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 1327200.0000, 
sim time next is 1328400.0000, 
raw observation next is [0.5, 92.0, 31.5, 0.0, 22.5, 27.17295689026674, 0.9906972236695256, 1.0, 1.0, 65.0, 64.34911953186065], 
processed observation next is [1.0, 0.391304347826087, 0.4764542936288089, 0.92, 0.105, 0.0, 0.375, 0.7644130741888949, 0.8302324078898419, 1.0, 1.0, 1.0, 0.6434911953186065], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7192857], dtype=float32), -0.71123415]. 
=============================================
[2019-04-17 15:28:26,728] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4309979e-09 5.0376387e-12 6.5525603e-01 3.3360064e-07 2.0503744e-06
 2.8966772e-08 4.9054597e-07 3.6521196e-05 3.3441083e-06 4.4438767e-07
 3.4470081e-01], sum to 1.0000
[2019-04-17 15:28:26,729] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5989
[2019-04-17 15:28:26,795] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.46666666666667, 64.33333333333333, 169.0, 0.0, 19.0, 27.87933361274414, 1.162904513785846, 0.0, 0.0, 25.0, 19.684928615432465], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1168800.0000, 
sim time next is 1170000.0000, 
raw observation next is [18.3, 65.0, 165.0, 0.0, 19.0, 27.87831283297609, 1.167740656165709, 0.0, 0.0, 25.0, 20.203733821203915], 
processed observation next is [0.0, 0.5652173913043478, 0.9695290858725764, 0.65, 0.55, 0.0, 0.08333333333333333, 0.8231927360813408, 0.8892468853885697, 0.0, 0.0, 0.2, 0.20203733821203915], 
reward next is 0.5980, 
noisyNet noise sample is [array([-0.07003468], dtype=float32), -0.2429541]. 
=============================================
[2019-04-17 15:28:26,805] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[32.084064]
 [32.03006 ]
 [32.80957 ]
 [34.066166]
 [34.674633]
 [35.85303 ]
 [37.15641 ]
 [37.83251 ]
 [38.678547]
 [39.568237]
 [40.594997]
 [41.519184]
 [41.143   ]
 [41.349846]
 [40.787792]
 [40.48716 ]
 [40.079327]
 [39.750656]
 [40.01318 ]
 [39.60381 ]
 [39.877476]
 [39.4886  ]
 [39.591476]
 [38.829277]
 [39.36459 ]], R is [[32.14351273]
 [32.42522812]
 [32.70291901]
 [32.37588882]
 [32.63445282]
 [32.89427567]
 [33.15208435]
 [33.40278244]
 [33.0687561 ]
 [33.31027603]
 [33.53731537]
 [33.76005173]
 [33.96773529]
 [33.62805939]
 [33.82269287]
 [34.02109909]
 [33.68088913]
 [33.90572739]
 [34.09503937]
 [34.27387619]
 [34.4458046 ]
 [34.61185837]
 [34.7808876 ]
 [34.43307877]
 [34.72049713]].
[2019-04-17 15:28:32,658] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1374460e-12 5.9808202e-17 9.7235495e-01 1.3502067e-09 1.4408786e-08
 9.5835067e-12 4.0981527e-10 3.7278414e-07 3.3712946e-09 1.7484976e-09
 2.7644711e-02], sum to 1.0000
[2019-04-17 15:28:32,658] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0932
[2019-04-17 15:28:32,710] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 25.56926491553119, 0.6158904945986453, 0.0, 1.0, 25.0, 20.524978984364516], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1387200.0000, 
sim time next is 1388400.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 19.0, 25.43132493674054, 0.5831874388412402, 0.0, 1.0, 25.0, 18.910630742198045], 
processed observation next is [1.0, 0.043478260869565216, 0.46260387811634357, 0.95, 0.0, 0.0, 0.08333333333333333, 0.6192770780617117, 0.6943958129470801, 0.0, 1.0, 0.2, 0.18910630742198045], 
reward next is 0.6109, 
noisyNet noise sample is [array([0.6663721], dtype=float32), 0.6239248]. 
=============================================
[2019-04-17 15:28:34,419] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.7667772e-13 8.1711316e-17 9.8299867e-01 6.5988942e-10 7.7835178e-09
 5.0287461e-12 3.8987683e-10 3.4758597e-07 7.6716775e-09 1.8377644e-09
 1.7000930e-02], sum to 1.0000
[2019-04-17 15:28:34,419] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9750
[2019-04-17 15:28:34,521] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 25.16430267461139, 0.5191364683923618, 0.0, 1.0, 25.0, 10.11258880489802], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1380000.0000, 
sim time next is 1381200.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 19.0, 25.07672777348197, 0.4975653665800816, 0.0, 1.0, 25.0, 10.150924096520828], 
processed observation next is [1.0, 1.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.08333333333333333, 0.5897273144568308, 0.6658551221933605, 0.0, 1.0, 0.2, 0.10150924096520829], 
reward next is 0.6985, 
noisyNet noise sample is [array([-0.89138263], dtype=float32), -0.6645944]. 
=============================================
[2019-04-17 15:28:34,539] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.6712363e-12 3.0592289e-17 9.7484326e-01 5.9264482e-10 3.6884746e-09
 3.7693754e-12 4.0190862e-10 1.6662129e-07 1.5007612e-09 1.5374031e-09
 2.5156585e-02], sum to 1.0000
[2019-04-17 15:28:34,539] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5077
[2019-04-17 15:28:34,562] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 22.5, 25.798586936585, 0.6497816094582041, 1.0, 1.0, 25.0, 10.19509190292326], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1358400.0000, 
sim time next is 1359600.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 22.5, 25.55743753015698, 0.6599625091555986, 1.0, 1.0, 25.0, 10.31437339516437], 
processed observation next is [1.0, 0.7391304347826086, 0.4764542936288089, 0.96, 0.0, 0.0, 0.375, 0.6297864608464151, 0.7199875030518662, 1.0, 1.0, 0.2, 0.10314373395164371], 
reward next is 0.6969, 
noisyNet noise sample is [array([-1.5599344], dtype=float32), 0.006977709]. 
=============================================
[2019-04-17 15:28:38,400] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.3227826e-12 3.5005474e-16 9.2525613e-01 1.7737436e-09 2.2651818e-08
 6.4994114e-11 1.4374408e-09 9.2577932e-07 4.2373425e-09 5.5472773e-09
 7.4742995e-02], sum to 1.0000
[2019-04-17 15:28:38,400] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4372
[2019-04-17 15:28:38,502] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 95.0, 91.0, 0.0, 22.5, 24.74655648132858, 0.3100703109920098, 1.0, 1.0, 25.0, 27.58997634837175], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1424400.0000, 
sim time next is 1425600.0000, 
raw observation next is [0.0, 95.0, 93.0, 0.0, 22.5, 24.75619117481489, 0.315775810106141, 1.0, 1.0, 25.0, 24.460864881094725], 
processed observation next is [1.0, 0.5217391304347826, 0.46260387811634357, 0.95, 0.31, 0.0, 0.375, 0.5630159312345743, 0.6052586033687136, 1.0, 1.0, 0.2, 0.24460864881094724], 
reward next is 0.5554, 
noisyNet noise sample is [array([-0.95413864], dtype=float32), 0.25364357]. 
=============================================
[2019-04-17 15:28:39,961] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2471302e-12 1.8268702e-17 9.6041614e-01 3.3228692e-10 1.6996486e-08
 5.9808681e-12 6.5375322e-10 1.2416201e-07 1.0330141e-09 1.3811160e-09
 3.9583724e-02], sum to 1.0000
[2019-04-17 15:28:39,961] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7815
[2019-04-17 15:28:40,079] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 95.0, 67.66666666666667, 0.0, 22.5, 25.50813678450256, 0.4675942864482266, 1.0, 1.0, 25.0, 34.6934705540676], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1419600.0000, 
sim time next is 1420800.0000, 
raw observation next is [0.0, 95.0, 75.0, 0.0, 22.5, 25.44272583478225, 0.4669190544358639, 1.0, 1.0, 25.0, 30.59842535108599], 
processed observation next is [1.0, 0.43478260869565216, 0.46260387811634357, 0.95, 0.25, 0.0, 0.375, 0.6202271528985209, 0.6556396848119547, 1.0, 1.0, 0.2, 0.3059842535108599], 
reward next is 0.4940, 
noisyNet noise sample is [array([0.71405315], dtype=float32), 0.13399166]. 
=============================================
[2019-04-17 15:28:50,936] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1427231e-12 4.5193935e-16 9.1436464e-01 1.2609332e-09 2.2027073e-08
 1.9882736e-11 1.8525947e-09 4.9383732e-07 1.5693713e-08 2.2496751e-09
 8.5634753e-02], sum to 1.0000
[2019-04-17 15:28:50,936] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9938
[2019-04-17 15:28:50,954] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [6.966666666666667, 75.33333333333333, 0.0, 0.0, 19.0, 23.37145515235435, 0.0819621244001034, 0.0, 1.0, 25.0, 7.397466910412071], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 1546800.0000, 
sim time next is 1548000.0000, 
raw observation next is [6.6, 76.0, 0.0, 0.0, 19.0, 23.34407526689851, 0.1309984159049092, 0.0, 1.0, 65.0, 86.49371019452329], 
processed observation next is [1.0, 0.9565217391304348, 0.6454293628808865, 0.76, 0.0, 0.0, 0.08333333333333333, 0.4453396055748759, 0.5436661386349697, 0.0, 1.0, 1.0, 0.8649371019452329], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11096166], dtype=float32), 0.49200752]. 
=============================================
[2019-04-17 15:28:57,057] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9193692e-11 9.2641967e-15 9.2664546e-01 1.7731987e-08 4.8543846e-08
 2.9905711e-10 5.6019474e-09 1.1621439e-06 3.9694765e-08 1.2784180e-08
 7.3353298e-02], sum to 1.0000
[2019-04-17 15:28:57,057] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7042
[2019-04-17 15:28:57,160] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.2, 87.0, 59.66666666666666, 0.0, 19.0, 23.43333588266585, 0.05170874520006336, 0.0, 1.0, 25.0, 16.185216205780236], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1784400.0000, 
sim time next is 1785600.0000, 
raw observation next is [-3.4, 87.0, 47.0, 0.0, 19.0, 23.30877878349727, 0.02176553898183525, 0.0, 1.0, 25.0, 15.353260442524096], 
processed observation next is [0.0, 0.6956521739130435, 0.368421052631579, 0.87, 0.15666666666666668, 0.0, 0.08333333333333333, 0.4423982319581059, 0.5072551796606117, 0.0, 1.0, 0.2, 0.15353260442524097], 
reward next is 0.6465, 
noisyNet noise sample is [array([-0.2699809], dtype=float32), 0.17531498]. 
=============================================
[2019-04-17 15:29:00,434] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4018108e-10 1.4638074e-13 9.4927740e-01 2.5517220e-08 5.9503385e-08
 5.9189553e-10 1.6017868e-08 1.3231282e-06 1.7379217e-07 3.4850508e-08
 5.0720837e-02], sum to 1.0000
[2019-04-17 15:29:00,434] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3025
[2019-04-17 15:29:00,563] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 19.0, 22.46441747368942, -0.1992696411309022, 0.0, 1.0, 25.0, 14.110137821879771], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1790400.0000, 
sim time next is 1791600.0000, 
raw observation next is [-3.899999999999999, 82.0, 0.0, 0.0, 19.0, 22.38533085225788, -0.2196366362279305, 0.0, 1.0, 25.0, 14.367916588331944], 
processed observation next is [0.0, 0.7391304347826086, 0.35457063711911363, 0.82, 0.0, 0.0, 0.08333333333333333, 0.36544423768815665, 0.42678778792402317, 0.0, 1.0, 0.2, 0.14367916588331944], 
reward next is 0.6563, 
noisyNet noise sample is [array([-0.24741006], dtype=float32), 0.027452165]. 
=============================================
[2019-04-17 15:29:13,908] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.29687750e-12 1.40630170e-15 8.79044592e-01 3.06563752e-09
 2.75435497e-08 4.53790130e-11 3.06578962e-09 9.51163656e-07
 1.69179959e-08 3.49265750e-09 1.20954484e-01], sum to 1.0000
[2019-04-17 15:29:13,908] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9090
[2019-04-17 15:29:14,078] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 19.0, 21.05352616425028, -0.6333003210296616, 0.0, 1.0, 25.0, 19.863861403445625], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2012400.0000, 
sim time next is 2013600.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 22.5, 21.16241061221867, -0.5301006013578259, 1.0, 1.0, 65.0, 103.40754736020493], 
processed observation next is [1.0, 0.30434782608695654, 0.2908587257617729, 0.87, 0.0, 0.0, 0.375, 0.2635342176848893, 0.32329979954739135, 1.0, 1.0, 1.0, 1.0340754736020492], 
reward next is 0.1505, 
noisyNet noise sample is [array([0.22836144], dtype=float32), -1.2051247]. 
=============================================
[2019-04-17 15:29:17,290] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3460804e-12 4.1242034e-17 9.2778522e-01 1.1767104e-09 5.2914033e-09
 8.0250719e-12 8.5804730e-10 1.2862748e-07 4.2340793e-09 2.0474085e-09
 7.2214685e-02], sum to 1.0000
[2019-04-17 15:29:17,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3914
[2019-04-17 15:29:17,434] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.8, 62.0, 80.33333333333334, 0.0, 22.5, 23.9928342592429, -0.04820620403969201, 1.0, 1.0, 25.0, 24.391996575578244], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1956000.0000, 
sim time next is 1957200.0000, 
raw observation next is [-2.8, 62.0, 66.66666666666667, 0.0, 22.5, 23.88856252479648, -0.1649039768900381, 1.0, 1.0, 25.0, 23.489618433956927], 
processed observation next is [1.0, 0.6521739130434783, 0.38504155124653744, 0.62, 0.22222222222222224, 0.0, 0.375, 0.49071354373304005, 0.4450320077033207, 1.0, 1.0, 0.2, 0.23489618433956927], 
reward next is 0.5651, 
noisyNet noise sample is [array([-1.225433], dtype=float32), -0.83571994]. 
=============================================
[2019-04-17 15:29:30,268] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6879673e-13 7.5811724e-18 6.0861444e-01 6.6062661e-10 3.0592775e-09
 3.6134676e-12 5.6078625e-10 4.5505837e-07 3.6653049e-09 5.7640875e-10
 3.9138508e-01], sum to 1.0000
[2019-04-17 15:29:30,268] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1062
[2019-04-17 15:29:30,331] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-6.700000000000001, 81.33333333333334, 0.0, 0.0, 19.0, 24.80495594006048, 0.2239711204929293, 0.0, 1.0, 65.0, 60.59263873240319], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2096400.0000, 
sim time next is 2097600.0000, 
raw observation next is [-6.700000000000001, 79.66666666666667, 0.0, 0.0, 19.0, 24.78890193426489, 0.2151503153335683, 0.0, 1.0, 25.0, 46.83598294991281], 
processed observation next is [1.0, 0.2608695652173913, 0.2770083102493075, 0.7966666666666667, 0.0, 0.0, 0.08333333333333333, 0.5657418278554074, 0.5717167717778561, 0.0, 1.0, 0.2, 0.46835982949912813], 
reward next is 0.3316, 
noisyNet noise sample is [array([-0.2965378], dtype=float32), 0.81521654]. 
=============================================
[2019-04-17 15:29:33,125] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.6348233e-12 1.4366352e-16 7.9817903e-01 1.2632901e-09 8.9625507e-09
 2.0611270e-11 4.3824916e-10 4.8676299e-07 6.3474896e-09 1.2246774e-09
 2.0182049e-01], sum to 1.0000
[2019-04-17 15:29:33,126] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9416
[2019-04-17 15:29:33,228] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-4.5, 70.0, 8.333333333333332, 0.0, 22.5, 23.6054333950067, -0.1311641747987894, 1.0, 1.0, 25.0, 50.24804036877741], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2222400.0000, 
sim time next is 2223600.0000, 
raw observation next is [-4.5, 69.0, 0.0, 0.0, 22.5, 22.73363640113654, -0.1103336367978398, 1.0, 1.0, 65.0, 67.48372337098431], 
processed observation next is [1.0, 0.7391304347826086, 0.3379501385041552, 0.69, 0.0, 0.0, 0.375, 0.39446970009471166, 0.46322212106738675, 1.0, 1.0, 1.0, 0.674837233709843], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.40415558], dtype=float32), -1.3790797]. 
=============================================
[2019-04-17 15:29:36,408] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.6879566e-12 1.6706891e-17 7.8820664e-01 7.9407292e-10 5.2585549e-09
 7.2891502e-12 7.4606488e-10 3.4600725e-07 7.3338429e-09 1.0420108e-09
 2.1179304e-01], sum to 1.0000
[2019-04-17 15:29:36,408] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5052
[2019-04-17 15:29:36,507] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.9, 68.0, 138.5, 142.5, 22.5, 25.10691038135064, 0.259148007117627, 1.0, 1.0, 65.0, 60.26396970914684], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2214000.0000, 
sim time next is 2215200.0000, 
raw observation next is [-3.9, 68.0, 150.8333333333333, 237.5, 22.5, 24.89680357216363, 0.3285071000854936, 1.0, 1.0, 25.0, 49.21076622949121], 
processed observation next is [1.0, 0.6521739130434783, 0.3545706371191136, 0.68, 0.5027777777777777, 0.26243093922651933, 0.375, 0.5747336310136358, 0.6095023666951646, 1.0, 1.0, 0.2, 0.49210766229491215], 
reward next is 0.3079, 
noisyNet noise sample is [array([0.6380225], dtype=float32), -0.4370892]. 
=============================================
[2019-04-17 15:29:41,708] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.4397437e-12 3.6342830e-16 8.0075902e-01 5.3175540e-09 3.9062677e-08
 2.5089738e-11 1.2209734e-09 8.3243202e-07 2.0687747e-08 2.0624424e-09
 1.9924010e-01], sum to 1.0000
[2019-04-17 15:29:41,708] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1592
[2019-04-17 15:29:41,854] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-7.833333333333334, 84.0, 91.66666666666667, 35.16666666666666, 22.5, 24.15329835042292, 0.1015032704755407, 1.0, 1.0, 25.0, 36.37952699746822], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2280000.0000, 
sim time next is 2281200.0000, 
raw observation next is [-7.266666666666667, 81.0, 113.8333333333333, 40.83333333333333, 22.5, 24.13865966411488, 0.1041654486398182, 1.0, 1.0, 25.0, 32.480360899421996], 
processed observation next is [1.0, 0.391304347826087, 0.26131117266851345, 0.81, 0.3794444444444443, 0.04511970534069981, 0.375, 0.5115549720095732, 0.5347218162132727, 1.0, 1.0, 0.2, 0.32480360899421995], 
reward next is 0.4752, 
noisyNet noise sample is [array([1.8005098], dtype=float32), -0.15641107]. 
=============================================
[2019-04-17 15:29:42,517] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8120366e-08 2.4574840e-11 7.6242203e-01 1.5720918e-06 2.4692035e-06
 5.4555873e-08 6.9796425e-07 3.2016662e-05 6.8394470e-06 1.0178765e-06
 2.3753317e-01], sum to 1.0000
[2019-04-17 15:29:42,517] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2839
[2019-04-17 15:29:42,624] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-8.4, 61.0, 0.0, 0.0, 19.0, 22.35422746561184, -0.3104599403295511, 0.0, 1.0, 25.0, 27.053895181438143], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2434800.0000, 
sim time next is 2436000.0000, 
raw observation next is [-8.4, 61.0, 0.0, 0.0, 19.0, 22.21602558388495, -0.3408072830438735, 0.0, 1.0, 25.0, 24.555297488375402], 
processed observation next is [0.0, 0.17391304347826086, 0.2299168975069252, 0.61, 0.0, 0.0, 0.08333333333333333, 0.35133546532374577, 0.3863975723187088, 0.0, 1.0, 0.2, 0.24555297488375402], 
reward next is 0.5544, 
noisyNet noise sample is [array([-0.19144014], dtype=float32), 0.7435897]. 
=============================================
[2019-04-17 15:29:44,038] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.9110393e-11 1.3606456e-15 8.6759514e-01 1.7925711e-08 4.9760651e-08
 1.3412005e-10 4.9389772e-09 1.5989916e-06 2.7880418e-08 1.5126492e-08
 1.3240321e-01], sum to 1.0000
[2019-04-17 15:29:44,038] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3986
[2019-04-17 15:29:44,267] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.6, 71.0, 0.0, 0.0, 19.0, 23.01067138045285, -0.08590023930579356, 0.0, 1.0, 25.0, 26.716672552664498], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2239200.0000, 
sim time next is 2240400.0000, 
raw observation next is [-5.8, 72.33333333333334, 0.0, 0.0, 19.0, 22.84932702365698, -0.1594031849380055, 0.0, 1.0, 25.0, 26.15430510540354], 
processed observation next is [1.0, 0.9565217391304348, 0.30193905817174516, 0.7233333333333334, 0.0, 0.0, 0.08333333333333333, 0.40411058530474825, 0.4468656050206648, 0.0, 1.0, 0.2, 0.2615430510540354], 
reward next is 0.5385, 
noisyNet noise sample is [array([-0.024205], dtype=float32), 0.50847346]. 
=============================================
[2019-04-17 15:29:52,138] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.51313290e-09 2.36280765e-12 7.83814728e-01 1.11443576e-07
 4.60797111e-07 7.85047316e-09 1.60395061e-07 1.31590186e-05
 9.43807720e-07 2.61200142e-07 2.16170132e-01], sum to 1.0000
[2019-04-17 15:29:52,139] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3081
[2019-04-17 15:29:52,381] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.733333333333333, 42.66666666666667, 0.0, 0.0, 19.0, 23.8186449371162, 0.04027286645255182, 0.0, 1.0, 25.0, 17.475426757408066], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2402400.0000, 
sim time next is 2403600.0000, 
raw observation next is [-3.066666666666666, 42.33333333333334, 0.0, 0.0, 19.0, 23.72716668051163, 0.01654171402572993, 0.0, 1.0, 25.0, 16.427452533154522], 
processed observation next is [0.0, 0.8260869565217391, 0.3776546629732226, 0.42333333333333345, 0.0, 0.0, 0.08333333333333333, 0.4772638900426358, 0.5055139046752434, 0.0, 1.0, 0.2, 0.1642745253315452], 
reward next is 0.6357, 
noisyNet noise sample is [array([0.05291984], dtype=float32), 0.4971218]. 
=============================================
[2019-04-17 15:29:54,134] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.37661435e-11 1.01666595e-14 9.32471395e-01 7.74009123e-09
 4.60304825e-08 1.65282316e-10 2.82634516e-09 5.64197592e-07
 1.44105874e-08 9.47592760e-09 6.75280392e-02], sum to 1.0000
[2019-04-17 15:29:54,134] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4644
[2019-04-17 15:29:54,152] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.166666666666667, 57.0, 0.0, 0.0, 19.0, 23.14418695791807, -0.1260370655218609, 0.0, 1.0, 25.0, 31.73557128330298], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2586000.0000, 
sim time next is 2587200.0000, 
raw observation next is [-3.533333333333333, 58.0, 0.0, 0.0, 19.0, 22.87685743543036, -0.1643881207666149, 0.0, 1.0, 25.0, 26.548707987506546], 
processed observation next is [1.0, 0.9565217391304348, 0.36472760849492153, 0.58, 0.0, 0.0, 0.08333333333333333, 0.4064047862858633, 0.4452039597444617, 0.0, 1.0, 0.2, 0.2654870798750655], 
reward next is 0.5345, 
noisyNet noise sample is [array([0.27074465], dtype=float32), 0.5548791]. 
=============================================
[2019-04-17 15:29:57,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4807453e-10 8.4279397e-15 6.4282638e-01 3.9040749e-08 4.1731980e-08
 2.4808224e-09 3.6157648e-08 2.0184348e-06 7.8349537e-08 4.9545452e-09
 3.5717142e-01], sum to 1.0000
[2019-04-17 15:29:57,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7536
[2019-04-17 15:29:57,728] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-1.7, 38.66666666666667, 0.0, 0.0, 19.0, 24.68111869695976, 0.1698556694636893, 0.0, 1.0, 25.0, 37.290479758654186], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2511600.0000, 
sim time next is 2512800.0000, 
raw observation next is [-1.7, 38.0, 0.0, 0.0, 19.0, 24.6146083428837, 0.1729204118483655, 0.0, 1.0, 65.0, 54.93825489662771], 
processed observation next is [1.0, 0.08695652173913043, 0.4155124653739613, 0.38, 0.0, 0.0, 0.08333333333333333, 0.5512173619069749, 0.5576401372827885, 0.0, 1.0, 1.0, 0.5493825489662771], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.36623153], dtype=float32), -0.5340869]. 
=============================================
[2019-04-17 15:30:03,210] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.4354824e-11 5.4553041e-16 8.4071583e-01 3.7551828e-09 2.6567420e-08
 4.5818852e-11 3.4069005e-09 5.6062999e-07 5.9445573e-09 8.8391880e-09
 1.5928358e-01], sum to 1.0000
[2019-04-17 15:30:03,220] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0919
[2019-04-17 15:30:03,319] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-6.333333333333334, 64.0, 18.0, 34.49999999999999, 22.5, 23.15904894353682, -0.1090084388515127, 1.0, 1.0, 25.0, 54.158497068019884], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2792400.0000, 
sim time next is 2793600.0000, 
raw observation next is [-6.0, 64.0, 54.0, 103.5, 22.5, 23.2322471722562, -0.09673487413242583, 1.0, 1.0, 25.0, 50.73958758236276], 
processed observation next is [1.0, 0.34782608695652173, 0.296398891966759, 0.64, 0.18, 0.1143646408839779, 0.375, 0.43602059768801676, 0.46775504195585804, 1.0, 1.0, 0.2, 0.5073958758236276], 
reward next is 0.2926, 
noisyNet noise sample is [array([0.16412956], dtype=float32), 0.73832834]. 
=============================================
[2019-04-17 15:30:08,157] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.0188485e-11 3.1651603e-15 9.5272380e-01 6.1677987e-09 7.1005729e-08
 1.4245351e-10 4.3478567e-09 5.0826662e-07 3.9475285e-08 9.1478469e-09
 4.7275536e-02], sum to 1.0000
[2019-04-17 15:30:08,157] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7650
[2019-04-17 15:30:08,169] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.2, 62.0, 0.0, 0.0, 22.5, 22.63753064739417, -0.1542821541521532, 1.0, 1.0, 25.0, 12.020488964016636], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2662800.0000, 
sim time next is 2664000.0000, 
raw observation next is [-1.2, 63.0, 0.0, 0.0, 22.5, 22.54119114606982, -0.1730585947633727, 0.0, 1.0, 25.0, 12.386436423517946], 
processed observation next is [1.0, 0.8695652173913043, 0.42936288088642666, 0.63, 0.0, 0.0, 0.375, 0.37843259550581837, 0.4423138017455424, 0.0, 1.0, 0.2, 0.12386436423517946], 
reward next is 0.6761, 
noisyNet noise sample is [array([-0.74354887], dtype=float32), 0.22888671]. 
=============================================
[2019-04-17 15:30:08,738] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.9745919e-11 1.0565539e-14 7.0237601e-01 1.8107110e-08 1.9710372e-07
 3.2962150e-10 7.1915287e-09 1.3219718e-06 1.4319293e-07 2.2851797e-08
 2.9762235e-01], sum to 1.0000
[2019-04-17 15:30:08,738] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5600
[2019-04-17 15:30:08,810] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 19.0, 21.92401102872304, -0.373083051728185, 0.0, 1.0, 65.0, 79.79457276075539], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2773200.0000, 
sim time next is 2774400.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 19.0, 22.26877971300497, -0.3243631669639707, 0.0, 1.0, 25.0, 49.49739231701968], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.59, 0.0, 0.0, 0.08333333333333333, 0.35573164275041425, 0.39187894434534315, 0.0, 1.0, 0.2, 0.49497392317019684], 
reward next is 0.3050, 
noisyNet noise sample is [array([-1.8761027], dtype=float32), -0.8394662]. 
=============================================
[2019-04-17 15:30:20,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3729329e-13 2.2493059e-17 6.2839836e-01 2.7865049e-10 4.0682475e-09
 1.6489118e-12 1.4985146e-10 1.1355834e-07 2.3988220e-09 2.3436814e-10
 3.7160143e-01], sum to 1.0000
[2019-04-17 15:30:20,411] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4425
[2019-04-17 15:30:20,493] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 95.33333333333334, 60.16666666666667, 51.83333333333333, 22.5, 24.02923664761693, 0.1034094490153707, 1.0, 1.0, 25.0, 48.93516651731167], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2911200.0000, 
sim time next is 2912400.0000, 
raw observation next is [2.0, 93.0, 38.5, 47.5, 22.5, 24.04186947917858, 0.109944145310402, 1.0, 1.0, 25.0, 41.35254295377856], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.93, 0.12833333333333333, 0.052486187845303865, 0.375, 0.5034891232648816, 0.5366480484368007, 1.0, 1.0, 0.2, 0.4135254295377856], 
reward next is 0.3865, 
noisyNet noise sample is [array([2.1576455], dtype=float32), -0.54116064]. 
=============================================
[2019-04-17 15:30:27,936] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.4082047e-10 6.1179896e-14 8.1835192e-01 4.2042640e-08 5.5686296e-08
 8.4722429e-10 1.9802536e-08 2.2538900e-06 2.0036431e-07 6.6700894e-09
 1.8164547e-01], sum to 1.0000
[2019-04-17 15:30:27,937] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7695
[2019-04-17 15:30:27,988] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.0, 65.0, 193.5, 623.1666666666667, 19.0, 22.75973000616047, -0.1401596011049222, 0.0, 1.0, 25.0, 29.957667716692946], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2982000.0000, 
sim time next is 2983200.0000, 
raw observation next is [-3.0, 65.0, 169.1666666666667, 709.1666666666667, 19.0, 22.67708761703101, -0.1495794989267538, 0.0, 1.0, 25.0, 25.28937577381249], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.65, 0.563888888888889, 0.783609576427256, 0.08333333333333333, 0.3897573014192508, 0.4501401670244154, 0.0, 1.0, 0.2, 0.2528937577381249], 
reward next is 0.5471, 
noisyNet noise sample is [array([0.7412685], dtype=float32), -0.03818674]. 
=============================================
[2019-04-17 15:30:29,432] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.3659155e-13 5.6244390e-18 7.3823714e-01 1.1397228e-10 2.6295401e-09
 3.0337558e-12 1.5746800e-10 1.6920029e-07 2.2731308e-09 3.3538211e-10
 2.6176262e-01], sum to 1.0000
[2019-04-17 15:30:29,432] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2851
[2019-04-17 15:30:29,530] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.0, 92.0, 71.00000000000001, 322.0000000000001, 22.5, 26.2123969270415, 0.7322878718613982, 1.0, 1.0, 25.0, 28.520334111845592], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3226800.0000, 
sim time next is 3228000.0000, 
raw observation next is [-3.0, 92.0, 87.66666666666667, 417.1666666666667, 22.5, 26.40905995593127, 0.7639570862161431, 1.0, 1.0, 25.0, 26.720281398173746], 
processed observation next is [1.0, 0.34782608695652173, 0.3795013850415513, 0.92, 0.2922222222222222, 0.4609576427255985, 0.375, 0.7007549963276057, 0.7546523620720477, 1.0, 1.0, 0.2, 0.26720281398173745], 
reward next is 0.5328, 
noisyNet noise sample is [array([0.7085243], dtype=float32), 0.18337253]. 
=============================================
[2019-04-17 15:30:30,363] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0390413e-08 6.5022085e-12 8.2675952e-01 5.6579870e-07 1.1167007e-06
 1.6196179e-08 4.3042257e-07 2.2076636e-05 6.6291259e-06 3.1772046e-07
 1.7320932e-01], sum to 1.0000
[2019-04-17 15:30:30,364] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3125
[2019-04-17 15:30:30,388] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.3333333333333334, 61.33333333333334, 48.66666666666666, 419.6666666666667, 19.0, 22.95103554755289, -0.1444353858329101, 0.0, 1.0, 25.0, 9.556361480348256], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3084000.0000, 
sim time next is 3085200.0000, 
raw observation next is [0.0, 72.0, 32.0, 287.0, 19.0, 22.88194714382924, -0.1656662226644045, 0.0, 1.0, 25.0, 9.409837968474164], 
processed observation next is [0.0, 0.7391304347826086, 0.46260387811634357, 0.72, 0.10666666666666667, 0.31712707182320443, 0.08333333333333333, 0.4068289286524367, 0.4447779257785318, 0.0, 1.0, 0.2, 0.09409837968474165], 
reward next is 0.7059, 
noisyNet noise sample is [array([2.1162915], dtype=float32), 0.2724429]. 
=============================================
[2019-04-17 15:30:42,286] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.9081685e-12 7.5464865e-17 9.5170492e-01 7.7422901e-10 9.1830898e-09
 3.1432064e-12 1.5592317e-09 1.4365345e-07 3.9169339e-09 9.2236879e-10
 4.8294932e-02], sum to 1.0000
[2019-04-17 15:30:42,287] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4641
[2019-04-17 15:30:42,332] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.0, 50.0, 96.5, 713.0, 22.5, 25.82806227203088, 0.6708175620650233, 1.0, 1.0, 65.0, 47.04786822009689], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3337200.0000, 
sim time next is 3338400.0000, 
raw observation next is [-2.666666666666667, 48.66666666666667, 90.16666666666666, 687.0, 22.5, 26.71489877685153, 0.7587802628788016, 1.0, 1.0, 25.0, 34.770630422190116], 
processed observation next is [1.0, 0.6521739130434783, 0.38873499538319484, 0.4866666666666667, 0.3005555555555555, 0.7591160220994475, 0.375, 0.7262415647376276, 0.7529267542929339, 1.0, 1.0, 0.2, 0.3477063042219012], 
reward next is 0.4523, 
noisyNet noise sample is [array([-0.583607], dtype=float32), -1.4177088]. 
=============================================
[2019-04-17 15:30:44,457] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.00447340e-12 1.01815385e-16 9.09026265e-01 6.78237799e-10
 2.40560425e-08 1.75835110e-11 8.31146429e-10 1.56589934e-07
 4.27273417e-09 1.65873382e-09 9.09736082e-02], sum to 1.0000
[2019-04-17 15:30:44,457] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2916
[2019-04-17 15:30:44,525] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.333333333333333, 75.0, 0.0, 0.0, 22.5, 25.37060062572036, 0.5317802425694598, 1.0, 1.0, 25.0, 20.00977985614857], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3436800.0000, 
sim time next is 3438000.0000, 
raw observation next is [1.0, 79.0, 0.0, 0.0, 22.5, 25.50714323068365, 0.5310274160099867, 1.0, 1.0, 25.0, 17.78115385255813], 
processed observation next is [1.0, 0.8260869565217391, 0.4903047091412743, 0.79, 0.0, 0.0, 0.375, 0.6255952692236374, 0.6770091386699956, 1.0, 1.0, 0.2, 0.1778115385255813], 
reward next is 0.6222, 
noisyNet noise sample is [array([-0.07886128], dtype=float32), -0.1785985]. 
=============================================
[2019-04-17 15:30:52,437] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9922238e-11 9.8986144e-16 9.7454858e-01 1.2031214e-09 8.3540144e-08
 1.8917307e-11 1.4177640e-09 1.8407643e-07 8.2119218e-09 4.3867390e-09
 2.5451036e-02], sum to 1.0000
[2019-04-17 15:30:52,437] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1771
[2019-04-17 15:30:52,535] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 22.5, 25.19615980064198, 0.4493196823075751, 1.0, 1.0, 25.0, 10.21482321668284], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3523200.0000, 
sim time next is 3524400.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 22.5, 24.98214456776405, 0.4225601293807455, 1.0, 1.0, 25.0, 9.876804175138673], 
processed observation next is [1.0, 0.8260869565217391, 0.518005540166205, 0.52, 0.0, 0.0, 0.375, 0.5818453806470041, 0.6408533764602485, 1.0, 1.0, 0.2, 0.09876804175138673], 
reward next is 0.7012, 
noisyNet noise sample is [array([-1.7216711], dtype=float32), 0.16137764]. 
=============================================
[2019-04-17 15:30:54,752] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1125508e-11 2.6339294e-16 9.4706464e-01 1.4210498e-09 2.5889486e-08
 2.4773385e-11 2.6717253e-09 6.3718630e-07 7.4790893e-09 1.7875367e-09
 5.2934621e-02], sum to 1.0000
[2019-04-17 15:30:54,752] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7258
[2019-04-17 15:30:54,793] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 53.66666666666667, 115.8333333333333, 820.1666666666667, 22.5, 24.55405268956953, 0.2549485602158549, 1.0, 1.0, 25.0, 22.165456029370624], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3501600.0000, 
sim time next is 3502800.0000, 
raw observation next is [2.0, 52.0, 115.5, 814.5, 22.5, 24.37206575549891, 0.2346486337749673, 1.0, 1.0, 25.0, 21.776531736167193], 
processed observation next is [1.0, 0.5652173913043478, 0.518005540166205, 0.52, 0.385, 0.9, 0.375, 0.5310054796249091, 0.5782162112583225, 1.0, 1.0, 0.2, 0.21776531736167193], 
reward next is 0.5822, 
noisyNet noise sample is [array([0.41966867], dtype=float32), 0.36086544]. 
=============================================
[2019-04-17 15:30:55,163] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.20258015e-10 1.01079193e-13 5.44985473e-01 1.40494265e-08
 8.69996342e-08 1.23607657e-09 1.97260270e-08 3.87994442e-06
 2.73935257e-07 1.48783466e-08 4.55010325e-01], sum to 1.0000
[2019-04-17 15:30:55,163] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3465
[2019-04-17 15:30:55,294] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [10.0, 28.0, 91.0, 446.3333333333334, 19.0, 25.67882558627714, 0.4726732319334468, 0.0, 1.0, 25.0, 37.671093268131344], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3660000.0000, 
sim time next is 3661200.0000, 
raw observation next is [11.0, 26.0, 95.0, 533.0, 19.0, 25.79055008067782, 0.4938267160796758, 0.0, 1.0, 25.0, 34.3600862192757], 
processed observation next is [0.0, 0.391304347826087, 0.7673130193905818, 0.26, 0.31666666666666665, 0.5889502762430939, 0.08333333333333333, 0.6492125067231518, 0.6646089053598919, 0.0, 1.0, 0.2, 0.343600862192757], 
reward next is 0.4564, 
noisyNet noise sample is [array([-0.10082158], dtype=float32), 1.8148019]. 
=============================================
[2019-04-17 15:30:55,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4326533e-12 3.4094971e-16 9.8968047e-01 6.5256439e-10 7.3340867e-09
 1.5537288e-11 7.6215717e-10 8.3875761e-08 2.1897575e-09 8.9129504e-10
 1.0319421e-02], sum to 1.0000
[2019-04-17 15:30:55,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9076
[2019-04-17 15:30:55,524] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 22.5, 24.42116781585354, 0.2968698707817815, 0.0, 1.0, 25.0, 12.695627198381604], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3528000.0000, 
sim time next is 3529200.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 24.25534307471924, 0.268230610130635, 0.0, 1.0, 25.0, 12.01722138184343], 
processed observation next is [1.0, 0.8695652173913043, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.5212785895599366, 0.5894102033768783, 0.0, 1.0, 0.2, 0.1201722138184343], 
reward next is 0.6798, 
noisyNet noise sample is [array([0.6203699], dtype=float32), -0.76757526]. 
=============================================
[2019-04-17 15:31:32,186] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.32347580e-09 4.38461550e-12 9.34991181e-01 3.46793655e-07
 5.16920579e-07 1.02490256e-08 1.08474765e-07 6.24615359e-06
 1.27741816e-06 1.22990954e-07 6.50001690e-02], sum to 1.0000
[2019-04-17 15:31:32,187] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1173
[2019-04-17 15:31:32,198] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-4.666666666666666, 49.33333333333333, 0.0, 0.0, 19.0, 21.33186814669406, -0.5788130233682455, 0.0, 1.0, 25.0, 13.166842153230524], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4171200.0000, 
sim time next is 4172400.0000, 
raw observation next is [-5.0, 49.0, 0.0, 0.0, 19.0, 21.24588000898679, -0.5982786680520075, 0.0, 1.0, 25.0, 13.368129321198085], 
processed observation next is [0.0, 0.30434782608695654, 0.32409972299168976, 0.49, 0.0, 0.0, 0.08333333333333333, 0.2704900007488993, 0.3005737773159975, 0.0, 1.0, 0.2, 0.13368129321198086], 
reward next is 0.6663, 
noisyNet noise sample is [array([-0.6840422], dtype=float32), 0.9775472]. 
=============================================
[2019-04-17 15:31:38,246] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.07256140e-11 3.43626380e-15 8.83994758e-01 4.15896295e-09
 1.03539826e-08 6.33446143e-11 2.51720822e-09 1.06603966e-06
 3.50246694e-08 5.02289943e-09 1.16004206e-01], sum to 1.0000
[2019-04-17 15:31:38,249] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6767
[2019-04-17 15:31:38,282] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [7.0, 52.0, 120.1666666666667, 842.8333333333334, 19.0, 23.34161177696804, -0.01560394871195193, 0.0, 1.0, 65.0, 65.54562495385437], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4278000.0000, 
sim time next is 4279200.0000, 
raw observation next is [7.0, 52.0, 131.3333333333333, 825.3333333333334, 19.0, 24.01776578200503, 0.0535922587215201, 0.0, 1.0, 25.0, 44.357556672486304], 
processed observation next is [0.0, 0.5217391304347826, 0.6565096952908588, 0.52, 0.4377777777777776, 0.9119705340699816, 0.08333333333333333, 0.5014804818337524, 0.5178640862405067, 0.0, 1.0, 0.2, 0.44357556672486304], 
reward next is 0.3564, 
noisyNet noise sample is [array([0.28542882], dtype=float32), -0.60832715]. 
=============================================
[2019-04-17 15:31:39,622] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.5558015e-12 7.4503589e-17 9.4009829e-01 1.9103841e-09 3.1017247e-08
 4.6859013e-11 1.2230562e-09 3.4954823e-07 1.0395899e-08 1.5752893e-09
 5.9901405e-02], sum to 1.0000
[2019-04-17 15:31:39,643] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5387
[2019-04-17 15:31:39,680] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.166666666666667, 72.33333333333334, 0.0, 0.0, 19.0, 22.31692284640257, -0.3481753600854225, 0.0, 1.0, 25.0, 10.94602415226972], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4342800.0000, 
sim time next is 4344000.0000, 
raw observation next is [3.033333333333333, 73.66666666666667, 0.0, 0.0, 19.0, 22.2015890903261, -0.3669435793585121, 0.0, 1.0, 25.0, 10.985273604496385], 
processed observation next is [1.0, 0.2608695652173913, 0.5466297322253002, 0.7366666666666667, 0.0, 0.0, 0.08333333333333333, 0.35013242419384155, 0.37768547354716264, 0.0, 1.0, 0.2, 0.10985273604496384], 
reward next is 0.6901, 
noisyNet noise sample is [array([-0.31430516], dtype=float32), -1.6841497]. 
=============================================
[2019-04-17 15:31:41,106] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.5322591e-14 4.2143640e-19 7.9095453e-01 2.3957376e-11 1.9397953e-10
 1.8147951e-13 3.5877471e-11 9.3935855e-09 2.7808605e-10 4.9599713e-11
 2.0904553e-01], sum to 1.0000
[2019-04-17 15:31:41,107] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4828
[2019-04-17 15:31:41,128] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.0, 37.0, 34.0, 0.0, 22.5, 26.65043883443983, 0.7816216914549124, 1.0, 1.0, 25.0, 18.811019748735315], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4380000.0000, 
sim time next is 4381200.0000, 
raw observation next is [13.0, 38.0, 24.0, 0.0, 22.5, 27.09341921241805, 0.8153131159876165, 1.0, 1.0, 25.0, 16.51505153956696], 
processed observation next is [1.0, 0.7391304347826086, 0.8227146814404434, 0.38, 0.08, 0.0, 0.375, 0.7577849343681707, 0.7717710386625388, 1.0, 1.0, 0.2, 0.1651505153956696], 
reward next is 0.6348, 
noisyNet noise sample is [array([-0.3126284], dtype=float32), -0.4763837]. 
=============================================
[2019-04-17 15:31:44,247] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.8796238e-12 2.2595302e-17 9.5729023e-01 2.7352673e-10 3.7922678e-09
 6.1576326e-12 5.6177907e-10 2.0555397e-07 6.2648073e-09 6.0723804e-10
 4.2709474e-02], sum to 1.0000
[2019-04-17 15:31:44,247] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0988
[2019-04-17 15:31:44,258] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 19.0, 22.66141563912033, -0.1380179763262073, 0.0, 1.0, 25.0, 8.039144127051923], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4576800.0000, 
sim time next is 4578000.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 19.0, 22.58736886101726, -0.1539557297579654, 0.0, 1.0, 25.0, 8.149706710556133], 
processed observation next is [1.0, 1.0, 0.4903047091412743, 0.61, 0.0, 0.0, 0.08333333333333333, 0.38228073841810506, 0.4486814234140115, 0.0, 1.0, 0.2, 0.08149706710556133], 
reward next is 0.7185, 
noisyNet noise sample is [array([0.8369637], dtype=float32), -1.3995612]. 
=============================================
[2019-04-17 15:31:48,965] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.15453430e-15 2.00839440e-19 9.19817030e-01 1.90220652e-11
 2.45471449e-10 1.19506469e-13 1.94160087e-11 1.04135305e-08
 1.50168780e-10 6.41755399e-11 8.01830068e-02], sum to 1.0000
[2019-04-17 15:31:48,965] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0993
[2019-04-17 15:31:48,982] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [5.466666666666667, 45.0, 104.1666666666667, 146.6666666666667, 22.5, 26.42038853848821, 0.6874287626121759, 1.0, 1.0, 25.0, 15.616180037687535], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4639200.0000, 
sim time next is 4640400.0000, 
raw observation next is [5.2, 46.0, 78.5, 146.0, 22.5, 26.60015722040682, 0.703115799913899, 1.0, 1.0, 25.0, 13.659501837438825], 
processed observation next is [1.0, 0.7391304347826086, 0.6066481994459835, 0.46, 0.26166666666666666, 0.16132596685082873, 0.375, 0.7166797683672351, 0.734371933304633, 1.0, 1.0, 0.2, 0.13659501837438826], 
reward next is 0.6634, 
noisyNet noise sample is [array([-1.8980948], dtype=float32), -0.46244755]. 
=============================================
[2019-04-17 15:31:52,863] A3C_AGENT_WORKER-Thread-7 INFO:Evaluating...
[2019-04-17 15:31:52,864] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-17 15:31:52,864] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation job starts!
[2019-04-17 15:31:52,864] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:31:52,864] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:31:52,869] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation job starts!
[2019-04-17 15:31:52,872] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:31:52,876] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res1/Eplus-env-sub_run5
[2019-04-17 15:31:52,892] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v1-res1/Eplus-env-sub_run5
[2019-04-17 15:31:52,903] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v2-res1/Eplus-env-sub_run5
[2019-04-17 15:32:58,505] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2163.0884 109482.2319 243.9565
[2019-04-17 15:32:58,539] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:32:58,539] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:32:58,539] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:32:58,539] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:32:58,539] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:32:58,682] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:32:58,682] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:32:58,682] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:32:58,682] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:32:58,682] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:33:08,038] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2083.5894 116959.4861 -153.1312
[2019-04-17 15:33:08,059] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:08,059] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:08,059] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:08,059] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:08,059] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:08,183] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:33:08,183] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:33:08,183] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:33:08,183] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:33:08,183] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:33:12,366] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2037.6038 115967.5370 -436.1302
[2019-04-17 15:33:12,386] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:12,386] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:12,386] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:12,386] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:12,386] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:12,490] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:33:12,490] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:33:12,490] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:33:12,490] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:33:12,490] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:33:13,389] A3C_AGENT_WORKER-Thread-7 INFO:Global step: 200000, evaluation results [200000.0, 2083.5894191020093, 116959.486135236, -153.13121380625196, 2163.0883565645604, 109482.2318562159, 243.95651415030937, 2037.6037649022992, 115967.53703203691, -436.13019030278656]
[2019-04-17 15:33:15,256] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3288049e-11 1.2386110e-15 8.4350336e-01 2.8873401e-09 1.0511010e-08
 8.4500143e-11 2.1342359e-09 1.4252591e-07 2.2923020e-08 6.2276859e-09
 1.5649650e-01], sum to 1.0000
[2019-04-17 15:33:15,256] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1221
[2019-04-17 15:33:15,274] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.5333333333333332, 48.66666666666667, 282.6666666666667, 321.6666666666667, 19.0, 23.75445643983328, 0.0387279618115314, 0.0, 1.0, 25.0, 17.37676963592353], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4880400.0000, 
sim time next is 4881600.0000, 
raw observation next is [1.0, 47.0, 282.0, 349.0, 19.0, 23.73098568402541, 0.03683357867349964, 0.0, 1.0, 25.0, 15.904115448274805], 
processed observation next is [0.0, 0.5217391304347826, 0.4903047091412743, 0.47, 0.94, 0.3856353591160221, 0.08333333333333333, 0.47758214033545077, 0.5122778595578332, 0.0, 1.0, 0.2, 0.15904115448274805], 
reward next is 0.6410, 
noisyNet noise sample is [array([0.03836606], dtype=float32), 0.11303822]. 
=============================================
[2019-04-17 15:33:15,964] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.83631364e-11 1.77161843e-15 8.92165661e-01 3.15537707e-09
 9.39355349e-09 7.46028794e-11 2.18935403e-09 3.20386022e-07
 2.36903261e-08 2.61570499e-09 1.07833974e-01], sum to 1.0000
[2019-04-17 15:33:15,966] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1400
[2019-04-17 15:33:15,989] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.0, 44.66666666666667, 0.0, 0.0, 19.0, 25.1699591052772, 0.3225503328779599, 0.0, 1.0, 25.0, 25.166169756640222], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4908000.0000, 
sim time next is 4909200.0000, 
raw observation next is [1.0, 42.33333333333333, 0.0, 0.0, 19.0, 25.03528736318082, 0.2921917080570222, 0.0, 1.0, 25.0, 23.180291726934676], 
processed observation next is [0.0, 0.8260869565217391, 0.4903047091412743, 0.4233333333333333, 0.0, 0.0, 0.08333333333333333, 0.5862739469317351, 0.5973972360190074, 0.0, 1.0, 0.2, 0.23180291726934676], 
reward next is 0.5682, 
noisyNet noise sample is [array([-0.27410856], dtype=float32), -0.42589188]. 
=============================================
[2019-04-17 15:33:16,268] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:16,435] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:17,269] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:17,269] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:17,271] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res16/Eplus-env-sub_run4
[2019-04-17 15:33:17,686] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:17,861] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:18,091] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:18,112] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:18,261] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:18,278] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:18,279] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6511381e-13 1.4973563e-18 9.1492254e-01 2.8441718e-11 1.4101778e-09
 8.9932136e-13 5.9920235e-11 1.4365328e-07 3.7292516e-10 1.1272802e-10
 8.5077353e-02], sum to 1.0000
[2019-04-17 15:33:18,280] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4888
[2019-04-17 15:33:18,295] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [8.2, 30.0, 0.0, 0.0, 19.0, 26.32649296926834, 0.6654091101594903, 0.0, 1.0, 25.0, 27.89341986113621], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 5096400.0000, 
sim time next is 5097600.0000, 
raw observation next is [8.1, 35.0, 0.0, 0.0, 19.0, 26.30810308224232, 0.6486120887261161, 0.0, 1.0, 25.0, 25.053104523574646], 
processed observation next is [1.0, 0.0, 0.6869806094182825, 0.35, 0.0, 0.0, 0.08333333333333333, 0.6923419235201932, 0.7162040295753721, 0.0, 1.0, 0.2, 0.2505310452357465], 
reward next is 0.5495, 
noisyNet noise sample is [array([0.9217058], dtype=float32), -0.7452985]. 
=============================================
[2019-04-17 15:33:18,350] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:18,509] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.92468246e-14 3.54834659e-19 8.84775996e-01 2.35406260e-11
 6.77382594e-10 2.07902082e-13 8.76736600e-11 2.27543335e-08
 3.63688413e-10 2.57067059e-11 1.15224056e-01], sum to 1.0000
[2019-04-17 15:33:18,510] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:18,510] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9112
[2019-04-17 15:33:18,528] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [10.33333333333333, 18.33333333333333, 0.0, 0.0, 22.5, 26.62849596334321, 0.7347098164728595, 0.0, 1.0, 25.0, 31.20030750087495], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 5082000.0000, 
sim time next is 5083200.0000, 
raw observation next is [10.0, 19.0, 0.0, 0.0, 22.5, 26.61625568631049, 0.7356607292220471, 0.0, 1.0, 65.0, 35.927840596363716], 
processed observation next is [1.0, 0.8695652173913043, 0.739612188365651, 0.19, 0.0, 0.0, 0.375, 0.718021307192541, 0.7452202430740157, 0.0, 1.0, 1.0, 0.35927840596363714], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04165674], dtype=float32), 0.1340501]. 
=============================================
[2019-04-17 15:33:18,686] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:18,686] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:18,688] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res5/Eplus-env-sub_run4
[2019-04-17 15:33:18,769] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:19,018] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:19,092] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:19,092] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:19,094] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res14/Eplus-env-sub_run4
[2019-04-17 15:33:19,145] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:19,146] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:19,161] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res7/Eplus-env-sub_run4
[2019-04-17 15:33:19,357] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:19,357] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:19,359] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res3/Eplus-env-sub_run4
[2019-04-17 15:33:19,771] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:19,772] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:19,781] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res6/Eplus-env-sub_run4
[2019-04-17 15:33:20,529] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:20,895] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:21,091] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:21,533] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:21,533] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:21,535] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res11/Eplus-env-sub_run4
[2019-04-17 15:33:21,645] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:22,075] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:22,076] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:22,090] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res2/Eplus-env-sub_run4
[2019-04-17 15:33:22,840] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9588533e-14 5.9873944e-20 9.4851375e-01 1.5974788e-12 5.6336272e-11
 2.5280738e-14 1.2531111e-11 3.9382844e-09 6.2330266e-11 5.0465495e-12
 5.1486231e-02], sum to 1.0000
[2019-04-17 15:33:22,841] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1898
[2019-04-17 15:33:22,871] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [11.66666666666667, 17.0, 42.66666666666666, 340.8333333333333, 22.5, 27.73854568175455, 0.9286528591531727, 1.0, 1.0, 25.0, 21.233424769139], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 5073600.0000, 
sim time next is 5074800.0000, 
raw observation next is [11.33333333333333, 17.0, 30.0, 243.3333333333333, 22.5, 27.74464777128927, 0.9568638733616943, 1.0, 1.0, 25.0, 18.060496530553994], 
processed observation next is [1.0, 0.7391304347826086, 0.7765466297322253, 0.17, 0.1, 0.2688766114180478, 0.375, 0.8120539809407724, 0.8189546244538981, 1.0, 1.0, 0.2, 0.18060496530553993], 
reward next is 0.6194, 
noisyNet noise sample is [array([1.0017285], dtype=float32), 0.72797114]. 
=============================================
[2019-04-17 15:33:23,381] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:23,636] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:23,750] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:24,126] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:24,372] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:24,372] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:24,374] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res4/Eplus-env-sub_run4
[2019-04-17 15:33:24,637] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:24,637] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:24,639] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res9/Eplus-env-sub_run4
[2019-04-17 15:33:25,111] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:25,513] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:25,870] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:26,089] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:26,112] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:26,112] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:26,114] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res12/Eplus-env-sub_run4
[2019-04-17 15:33:26,269] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:26,529] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:26,833] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:26,871] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:26,871] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:26,873] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res15/Eplus-env-sub_run4
[2019-04-17 15:33:27,090] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:27,090] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:27,092] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res10/Eplus-env-sub_run4
[2019-04-17 15:33:27,249] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:27,801] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:27,801] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:27,803] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res13/Eplus-env-sub_run4
[2019-04-17 15:33:28,333] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:28,657] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:33:28,706] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:29,001] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-17 15:33:29,334] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:29,334] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:29,336] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res8/Eplus-env-sub_run4
[2019-04-17 15:33:29,658] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:33:29,658] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:33:29,660] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res17/Eplus-env-sub_run4
[2019-04-17 15:33:31,076] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[54.63292 ]
 [54.672054]
 [54.41321 ]
 [54.552444]
 [53.647556]
 [53.288433]
 [53.46274 ]
 [53.84521 ]
 [53.951595]
 [53.987617]
 [54.440617]
 [54.802063]
 [55.24961 ]
 [55.337936]
 [55.98567 ]
 [56.22374 ]
 [56.83084 ]
 [57.03622 ]
 [57.14589 ]
 [57.55686 ]
 [57.52229 ]
 [57.941864]
 [57.685352]], R is [[ 0.54946895]
 [ 1.06504007]
 [ 1.54352063]
 [ 1.94271779]
 [ 1.92329061]
 [ 2.6063621 ]
 [ 3.28452869]
 [ 3.95122636]
 [ 4.60630549]
 [ 5.24970064]
 [ 5.88086848]
 [ 6.49935857]
 [ 7.10450659]
 [ 7.69899983]
 [ 8.27897541]
 [ 8.84302891]
 [ 9.38200165]
 [ 9.89557854]
 [10.42375039]
 [10.93326744]
 [11.39189802]
 [11.91544511]
 [12.30303234]].
[2019-04-17 15:33:32,039] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.9617727e-14 1.5792622e-18 9.8780745e-01 3.3858055e-11 7.9225293e-11
 2.7694687e-13 3.5560718e-11 3.2993640e-08 6.6551864e-10 3.8709692e-11
 1.2192583e-02], sum to 1.0000
[2019-04-17 15:33:32,039] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8382
[2019-04-17 15:33:32,052] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [7.7, 93.0, 17.5, 0.0, 19.0, 23.03871920680362, -0.08343192316873184, 0.0, 1.0, 25.0, 28.031159724261073], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 30000.0000, 
sim time next is 31200.0000, 
raw observation next is [7.699999999999999, 93.0, 23.83333333333333, 0.0, 19.0, 22.94968494643818, -0.1000847027993418, 0.0, 1.0, 25.0, 25.65351717059884], 
processed observation next is [0.0, 0.34782608695652173, 0.6759002770083103, 0.93, 0.07944444444444443, 0.0, 0.08333333333333333, 0.4124737455365149, 0.46663843240021935, 0.0, 1.0, 0.2, 0.2565351717059884], 
reward next is 0.5435, 
noisyNet noise sample is [array([0.16110617], dtype=float32), -0.80087256]. 
=============================================
[2019-04-17 15:33:33,336] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0940399e-12 1.3616299e-16 9.2882061e-01 2.9905381e-10 2.8038063e-09
 9.0049808e-12 2.3425104e-10 1.5178158e-07 3.1735978e-09 5.7318406e-10
 7.1179256e-02], sum to 1.0000
[2019-04-17 15:33:33,336] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9981
[2019-04-17 15:33:33,391] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 19.0, 22.23002916955281, -0.3029327800686002, 0.0, 1.0, 25.0, 32.87645001373491], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 14400.0000, 
sim time next is 15600.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 19.0, 22.22675491227193, -0.2671387700660129, 0.0, 1.0, 65.0, 58.629707268477034], 
processed observation next is [0.0, 0.17391304347826086, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.35222957602266075, 0.41095374331132906, 0.0, 1.0, 1.0, 0.5862970726847704], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5864481], dtype=float32), -0.53888136]. 
=============================================
[2019-04-17 15:33:42,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.12182876e-12 9.60335846e-18 8.93286884e-01 4.18359486e-10
 3.01614378e-09 1.84490379e-12 1.99548850e-10 1.31086622e-07
 6.32148511e-09 3.38912259e-10 1.06713034e-01], sum to 1.0000
[2019-04-17 15:33:42,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5709
[2019-04-17 15:33:43,089] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.2, 61.0, 122.3333333333333, 0.0, 22.5, 21.95148454140642, -0.4917721452126038, 1.0, 1.0, 65.0, 100.97418251102468], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 224400.0000, 
sim time next is 225600.0000, 
raw observation next is [-3.0, 60.0, 106.8333333333333, 0.0, 22.5, 22.6604750776882, -0.3505673631487906, 1.0, 1.0, 25.0, 52.864586562726075], 
processed observation next is [1.0, 0.6086956521739131, 0.3795013850415513, 0.6, 0.356111111111111, 0.0, 0.375, 0.3883729231406834, 0.38314421228373646, 1.0, 1.0, 0.2, 0.5286458656272608], 
reward next is 0.2714, 
noisyNet noise sample is [array([-0.05798177], dtype=float32), -0.34954876]. 
=============================================
[2019-04-17 15:33:55,969] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5968546e-13 1.1274380e-18 8.3677524e-01 1.2450338e-10 1.1715797e-09
 6.0855254e-13 2.9579984e-11 6.4869269e-08 3.0801600e-10 8.0726675e-11
 1.6322465e-01], sum to 1.0000
[2019-04-17 15:33:55,969] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8247
[2019-04-17 15:33:56,019] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.733333333333333, 71.66666666666667, 0.0, 0.0, 19.0, 24.63451632792157, 0.1587592296522936, 0.0, 1.0, 25.0, 36.79527995818604], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 250800.0000, 
sim time next is 252000.0000, 
raw observation next is [-3.9, 75.0, 0.0, 0.0, 19.0, 24.50417818427857, 0.1331207380569595, 0.0, 1.0, 25.0, 31.73669990522665], 
processed observation next is [1.0, 0.9565217391304348, 0.3545706371191136, 0.75, 0.0, 0.0, 0.08333333333333333, 0.5420148486898807, 0.5443735793523198, 0.0, 1.0, 0.2, 0.3173669990522665], 
reward next is 0.4826, 
noisyNet noise sample is [array([-0.7576001], dtype=float32), 0.4060839]. 
=============================================
[2019-04-17 15:33:57,255] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1828995e-13 5.1846366e-18 8.9051741e-01 8.4417459e-11 2.1223125e-09
 1.1595695e-12 9.2324634e-11 7.2308175e-08 5.7109173e-10 1.4257633e-10
 1.0948251e-01], sum to 1.0000
[2019-04-17 15:33:57,255] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2350
[2019-04-17 15:33:57,300] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-11.9, 69.0, 0.0, 0.0, 19.0, 24.04338636689469, 0.0297344413962524, 0.0, 1.0, 25.0, 49.84738581242712], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 282000.0000, 
sim time next is 283200.0000, 
raw observation next is [-12.1, 68.0, 0.0, 0.0, 19.0, 23.90603748834476, -0.001427390598541976, 0.0, 1.0, 25.0, 44.042755839934486], 
processed observation next is [1.0, 0.2608695652173913, 0.12742382271468145, 0.68, 0.0, 0.0, 0.08333333333333333, 0.4921697906953968, 0.49952420313381934, 0.0, 1.0, 0.2, 0.4404275583993449], 
reward next is 0.3596, 
noisyNet noise sample is [array([-1.1360884], dtype=float32), -0.8987313]. 
=============================================
[2019-04-17 15:33:59,417] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.9245928e-11 2.4006964e-15 7.0822740e-01 5.2521072e-09 2.1664828e-08
 8.4723693e-11 1.6058739e-09 1.2500376e-06 2.2070273e-08 6.1496883e-09
 2.9177126e-01], sum to 1.0000
[2019-04-17 15:33:59,417] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1940
[2019-04-17 15:33:59,713] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-16.36666666666667, 79.0, 0.0, 0.0, 22.5, 20.76799586049062, -0.7311604093734309, 1.0, 1.0, 25.0, 43.52299295462146], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 372000.0000, 
sim time next is 373200.0000, 
raw observation next is [-16.53333333333333, 80.0, 0.0, 0.0, 22.5, 20.88266132897915, -0.7556532048146801, 1.0, 1.0, 25.0, 36.08812925924239], 
processed observation next is [1.0, 0.30434782608695654, 0.0046168051708218244, 0.8, 0.0, 0.0, 0.375, 0.2402217774149292, 0.24811559839510663, 1.0, 1.0, 0.2, 0.3608812925924239], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.32058412], dtype=float32), 0.48352447]. 
=============================================
[2019-04-17 15:34:05,231] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1132423e-12 5.0731884e-17 8.5365397e-01 6.2205191e-10 3.6358665e-09
 1.8448092e-11 5.2243432e-10 2.5956109e-07 3.3868939e-09 5.5360005e-10
 1.4634579e-01], sum to 1.0000
[2019-04-17 15:34:05,231] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8065
[2019-04-17 15:34:05,257] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-13.9, 67.33333333333334, 0.0, 0.0, 19.0, 21.44277503145433, -0.5735450752342107, 0.0, 1.0, 25.0, 39.96329821810487], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 344400.0000, 
sim time next is 345600.0000, 
raw observation next is [-13.9, 66.0, 0.0, 0.0, 19.0, 21.32316274669988, -0.6077722625355994, 0.0, 1.0, 25.0, 35.64203380072465], 
processed observation next is [1.0, 0.0, 0.07756232686980608, 0.66, 0.0, 0.0, 0.08333333333333333, 0.2769302288916566, 0.2974092458214669, 0.0, 1.0, 0.2, 0.3564203380072465], 
reward next is 0.4436, 
noisyNet noise sample is [array([0.8232048], dtype=float32), 0.08787905]. 
=============================================
[2019-04-17 15:34:21,583] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1444127e-11 6.0919774e-15 8.1231862e-01 4.5297432e-09 3.5333386e-08
 2.5602778e-10 2.2886897e-09 1.4552787e-06 1.2465328e-07 8.8366248e-09
 1.8767975e-01], sum to 1.0000
[2019-04-17 15:34:21,583] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4520
[2019-04-17 15:34:21,665] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.0, 56.0, 22.5, 12.83333333333333, 19.0, 23.12692828881866, -0.1531020259360642, 0.0, 1.0, 25.0, 36.7962743172843], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 664800.0000, 
sim time next is 666000.0000, 
raw observation next is [-1.2, 57.0, 13.5, 8.5, 19.0, 22.99084648177367, -0.1805943474080664, 0.0, 1.0, 25.0, 33.13593479794477], 
processed observation next is [0.0, 0.7391304347826086, 0.42936288088642666, 0.57, 0.045, 0.009392265193370166, 0.08333333333333333, 0.4159038734811391, 0.4398018841973112, 0.0, 1.0, 0.2, 0.3313593479794477], 
reward next is 0.4686, 
noisyNet noise sample is [array([1.615338], dtype=float32), 0.9386341]. 
=============================================
[2019-04-17 15:34:22,622] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.2716361e-13 7.5247323e-17 3.7737539e-01 1.7005754e-10 1.0935854e-09
 2.3654210e-12 3.4695438e-10 2.8526972e-07 2.1294355e-09 4.3154308e-10
 6.2262434e-01], sum to 1.0000
[2019-04-17 15:34:22,622] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3594
[2019-04-17 15:34:22,754] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.2, 80.0, 134.0, 495.5, 19.0, 24.12244417254373, 0.09812968743101813, 0.0, 1.0, 25.0, 44.2085366161492], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 565200.0000, 
sim time next is 566400.0000, 
raw observation next is [-1.2, 80.0, 136.6666666666667, 561.8333333333334, 19.0, 24.04025262874822, 0.0877218388977233, 0.0, 1.0, 25.0, 39.11915201318985], 
processed observation next is [0.0, 0.5652173913043478, 0.42936288088642666, 0.8, 0.4555555555555557, 0.6208103130755065, 0.08333333333333333, 0.5033543857290184, 0.5292406129659077, 0.0, 1.0, 0.2, 0.39119152013189845], 
reward next is 0.4088, 
noisyNet noise sample is [array([1.584059], dtype=float32), -0.5890053]. 
=============================================
[2019-04-17 15:34:26,439] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9387859e-10 6.6760101e-14 7.1437788e-01 3.1193036e-08 7.5741312e-08
 9.2604713e-10 1.0854279e-08 2.3273510e-06 1.8024770e-07 2.3816066e-08
 2.8561941e-01], sum to 1.0000
[2019-04-17 15:34:26,440] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1444
[2019-04-17 15:34:26,459] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.6, 54.0, 55.0, 26.5, 19.0, 22.76830831664431, -0.2161265876640273, 0.0, 1.0, 25.0, 25.239570936747597], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 662400.0000, 
sim time next is 663600.0000, 
raw observation next is [-0.8, 55.00000000000001, 36.33333333333333, 18.83333333333333, 19.0, 22.65808400062282, -0.2430793143831421, 0.0, 1.0, 25.0, 23.0468134623409], 
processed observation next is [0.0, 0.6956521739130435, 0.4404432132963989, 0.55, 0.1211111111111111, 0.020810313075506442, 0.08333333333333333, 0.38817366671856846, 0.418973561872286, 0.0, 1.0, 0.2, 0.230468134623409], 
reward next is 0.5695, 
noisyNet noise sample is [array([0.141123], dtype=float32), 1.2279038]. 
=============================================
[2019-04-17 15:34:29,154] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1188179e-12 1.4694954e-16 8.3971184e-01 5.3985921e-10 5.1323199e-09
 4.9724248e-12 6.3900141e-10 1.5168376e-07 4.3240482e-09 4.9676330e-10
 1.6028795e-01], sum to 1.0000
[2019-04-17 15:34:29,154] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0925
[2019-04-17 15:34:29,195] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.8, 54.0, 34.0, 2.5, 22.5, 25.16002313381652, 0.3419169164412039, 1.0, 1.0, 25.0, 45.32698352877876], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 752400.0000, 
sim time next is 753600.0000, 
raw observation next is [-3.166666666666667, 54.66666666666667, 0.0, 0.0, 22.5, 25.23610021109275, 0.3129652776979772, 1.0, 1.0, 25.0, 39.36557362676223], 
processed observation next is [1.0, 0.7391304347826086, 0.3748845798707295, 0.5466666666666667, 0.0, 0.0, 0.375, 0.6030083509243959, 0.6043217592326591, 1.0, 1.0, 0.2, 0.3936557362676223], 
reward next is 0.4063, 
noisyNet noise sample is [array([-1.1676298], dtype=float32), 0.9592012]. 
=============================================
[2019-04-17 15:34:32,011] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [4.7883702e-12 2.3599892e-16 8.1939858e-01 1.8614931e-09 2.3921485e-08
 1.5843776e-11 8.1180651e-10 7.0650304e-07 5.8238188e-09 3.5000862e-09
 1.8060066e-01], sum to 1.0000
[2019-04-17 15:34:32,012] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.5527
[2019-04-17 15:34:32,036] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-6.533333333333333, 66.0, 0.0, 0.0, 19.0, 23.67936748452303, 0.07421281674516221, 0.0, 1.0, 25.0, 26.423299689729056], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 772800.0000, 
sim time next is 774000.0000, 
raw observation next is [-6.7, 67.0, 0.0, 0.0, 19.0, 23.51200233723632, 0.0401934011372407, 0.0, 1.0, 25.0, 23.998275655248214], 
processed observation next is [1.0, 1.0, 0.2770083102493075, 0.67, 0.0, 0.0, 0.08333333333333333, 0.4593335281030268, 0.5133978003790802, 0.0, 1.0, 0.2, 0.23998275655248213], 
reward next is 0.5600, 
noisyNet noise sample is [array([-1.7226168], dtype=float32), 0.6347357]. 
=============================================
[2019-04-17 15:34:32,873] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.12154479e-14 6.68826125e-20 8.77585649e-01 4.33933748e-12
 1.87153223e-10 2.28470725e-13 1.03663961e-11 3.37098847e-08
 1.51088239e-10 4.42828586e-11 1.22414365e-01], sum to 1.0000
[2019-04-17 15:34:32,873] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2125
[2019-04-17 15:34:32,943] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 22.5, 26.68140974844111, 0.8209350000351018, 1.0, 1.0, 25.0, 33.60176563681546], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1015200.0000, 
sim time next is 1016400.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 22.5, 26.68101789888981, 0.8229894595422557, 1.0, 1.0, 25.0, 33.697955158817614], 
processed observation next is [1.0, 0.782608695652174, 0.8614958448753465, 0.81, 0.0, 0.0, 0.375, 0.7234181582408175, 0.7743298198474186, 1.0, 1.0, 0.2, 0.33697955158817616], 
reward next is 0.4630, 
noisyNet noise sample is [array([-0.05072095], dtype=float32), -0.77646315]. 
=============================================
[2019-04-17 15:34:34,867] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.5005915e-12 1.4500908e-16 8.1777406e-01 9.1397118e-10 7.2145996e-09
 6.9757443e-11 4.1907028e-10 5.1340550e-07 7.6606774e-09 2.0936175e-09
 1.8222538e-01], sum to 1.0000
[2019-04-17 15:34:34,867] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0082
[2019-04-17 15:34:34,893] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 23.64774963804786, 0.01056711208601317, 0.0, 1.0, 25.0, 37.10855150835887], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 886800.0000, 
sim time next is 888000.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 23.59795553431868, 0.00990839997947935, 0.0, 1.0, 25.0, 33.11729213121576], 
processed observation next is [1.0, 0.2608695652173913, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.46649629452655655, 0.5033027999931597, 0.0, 1.0, 0.2, 0.33117292131215764], 
reward next is 0.4688, 
noisyNet noise sample is [array([1.4035496], dtype=float32), -0.68973124]. 
=============================================
[2019-04-17 15:34:35,219] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2805841e-13 1.5101109e-17 8.0800587e-01 5.5683413e-10 3.8786063e-09
 3.3746942e-12 1.3458742e-10 7.7475647e-08 3.2976941e-09 2.9161043e-10
 1.9199401e-01], sum to 1.0000
[2019-04-17 15:34:35,220] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5918
[2019-04-17 15:34:35,347] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.9, 84.66666666666667, 0.0, 0.0, 22.5, 24.6217452196236, 0.2100004373155582, 1.0, 1.0, 25.0, 30.23351855345443], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 840000.0000, 
sim time next is 841200.0000, 
raw observation next is [-3.899999999999999, 83.33333333333334, 0.0, 0.0, 22.5, 24.18257570261881, 0.149370437493544, 1.0, 1.0, 25.0, 27.561024786412872], 
processed observation next is [1.0, 0.7391304347826086, 0.35457063711911363, 0.8333333333333335, 0.0, 0.0, 0.375, 0.5152146418849007, 0.5497901458311814, 1.0, 1.0, 0.2, 0.27561024786412874], 
reward next is 0.5244, 
noisyNet noise sample is [array([-0.10035869], dtype=float32), -0.12990111]. 
=============================================
[2019-04-17 15:34:38,596] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3861206e-13 1.2129041e-18 9.4965595e-01 1.0409010e-10 9.8381359e-10
 1.6483547e-12 2.8547614e-10 1.9866011e-08 8.3550294e-10 9.7115024e-11
 5.0344035e-02], sum to 1.0000
[2019-04-17 15:34:38,597] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0605
[2019-04-17 15:34:38,639] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [5.0, 100.0, 0.0, 0.0, 22.5, 23.28017423733133, 0.03231821337468396, 1.0, 1.0, 25.0, 30.355690252676922], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 936000.0000, 
sim time next is 937200.0000, 
raw observation next is [5.0, 100.0, 0.0, 0.0, 19.0, 23.31472616410891, 0.0241896244751803, 0.0, 1.0, 25.0, 27.091527061213675], 
processed observation next is [1.0, 0.8695652173913043, 0.6011080332409973, 1.0, 0.0, 0.0, 0.08333333333333333, 0.44289384700907597, 0.5080632081583935, 0.0, 1.0, 0.2, 0.27091527061213677], 
reward next is 0.5291, 
noisyNet noise sample is [array([0.249289], dtype=float32), 0.0048998236]. 
=============================================
[2019-04-17 15:34:44,418] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.75440484e-15 5.04630806e-20 5.64292669e-01 2.00331678e-12
 1.11084156e-10 2.16102398e-14 1.73470960e-11 2.65363980e-08
 1.52557730e-10 1.01337098e-11 4.35707361e-01], sum to 1.0000
[2019-04-17 15:34:44,418] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3794
[2019-04-17 15:34:44,496] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.93333333333333, 81.0, 102.3333333333333, 195.0, 22.5, 27.52124521887396, 1.037066912079787, 1.0, 1.0, 25.0, 20.71990065144012], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1071600.0000, 
sim time next is 1072800.0000, 
raw observation next is [13.3, 80.0, 107.0, 117.0, 22.5, 27.65984978365363, 1.059419542895836, 1.0, 1.0, 25.0, 19.004872142896605], 
processed observation next is [1.0, 0.43478260869565216, 0.8310249307479226, 0.8, 0.3566666666666667, 0.1292817679558011, 0.375, 0.8049874819711359, 0.8531398476319453, 1.0, 1.0, 0.2, 0.19004872142896606], 
reward next is 0.6100, 
noisyNet noise sample is [array([0.08283661], dtype=float32), 0.7290514]. 
=============================================
[2019-04-17 15:34:45,899] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.0368581e-11 6.0288084e-16 5.0050217e-01 2.0715885e-09 1.2160907e-08
 3.7299545e-11 3.1390830e-09 7.3542247e-07 2.3120215e-08 2.7263567e-09
 4.9949700e-01], sum to 1.0000
[2019-04-17 15:34:45,899] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2428
[2019-04-17 15:34:45,918] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.93333333333333, 65.66666666666666, 135.0, 0.0, 19.0, 27.66044952667018, 1.109975999372227, 0.0, 0.0, 65.0, 25.740235829700403], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1161600.0000, 
sim time next is 1162800.0000, 
raw observation next is [18.3, 65.0, 145.0, 0.0, 19.0, 27.70871395593971, 1.112907305001806, 0.0, 0.0, 25.0, 21.732210738793718], 
processed observation next is [0.0, 0.4782608695652174, 0.9695290858725764, 0.65, 0.48333333333333334, 0.0, 0.08333333333333333, 0.8090594963283092, 0.8709691016672686, 0.0, 0.0, 0.2, 0.21732210738793717], 
reward next is 0.5827, 
noisyNet noise sample is [array([2.6634007], dtype=float32), 0.33018565]. 
=============================================
[2019-04-17 15:34:50,500] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [3.1571649e-12 2.1368311e-16 8.6310142e-01 4.6208856e-10 2.0090674e-09
 3.4488209e-12 4.3721635e-10 2.4559662e-07 1.2094891e-08 9.2004432e-10
 1.3689838e-01], sum to 1.0000
[2019-04-17 15:34:50,500] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6571
[2019-04-17 15:34:50,554] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.33333333333333, 81.0, 0.0, 0.0, 19.0, 27.52933538183063, 1.089755093931364, 0.0, 1.0, 25.0, 26.3081771254107], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1147200.0000, 
sim time next is 1148400.0000, 
raw observation next is [12.7, 80.0, 0.0, 0.0, 19.0, 27.53456794211408, 1.089964446253337, 0.0, 1.0, 25.0, 26.16665042512598], 
processed observation next is [0.0, 0.30434782608695654, 0.8144044321329641, 0.8, 0.0, 0.0, 0.08333333333333333, 0.7945473285095067, 0.8633214820844457, 0.0, 1.0, 0.2, 0.2616665042512598], 
reward next is 0.5383, 
noisyNet noise sample is [array([-1.3417879], dtype=float32), -1.3237783]. 
=============================================
[2019-04-17 15:34:50,911] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4708241e-09 3.5389722e-13 8.7382025e-01 3.1898267e-08 2.4750065e-07
 3.2425429e-09 7.3303035e-08 4.2768584e-06 5.6023606e-07 9.9107147e-08
 1.2617445e-01], sum to 1.0000
[2019-04-17 15:34:50,912] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5590
[2019-04-17 15:34:50,935] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.9, 65.66666666666667, 0.0, 0.0, 19.0, 27.93724838044233, 1.177985861169957, 0.0, 0.0, 25.0, 19.889181642829104], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1190400.0000, 
sim time next is 1191600.0000, 
raw observation next is [17.7, 67.0, 0.0, 0.0, 19.0, 27.90767674471696, 1.176735014717426, 0.0, 0.0, 25.0, 20.96073249636723], 
processed observation next is [0.0, 0.8260869565217391, 0.9529085872576178, 0.67, 0.0, 0.0, 0.08333333333333333, 0.8256397287264132, 0.8922450049058087, 0.0, 0.0, 0.2, 0.2096073249636723], 
reward next is 0.5904, 
noisyNet noise sample is [array([0.36129478], dtype=float32), 0.0896559]. 
=============================================
[2019-04-17 15:34:53,731] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4127244e-13 2.3867474e-18 9.1363728e-01 1.5390382e-10 1.3791173e-09
 1.3489602e-12 6.4841271e-11 7.2135855e-08 1.0713548e-09 2.4049124e-10
 8.6362585e-02], sum to 1.0000
[2019-04-17 15:34:53,731] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7197
[2019-04-17 15:34:53,798] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.266666666666667, 92.0, 0.0, 0.0, 19.0, 26.08276000049418, 0.7426906633375913, 0.0, 1.0, 25.0, 9.273817174795486], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1320000.0000, 
sim time next is 1321200.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 19.0, 25.99294839381275, 0.7111799359691934, 0.0, 1.0, 25.0, 8.823708332831288], 
processed observation next is [1.0, 0.30434782608695654, 0.49307479224376743, 0.92, 0.0, 0.0, 0.08333333333333333, 0.6660790328177292, 0.7370599786563977, 0.0, 1.0, 0.2, 0.08823708332831287], 
reward next is 0.7118, 
noisyNet noise sample is [array([-0.23338288], dtype=float32), 1.3005314]. 
=============================================
[2019-04-17 15:34:55,871] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.9505667e-14 2.4798089e-18 9.4481009e-01 2.2633628e-11 1.0977639e-09
 9.0878233e-14 2.1812722e-11 4.0074063e-08 1.3067029e-10 8.1872044e-11
 5.5189885e-02], sum to 1.0000
[2019-04-17 15:34:55,875] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9532
[2019-04-17 15:34:55,913] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [0.0, 95.0, 59.0, 0.0, 22.5, 26.30345513124175, 0.6800775140724852, 1.0, 1.0, 25.0, 23.080428236349157], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 1418400.0000, 
sim time next is 1419600.0000, 
raw observation next is [0.0, 95.0, 67.66666666666667, 0.0, 22.5, 26.32979305790622, 0.7156277470811526, 1.0, 1.0, 65.0, 51.09602193160568], 
processed observation next is [1.0, 0.43478260869565216, 0.46260387811634357, 0.95, 0.22555555555555556, 0.0, 0.375, 0.694149421492185, 0.7385425823603842, 1.0, 1.0, 1.0, 0.5109602193160567], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01967482], dtype=float32), -0.24584281]. 
=============================================
[2019-04-17 15:34:57,345] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.5882643e-13 1.6484196e-18 9.1290808e-01 1.5010150e-10 3.7993577e-09
 1.1558298e-12 3.5256723e-10 1.1437797e-07 2.1732445e-09 2.0534492e-10
 8.7091900e-02], sum to 1.0000
[2019-04-17 15:34:57,345] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3049
[2019-04-17 15:34:57,369] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.433333333333334, 90.0, 0.0, 0.0, 19.0, 25.63926374455601, 0.6392456906889644, 0.0, 1.0, 25.0, 22.245093564643483], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1459200.0000, 
sim time next is 1460400.0000, 
raw observation next is [1.266666666666667, 91.0, 0.0, 0.0, 19.0, 25.55829432714233, 0.6180119994918082, 0.0, 1.0, 25.0, 20.460017532789085], 
processed observation next is [1.0, 0.9130434782608695, 0.4976915974145891, 0.91, 0.0, 0.0, 0.08333333333333333, 0.6298578605951942, 0.7060039998306027, 0.0, 1.0, 0.2, 0.20460017532789085], 
reward next is 0.5954, 
noisyNet noise sample is [array([1.1648458], dtype=float32), -0.69920963]. 
=============================================
[2019-04-17 15:35:08,798] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8277431e-13 2.9775001e-18 9.6783495e-01 4.3487273e-11 6.7267519e-10
 4.7565375e-13 4.5397373e-11 2.7592245e-08 3.1516412e-10 1.2456468e-10
 3.2164976e-02], sum to 1.0000
[2019-04-17 15:35:08,798] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3577
[2019-04-17 15:35:08,888] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.3, 51.0, 64.0, 18.5, 22.5, 24.82059993921175, 0.3108635422266874, 1.0, 1.0, 25.0, 6.07395385302126], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1612800.0000, 
sim time next is 1614000.0000, 
raw observation next is [12.93333333333334, 52.00000000000001, 54.66666666666667, 30.83333333333334, 22.5, 24.54698646916655, 0.2834324757864056, 1.0, 1.0, 25.0, 6.305634455108784], 
processed observation next is [1.0, 0.6956521739130435, 0.8208679593721148, 0.52, 0.18222222222222223, 0.03406998158379374, 0.375, 0.5455822057638793, 0.594477491928802, 1.0, 1.0, 0.2, 0.06305634455108784], 
reward next is 0.7369, 
noisyNet noise sample is [array([-0.09274612], dtype=float32), 1.2074261]. 
=============================================
[2019-04-17 15:35:12,486] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.9163368e-14 3.8221677e-19 9.6021640e-01 2.4676174e-11 1.7351735e-10
 2.4769564e-13 1.1891494e-11 7.9663955e-09 1.5546137e-10 4.5986645e-11
 3.9783545e-02], sum to 1.0000
[2019-04-17 15:35:12,487] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7466
[2019-04-17 15:35:12,567] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [10.13333333333333, 62.66666666666667, 0.0, 0.0, 22.5, 25.82105747736771, 0.6341805174549406, 1.0, 1.0, 25.0, 5.2806514005738086], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1621200.0000, 
sim time next is 1622400.0000, 
raw observation next is [9.766666666666667, 64.33333333333334, 0.0, 0.0, 22.5, 25.74879814798053, 0.6168733187921663, 0.0, 1.0, 25.0, 5.490513285671976], 
processed observation next is [1.0, 0.782608695652174, 0.7331486611265007, 0.6433333333333334, 0.0, 0.0, 0.375, 0.6457331789983775, 0.7056244395973889, 0.0, 1.0, 0.2, 0.05490513285671976], 
reward next is 0.7451, 
noisyNet noise sample is [array([1.3785449], dtype=float32), 2.5137253]. 
=============================================
[2019-04-17 15:35:18,082] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0246337e-10 1.4708529e-14 9.4081402e-01 1.1581415e-08 3.4378505e-08
 3.2093803e-10 8.2641654e-09 1.4671282e-06 8.7029683e-08 2.5048442e-08
 5.9184399e-02], sum to 1.0000
[2019-04-17 15:35:18,082] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3704
[2019-04-17 15:35:18,173] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 19.0, 21.02772037179693, -0.55435788910862, 0.0, 1.0, 25.0, 34.77101686602115], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1790400.0000, 
sim time next is 1791600.0000, 
raw observation next is [-3.899999999999999, 82.0, 0.0, 0.0, 19.0, 20.98950342946151, -0.571385551186485, 0.0, 1.0, 25.0, 30.85109181659159], 
processed observation next is [0.0, 0.7391304347826086, 0.35457063711911363, 0.82, 0.0, 0.0, 0.08333333333333333, 0.24912528578845924, 0.309538149604505, 0.0, 1.0, 0.2, 0.3085109181659159], 
reward next is 0.4915, 
noisyNet noise sample is [array([-0.6563511], dtype=float32), 1.3400418]. 
=============================================
[2019-04-17 15:35:20,637] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9191916e-14 5.7298698e-20 9.7619265e-01 1.5542257e-11 1.2445876e-10
 5.4802967e-14 1.1574835e-11 1.3522929e-08 6.8469133e-11 1.2804039e-11
 2.3807319e-02], sum to 1.0000
[2019-04-17 15:35:20,637] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2902
[2019-04-17 15:35:20,729] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.3333333333333333, 93.0, 0.0, 0.0, 19.0, 23.72168465523883, 0.1328107255006362, 0.0, 1.0, 25.0, 24.75885881144906], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1726800.0000, 
sim time next is 1728000.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 19.0, 23.563789192273, 0.1040113392879602, 0.0, 1.0, 25.0, 22.4097090635654], 
processed observation next is [0.0, 0.0, 0.4764542936288089, 0.92, 0.0, 0.0, 0.08333333333333333, 0.4636490993560833, 0.53467044642932, 0.0, 1.0, 0.2, 0.224097090635654], 
reward next is 0.5759, 
noisyNet noise sample is [array([-1.5570846], dtype=float32), -3.154467]. 
=============================================
[2019-04-17 15:35:37,928] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.7402585e-11 2.7480072e-15 8.6559647e-01 3.3085619e-09 2.5723661e-08
 7.4845338e-11 4.2283346e-09 1.2904089e-06 1.8858028e-08 9.1541565e-09
 1.3440219e-01], sum to 1.0000
[2019-04-17 15:35:37,928] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8604
[2019-04-17 15:35:37,941] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.4, 89.33333333333334, 0.0, 0.0, 19.0, 19.62633140686022, -0.9913315407861413, 0.0, 1.0, 25.0, 28.413828295551365], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2086800.0000, 
sim time next is 2088000.0000, 
raw observation next is [-5.6, 91.0, 0.0, 0.0, 19.0, 19.55234597996969, -0.9946933940518181, 0.0, 1.0, 25.0, 25.757700443328098], 
processed observation next is [1.0, 0.17391304347826086, 0.30747922437673136, 0.91, 0.0, 0.0, 0.08333333333333333, 0.1293621649974742, 0.16843553531606062, 0.0, 1.0, 0.2, 0.25757700443328096], 
reward next is 0.5424, 
noisyNet noise sample is [array([-1.2203456], dtype=float32), -0.8689671]. 
=============================================
[2019-04-17 15:35:56,882] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.2642106e-13 3.7271064e-17 9.4092774e-01 1.2333945e-10 5.0061261e-10
 5.3786446e-13 5.7661906e-11 2.9165607e-08 4.2652404e-10 1.9623614e-10
 5.9072278e-02], sum to 1.0000
[2019-04-17 15:35:56,882] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3478
[2019-04-17 15:35:57,004] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.9, 70.0, 124.0, 0.0, 22.5, 24.09320799313686, -0.1269155391572972, 1.0, 1.0, 25.0, 29.76261980126654], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2211600.0000, 
sim time next is 2212800.0000, 
raw observation next is [-3.899999999999999, 69.0, 126.1666666666667, 47.49999999999999, 22.5, 23.81166030202168, -0.06210846515931983, 1.0, 1.0, 25.0, 26.30204744432542], 
processed observation next is [1.0, 0.6086956521739131, 0.35457063711911363, 0.69, 0.4205555555555557, 0.05248618784530386, 0.375, 0.48430502516847324, 0.4792971782802267, 1.0, 1.0, 0.2, 0.2630204744432542], 
reward next is 0.5370, 
noisyNet noise sample is [array([2.1101894], dtype=float32), -0.33673006]. 
=============================================
[2019-04-17 15:36:04,098] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.07411857e-11 1.25690266e-15 8.89416277e-01 3.03275938e-09
 6.65246702e-09 1.04858691e-10 1.91770555e-09 8.08415109e-07
 4.56474751e-08 2.91019719e-09 1.10582806e-01], sum to 1.0000
[2019-04-17 15:36:04,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1448
[2019-04-17 15:36:04,122] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.633333333333333, 64.0, 136.0, 435.0, 19.0, 23.65390250210538, 0.01672458795953898, 0.0, 1.0, 25.0, 47.77240857527865], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2370000.0000, 
sim time next is 2371200.0000, 
raw observation next is [-2.466666666666667, 63.0, 143.6666666666667, 426.0, 19.0, 23.62575389556502, 0.009098075905985529, 0.0, 1.0, 25.0, 40.13780653582928], 
processed observation next is [0.0, 0.43478260869565216, 0.39427516158818104, 0.63, 0.47888888888888903, 0.4707182320441989, 0.08333333333333333, 0.46881282463041823, 0.5030326919686618, 0.0, 1.0, 0.2, 0.4013780653582928], 
reward next is 0.3986, 
noisyNet noise sample is [array([1.1695237], dtype=float32), 1.0335555]. 
=============================================
[2019-04-17 15:36:23,178] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3266150e-08 5.2613647e-12 9.3437016e-01 2.5401440e-07 3.1510081e-07
 2.0645619e-08 3.2596688e-07 8.2160477e-06 2.1157764e-06 1.7659210e-07
 6.5618411e-02], sum to 1.0000
[2019-04-17 15:36:23,178] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0160
[2019-04-17 15:36:23,253] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.3, 25.66666666666667, 50.33333333333333, 345.8333333333333, 19.0, 20.56513235957332, -0.7721414037922664, 0.0, 1.0, 25.0, 16.56332052403371], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2478000.0000, 
sim time next is 2479200.0000, 
raw observation next is [3.3, 25.33333333333333, 41.0, 239.6666666666667, 19.0, 20.60042684983003, -0.774560861538727, 0.0, 1.0, 25.0, 15.099914083972244], 
processed observation next is [0.0, 0.6956521739130435, 0.554016620498615, 0.2533333333333333, 0.13666666666666666, 0.2648250460405157, 0.08333333333333333, 0.21670223748583575, 0.24181304615375765, 0.0, 1.0, 0.2, 0.15099914083972243], 
reward next is 0.6490, 
noisyNet noise sample is [array([0.5575407], dtype=float32), -1.637996]. 
=============================================
[2019-04-17 15:36:25,566] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6906652e-10 1.5931061e-13 8.4102643e-01 2.2425484e-08 1.3891743e-07
 1.1459339e-09 2.5948653e-08 3.6511547e-06 4.2639962e-07 1.4032332e-08
 1.5896934e-01], sum to 1.0000
[2019-04-17 15:36:25,566] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9183
[2019-04-17 15:36:25,616] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-1.7, 40.0, 0.0, 0.0, 19.0, 21.160953543898, -0.6801738696151588, 0.0, 1.0, 25.0, 28.29062899671068], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2514000.0000, 
sim time next is 2515200.0000, 
raw observation next is [-1.7, 42.0, 0.0, 0.0, 19.0, 21.09525552016663, -0.6416015156791266, 0.0, 1.0, 65.0, 62.34796910161384], 
processed observation next is [1.0, 0.08695652173913043, 0.4155124653739613, 0.42, 0.0, 0.0, 0.08333333333333333, 0.25793796001388597, 0.2861328281069578, 0.0, 1.0, 1.0, 0.6234796910161384], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5256333], dtype=float32), -0.5545463]. 
=============================================
[2019-04-17 15:36:28,860] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4546532e-12 7.8384819e-17 8.5808927e-01 1.2201297e-09 4.4942792e-09
 1.3798204e-11 2.7053745e-10 4.1912753e-07 3.1735947e-09 9.1909114e-10
 1.4191031e-01], sum to 1.0000
[2019-04-17 15:36:28,860] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7424
[2019-04-17 15:36:28,920] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-9.0, 69.0, 0.0, 0.0, 19.0, 22.51471385519208, -0.2789595204038711, 0.0, 1.0, 25.0, 34.0043885886782], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2682000.0000, 
sim time next is 2683200.0000, 
raw observation next is [-9.666666666666668, 71.33333333333334, 0.0, 0.0, 19.0, 22.37851718566981, -0.3187183708982871, 0.0, 1.0, 25.0, 30.64565353267895], 
processed observation next is [1.0, 0.043478260869565216, 0.19482917820867957, 0.7133333333333334, 0.0, 0.0, 0.08333333333333333, 0.3648764321391509, 0.39376054303390434, 0.0, 1.0, 0.2, 0.3064565353267895], 
reward next is 0.4935, 
noisyNet noise sample is [array([0.8972487], dtype=float32), -0.71475196]. 
=============================================
[2019-04-17 15:36:30,159] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1341913e-11 2.8575213e-15 9.5113325e-01 2.1637676e-09 2.2454662e-08
 4.9737638e-11 6.4340799e-09 3.6130663e-07 2.4927255e-08 2.9161416e-09
 4.8866451e-02], sum to 1.0000
[2019-04-17 15:36:30,159] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5419
[2019-04-17 15:36:30,316] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.1333333333333334, 35.33333333333334, 0.0, 0.0, 22.5, 22.0499697304332, -0.3681773694960369, 1.0, 1.0, 25.0, 8.987142747236373], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2571600.0000, 
sim time next is 2572800.0000, 
raw observation next is [-0.2333333333333333, 35.66666666666667, 0.0, 0.0, 22.5, 22.06052207343478, -0.3748888884714094, 1.0, 1.0, 25.0, 9.44220128532522], 
processed observation next is [1.0, 0.782608695652174, 0.456140350877193, 0.3566666666666667, 0.0, 0.0, 0.375, 0.33837683945289826, 0.37503703717619685, 1.0, 1.0, 0.2, 0.0944220128532522], 
reward next is 0.7056, 
noisyNet noise sample is [array([-0.22854471], dtype=float32), -0.9304023]. 
=============================================
[2019-04-17 15:36:36,021] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6160505e-11 8.3852058e-16 9.8683214e-01 1.3688808e-09 3.3495822e-09
 3.8748629e-11 7.0758888e-10 4.7937853e-08 5.4625726e-09 1.1452140e-09
 1.3167822e-02], sum to 1.0000
[2019-04-17 15:36:36,022] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8563
[2019-04-17 15:36:36,061] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.5, 49.0, 141.6666666666667, 192.3333333333333, 22.5, 21.62928261020666, -0.5786528220125178, 1.0, 1.0, 25.0, 13.207777431316579], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2648400.0000, 
sim time next is 2649600.0000, 
raw observation next is [0.5, 50.0, 115.0, 165.0, 22.5, 21.54615869457844, -0.5865830347457653, 1.0, 1.0, 25.0, 13.240531327638195], 
processed observation next is [1.0, 0.6956521739130435, 0.4764542936288089, 0.5, 0.38333333333333336, 0.18232044198895028, 0.375, 0.29551322454820345, 0.30447232175141153, 1.0, 1.0, 0.2, 0.13240531327638194], 
reward next is 0.6241, 
noisyNet noise sample is [array([0.560964], dtype=float32), 0.073721066]. 
=============================================
[2019-04-17 15:36:38,717] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7553701e-10 5.5675188e-14 8.8123155e-01 7.0527655e-08 1.0435307e-07
 8.5974078e-10 1.0059295e-08 3.8597573e-06 1.3421914e-07 2.4833632e-08
 1.1876425e-01], sum to 1.0000
[2019-04-17 15:36:38,769] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4737
[2019-04-17 15:36:38,803] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-7.0, 64.0, 0.0, 0.0, 19.0, 20.47680892970015, -0.7743980304041362, 0.0, 1.0, 25.0, 12.42974071460809], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2786400.0000, 
sim time next is 2787600.0000, 
raw observation next is [-7.0, 64.0, 0.0, 0.0, 19.0, 20.35013834893479, -0.8106243292274672, 0.0, 1.0, 25.0, 16.90657456204446], 
processed observation next is [1.0, 0.2608695652173913, 0.2686980609418283, 0.64, 0.0, 0.0, 0.08333333333333333, 0.19584486241123264, 0.22979189025751093, 0.0, 1.0, 0.2, 0.16906574562044463], 
reward next is 0.6309, 
noisyNet noise sample is [array([1.5593344], dtype=float32), 0.037073366]. 
=============================================
[2019-04-17 15:36:40,435] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6448575e-13 9.2376702e-18 9.1698837e-01 3.2385869e-10 3.4282210e-09
 3.3961501e-12 1.3086046e-10 6.1247469e-08 1.0647555e-09 4.8504967e-10
 8.3011486e-02], sum to 1.0000
[2019-04-17 15:36:40,436] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2869
[2019-04-17 15:36:40,581] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.6, 100.0, 0.0, 0.0, 19.0, 22.17339202438398, -0.3852368313288262, 0.0, 1.0, 25.0, 46.28780954286822], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3124800.0000, 
sim time next is 3126000.0000, 
raw observation next is [2.733333333333333, 100.0, 0.0, 0.0, 19.0, 22.1035505720118, -0.4046702935837008, 0.0, 1.0, 25.0, 41.736456736272544], 
processed observation next is [1.0, 0.17391304347826086, 0.538319482917821, 1.0, 0.0, 0.0, 0.08333333333333333, 0.34196254766765016, 0.36510990213876643, 0.0, 1.0, 0.2, 0.4173645673627254], 
reward next is 0.3826, 
noisyNet noise sample is [array([0.33292958], dtype=float32), 1.40546]. 
=============================================
[2019-04-17 15:36:46,015] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5214637e-13 7.8280866e-18 7.7278692e-01 7.9297777e-11 1.1685329e-09
 1.0006211e-12 1.9353129e-10 1.2034563e-07 6.6106005e-09 2.0102163e-10
 2.2721301e-01], sum to 1.0000
[2019-04-17 15:36:46,015] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8052
[2019-04-17 15:36:46,490] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [0.6666666666666667, 95.33333333333334, 58.33333333333333, 25.99999999999999, 22.5, 22.60379594642973, -0.3448970479272959, 1.0, 1.0, 25.0, 34.680053610749894], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2884800.0000, 
sim time next is 2886000.0000, 
raw observation next is [0.3333333333333334, 97.66666666666666, 53.83333333333333, 0.0, 22.5, 22.81644699278454, -0.2053248323966552, 1.0, 1.0, 65.0, 110.39116261797105], 
processed observation next is [1.0, 0.391304347826087, 0.4718374884579871, 0.9766666666666666, 0.17944444444444443, 0.0, 0.375, 0.4013705827320451, 0.43155838920111494, 1.0, 1.0, 1.0, 1.1039116261797104], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00154148], dtype=float32), 1.7832979]. 
=============================================
[2019-04-17 15:36:54,061] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1814040e-13 5.2211806e-19 9.0839094e-01 5.5083382e-11 2.2523466e-10
 2.4448396e-13 5.2842088e-11 1.7711358e-08 4.9324778e-10 3.0171577e-11
 9.1609061e-02], sum to 1.0000
[2019-04-17 15:36:54,061] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0149
[2019-04-17 15:36:54,161] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.0, 93.0, 77.0, 78.0, 22.5, 23.48757383713431, -0.1377449911260122, 1.0, 1.0, 25.0, 61.68724982044607], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2883600.0000, 
sim time next is 2884800.0000, 
raw observation next is [0.6666666666666667, 95.33333333333334, 58.33333333333333, 25.99999999999999, 22.5, 23.5806912362034, -0.1241950804451685, 1.0, 1.0, 25.0, 49.0037854179365], 
processed observation next is [1.0, 0.391304347826087, 0.4810710987996307, 0.9533333333333335, 0.19444444444444442, 0.028729281767955788, 0.375, 0.46505760301695, 0.45860163985161045, 1.0, 1.0, 0.2, 0.49003785417936496], 
reward next is 0.3100, 
noisyNet noise sample is [array([-0.1512561], dtype=float32), 0.6180071]. 
=============================================
[2019-04-17 15:37:04,691] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4992542e-14 3.2911051e-20 9.6518475e-01 3.0508721e-12 7.8452099e-11
 1.4154160e-13 7.5457548e-12 7.2901263e-09 1.7686740e-10 1.8358030e-11
 3.4815229e-02], sum to 1.0000
[2019-04-17 15:37:04,692] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2344
[2019-04-17 15:37:04,729] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [6.6, 99.0, 71.0, 589.0, 22.5, 23.81612475182144, -0.03555557171809148, 1.0, 1.0, 25.0, 1.116613940872974], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3168000.0000, 
sim time next is 3169200.0000, 
raw observation next is [6.4, 99.33333333333334, 62.33333333333333, 529.0, 22.5, 23.55034612889934, 0.0287376763461063, 1.0, 1.0, 25.0, 1.044935714294647], 
processed observation next is [1.0, 0.6956521739130435, 0.6398891966759004, 0.9933333333333334, 0.20777777777777776, 0.5845303867403315, 0.375, 0.4625288440749449, 0.509579225448702, 1.0, 1.0, 0.2, 0.01044935714294647], 
reward next is 0.7896, 
noisyNet noise sample is [array([0.7989007], dtype=float32), 0.7149956]. 
=============================================
[2019-04-17 15:37:07,847] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1723914e-12 1.6999682e-17 8.2058239e-01 6.4337108e-10 2.1064648e-09
 6.8433280e-12 1.2135620e-10 9.6948177e-08 1.3583561e-09 7.6128592e-10
 1.7941748e-01], sum to 1.0000
[2019-04-17 15:37:07,847] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3791
[2019-04-17 15:37:07,970] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-7.0, 79.33333333333334, 0.0, 0.0, 19.0, 22.80370673724646, -0.03520071140177402, 0.0, 1.0, 65.0, 91.45216212942455], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3284400.0000, 
sim time next is 3285600.0000, 
raw observation next is [-7.0, 74.66666666666667, 0.0, 0.0, 19.0, 23.02068404786952, 0.004384861390465854, 0.0, 1.0, 25.0, 44.62689957608233], 
processed observation next is [1.0, 0.0, 0.2686980609418283, 0.7466666666666667, 0.0, 0.0, 0.08333333333333333, 0.41839033732245995, 0.5014616204634886, 0.0, 1.0, 0.2, 0.4462689957608233], 
reward next is 0.3537, 
noisyNet noise sample is [array([2.0623705], dtype=float32), 0.6400131]. 
=============================================
[2019-04-17 15:37:08,274] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2661998e-12 9.1451203e-18 9.7175390e-01 3.4624881e-10 1.3613360e-09
 7.1961594e-13 1.5639821e-10 8.4393491e-08 6.9308592e-10 2.8666788e-10
 2.8246053e-02], sum to 1.0000
[2019-04-17 15:37:08,275] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6347
[2019-04-17 15:37:08,329] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 52.0, 115.5, 814.5, 22.5, 24.18911747272096, 0.1893327077745291, 1.0, 1.0, 25.0, 11.01091020857246], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3502800.0000, 
sim time next is 3504000.0000, 
raw observation next is [2.333333333333333, 51.0, 115.1666666666667, 808.8333333333334, 22.5, 24.39197324819179, 0.2248411093325913, 1.0, 1.0, 25.0, 9.682336799913429], 
processed observation next is [1.0, 0.5652173913043478, 0.5272391505078486, 0.51, 0.383888888888889, 0.8937384898710866, 0.375, 0.5326644373493158, 0.5749470364441971, 1.0, 1.0, 0.2, 0.0968233679991343], 
reward next is 0.7032, 
noisyNet noise sample is [array([0.37744576], dtype=float32), -0.56309134]. 
=============================================
[2019-04-17 15:37:16,866] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3696268e-13 7.8506513e-18 9.4604951e-01 5.3864843e-11 8.4257668e-10
 1.0774566e-12 2.1073962e-10 2.6348534e-08 2.0913165e-09 1.3595398e-10
 5.3950433e-02], sum to 1.0000
[2019-04-17 15:37:16,866] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7983
[2019-04-17 15:37:16,925] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.333333333333333, 71.0, 87.66666666666667, 699.8333333333334, 22.5, 23.34950933411795, -0.0456120914631219, 1.0, 1.0, 25.0, 8.846379846576074], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3252000.0000, 
sim time next is 3253200.0000, 
raw observation next is [-2.666666666666667, 71.0, 80.66666666666667, 656.8333333333334, 22.5, 23.40681468795828, -0.03330980038825462, 1.0, 1.0, 25.0, 8.774188560945198], 
processed observation next is [1.0, 0.6521739130434783, 0.38873499538319484, 0.71, 0.2688888888888889, 0.7257826887661142, 0.375, 0.4505678906631901, 0.48889673320391513, 1.0, 1.0, 0.2, 0.08774188560945198], 
reward next is 0.7123, 
noisyNet noise sample is [array([-0.5227609], dtype=float32), -0.9603915]. 
=============================================
[2019-04-17 15:37:18,960] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-17 15:37:19,005] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-17 15:37:19,005] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:37:19,007] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res1/Eplus-env-sub_run6
[2019-04-17 15:37:19,069] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation job starts!
[2019-04-17 15:37:19,069] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:37:19,071] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v1-res1/Eplus-env-sub_run6
[2019-04-17 15:37:19,123] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation job starts!
[2019-04-17 15:37:19,124] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:37:19,126] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v2-res1/Eplus-env-sub_run6
[2019-04-17 15:37:52,894] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.1728672], dtype=float32), 0.20424978]
[2019-04-17 15:37:52,894] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:Observation this: [12.13333333333333, 80.33333333333334, 0.0, 0.0, 19.0, 25.16389467416558, 0.4837066269801202, 0.0, 1.0, 25.0, 15.531323144391266]
[2019-04-17 15:37:52,895] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-04-17 15:37:52,895] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Softmax [1.8419123e-13 4.0017749e-18 9.4677168e-01 7.8782807e-11 3.7133055e-10
 1.1059444e-12 4.7775346e-11 2.4177256e-08 1.0626858e-09 8.6501563e-11
 5.3228360e-02], sampled 0.36135970377751914
[2019-04-17 15:38:30,486] A3C_EVAL-Part4-Heavy-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.1728672], dtype=float32), 0.20424978]
[2019-04-17 15:38:30,486] A3C_EVAL-Part4-Heavy-Pit-Test-v2 DEBUG:Observation this: [-2.388039636333333, 13.90906045, 71.16253179333334, 457.2799314333333, 22.5, 22.55038430585691, -0.3156392624824979, 1.0, 1.0, 25.0, 3.8047497720017454]
[2019-04-17 15:38:30,486] A3C_EVAL-Part4-Heavy-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-04-17 15:38:30,487] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Softmax [2.63324185e-09 1.81537608e-12 9.21994328e-01 1.08484485e-07
 3.85487084e-07 5.58894619e-09 1.66392923e-07 4.93766584e-06
 1.11675831e-06 1.52236652e-07 7.79986382e-02], sampled 0.8591559340504248
[2019-04-17 15:38:32,254] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2194.4441 110957.0738 349.4518
[2019-04-17 15:38:32,279] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:32,279] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:32,279] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:32,279] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:32,279] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:32,279] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:32,381] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:32,381] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:32,381] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:32,381] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:32,381] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:32,381] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:38,329] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2116.8607 120813.4274 13.6656
[2019-04-17 15:38:38,349] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:38,349] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:38,349] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:38,349] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:38,349] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:38,349] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:38,459] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:38,459] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:38,459] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:38,459] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:38,459] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:38,459] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:42,106] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2071.5330 122381.5713 -208.8703
[2019-04-17 15:38:42,127] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:42,127] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:42,127] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:42,127] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:42,127] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:42,127] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:38:42,233] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:42,233] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:42,233] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:42,233] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:42,233] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:42,233] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:38:43,129] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 250000, evaluation results [250000.0, 2116.860732162868, 120813.42742265861, 13.665600527332517, 2194.44405839713, 110957.07384089532, 349.45183028334225, 2071.5329770432922, 122381.57132813783, -208.8703036355189]
[2019-04-17 15:38:43,146] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3701759e-12 3.3057155e-16 9.4713628e-01 2.0199875e-09 3.7407104e-09
 4.7061476e-11 8.4200463e-10 1.8331134e-07 8.3530436e-09 2.3460036e-09
 5.2863505e-02], sum to 1.0000
[2019-04-17 15:38:43,146] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7088
[2019-04-17 15:38:43,158] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 19.0, 21.8303725033705, -0.3784162449044992, 0.0, 1.0, 25.0, 13.284311951092569], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3376800.0000, 
sim time next is 3378000.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 21.74474901667995, -0.3924259159811103, 0.0, 1.0, 25.0, 13.395087879992001], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.3120624180566625, 0.3691913613396299, 0.0, 1.0, 0.2, 0.13395087879992001], 
reward next is 0.6660, 
noisyNet noise sample is [array([-0.5476136], dtype=float32), 0.8295373]. 
=============================================
[2019-04-17 15:38:44,597] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8718558e-12 9.2822953e-17 9.1294014e-01 4.9892407e-10 2.3781188e-09
 4.3542713e-12 1.1684197e-10 1.7930830e-07 5.8695107e-09 6.9098394e-10
 8.7059662e-02], sum to 1.0000
[2019-04-17 15:38:44,597] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0051
[2019-04-17 15:38:44,712] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 48.0, 104.0, 711.0, 22.5, 23.14644670726536, -0.1866887015992712, 1.0, 1.0, 25.0, 23.18851132817082], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3405600.0000, 
sim time next is 3406800.0000, 
raw observation next is [2.333333333333333, 48.33333333333333, 107.3333333333333, 746.3333333333334, 22.5, 23.19963708477058, -0.1746210909275781, 1.0, 1.0, 25.0, 20.146536484210102], 
processed observation next is [1.0, 0.43478260869565216, 0.5272391505078486, 0.4833333333333333, 0.3577777777777777, 0.8246777163904236, 0.375, 0.4333030903975483, 0.44179296969080734, 1.0, 1.0, 0.2, 0.20146536484210104], 
reward next is 0.5985, 
noisyNet noise sample is [array([-0.03108458], dtype=float32), 1.1029422]. 
=============================================
[2019-04-17 15:38:46,914] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.72837664e-11 2.50041945e-15 8.84853542e-01 8.00569833e-10
 1.47399701e-08 8.14039322e-11 1.13180232e-09 4.05544085e-07
 8.28555358e-08 3.74608300e-09 1.15145944e-01], sum to 1.0000
[2019-04-17 15:38:46,916] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2525
[2019-04-17 15:38:46,947] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [4.0, 45.0, 116.5, 822.5, 19.0, 24.65139514323162, 0.2140520988422845, 0.0, 1.0, 25.0, 28.209360762855617], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3672000.0000, 
sim time next is 3673200.0000, 
raw observation next is [4.333333333333334, 44.0, 116.8333333333333, 826.8333333333334, 19.0, 24.60100764743844, 0.2124514924896291, 0.0, 1.0, 25.0, 25.484369350003025], 
processed observation next is [0.0, 0.5217391304347826, 0.58264081255771, 0.44, 0.3894444444444443, 0.9136279926335176, 0.08333333333333333, 0.55008397061987, 0.5708171641632097, 0.0, 1.0, 0.2, 0.2548436935000302], 
reward next is 0.5452, 
noisyNet noise sample is [array([-0.93670905], dtype=float32), 0.007934316]. 
=============================================
[2019-04-17 15:38:49,863] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.3735942e-11 2.8423213e-15 8.5918832e-01 3.2973619e-09 7.5552551e-09
 5.4999415e-11 1.2677739e-09 7.9970812e-07 6.7534764e-08 3.1994378e-09
 1.4081082e-01], sum to 1.0000
[2019-04-17 15:38:49,864] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6070
[2019-04-17 15:38:49,894] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [6.0, 43.0, 108.5, 797.0, 19.0, 22.81504167252855, -0.1186362861778528, 0.0, 1.0, 65.0, 74.84500516036229], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3679200.0000, 
sim time next is 3680400.0000, 
raw observation next is [6.0, 44.33333333333334, 105.5, 783.0, 19.0, 23.41216626335968, -0.04392733928358008, 0.0, 1.0, 25.0, 39.077499115771225], 
processed observation next is [0.0, 0.6086956521739131, 0.6288088642659281, 0.4433333333333334, 0.3516666666666667, 0.8651933701657458, 0.08333333333333333, 0.45101385527997334, 0.48535755357213994, 0.0, 1.0, 0.2, 0.39077499115771225], 
reward next is 0.4092, 
noisyNet noise sample is [array([-1.1467438], dtype=float32), -1.9822893]. 
=============================================
[2019-04-17 15:38:52,097] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.1793667e-10 1.4438215e-13 7.9648370e-01 2.8469740e-08 2.5696975e-08
 6.8620548e-10 4.8278611e-08 5.4183142e-06 1.8313007e-07 2.2094369e-08
 2.0351060e-01], sum to 1.0000
[2019-04-17 15:38:52,098] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6181
[2019-04-17 15:38:52,125] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-4.0, 54.0, 112.5, 787.0, 19.0, 21.33179762595253, -0.5383463911769998, 0.0, 1.0, 25.0, 52.57817578401617], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3582000.0000, 
sim time next is 3583200.0000, 
raw observation next is [-3.666666666666667, 54.33333333333334, 113.5, 806.3333333333333, 19.0, 21.43229023202599, -0.528996874066123, 0.0, 1.0, 25.0, 44.86770364072933], 
processed observation next is [0.0, 0.4782608695652174, 0.3610341643582641, 0.5433333333333334, 0.37833333333333335, 0.8909760589318599, 0.08333333333333333, 0.28602418600216595, 0.3236677086446257, 0.0, 1.0, 0.2, 0.44867703640729334], 
reward next is 0.3513, 
noisyNet noise sample is [array([-1.2515599], dtype=float32), 1.0631472]. 
=============================================
[2019-04-17 15:38:55,559] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.6729012e-12 2.0343151e-17 9.5051646e-01 3.8297948e-10 6.7307142e-09
 2.3558067e-11 2.0128472e-10 1.7178411e-07 1.6132837e-09 3.5405426e-10
 4.9483359e-02], sum to 1.0000
[2019-04-17 15:38:55,560] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4772
[2019-04-17 15:38:55,576] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.0, 58.33333333333334, 0.0, 0.0, 19.0, 22.88727712433642, -0.152104652880378, 0.0, 1.0, 25.0, 29.355351138641858], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3878400.0000, 
sim time next is 3879600.0000, 
raw observation next is [-1.0, 56.66666666666667, 0.0, 0.0, 19.0, 22.82849415623906, -0.1612385142766799, 0.0, 1.0, 25.0, 26.035421657894148], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.5666666666666668, 0.0, 0.0, 0.08333333333333333, 0.40237451301992166, 0.44625382857444, 0.0, 1.0, 0.2, 0.2603542165789415], 
reward next is 0.5396, 
noisyNet noise sample is [array([0.05435497], dtype=float32), 2.3377218]. 
=============================================
[2019-04-17 15:38:59,596] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.8379079e-14 1.2508004e-18 9.8692906e-01 1.5780502e-11 1.4869017e-10
 3.1235916e-13 5.2302589e-11 6.9674466e-09 1.1193927e-09 6.9345335e-11
 1.3070932e-02], sum to 1.0000
[2019-04-17 15:38:59,596] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8892
[2019-04-17 15:38:59,619] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.333333333333333, 45.66666666666667, 15.0, 149.1666666666667, 22.5, 23.30373676440437, -0.06068090832498633, 1.0, 1.0, 25.0, 6.093103485377444], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3865200.0000, 
sim time next is 3866400.0000, 
raw observation next is [2.0, 48.0, 0.0, 0.0, 22.5, 23.29489078797637, -0.06619384584834241, 1.0, 1.0, 25.0, 6.824387724645085], 
processed observation next is [1.0, 0.782608695652174, 0.518005540166205, 0.48, 0.0, 0.0, 0.375, 0.44124089899803093, 0.4779353847172192, 1.0, 1.0, 0.2, 0.06824387724645085], 
reward next is 0.7318, 
noisyNet noise sample is [array([0.17012686], dtype=float32), -0.8786765]. 
=============================================
[2019-04-17 15:39:08,736] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6552277e-17 2.3868306e-22 9.9133801e-01 6.2028990e-13 1.5964985e-12
 1.4625618e-15 7.2757359e-14 1.4927611e-10 2.5710545e-12 3.9741886e-13
 8.6620292e-03], sum to 1.0000
[2019-04-17 15:39:08,736] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7078
[2019-04-17 15:39:08,753] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 85.0, 78.0, 0.0, 22.5, 25.39052654015798, 0.495610709530752, 1.0, 1.0, 25.0, 13.207902377532925], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4460400.0000, 
sim time next is 4461600.0000, 
raw observation next is [0.0, 82.66666666666667, 73.33333333333334, 0.0, 22.5, 25.46517101656257, 0.4872401078429098, 1.0, 1.0, 25.0, 12.102618031431923], 
processed observation next is [1.0, 0.6521739130434783, 0.46260387811634357, 0.8266666666666667, 0.24444444444444446, 0.0, 0.375, 0.6220975847135476, 0.6624133692809699, 1.0, 1.0, 0.2, 0.12102618031431923], 
reward next is 0.6790, 
noisyNet noise sample is [array([-0.4061588], dtype=float32), 1.3352878]. 
=============================================
[2019-04-17 15:39:13,470] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.04144761e-14 1.60729444e-18 9.82445955e-01 6.27702577e-12
 3.95393752e-11 1.42945741e-13 9.04633399e-12 6.89256785e-09
 3.36368766e-10 1.14357464e-11 1.75540224e-02], sum to 1.0000
[2019-04-17 15:39:13,470] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8069
[2019-04-17 15:39:13,481] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [4.4, 75.0, 0.0, 0.0, 19.0, 23.81123532545471, 0.03599334898862534, 0.0, 1.0, 25.0, 11.364166252868259], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4316400.0000, 
sim time next is 4317600.0000, 
raw observation next is [4.433333333333334, 75.33333333333334, 0.0, 0.0, 19.0, 23.78987604645389, 0.01941561755458142, 0.0, 1.0, 25.0, 10.704810865409074], 
processed observation next is [0.0, 1.0, 0.5854108956602032, 0.7533333333333334, 0.0, 0.0, 0.08333333333333333, 0.48248967053782427, 0.5064718725181938, 0.0, 1.0, 0.2, 0.10704810865409074], 
reward next is 0.6930, 
noisyNet noise sample is [array([-0.36086616], dtype=float32), -1.85427]. 
=============================================
[2019-04-17 15:39:16,623] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5351171e-15 1.8214915e-20 9.8593509e-01 3.3729144e-12 3.7930815e-11
 1.2146713e-13 2.4397140e-12 1.1737484e-09 1.4977569e-10 3.3508563e-12
 1.4064843e-02], sum to 1.0000
[2019-04-17 15:39:16,623] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9369
[2019-04-17 15:39:16,649] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.0, 50.0, 0.0, 0.0, 22.5, 23.90071825649844, 0.1135962502656229, 1.0, 1.0, 25.0, 5.430491740593416], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4388400.0000, 
sim time next is 4389600.0000, 
raw observation next is [11.66666666666667, 52.66666666666667, 0.0, 0.0, 22.5, 23.94438445018606, 0.1113054094290514, 1.0, 1.0, 25.0, 5.597431764045316], 
processed observation next is [1.0, 0.8260869565217391, 0.785780240073869, 0.5266666666666667, 0.0, 0.0, 0.375, 0.49536537084883836, 0.5371018031430171, 1.0, 1.0, 0.2, 0.05597431764045316], 
reward next is 0.7440, 
noisyNet noise sample is [array([1.4041814], dtype=float32), 0.3489854]. 
=============================================
[2019-04-17 15:39:17,680] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.1236979e-11 1.9758587e-16 9.6118814e-01 1.0009458e-09 3.4150904e-09
 2.4589927e-11 7.9788498e-10 1.4922001e-07 1.3262963e-08 2.3918103e-09
 3.8811758e-02], sum to 1.0000
[2019-04-17 15:39:17,680] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1576
[2019-04-17 15:39:17,708] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 40.0, 16.5, 92.5, 19.0, 23.45805116757109, -0.0495021085473237, 0.0, 1.0, 25.0, 24.43772930832864], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4816800.0000, 
sim time next is 4818000.0000, 
raw observation next is [1.666666666666667, 41.0, 0.0, 0.0, 19.0, 23.33956959324356, -0.07106698782005248, 0.0, 1.0, 25.0, 22.480228930085104], 
processed observation next is [0.0, 0.782608695652174, 0.5087719298245615, 0.41, 0.0, 0.0, 0.08333333333333333, 0.44496413277029667, 0.4763110040599825, 0.0, 1.0, 0.2, 0.22480228930085105], 
reward next is 0.5752, 
noisyNet noise sample is [array([0.04090032], dtype=float32), -0.44597712]. 
=============================================
[2019-04-17 15:39:18,296] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:18,453] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:19,302] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:19,302] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:19,304] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res16/Eplus-env-sub_run5
[2019-04-17 15:39:20,693] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2291864e-11 1.1710222e-15 9.7699350e-01 2.2121305e-09 2.6564255e-09
 2.3939760e-11 8.1132068e-10 1.5615770e-07 2.4742823e-08 3.1887202e-09
 2.3006374e-02], sum to 1.0000
[2019-04-17 15:39:20,694] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0043
[2019-04-17 15:39:20,792] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 19.0, 22.5108406335211, -0.2723277609732025, 0.0, 1.0, 25.0, 10.57600965695767], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4838400.0000, 
sim time next is 4839600.0000, 
raw observation next is [-2.0, 60.00000000000001, 0.0, 0.0, 19.0, 22.40116594835293, -0.3002245289890248, 0.0, 1.0, 25.0, 10.790657057056904], 
processed observation next is [0.0, 0.0, 0.40720221606648205, 0.6000000000000001, 0.0, 0.0, 0.08333333333333333, 0.3667638290294108, 0.3999251570036584, 0.0, 1.0, 0.2, 0.10790657057056904], 
reward next is 0.6921, 
noisyNet noise sample is [array([0.00758587], dtype=float32), -0.028732782]. 
=============================================
[2019-04-17 15:39:22,606] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:23,103] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:23,605] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:23,605] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:23,607] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res14/Eplus-env-sub_run5
[2019-04-17 15:39:24,616] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.0468523e-14 1.1162297e-17 9.8856366e-01 6.0397229e-11 7.5153850e-10
 1.0451571e-12 1.4901487e-10 3.8923211e-08 2.5474167e-09 7.4331527e-11
 1.1436401e-02], sum to 1.0000
[2019-04-17 15:39:24,616] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0714
[2019-04-17 15:39:24,650] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [8.0, 26.0, 110.3333333333333, 825.8333333333333, 22.5, 21.83888749871058, -0.5163375301812729, 1.0, 1.0, 25.0, 2.858941381920995], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4976400.0000, 
sim time next is 4977600.0000, 
raw observation next is [8.0, 26.0, 106.1666666666667, 811.5, 22.5, 21.95084133297786, -0.5614619478372718, 1.0, 1.0, 25.0, 2.7433089804515385], 
processed observation next is [1.0, 0.6086956521739131, 0.6842105263157896, 0.26, 0.353888888888889, 0.8966850828729281, 0.375, 0.3292367777481549, 0.31284601738757606, 1.0, 1.0, 0.2, 0.027433089804515386], 
reward next is 0.7480, 
noisyNet noise sample is [array([-0.22055304], dtype=float32), -0.47707483]. 
=============================================
[2019-04-17 15:39:25,901] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1972398e-15 4.7578665e-21 9.2465776e-01 1.7084562e-12 1.8406072e-11
 4.9388926e-14 9.8082003e-13 2.5015123e-09 8.0406688e-11 3.7979815e-12
 7.5342193e-02], sum to 1.0000
[2019-04-17 15:39:25,951] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2650
[2019-04-17 15:39:26,012] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 92.0, 31.5, 0.0, 22.5, 22.69237511230546, -0.2218156358153579, 1.0, 1.0, 25.0, 15.71785598161318], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4694400.0000, 
sim time next is 4695600.0000, 
raw observation next is [0.0, 92.0, 52.5, 0.0, 22.5, 22.60799796422062, -0.1946029014492848, 1.0, 1.0, 25.0, 14.792384592696486], 
processed observation next is [1.0, 0.34782608695652173, 0.46260387811634357, 0.92, 0.175, 0.0, 0.375, 0.38399983035171825, 0.43513236618357176, 1.0, 1.0, 0.2, 0.14792384592696486], 
reward next is 0.6521, 
noisyNet noise sample is [array([0.98719573], dtype=float32), 0.37153044]. 
=============================================
[2019-04-17 15:39:26,040] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:26,267] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:27,043] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:27,044] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:27,058] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res11/Eplus-env-sub_run5
[2019-04-17 15:39:31,178] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:31,485] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:32,160] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:32,160] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:32,162] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res15/Eplus-env-sub_run5
[2019-04-17 15:39:32,970] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:33,249] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:33,789] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5812831e-14 8.7874850e-19 9.3627393e-01 4.4826483e-11 1.9686650e-10
 7.4023247e-13 2.5977347e-11 2.7553435e-08 2.1729845e-09 1.4515472e-10
 6.3726090e-02], sum to 1.0000
[2019-04-17 15:39:33,789] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7024
[2019-04-17 15:39:33,835] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.666666666666667, 45.0, 109.5, 670.5, 22.5, 21.58907229257917, -0.5358432978557819, 1.0, 1.0, 25.0, 5.587103558171603], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 5044800.0000, 
sim time next is 5046000.0000, 
raw observation next is [2.333333333333333, 43.0, 112.6666666666667, 716.5, 22.5, 21.82381243685172, -0.4934825855118153, 1.0, 1.0, 25.0, 4.179932517835259], 
processed observation next is [1.0, 0.391304347826087, 0.5272391505078486, 0.43, 0.37555555555555564, 0.7917127071823205, 0.375, 0.3186510364043101, 0.3355058048293949, 1.0, 1.0, 0.2, 0.04179932517835259], 
reward next is 0.7582, 
noisyNet noise sample is [array([1.4366913], dtype=float32), 1.2881176]. 
=============================================
[2019-04-17 15:39:33,973] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:33,974] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:33,975] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res5/Eplus-env-sub_run5
[2019-04-17 15:39:35,239] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.41868105e-11 2.62813868e-15 9.40257072e-01 1.70103276e-09
 1.20307941e-08 1.13338006e-10 3.35624217e-09 2.81090962e-07
 6.54944685e-08 2.00756611e-09 5.97424656e-02], sum to 1.0000
[2019-04-17 15:39:35,240] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4290
[2019-04-17 15:39:35,253] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.6666666666666666, 47.66666666666666, 0.0, 0.0, 19.0, 20.10276647617527, -0.8823778963671165, 0.0, 1.0, 25.0, 11.720098929606074], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4930800.0000, 
sim time next is 4932000.0000, 
raw observation next is [-1.0, 50.0, 0.0, 0.0, 19.0, 20.06795832402281, -0.8792745168042205, 0.0, 1.0, 25.0, 11.81548762171583], 
processed observation next is [1.0, 0.08695652173913043, 0.4349030470914128, 0.5, 0.0, 0.0, 0.08333333333333333, 0.17232986033523426, 0.20690849439859316, 0.0, 1.0, 0.2, 0.1181548762171583], 
reward next is 0.6818, 
noisyNet noise sample is [array([-0.14342208], dtype=float32), -1.0518012]. 
=============================================
[2019-04-17 15:39:35,897] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:36,215] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:36,746] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:36,873] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:36,873] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:36,875] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res6/Eplus-env-sub_run5
[2019-04-17 15:39:37,067] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:37,649] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:37,753] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:37,753] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:37,755] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res17/Eplus-env-sub_run5
[2019-04-17 15:39:37,893] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:38,203] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8466564e-14 3.4834069e-18 9.0477306e-01 7.7548079e-11 5.6715621e-10
 1.0426809e-12 2.8701741e-11 2.8201134e-08 6.1329003e-10 8.2038591e-11
 9.5226966e-02], sum to 1.0000
[2019-04-17 15:39:38,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9479
[2019-04-17 15:39:38,388] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-7.3, 68.0, 0.0, 0.0, 22.5, 21.08054085130826, -0.6300129316418005, 0.0, 1.0, 25.0, 52.97871827535507], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 114000.0000, 
sim time next is 115200.0000, 
raw observation next is [-7.3, 68.0, 18.5, 4.5, 22.5, 21.05574746381841, -0.5559704322470089, 1.0, 1.0, 65.0, 92.33791806888405], 
processed observation next is [1.0, 0.34782608695652173, 0.26038781163434904, 0.68, 0.06166666666666667, 0.004972375690607734, 0.375, 0.25464562198486745, 0.3146765225843304, 1.0, 1.0, 1.0, 0.9233791806888405], 
reward next is 0.2799, 
noisyNet noise sample is [array([-0.33244026], dtype=float32), -0.08575962]. 
=============================================
[2019-04-17 15:39:38,593] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:38,594] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:38,596] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res3/Eplus-env-sub_run5
[2019-04-17 15:39:39,977] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:40,259] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:40,977] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:40,977] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:40,979] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res7/Eplus-env-sub_run5
[2019-04-17 15:39:45,297] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:45,515] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:46,296] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:46,296] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:46,341] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res9/Eplus-env-sub_run5
[2019-04-17 15:39:48,449] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:48,793] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:48,825] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:49,136] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:49,436] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:49,436] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:49,452] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res2/Eplus-env-sub_run5
[2019-04-17 15:39:49,788] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:49,788] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:49,790] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res8/Eplus-env-sub_run5
[2019-04-17 15:39:50,199] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:50,364] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:51,176] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:51,176] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:51,178] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res4/Eplus-env-sub_run5
[2019-04-17 15:39:51,562] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:51,990] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:52,478] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6408399e-11 5.9531080e-16 9.7829437e-01 5.3456078e-10 4.5185993e-09
 2.3700991e-11 1.3609646e-09 7.8409322e-08 2.7870493e-08 2.1621753e-09
 2.1705464e-02], sum to 1.0000
[2019-04-17 15:39:52,479] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3932
[2019-04-17 15:39:52,506] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-10.23333333333333, 46.66666666666666, 20.0, 201.0, 22.5, 18.85654477897846, -1.225374516362285, 1.0, 1.0, 25.0, 19.291048685046803], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 319200.0000, 
sim time next is 320400.0000, 
raw observation next is [-10.6, 49.0, 12.0, 123.0, 22.5, 18.86179773800803, -1.400510381049108, 1.0, 1.0, 25.0, 20.0128303337233], 
processed observation next is [1.0, 0.7391304347826086, 0.1689750692520776, 0.49, 0.04, 0.13591160220994475, 0.375, 0.07181647816733576, 0.03316320631696401, 1.0, 1.0, 0.2, 0.200128303337233], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6103677], dtype=float32), 0.3108911]. 
=============================================
[2019-04-17 15:39:52,554] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:52,554] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:52,556] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res12/Eplus-env-sub_run5
[2019-04-17 15:39:53,173] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.2229047e-14 1.2591118e-17 9.7655177e-01 9.5643382e-11 3.3934727e-10
 2.0968617e-12 3.6242148e-11 7.2267956e-09 1.7934444e-09 1.0921838e-10
 2.3448229e-02], sum to 1.0000
[2019-04-17 15:39:53,173] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5329
[2019-04-17 15:39:53,213] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.0, 65.0, 141.0, 0.0, 22.5, 19.7872341563905, -1.009588948306441, 1.0, 1.0, 25.0, 15.99330430299792], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 216000.0000, 
sim time next is 217200.0000, 
raw observation next is [-4.833333333333334, 65.0, 133.0, 0.0, 22.5, 19.80821730046184, -1.00584014870979, 1.0, 1.0, 25.0, 16.25445374453545], 
processed observation next is [1.0, 0.5217391304347826, 0.32871652816251157, 0.65, 0.44333333333333336, 0.0, 0.375, 0.15068477503848676, 0.16471995043006996, 1.0, 1.0, 0.2, 0.1625445374453545], 
reward next is 0.0375, 
noisyNet noise sample is [array([0.36973485], dtype=float32), -0.012547417]. 
=============================================
[2019-04-17 15:39:55,931] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:56,227] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:39:56,574] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:56,760] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-17 15:39:56,933] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:56,933] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:56,935] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res13/Eplus-env-sub_run5
[2019-04-17 15:39:57,221] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:39:57,221] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:39:57,223] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res10/Eplus-env-sub_run5
[2019-04-17 15:40:01,127] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.9292489e-12 1.1231057e-16 9.6688998e-01 8.5705437e-10 6.7999482e-09
 1.0301506e-11 8.1969659e-10 1.3239779e-07 1.1185140e-08 1.8649227e-09
 3.3109840e-02], sum to 1.0000
[2019-04-17 15:40:01,128] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4435
[2019-04-17 15:40:01,356] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-9.866666666666667, 45.66666666666667, 85.0, 736.8333333333334, 22.5, 19.81585731903978, -1.021811384506724, 1.0, 1.0, 25.0, 41.00089572735697], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 304800.0000, 
sim time next is 306000.0000, 
raw observation next is [-9.5, 44.0, 89.0, 694.5, 22.5, 19.72325819876139, -1.043085480491163, 1.0, 1.0, 25.0, 34.476291629801665], 
processed observation next is [1.0, 0.5652173913043478, 0.1994459833795014, 0.44, 0.2966666666666667, 0.7674033149171271, 0.375, 0.14360484989678243, 0.15230483983627904, 1.0, 1.0, 0.2, 0.34476291629801664], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.030279], dtype=float32), -2.3639188]. 
=============================================
[2019-04-17 15:40:02,094] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.00867606 0.00209242 0.4061063  0.03019087 0.0191572  0.01631382
 0.03122199 0.04062201 0.03452915 0.01775155 0.39333868], sum to 1.0000
[2019-04-17 15:40:02,095] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4307
[2019-04-17 15:40:02,151] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 21.00409290560645, -0.75, 0.0, 1.0, 40.0, 27.21893199633566], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 0.0000, 
sim time next is 1200.0000, 
raw observation next is [2.4, 95.33333333333334, 0.0, 0.0, 19.0, 20.99774320031207, -0.537292254515722, 0.0, 1.0, 30.0, 21.661460595120065], 
processed observation next is [0.0, 0.0, 0.5290858725761773, 0.9533333333333335, 0.0, 0.0, 0.08333333333333333, 0.24981193335933907, 0.32090258182809267, 0.0, 1.0, 0.3, 0.21661460595120066], 
reward next is 0.4834, 
noisyNet noise sample is [array([-0.03459688], dtype=float32), -0.9507145]. 
=============================================
[2019-04-17 15:40:04,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0238993e-14 9.1097184e-19 9.1266370e-01 1.0116459e-11 2.9246043e-11
 1.4574717e-13 1.4421537e-11 3.1619833e-09 1.1116682e-09 3.7800427e-12
 8.7336279e-02], sum to 1.0000
[2019-04-17 15:40:04,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7982
[2019-04-17 15:40:04,632] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 19.0, 21.66855109984005, -0.3255937685670007, 0.0, 1.0, 65.0, 78.39122907138034], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 26400.0000, 
sim time next is 27600.0000, 
raw observation next is [7.699999999999999, 93.0, 0.0, 0.0, 19.0, 22.1805276023082, -0.2653078449842223, 0.0, 1.0, 25.0, 42.26435571191891], 
processed observation next is [0.0, 0.30434782608695654, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.34837730019234997, 0.4115640516719259, 0.0, 1.0, 0.2, 0.4226435571191891], 
reward next is 0.3774, 
noisyNet noise sample is [array([0.11828728], dtype=float32), -0.16601503]. 
=============================================
[2019-04-17 15:40:24,316] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4766186e-13 3.7680368e-18 8.6093515e-01 4.0013944e-11 7.2774209e-10
 1.2952912e-12 1.1278989e-10 1.3446080e-08 1.0054523e-09 1.5362862e-10
 1.3906480e-01], sum to 1.0000
[2019-04-17 15:40:24,316] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3939
[2019-04-17 15:40:24,637] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-10.6, 52.66666666666667, 102.1666666666667, 674.6666666666666, 22.5, 23.35426777614817, -0.09078479603243834, 1.0, 1.0, 65.0, 101.46514807162578], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 301200.0000, 
sim time next is 302400.0000, 
raw observation next is [-10.6, 49.0, 94.5, 708.0, 22.5, 24.11353820133281, -0.01190315041792753, 1.0, 1.0, 25.0, 53.437624165345326], 
processed observation next is [1.0, 0.5217391304347826, 0.1689750692520776, 0.49, 0.315, 0.7823204419889502, 0.375, 0.509461516777734, 0.4960322831940242, 1.0, 1.0, 0.2, 0.5343762416534532], 
reward next is 0.2656, 
noisyNet noise sample is [array([0.2774375], dtype=float32), -0.55058134]. 
=============================================
[2019-04-17 15:40:30,049] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.1555384e-11 7.5289466e-16 8.7196159e-01 3.3979120e-10 6.0970322e-09
 1.7222104e-11 1.9898527e-09 1.1608579e-07 1.1727169e-08 9.0082125e-10
 1.2803829e-01], sum to 1.0000
[2019-04-17 15:40:30,049] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8171
[2019-04-17 15:40:30,101] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.9, 53.0, 0.0, 0.0, 22.5, 20.51876509675131, -0.7476727632659247, 1.0, 1.0, 25.0, 13.836236321496155], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 759600.0000, 
sim time next is 760800.0000, 
raw observation next is [-4.266666666666667, 54.66666666666667, 0.0, 0.0, 22.5, 20.50566789854508, -0.757310678384374, 1.0, 1.0, 25.0, 14.20091338450622], 
processed observation next is [1.0, 0.8260869565217391, 0.3444136657433057, 0.5466666666666667, 0.0, 0.0, 0.375, 0.20880565821209007, 0.24756310720520866, 1.0, 1.0, 0.2, 0.1420091338450622], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.01008665], dtype=float32), -1.9762837]. 
=============================================
[2019-04-17 15:40:32,362] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.1838779e-13 1.0684143e-18 7.3077309e-01 2.3722753e-11 3.8636283e-10
 4.9095466e-13 2.7146650e-11 4.1352095e-08 3.8083819e-10 4.4445225e-11
 2.6922691e-01], sum to 1.0000
[2019-04-17 15:40:32,362] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.1649
[2019-04-17 15:40:32,597] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-13.0, 54.0, 58.0, 787.5, 22.5, 23.22736037808508, -0.227585270492484, 1.0, 1.0, 25.0, 49.26805101007082], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 387600.0000, 
sim time next is 388800.0000, 
raw observation next is [-12.8, 51.0, 58.0, 834.5, 22.5, 23.44867480829141, -0.2019435869766274, 1.0, 1.0, 25.0, 40.42538731206633], 
processed observation next is [1.0, 0.5217391304347826, 0.1080332409972299, 0.51, 0.19333333333333333, 0.9220994475138121, 0.375, 0.45405623402428424, 0.4326854710077909, 1.0, 1.0, 0.2, 0.4042538731206633], 
reward next is 0.3957, 
noisyNet noise sample is [array([0.10179929], dtype=float32), -0.13801903]. 
=============================================
[2019-04-17 15:40:35,073] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.6465006e-12 2.1618519e-16 9.2193234e-01 2.6191602e-09 1.2824148e-08
 3.0186482e-11 1.9880306e-09 3.4251565e-07 5.4383777e-09 1.3401649e-09
 7.8067370e-02], sum to 1.0000
[2019-04-17 15:40:35,073] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4737
[2019-04-17 15:40:35,151] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-10.2, 43.66666666666667, 0.0, 0.0, 19.0, 21.46932980582393, -0.5507255303477734, 0.0, 1.0, 65.0, 83.21848309513825], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 418800.0000, 
sim time next is 420000.0000, 
raw observation next is [-10.4, 45.33333333333334, 0.0, 0.0, 19.0, 21.87813899412542, -0.5328799807889288, 0.0, 1.0, 25.0, 53.365803133517495], 
processed observation next is [1.0, 0.8695652173913043, 0.1745152354570637, 0.4533333333333334, 0.0, 0.0, 0.08333333333333333, 0.32317824951045154, 0.3223733397370237, 0.0, 1.0, 0.2, 0.533658031335175], 
reward next is 0.2663, 
noisyNet noise sample is [array([0.6633479], dtype=float32), -0.05016131]. 
=============================================
[2019-04-17 15:40:35,175] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[46.231297]
 [45.33506 ]
 [45.60052 ]
 [45.439453]
 [45.2756  ]
 [44.96152 ]
 [44.01559 ]
 [42.85736 ]
 [43.089256]
 [43.449776]
 [43.896473]
 [44.298634]
 [44.668804]
 [45.049023]
 [45.38325 ]
 [45.723835]
 [46.02542 ]
 [46.383278]
 [46.795425]
 [47.369102]
 [47.70122 ]
 [48.158573]
 [48.451767]
 [48.772358]
 [48.96202 ]], R is [[45.56605148]
 [45.11038971]
 [45.05407333]
 [45.04187775]
 [44.8841362 ]
 [44.61199188]
 [44.20246887]
 [44.53368759]
 [44.0883522 ]
 [43.64746857]
 [43.21099472]
 [43.2584343 ]
 [43.64142609]
 [43.40760422]
 [43.71341324]
 [43.95009613]
 [43.95689011]
 [44.18490219]
 [44.43803406]
 [44.67858505]
 [44.77016449]
 [44.97662354]
 [45.12179947]
 [45.24707794]
 [45.3547821 ]].
[2019-04-17 15:40:43,379] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8882489e-16 5.7069237e-22 9.0430713e-01 1.1718569e-12 8.1265611e-12
 9.0057932e-15 1.2285219e-12 4.4709755e-10 5.2017061e-11 2.5247814e-12
 9.5692888e-02], sum to 1.0000
[2019-04-17 15:40:43,379] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8613
[2019-04-17 15:40:43,414] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [4.4, 93.0, 36.0, 0.0, 22.5, 25.99423821443419, 0.593838431306253, 1.0, 1.0, 25.0, 30.814958945645877], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 921600.0000, 
sim time next is 922800.0000, 
raw observation next is [4.600000000000001, 92.66666666666667, 24.0, 0.0, 22.5, 26.2525072505183, 0.613778029756441, 1.0, 1.0, 25.0, 25.65696991173104], 
processed observation next is [1.0, 0.6956521739130435, 0.5900277008310251, 0.9266666666666667, 0.08, 0.0, 0.375, 0.6877089375431916, 0.7045926765854803, 1.0, 1.0, 0.2, 0.25656969911731037], 
reward next is 0.5434, 
noisyNet noise sample is [array([-0.30752245], dtype=float32), -0.2844169]. 
=============================================
[2019-04-17 15:41:05,808] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4202521e-14 8.9879436e-20 9.7977394e-01 9.4718938e-12 3.7125275e-10
 2.8962421e-14 9.3649350e-12 3.3411827e-09 1.5120440e-10 1.3190589e-11
 2.0226000e-02], sum to 1.0000
[2019-04-17 15:41:05,808] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8250
[2019-04-17 15:41:06,024] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.1, 89.33333333333334, 0.0, 0.0, 22.5, 25.43237538134004, 0.423451591271473, 1.0, 1.0, 25.0, 33.131768967297944], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1446000.0000, 
sim time next is 1447200.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 24.89679026210906, 0.4855202094886966, 1.0, 1.0, 25.0, 30.034097442337128], 
processed observation next is [1.0, 0.782608695652174, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.5747325218424217, 0.6618400698295656, 1.0, 1.0, 0.2, 0.30034097442337127], 
reward next is 0.4997, 
noisyNet noise sample is [array([-0.6165293], dtype=float32), -0.3106795]. 
=============================================
[2019-04-17 15:41:07,479] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.4236870e-14 1.8832420e-19 9.2241877e-01 6.7670960e-12 1.2192808e-10
 6.0531854e-14 1.4668414e-11 2.5122990e-09 3.4500869e-10 1.2170078e-11
 7.7581242e-02], sum to 1.0000
[2019-04-17 15:41:07,489] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7329
[2019-04-17 15:41:07,499] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [4.200000000000001, 95.0, 0.0, 0.0, 19.0, 26.92877892422711, 0.9877636172368761, 0.0, 1.0, 25.0, 16.21894312166975], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1297200.0000, 
sim time next is 1298400.0000, 
raw observation next is [4.0, 94.0, 0.0, 0.0, 19.0, 26.88818268573487, 0.9695309454488319, 0.0, 1.0, 25.0, 15.009101021511956], 
processed observation next is [1.0, 0.0, 0.5734072022160666, 0.94, 0.0, 0.0, 0.08333333333333333, 0.7406818904779057, 0.8231769818162773, 0.0, 1.0, 0.2, 0.15009101021511956], 
reward next is 0.6499, 
noisyNet noise sample is [array([0.7563207], dtype=float32), -1.0049313]. 
=============================================
[2019-04-17 15:41:09,405] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.26851189e-15 1.30834495e-20 9.56901371e-01 3.13631911e-12
 7.26773988e-11 2.68463959e-14 5.81747758e-12 2.11274065e-09
 7.31255473e-11 2.99702646e-12 4.30985838e-02], sum to 1.0000
[2019-04-17 15:41:09,406] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1488
[2019-04-17 15:41:09,416] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.5, 92.0, 40.5, 0.0, 22.5, 26.96834620558296, 0.9081426445630488, 1.0, 1.0, 25.0, 13.12460666479811], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1329600.0000, 
sim time next is 1330800.0000, 
raw observation next is [0.5, 92.0, 54.5, 0.0, 22.5, 27.08562946910761, 0.9189390319434021, 1.0, 1.0, 25.0, 12.182654968334084], 
processed observation next is [1.0, 0.391304347826087, 0.4764542936288089, 0.92, 0.18166666666666667, 0.0, 0.375, 0.7571357890923007, 0.8063130106478007, 1.0, 1.0, 0.2, 0.12182654968334085], 
reward next is 0.6782, 
noisyNet noise sample is [array([-0.88960975], dtype=float32), 1.6416669]. 
=============================================
[2019-04-17 15:41:12,243] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2437329e-13 2.0791069e-17 9.2001587e-01 1.3209404e-10 7.1228989e-10
 9.7957005e-13 1.9206012e-10 8.0940454e-09 2.5896043e-09 8.2847373e-10
 7.9984099e-02], sum to 1.0000
[2019-04-17 15:41:12,243] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8705
[2019-04-17 15:41:12,277] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.633333333333333, 79.33333333333334, 0.0, 0.0, 19.0, 21.61467038465904, -0.4710841463606352, 0.0, 1.0, 25.0, 12.26401169788579], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 861600.0000, 
sim time next is 862800.0000, 
raw observation next is [-2.466666666666667, 79.66666666666666, 0.0, 0.0, 19.0, 21.53085506226582, -0.4908095188277945, 0.0, 1.0, 25.0, 11.321247556443364], 
processed observation next is [1.0, 1.0, 0.39427516158818104, 0.7966666666666665, 0.0, 0.0, 0.08333333333333333, 0.29423792185548514, 0.3363968270574018, 0.0, 1.0, 0.2, 0.11321247556443365], 
reward next is 0.6868, 
noisyNet noise sample is [array([-1.2378744], dtype=float32), -0.35500544]. 
=============================================
[2019-04-17 15:41:13,219] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.2771148e-15 7.2148787e-20 8.5740447e-01 9.9830717e-12 1.2724011e-10
 4.6260786e-14 5.3463770e-12 2.2585100e-09 1.4202460e-10 8.4432591e-12
 1.4259553e-01], sum to 1.0000
[2019-04-17 15:41:13,225] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0636
[2019-04-17 15:41:13,300] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.8, 92.0, 0.0, 0.0, 19.0, 25.98134566998669, 0.7107356105509104, 0.0, 1.0, 25.0, 13.93871230263439], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1312800.0000, 
sim time next is 1314000.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 19.0, 25.88626103636393, 0.7068589174973013, 0.0, 1.0, 25.0, 12.917076841095493], 
processed observation next is [1.0, 0.21739130434782608, 0.5069252077562327, 0.92, 0.0, 0.0, 0.08333333333333333, 0.6571884196969942, 0.7356196391657671, 0.0, 1.0, 0.2, 0.12917076841095493], 
reward next is 0.6708, 
noisyNet noise sample is [array([-0.24848853], dtype=float32), 0.079715185]. 
=============================================
[2019-04-17 15:41:17,269] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.1596961e-14 3.6097339e-18 9.2961460e-01 5.6108836e-11 9.0609670e-10
 9.4525722e-13 1.2033809e-10 3.7323240e-08 1.5817548e-09 6.7016954e-11
 7.0385359e-02], sum to 1.0000
[2019-04-17 15:41:17,280] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0696
[2019-04-17 15:41:17,290] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.2, 96.0, 0.0, 0.0, 19.0, 22.41934546569929, -0.1893890845555984, 0.0, 1.0, 25.0, 9.401682124320404], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1484400.0000, 
sim time next is 1485600.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 19.0, 22.35715742717612, -0.2053776251808862, 0.0, 1.0, 25.0, 9.55230288183396], 
processed observation next is [1.0, 0.17391304347826086, 0.5235457063711911, 0.96, 0.0, 0.0, 0.08333333333333333, 0.36309645226467663, 0.4315407916063713, 0.0, 1.0, 0.2, 0.0955230288183396], 
reward next is 0.7045, 
noisyNet noise sample is [array([-0.14177486], dtype=float32), -0.13870426]. 
=============================================
[2019-04-17 15:41:25,854] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0904795e-14 1.0141630e-18 9.8794681e-01 3.1969580e-11 1.4376854e-10
 2.6019925e-13 2.7198445e-11 6.2237384e-09 2.6402813e-10 2.1452022e-11
 1.2053212e-02], sum to 1.0000
[2019-04-17 15:41:25,854] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3533
[2019-04-17 15:41:25,901] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.3333333333333333, 93.0, 0.0, 0.0, 19.0, 21.56674886003376, -0.3678990921770099, 0.0, 1.0, 25.0, 13.539590123810104], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1726800.0000, 
sim time next is 1728000.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 19.0, 21.50446005909405, -0.3833858889938129, 0.0, 1.0, 25.0, 13.612692620965174], 
processed observation next is [0.0, 0.0, 0.4764542936288089, 0.92, 0.0, 0.0, 0.08333333333333333, 0.29203833825783754, 0.37220470366872904, 0.0, 1.0, 0.2, 0.13612692620965172], 
reward next is 0.6639, 
noisyNet noise sample is [array([-0.52293473], dtype=float32), 0.7186485]. 
=============================================
[2019-04-17 15:41:26,675] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7646854e-12 5.4936307e-16 9.8756146e-01 7.5552570e-10 1.5341219e-09
 1.7127803e-11 3.4546771e-10 2.9917395e-08 2.7134467e-08 4.1227691e-10
 1.2438466e-02], sum to 1.0000
[2019-04-17 15:41:26,675] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9160
[2019-04-17 15:41:26,698] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.8, 83.0, 120.1666666666667, 0.0, 19.0, 22.7132797358208, -0.126470882787096, 0.0, 1.0, 25.0, 13.93692679224899], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1776000.0000, 
sim time next is 1777200.0000, 
raw observation next is [-2.8, 83.0, 115.6666666666667, 0.0, 19.0, 22.6439159354527, -0.1369562585917579, 0.0, 1.0, 25.0, 14.04258728633583], 
processed observation next is [0.0, 0.5652173913043478, 0.38504155124653744, 0.83, 0.38555555555555565, 0.0, 0.08333333333333333, 0.38699299462105835, 0.45434791380274736, 0.0, 1.0, 0.2, 0.1404258728633583], 
reward next is 0.6596, 
noisyNet noise sample is [array([-0.37171742], dtype=float32), 0.108651556]. 
=============================================
[2019-04-17 15:41:33,006] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.4582022e-10 1.3706623e-13 9.0428734e-01 2.5418892e-08 4.5572019e-08
 1.1655138e-09 2.7235350e-08 9.0285505e-07 2.3083513e-07 2.4435552e-08
 9.5711417e-02], sum to 1.0000
[2019-04-17 15:41:33,006] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9130
[2019-04-17 15:41:33,065] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-6.0, 83.0, 0.0, 0.0, 19.0, 19.15891119697409, -1.01768093968096, 0.0, 1.0, 25.0, 17.594312325465168], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 1821600.0000, 
sim time next is 1822800.0000, 
raw observation next is [-6.066666666666666, 84.33333333333334, 0.0, 0.0, 19.0, 19.15420629183331, -0.9674663380149617, 0.0, 1.0, 65.0, 94.77359204426088], 
processed observation next is [0.0, 0.08695652173913043, 0.2945521698984303, 0.8433333333333334, 0.0, 0.0, 0.08333333333333333, 0.09618385765277597, 0.17751122066167943, 0.0, 1.0, 1.0, 0.9477359204426088], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2636879], dtype=float32), -0.3816809]. 
=============================================
[2019-04-17 15:41:37,491] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7150682e-14 4.5292166e-19 9.4342405e-01 1.0601903e-11 6.1419236e-10
 1.5327502e-13 1.6215723e-11 8.4829184e-09 3.0322550e-10 2.4596953e-11
 5.6575920e-02], sum to 1.0000
[2019-04-17 15:41:37,491] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8907
[2019-04-17 15:41:37,568] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [6.6, 86.0, 0.0, 0.0, 19.0, 22.98081777139091, -0.003769567766994997, 0.0, 1.0, 25.0, 8.749994731961033], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1634400.0000, 
sim time next is 1635600.0000, 
raw observation next is [6.800000000000001, 84.66666666666667, 0.0, 0.0, 19.0, 22.92759020971263, -0.05132589947286243, 0.0, 1.0, 25.0, 9.030039129105528], 
processed observation next is [1.0, 0.9565217391304348, 0.6509695290858727, 0.8466666666666667, 0.0, 0.0, 0.08333333333333333, 0.4106325174760525, 0.48289136684237915, 0.0, 1.0, 0.2, 0.09030039129105528], 
reward next is 0.7097, 
noisyNet noise sample is [array([1.5121521], dtype=float32), 1.1646844]. 
=============================================
[2019-04-17 15:41:39,789] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.90373586e-14 3.57598321e-19 9.85052228e-01 1.40993285e-11
 3.20208332e-10 1.63071772e-13 2.94449951e-11 4.17032808e-09
 3.61116165e-10 2.60455529e-11 1.49477590e-02], sum to 1.0000
[2019-04-17 15:41:39,789] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5232
[2019-04-17 15:41:39,863] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [7.333333333333334, 74.66666666666667, 0.0, 0.0, 19.0, 23.36163546438934, 0.03974511448574596, 0.0, 1.0, 25.0, 6.901969364373704], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1545600.0000, 
sim time next is 1546800.0000, 
raw observation next is [6.966666666666667, 75.33333333333333, 0.0, 0.0, 19.0, 23.31392591881922, 0.03210888862197079, 0.0, 1.0, 25.0, 7.152190618662807], 
processed observation next is [1.0, 0.9130434782608695, 0.6555863342566944, 0.7533333333333333, 0.0, 0.0, 0.08333333333333333, 0.4428271599016016, 0.5107029628739902, 0.0, 1.0, 0.2, 0.07152190618662807], 
reward next is 0.7285, 
noisyNet noise sample is [array([0.0473879], dtype=float32), 1.2863595]. 
=============================================
[2019-04-17 15:41:40,190] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6383777e-14 8.3057244e-20 9.7974247e-01 6.3468310e-12 1.7501724e-10
 1.1485252e-13 1.1924803e-11 4.0871733e-09 3.4853700e-10 2.1166053e-11
 2.0257529e-02], sum to 1.0000
[2019-04-17 15:41:40,190] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1740
[2019-04-17 15:41:40,301] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.3333333333333333, 93.0, 95.0, 0.0, 22.5, 23.26408557497509, -0.008182007832545546, 1.0, 1.0, 25.0, 14.90511384877168], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1428000.0000, 
sim time next is 1429200.0000, 
raw observation next is [0.5, 92.0, 93.0, 0.0, 22.5, 23.39495757826096, 0.01858943037090805, 1.0, 1.0, 25.0, 13.64799664557185], 
processed observation next is [1.0, 0.5652173913043478, 0.4764542936288089, 0.92, 0.31, 0.0, 0.375, 0.44957979818841337, 0.5061964767903027, 1.0, 1.0, 0.2, 0.1364799664557185], 
reward next is 0.6635, 
noisyNet noise sample is [array([0.7065902], dtype=float32), 0.77544385]. 
=============================================
[2019-04-17 15:41:55,371] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.8689004e-12 7.7315643e-16 9.5832950e-01 1.1759238e-09 3.3797658e-08
 3.5914629e-11 1.0359910e-09 1.5516513e-07 2.2628653e-08 2.7042932e-09
 4.1670352e-02], sum to 1.0000
[2019-04-17 15:41:55,371] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3722
[2019-04-17 15:41:55,439] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.7, 54.66666666666667, 0.0, 0.0, 19.0, 20.39573104547804, -0.7852798597757885, 0.0, 1.0, 25.0, 8.33100036018118], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2323200.0000, 
sim time next is 2324400.0000, 
raw observation next is [-1.7, 55.33333333333333, 0.0, 0.0, 19.0, 20.34840110019073, -0.7945147047880535, 0.0, 1.0, 25.0, 9.350075280717752], 
processed observation next is [1.0, 0.9130434782608695, 0.4155124653739613, 0.5533333333333332, 0.0, 0.0, 0.08333333333333333, 0.19570009168256094, 0.23516176507064881, 0.0, 1.0, 0.2, 0.09350075280717751], 
reward next is 0.7065, 
noisyNet noise sample is [array([-0.69325984], dtype=float32), 0.46663538]. 
=============================================
[2019-04-17 15:42:02,169] A3C_AGENT_WORKER-Thread-8 INFO:Evaluating...
[2019-04-17 15:42:02,171] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-17 15:42:02,171] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:42:02,177] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res1/Eplus-env-sub_run7
[2019-04-17 15:42:02,218] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation job starts!
[2019-04-17 15:42:02,220] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation job starts!
[2019-04-17 15:42:02,220] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:42:02,220] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:42:02,224] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v1-res1/Eplus-env-sub_run7
[2019-04-17 15:42:02,224] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v2-res1/Eplus-env-sub_run7
[2019-04-17 15:43:04,435] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.17463009], dtype=float32), 0.21796732]
[2019-04-17 15:43:04,435] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:Observation this: [-2.366666666666667, 66.66666666666666, 134.1666666666667, 189.1666666666667, 19.0, 22.25200690295001, -0.3379696850358405, 0.0, 1.0, 25.0, 31.405720767070193]
[2019-04-17 15:43:04,435] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-04-17 15:43:04,436] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Softmax [3.1208078e-11 7.1643809e-15 8.7393880e-01 6.2335941e-09 1.8205620e-08
 1.1526586e-10 3.1286780e-09 4.4276808e-07 6.2883025e-08 6.9245347e-09
 1.2606069e-01], sampled 0.1950283154278465
[2019-04-17 15:43:35,864] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2216.5134 108751.0261 254.2435
[2019-04-17 15:43:35,885] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:35,885] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:35,885] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:35,885] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:35,885] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:35,885] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:35,885] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:35,994] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:35,994] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:35,994] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:35,994] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:35,994] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:35,994] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:35,994] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:43,458] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2149.3038 118355.0385 -59.2918
[2019-04-17 15:43:43,478] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:43,478] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:43,478] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:43,478] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:43,478] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:43,478] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:43,478] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:43,585] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:43,585] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:43,585] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:43,585] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:43,585] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:43,585] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:43,585] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:46,469] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2039.6520 122176.3160 -265.6566
[2019-04-17 15:43:46,488] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:46,488] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:46,488] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:46,488] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:46,488] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:46,488] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:46,488] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:43:46,596] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:46,596] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:46,596] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:46,596] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:46,596] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:46,596] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:46,596] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:43:47,489] A3C_AGENT_WORKER-Thread-8 INFO:Global step: 300000, evaluation results [300000.0, 2149.3038398295716, 118355.03853478735, -59.2918143397174, 2216.5134267072112, 108751.02605656708, 254.24345422865917, 2039.6520170203414, 122176.3160256782, -265.6566027200955]
[2019-04-17 15:43:55,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5721350e-12 9.1112052e-17 8.7771523e-01 5.0155963e-10 4.3033537e-09
 1.0356601e-11 9.8118791e-10 3.1434702e-08 9.7564961e-09 4.7973853e-10
 1.2228471e-01], sum to 1.0000
[2019-04-17 15:43:55,640] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5507
[2019-04-17 15:43:55,793] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-4.566666666666666, 69.33333333333333, 0.0, 0.0, 22.5, 22.48604064558302, -0.3363785487432769, 1.0, 1.0, 25.0, 25.37067283524854], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2227200.0000, 
sim time next is 2228400.0000, 
raw observation next is [-4.6, 70.0, 0.0, 0.0, 22.5, 22.3245202522174, -0.3695150723151284, 0.0, 1.0, 25.0, 22.593696311046216], 
processed observation next is [1.0, 0.8260869565217391, 0.33518005540166207, 0.7, 0.0, 0.0, 0.375, 0.36037668768478337, 0.3768283092282905, 0.0, 1.0, 0.2, 0.22593696311046216], 
reward next is 0.5741, 
noisyNet noise sample is [array([-0.21658184], dtype=float32), -0.7585025]. 
=============================================
[2019-04-17 15:43:56,751] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4418435e-10 1.9589545e-13 9.0268135e-01 1.3554055e-08 4.7937398e-08
 8.5440610e-10 3.9930388e-08 6.2353848e-07 8.8514113e-08 1.5107783e-08
 9.7317919e-02], sum to 1.0000
[2019-04-17 15:43:56,752] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9734
[2019-04-17 15:43:56,802] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [2.566666666666667, 26.0, 13.0, 82.33333333333333, 19.0, 22.27269914615445, -0.3971966025840681, 0.0, 1.0, 25.0, 22.326733597975604], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2481600.0000, 
sim time next is 2482800.0000, 
raw observation next is [1.833333333333333, 27.0, 0.0, 0.0, 19.0, 22.19541928138588, -0.3653689017625603, 0.0, 1.0, 65.0, 60.455900445686844], 
processed observation next is [0.0, 0.7391304347826086, 0.5133887349953832, 0.27, 0.0, 0.0, 0.08333333333333333, 0.3496182734488234, 0.37821036607914654, 0.0, 1.0, 1.0, 0.6045590044568684], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5810381], dtype=float32), -0.26520035]. 
=============================================
[2019-04-17 15:44:03,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0916030e-10 1.0814172e-12 8.5254455e-01 1.0569754e-07 1.6382407e-07
 3.4801126e-09 7.3373776e-08 3.6009449e-06 9.0878979e-07 1.3167652e-07
 1.4745034e-01], sum to 1.0000
[2019-04-17 15:44:03,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2607
[2019-04-17 15:44:03,162] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.4, 42.0, 0.0, 0.0, 19.0, 20.31785221635401, -0.7941523536705489, 0.0, 1.0, 25.0, 13.02821006669576], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2407200.0000, 
sim time next is 2408400.0000, 
raw observation next is [-3.4, 42.0, 0.0, 0.0, 19.0, 20.25321427151674, -0.8041666171449832, 0.0, 1.0, 25.0, 13.407601348464215], 
processed observation next is [0.0, 0.9130434782608695, 0.368421052631579, 0.42, 0.0, 0.0, 0.08333333333333333, 0.1877678559597283, 0.2319444609516723, 0.0, 1.0, 0.2, 0.13407601348464215], 
reward next is 0.6659, 
noisyNet noise sample is [array([-0.23177186], dtype=float32), 2.9519303]. 
=============================================
[2019-04-17 15:44:08,595] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.58167223e-14 2.48077566e-19 8.56017888e-01 1.13617865e-11
 2.82026180e-10 3.06575512e-13 1.86704593e-11 8.08609890e-09
 2.92020047e-10 1.94959916e-11 1.43982098e-01], sum to 1.0000
[2019-04-17 15:44:08,595] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5906
[2019-04-17 15:44:08,620] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.0, 100.0, 0.0, 0.0, 19.0, 22.67898400422898, -0.3038579195789285, 0.0, 1.0, 25.0, 46.564695834975055], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2872800.0000, 
sim time next is 2874000.0000, 
raw observation next is [1.333333333333333, 97.66666666666667, 0.0, 0.0, 19.0, 22.45756777906579, -0.3448488269328878, 0.0, 1.0, 25.0, 43.2686716987276], 
processed observation next is [1.0, 0.2608695652173913, 0.4995383194829178, 0.9766666666666667, 0.0, 0.0, 0.08333333333333333, 0.3714639815888159, 0.38505039102237076, 0.0, 1.0, 0.2, 0.432686716987276], 
reward next is 0.3673, 
noisyNet noise sample is [array([0.8561756], dtype=float32), 0.33640513]. 
=============================================
[2019-04-17 15:44:14,065] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.0197570e-12 4.7823184e-16 8.9813626e-01 4.9017229e-10 1.2677639e-08
 7.2318445e-12 7.8199136e-10 4.1614705e-08 1.3048748e-08 1.8930879e-09
 1.0186368e-01], sum to 1.0000
[2019-04-17 15:44:14,066] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6442
[2019-04-17 15:44:14,089] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.666666666666667, 52.66666666666667, 0.0, 0.0, 22.5, 21.66680734785437, -0.4851215118973526, 1.0, 1.0, 25.0, 25.029835784521264], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2742000.0000, 
sim time next is 2743200.0000, 
raw observation next is [-4.0, 54.0, 0.0, 0.0, 22.5, 21.66544208554795, -0.4866909510038802, 1.0, 1.0, 25.0, 23.9745824851043], 
processed observation next is [1.0, 0.782608695652174, 0.3518005540166205, 0.54, 0.0, 0.0, 0.375, 0.30545350712899594, 0.33776968299870663, 1.0, 1.0, 0.2, 0.239745824851043], 
reward next is 0.5603, 
noisyNet noise sample is [array([2.2325354], dtype=float32), 0.18262243]. 
=============================================
[2019-04-17 15:44:18,310] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.05665701e-11 4.43214098e-15 9.13902044e-01 4.69054751e-09
 9.32453226e-09 1.72501222e-10 3.48742124e-09 2.41301393e-07
 1.18039004e-07 4.97601516e-09 8.60976055e-02], sum to 1.0000
[2019-04-17 15:44:18,310] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3276
[2019-04-17 15:44:18,386] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.2, 47.0, 209.5, 365.0, 19.0, 21.90337923215483, -0.3989043242849757, 0.0, 1.0, 25.0, 45.39169830487487], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2376000.0000, 
sim time next is 2377200.0000, 
raw observation next is [-1.0, 49.33333333333334, 237.8333333333333, 404.3333333333334, 19.0, 22.15187798904986, -0.3798505187473975, 0.0, 1.0, 25.0, 35.95872728324803], 
processed observation next is [0.0, 0.5217391304347826, 0.4349030470914128, 0.4933333333333334, 0.7927777777777776, 0.44677716390423583, 0.08333333333333333, 0.34598983242082176, 0.37338316041753417, 0.0, 1.0, 0.2, 0.3595872728324803], 
reward next is 0.4404, 
noisyNet noise sample is [array([0.20962484], dtype=float32), -1.2133129]. 
=============================================
[2019-04-17 15:44:21,123] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0878647e-10 6.6103976e-14 8.1304544e-01 1.4190948e-08 3.1488558e-08
 4.6701881e-10 5.2459942e-08 8.6611050e-07 1.6465847e-07 1.5061074e-08
 1.8695337e-01], sum to 1.0000
[2019-04-17 15:44:21,123] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7784
[2019-04-17 15:44:21,166] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.3, 25.66666666666667, 50.33333333333333, 345.8333333333333, 19.0, 22.36763096032875, -0.3445352296035772, 0.0, 1.0, 65.0, 57.469142542214314], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2478000.0000, 
sim time next is 2479200.0000, 
raw observation next is [3.3, 25.33333333333333, 41.0, 239.6666666666667, 19.0, 22.61036451919789, -0.3273099760107219, 0.0, 1.0, 25.0, 44.55848930509781], 
processed observation next is [0.0, 0.6956521739130435, 0.554016620498615, 0.2533333333333333, 0.13666666666666666, 0.2648250460405157, 0.08333333333333333, 0.3841970432664909, 0.3908966746630927, 0.0, 1.0, 0.2, 0.4455848930509781], 
reward next is 0.3544, 
noisyNet noise sample is [array([-1.2856027], dtype=float32), 2.8876734]. 
=============================================
[2019-04-17 15:44:22,190] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.3105680e-12 1.3578996e-16 9.6081138e-01 1.3321304e-09 6.2019603e-09
 1.3746435e-11 3.7008793e-10 9.0942486e-08 9.4510719e-09 6.4652106e-10
 3.9188445e-02], sum to 1.0000
[2019-04-17 15:44:22,190] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7263
[2019-04-17 15:44:22,211] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.633333333333334, 27.0, 161.0, 309.5, 22.5, 22.85049879825083, -0.2942488073023428, 1.0, 1.0, 25.0, 6.321023973629047], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2557200.0000, 
sim time next is 2558400.0000, 
raw observation next is [3.466666666666667, 28.0, 151.5, 287.6666666666667, 22.5, 22.87907861141972, -0.2958472802010552, 1.0, 1.0, 25.0, 5.856213254866394], 
processed observation next is [1.0, 0.6086956521739131, 0.5586334256694367, 0.28, 0.505, 0.31786372007366487, 0.375, 0.40658988428497683, 0.4013842399329816, 1.0, 1.0, 0.2, 0.058562132548663944], 
reward next is 0.7414, 
noisyNet noise sample is [array([0.01829336], dtype=float32), -1.2162179]. 
=============================================
[2019-04-17 15:44:23,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.1516170e-11 2.2385343e-14 9.6345711e-01 5.1274611e-09 1.7494667e-08
 2.5870658e-10 1.3670362e-08 2.9742196e-07 8.4566786e-08 1.1016063e-08
 3.6542471e-02], sum to 1.0000
[2019-04-17 15:44:23,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8947
[2019-04-17 15:44:23,108] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.333333333333333, 44.66666666666667, 107.3333333333333, 800.8333333333334, 19.0, 22.11757355109879, -0.3420768082395066, 0.0, 1.0, 25.0, 31.989907933045366], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3073200.0000, 
sim time next is 3074400.0000, 
raw observation next is [-1.0, 42.0, 104.0, 790.5, 19.0, 22.21252547245885, -0.3333472085951104, 0.0, 1.0, 25.0, 28.67871314063127], 
processed observation next is [0.0, 0.6086956521739131, 0.4349030470914128, 0.42, 0.3466666666666667, 0.8734806629834254, 0.08333333333333333, 0.3510437893715708, 0.3888842638016299, 0.0, 1.0, 0.2, 0.2867871314063127], 
reward next is 0.5132, 
noisyNet noise sample is [array([-0.299952], dtype=float32), -0.8320818]. 
=============================================
[2019-04-17 15:44:24,568] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.6852955e-12 1.2230744e-15 9.1220105e-01 8.8334434e-10 1.7476905e-08
 4.3796387e-11 8.3133972e-10 2.5458121e-07 2.3563860e-08 1.4110985e-09
 8.7798707e-02], sum to 1.0000
[2019-04-17 15:44:24,568] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0531
[2019-04-17 15:44:24,587] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.733333333333333, 51.33333333333333, 135.5, 35.0, 22.5, 20.24655743982616, -0.9280046180674804, 1.0, 1.0, 25.0, 13.77682510887859], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2540400.0000, 
sim time next is 2541600.0000, 
raw observation next is [-1.2, 49.0, 134.5, 39.0, 22.5, 20.35321257853385, -0.9126401773925398, 1.0, 1.0, 25.0, 13.71106651153864], 
processed observation next is [1.0, 0.43478260869565216, 0.42936288088642666, 0.49, 0.4483333333333333, 0.0430939226519337, 0.375, 0.19610104821115412, 0.19578660753582008, 1.0, 1.0, 0.2, 0.1371106651153864], 
reward next is 0.1536, 
noisyNet noise sample is [array([-0.35587865], dtype=float32), -1.310304]. 
=============================================
[2019-04-17 15:44:24,620] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2804969e-15 1.3112247e-20 9.8868763e-01 4.7429140e-13 1.5254647e-11
 5.8762254e-15 3.1277331e-12 6.8199263e-10 3.9136413e-11 1.8877356e-12
 1.1312335e-02], sum to 1.0000
[2019-04-17 15:44:24,621] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0666
[2019-04-17 15:44:24,672] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [5.333333333333333, 100.0, 0.0, 0.0, 22.5, 22.81783114554443, -0.03817987483225117, 1.0, 1.0, 25.0, 6.90989057077627], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3176400.0000, 
sim time next is 3177600.0000, 
raw observation next is [4.666666666666666, 100.0, 0.0, 0.0, 22.5, 23.03921921608293, -0.02393713780157394, 0.0, 1.0, 25.0, 6.524073338607639], 
processed observation next is [1.0, 0.782608695652174, 0.5918744228993538, 1.0, 0.0, 0.0, 0.375, 0.4199349346735775, 0.492020954066142, 0.0, 1.0, 0.2, 0.06524073338607639], 
reward next is 0.7348, 
noisyNet noise sample is [array([-1.2008878], dtype=float32), 0.2087861]. 
=============================================
[2019-04-17 15:44:33,146] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2327792e-13 4.6403951e-18 9.5143300e-01 1.8061307e-10 2.3710784e-09
 1.1345338e-12 2.0523330e-10 4.7102866e-08 4.3465569e-09 1.7940142e-10
 4.8566945e-02], sum to 1.0000
[2019-04-17 15:44:33,147] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7013
[2019-04-17 15:44:33,189] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.2, 63.66666666666667, 0.0, 0.0, 19.0, 23.45132090196998, -0.05314236741208989, 0.0, 1.0, 25.0, 12.957342554065761], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2665200.0000, 
sim time next is 2666400.0000, 
raw observation next is [-1.2, 64.33333333333333, 0.0, 0.0, 19.0, 23.33780396750221, -0.07535282801171482, 0.0, 1.0, 25.0, 12.11745770131489], 
processed observation next is [1.0, 0.8695652173913043, 0.42936288088642666, 0.6433333333333333, 0.0, 0.0, 0.08333333333333333, 0.4448169972918509, 0.4748823906627617, 0.0, 1.0, 0.2, 0.1211745770131489], 
reward next is 0.6788, 
noisyNet noise sample is [array([-0.18018101], dtype=float32), -0.9781504]. 
=============================================
[2019-04-17 15:44:36,896] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1998123e-14 7.8466679e-19 9.2784011e-01 3.4884467e-11 2.2560349e-10
 5.9868717e-13 1.7169842e-11 6.6839232e-09 1.5013685e-09 6.1062044e-11
 7.2159894e-02], sum to 1.0000
[2019-04-17 15:44:36,896] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1972
[2019-04-17 15:44:36,937] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.0, 71.0, 93.5, 534.5, 22.5, 22.75660926916583, -0.1817863846218108, 1.0, 1.0, 25.0, 13.942183932224296], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3488400.0000, 
sim time next is 3489600.0000, 
raw observation next is [-0.6666666666666667, 67.33333333333334, 97.16666666666666, 624.8333333333334, 22.5, 22.87674177886897, -0.1601474666642795, 1.0, 1.0, 25.0, 13.066017431350314], 
processed observation next is [1.0, 0.391304347826087, 0.44413665743305636, 0.6733333333333335, 0.32388888888888884, 0.6904235727440148, 0.375, 0.4063951482390807, 0.44661751111190684, 1.0, 1.0, 0.2, 0.13066017431350313], 
reward next is 0.6693, 
noisyNet noise sample is [array([0.71216184], dtype=float32), 0.7918077]. 
=============================================
[2019-04-17 15:44:39,069] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.8657439e-15 1.1390110e-19 9.7657531e-01 1.1026755e-11 1.0836402e-10
 1.3351067e-13 1.9143773e-11 5.3336224e-09 1.3466842e-10 3.8477027e-11
 2.3424722e-02], sum to 1.0000
[2019-04-17 15:44:39,070] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1880
[2019-04-17 15:44:39,091] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.0, 74.0, 0.0, 0.0, 19.0, 24.36826415924545, 0.2194990542983803, 0.0, 1.0, 25.0, 24.360300087665834], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3536400.0000, 
sim time next is 3537600.0000, 
raw observation next is [-1.0, 70.0, 0.0, 0.0, 19.0, 24.04198175761323, 0.1758660269729773, 0.0, 1.0, 25.0, 20.44478403677853], 
processed observation next is [1.0, 0.9565217391304348, 0.4349030470914128, 0.7, 0.0, 0.0, 0.08333333333333333, 0.5034984798011024, 0.5586220089909925, 0.0, 1.0, 0.2, 0.2044478403677853], 
reward next is 0.5956, 
noisyNet noise sample is [array([-1.6087247], dtype=float32), -0.6356485]. 
=============================================
[2019-04-17 15:44:40,024] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.5743944e-14 1.9063210e-19 9.4740361e-01 5.9244311e-11 2.5980906e-10
 2.9969972e-13 4.3523171e-11 6.3329044e-09 3.4127426e-10 2.8502660e-11
 5.2596428e-02], sum to 1.0000
[2019-04-17 15:44:40,027] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9841
[2019-04-17 15:44:40,060] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [1.0, 83.66666666666667, 0.0, 0.0, 19.0, 23.29262583628013, 0.0009832304155960963, 0.0, 1.0, 25.0, 15.478903157359412], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 3457200.0000, 
sim time next is 3458400.0000, 
raw observation next is [1.0, 81.33333333333334, 0.0, 0.0, 19.0, 23.28704305746199, 0.05095690741564773, 0.0, 1.0, 65.0, 80.08875616212394], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.8133333333333335, 0.0, 0.0, 0.08333333333333333, 0.4405869214551658, 0.516985635805216, 0.0, 1.0, 1.0, 0.8008875616212394], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0190121], dtype=float32), 1.0430214]. 
=============================================
[2019-04-17 15:44:40,172] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4728950e-10 1.4421708e-13 9.2258525e-01 2.8609817e-08 7.8613063e-08
 8.2812013e-10 2.7648781e-08 1.0962699e-06 3.7975062e-07 2.9700292e-08
 7.7413186e-02], sum to 1.0000
[2019-04-17 15:44:40,175] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4127
[2019-04-17 15:44:40,206] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.3333333333333333, 40.0, 22.16666666666666, 204.1666666666667, 19.0, 22.17159492421047, -0.2960371589943259, 0.0, 1.0, 25.0, 40.64985248793383], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3604800.0000, 
sim time next is 3606000.0000, 
raw observation next is [-0.6666666666666666, 41.0, 11.66666666666667, 118.3333333333333, 19.0, 22.41946991661188, -0.2913729047676877, 0.0, 1.0, 25.0, 33.14101260948539], 
processed observation next is [0.0, 0.7391304347826086, 0.44413665743305636, 0.41, 0.038888888888888896, 0.1307550644567219, 0.08333333333333333, 0.36828915971765674, 0.4028756984107708, 0.0, 1.0, 0.2, 0.3314101260948539], 
reward next is 0.4686, 
noisyNet noise sample is [array([0.30903727], dtype=float32), -1.198948]. 
=============================================
[2019-04-17 15:44:42,415] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.8886845e-14 3.6489667e-19 8.5779035e-01 6.1249672e-11 2.7689775e-10
 3.1257115e-13 2.7255897e-11 1.6444890e-08 5.1196930e-10 4.5003938e-11
 1.4220968e-01], sum to 1.0000
[2019-04-17 15:44:42,416] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3178
[2019-04-17 15:44:42,436] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [4.0, 100.0, 0.0, 0.0, 19.0, 20.60029885081122, -0.705504851163648, 0.0, 1.0, 65.0, 86.53612347041533], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3132000.0000, 
sim time next is 3133200.0000, 
raw observation next is [4.666666666666667, 100.0, 0.0, 0.0, 19.0, 21.05498754789158, -0.6552340179627779, 0.0, 1.0, 25.0, 50.78658125128687], 
processed observation next is [1.0, 0.2608695652173913, 0.5918744228993538, 1.0, 0.0, 0.0, 0.08333333333333333, 0.2545822956576318, 0.281588660679074, 0.0, 1.0, 0.2, 0.5078658125128687], 
reward next is 0.2921, 
noisyNet noise sample is [array([1.5552293], dtype=float32), 2.0863895]. 
=============================================
[2019-04-17 15:44:52,093] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.28386295e-11 1.36286426e-15 8.76537561e-01 2.96744163e-09
 1.40556811e-08 5.51942728e-11 2.21109930e-09 3.12363227e-07
 3.00873992e-08 1.79583581e-09 1.23462163e-01], sum to 1.0000
[2019-04-17 15:44:52,094] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5925
[2019-04-17 15:44:52,105] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-10.66666666666667, 76.0, 0.0, 0.0, 19.0, 19.25550409584728, -1.000902059492623, 0.0, 1.0, 25.0, 16.856614315207004], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3303600.0000, 
sim time next is 3304800.0000, 
raw observation next is [-11.0, 76.0, 0.0, 0.0, 19.0, 19.12962642018086, -1.028970650458356, 0.0, 1.0, 25.0, 17.016084726712613], 
processed observation next is [1.0, 0.2608695652173913, 0.15789473684210528, 0.76, 0.0, 0.0, 0.08333333333333333, 0.09413553501507159, 0.157009783180548, 0.0, 1.0, 0.2, 0.17016084726712613], 
reward next is 0.6298, 
noisyNet noise sample is [array([-0.7836294], dtype=float32), -2.0107825]. 
=============================================
[2019-04-17 15:44:52,485] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3716685e-14 1.2112392e-18 9.4184846e-01 4.4365147e-11 5.2600102e-10
 3.6788522e-13 4.2732082e-11 1.1827807e-08 3.3040218e-10 2.4470592e-11
 5.8151599e-02], sum to 1.0000
[2019-04-17 15:44:52,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2140
[2019-04-17 15:44:52,535] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.333333333333333, 73.0, 0.0, 0.0, 19.0, 22.7831854621834, -0.1781230237394687, 0.0, 1.0, 65.0, 90.52206283541692], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3903600.0000, 
sim time next is 3904800.0000, 
raw observation next is [-3.666666666666667, 75.0, 0.0, 0.0, 19.0, 23.07785580081432, -0.1247254187859336, 0.0, 1.0, 25.0, 42.37707087969936], 
processed observation next is [1.0, 0.17391304347826086, 0.3610341643582641, 0.75, 0.0, 0.0, 0.08333333333333333, 0.42315465006785996, 0.45842486040468877, 0.0, 1.0, 0.2, 0.4237707087969936], 
reward next is 0.3762, 
noisyNet noise sample is [array([-0.28627634], dtype=float32), -1.8009921]. 
=============================================
[2019-04-17 15:44:54,048] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.01871961e-12 1.56728028e-16 9.85911012e-01 2.72714185e-10
 1.32022004e-09 4.89432713e-12 4.71659267e-10 1.82863591e-08
 6.03349148e-09 2.23109045e-10 1.40889855e-02], sum to 1.0000
[2019-04-17 15:44:54,048] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7347
[2019-04-17 15:44:54,075] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.333333333333333, 24.66666666666666, 27.83333333333333, 252.1666666666667, 22.5, 23.58233451626018, -0.147427819338215, 1.0, 1.0, 25.0, 7.008837635372885], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4036800.0000, 
sim time next is 4038000.0000, 
raw observation next is [-2.666666666666667, 25.33333333333333, 16.66666666666667, 160.8333333333333, 22.5, 23.02616591478777, -0.1777543825392887, 1.0, 1.0, 25.0, 6.834691469026254], 
processed observation next is [1.0, 0.7391304347826086, 0.38873499538319484, 0.2533333333333333, 0.05555555555555557, 0.17771639042357268, 0.375, 0.4188471595656476, 0.44074853915357043, 1.0, 1.0, 0.2, 0.06834691469026254], 
reward next is 0.7317, 
noisyNet noise sample is [array([1.6766897], dtype=float32), 0.66880554]. 
=============================================
[2019-04-17 15:44:54,332] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.47169630e-13 2.02325996e-17 9.66854334e-01 1.40615394e-10
 4.91624186e-10 7.50254134e-13 1.10780295e-10 2.21812080e-08
 1.73388393e-09 1.30390004e-10 3.31456773e-02], sum to 1.0000
[2019-04-17 15:44:54,334] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1054
[2019-04-17 15:44:54,350] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-7.333333333333334, 62.0, 5.0, 135.8333333333333, 22.5, 22.56327878685003, -0.2608717040981861, 1.0, 1.0, 25.0, 14.42872656393947], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3914400.0000, 
sim time next is 3915600.0000, 
raw observation next is [-7.666666666666666, 60.0, 20.16666666666666, 213.5, 22.5, 22.55168740626674, -0.2580172721050512, 1.0, 1.0, 25.0, 14.50621335535928], 
processed observation next is [1.0, 0.30434782608695654, 0.25023084025854114, 0.6, 0.0672222222222222, 0.23591160220994475, 0.375, 0.3793072838555617, 0.41399424263164963, 1.0, 1.0, 0.2, 0.1450621335535928], 
reward next is 0.6549, 
noisyNet noise sample is [array([2.3248367], dtype=float32), 0.47527224]. 
=============================================
[2019-04-17 15:44:54,498] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1226207e-13 9.4554457e-19 9.4928300e-01 5.4104648e-11 1.5419831e-10
 2.8469870e-13 9.0184950e-11 3.0285118e-08 8.1664225e-10 1.8478720e-10
 5.0717030e-02], sum to 1.0000
[2019-04-17 15:44:54,499] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9452
[2019-04-17 15:44:54,582] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.0, 46.33333333333334, 115.3333333333333, 806.1666666666666, 22.5, 23.7878031003588, -0.04961902016998152, 1.0, 1.0, 25.0, 35.66633494272236], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3411600.0000, 
sim time next is 3412800.0000, 
raw observation next is [3.0, 45.0, 116.0, 810.5, 22.5, 23.93790710070489, -0.1263525784666717, 1.0, 1.0, 25.0, 28.611256615305884], 
processed observation next is [1.0, 0.5217391304347826, 0.5457063711911359, 0.45, 0.38666666666666666, 0.8955801104972375, 0.375, 0.4948255917254076, 0.45788247384444275, 1.0, 1.0, 0.2, 0.28611256615305886], 
reward next is 0.5139, 
noisyNet noise sample is [array([-0.95417285], dtype=float32), 2.353046]. 
=============================================
[2019-04-17 15:44:55,737] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2800149e-11 2.9624749e-15 9.6282464e-01 1.3064355e-09 1.3405358e-08
 8.5021067e-11 6.9189112e-09 1.2511916e-07 2.9759867e-08 3.9074219e-09
 3.7175160e-02], sum to 1.0000
[2019-04-17 15:44:55,737] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6579
[2019-04-17 15:44:55,770] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.0, 26.0, 0.0, 0.0, 22.5, 20.77925550334298, -0.6857179369804728, 1.0, 1.0, 25.0, 10.712960564610771], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4039200.0000, 
sim time next is 4040400.0000, 
raw observation next is [-3.333333333333333, 27.66666666666667, 0.0, 0.0, 22.5, 20.83338070094084, -0.6986116405111925, 1.0, 1.0, 25.0, 11.3657544307939], 
processed observation next is [1.0, 0.782608695652174, 0.37026777469990774, 0.2766666666666667, 0.0, 0.0, 0.375, 0.23611505841173663, 0.26712945316293585, 1.0, 1.0, 0.2, 0.11365754430793899], 
reward next is 0.0117, 
noisyNet noise sample is [array([1.8090353], dtype=float32), -2.6622465]. 
=============================================
[2019-04-17 15:44:56,383] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.5388904e-14 1.0937322e-18 9.8333079e-01 1.5265579e-11 1.4571916e-10
 2.1945168e-13 4.1215416e-11 2.8787079e-09 1.1370639e-09 1.5384810e-11
 1.6669229e-02], sum to 1.0000
[2019-04-17 15:44:56,384] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4483
[2019-04-17 15:44:56,434] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.0, 47.66666666666666, 116.3333333333333, 815.1666666666667, 22.5, 22.49200347299336, -0.3912741132171421, 1.0, 1.0, 25.0, 13.848054459071186], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3415200.0000, 
sim time next is 3416400.0000, 
raw observation next is [3.0, 49.0, 115.0, 811.5, 22.5, 22.08045976377414, -0.3641604555230722, 1.0, 1.0, 25.0, 18.707069863198953], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.49, 0.38333333333333336, 0.8966850828729281, 0.375, 0.34003831364784504, 0.37861318149230927, 1.0, 1.0, 0.2, 0.18707069863198952], 
reward next is 0.6129, 
noisyNet noise sample is [array([-1.3452492], dtype=float32), -0.29341918]. 
=============================================
[2019-04-17 15:45:00,907] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6813838e-14 2.1100217e-18 9.9624532e-01 1.8882389e-11 1.6766348e-10
 1.7446324e-13 1.7289753e-11 4.3004675e-09 6.8954786e-11 1.4574519e-11
 3.7546931e-03], sum to 1.0000
[2019-04-17 15:45:00,910] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9689
[2019-04-17 15:45:00,941] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.0, 38.33333333333334, 0.0, 0.0, 19.0, 23.42928185499214, -0.06009704892482875, 0.0, 1.0, 25.0, 7.064106060550259], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4135200.0000, 
sim time next is 4136400.0000, 
raw observation next is [1.0, 36.0, 0.0, 0.0, 19.0, 23.36168997043289, -0.07440709088810689, 0.0, 1.0, 25.0, 6.863879286791715], 
processed observation next is [1.0, 0.9130434782608695, 0.4903047091412743, 0.36, 0.0, 0.0, 0.08333333333333333, 0.4468074975360743, 0.475197636370631, 0.0, 1.0, 0.2, 0.06863879286791714], 
reward next is 0.7314, 
noisyNet noise sample is [array([0.85717416], dtype=float32), 0.93081045]. 
=============================================
[2019-04-17 15:45:01,362] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.9192703e-12 9.7918660e-16 9.8198456e-01 8.7723440e-10 1.4772283e-09
 1.7592898e-11 4.9256094e-10 3.8115594e-08 7.6773850e-09 4.8858423e-10
 1.8015390e-02], sum to 1.0000
[2019-04-17 15:45:01,362] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6270
[2019-04-17 15:45:01,378] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.0, 47.0, 0.0, 0.0, 19.0, 22.33064174578709, -0.377355579884898, 0.0, 1.0, 25.0, 11.444515799746679], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4230000.0000, 
sim time next is 4231200.0000, 
raw observation next is [1.333333333333333, 47.33333333333334, 0.0, 0.0, 19.0, 22.24283761547718, -0.395787462692863, 0.0, 1.0, 25.0, 10.736954931762579], 
processed observation next is [0.0, 1.0, 0.4995383194829178, 0.47333333333333344, 0.0, 0.0, 0.08333333333333333, 0.35356980128976484, 0.36807084576904564, 0.0, 1.0, 0.2, 0.1073695493176258], 
reward next is 0.6926, 
noisyNet noise sample is [array([1.5658401], dtype=float32), -0.74935555]. 
=============================================
[2019-04-17 15:45:02,985] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.9567456e-14 8.8015998e-19 9.8265529e-01 2.3647657e-11 5.3671634e-10
 3.1137156e-13 9.1583297e-11 4.3811301e-09 5.2822907e-10 6.2710302e-11
 1.7344737e-02], sum to 1.0000
[2019-04-17 15:45:02,987] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5162
[2019-04-17 15:45:03,080] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 22.5, 22.88632771029829, -0.1858879743348445, 1.0, 1.0, 25.0, 36.96853449372392], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4564800.0000, 
sim time next is 4566000.0000, 
raw observation next is [2.0, 53.66666666666667, 0.0, 0.0, 19.0, 22.80418159122198, -0.2003018855935903, 0.0, 1.0, 25.0, 29.67170508492815], 
processed observation next is [1.0, 0.8695652173913043, 0.518005540166205, 0.5366666666666667, 0.0, 0.0, 0.08333333333333333, 0.400348465935165, 0.43323270480213655, 0.0, 1.0, 0.2, 0.2967170508492815], 
reward next is 0.5033, 
noisyNet noise sample is [array([1.263943], dtype=float32), -1.5690011]. 
=============================================
[2019-04-17 15:45:03,519] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0660978e-11 8.8269224e-16 9.0762866e-01 1.5424790e-09 3.5789638e-09
 2.1248323e-11 9.1901187e-10 2.1122898e-07 1.6911319e-08 2.3155042e-09
 9.2371128e-02], sum to 1.0000
[2019-04-17 15:45:03,521] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4918
[2019-04-17 15:45:03,549] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-6.666666666666667, 70.0, 73.83333333333334, 374.3333333333334, 19.0, 22.29060736570361, -0.3151714192492253, 0.0, 1.0, 25.0, 47.83630127808355], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3572400.0000, 
sim time next is 3573600.0000, 
raw observation next is [-6.333333333333334, 70.0, 90.0, 466.8333333333333, 19.0, 22.39422394017525, -0.3080757358264428, 0.0, 1.0, 25.0, 41.867406791149435], 
processed observation next is [0.0, 0.34782608695652173, 0.28716528162511545, 0.7, 0.3, 0.5158379373848987, 0.08333333333333333, 0.36618532834793766, 0.3973080880578524, 0.0, 1.0, 0.2, 0.41867406791149436], 
reward next is 0.3813, 
noisyNet noise sample is [array([0.19677891], dtype=float32), -0.6004631]. 
=============================================
[2019-04-17 15:45:03,743] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.6131870e-12 8.6968923e-16 9.7744113e-01 3.3446507e-10 1.9516220e-09
 7.7758702e-12 5.2099336e-10 3.4541173e-08 1.5349963e-08 2.6302083e-10
 2.2558901e-02], sum to 1.0000
[2019-04-17 15:45:03,744] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.9923
[2019-04-17 15:45:03,756] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [5.0, 50.0, 75.5, 613.5, 19.0, 21.84079654013625, -0.4295194770885094, 0.0, 1.0, 25.0, 3.443569798582087], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 3686400.0000, 
sim time next is 3687600.0000, 
raw observation next is [4.666666666666667, 53.0, 67.83333333333333, 552.5, 19.0, 21.91385390065485, -0.3567761764132659, 0.0, 1.0, 65.0, 87.26471901193229], 
processed observation next is [0.0, 0.6956521739130435, 0.5918744228993538, 0.53, 0.2261111111111111, 0.6104972375690608, 0.08333333333333333, 0.3261544917212375, 0.3810746078622447, 0.0, 1.0, 1.0, 0.8726471901193229], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4105883], dtype=float32), -1.0098531]. 
=============================================
[2019-04-17 15:45:06,107] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1013910e-14 3.6210382e-19 8.7816536e-01 1.9593296e-11 2.0471159e-10
 7.8523369e-14 9.1064821e-12 5.3075997e-09 5.8034949e-10 2.4345866e-11
 1.2183465e-01], sum to 1.0000
[2019-04-17 15:45:06,108] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8700
[2019-04-17 15:45:06,130] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.7333333333333334, 73.0, 0.0, 0.0, 19.0, 22.22060871051392, -0.2992262024869664, 0.0, 1.0, 25.0, 15.13692667346935], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4501200.0000, 
sim time next is 4502400.0000, 
raw observation next is [-0.8666666666666667, 73.0, 0.0, 0.0, 19.0, 22.05977456869451, -0.3216703529912497, 0.0, 1.0, 25.0, 13.931461899396535], 
processed observation next is [1.0, 0.08695652173913043, 0.4385964912280702, 0.73, 0.0, 0.0, 0.08333333333333333, 0.33831454739120925, 0.39277654900291675, 0.0, 1.0, 0.2, 0.13931461899396536], 
reward next is 0.6607, 
noisyNet noise sample is [array([-0.0873384], dtype=float32), 0.9048381]. 
=============================================
[2019-04-17 15:45:07,449] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [4.6221483e-14 2.1984532e-19 9.6993053e-01 2.5449885e-11 2.7799821e-10
 1.7020945e-13 1.9628821e-11 8.5647160e-09 2.0155733e-10 1.8613567e-11
 3.0069504e-02], sum to 1.0000
[2019-04-17 15:45:07,449] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.9937
[2019-04-17 15:45:07,475] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 19.0, 22.44817156838176, -0.3211135104037708, 0.0, 1.0, 25.0, 30.892658952157532], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 3814800.0000, 
sim time next is 3816000.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 19.0, 22.36431020049583, -0.2777348824221469, 0.0, 1.0, 65.0, 68.81273374700379], 
processed observation next is [1.0, 0.17391304347826086, 0.3518005540166205, 0.71, 0.0, 0.0, 0.08333333333333333, 0.3636925167079858, 0.4074217058592844, 0.0, 1.0, 1.0, 0.6881273374700378], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.08160953], dtype=float32), 0.04325589]. 
=============================================
[2019-04-17 15:45:10,621] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0883068e-14 1.5111320e-18 9.7092414e-01 1.6130956e-11 5.3127957e-11
 2.2184082e-13 1.7218638e-11 6.4830998e-09 6.8727940e-10 3.8897871e-11
 2.9075893e-02], sum to 1.0000
[2019-04-17 15:45:10,621] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0513
[2019-04-17 15:45:10,713] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [4.9, 75.0, 0.0, 0.0, 19.0, 23.29451849930436, -0.126822531269047, 0.0, 1.0, 25.0, 24.181948778661965], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4311600.0000, 
sim time next is 4312800.0000, 
raw observation next is [4.8, 76.0, 0.0, 0.0, 19.0, 23.18663767179508, -0.1456699972845456, 0.0, 1.0, 25.0, 21.904442360488595], 
processed observation next is [0.0, 0.9565217391304348, 0.5955678670360112, 0.76, 0.0, 0.0, 0.08333333333333333, 0.43221980598292326, 0.45144333423848476, 0.0, 1.0, 0.2, 0.21904442360488596], 
reward next is 0.5810, 
noisyNet noise sample is [array([-0.36164016], dtype=float32), -1.1304038]. 
=============================================
[2019-04-17 15:45:12,524] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.06262807e-14 2.28953202e-19 9.83579934e-01 2.38500036e-11
 9.09167255e-11 7.96838114e-14 1.15662185e-11 4.36221148e-09
 2.33102454e-10 1.65597241e-11 1.64200421e-02], sum to 1.0000
[2019-04-17 15:45:12,525] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5105
[2019-04-17 15:45:12,615] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.9333333333333333, 71.0, 0.0, 0.0, 19.0, 22.28428486114871, -0.2598290533125718, 0.0, 1.0, 25.0, 12.85244332220164], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4513200.0000, 
sim time next is 4514400.0000, 
raw observation next is [-1.0, 71.0, 0.0, 0.0, 19.0, 22.28229786750275, -0.2701995004371106, 0.0, 1.0, 25.0, 12.792268623998964], 
processed observation next is [1.0, 0.2608695652173913, 0.4349030470914128, 0.71, 0.0, 0.0, 0.08333333333333333, 0.35685815562522905, 0.40993349985429645, 0.0, 1.0, 0.2, 0.12792268623998965], 
reward next is 0.6721, 
noisyNet noise sample is [array([0.60799307], dtype=float32), 1.2865921]. 
=============================================
[2019-04-17 15:45:16,278] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4851007e-16 6.2884513e-20 9.6752924e-01 3.2041299e-12 3.7866616e-11
 2.8599264e-14 4.9928837e-12 2.0355613e-09 1.5493969e-10 6.8443029e-12
 3.2470800e-02], sum to 1.0000
[2019-04-17 15:45:16,278] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7226
[2019-04-17 15:45:16,311] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [6.8, 65.0, 0.0, 0.0, 19.0, 23.29533182831796, -0.01021653414275999, 0.0, 1.0, 25.0, 7.817757971818692], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4410000.0000, 
sim time next is 4411200.0000, 
raw observation next is [6.566666666666667, 65.33333333333334, 0.0, 0.0, 19.0, 23.24893649449393, -0.02185221707268308, 0.0, 1.0, 25.0, 8.058516064962365], 
processed observation next is [1.0, 0.043478260869565216, 0.6445060018467221, 0.6533333333333334, 0.0, 0.0, 0.08333333333333333, 0.43741137454116075, 0.49271592764243893, 0.0, 1.0, 0.2, 0.08058516064962365], 
reward next is 0.7194, 
noisyNet noise sample is [array([2.0262208], dtype=float32), 0.2946881]. 
=============================================
[2019-04-17 15:45:19,261] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6189392e-16 7.3441303e-21 9.4975847e-01 1.5346800e-12 1.5613212e-11
 6.9078315e-15 2.7076793e-12 6.5409433e-10 7.0628177e-11 2.1696724e-12
 5.0241452e-02], sum to 1.0000
[2019-04-17 15:45:19,262] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5560
[2019-04-17 15:45:19,416] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 22.5, 22.79140144697488, -0.1117011795124167, 1.0, 1.0, 25.0, 14.228772998743686], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4471200.0000, 
sim time next is 4472400.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 22.5, 22.89836370507473, -0.11310262991817, 1.0, 1.0, 25.0, 12.47880035476672], 
processed observation next is [1.0, 0.782608695652174, 0.46260387811634357, 0.72, 0.0, 0.0, 0.375, 0.40819697542289407, 0.46229912336060996, 1.0, 1.0, 0.2, 0.12478800354766721], 
reward next is 0.6752, 
noisyNet noise sample is [array([-1.7640028], dtype=float32), 1.3248736]. 
=============================================
[2019-04-17 15:45:19,573] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6312461e-12 4.0749641e-16 9.3066090e-01 4.0377621e-10 1.9349990e-09
 1.0732601e-11 4.7457194e-10 4.3265072e-08 5.6341793e-09 5.5228311e-10
 6.9339119e-02], sum to 1.0000
[2019-04-17 15:45:19,573] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5237
[2019-04-17 15:45:19,602] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7818361e-15 9.7422554e-21 9.8411894e-01 2.0818735e-12 3.4602890e-11
 2.3182201e-14 1.0529760e-11 8.4813317e-10 9.0376297e-11 2.7368947e-12
 1.5881049e-02], sum to 1.0000
[2019-04-17 15:45:19,602] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9999
[2019-04-17 15:45:19,742] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.333333333333333, 36.66666666666666, 94.0, 504.0, 22.5, 20.82381083611881, -0.7313837131060003, 1.0, 1.0, 25.0, 12.46009163564501], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4092000.0000, 
sim time next is 4093200.0000, 
raw observation next is [-3.0, 38.0, 98.0, 574.0, 22.5, 21.02853573473912, -0.7152181512704807, 1.0, 1.0, 25.0, 11.995474170531079], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.38, 0.32666666666666666, 0.6342541436464089, 0.375, 0.2523779778949266, 0.26159394957650645, 1.0, 1.0, 0.2, 0.11995474170531079], 
reward next is 0.1617, 
noisyNet noise sample is [array([-0.30638131], dtype=float32), 0.9032263]. 
=============================================
[2019-04-17 15:45:19,849] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [4.7, 49.0, 171.0, 706.0, 22.5, 24.43805911965782, 0.1409354077591402, 1.0, 1.0, 25.0, 19.560463659931756], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 4629600.0000, 
sim time next is 4630800.0000, 
raw observation next is [4.800000000000001, 49.33333333333334, 192.3333333333333, 634.6666666666666, 22.5, 24.72508085278362, 0.2811492333328172, 1.0, 1.0, 65.0, 84.10784137364304], 
processed observation next is [1.0, 0.6086956521739131, 0.5955678670360112, 0.4933333333333334, 0.641111111111111, 0.7012891344383057, 0.375, 0.560423404398635, 0.5937164111109391, 1.0, 1.0, 1.0, 0.8410784137364304], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24248677], dtype=float32), -0.67727435]. 
=============================================
[2019-04-17 15:45:30,975] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:45:31,271] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:45:31,949] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:45:31,949] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:45:31,953] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res14/Eplus-env-sub_run6
[2019-04-17 15:45:35,232] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.7200806e-12 7.8547517e-15 8.8324416e-01 4.3651998e-09 6.8523245e-09
 5.8594102e-11 2.5109104e-09 4.1515776e-07 5.5575839e-08 1.9282800e-09
 1.1675540e-01], sum to 1.0000
[2019-04-17 15:45:35,232] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8636
[2019-04-17 15:45:35,390] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.0, 49.0, 0.0, 0.0, 19.0, 21.34994798818071, -0.5969807761328365, 0.0, 1.0, 25.0, 12.491407911507054], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4256400.0000, 
sim time next is 4257600.0000, 
raw observation next is [3.0, 49.0, 0.0, 0.0, 19.0, 21.26408531776601, -0.6147103656443671, 0.0, 1.0, 25.0, 11.56405215644175], 
processed observation next is [0.0, 0.2608695652173913, 0.5457063711911359, 0.49, 0.0, 0.0, 0.08333333333333333, 0.2720071098138342, 0.29509654478521097, 0.0, 1.0, 0.2, 0.11564052156441751], 
reward next is 0.6844, 
noisyNet noise sample is [array([2.3699615], dtype=float32), 1.1097234]. 
=============================================
[2019-04-17 15:45:40,976] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [3.4992910e-14 1.2071032e-18 9.1735083e-01 7.6662489e-11 2.1058345e-10
 2.2224116e-13 5.5735239e-11 1.7404703e-08 3.4497829e-09 5.3086657e-11
 8.2649171e-02], sum to 1.0000
[2019-04-17 15:45:40,976] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6242
[2019-04-17 15:45:41,019] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.4, 70.33333333333333, 0.0, 0.0, 19.0, 21.25645895819186, -0.5997896366494625, 0.0, 1.0, 25.0, 11.5819812845938], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4340400.0000, 
sim time next is 4341600.0000, 
raw observation next is [3.3, 71.0, 0.0, 0.0, 19.0, 21.24017015206983, -0.5921912317792196, 0.0, 1.0, 25.0, 11.58969395582891], 
processed observation next is [1.0, 0.2608695652173913, 0.554016620498615, 0.71, 0.0, 0.0, 0.08333333333333333, 0.27001417933915245, 0.3026029227402601, 0.0, 1.0, 0.2, 0.1158969395582891], 
reward next is 0.6841, 
noisyNet noise sample is [array([-1.9036324], dtype=float32), 0.7552967]. 
=============================================
[2019-04-17 15:45:41,547] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:45:41,756] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:45:42,557] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:45:42,557] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:45:42,560] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res15/Eplus-env-sub_run6
[2019-04-17 15:45:43,983] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:45:44,049] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:45:44,173] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:45:44,433] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:45:44,982] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:45:44,982] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:45:44,985] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res11/Eplus-env-sub_run6
[2019-04-17 15:45:45,047] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:45:45,047] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:45:45,051] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res16/Eplus-env-sub_run6
[2019-04-17 15:45:46,967] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.3232017e-17 1.0412957e-22 9.7442639e-01 1.0535168e-13 1.0719893e-12
 9.3084400e-16 1.7723595e-13 5.4156159e-11 5.9709507e-12 4.6151966e-13
 2.5573578e-02], sum to 1.0000
[2019-04-17 15:45:46,968] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5635
[2019-04-17 15:45:47,033] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [1.0, 86.0, 160.1666666666667, 24.33333333333333, 22.5, 24.77338847076977, 0.2753045827223189, 1.0, 1.0, 25.0, 13.131220789440956], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4447200.0000, 
sim time next is 4448400.0000, 
raw observation next is [1.0, 86.0, 135.3333333333333, 0.0, 22.5, 24.72505585534955, 0.2703861602882658, 1.0, 1.0, 25.0, 12.519212483637025], 
processed observation next is [1.0, 0.4782608695652174, 0.4903047091412743, 0.86, 0.45111111111111096, 0.0, 0.375, 0.560421321279129, 0.5901287200960886, 1.0, 1.0, 0.2, 0.12519212483637024], 
reward next is 0.6748, 
noisyNet noise sample is [array([0.04566281], dtype=float32), -1.0624865]. 
=============================================
[2019-04-17 15:45:49,344] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:45:49,565] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:45:49,737] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3547746e-14 8.3669169e-19 7.7687281e-01 9.0156528e-11 1.9264325e-10
 3.1727062e-13 6.5979430e-11 1.9057383e-08 2.7420539e-09 3.0266584e-11
 2.2312719e-01], sum to 1.0000
[2019-04-17 15:45:49,738] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0269
[2019-04-17 15:45:49,833] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.7333333333333334, 73.0, 0.0, 0.0, 19.0, 22.32619075269282, -0.1832503514807513, 0.0, 1.0, 65.0, 91.52001317971526], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4501200.0000, 
sim time next is 4502400.0000, 
raw observation next is [-0.8666666666666667, 73.0, 0.0, 0.0, 19.0, 22.56321481015888, -0.1320100337675393, 0.0, 1.0, 25.0, 43.79017467154388], 
processed observation next is [1.0, 0.08695652173913043, 0.4385964912280702, 0.73, 0.0, 0.0, 0.08333333333333333, 0.38026790084657325, 0.4559966554108202, 0.0, 1.0, 0.2, 0.4379017467154388], 
reward next is 0.3621, 
noisyNet noise sample is [array([0.66408247], dtype=float32), -0.35783884]. 
=============================================
[2019-04-17 15:45:50,249] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6191068e-14 2.1939289e-18 8.9763075e-01 1.5619990e-11 4.6883816e-11
 5.4541842e-13 9.5431553e-12 8.1385476e-09 7.7085044e-10 4.1981755e-11
 1.0236928e-01], sum to 1.0000
[2019-04-17 15:45:50,250] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6394
[2019-04-17 15:45:50,272] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [7.7, 93.0, 17.5, 0.0, 19.0, 21.99474243577054, -0.3225422201488833, 0.0, 1.0, 25.0, 15.159149574832774], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 30000.0000, 
sim time next is 31200.0000, 
raw observation next is [7.699999999999999, 93.0, 23.83333333333333, 0.0, 19.0, 21.92537277101367, -0.3386165248988216, 0.0, 1.0, 25.0, 14.108908202428186], 
processed observation next is [0.0, 0.34782608695652173, 0.6759002770083103, 0.93, 0.07944444444444443, 0.0, 0.08333333333333333, 0.3271143975844725, 0.38712782503372617, 0.0, 1.0, 0.2, 0.14108908202428186], 
reward next is 0.6589, 
noisyNet noise sample is [array([-0.67927027], dtype=float32), 0.13673301]. 
=============================================
[2019-04-17 15:45:50,345] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:45:50,345] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:45:50,352] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res5/Eplus-env-sub_run6
[2019-04-17 15:45:51,615] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:45:51,810] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:45:52,602] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:45:52,603] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:45:52,625] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res6/Eplus-env-sub_run6
[2019-04-17 15:45:53,051] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2926118e-15 9.7832679e-21 9.7607774e-01 2.8305160e-12 1.4499700e-11
 2.3484270e-14 1.5125195e-12 5.3861543e-10 1.2296004e-10 3.5921531e-12
 2.3922265e-02], sum to 1.0000
[2019-04-17 15:45:53,052] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1959
[2019-04-17 15:45:53,197] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.0, 45.0, 208.5, 62.5, 22.5, 24.58158026498576, 0.2335565393381477, 1.0, 1.0, 25.0, 10.49493251773142], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4546800.0000, 
sim time next is 4548000.0000, 
raw observation next is [2.666666666666667, 46.0, 171.5, 28.83333333333333, 22.5, 24.25045108722019, 0.1919830087271629, 1.0, 1.0, 25.0, 10.69316897659227], 
processed observation next is [1.0, 0.6521739130434783, 0.5364727608494922, 0.46, 0.5716666666666667, 0.031860036832412515, 0.375, 0.5208709239350157, 0.5639943362423877, 1.0, 1.0, 0.2, 0.1069316897659227], 
reward next is 0.6931, 
noisyNet noise sample is [array([-0.3219147], dtype=float32), -2.0136447]. 
=============================================
[2019-04-17 15:45:54,263] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:45:54,495] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:45:54,818] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:45:55,031] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:45:55,264] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:45:55,264] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:45:55,271] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res3/Eplus-env-sub_run6
[2019-04-17 15:45:55,825] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:45:55,825] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:45:55,829] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res7/Eplus-env-sub_run6
[2019-04-17 15:46:03,022] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:46:03,244] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:46:04,029] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:46:04,029] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:46:04,055] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res9/Eplus-env-sub_run6
[2019-04-17 15:46:12,871] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.80865183e-14 3.33082730e-19 9.82667744e-01 2.01006269e-12
 1.08781636e-10 4.46771323e-14 2.28124394e-11 2.89713498e-09
 2.58699201e-10 7.31616070e-12 1.73322577e-02], sum to 1.0000
[2019-04-17 15:46:12,872] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2860
[2019-04-17 15:46:12,958] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [10.33333333333333, 18.33333333333333, 0.0, 0.0, 22.5, 24.43985286218184, 0.1985002408534571, 0.0, 1.0, 25.0, 5.482252458684459], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 5082000.0000, 
sim time next is 5083200.0000, 
raw observation next is [10.0, 19.0, 0.0, 0.0, 22.5, 24.35205696711205, 0.1852142122864208, 0.0, 1.0, 25.0, 5.4172591591364245], 
processed observation next is [1.0, 0.8695652173913043, 0.739612188365651, 0.19, 0.0, 0.0, 0.375, 0.5293380805926707, 0.5617380707621403, 0.0, 1.0, 0.2, 0.05417259159136425], 
reward next is 0.7458, 
noisyNet noise sample is [array([-1.0513992], dtype=float32), -1.3124714]. 
=============================================
[2019-04-17 15:46:13,716] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:46:14,017] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:46:14,753] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:46:14,753] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:46:14,772] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res17/Eplus-env-sub_run6
[2019-04-17 15:46:17,660] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2853908e-12 6.4160157e-16 9.5141417e-01 9.8083219e-10 2.2924178e-09
 6.9753548e-12 3.3705305e-10 1.0073483e-07 2.6505781e-08 7.1661560e-10
 4.8585761e-02], sum to 1.0000
[2019-04-17 15:46:17,661] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4121
[2019-04-17 15:46:17,667] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.9087264e-13 3.5760197e-18 9.6680886e-01 6.5597146e-11 1.0242290e-09
 5.5432693e-13 9.0579932e-11 3.3983017e-08 1.3463314e-09 5.4621141e-11
 3.3191118e-02], sum to 1.0000
[2019-04-17 15:46:17,667] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3409
[2019-04-17 15:46:17,683] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 19.0, 20.30970212033456, -0.813006631529114, 0.0, 1.0, 25.0, 11.59124208222904], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 248400.0000, 
sim time next is 249600.0000, 
raw observation next is [-3.566666666666667, 68.33333333333334, 0.0, 0.0, 19.0, 20.22223946192596, -0.8343770489099863, 0.0, 1.0, 25.0, 11.829820660490094], 
processed observation next is [1.0, 0.9130434782608695, 0.3638042474607572, 0.6833333333333335, 0.0, 0.0, 0.08333333333333333, 0.18518662182716325, 0.22187431703000457, 0.0, 1.0, 0.2, 0.11829820660490094], 
reward next is 0.6817, 
noisyNet noise sample is [array([0.01236742], dtype=float32), -2.2303593]. 
=============================================
[2019-04-17 15:46:17,715] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.666666666666667, 69.0, 170.5, 472.5, 19.0, 20.98973728979642, -0.5442155149780573, 0.0, 1.0, 25.0, 11.385373693291395], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4786800.0000, 
sim time next is 4788000.0000, 
raw observation next is [-3.0, 65.0, 163.5, 575.5, 19.0, 21.03219576996877, -0.5502592543400332, 0.0, 1.0, 25.0, 10.137630791637406], 
processed observation next is [0.0, 0.43478260869565216, 0.3795013850415513, 0.65, 0.545, 0.6359116022099448, 0.08333333333333333, 0.25268298083073076, 0.3165802485533223, 0.0, 1.0, 0.2, 0.10137630791637406], 
reward next is 0.6986, 
noisyNet noise sample is [array([0.46102867], dtype=float32), -0.6770834]. 
=============================================
[2019-04-17 15:46:17,805] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6962701e-12 1.3191100e-16 9.5876688e-01 6.9886158e-10 1.7353199e-09
 1.4861716e-11 3.6799119e-10 3.1028804e-08 2.4611579e-08 3.6406278e-10
 4.1233119e-02], sum to 1.0000
[2019-04-17 15:46:17,805] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2675
[2019-04-17 15:46:17,835] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.0, 45.0, 152.8333333333333, 404.5, 19.0, 21.24313775758168, -0.5690728929536658, 0.0, 1.0, 25.0, 9.976132150093171], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4894800.0000, 
sim time next is 4896000.0000, 
raw observation next is [3.0, 45.0, 132.5, 369.5, 19.0, 21.22851023994715, -0.5704401016696797, 0.0, 1.0, 25.0, 9.009704616253185], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.45, 0.44166666666666665, 0.40828729281767956, 0.08333333333333333, 0.2690425199955957, 0.3098532994434401, 0.0, 1.0, 0.2, 0.09009704616253185], 
reward next is 0.7099, 
noisyNet noise sample is [array([-1.2840117], dtype=float32), -0.40045658]. 
=============================================
[2019-04-17 15:46:19,199] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.4970198e-12 7.2562275e-17 7.4665755e-01 4.4835641e-10 3.8386343e-09
 8.0315954e-12 4.3709483e-10 1.3237103e-07 1.4403924e-08 1.0801068e-09
 2.5334236e-01], sum to 1.0000
[2019-04-17 15:46:19,199] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.5097
[2019-04-17 15:46:19,211] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.666666666666667, 48.66666666666666, 0.0, 0.0, 19.0, 21.0065649695073, -0.699686066694624, 0.0, 1.0, 25.0, 22.77421457717091], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4945200.0000, 
sim time next is 4946400.0000, 
raw observation next is [-3.0, 50.0, 0.0, 0.0, 19.0, 20.82558869917056, -0.7194807202465099, 0.0, 1.0, 25.0, 20.81940142775454], 
processed observation next is [1.0, 0.2608695652173913, 0.3795013850415513, 0.5, 0.0, 0.0, 0.08333333333333333, 0.23546572493087994, 0.2601730932511634, 0.0, 1.0, 0.2, 0.2081940142775454], 
reward next is 0.5918, 
noisyNet noise sample is [array([-0.37960625], dtype=float32), 0.15990679]. 
=============================================
[2019-04-17 15:46:27,214] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:46:27,511] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:46:27,518] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:46:27,570] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:46:27,633] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:46:27,763] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:46:27,916] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:46:27,969] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:46:28,221] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:46:28,221] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:46:28,224] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res8/Eplus-env-sub_run6
[2019-04-17 15:46:28,375] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:46:28,513] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:46:28,513] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:46:28,517] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res2/Eplus-env-sub_run6
[2019-04-17 15:46:28,613] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:46:28,613] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:46:28,645] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:46:28,646] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:46:28,649] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res10/Eplus-env-sub_run6
[2019-04-17 15:46:28,709] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:46:28,709] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res4/Eplus-env-sub_run6
[2019-04-17 15:46:29,376] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:46:29,376] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:46:29,379] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res12/Eplus-env-sub_run6
[2019-04-17 15:46:31,426] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3599399e-11 3.4027698e-15 4.7884414e-01 8.3081240e-09 1.2786526e-08
 1.3030674e-10 2.8580485e-09 5.1249344e-07 5.4030380e-08 5.7217395e-09
 5.2115530e-01], sum to 1.0000
[2019-04-17 15:46:31,426] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0086
[2019-04-17 15:46:31,482] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.9, 86.0, 0.0, 0.0, 19.0, 18.8827452799225, -1.082520464698144, 0.0, 1.0, 65.0, 82.84515066991901], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 612000.0000, 
sim time next is 613200.0000, 
raw observation next is [-3.9, 82.33333333333334, 0.0, 0.0, 19.0, 19.36673805737391, -1.032836916016038, 0.0, 1.0, 25.0, 51.1701732010317], 
processed observation next is [0.0, 0.08695652173913043, 0.3545706371191136, 0.8233333333333335, 0.0, 0.0, 0.08333333333333333, 0.11389483811449264, 0.155721027994654, 0.0, 1.0, 0.2, 0.511701732010317], 
reward next is 0.2883, 
noisyNet noise sample is [array([-0.47081825], dtype=float32), -0.13790153]. 
=============================================
[2019-04-17 15:46:33,498] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:46:33,874] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-17 15:46:34,499] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-17 15:46:34,499] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:46:34,502] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res13/Eplus-env-sub_run6
[2019-04-17 15:46:36,368] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6152078e-11 3.4867249e-15 7.8779811e-01 3.6343553e-09 7.4679027e-09
 5.7415048e-11 2.6237763e-09 2.2870607e-07 5.6907624e-08 3.4350498e-09
 2.1220170e-01], sum to 1.0000
[2019-04-17 15:46:36,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3131
[2019-04-17 15:46:36,397] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.2, 57.0, 0.0, 0.0, 19.0, 20.603594191694, -0.7647221768163392, 0.0, 1.0, 25.0, 34.37442172997394], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 668400.0000, 
sim time next is 669600.0000, 
raw observation next is [-1.2, 57.0, 0.0, 0.0, 19.0, 20.4729683732291, -0.7882550475384971, 0.0, 1.0, 25.0, 30.93929156976062], 
processed observation next is [0.0, 0.782608695652174, 0.42936288088642666, 0.57, 0.0, 0.0, 0.08333333333333333, 0.20608069776909174, 0.23724831748716765, 0.0, 1.0, 0.2, 0.3093929156976062], 
reward next is 0.4906, 
noisyNet noise sample is [array([0.10930855], dtype=float32), -0.6421596]. 
=============================================
[2019-04-17 15:46:49,725] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1078159e-13 2.9650599e-18 9.1768658e-01 7.1105156e-11 2.1905396e-10
 5.1923743e-13 5.8383062e-11 9.5481996e-09 3.7712503e-10 6.7027724e-11
 8.2313351e-02], sum to 1.0000
[2019-04-17 15:46:49,726] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0438
[2019-04-17 15:46:49,892] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 20.80226853245019, -0.7375269185301678, 0.0, 1.0, 25.0, 31.48496302087145], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 889200.0000, 
sim time next is 890400.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 22.5, 20.72151659051208, -0.7216326535808032, 1.0, 1.0, 25.0, 40.24913217035556], 
processed observation next is [1.0, 0.30434782608695654, 0.46260387811634357, 0.72, 0.0, 0.0, 0.375, 0.2267930492093401, 0.25945578213973225, 1.0, 1.0, 0.2, 0.40249132170355556], 
reward next is 0.1589, 
noisyNet noise sample is [array([0.7048887], dtype=float32), 0.16220981]. 
=============================================
[2019-04-17 15:46:52,629] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0459365e-13 5.3413703e-18 8.1591785e-01 9.6730575e-11 7.4300316e-10
 9.7713656e-13 7.1788832e-11 4.3472241e-08 9.9215469e-10 9.1998478e-11
 1.8408214e-01], sum to 1.0000
[2019-04-17 15:46:52,629] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2243
[2019-04-17 15:46:52,804] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 20.87733929374553, -0.6786695235230932, 0.0, 1.0, 25.0, 23.72743961945134], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 888000.0000, 
sim time next is 889200.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 20.89267749928224, -0.6885641004470143, 0.0, 1.0, 25.0, 21.500471968468265], 
processed observation next is [1.0, 0.30434782608695654, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.24105645827351996, 0.2704786331843286, 0.0, 1.0, 0.2, 0.21500471968468265], 
reward next is 0.5850, 
noisyNet noise sample is [array([0.8272856], dtype=float32), -1.6413577]. 
=============================================
[2019-04-17 15:46:56,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6363883e-14 2.4017308e-19 9.7951573e-01 1.2769083e-11 4.4011364e-11
 1.2250746e-13 1.5524205e-11 5.2089186e-09 6.2441097e-10 9.8706460e-12
 2.0484308e-02], sum to 1.0000
[2019-04-17 15:46:56,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9073
[2019-04-17 15:46:56,884] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.8, 79.0, 0.0, 0.0, 19.0, 21.85057410403051, -0.4683582419976839, 0.0, 1.0, 25.0, 12.222923652184095], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 860400.0000, 
sim time next is 861600.0000, 
raw observation next is [-2.633333333333333, 79.33333333333334, 0.0, 0.0, 19.0, 21.75068910883455, -0.4898630909735651, 0.0, 1.0, 25.0, 12.27837876341471], 
processed observation next is [1.0, 1.0, 0.38965835641735924, 0.7933333333333334, 0.0, 0.0, 0.08333333333333333, 0.3125574257362125, 0.33671230300881166, 0.0, 1.0, 0.2, 0.12278378763414709], 
reward next is 0.6772, 
noisyNet noise sample is [array([-2.4970994], dtype=float32), 0.33123165]. 
=============================================
[2019-04-17 15:46:59,546] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8977261e-13 1.4045365e-17 9.5460534e-01 1.5664699e-10 2.9481992e-10
 2.7311849e-12 1.6008884e-10 1.3640405e-08 3.8682622e-09 1.8086445e-10
 4.5394633e-02], sum to 1.0000
[2019-04-17 15:46:59,546] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6230
[2019-04-17 15:46:59,559] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.766666666666667, 63.0, 143.6666666666667, 0.0, 22.5, 21.79272208448975, -0.5082680993165098, 1.0, 1.0, 25.0, 12.616828324984525], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 222000.0000, 
sim time next is 223200.0000, 
raw observation next is [-3.4, 62.0, 133.0, 0.0, 22.5, 21.90866942077536, -0.4952543032078731, 1.0, 1.0, 25.0, 11.12627785813092], 
processed observation next is [1.0, 0.6086956521739131, 0.368421052631579, 0.62, 0.44333333333333336, 0.0, 0.375, 0.32572245173128006, 0.3349152322640423, 1.0, 1.0, 0.2, 0.11126277858130919], 
reward next is 0.6887, 
noisyNet noise sample is [array([-0.40732434], dtype=float32), -0.74538094]. 
=============================================
[2019-04-17 15:47:01,930] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3541766e-16 3.1804135e-22 9.9046892e-01 1.4367395e-13 1.9871858e-12
 1.3928212e-15 4.4272420e-13 1.7733170e-10 4.5458953e-12 2.5176828e-13
 9.5310705e-03], sum to 1.0000
[2019-04-17 15:47:01,936] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9536
[2019-04-17 15:47:01,999] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.5, 75.0, 41.0, 0.0, 22.5, 24.63324617947525, 0.2669129480187185, 1.0, 1.0, 25.0, 7.727141969391246], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1008000.0000, 
sim time next is 1009200.0000, 
raw observation next is [15.5, 76.0, 30.33333333333334, 0.0, 22.5, 24.62002044430472, 0.09592406024766797, 1.0, 1.0, 25.0, 7.5615818815494364], 
processed observation next is [1.0, 0.6956521739130435, 0.8919667590027703, 0.76, 0.10111111111111114, 0.0, 0.375, 0.5516683703587267, 0.5319746867492227, 1.0, 1.0, 0.2, 0.07561581881549437], 
reward next is 0.7244, 
noisyNet noise sample is [array([0.09732044], dtype=float32), 0.31839982]. 
=============================================
[2019-04-17 15:47:09,985] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-17 15:47:09,985] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-17 15:47:09,985] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:47:09,995] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Train-v3-res1/Eplus-env-sub_run8
[2019-04-17 15:47:10,021] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation job starts!
[2019-04-17 15:47:10,022] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:47:10,024] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v1-res1/Eplus-env-sub_run8
[2019-04-17 15:47:10,068] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation job starts!
[2019-04-17 15:47:10,069] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-17 15:47:10,071] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_heavy/3/Eplus-env-Part4-Heavy-Pit-Test-v2-res1/Eplus-env-sub_run8
[2019-04-17 15:47:51,326] A3C_EVAL-Part4-Heavy-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.18727629], dtype=float32), 0.2429702]
[2019-04-17 15:47:51,326] A3C_EVAL-Part4-Heavy-Pit-Test-v2 DEBUG:Observation this: [-2.691261003, 84.09782579333333, 0.0, 0.0, 19.0, 20.45227833182873, -0.7939524522379275, 0.0, 1.0, 25.0, 11.37899948173454]
[2019-04-17 15:47:51,326] A3C_EVAL-Part4-Heavy-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-04-17 15:47:51,328] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Softmax [1.0009793e-11 1.2452138e-15 7.8849846e-01 2.3608950e-09 3.4195173e-09
 3.3084199e-11 1.4879417e-09 1.5058846e-07 2.7797840e-08 2.1136299e-09
 2.1150137e-01], sampled 0.8089527145151232
[2019-04-17 15:47:52,451] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.18727629], dtype=float32), 0.2429702]
[2019-04-17 15:47:52,451] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:Observation this: [-0.1, 56.0, 0.0, 0.0, 19.0, 22.88309979118741, -0.1904306621298677, 0.0, 1.0, 25.0, 17.9091735477604]
[2019-04-17 15:47:52,451] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-04-17 15:47:52,452] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Softmax [1.1989883e-11 1.4326217e-15 9.0985888e-01 2.5572418e-09 2.6878550e-09
 2.4391064e-11 1.4288029e-09 1.5639547e-07 2.4851307e-08 1.8309033e-09
 9.0140998e-02], sampled 0.34517621663143894
[2019-04-17 15:48:16,750] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.18727629], dtype=float32), 0.2429702]
[2019-04-17 15:48:16,750] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:Observation this: [-5.533333333333333, 67.33333333333333, 0.0, 0.0, 19.0, 22.44804763297451, -0.2924580347361031, 0.0, 1.0, 25.0, 21.184171397279435]
[2019-04-17 15:48:16,750] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-04-17 15:48:16,751] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Softmax [1.6619185e-11 1.3239662e-15 9.1469479e-01 2.0424313e-09 3.0073923e-09
 2.1732924e-11 1.3827270e-09 1.4106796e-07 1.9601909e-08 1.9830615e-09
 8.5305162e-02], sampled 0.8978599610252987
[2019-04-17 15:48:19,238] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.18727629], dtype=float32), 0.2429702]
[2019-04-17 15:48:19,238] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:Observation this: [2.7, 65.0, 208.5, 251.5, 22.5, 23.53385969097472, 0.02329739953615799, 1.0, 1.0, 25.0, 13.074152839688114]
[2019-04-17 15:48:19,239] A3C_EVAL-Part4-Heavy-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-04-17 15:48:19,239] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Softmax [4.8789716e-13 2.2987755e-17 9.2092621e-01 2.1081470e-10 4.5739973e-10
 1.3241087e-12 1.3493376e-10 1.3715843e-08 3.3861531e-09 2.1844131e-10
 7.9073824e-02], sampled 0.8342450388589385
[2019-04-17 15:48:50,218] A3C_EVAL-Part4-Heavy-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2059.0424 123056.7239 599.0655
[2019-04-17 15:48:50,238] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:48:50,238] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:48:50,238] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:48:50,238] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:48:50,238] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:48:50,238] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:48:50,238] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:48:50,238] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:48:50,341] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:48:50,341] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:48:50,341] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:48:50,341] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:48:50,341] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:48:50,341] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:48:50,341] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:48:50,341] EPLUS_ENV_Part4-Heavy-Pit-Test-v1_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:01,900] A3C_EVAL-Part4-Heavy-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2035.3555 131416.5651 382.0539
[2019-04-17 15:49:01,920] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:01,920] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:01,920] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:01,920] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:01,920] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:01,920] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:01,920] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:01,920] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:02,022] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:02,022] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:02,022] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:02,022] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:02,022] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:02,022] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:02,022] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:02,022] EPLUS_ENV_Part4-Heavy-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:07,659] A3C_EVAL-Part4-Heavy-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2024.4347 131449.5913 128.1501
[2019-04-17 15:49:07,679] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:07,679] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:07,679] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:07,679] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:07,679] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:07,679] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:07,679] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:07,679] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-17 15:49:07,777] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:07,777] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:07,777] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:07,777] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:07,777] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:07,777] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:07,777] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:07,777] EPLUS_ENV_Part4-Heavy-Pit-Test-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-17 15:49:08,840] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 350000, evaluation results [350000.0, 2035.3554789076175, 131416.5651471761, 382.05391501595227, 2059.0423848492296, 123056.72387346922, 599.0655118221838, 2024.4346513676376, 131449.59128526025, 128.15014336678166]
[2019-04-17 15:49:18,953] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3519814e-12 6.5576777e-16 9.0562862e-01 7.7189755e-10 2.1673481e-09
 1.0698814e-11 6.7671907e-10 1.7284107e-07 3.1552613e-08 1.1541609e-09
 9.4371095e-02], sum to 1.0000
[2019-04-17 15:49:18,953] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6811
[2019-04-17 15:49:18,972] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.5, 93.0, 0.0, 0.0, 19.0, 27.31980529140887, 1.047702400200921, 0.0, 0.0, 25.0, 8.83265417176455], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1221600.0000, 
sim time next is 1222800.0000, 
raw observation next is [15.5, 93.0, 0.0, 0.0, 19.0, 27.24169486564843, 1.034323590947233, 0.0, 0.0, 25.0, 8.234683031170517], 
processed observation next is [0.0, 0.13043478260869565, 0.8919667590027703, 0.93, 0.0, 0.0, 0.08333333333333333, 0.7701412388040358, 0.8447745303157443, 0.0, 0.0, 0.2, 0.08234683031170517], 
reward next is 0.7177, 
noisyNet noise sample is [array([-1.0893309], dtype=float32), 1.770052]. 
=============================================
[2019-04-17 15:49:19,543] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7376268e-14 2.9018721e-19 9.1055292e-01 1.4760550e-11 9.5904160e-11
 3.1292890e-14 7.7535556e-12 6.3092958e-09 3.6022502e-10 2.6801108e-11
 8.9447066e-02], sum to 1.0000
[2019-04-17 15:49:19,543] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1813
[2019-04-17 15:49:19,555] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.7, 80.0, 0.0, 0.0, 19.0, 26.0119371081854, 0.6962390506259366, 0.0, 1.0, 25.0, 21.660619889182378], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1148400.0000, 
sim time next is 1149600.0000, 
raw observation next is [12.7, 81.33333333333334, 0.0, 0.0, 19.0, 25.98172825119945, 0.688975688963335, 0.0, 1.0, 25.0, 19.781845331157818], 
processed observation next is [0.0, 0.30434782608695654, 0.8144044321329641, 0.8133333333333335, 0.0, 0.0, 0.08333333333333333, 0.6651440209332874, 0.7296585629877783, 0.0, 1.0, 0.2, 0.19781845331157819], 
reward next is 0.6022, 
noisyNet noise sample is [array([0.1300482], dtype=float32), -1.0634112]. 
=============================================
[2019-04-17 15:49:26,046] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9326712e-14 5.4299718e-19 9.8050058e-01 1.7023907e-11 9.5580419e-11
 1.9391735e-14 1.3508076e-11 2.6851645e-09 1.7024498e-10 2.0348423e-11
 1.9499432e-02], sum to 1.0000
[2019-04-17 15:49:26,047] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1380
[2019-04-17 15:49:26,068] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.7000000000000001, 92.0, 91.0, 0.0, 22.5, 22.53837025661187, -0.1854952077388943, 1.0, 1.0, 25.0, 10.073593952454136], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1430400.0000, 
sim time next is 1431600.0000, 
raw observation next is [0.9000000000000001, 92.0, 87.0, 0.0, 22.5, 22.78848133342397, -0.1629404348443551, 1.0, 1.0, 25.0, 9.987587534108105], 
processed observation next is [1.0, 0.5652173913043478, 0.48753462603878117, 0.92, 0.29, 0.0, 0.375, 0.39904011111866416, 0.44568652171854833, 1.0, 1.0, 0.2, 0.09987587534108106], 
reward next is 0.7001, 
noisyNet noise sample is [array([0.9370399], dtype=float32), -0.4015517]. 
=============================================
[2019-04-17 15:49:26,805] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6230428e-12 1.2823316e-16 8.1568485e-01 8.0813339e-10 3.6073500e-10
 5.5162853e-12 3.8605227e-10 4.2011578e-08 8.5747720e-09 8.4727186e-10
 1.8431516e-01], sum to 1.0000
[2019-04-17 15:49:26,805] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8444
[2019-04-17 15:49:26,835] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-1.7, 87.0, 0.0, 0.0, 19.0, 22.57834271238788, -0.196388315991025, 0.0, 1.0, 25.0, 35.683327485651986], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 1754400.0000, 
sim time next is 1755600.0000, 
raw observation next is [-1.7, 87.0, 0.0, 0.0, 19.0, 22.54404342014331, -0.1563108551429043, 0.0, 1.0, 65.0, 66.98707481254183], 
processed observation next is [0.0, 0.30434782608695654, 0.4155124653739613, 0.87, 0.0, 0.0, 0.08333333333333333, 0.37867028501194255, 0.44789638161903195, 0.0, 1.0, 1.0, 0.6698707481254184], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.79754823], dtype=float32), 0.252864]. 
=============================================
[2019-04-17 15:49:28,664] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.4028596e-15 2.4959690e-20 9.8649931e-01 2.3947350e-12 2.3275926e-11
 5.4757635e-15 2.5966206e-12 6.6534001e-10 8.0800235e-11 5.8746905e-12
 1.3500741e-02], sum to 1.0000
[2019-04-17 15:49:28,665] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1691
[2019-04-17 15:49:28,690] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [6.800000000000001, 84.66666666666667, 0.0, 0.0, 19.0, 23.09727257174266, -0.002438404199453625, 0.0, 1.0, 25.0, 8.57989962200448], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1635600.0000, 
sim time next is 1636800.0000, 
raw observation next is [7.0, 83.33333333333334, 0.0, 0.0, 19.0, 22.99332647361689, -0.01040179489961819, 0.0, 1.0, 25.0, 8.779465696314384], 
processed observation next is [1.0, 0.9565217391304348, 0.6565096952908588, 0.8333333333333335, 0.0, 0.0, 0.08333333333333333, 0.41611053946807414, 0.49653273503346057, 0.0, 1.0, 0.2, 0.08779465696314384], 
reward next is 0.7122, 
noisyNet noise sample is [array([-1.0330501], dtype=float32), 1.5047716]. 
=============================================
[2019-04-17 15:49:29,769] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6294124e-15 5.2177200e-21 9.8537397e-01 5.5920702e-12 1.3560671e-11
 7.7031700e-15 8.5385744e-12 1.3744448e-09 9.0973867e-11 3.4787381e-12
 1.4625974e-02], sum to 1.0000
[2019-04-17 15:49:29,770] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7063
[2019-04-17 15:49:29,860] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [10.53333333333333, 59.33333333333334, 76.66666666666666, 669.3333333333333, 22.5, 24.81428466908292, 0.2701785934048377, 1.0, 1.0, 25.0, 15.842568863442976], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1520400.0000, 
sim time next is 1521600.0000, 
raw observation next is [11.06666666666667, 55.66666666666667, 75.33333333333333, 632.1666666666666, 22.5, 24.8825032228136, 0.2943274336190438, 1.0, 1.0, 25.0, 13.994890718788628], 
processed observation next is [1.0, 0.6086956521739131, 0.7691597414589106, 0.5566666666666668, 0.2511111111111111, 0.6985267034990792, 0.375, 0.5735419352344667, 0.5981091445396812, 1.0, 1.0, 0.2, 0.13994890718788627], 
reward next is 0.6601, 
noisyNet noise sample is [array([-2.2788496], dtype=float32), -1.4485726]. 
=============================================
[2019-04-17 15:49:30,863] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.7280437e-14 2.0075976e-19 9.8508191e-01 1.9748000e-11 2.6052200e-11
 4.9709972e-14 8.6238239e-12 3.6795000e-09 3.5629381e-11 1.6020078e-11
 1.4918046e-02], sum to 1.0000
[2019-04-17 15:49:30,867] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5349
[2019-04-17 15:49:30,902] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.7000000000000001, 90.66666666666666, 0.0, 0.0, 19.0, 22.21737746117417, -0.1739868730009316, 0.0, 1.0, 25.0, 12.19176092608502], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1716000.0000, 
sim time next is 1717200.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 19.0, 22.14310509778205, -0.189337313454658, 0.0, 1.0, 25.0, 12.34813072718212], 
processed observation next is [1.0, 0.9130434782608695, 0.4764542936288089, 0.92, 0.0, 0.0, 0.08333333333333333, 0.34525875814850426, 0.43688756218178065, 0.0, 1.0, 0.2, 0.1234813072718212], 
reward next is 0.6765, 
noisyNet noise sample is [array([-0.05605002], dtype=float32), -0.4141915]. 
=============================================
[2019-04-17 15:49:31,328] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [9.6206781e-15 1.7984858e-19 9.7258389e-01 3.6211895e-12 2.4628573e-11
 3.5413651e-14 3.4863119e-12 3.2181846e-09 1.0817914e-10 4.1015845e-12
 2.7416106e-02], sum to 1.0000
[2019-04-17 15:49:31,329] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.9546
[2019-04-17 15:49:31,375] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 22.5, 21.39422215971122, -0.4970545074835828, 0.0, 1.0, 25.0, 7.379210104097698], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1018800.0000, 
sim time next is 1020000.0000, 
raw observation next is [14.4, 79.66666666666667, 0.0, 0.0, 22.5, 21.40020659734634, -0.5086310865576449, 1.0, 1.0, 25.0, 7.473628564353419], 
processed observation next is [1.0, 0.8260869565217391, 0.8614958448753465, 0.7966666666666667, 0.0, 0.0, 0.375, 0.2833505497788617, 0.33045630448078506, 1.0, 1.0, 0.2, 0.07473628564353418], 
reward next is 0.7353, 
noisyNet noise sample is [array([1.3842491], dtype=float32), 0.94152707]. 
=============================================
[2019-04-17 15:49:31,404] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[57.106857]
 [57.52127 ]
 [57.571117]
 [57.622353]
 [57.49978 ]
 [57.492447]
 [57.50786 ]
 [57.559937]
 [57.515736]
 [57.59125 ]
 [57.66394 ]
 [57.673985]
 [57.714962]
 [57.699093]
 [57.77238 ]
 [57.7139  ]
 [57.64808 ]
 [57.57216 ]
 [57.551304]
 [57.48102 ]
 [57.34186 ]
 [57.17936 ]
 [57.001667]
 [56.763523]
 [56.550114]], R is [[57.73571014]
 [57.88455963]
 [58.05103302]
 [58.21294785]
 [58.36076355]
 [58.50802231]
 [58.65455246]
 [58.80036163]
 [58.94428635]
 [59.084198  ]
 [59.22471237]
 [59.36324692]
 [59.49966812]
 [59.63436508]
 [59.78934479]
 [59.8999939 ]
 [60.02839279]
 [60.15406799]
 [60.2768631 ]
 [60.40949249]
 [60.52950287]
 [60.64791107]
 [60.76404572]
 [60.88638687]
 [61.0209465 ]].
[2019-04-17 15:49:31,902] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.2829527e-14 5.5923827e-20 9.0582919e-01 6.4298003e-12 2.8265694e-11
 4.0723189e-14 4.7965941e-12 3.8441708e-09 4.4395970e-11 6.0797921e-12
 9.4170809e-02], sum to 1.0000
[2019-04-17 15:49:31,903] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3946
[2019-04-17 15:49:31,924] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.4, 75.0, 0.0, 0.0, 19.0, 22.40141703668036, -0.2512734130224252, 0.0, 1.0, 25.0, 44.74354056322187], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1038000.0000, 
sim time next is 1039200.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 19.0, 22.56082304701917, -0.2524048400293189, 0.0, 1.0, 25.0, 38.6580649145006], 
processed observation next is [1.0, 0.0, 0.8614958448753465, 0.75, 0.0, 0.0, 0.08333333333333333, 0.3800685872515975, 0.4158650533235604, 0.0, 1.0, 0.2, 0.386580649145006], 
reward next is 0.4134, 
noisyNet noise sample is [array([0.5280951], dtype=float32), -0.11385493]. 
=============================================
[2019-04-17 15:49:33,648] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.95311030e-15 2.58481663e-20 9.68475223e-01 7.86552854e-12
 1.14306474e-10 3.84142892e-14 4.00832579e-12 1.13289866e-09
 1.18446003e-10 6.12135819e-12 3.15247588e-02], sum to 1.0000
[2019-04-17 15:49:33,651] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1895
[2019-04-17 15:49:33,669] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.53333333333333, 86.0, 126.5, 0.0, 22.5, 21.58166848330449, -0.4679675559393308, 1.0, 1.0, 25.0, 7.500157732178156], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 996000.0000, 
sim time next is 997200.0000, 
raw observation next is [12.7, 86.0, 123.5, 0.0, 22.5, 21.57169191840777, -0.4706297373784823, 1.0, 1.0, 25.0, 7.384322415136719], 
processed observation next is [1.0, 0.5652173913043478, 0.8144044321329641, 0.86, 0.4116666666666667, 0.0, 0.375, 0.2976409932006474, 0.34312342087383924, 1.0, 1.0, 0.2, 0.07384322415136718], 
reward next is 0.7262, 
noisyNet noise sample is [array([1.6902999], dtype=float32), -2.1499965]. 
=============================================
[2019-04-17 15:49:43,241] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [1.7961074e-14 9.8215419e-20 9.8248971e-01 3.6432888e-12 2.4280256e-10
 3.2491374e-14 4.9031890e-12 2.8078011e-09 6.0462316e-11 9.2650020e-12
 1.7510330e-02], sum to 1.0000
[2019-04-17 15:49:43,241] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2390
[2019-04-17 15:49:43,270] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 95.0, 87.0, 0.0, 22.5, 24.11535978757873, 0.1578513866619304, 1.0, 1.0, 25.0, 12.493798578028066], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1423200.0000, 
sim time next is 1424400.0000, 
raw observation next is [0.0, 95.0, 91.0, 0.0, 22.5, 24.06713617858867, 0.1564473860514438, 1.0, 1.0, 25.0, 11.489277677784525], 
processed observation next is [1.0, 0.4782608695652174, 0.46260387811634357, 0.95, 0.30333333333333334, 0.0, 0.375, 0.5055946815490557, 0.5521491286838146, 1.0, 1.0, 0.2, 0.11489277677784525], 
reward next is 0.6851, 
noisyNet noise sample is [array([0.03826063], dtype=float32), -0.554201]. 
=============================================
[2019-04-17 15:49:43,344] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5619785e-14 1.4585347e-19 8.9848644e-01 4.1913313e-11 1.6271268e-10
 1.0403807e-13 7.1361810e-12 9.4397725e-09 1.4855336e-10 2.9811376e-11
 1.0151357e-01], sum to 1.0000
[2019-04-17 15:49:43,344] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2879
[2019-04-17 15:49:43,372] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.4, 98.33333333333333, 0.0, 0.0, 19.0, 23.2881004096726, 0.04493963717700687, 0.0, 1.0, 25.0, 9.979793075070326], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1395600.0000, 
sim time next is 1396800.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 19.0, 23.17614243820475, 0.02400987028227186, 0.0, 1.0, 25.0, 10.08064724736916], 
processed observation next is [1.0, 0.17391304347826086, 0.44598337950138506, 1.0, 0.0, 0.0, 0.08333333333333333, 0.4313452031837291, 0.5080032900940906, 0.0, 1.0, 0.2, 0.10080647247369161], 
reward next is 0.6992, 
noisyNet noise sample is [array([0.5458441], dtype=float32), -0.49892297]. 
=============================================
[2019-04-17 15:49:44,159] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.1875344e-12 9.7478786e-16 9.1672802e-01 1.2728907e-09 1.0722316e-08
 8.7805832e-11 1.2912796e-09 1.6798263e-07 2.7915791e-08 2.7110054e-09
 8.3271734e-02], sum to 1.0000
[2019-04-17 15:49:44,159] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3314
[2019-04-17 15:49:44,177] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.6, 83.0, 85.5, 0.0, 22.5, 19.37462308780185, -1.125697014122308, 1.0, 1.0, 25.0, 17.17963356550664], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2023200.0000, 
sim time next is 2024400.0000, 
raw observation next is [-5.6, 83.0, 96.5, 0.0, 22.5, 19.38617802870025, -1.120643655271797, 1.0, 1.0, 25.0, 17.36491927315153], 
processed observation next is [1.0, 0.43478260869565216, 0.30747922437673136, 0.83, 0.32166666666666666, 0.0, 0.375, 0.11551483572502086, 0.12645211490940098, 1.0, 1.0, 0.2, 0.17364919273151527], 
reward next is 0.0505, 
noisyNet noise sample is [array([-1.1180834], dtype=float32), 0.9904314]. 
=============================================
[2019-04-17 15:49:47,414] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [1.1174374e-14 9.7776064e-20 9.5807952e-01 1.0359943e-11 2.8557184e-11
 2.7597191e-14 4.2116627e-12 3.5583028e-09 7.0530901e-11 5.3046495e-12
 4.1920487e-02], sum to 1.0000
[2019-04-17 15:49:47,425] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6781
[2019-04-17 15:49:47,450] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 19.0, 22.91672685626528, -0.06557638966121491, 0.0, 1.0, 25.0, 16.640538518795505], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1399200.0000, 
sim time next is 1400400.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 19.0, 22.80578300720126, -0.0986872259266619, 0.0, 1.0, 25.0, 15.1308053406068], 
processed observation next is [1.0, 0.21739130434782608, 0.44598337950138506, 1.0, 0.0, 0.0, 0.08333333333333333, 0.4004819172667717, 0.46710425802444605, 0.0, 1.0, 0.2, 0.151308053406068], 
reward next is 0.6487, 
noisyNet noise sample is [array([-1.1299359], dtype=float32), -0.92880446]. 
=============================================
[2019-04-17 15:49:48,641] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.3441969e-12 5.1536984e-16 9.6770179e-01 3.5800879e-10 5.1188991e-09
 7.6797943e-12 6.7230310e-10 3.3586844e-08 5.2091491e-09 5.4642535e-10
 3.2298252e-02], sum to 1.0000
[2019-04-17 15:49:48,642] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4636
[2019-04-17 15:49:48,681] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.2, 52.66666666666667, 0.0, 0.0, 22.5, 21.02473247965225, -0.6730114525326755, 1.0, 1.0, 25.0, 10.600056781911249], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2312400.0000, 
sim time next is 2313600.0000, 
raw observation next is [-1.2, 53.33333333333334, 0.0, 0.0, 22.5, 20.88903895273878, -0.6860999772419016, 1.0, 1.0, 25.0, 10.833136513029025], 
processed observation next is [1.0, 0.782608695652174, 0.42936288088642666, 0.5333333333333334, 0.0, 0.0, 0.375, 0.24075324606156498, 0.2713000075860328, 1.0, 1.0, 0.2, 0.10833136513029025], 
reward next is 0.1127, 
noisyNet noise sample is [array([-0.19744952], dtype=float32), -0.92529386]. 
=============================================
[2019-04-17 15:49:48,714] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.1341928e-12 4.5478274e-17 7.5659692e-01 6.6498429e-10 2.1915318e-09
 4.9816180e-12 1.1841560e-10 5.4596878e-08 1.2607805e-09 4.1447146e-10
 2.4340294e-01], sum to 1.0000
[2019-04-17 15:49:48,724] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5005
[2019-04-17 15:49:48,749] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-4.833333333333333, 86.0, 0.0, 0.0, 19.0, 21.0712342065195, -0.6480379745676567, 0.0, 1.0, 25.0, 15.03817031558145], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2083200.0000, 
sim time next is 2084400.0000, 
raw observation next is [-5.0, 86.0, 0.0, 0.0, 19.0, 20.95908041227266, -0.6642887871846097, 0.0, 1.0, 25.0, 15.2241618861629], 
processed observation next is [1.0, 0.13043478260869565, 0.32409972299168976, 0.86, 0.0, 0.0, 0.08333333333333333, 0.2465900343560549, 0.27857040427179675, 0.0, 1.0, 0.2, 0.152241618861629], 
reward next is 0.6478, 
noisyNet noise sample is [array([1.0629414], dtype=float32), -0.09907802]. 
=============================================
[2019-04-17 15:49:48,946] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9068318e-14 2.3482662e-19 9.3159026e-01 1.2334108e-11 1.5486386e-10
 9.4294296e-14 1.2279368e-11 2.3599660e-09 2.2360537e-10 2.1225426e-11
 6.8409748e-02], sum to 1.0000
[2019-04-17 15:49:48,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7326
[2019-04-17 15:49:48,981] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.2, 96.0, 0.0, 0.0, 19.0, 21.80596962061065, -0.3305980357744529, 0.0, 1.0, 25.0, 8.741768564753626], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1486800.0000, 
sim time next is 1488000.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 19.0, 21.70434636258731, -0.3449412768753873, 0.0, 1.0, 25.0, 8.250630065514773], 
processed observation next is [1.0, 0.21739130434782608, 0.5235457063711911, 0.96, 0.0, 0.0, 0.08333333333333333, 0.3086955302156091, 0.38501957437487094, 0.0, 1.0, 0.2, 0.08250630065514773], 
reward next is 0.7175, 
noisyNet noise sample is [array([1.4510704], dtype=float32), 0.47962987]. 
=============================================
[2019-04-17 15:49:54,649] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3409563e-12 5.1553813e-17 9.4242162e-01 2.9448574e-10 1.4406812e-09
 3.2141865e-12 5.8181482e-10 7.8115512e-08 3.9305754e-09 3.5724171e-10
 5.7578292e-02], sum to 1.0000
[2019-04-17 15:49:54,649] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2092
[2019-04-17 15:49:54,702] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-7.833333333333334, 84.0, 91.66666666666667, 35.16666666666666, 22.5, 21.11183328406891, -0.6829290841927849, 1.0, 1.0, 25.0, 15.23395524059865], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 2280000.0000, 
sim time next is 2281200.0000, 
raw observation next is [-7.266666666666667, 81.0, 113.8333333333333, 40.83333333333333, 22.5, 21.14260634701166, -0.6750096473810546, 1.0, 1.0, 25.0, 13.771637730814628], 
processed observation next is [1.0, 0.391304347826087, 0.26131117266851345, 0.81, 0.3794444444444443, 0.04511970534069981, 0.375, 0.26188386225097177, 0.2749967842063151, 1.0, 1.0, 0.2, 0.1377163773081463], 
reward next is 0.2614, 
noisyNet noise sample is [array([0.05158912], dtype=float32), -2.6309211]. 
=============================================
[2019-04-17 15:50:25,497] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.12386894e-13 8.72082292e-18 8.77693355e-01 9.90848306e-11
 5.75238357e-10 8.73099715e-13 6.62874616e-11 4.51209772e-08
 1.65075720e-09 1.69448941e-10 1.22306615e-01], sum to 1.0000
[2019-04-17 15:50:25,498] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9460
[2019-04-17 15:50:25,535] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-8.0, 77.0, 0.0, 0.0, 19.0, 23.29728797922716, -0.04210897305241229, 0.0, 1.0, 25.0, 31.554760213800364], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 3292800.0000, 
sim time next is 3294000.0000, 
raw observation next is [-8.0, 77.0, 0.0, 0.0, 19.0, 23.10610463276674, -0.01481535521741493, 0.0, 1.0, 65.0, 67.71412737233975], 
processed observation next is [1.0, 0.13043478260869565, 0.24099722991689754, 0.77, 0.0, 0.0, 0.08333333333333333, 0.4255087193972284, 0.49506154826086174, 0.0, 1.0, 1.0, 0.6771412737233975], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.67646843], dtype=float32), 0.9778193]. 
=============================================
[2019-04-17 15:50:41,730] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.6859066e-12 1.5655521e-16 9.2460954e-01 6.4103223e-10 2.6040832e-09
 1.6151042e-11 1.7365472e-09 8.9133486e-08 5.2779909e-09 7.9764056e-10
 7.5390302e-02], sum to 1.0000
[2019-04-17 15:50:41,730] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0676
[2019-04-17 15:50:41,764] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.666666666666667, 63.66666666666667, 0.0, 0.0, 19.0, 20.07826014538463, -0.8931070962044441, 0.0, 1.0, 25.0, 24.232031205655794], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3390000.0000, 
sim time next is 3391200.0000, 
raw observation next is [-3.0, 60.0, 0.0, 0.0, 19.0, 19.85774951556506, -0.9300230664436007, 0.0, 1.0, 25.0, 21.341037218786788], 
processed observation next is [1.0, 0.2608695652173913, 0.3795013850415513, 0.6, 0.0, 0.0, 0.08333333333333333, 0.15481245963042176, 0.18999231118546644, 0.0, 1.0, 0.2, 0.21341037218786787], 
reward next is 0.5866, 
noisyNet noise sample is [array([-0.18272114], dtype=float32), -1.767166]. 
=============================================
[2019-04-17 15:50:41,923] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.2439755e-13 7.5489320e-19 9.1429371e-01 1.2030810e-10 1.7533561e-10
 1.8302615e-13 2.8918251e-11 6.2857710e-09 7.7413359e-10 9.5177338e-11
 8.5706286e-02], sum to 1.0000
[2019-04-17 15:50:41,930] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9700
[2019-04-17 15:50:41,963] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [1.0, 83.66666666666667, 0.0, 0.0, 19.0, 20.74765632384883, -0.6624261544577689, 0.0, 1.0, 25.0, 12.85947704220986], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 3457200.0000, 
sim time next is 3458400.0000, 
raw observation next is [1.0, 81.33333333333334, 0.0, 0.0, 19.0, 20.77013969266391, -0.6092401332384648, 0.0, 1.0, 65.0, 90.92522761561392], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.8133333333333335, 0.0, 0.0, 0.08333333333333333, 0.23084497438865922, 0.2969199555871784, 0.0, 1.0, 1.0, 0.9092522761561392], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00880793], dtype=float32), 0.03027802]. 
=============================================
[2019-04-17 15:50:50,238] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [1.2837114e-12 2.1800583e-16 9.1188508e-01 6.0644340e-10 8.5631263e-10
 1.1441945e-11 1.7297916e-10 3.3583518e-08 1.2889842e-08 1.5247702e-09
 8.8114917e-02], sum to 1.0000
[2019-04-17 15:50:50,245] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8262
[2019-04-17 15:50:50,261] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.333333333333333, 63.66666666666667, 0.0, 0.0, 19.0, 21.84547901001475, -0.3705281399611486, 0.0, 1.0, 25.0, 13.127939400482855], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3547200.0000, 
sim time next is 3548400.0000, 
raw observation next is [-2.666666666666667, 67.33333333333333, 0.0, 0.0, 19.0, 21.76506847780885, -0.389928615483742, 0.0, 1.0, 25.0, 13.07321441669763], 
processed observation next is [0.0, 0.043478260869565216, 0.38873499538319484, 0.6733333333333333, 0.0, 0.0, 0.08333333333333333, 0.3137557064840708, 0.37002379483875264, 0.0, 1.0, 0.2, 0.1307321441669763], 
reward next is 0.6693, 
noisyNet noise sample is [array([-0.05378391], dtype=float32), 0.2586091]. 
=============================================
[2019-04-17 15:50:50,524] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3241880e-15 2.2080511e-19 9.8544508e-01 3.2237186e-12 2.4462403e-11
 7.2680814e-14 4.1646946e-12 9.9856201e-10 9.8933473e-11 8.3554092e-12
 1.4554936e-02], sum to 1.0000
[2019-04-17 15:50:50,525] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7032
[2019-04-17 15:50:50,544] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 22.44834451091673, -0.2648720285145538, 0.0, 1.0, 25.0, 22.01363275492649], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3481200.0000, 
sim time next is 3482400.0000, 
raw observation next is [-0.3333333333333333, 71.66666666666667, 0.0, 0.0, 22.5, 22.28826849658259, -0.282712620866692, 0.0, 1.0, 25.0, 21.61332788720136], 
processed observation next is [1.0, 0.30434782608695654, 0.4533702677747, 0.7166666666666667, 0.0, 0.0, 0.375, 0.35735570804854905, 0.4057624597111027, 0.0, 1.0, 0.2, 0.2161332788720136], 
reward next is 0.5839, 
noisyNet noise sample is [array([-0.3001997], dtype=float32), 0.48749337]. 
=============================================
[2019-04-17 15:50:55,277] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.22593671e-10 2.16246766e-14 9.31848049e-01 4.03692768e-09
 7.83675880e-09 1.01806785e-10 6.66572841e-09 6.09037329e-07
 7.30281400e-08 9.73196990e-09 6.81512430e-02], sum to 1.0000
[2019-04-17 15:50:55,277] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6513
[2019-04-17 15:50:55,300] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [0.6666666666666666, 39.66666666666666, 79.5, 641.8333333333334, 19.0, 20.10921244440354, -0.8134552867185373, 0.0, 1.0, 25.0, 10.40260561102185], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3080400.0000, 
sim time next is 3081600.0000, 
raw observation next is [1.0, 40.0, 70.5, 579.5, 19.0, 20.15938701943796, -0.8170913845654391, 0.0, 1.0, 25.0, 9.521836084564377], 
processed observation next is [0.0, 0.6956521739130435, 0.4903047091412743, 0.4, 0.235, 0.6403314917127072, 0.08333333333333333, 0.17994891828649676, 0.22763620514485364, 0.0, 1.0, 0.2, 0.09521836084564378], 
reward next is 0.7048, 
noisyNet noise sample is [array([-1.5387069], dtype=float32), -0.534075]. 
=============================================
[2019-04-17 15:50:57,409] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.1283754e-14 2.0988847e-19 9.8245066e-01 1.5634733e-11 1.6634495e-10
 8.6303435e-14 3.4928033e-11 1.0057447e-08 4.6774395e-10 1.6716928e-11
 1.7549304e-02], sum to 1.0000
[2019-04-17 15:50:57,409] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3220
[2019-04-17 15:50:57,431] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.0, 42.33333333333334, 56.33333333333334, 489.0, 22.5, 23.42907916095911, -0.09801978095396428, 1.0, 1.0, 25.0, 6.726303978288708], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3861600.0000, 
sim time next is 3862800.0000, 
raw observation next is [3.0, 41.0, 41.0, 365.0, 22.5, 23.60898267365078, -0.1763876073130674, 1.0, 1.0, 25.0, 6.32182588663038], 
processed observation next is [1.0, 0.7391304347826086, 0.5457063711911359, 0.41, 0.13666666666666666, 0.40331491712707185, 0.375, 0.4674152228042316, 0.4412041308956442, 1.0, 1.0, 0.2, 0.0632182588663038], 
reward next is 0.7368, 
noisyNet noise sample is [array([0.640538], dtype=float32), -0.171292]. 
=============================================
[2019-04-17 15:50:57,654] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.86826553e-15 1.03649075e-20 9.85767007e-01 5.66085698e-13
 1.49961033e-11 4.72556208e-15 4.75900005e-12 1.05262821e-09
 7.55766699e-11 2.62747788e-12 1.42330537e-02], sum to 1.0000
[2019-04-17 15:50:57,655] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4806
[2019-04-17 15:50:57,723] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 67.0, 64.83333333333333, 544.8333333333333, 22.5, 24.72145896294557, 0.1870720073749078, 1.0, 1.0, 25.0, 21.816397055930672], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3428400.0000, 
sim time next is 3429600.0000, 
raw observation next is [2.0, 67.0, 52.83333333333334, 447.6666666666667, 22.5, 24.87970549357181, 0.09209172276054339, 1.0, 1.0, 25.0, 19.287702347945526], 
processed observation next is [1.0, 0.6956521739130435, 0.518005540166205, 0.67, 0.17611111111111113, 0.4946593001841621, 0.375, 0.5733087911309841, 0.5306972409201811, 1.0, 1.0, 0.2, 0.19287702347945526], 
reward next is 0.6071, 
noisyNet noise sample is [array([-0.3960182], dtype=float32), 0.80464053]. 
=============================================
[2019-04-17 15:51:04,329] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7293146e-13 3.9674143e-17 9.6668810e-01 1.2177698e-10 9.2245828e-10
 1.1960269e-12 1.8116185e-10 3.7077648e-08 3.2679479e-09 2.5323538e-10
 3.3311844e-02], sum to 1.0000
[2019-04-17 15:51:04,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9441
[2019-04-17 15:51:04,451] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.0, 55.0, 0.0, 0.0, 22.5, 21.58851078393972, -0.4863679181862181, 1.0, 1.0, 25.0, 12.077689074498984], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3349200.0000, 
sim time next is 3350400.0000, 
raw observation next is [-3.0, 55.0, 0.0, 0.0, 22.5, 21.43805223455627, -0.5142351607862707, 1.0, 1.0, 25.0, 12.410091314929215], 
processed observation next is [1.0, 0.782608695652174, 0.3795013850415513, 0.55, 0.0, 0.0, 0.375, 0.2865043528796892, 0.32858827973790977, 1.0, 1.0, 0.2, 0.12410091314929214], 
reward next is 0.6939, 
noisyNet noise sample is [array([0.0029246], dtype=float32), 0.5046167]. 
=============================================
[2019-04-17 15:51:04,484] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.59391761e-14 6.43702285e-19 9.71435606e-01 1.66353927e-11
 1.09605706e-10 1.57958160e-13 3.19557193e-11 4.76056705e-09
 2.82731172e-10 3.95755234e-11 2.85644159e-02], sum to 1.0000
[2019-04-17 15:51:04,485] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0573
[2019-04-17 15:51:04,609] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.0, 48.66666666666666, 51.83333333333334, 439.6666666666667, 22.5, 23.2863597643846, -0.15716828144515, 1.0, 1.0, 25.0, 19.133203927363695], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3343200.0000, 
sim time next is 3344400.0000, 
raw observation next is [-2.0, 50.0, 35.5, 317.0, 22.5, 23.36736384434074, -0.2434200401826942, 1.0, 1.0, 25.0, 17.115088328460807], 
processed observation next is [1.0, 0.7391304347826086, 0.40720221606648205, 0.5, 0.11833333333333333, 0.35027624309392263, 0.375, 0.4472803203617284, 0.41885998660576856, 1.0, 1.0, 0.2, 0.17115088328460806], 
reward next is 0.6288, 
noisyNet noise sample is [array([0.26067403], dtype=float32), 1.6961526]. 
=============================================
[2019-04-17 15:51:06,024] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.6350144e-15 9.8044434e-21 9.7757119e-01 2.6651860e-12 1.2654767e-11
 1.1168308e-14 1.4692553e-12 1.2982410e-09 1.6022654e-11 5.6612571e-12
 2.2428764e-02], sum to 1.0000
[2019-04-17 15:51:06,025] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9389
[2019-04-17 15:51:06,100] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 19.0, 21.86560710137543, -0.3947043358099507, 0.0, 1.0, 25.0, 11.89036692954836], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3211200.0000, 
sim time next is 3212400.0000, 
raw observation next is [-1.333333333333333, 100.0, 0.0, 0.0, 19.0, 21.74504011691903, -0.4193540862074858, 0.0, 1.0, 25.0, 12.12773298649362], 
processed observation next is [1.0, 0.17391304347826086, 0.42566943674976926, 1.0, 0.0, 0.0, 0.08333333333333333, 0.31208667640991905, 0.3602153045975047, 0.0, 1.0, 0.2, 0.1212773298649362], 
reward next is 0.6787, 
noisyNet noise sample is [array([1.8519226], dtype=float32), 0.38001323]. 
=============================================
[2019-04-17 15:51:08,951] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8268728e-13 6.8436937e-18 9.6379936e-01 1.8198087e-10 2.8732564e-10
 1.0331676e-12 1.3684075e-10 4.2874607e-08 4.9010569e-09 5.0737567e-11
 3.6200654e-02], sum to 1.0000
[2019-04-17 15:51:08,952] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4809
[2019-04-17 15:51:09,070] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.0, 60.0, 93.0, 540.0, 22.5, 21.0112530136621, -0.6795177528582715, 1.0, 1.0, 25.0, 11.159737701779644], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3402000.0000, 
sim time next is 3403200.0000, 
raw observation next is [-1.110223024625157e-16, 56.00000000000001, 97.0, 618.6666666666667, 22.5, 21.16624002866881, -0.6430494247905437, 1.0, 1.0, 25.0, 10.847528749685754], 
processed observation next is [1.0, 0.391304347826087, 0.46260387811634357, 0.56, 0.3233333333333333, 0.6836095764272561, 0.375, 0.26385333572240083, 0.2856501917364854, 1.0, 1.0, 0.2, 0.10847528749685754], 
reward next is 0.6614, 
noisyNet noise sample is [array([-1.7944998], dtype=float32), 1.6030574]. 
=============================================
